{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d6bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 패키지로드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import librosa\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07811e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"./acc/sample_submission.csv\")\n",
    "\n",
    "africa_train_paths = glob(\"./acc/train/africa/*.wav\")\n",
    "australia_train_paths = glob(\"./acc/train/australia/*.wav\")\n",
    "canada_train_paths = glob(\"./acc/train/canada/*.wav\")\n",
    "england_train_paths = glob(\"./acc/train/england/*.wav\")\n",
    "hongkong_train_paths = glob(\"./acc/train/hongkong/*.wav\")\n",
    "us_train_paths = glob(\"./acc/train/us/*.wav\")\n",
    "\n",
    "path_list = [africa_train_paths, australia_train_paths, canada_train_paths,\n",
    "             england_train_paths, hongkong_train_paths, us_train_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c913cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./acc/test/1636.wav</td>\n",
       "      <td>1636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./acc/test/2045.wav</td>\n",
       "      <td>2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./acc/test/3766.wav</td>\n",
       "      <td>3766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./acc/test/576.wav</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./acc/test/5634.wav</td>\n",
       "      <td>5634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  path    id\n",
       "0  ./acc/test/1636.wav  1636\n",
       "1  ./acc/test/2045.wav  2045\n",
       "2  ./acc/test/3766.wav  3766\n",
       "3   ./acc/test/576.wav   576\n",
       "4  ./acc/test/5634.wav  5634"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glob로 test data의 path를 불러올때 순서대로 로드되지 않을 경우를 주의해야 합니다.\n",
    "# test_ 데이터 프레임을 만들어서 나중에 sample_submission과 id를 기준으로 merge시킬 준비를 합니다.\n",
    "\n",
    "def get_id(data):\n",
    "    return data.split(\"/\")[3].split(\".\")[0]\n",
    "\n",
    "test_ = pd.DataFrame(index = range(0, 6100), columns = [\"path\", \"id\"])\n",
    "test_[\"path\"] = glob(\"./acc/test/*.wav\")\n",
    "test_[\"id\"] = test_[\"path\"].apply(lambda x : get_id(x))\n",
    "\n",
    "test_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5b841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(paths):\n",
    "\n",
    "    result = []\n",
    "    for path in tqdm(paths):\n",
    "        # sr = 16000이 의미하는 것은 1초당 16000개의 데이터를 샘플링 한다는 것입니다.\n",
    "        data, sr = librosa.load(path, sr = 16000)\n",
    "        result.append(data)\n",
    "    result = np.array(result) \n",
    "    # 메모리가 부족할 때는 데이터 타입을 변경해 주세요 ex) np.array(data, dtype = np.float32)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6353b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [07:34<00:00,  5.50it/s]\n",
      "100%|██████████| 1000/1000 [02:57<00:00,  5.62it/s]\n",
      "100%|██████████| 1000/1000 [02:57<00:00,  5.63it/s]\n",
      "100%|██████████| 10000/10000 [29:44<00:00,  5.60it/s] \n",
      "100%|██████████| 1020/1020 [03:10<00:00,  5.36it/s]\n",
      "100%|██████████| 10000/10000 [29:30<00:00,  5.65it/s] \n",
      "100%|██████████| 6100/6100 [18:17<00:00,  5.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# train 데이터를 로드하기 위해서는 많은 시간이 소모 됩니다.\n",
    "# 따라서 추출된 정보를 npy파일로 저장하여 필요 할 때마다 불러올 수 있게 준비합니다.\n",
    "\n",
    "os.mkdir(\"./npy_data\")\n",
    "\n",
    "africa_train_data = load_data(africa_train_paths)\n",
    "np.save(\"./npy_data/africa_npy\", africa_train_data)\n",
    "\n",
    "australia_train_data = load_data(australia_train_paths)\n",
    "np.save(\"./npy_data/australia_npy\", australia_train_data)\n",
    "\n",
    "canada_train_data = load_data(canada_train_paths)\n",
    "np.save(\"./npy_data/canada_npy\", canada_train_data)\n",
    "\n",
    "england_train_data = load_data(england_train_paths)\n",
    "np.save(\"./npy_data/england_npy\", england_train_data)\n",
    "\n",
    "hongkong_train_data = load_data(hongkong_train_paths)\n",
    "np.save(\"./npy_data/hongkong_npy\", hongkong_train_data)\n",
    "\n",
    "us_train_data = load_data(us_train_paths)\n",
    "np.save(\"./npy_data/us_npy\", us_train_data)\n",
    "\n",
    "test_data = load_data(test_[\"path\"])\n",
    "np.save(\"./npy_data/test_npy\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6d5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# npy파일로 저장된 데이터를 불러옵니다.\n",
    "africa_train_data = np.load(\"./npy_data/africa_npy.npy\", allow_pickle = True)\n",
    "australia_train_data = np.load(\"./npy_data/australia_npy.npy\", allow_pickle = True)\n",
    "canada_train_data = np.load(\"./npy_data/canada_npy.npy\", allow_pickle = True)\n",
    "england_train_data = np.load(\"./npy_data/england_npy.npy\", allow_pickle = True)\n",
    "hongkong_train_data = np.load(\"./npy_data/hongkong_npy.npy\", allow_pickle = True)\n",
    "us_train_data = np.load(\"./npy_data/us_npy.npy\", allow_pickle = True)\n",
    "\n",
    "test_data = np.load(\"./npy_data/test_npy.npy\", allow_pickle = True)\n",
    "\n",
    "train_data_list = [africa_train_data, australia_train_data, canada_train_data, england_train_data, hongkong_train_data, us_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672c878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 이번 대회에서 음성은 각각 다른 길이를 갖고 있습니다.\n",
    "# baseline 코드에서는 음성 중 길이가 가장 작은 길이의 데이터를 기준으로 데이터를 잘라서 사용합니다.\n",
    "\n",
    "def get_mini(data):\n",
    "\n",
    "    mini = 9999999\n",
    "    for i in data:\n",
    "        if len(i) < mini:\n",
    "            mini = len(i)\n",
    "\n",
    "    return mini\n",
    "\n",
    "#음성들의 길이를 맞춰줍니다.\n",
    "\n",
    "def set_length(data, d_mini):\n",
    "\n",
    "    result = []\n",
    "    for i in data:\n",
    "        result.append(i[:d_mini])\n",
    "    result = np.array(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "#feature를 생성합니다.\n",
    "\n",
    "def get_feature(data, sr = 16000, n_fft = 256, win_length = 200, hop_length = 160, n_mels = 64):\n",
    "    mel = []\n",
    "    for i in data:\n",
    "        # win_length 는 음성을 작은 조각으로 자를때 작은 조각의 크기입니다.\n",
    "        # hop_length 는 음성을 작은 조각으로 자를때 자르는 간격을 의미합니다.\n",
    "        # n_mels 는 적용할 mel filter의 개수입니다.\n",
    "        mel_ = librosa.feature.melspectrogram(i, sr = sr, n_fft = n_fft, win_length = win_length, hop_length = hop_length, n_mels = n_mels)\n",
    "        mel.append(mel_)\n",
    "    mel = np.array(mel)\n",
    "    mel = librosa.power_to_db(mel, ref = np.max)\n",
    "\n",
    "    mel_mean = mel.mean()\n",
    "    mel_std = mel.std()\n",
    "    mel = (mel - mel_mean) / mel_std\n",
    "\n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18125960",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.concatenate(train_data_list, axis= 0)\n",
    "test_x = np.array(test_data)\n",
    "\n",
    "# 음성의 길이 중 가장 작은 길이를 구합니다.\n",
    "\n",
    "train_mini = get_mini(train_x)\n",
    "test_mini = get_mini(test_x)\n",
    "\n",
    "mini = np.min([train_mini, test_mini])\n",
    "\n",
    "# data의 길이를 가장 작은 길이에 맞춰 잘라줍니다.\n",
    "\n",
    "train_x = set_length(train_x, mini)\n",
    "test_x = set_length(test_x, mini)\n",
    "\n",
    "# librosa를 이용해 feature를 추출합니다.\n",
    "\n",
    "train_x = get_feature(data = train_x)\n",
    "test_x = get_feature(data = test_x)\n",
    "\n",
    "train_x = train_x.reshape(-1, train_x.shape[1], train_x.shape[2], 1)\n",
    "test_x = test_x.reshape(-1, test_x.shape[1], test_x.shape[2], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af410e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6100, 64, 501, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aada3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25520, 64, 501, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5640e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#라벨링\n",
    "train_y = np.concatenate((np.zeros(len(africa_train_data), dtype = np.int),\n",
    "                        np.ones(len(australia_train_data), dtype = np.int),\n",
    "                         np.ones(len(canada_train_data), dtype = np.int) * 2,\n",
    "                         np.ones(len(england_train_data), dtype = np.int) * 3,\n",
    "                         np.ones(len(hongkong_train_data), dtype = np.int) * 4,\n",
    "                         np.ones(len(us_train_data), dtype = np.int) * 5), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c572b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_y = pd.get_dummies(train_y).to_numpy(dtype = 'long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab3c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25520, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a167fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15bb7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"numpy array를 tensor(torch)로 변환합니다.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        x, y = sample['x'], sample['y']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        x = x.transpose((2, 0, 1))\n",
    "        return {'x': torch.FloatTensor(x),\n",
    "                'y': torch.FloatTensor(y)}\n",
    "to_tensor = transforms.Compose([\n",
    "                      ToTensor() \n",
    "])\n",
    "class CustomDataset(torch.utils.data.Dataset): \n",
    "    def __init__(self,train_x,train_y,transforms=to_tensor):\n",
    "        self.x_data = train_x\n",
    "        self.y_data = train_y\n",
    "        self.transforms = transforms# Transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        \n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        sample = {'x': x, 'y': y}\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        y = y.astype(np.float32)\n",
    "        \n",
    "        \n",
    "        return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99d73f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu 할당\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dd85b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelResnet(\n",
       "  (conv2d): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (FC): Linear(in_features=1000, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiLabelResnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLabelResnet, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(64, 3, 1, stride=1)\n",
    "        self.resnet = timm.create_model('resnet101', pretrained=False) \n",
    "        self.FC = nn.Linear(1000, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # resnet의 입력은 [3, N, N]으로\n",
    "        # 3개의 채널을 갖기 때문에\n",
    "        # resnet 입력 전에 conv2d를 한 층 추가\n",
    "        x = F.relu(self.conv2d(x))\n",
    "\n",
    "        # resnet18을 추가\n",
    "        x = F.relu(self.resnet(x))\n",
    "\n",
    "        # 마지막 출력에 nn.Linear를 추가\n",
    "        # multilabel을 예측해야 하기 때문에\n",
    "        # softmax가 아닌 sigmoid를 적용\n",
    "        #x = self.FC(x)\n",
    "        x = torch.sigmoid(self.FC(x))\n",
    "        return x\n",
    "# 모델 선언\n",
    "\n",
    "model = MultiLabelResnet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a56441fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd77c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(train_x,train_y)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a811ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion  = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93bda17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|██████████| 100/100 [00:36<00:00,  2.72batch/s, train_acc=0.178, train_loss=0.448]\n",
      "Train Epoch 2: 100%|██████████| 100/100 [00:36<00:00,  2.71batch/s, train_acc=0.264, train_loss=0.446]\n",
      "Train Epoch 3: 100%|██████████| 100/100 [00:37<00:00,  2.69batch/s, train_acc=0.267, train_loss=0.444]\n",
      "Train Epoch 4: 100%|██████████| 100/100 [00:37<00:00,  2.68batch/s, train_acc=0.265, train_loss=0.442]\n",
      "Train Epoch 5: 100%|██████████| 100/100 [00:37<00:00,  2.67batch/s, train_acc=0.269, train_loss=0.44]\n",
      "Train Epoch 6: 100%|██████████| 100/100 [00:37<00:00,  2.66batch/s, train_acc=0.269, train_loss=0.437]\n",
      "Train Epoch 7: 100%|██████████| 100/100 [00:37<00:00,  2.66batch/s, train_acc=0.27, train_loss=0.435]\n",
      "Train Epoch 8: 100%|██████████| 100/100 [00:37<00:00,  2.65batch/s, train_acc=0.271, train_loss=0.432]\n",
      "Train Epoch 9: 100%|██████████| 100/100 [00:37<00:00,  2.65batch/s, train_acc=0.271, train_loss=0.431]\n",
      "Train Epoch 10: 100%|██████████| 100/100 [00:37<00:00,  2.65batch/s, train_acc=0.275, train_loss=0.429]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 모델의 dropoupt, batchnormalization를 train 모드로 설정\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1,10+1):\n",
    "    # 1개 epoch 훈련\n",
    "    train_acc_list = []\n",
    "    with tqdm(dataloader,#train_data_loader를 iterative하게 반환\n",
    "            total=dataloader.__len__(), # train_data_loader의 크기\n",
    "            unit=\"batch\") as train_bar: # 한번 반환하는 smaple의 단위는 \"batch\"\n",
    "        for idx,sample in enumerate(train_bar):\n",
    "            if idx == 224 :\n",
    "                break\n",
    "            train_bar.set_description(f\"Train Epoch {epoch}\")\n",
    "            # 갱신할 변수들에 대한 모든 변화도를 0으로 초기화\n",
    "            # 참고)https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            images, labels = sample\n",
    "            # tensor를 gpu에 올리기 \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "\n",
    "            \n",
    "            # .forward()에서 중간 노드의 gradient를 계산\n",
    "            with torch.set_grad_enabled(True):\n",
    "                # 모델 예측\n",
    "                probs = model(images)\n",
    "                probs = F.softmax(probs)\n",
    "               # probs = (probs == probs.max()) * 1.0\n",
    "                #loss = criterion(probs, y_train)\n",
    "                \n",
    "                \n",
    "                loss = criterion(probs, labels)\n",
    "                #loss = criterion(probs, torch.max(y_train, 1)[1])\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                probs  = probs.cpu().detach().numpy()\n",
    "                labels = labels.cpu().detach().numpy()\n",
    "                # train accuracy 계산\n",
    "                cnt = 0\n",
    "                for i in range(0,175):\n",
    "                    if probs[i].argmax() == labels[i].argmax():\n",
    "                    \n",
    "                        cnt +=1\n",
    "                        \n",
    "        \n",
    "                #preds = probs > 0.5\n",
    "                #batch_acc = (labels == preds).mean()\n",
    "                batch_acc = cnt/256 #(배치사이즈로 나누기)\n",
    "                train_acc_list.append(batch_acc)\n",
    "                train_acc = np.mean(train_acc_list)\n",
    "\n",
    "            # 현재 progress bar에 현재 미니배치의 loss 결과 출력\n",
    "            train_bar.set_postfix(train_loss= loss.item(),\n",
    "                                    train_acc = train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51a9037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0c9bb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([212, 6])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1259f75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4080, 0.4133, 0.3688, 0.7125, 0.3799, 0.7079], device='cuda:0',\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[179]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11a02175",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2981065a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4402, 0.3849, 0.4081, 0.6494, 0.3744, 0.7220],\n",
       "        [0.4264, 0.3729, 0.4102, 0.6647, 0.3673, 0.7419],\n",
       "        [0.4028, 0.3277, 0.3589, 0.7337, 0.3404, 0.8159],\n",
       "        ...,\n",
       "        [0.4398, 0.3776, 0.3898, 0.6565, 0.3651, 0.7151],\n",
       "        [0.4323, 0.3492, 0.3824, 0.6936, 0.3503, 0.7744],\n",
       "        [0.4264, 0.3916, 0.4190, 0.6495, 0.3813, 0.7322]], device='cuda:0',\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee954e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df6d9364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6100, 64, 501, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cfe096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_y = pd.DataFrame(index=range(0,len(test_x)), columns=['0', '1', '2', '3', '4', '5'])\n",
    "test_y = test_y.fillna(0).to_numpy()\n",
    "dataset = CustomDataset(test_x,test_y)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfbc0080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b42b6b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6100, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57d82f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ = []\n",
    "for idx, sample in enumerate(dataloader):\n",
    "    with torch.no_grad():\n",
    "        # 추론\n",
    "        model.eval()\n",
    "        images,_ = sample\n",
    "        images = images.to(device)\n",
    "        probs  = model(images)\n",
    "        probs = F.softmax(probs)\n",
    "        probs = probs.cpu().detach().numpy()\n",
    "        pred_.append(probs)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9b45908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 6)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46cb6e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.15157057, 0.15375239, 0.14690813, 0.19858463, 0.15054806,\n",
       "         0.19863619],\n",
       "        [0.15023679, 0.15304187, 0.14553908, 0.20272414, 0.14728282,\n",
       "         0.20117536],\n",
       "        [0.14998494, 0.15468429, 0.14548811, 0.20463553, 0.14651199,\n",
       "         0.19869515],\n",
       "        ...,\n",
       "        [0.1495984 , 0.15174147, 0.14601216, 0.20251873, 0.14862378,\n",
       "         0.20150548],\n",
       "        [0.15158302, 0.1554691 , 0.14678638, 0.198491  , 0.15035564,\n",
       "         0.19731481],\n",
       "        [0.15330476, 0.15870261, 0.14831421, 0.19460163, 0.15203936,\n",
       "         0.19303748]], dtype=float32),\n",
       " array([[0.1481286 , 0.15474829, 0.14566131, 0.20342004, 0.14660773,\n",
       "         0.2014341 ],\n",
       "        [0.14698723, 0.15581152, 0.14398839, 0.20303325, 0.1473341 ,\n",
       "         0.20284556],\n",
       "        [0.1515528 , 0.15458037, 0.14757988, 0.19696695, 0.15020427,\n",
       "         0.19911568],\n",
       "        ...,\n",
       "        [0.14821756, 0.15302   , 0.14563133, 0.2041979 , 0.14497176,\n",
       "         0.20396143],\n",
       "        [0.1497958 , 0.15209864, 0.14711751, 0.2036754 , 0.14596651,\n",
       "         0.20134611],\n",
       "        [0.14543335, 0.15061136, 0.14098783, 0.21122228, 0.1430808 ,\n",
       "         0.20866434]], dtype=float32),\n",
       " array([[0.15128247, 0.15073198, 0.14641517, 0.20190139, 0.14824119,\n",
       "         0.2014278 ],\n",
       "        [0.15430138, 0.15413688, 0.14760931, 0.19899803, 0.14917393,\n",
       "         0.19578046],\n",
       "        [0.15316154, 0.15606838, 0.148693  , 0.19361265, 0.15177055,\n",
       "         0.19669388],\n",
       "        ...,\n",
       "        [0.15346836, 0.1557396 , 0.14880508, 0.1940803 , 0.15304092,\n",
       "         0.19486575],\n",
       "        [0.15127692, 0.15605615, 0.14690107, 0.19697757, 0.15100782,\n",
       "         0.19778048],\n",
       "        [0.15141913, 0.15398552, 0.14603393, 0.20201628, 0.14659308,\n",
       "         0.19995214]], dtype=float32),\n",
       " array([[0.15209125, 0.15796357, 0.1478128 , 0.1956627 , 0.14913057,\n",
       "         0.19733907],\n",
       "        [0.15095817, 0.15291817, 0.1471919 , 0.2008512 , 0.14780234,\n",
       "         0.20027818],\n",
       "        [0.15192871, 0.15363023, 0.14489189, 0.20146717, 0.1472038 ,\n",
       "         0.20087816],\n",
       "        ...,\n",
       "        [0.14855221, 0.15925266, 0.14724457, 0.19450772, 0.15114564,\n",
       "         0.1992972 ],\n",
       "        [0.15362321, 0.15527862, 0.14847118, 0.19521005, 0.15085886,\n",
       "         0.19655804],\n",
       "        [0.1511372 , 0.15680422, 0.14550468, 0.20029365, 0.14738077,\n",
       "         0.19887945]], dtype=float32),\n",
       " array([[0.14984466, 0.15438218, 0.14653388, 0.19971558, 0.14754494,\n",
       "         0.20197874],\n",
       "        [0.15363061, 0.15494296, 0.1505706 , 0.19221252, 0.15456955,\n",
       "         0.19407378],\n",
       "        [0.14712211, 0.14964952, 0.14350913, 0.21005219, 0.1410883 ,\n",
       "         0.20857875],\n",
       "        ...,\n",
       "        [0.15128137, 0.1566136 , 0.14863195, 0.19530365, 0.15259896,\n",
       "         0.19557053],\n",
       "        [0.15066314, 0.15177387, 0.14390223, 0.20215999, 0.14714551,\n",
       "         0.20435525],\n",
       "        [0.1502256 , 0.15621592, 0.14591336, 0.19995828, 0.14705022,\n",
       "         0.20063666]], dtype=float32),\n",
       " array([[0.15134738, 0.15510479, 0.14737907, 0.19731547, 0.1505997 ,\n",
       "         0.19825357],\n",
       "        [0.15362352, 0.15712924, 0.14770497, 0.19386336, 0.15392272,\n",
       "         0.1937562 ],\n",
       "        [0.15219407, 0.1543663 , 0.14734298, 0.19792461, 0.14971212,\n",
       "         0.19845992],\n",
       "        ...,\n",
       "        [0.15140878, 0.15460153, 0.14629859, 0.19872555, 0.1485539 ,\n",
       "         0.20041165],\n",
       "        [0.14920439, 0.15363814, 0.14571299, 0.20376113, 0.1463385 ,\n",
       "         0.20134477],\n",
       "        [0.15101637, 0.15330637, 0.14683919, 0.19978315, 0.15004632,\n",
       "         0.19900861]], dtype=float32),\n",
       " array([[0.15052898, 0.15640435, 0.14670397, 0.19753568, 0.15097776,\n",
       "         0.1978492 ],\n",
       "        [0.15235208, 0.15342276, 0.14762087, 0.20013642, 0.14937663,\n",
       "         0.19709127],\n",
       "        [0.15007107, 0.15607274, 0.14588   , 0.19905394, 0.14843902,\n",
       "         0.2004832 ],\n",
       "        ...,\n",
       "        [0.1548453 , 0.15509912, 0.15017182, 0.19066186, 0.15432066,\n",
       "         0.19490121],\n",
       "        [0.15052521, 0.153661  , 0.1465009 , 0.20149468, 0.14606082,\n",
       "         0.20175748],\n",
       "        [0.15058249, 0.15765277, 0.14661084, 0.19613054, 0.15272056,\n",
       "         0.19630289]], dtype=float32),\n",
       " array([[0.15130176, 0.15374376, 0.1459185 , 0.19845563, 0.14954185,\n",
       "         0.2010385 ],\n",
       "        [0.15287016, 0.15624975, 0.14796816, 0.19668975, 0.14876908,\n",
       "         0.19745313],\n",
       "        [0.15137215, 0.1528158 , 0.14749473, 0.2010407 , 0.1472722 ,\n",
       "         0.20000447],\n",
       "        ...,\n",
       "        [0.14879522, 0.1551696 , 0.14586787, 0.20342788, 0.14765543,\n",
       "         0.19908403],\n",
       "        [0.15075132, 0.15232465, 0.14672317, 0.200246  , 0.14972013,\n",
       "         0.20023476],\n",
       "        [0.15175356, 0.156336  , 0.1478948 , 0.19692467, 0.15081212,\n",
       "         0.19627881]], dtype=float32),\n",
       " array([[0.14730531, 0.15253192, 0.14519759, 0.2046952 , 0.14571908,\n",
       "         0.20455092],\n",
       "        [0.1511539 , 0.15808311, 0.15001288, 0.19168232, 0.15405476,\n",
       "         0.19501303],\n",
       "        [0.15141693, 0.15519753, 0.1477607 , 0.19695902, 0.14963315,\n",
       "         0.1990326 ],\n",
       "        ...,\n",
       "        [0.14738269, 0.15046746, 0.14238547, 0.21215591, 0.1414718 ,\n",
       "         0.2061366 ],\n",
       "        [0.14603798, 0.14913961, 0.13959911, 0.21414094, 0.14276807,\n",
       "         0.2083142 ],\n",
       "        [0.15120924, 0.15606163, 0.1472426 , 0.19628422, 0.1515555 ,\n",
       "         0.19764686]], dtype=float32),\n",
       " array([[0.15292229, 0.15452224, 0.1463429 , 0.19725354, 0.14900571,\n",
       "         0.19995329],\n",
       "        [0.15040205, 0.1571014 , 0.14666528, 0.19706811, 0.15048029,\n",
       "         0.19828293],\n",
       "        [0.15358675, 0.1547656 , 0.1481984 , 0.1953814 , 0.15323187,\n",
       "         0.1948359 ],\n",
       "        ...,\n",
       "        [0.1528216 , 0.15485282, 0.14886372, 0.19448657, 0.1520728 ,\n",
       "         0.19690241],\n",
       "        [0.15425995, 0.15584056, 0.1497112 , 0.19090188, 0.15560143,\n",
       "         0.19368497],\n",
       "        [0.14907466, 0.15034099, 0.14428405, 0.20579824, 0.14509092,\n",
       "         0.20541118]], dtype=float32),\n",
       " array([[0.15050952, 0.15607706, 0.14577709, 0.20092382, 0.14871274,\n",
       "         0.19799984],\n",
       "        [0.15343526, 0.15367916, 0.14609058, 0.19920987, 0.14803192,\n",
       "         0.19955319],\n",
       "        [0.15090702, 0.15317678, 0.14651589, 0.20000781, 0.1485036 ,\n",
       "         0.20088889],\n",
       "        ...,\n",
       "        [0.14931892, 0.15904021, 0.14628065, 0.19669367, 0.15100072,\n",
       "         0.19766589],\n",
       "        [0.15379135, 0.15368448, 0.14776823, 0.19549659, 0.15171303,\n",
       "         0.19754627],\n",
       "        [0.15160574, 0.15375541, 0.14830652, 0.19943906, 0.14815801,\n",
       "         0.1987353 ]], dtype=float32),\n",
       " array([[0.14993177, 0.15205939, 0.14747585, 0.20179173, 0.14705074,\n",
       "         0.2016905 ],\n",
       "        [0.14873794, 0.14974159, 0.14409   , 0.20568068, 0.14366753,\n",
       "         0.20808221],\n",
       "        [0.14899753, 0.15523757, 0.14643146, 0.2016049 , 0.14653227,\n",
       "         0.20119627],\n",
       "        ...,\n",
       "        [0.15100084, 0.14935553, 0.14592797, 0.20388302, 0.14579044,\n",
       "         0.20404218],\n",
       "        [0.14971001, 0.15596549, 0.14623232, 0.19841184, 0.15195078,\n",
       "         0.19772959],\n",
       "        [0.14943767, 0.15385224, 0.14702445, 0.2024546 , 0.14711621,\n",
       "         0.20011488]], dtype=float32),\n",
       " array([[0.1506416 , 0.15299332, 0.14516993, 0.20277871, 0.14661494,\n",
       "         0.20180155],\n",
       "        [0.14756456, 0.15116453, 0.1452083 , 0.20743811, 0.14493695,\n",
       "         0.20368762],\n",
       "        [0.15023024, 0.15118425, 0.14670034, 0.20205665, 0.14835425,\n",
       "         0.20147422],\n",
       "        ...,\n",
       "        [0.15289706, 0.15459639, 0.14680755, 0.1987097 , 0.14970846,\n",
       "         0.19728084],\n",
       "        [0.15072353, 0.15263551, 0.1452327 , 0.2017314 , 0.14600217,\n",
       "         0.2036746 ],\n",
       "        [0.14975153, 0.15130237, 0.1449895 , 0.20707229, 0.14607513,\n",
       "         0.20080923]], dtype=float32),\n",
       " array([[0.1506219 , 0.15428829, 0.1463661 , 0.19906491, 0.1498214 ,\n",
       "         0.19983736],\n",
       "        [0.15055291, 0.15492328, 0.14841238, 0.19699192, 0.15075491,\n",
       "         0.19836459],\n",
       "        [0.14929616, 0.15124162, 0.14468831, 0.2044663 , 0.14831465,\n",
       "         0.20199299],\n",
       "        ...,\n",
       "        [0.15255453, 0.15421754, 0.14636959, 0.20013703, 0.14949168,\n",
       "         0.19722961],\n",
       "        [0.15303467, 0.15520135, 0.14837714, 0.19492617, 0.15109938,\n",
       "         0.1973613 ],\n",
       "        [0.1516013 , 0.1522976 , 0.14650205, 0.20153585, 0.14736472,\n",
       "         0.20069852]], dtype=float32),\n",
       " array([[0.15223205, 0.15341944, 0.1440157 , 0.20249236, 0.1452165 ,\n",
       "         0.20262402],\n",
       "        [0.15041156, 0.15284307, 0.14706033, 0.19950888, 0.14932942,\n",
       "         0.20084673],\n",
       "        [0.14889477, 0.15211064, 0.14164253, 0.20873107, 0.1425146 ,\n",
       "         0.20610632],\n",
       "        ...,\n",
       "        [0.15152375, 0.1541178 , 0.14897215, 0.19626097, 0.15059718,\n",
       "         0.19852814],\n",
       "        [0.15370019, 0.15301047, 0.14678308, 0.19617894, 0.15136977,\n",
       "         0.1989576 ],\n",
       "        [0.15049353, 0.15424195, 0.1460258 , 0.2002817 , 0.14983402,\n",
       "         0.19912305]], dtype=float32),\n",
       " array([[0.15047778, 0.15338336, 0.1454983 , 0.20131427, 0.14964312,\n",
       "         0.19968313],\n",
       "        [0.148463  , 0.15551932, 0.14321753, 0.2028063 , 0.14569302,\n",
       "         0.20430084],\n",
       "        [0.15150784, 0.15399446, 0.14755625, 0.19891474, 0.14843544,\n",
       "         0.19959125],\n",
       "        ...,\n",
       "        [0.15493263, 0.15443665, 0.14783475, 0.19507091, 0.15165877,\n",
       "         0.19606626],\n",
       "        [0.15003523, 0.15514612, 0.1475081 , 0.19997635, 0.14914764,\n",
       "         0.19818658],\n",
       "        [0.15136735, 0.15584502, 0.14741087, 0.1979426 , 0.15135805,\n",
       "         0.19607612]], dtype=float32),\n",
       " array([[0.1510413 , 0.15382649, 0.1467672 , 0.20015918, 0.14801201,\n",
       "         0.20019382],\n",
       "        [0.14647178, 0.15723525, 0.14212742, 0.2039081 , 0.14558545,\n",
       "         0.204672  ],\n",
       "        [0.1549503 , 0.15459615, 0.14832483, 0.19417599, 0.15199532,\n",
       "         0.19595738],\n",
       "        ...,\n",
       "        [0.15002896, 0.15296212, 0.144398  , 0.20340633, 0.14612779,\n",
       "         0.20307678],\n",
       "        [0.15363699, 0.15426612, 0.14862289, 0.19669005, 0.14986679,\n",
       "         0.19691719],\n",
       "        [0.15139039, 0.15202515, 0.14745831, 0.20140503, 0.14845532,\n",
       "         0.19926582]], dtype=float32),\n",
       " array([[0.14929724, 0.15190125, 0.1466912 , 0.20431304, 0.14568739,\n",
       "         0.20210989],\n",
       "        [0.15193596, 0.15495846, 0.14786825, 0.19682425, 0.15067399,\n",
       "         0.19773905],\n",
       "        [0.15309994, 0.15435895, 0.14815447, 0.19687788, 0.15209919,\n",
       "         0.19540957],\n",
       "        ...,\n",
       "        [0.15021609, 0.15363148, 0.14654662, 0.20189998, 0.14700697,\n",
       "         0.2006989 ],\n",
       "        [0.1508607 , 0.15314972, 0.14505528, 0.20285177, 0.14548862,\n",
       "         0.20259388],\n",
       "        [0.15194012, 0.15433833, 0.1475208 , 0.19838327, 0.14978828,\n",
       "         0.19802918]], dtype=float32),\n",
       " array([[0.1479127 , 0.15226741, 0.14350149, 0.20906451, 0.14348964,\n",
       "         0.20376433],\n",
       "        [0.15133402, 0.15383466, 0.14656906, 0.1985747 , 0.15016401,\n",
       "         0.19952355],\n",
       "        [0.15167433, 0.15816477, 0.14662975, 0.19595137, 0.15184635,\n",
       "         0.19573334],\n",
       "        ...,\n",
       "        [0.15289403, 0.15662906, 0.14801392, 0.19351001, 0.15220538,\n",
       "         0.19674759],\n",
       "        [0.15113063, 0.15295073, 0.14563014, 0.20145099, 0.14844222,\n",
       "         0.20039536],\n",
       "        [0.15200874, 0.15467037, 0.1480996 , 0.19740568, 0.15035425,\n",
       "         0.19746132]], dtype=float32),\n",
       " array([[0.1548247 , 0.15613012, 0.14838357, 0.19338553, 0.15411477,\n",
       "         0.19316131],\n",
       "        [0.15111823, 0.15745063, 0.14661378, 0.19747935, 0.15182531,\n",
       "         0.19551274],\n",
       "        [0.1464456 , 0.14963171, 0.14449772, 0.2082641 , 0.1429356 ,\n",
       "         0.20822524],\n",
       "        ...,\n",
       "        [0.15184289, 0.15665442, 0.1457207 , 0.19848068, 0.15004058,\n",
       "         0.19726072],\n",
       "        [0.14945617, 0.15330826, 0.14632045, 0.20052168, 0.15036833,\n",
       "         0.20002505],\n",
       "        [0.15069975, 0.15641667, 0.14593565, 0.19865797, 0.15040511,\n",
       "         0.19788487]], dtype=float32),\n",
       " array([[0.15223199, 0.15779117, 0.1478147 , 0.19529763, 0.15240926,\n",
       "         0.19445522],\n",
       "        [0.15497556, 0.15629762, 0.14909528, 0.19159436, 0.15459734,\n",
       "         0.19343983],\n",
       "        [0.15229173, 0.15363875, 0.14621104, 0.19814397, 0.15062329,\n",
       "         0.19909121],\n",
       "        ...,\n",
       "        [0.15348446, 0.15586449, 0.14847504, 0.19386491, 0.15145648,\n",
       "         0.19685465],\n",
       "        [0.15228134, 0.15626255, 0.14764795, 0.19807519, 0.14935677,\n",
       "         0.19637628],\n",
       "        [0.14803791, 0.15331712, 0.14537539, 0.20193037, 0.14983986,\n",
       "         0.2014993 ]], dtype=float32),\n",
       " array([[0.14971644, 0.15551011, 0.14628308, 0.19818988, 0.14976335,\n",
       "         0.20053713],\n",
       "        [0.14955889, 0.15242995, 0.14744017, 0.19969632, 0.15086453,\n",
       "         0.20001008],\n",
       "        [0.15251812, 0.15294796, 0.14816904, 0.19886373, 0.15081674,\n",
       "         0.19668435],\n",
       "        ...,\n",
       "        [0.15187885, 0.15378919, 0.1470426 , 0.19969708, 0.14932993,\n",
       "         0.19826233],\n",
       "        [0.15022436, 0.1535    , 0.14706983, 0.19923304, 0.14938904,\n",
       "         0.20058374],\n",
       "        [0.14826225, 0.15035392, 0.14373215, 0.20571898, 0.14707233,\n",
       "         0.20486033]], dtype=float32),\n",
       " array([[0.14767295, 0.1519334 , 0.14518206, 0.20408612, 0.14586689,\n",
       "         0.20525855],\n",
       "        [0.15186785, 0.15592769, 0.14678772, 0.19822268, 0.14922391,\n",
       "         0.19797018],\n",
       "        [0.15026431, 0.15434887, 0.14644445, 0.19889252, 0.14881784,\n",
       "         0.20123194],\n",
       "        ...,\n",
       "        [0.15011293, 0.15573624, 0.1476793 , 0.19849446, 0.15007791,\n",
       "         0.19789907],\n",
       "        [0.14954668, 0.15270051, 0.14490958, 0.2041978 , 0.14536133,\n",
       "         0.2032841 ],\n",
       "        [0.14877899, 0.15361781, 0.14653106, 0.2044005 , 0.14676881,\n",
       "         0.19990288]], dtype=float32),\n",
       " array([[0.14796253, 0.15242627, 0.14503716, 0.20385846, 0.14586592,\n",
       "         0.20484963],\n",
       "        [0.15129207, 0.15104754, 0.14803684, 0.20060688, 0.1487064 ,\n",
       "         0.20031026],\n",
       "        [0.1513413 , 0.15615453, 0.14623557, 0.197871  , 0.15046632,\n",
       "         0.19793127],\n",
       "        ...,\n",
       "        [0.14892672, 0.15421593, 0.14377226, 0.20422219, 0.14468202,\n",
       "         0.20418085],\n",
       "        [0.14656176, 0.15095305, 0.14502476, 0.20704244, 0.14800514,\n",
       "         0.20241286],\n",
       "        [0.1499847 , 0.15322033, 0.14464985, 0.20008646, 0.15145658,\n",
       "         0.20060208]], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11542a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_type(data):\n",
    "    return np.int(data)\n",
    "\n",
    "# 처음에 살펴본 것처럼 glob로 test data의 path는 sample_submission의 id와 같이 1,2,3,4,5.....으로 정렬 되어있지 않습니다.\n",
    "# 만들어둔 test_ 데이터프레임을 이용하여 sample_submission과 predict값의 id를 맞춰줍니다.\n",
    "sample_submission = pd.read_csv(\"./acc/sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "581b9f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>africa</th>\n",
       "      <th>australia</th>\n",
       "      <th>canada</th>\n",
       "      <th>england</th>\n",
       "      <th>hongkong</th>\n",
       "      <th>us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>6096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>6097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>6098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>6099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>6100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  africa  australia  canada  england  hongkong  us\n",
       "0        1       0          0       0        0         0   0\n",
       "1        2       0          0       0        0         0   0\n",
       "2        3       0          0       0        0         0   0\n",
       "3        4       0          0       0        0         0   0\n",
       "4        5       0          0       0        0         0   0\n",
       "...    ...     ...        ...     ...      ...       ...  ..\n",
       "6095  6096       0          0       0        0         0   0\n",
       "6096  6097       0          0       0        0         0   0\n",
       "6097  6098       0          0       0        0         0   0\n",
       "6098  6099       0          0       0        0         0   0\n",
       "6099  6100       0          0       0        0         0   0\n",
       "\n",
       "[6100 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aaac7268",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-10932ebe89a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "result = pd.concat([test_, pd.DataFrame(np.mean(pred, axis = 0))], axis = 1).iloc[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c46a8178",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (256,6) (212,6) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e944433ad4bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3335\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (256,6) (212,6) "
     ]
    }
   ],
   "source": [
    "np.mean(pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88763ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcaset6",
   "language": "python",
   "name": "dcase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
