{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c8e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metrics import evaluate_metrics\n",
    "from eval_metrics import evaluate_metrics_from_lists\n",
    "from eval_metrics import combine_single_and_per_file_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07d416f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from util import get_file_list, get_padding, print_hparams, greedy_decode, \\\n",
    "    calculate_bleu, calculate_spider, LabelSmoothingLoss, beam_search, align_word_embedding, gen_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96263b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d90e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 'Many different types of birds tweeting and whistling in the trees.'\n",
    "pred='Many different types of birds are tweeting and singing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31bf0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f0cb44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import csv\n",
    "from typing import Dict, List, Union, Tuple, Any\n",
    "\n",
    "from coco_caption.pycocotools.coco import COCO\n",
    "from coco_caption.pycocoevalcap.eval import COCOEvalCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ee392df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(data: Union[List[Dict[str, Any]], Dict[str, Any]],\n",
    "               path: Path) \\\n",
    "        -> None:\n",
    "    \"\"\" Write a dict or a list of dicts into a JSON file\n",
    "\n",
    "    :param data: Data to write\n",
    "    :type data: list[dict[str, any]] | dict[str, any]\n",
    "    :param path: Path to the output file\n",
    "    :type path: Path\n",
    "    \"\"\"\n",
    "    with path.open(\"w\") as f:\n",
    "        json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59bd5ef9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'write_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d2d89986ebd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpred_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mwrite_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mwrite_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'write_json' is not defined"
     ]
    }
   ],
   "source": [
    "tmp_dir = Path('tmp')\n",
    "\n",
    "if not tmp_dir.is_dir():\n",
    "    tmp_dir.mkdir()\n",
    "\n",
    "ref_file = tmp_dir.joinpath('ref.json')\n",
    "pred_file = tmp_dir.joinpath('pred.json')\n",
    "\n",
    "write_json(ref, ref_file)\n",
    "write_json(pred, pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f48aacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('tmp/ref.json')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f087c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2107054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = Path('tmp')\n",
    "ref_file = tmp_dir.joinpath('ref.json')\n",
    "pred_file = tmp_dir.joinpath('pred.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd818096",
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoEval.params['audio_id'][0]= cocoRes.getAudioIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea028ed4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-34bca24e123d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcocoEval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dcase_2020_T6/coco_caption/pycocoevalcap/eval.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maudioId\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maudioIds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mgts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudioId\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudioToAnns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudioId\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudioId\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcocoRes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudioToAnns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudioId\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "cocoEval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c9783cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Bleu_1', 0.5150218257646578), ('Bleu_2', 0.34040158314669394), ('Bleu_3', 0.23015204254197477), ('Bleu_4', 0.15081783804225588), ('METEOR', 0.15907197362807568), ('ROUGE_L', 0.36777795785420464), ('CIDEr', 0.371045640092004), ('SPICE', 0.10943448773657152), ('SPIDEr', 0.24024006391428776)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " cocoEval.eval.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50f6fb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coco_caption.pycocotools.coco.COCO at 0x7fb790e5f550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f55b1df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coco_caption.pycocotools.coco.COCO at 0x7fb791445190>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cocoRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a5399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f1afbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coco_caption.pycocotools.coco.COCO at 0x7fb791445790>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cocoRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f7b3399",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004715\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8060, 'reflen': 9433, 'guess': [8060, 7036, 6012, 4988], 'correct': [4922, 1877, 750, 251]}\n",
      "ratio: 0.8544471536095776\n",
      "Bleu_1: 0.515\n",
      "Bleu_2: 0.340\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n"
     ]
    }
   ],
   "source": [
    "coco = COCO(str(ref_file))\n",
    "cocoRes = coco.loadRes(str(pred_file))\n",
    "\n",
    "# Create evaluation object and evaluate metrics\n",
    "cocoEval = COCOEvalCap(coco, cocoRes)\n",
    "cocoEval.params['audio_id']= cocoRes.getAudioIds()\n",
    "cocoEval.evaluate()\n",
    "\n",
    "# Make dict from metrics\n",
    "metrics = dict(\n",
    "        (m, s) for m, s in cocoEval.eval.items()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfacbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "1028개 ref 1028*5\n",
    "pred 1023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d313b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91be6e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2314cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17691950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bleu_1': 0.5150218257646578,\n",
       " 'Bleu_2': 0.34040158314669394,\n",
       " 'Bleu_3': 0.23015204254197477,\n",
       " 'Bleu_4': 0.15081783804225588,\n",
       " 'METEOR': 0.15907197362807568,\n",
       " 'ROUGE_L': 0.36777795785420464,\n",
       " 'CIDEr': 0.371045640092004,\n",
       " 'SPICE': 0.10943448773657152,\n",
       " 'SPIDEr': 0.24024006391428776}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb1d254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b2df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4433ed80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d142da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac268ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spider(output_batch, ref_batch, word_dict_pickle_path):\n",
    "    word_dict = get_word_dict(word_dict_pickle_path)\n",
    "    word_dict[len(word_dict)] = '<pad>'\n",
    "    special_token = ['<sos>', '<eos>', '<pad>']\n",
    "    output_str = [ind_to_str(o, special_token, word_dict) for o in output_batch]\n",
    "    ref_str = [[ind_to_str(r, special_token, word_dict) for r in ref] for ref in ref_batch]\n",
    "\n",
    "    output_str = [' '.join(o) for o in output_str]\n",
    "    ref_str = [[' '.join(r) for r in ref] for ref in ref_str]\n",
    "\n",
    "    metrics, per_file_metrics = evaluate_metrics_from_lists(output_str, ref_str)\n",
    "    score = metrics['SPIDEr']\n",
    "\n",
    "    return score, output_str, ref_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c51097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1c94b3d230>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "from data_handling import get_clotho_loader, get_test_data_loader\n",
    "from model import TransformerModel  # , RNNModel, RNNModelSmall\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "from util import get_file_list, get_padding, print_hparams, greedy_decode, \\\n",
    "    calculate_bleu, calculate_spider, LabelSmoothingLoss, beam_search, align_word_embedding, gen_str\n",
    "from hparams import hparams\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "\n",
    "hp = hparams()\n",
    "parser = argparse.ArgumentParser(description='hparams for model')\n",
    "\n",
    "device = torch.device(hp.device)\n",
    "np.random.seed(hp.seed)\n",
    "torch.manual_seed(hp.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84f4d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d65b24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn14,Cnn10,init_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "742ad746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb03e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transfer_Cnn10(nn.Module):\n",
    "    def __init__(self, freeze_base=True, pretrain_checkpoint=None):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_Cnn10, self).__init__()\n",
    "\n",
    "        audioset_classes_num = 527\n",
    "        self.base = Cnn10()\n",
    "\n",
    "        #self.init_weights()\n",
    "\n",
    "        if pretrain_checkpoint:\n",
    "            self.load_from_pretrain(pretrain_checkpoint)\n",
    "            \n",
    "        #self.base.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        # 안쓰이는이유는 multi-class clasification을 생략하기 때문,\n",
    "\n",
    "        if freeze_base:\n",
    "            # 2단계 freeze / 3단계 freeze X\n",
    "            # Freeze AudioSet pretrained layers\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    #def init_weights(self):\n",
    "        #init_layer(self.fc_transfer)\n",
    "\n",
    "    def load_from_pretrain(self, pretrained_checkpoint):\n",
    "        pretrained_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\"\n",
    "        checkpoint = torch.load(pretrained_checkpoint)\n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_imag.weight')#가중치 삭제  \n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_real.weight')#가중치 삭제\n",
    "        checkpoint['model'].pop('logmel_extractor.melW')#가중치 삭제\n",
    "        checkpoint['model'].pop('fc1.weight')\n",
    "        checkpoint['model'].pop('fc1.bias')\n",
    "        checkpoint['model'].pop('fc_audioset.weight')\n",
    "        checkpoint['model'].pop('fc_audioset.bias')\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        output = self.base(input)\n",
    "\n",
    "        #embedding = output_dict['embedding']\n",
    "        #clipwise_output = output_dict['clipwise_output']\n",
    "\n",
    "        return output #, clipwise_output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a913d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ee00690",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Transfer_Cnn10(freeze_base=True,pretrain_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3c4d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn14,Transfer_Cnn14,init_layer\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, batch_size, dropout=0.5,pretrain_cnn=None,\n",
    "                 pretrain_emb=None,freeze_cnn=True):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.model_type = 'cnn10+transformer'\n",
    "        decoder_layers = TransformerDecoderLayer(d_model=nhid, nhead=nhead, dropout=dropout)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "        self.word_emb = nn.Embedding(ntoken, nhid)\n",
    "        self.ninp = ninp\n",
    "        self.nhid = nhid\n",
    "        self.fc = nn.Linear(512, 512, bias=True)\n",
    "        self.fc1 = nn.Linear(512, nhid, bias=True)\n",
    "        self.dec_fc = nn.Linear(nhid, ntoken)\n",
    "        self.batch_size = batch_size\n",
    "        self.ntoken = ntoken\n",
    "\n",
    "        #def __init__(self, freeze_base, pretrain_checkpoint=None):\n",
    "        pretrain_cnn=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\"\n",
    "        \n",
    "        #self.encoder = Transfer_ResNet54(freeze_base=freeze_cnn, pretrain_checkpoint=pretrain_cnn)\n",
    "        self.encoder = cnn\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pos_encoder = PositionalEncoding(nhid, dropout)\n",
    "        self.generator = nn.Softmax(dim=-1)\n",
    "        self.init_weights()\n",
    "\n",
    "        '''\n",
    "        if pretrain_cnn is not None:\n",
    "            dict_trained = pretrain_cnn\n",
    "            dict_new = self.encoder.state_dict().copy()\n",
    "            new_list = list(self.encoder.state_dict().keys())\n",
    "            trained_list = list(dict_trained.keys())\n",
    "            for i in range(len(new_list)):\n",
    "                dict_new[new_list[i]] = dict_trained[trained_list[i]]\n",
    "            self.encoder.load_state_dict(dict_new)\n",
    "        \n",
    "        if freeze_cnn:\n",
    "            self.freeze_cnn()\n",
    "        '''\n",
    "\n",
    "        if pretrain_emb is not None:\n",
    "            self.word_emb.weight.data = pretrain_emb\n",
    "\n",
    "    '''\n",
    "    def freeze_cnn(self):\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "    '''\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc)\n",
    "        self.word_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dec_fc.bias.data.zero_()\n",
    "        self.dec_fc.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def encode(self, src, input_mask=None):\n",
    "        global x \n",
    "        x = self.encoder(src)  # (batch_size, 2048, T/16, mel_bins/16) ,mixup\n",
    "        x = torch.mean(x, dim=3)  # (batch_size, 2048, T/16)\n",
    "        x = x.permute(2, 0, 1)  # (T/16,batch_size,2048)\n",
    "        x = F.relu_(self.fc(x))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "    def decode(self, mem, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # tgt:(batch_size,T_out)\n",
    "        # mem:(T_mem,batch_size,nhid)\n",
    "\n",
    "        tgt = tgt.transpose(0, 1)  # (T_out,batch_size)\n",
    "        if target_mask is None or target_mask.size(0) != len(tgt):\n",
    "            device = tgt.device\n",
    "            target_mask = self.generate_square_subsequent_mask(len(tgt)).to(device)\n",
    "\n",
    "        tgt = self.dropout(self.word_emb(tgt)) * math.sqrt(self.nhid)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        # mem = self.pos_encoder(mem)\n",
    "        output = self.transformer_decoder(tgt, mem, memory_mask=input_mask, tgt_mask=target_mask,\n",
    "                                          tgt_key_padding_mask=target_padding_mask)\n",
    "        output = self.dec_fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, src, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # src:(batch_size,T_in,feature_dim)\n",
    "        # tgt:(batch_size,T_out)\n",
    "        mem = self.encode(src)\n",
    "        output = self.decode(mem, tgt, input_mask=input_mask, target_mask=target_mask,\n",
    "                             target_padding_mask=target_padding_mask)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3ff1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_emb = align_word_embedding(hp.word_dict_pickle_path, hp.pretrain_emb_path, hp.ntoken,\n",
    "                                        hp.nhid) if hp.load_pretrain_emb else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbd88de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(hp.ntoken, hp.ninp, hp.nhead, hp.nhid, hp.nlayers, hp.batch_size, dropout=0.2,\n",
    "                             pretrain_cnn=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\", pretrain_emb=pretrain_emb, freeze_cnn=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7ef43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6877a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_beam = get_clotho_loader(data_dir=hp.data_dir, split='evaluation',\n",
    "                                        input_field_name='features',\n",
    "                                        output_field_name='words_ind',\n",
    "                                        load_into_memory=False,\n",
    "                                        batch_size=32,\n",
    "                                        nb_t_steps_pad='max',\n",
    "                                        shuffle=False,\n",
    "                                        return_reference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a1a842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src, tgt, tgt_len, ref = next(iter(evaluation_beam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de7d8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = src.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e225e4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        ...,\n",
       "        [-12.5787, -10.3935,  -8.6105,  ..., -41.5464, -42.8459, -43.2396],\n",
       "        [-10.6613,  -8.3408,  -7.2884,  ..., -41.8352, -42.3398, -43.2158],\n",
       "        [ -9.5568, -10.8398,  -9.9628,  ..., -42.3450, -44.2460, -45.3972]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b78dcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 2501,  667,  421, 3916, 2121,  891,  699, 1523, 2648, 2564,  942,\n",
       "        1078, 2503, 3305, 1823, 1584, 1391, 2200, 1823, 1956, 3440,  699, 1929,\n",
       "        2409, 4270, 3354, 3857,  906, 4254,  421, 4106, 3511, 3421, 3338,  359,\n",
       "        3459, 4149, 4027, 1823,  563, 2220, 3142, 3713,  414, 2869, 3338, 3089,\n",
       "         112, 1700, 1623,  540, 1945, 3857, 3270, 1423,  732, 2874,  137, 3037,\n",
       "        1721,  979, 3528, 1462, 2893, 1312, 3671,  719, 4172,  801, 3033,  699,\n",
       "         936, 1312, 1312, 4172, 1923, 4159, 1683, 2884, 2648,  606, 1116, 3270,\n",
       "        2028, 2662,  152, 4069,  519, 1265, 2718, 4220, 2274, 4218, 3997, 3000,\n",
       "        1464, 2718, 2263,  241], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36cfaff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2210ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3ba74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a154e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8897719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output =beam_search(model, src, max_len=30, start_symbol_ind=0, beam_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92493a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 1685, 3917, 3865, 2462, 2102,  316, 2102, 4272, 1823, 2115,  426,\n",
       "        1146, 3494, 1719, 3933, 4239, 3917, 1136, 1386,  766, 1767, 3440,  699,\n",
       "        3440,  437, 3354, 2776, 1312, 4194,   47], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a90922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896e42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bd7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for i in range(output.size()[0]):\n",
    "                output_sentence_ind = []\n",
    "                for j in range(1, output.size(1)):\n",
    "                    sym = output[i, j]\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f77f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08943d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c469b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94322b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_str='Many different types of birds are tweeting and singing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3660bf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5cf1797c0ed3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_file_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_metrics_from_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dcase_2020_T6/eval_metrics.py\u001b[0m in \u001b[0;36mevaluate_metrics_from_lists\u001b[0;34m(predictions, ground_truths, ids)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mground_truths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics, per_file_metrics = evaluate_metrics_from_lists(output_str, ref_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b86fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0891a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
