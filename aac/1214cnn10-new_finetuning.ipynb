{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f52a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58059f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn14,Cnn10,init_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5214a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a900f95",
   "metadata": {},
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abbeed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transfer_Cnn10(nn.Module):\n",
    "    def __init__(self, freeze_base=True, pretrain_checkpoint=None):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_Cnn10, self).__init__()\n",
    "\n",
    "        audioset_classes_num = 527\n",
    "        self.base = Cnn10()\n",
    "\n",
    "        #self.init_weights()\n",
    "\n",
    "        if pretrain_checkpoint:\n",
    "            self.load_from_pretrain(pretrain_checkpoint)\n",
    "            \n",
    "        #self.base.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        # 안쓰이는이유는 multi-class clasification을 생략하기 때문,\n",
    "\n",
    "        if freeze_base:\n",
    "            # 2단계 freeze / 3단계 freeze X\n",
    "            # Freeze AudioSet pretrained layers\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    #def init_weights(self):\n",
    "        #init_layer(self.fc_transfer)\n",
    "\n",
    "    def load_from_pretrain(self, pretrained_checkpoint):\n",
    "        pretrained_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\"\n",
    "        checkpoint = torch.load(pretrained_checkpoint)\n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_imag.weight')#가중치 삭제  \n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_real.weight')#가중치 삭제\n",
    "        checkpoint['model'].pop('logmel_extractor.melW')#가중치 삭제\n",
    "        checkpoint['model'].pop('fc1.weight')\n",
    "        checkpoint['model'].pop('fc1.bias')\n",
    "        checkpoint['model'].pop('fc_audioset.weight')\n",
    "        checkpoint['model'].pop('fc_audioset.bias')\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        output = self.base(input)\n",
    "\n",
    "        #embedding = output_dict['embedding']\n",
    "        #clipwise_output = output_dict['clipwise_output']\n",
    "\n",
    "        return output #, clipwise_output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c2840e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_checkpoint=\"./passt.pt\"\n",
    "checkpoint = torch.load(pretrained_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4cfe7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iteration': 440000,\n",
       " 'model': OrderedDict([('spectrogram_extractor.stft.conv_real.weight',\n",
       "               tensor([[[ 0.0000e+00,  9.4124e-06,  3.7649e-05,  ...,  8.4709e-05,\n",
       "                          3.7649e-05,  9.4124e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00,  9.4122e-06,  3.7646e-05,  ...,  8.4695e-05,\n",
       "                          3.7646e-05,  9.4122e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00,  9.4117e-06,  3.7638e-05,  ...,  8.4652e-05,\n",
       "                          3.7638e-05,  9.4117e-06]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4117e-06,  3.7638e-05,  ..., -8.4652e-05,\n",
       "                          3.7638e-05, -9.4117e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4122e-06,  3.7646e-05,  ..., -8.4695e-05,\n",
       "                          3.7646e-05, -9.4122e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4124e-06,  3.7649e-05,  ..., -8.4709e-05,\n",
       "                          3.7649e-05, -9.4124e-06]]], device='cuda:0')),\n",
       "              ('spectrogram_extractor.stft.conv_imag.weight',\n",
       "               tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -5.7753e-08, -4.6201e-07,  ...,  1.5592e-06,\n",
       "                          4.6201e-07,  5.7753e-08]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1550e-07, -9.2395e-07,  ...,  3.1179e-06,\n",
       "                          9.2395e-07,  1.1550e-07]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1550e-07,  9.2395e-07,  ...,  3.1179e-06,\n",
       "                         -9.2395e-07,  1.1550e-07]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -5.7753e-08,  4.6201e-07,  ...,  1.5592e-06,\n",
       "                         -4.6201e-07,  5.7753e-08]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1527e-21,  9.2214e-21,  ..., -1.7514e-17,\n",
       "                          1.2470e-17, -8.8136e-21]]], device='cuda:0')),\n",
       "              ('logmel_extractor.melW',\n",
       "               tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0043, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       ...,\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "                      device='cuda:0')),\n",
       "              ('bn0.weight',\n",
       "               tensor([1.2579, 1.2287, 1.1752, 1.1472, 1.1341, 1.1017, 1.0914, 1.0787, 1.0651,\n",
       "                       1.0756, 1.0683, 1.0589, 1.0478, 1.0323, 1.0432, 1.0094, 1.0038, 1.0202,\n",
       "                       1.0210, 1.0268, 1.0409, 1.0565, 1.0200, 1.0603, 1.0618, 1.0505, 1.0631,\n",
       "                       1.0512, 1.0770, 1.0790, 1.0833, 1.0788, 1.0826, 1.0741, 1.0893, 1.0994,\n",
       "                       1.1181, 1.1037, 1.1052, 1.1233, 1.1174, 1.1264, 1.1512, 1.1866, 1.2267,\n",
       "                       1.2610, 1.2632, 1.3015, 1.2884, 1.3413, 1.3513, 1.3659, 1.3383, 1.3445,\n",
       "                       1.3790, 1.3468, 1.3447, 1.3394, 1.2890, 1.2610, 1.2722, 1.2695, 1.2540,\n",
       "                       1.2942], device='cuda:0')),\n",
       "              ('bn0.bias',\n",
       "               tensor([ 0.1418,  0.1614,  0.2051,  0.2250,  0.2054,  0.2128,  0.2234,  0.2539,\n",
       "                        0.2251,  0.2122,  0.2185,  0.2002,  0.2017,  0.1822,  0.1683,  0.1444,\n",
       "                        0.1269,  0.1714,  0.1422,  0.1387,  0.1513,  0.1419,  0.1510,  0.1334,\n",
       "                        0.1520,  0.1332,  0.1163,  0.1276,  0.1073,  0.1257,  0.1314,  0.1131,\n",
       "                        0.1414,  0.1328,  0.1064,  0.1035,  0.0991,  0.1022,  0.1113,  0.1031,\n",
       "                        0.0918,  0.0667,  0.0340,  0.0058, -0.0343, -0.0510, -0.0735, -0.0952,\n",
       "                       -0.1210, -0.1620, -0.1719, -0.1713, -0.1978, -0.1898, -0.2296, -0.2104,\n",
       "                       -0.2010, -0.2143, -0.1837, -0.2698, -0.2991, -0.3428, -0.3216, -0.2706],\n",
       "                      device='cuda:0')),\n",
       "              ('bn0.running_mean',\n",
       "               tensor([-14.7698, -13.6179, -13.6138, -13.7430, -14.3962, -14.5996, -15.4520,\n",
       "                       -15.8805, -16.5379, -17.0350, -17.5244, -18.0900, -18.3324, -19.0569,\n",
       "                       -19.5501, -20.2974, -20.4803, -21.0466, -21.3381, -21.5437, -22.0068,\n",
       "                       -22.1964, -22.6461, -23.1714, -23.2960, -23.5023, -23.8864, -24.1805,\n",
       "                       -24.8282, -24.9183, -25.4159, -25.7884, -26.1122, -26.6204, -27.0275,\n",
       "                       -27.5277, -28.0286, -28.3588, -28.8325, -29.3342, -30.0424, -30.7998,\n",
       "                       -31.6253, -32.8063, -33.9453, -34.8903, -35.8278, -36.8257, -37.9765,\n",
       "                       -39.4108, -40.4666, -41.2937, -42.2061, -43.2223, -44.2648, -45.2302,\n",
       "                       -46.2764, -47.3646, -48.5596, -50.5382, -52.2995, -53.9504, -55.6551,\n",
       "                       -57.6545], device='cuda:0')),\n",
       "              ('bn0.running_var',\n",
       "               tensor([596.6601, 575.9350, 560.0305, 552.3881, 547.5211, 543.4526, 540.1447,\n",
       "                       537.5850, 537.4604, 537.6881, 536.0203, 530.9358, 531.9637, 525.5637,\n",
       "                       517.0662, 513.1134, 512.5848, 509.0781, 503.4427, 505.8644, 502.7238,\n",
       "                       499.5360, 499.5542, 495.1674, 495.0078, 492.7249, 487.0581, 484.2194,\n",
       "                       479.8156, 480.9565, 476.3221, 475.1716, 477.7686, 474.1192, 475.2479,\n",
       "                       472.0588, 468.3824, 464.7163, 466.6536, 467.5047, 463.1785, 460.5492,\n",
       "                       459.6526, 470.3666, 489.5420, 499.5362, 507.8021, 513.4002, 517.6402,\n",
       "                       540.6107, 557.5811, 558.7811, 560.7786, 561.4371, 562.8868, 558.7776,\n",
       "                       555.0521, 546.9778, 535.2908, 534.0878, 539.0059, 537.0637, 529.1208,\n",
       "                       521.8989], device='cuda:0')),\n",
       "              ('bn0.num_batches_tracked', tensor(440000, device='cuda:0')),\n",
       "              ('conv_block1.conv1.weight',\n",
       "               tensor([[[[-3.7039e-02, -4.2758e-01,  4.6078e-01],\n",
       "                         [-9.8838e-02, -4.7424e-01,  3.5086e-01],\n",
       "                         [ 5.4757e-02, -2.9605e-01,  4.8484e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.3487e-01, -2.7748e-01, -2.2969e-01],\n",
       "                         [-2.5529e-03, -1.0134e-01, -9.9216e-02],\n",
       "                         [ 8.8498e-02,  4.3399e-01,  3.1902e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.8117e-01,  2.1679e-01,  8.6598e-03],\n",
       "                         [-3.0433e-01,  4.2776e-01, -2.8384e-02],\n",
       "                         [-3.1323e-01,  3.7712e-01, -8.6349e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.1328e-01, -4.7214e-01, -1.5421e-01],\n",
       "                         [-7.4739e-03,  1.5373e-01, -9.9434e-02],\n",
       "                         [ 5.1257e-01,  3.8470e-01,  2.0314e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2202e-01,  1.1475e-01,  1.7375e-01],\n",
       "                         [ 4.6711e-02, -2.4738e-01, -1.1763e-01],\n",
       "                         [-1.2941e-01, -1.4176e-01, -8.9102e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.6680e-01, -5.6923e-01, -3.8833e-01],\n",
       "                         [ 7.2493e-01, -2.7824e-01,  9.7279e-03],\n",
       "                         [ 2.4725e-01, -1.6016e-01,  9.7753e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.4617e-01,  1.1877e-01,  9.5465e-02],\n",
       "                         [ 5.3723e-02,  1.6259e-02,  3.4303e-02],\n",
       "                         [-2.3713e-01, -1.7044e-01, -7.7720e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.7280e-01,  5.4870e-01, -3.0124e-01],\n",
       "                         [-3.1358e-01,  4.4885e-01, -2.8404e-01],\n",
       "                         [-1.4353e-01,  5.0320e-01, -2.3500e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.4014e-04, -6.3007e-02, -2.5290e-01],\n",
       "                         [-1.3695e-02, -7.0924e-02, -1.0243e-01],\n",
       "                         [ 1.5860e-01,  2.4922e-01,  7.3565e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2324e-01, -2.8807e-01,  7.9693e-01],\n",
       "                         [-2.5401e-01, -1.1556e-01,  2.5972e-01],\n",
       "                         [-2.0476e-01, -4.7462e-01, -3.4198e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.0406e-01,  5.1279e-02, -3.6834e-01],\n",
       "                         [-2.3591e-01,  2.6704e-01,  1.5689e-01],\n",
       "                         [-2.8982e-01, -2.9980e-02,  1.7038e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.3808e-02, -2.1475e-01,  2.4791e-01],\n",
       "                         [-1.5626e-01, -2.8334e-01,  9.1087e-02],\n",
       "                         [-8.4360e-02, -1.1746e-01,  1.6794e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.2985e-01, -1.6245e-01, -3.5523e-01],\n",
       "                         [ 5.0251e-01, -1.0382e-01, -3.8975e-01],\n",
       "                         [ 2.4276e-01,  5.4808e-02, -2.7259e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.4744e-01,  2.3009e-01,  8.3530e-01],\n",
       "                         [-1.4976e-01, -2.8275e-01,  2.4763e-01],\n",
       "                         [-1.9248e-01, -3.3660e-01, -1.4239e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.4622e-02, -5.6861e-02, -4.1197e-01],\n",
       "                         [ 5.7208e-01, -5.0864e-02, -4.3210e-01],\n",
       "                         [ 5.4853e-01,  5.0650e-02, -3.2082e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6556e-01, -5.3412e-01, -2.3066e-01],\n",
       "                         [-2.8875e-02,  2.4764e-02, -1.6386e-01],\n",
       "                         [-3.9200e-03,  5.5788e-01,  2.6252e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.1720e-01, -4.7870e-01,  1.1784e-01],\n",
       "                         [-2.0684e-01,  6.2280e-02,  4.1311e-01],\n",
       "                         [ 5.6433e-02,  4.4781e-02,  4.6758e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1200e-01,  2.7321e-01, -3.9600e-02],\n",
       "                         [-3.1901e-01,  3.1452e-01, -2.7479e-03],\n",
       "                         [-3.3993e-01,  3.6536e-01,  5.1426e-04]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.2003e-01,  1.8998e-01,  1.2129e-01],\n",
       "                         [-2.7666e-01,  9.2499e-02, -4.6375e-02],\n",
       "                         [-1.4448e-01,  6.8090e-02,  7.0098e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.7226e-02, -1.2127e-01,  2.3658e-01],\n",
       "                         [-2.4300e-01, -1.9383e-01,  1.1952e-01],\n",
       "                         [ 2.2897e-02, -8.7058e-02,  3.2172e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.3028e-02, -2.3576e-01,  4.1035e-02],\n",
       "                         [ 1.6508e-01, -1.1036e-01,  9.5125e-02],\n",
       "                         [-2.9840e-03,  1.8085e-01,  2.6306e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.4316e-01,  1.1665e+00, -4.3412e-01],\n",
       "                         [ 6.2403e-02, -5.5574e-01,  1.2445e-01],\n",
       "                         [ 5.2582e-02, -3.2262e-01,  1.8072e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.5395e-01,  6.7191e-01, -4.2608e-01],\n",
       "                         [ 1.4435e-01,  7.4019e-01, -1.7308e-01],\n",
       "                         [-2.6455e-01, -1.5263e-02, -2.0942e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.5521e-01, -2.1611e-01,  7.1947e-02],\n",
       "                         [ 3.0966e-01, -3.0091e-01, -7.8164e-03],\n",
       "                         [ 3.0483e-01, -3.1466e-01,  1.5690e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9823e-01, -4.2168e-01,  6.0279e-02],\n",
       "                         [-3.2808e-01, -3.3818e-01,  3.4307e-01],\n",
       "                         [-9.1788e-02,  2.4978e-01,  6.2914e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0916e-01, -1.0632e-02,  4.5488e-01],\n",
       "                         [ 1.1837e-02, -5.0426e-01,  5.5825e-02],\n",
       "                         [ 1.8273e-01, -5.3850e-01,  8.3406e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.7359e-01, -1.8598e-01,  2.1945e-02],\n",
       "                         [ 2.8800e-01, -1.5747e-01, -1.0243e-01],\n",
       "                         [ 1.2883e-01, -3.4466e-01, -1.4244e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.6872e-01, -1.4464e-01,  2.2020e-01],\n",
       "                         [-2.9175e-01,  2.2592e-01,  2.0379e-01],\n",
       "                         [-1.6604e-01,  2.6496e-01, -8.3792e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.5360e-02,  3.8966e-01,  1.4031e-01],\n",
       "                         [ 1.2257e-02,  2.1597e-02, -4.7005e-02],\n",
       "                         [ 9.1067e-02, -1.6526e-01, -1.9378e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0163e-01, -4.5580e-01,  3.1707e-01],\n",
       "                         [ 1.8935e-01, -4.5179e-01,  2.3650e-01],\n",
       "                         [ 2.7485e-01, -4.0986e-01,  2.1443e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.7262e-01, -1.0266e-01, -4.1695e-01],\n",
       "                         [ 4.8492e-01, -2.3177e-03, -4.4562e-01],\n",
       "                         [ 3.3022e-01,  6.2551e-02, -3.2547e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2101e-01,  1.0126e-01, -3.6913e-02],\n",
       "                         [ 1.4700e-01,  6.9705e-02, -3.9404e-02],\n",
       "                         [-5.5072e-02, -1.1184e-01, -6.6921e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.8531e-01, -4.7569e-02, -2.3400e-01],\n",
       "                         [ 3.4791e-01, -7.7497e-02, -2.4477e-01],\n",
       "                         [ 3.7497e-01, -1.4277e-01, -3.4089e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1033e+00,  1.2753e-01, -6.2010e-03],\n",
       "                         [-7.2243e-01, -4.6420e-01, -5.2412e-03],\n",
       "                         [-3.7374e-01,  4.0990e-01, -7.4779e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.1552e-01,  5.3512e-01,  8.1034e-02],\n",
       "                         [-1.1637e-01,  3.2702e-02,  9.7668e-03],\n",
       "                         [ 7.4868e-01, -5.4375e-01, -1.1775e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.5149e-01,  1.8367e-01,  5.9942e-01],\n",
       "                         [ 6.4945e-02, -3.3298e-01,  4.7456e-02],\n",
       "                         [-7.2457e-02, -6.4503e-01, -2.3545e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.3996e-01, -4.6708e-01,  6.5029e-02],\n",
       "                         [ 4.1431e-01, -5.8810e-01, -1.2947e-01],\n",
       "                         [ 6.3620e-01, -4.6198e-01,  8.9512e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.8400e-01,  6.0769e-01,  3.9696e-01],\n",
       "                         [-1.0041e-01, -5.5067e-02, -6.5041e-02],\n",
       "                         [-4.0160e-01, -5.5484e-01, -4.9943e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.7577e-01,  9.2406e-02,  9.8464e-02],\n",
       "                         [-2.4153e-01, -1.5672e-02,  1.2420e-01],\n",
       "                         [-6.3149e-01, -2.6339e-02,  4.9605e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.2362e-01, -4.3782e-01, -5.7199e-01],\n",
       "                         [ 5.7036e-02,  1.7327e-01,  5.8640e-02],\n",
       "                         [ 3.2428e-01,  2.6780e-01,  1.1553e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.2817e-02,  2.5345e-01, -2.3407e-01],\n",
       "                         [ 6.5310e-02,  1.0996e-01, -1.5513e-01],\n",
       "                         [-2.7904e-02,  2.7827e-01, -2.4337e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1770e-01,  3.1490e-01, -9.0855e-01],\n",
       "                         [-1.3766e-01,  3.3192e-03,  7.7066e-01],\n",
       "                         [-5.3093e-02, -3.6863e-01,  2.3213e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.5213e-02, -4.4828e-01,  6.2535e-02],\n",
       "                         [ 5.3619e-02, -4.0840e-01,  4.2392e-03],\n",
       "                         [ 2.0112e-01, -2.2866e-01,  3.0056e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.9792e-01,  2.0081e-01,  1.9037e-01],\n",
       "                         [-2.4127e-01, -3.5608e-01, -2.4821e-01],\n",
       "                         [-3.8929e-02,  1.7353e-01, -4.8857e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.0018e-01,  1.3077e-03, -2.7321e-01],\n",
       "                         [ 2.7165e-02,  3.3843e-02, -7.1168e-02],\n",
       "                         [ 5.3553e-02,  2.3183e-01, -4.2740e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.8983e-01, -3.7882e-02,  7.5205e-01],\n",
       "                         [-4.3510e-01, -2.7665e-01,  5.3879e-01],\n",
       "                         [-3.7065e-01, -1.9793e-01,  3.8153e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0559e-01,  3.1273e-01,  1.5594e-01],\n",
       "                         [ 1.7393e-01, -6.1596e-02, -2.1482e-01],\n",
       "                         [ 1.0072e-01, -3.6248e-01, -2.6370e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0709e-01, -2.5422e-01,  5.1832e-02],\n",
       "                         [ 2.1006e-01, -1.3040e-01, -6.3120e-02],\n",
       "                         [ 6.7084e-02, -9.1186e-02,  8.9826e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.0937e-01,  3.9595e-01,  2.2122e-01],\n",
       "                         [-1.6386e-01,  2.8206e-02, -1.7149e-01],\n",
       "                         [-4.2785e-01, -1.2610e-01, -1.6499e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.4867e-01, -2.5180e-01, -3.5126e-01],\n",
       "                         [-1.1301e-01, -1.2536e-01, -8.0463e-02],\n",
       "                         [ 8.8822e-01,  3.9861e-01,  2.1695e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0753e-02,  4.4991e-02, -2.4421e-01],\n",
       "                         [ 9.5658e-03,  2.3654e-01, -2.5991e-01],\n",
       "                         [ 2.4366e-02,  3.8166e-01, -2.2451e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 8.7838e-01, -5.9983e-02,  1.4472e-01],\n",
       "                         [ 2.1890e-01, -8.2260e-02,  3.5236e-02],\n",
       "                         [-1.6305e-01, -5.5475e-01, -3.4149e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1640e-01,  7.8737e-02, -1.7762e-01],\n",
       "                         [-1.4516e-02,  1.3225e-01,  2.5413e-02],\n",
       "                         [-2.8115e-02,  1.8151e-01, -3.3639e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.3240e-01, -3.6960e-01, -1.5010e-01],\n",
       "                         [ 6.2620e-02,  2.2893e-02,  1.1247e-01],\n",
       "                         [ 2.6827e-01,  3.7458e-01, -8.5182e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0860e-01,  1.1462e+00, -4.2346e-02],\n",
       "                         [-1.4127e-01,  3.0784e-01, -4.1399e-02],\n",
       "                         [-3.6094e-01, -1.9679e-01, -2.6113e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.3481e-01, -2.5167e-01,  3.8530e-01],\n",
       "                         [-1.3977e-01, -3.6216e-01,  1.1309e-03],\n",
       "                         [ 2.0413e-01, -4.5980e-01,  2.9574e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.7680e-02,  2.6627e-01, -2.8784e-01],\n",
       "                         [-3.3592e-01,  2.4736e-01, -1.2399e-01],\n",
       "                         [-2.8255e-01,  8.0267e-01, -4.0267e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.3659e-01, -5.6885e-01, -5.8263e-02],\n",
       "                         [ 2.3202e-01, -3.7275e-01,  4.3137e-02],\n",
       "                         [ 2.3751e-01, -1.1991e-01,  2.6967e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.7833e-01,  6.2141e-01,  4.1701e-01],\n",
       "                         [-9.2735e-02, -3.6468e-02, -3.5021e-01],\n",
       "                         [-5.1336e-02,  1.1924e-01, -1.3558e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.9185e-01,  2.7757e-01,  1.5429e-01],\n",
       "                         [ 2.0638e-01, -9.3221e-02, -4.2492e-02],\n",
       "                         [-3.6869e-01, -2.5070e-01, -3.6196e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1912e-01, -3.4506e-01, -2.0505e-01],\n",
       "                         [-3.5524e-02,  5.3625e-02,  3.3577e-01],\n",
       "                         [ 1.5814e-01, -1.6911e-02,  5.5144e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-7.1422e-01, -9.4341e-02,  4.3752e-02],\n",
       "                         [ 1.3863e+00, -7.7188e-02,  1.9691e-02],\n",
       "                         [-3.5302e-01, -1.1650e-01, -4.4031e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.5821e-01,  1.7370e-01,  3.0065e-01],\n",
       "                         [-4.7475e-01, -6.5231e-01, -4.0496e-01],\n",
       "                         [ 1.6438e-01,  4.0722e-01,  1.4705e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6765e-01, -3.5122e-01, -3.0718e-01],\n",
       "                         [-3.7997e-02, -1.8845e-01,  5.6407e-02],\n",
       "                         [ 2.3948e-01,  2.0316e-01,  6.8780e-01]]]], device='cuda:0')),\n",
       "              ('conv_block1.conv2.weight',\n",
       "               tensor([[[[ 3.7716e-02,  3.8377e-01, -2.6829e-02],\n",
       "                         [ 1.4405e-02, -2.7071e-02, -1.1790e-01],\n",
       "                         [ 3.1483e-02, -1.2675e-01,  1.0402e-01]],\n",
       "               \n",
       "                        [[-1.3191e-01,  5.1577e-02,  9.3906e-02],\n",
       "                         [-1.0973e-01,  1.2606e-01,  6.9330e-02],\n",
       "                         [-7.9789e-02,  1.4824e-01, -2.2891e-01]],\n",
       "               \n",
       "                        [[ 8.4112e-02, -6.5050e-02,  2.2053e-02],\n",
       "                         [-1.6003e-02,  3.6255e-02, -1.0961e-01],\n",
       "                         [ 2.1383e-03,  1.7355e-01, -2.0730e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.2900e-01, -9.4333e-02, -4.8292e-01],\n",
       "                         [ 1.5381e-01, -8.5188e-03,  2.9697e-02],\n",
       "                         [ 1.7547e-01,  5.9568e-02,  4.1180e-01]],\n",
       "               \n",
       "                        [[-6.4412e-02,  2.3372e-02, -8.3541e-02],\n",
       "                         [-5.3537e-02, -8.9693e-02, -1.3112e-02],\n",
       "                         [-5.3418e-02, -4.0995e-02,  1.0250e-01]],\n",
       "               \n",
       "                        [[-2.1671e-01,  2.8036e-02, -1.3197e-04],\n",
       "                         [-3.4290e-02,  5.9299e-02, -1.8906e-02],\n",
       "                         [-5.3243e-02, -4.2178e-02,  2.6321e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0785e+00, -2.0748e-01,  7.5568e-02],\n",
       "                         [ 2.0621e-01, -5.9543e-02,  6.3722e-02],\n",
       "                         [-6.5188e-01, -1.2228e-02,  1.1816e-01]],\n",
       "               \n",
       "                        [[-1.2173e-01,  1.9149e-01,  8.3929e-02],\n",
       "                         [ 8.3358e-02, -2.0013e-01, -1.1041e-02],\n",
       "                         [ 2.7151e-01, -3.6403e-01, -4.3889e-02]],\n",
       "               \n",
       "                        [[-1.7432e-01,  1.5744e-01, -2.0128e-01],\n",
       "                         [ 2.6894e-02, -1.1746e-01, -5.5749e-03],\n",
       "                         [ 2.9326e-01, -4.2377e-01,  5.7002e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.5385e-01, -8.2642e-01,  3.3079e-01],\n",
       "                         [-4.6052e-02, -1.7915e-01,  1.1808e-01],\n",
       "                         [-5.4963e-01,  1.0333e+00, -2.4473e-01]],\n",
       "               \n",
       "                        [[-6.9922e-02,  1.3253e-01,  8.7043e-02],\n",
       "                         [ 1.5732e-01,  1.6859e-01, -2.4649e-02],\n",
       "                         [ 4.5574e-02, -1.4071e-01, -1.5539e-01]],\n",
       "               \n",
       "                        [[ 1.2706e-01,  3.1828e-02,  1.1200e-01],\n",
       "                         [ 9.8312e-02,  3.1909e-02,  8.6010e-02],\n",
       "                         [ 1.4542e-02, -3.4562e-04,  8.4735e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.7297e-02, -1.1035e-01, -1.1087e-01],\n",
       "                         [-7.3131e-02, -9.5376e-02, -9.5487e-02],\n",
       "                         [-8.0729e-02, -9.2381e-04,  2.4190e-02]],\n",
       "               \n",
       "                        [[-1.7203e-01, -4.6300e-01,  2.5281e-01],\n",
       "                         [-1.5188e-01, -4.7515e-01, -3.0280e-02],\n",
       "                         [ 6.9937e-02, -1.2466e-01,  4.5305e-01]],\n",
       "               \n",
       "                        [[ 8.2297e-02,  1.0682e-01,  2.8612e-02],\n",
       "                         [ 1.3627e-01,  4.2858e-02, -3.2870e-02],\n",
       "                         [-3.5023e-02, -7.2602e-02, -2.1970e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.8166e-02,  1.6987e-01,  2.3324e-01],\n",
       "                         [ 2.0293e-01, -1.0903e-02, -1.6093e-01],\n",
       "                         [ 1.5683e-01, -1.1523e-01, -3.9176e-01]],\n",
       "               \n",
       "                        [[ 2.7918e-02, -5.2651e-02, -3.0204e-02],\n",
       "                         [-6.0518e-02, -1.3612e-01, -2.5142e-01],\n",
       "                         [ 8.2353e-02, -6.1556e-02,  5.9971e-02]],\n",
       "               \n",
       "                        [[-7.5691e-02, -5.9457e-03, -4.2270e-02],\n",
       "                         [-4.8160e-02, -3.5608e-02, -2.8247e-02],\n",
       "                         [-1.7834e-02, -7.6805e-02,  2.5366e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-4.9454e-02, -5.7105e-03, -8.8107e-02],\n",
       "                         [-3.6103e-02,  2.0379e-01,  3.4189e-01],\n",
       "                         [-4.2215e-02, -2.1860e-01, -2.4045e-01]],\n",
       "               \n",
       "                        [[-3.0638e-01, -1.8374e-01, -3.8692e-01],\n",
       "                         [ 4.3731e-01,  6.7990e-01,  3.9994e-01],\n",
       "                         [-3.8064e-01, -3.3509e-01, -6.1751e-01]],\n",
       "               \n",
       "                        [[-1.5306e-02, -1.0777e-02, -4.1142e-02],\n",
       "                         [-8.7511e-02, -1.0601e-01, -1.5231e-01],\n",
       "                         [-1.8568e-02,  3.6170e-02, -7.9173e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.1569e-01,  2.8898e-01,  3.5592e-01],\n",
       "                         [-1.0991e+00, -7.5708e-01, -8.5644e-01],\n",
       "                         [ 6.9730e-01,  1.2808e-01,  4.9305e-01]],\n",
       "               \n",
       "                        [[-6.9309e-02, -2.3946e-02, -6.7120e-02],\n",
       "                         [ 7.7438e-02,  7.9852e-02, -2.2187e-02],\n",
       "                         [-5.7858e-02, -7.3175e-03, -4.6205e-02]],\n",
       "               \n",
       "                        [[ 2.4485e-01,  3.5203e-01,  1.8942e-01],\n",
       "                         [-2.1788e-01, -1.4184e-01, -1.8707e-01],\n",
       "                         [-1.7722e-01, -9.8066e-02, -2.2995e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2625e-02,  1.0379e-02, -8.0609e-02],\n",
       "                         [ 5.3149e-02, -9.3726e-02, -1.0543e-01],\n",
       "                         [ 4.8197e-02, -5.4563e-02, -4.1949e-02]],\n",
       "               \n",
       "                        [[ 1.4315e-02,  7.2706e-02, -6.4910e-02],\n",
       "                         [-3.9319e-02, -1.9981e-01, -9.3217e-02],\n",
       "                         [ 5.4948e-02,  7.2174e-02,  5.5379e-02]],\n",
       "               \n",
       "                        [[-2.6129e-02, -1.1373e-02, -1.9768e-02],\n",
       "                         [ 2.1967e-02,  6.3522e-02,  1.2756e-02],\n",
       "                         [ 9.7849e-02,  8.7106e-02,  4.9843e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.5595e-02, -1.5106e-01,  2.8897e-01],\n",
       "                         [ 9.5800e-02, -1.1059e-01,  1.5325e-01],\n",
       "                         [ 2.9394e-02, -2.9501e-02,  1.2501e-01]],\n",
       "               \n",
       "                        [[ 1.2613e-01,  6.3016e-02,  2.7176e-02],\n",
       "                         [-5.3751e-02, -8.8469e-02, -2.4307e-02],\n",
       "                         [ 7.0750e-02,  2.2604e-02,  1.4919e-02]],\n",
       "               \n",
       "                        [[ 2.6332e-02, -2.9871e-02,  7.3902e-02],\n",
       "                         [ 5.8938e-02,  8.6006e-02,  3.4223e-02],\n",
       "                         [-2.8744e-02,  8.2594e-03,  1.7609e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.7435e-01,  4.7874e-02,  7.0055e-02],\n",
       "                         [ 8.6948e-02,  3.3030e-01,  1.3110e-01],\n",
       "                         [ 1.5556e-01,  3.2963e-01,  1.5869e-01]],\n",
       "               \n",
       "                        [[-6.3539e-01, -6.0424e-01, -2.4252e-01],\n",
       "                         [-1.3502e-01, -1.3486e-01, -3.6140e-01],\n",
       "                         [-5.2280e-01, -4.7667e-01, -5.4187e-01]],\n",
       "               \n",
       "                        [[ 1.0034e-01, -3.9097e-01, -6.2816e-01],\n",
       "                         [-5.8587e-02, -3.5102e-01, -4.4382e-01],\n",
       "                         [-1.9356e-02, -2.9316e-01, -2.4458e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.3339e-01, -3.5807e-01, -7.3283e-03],\n",
       "                         [ 9.7241e-03, -1.2542e-01,  4.9291e-02],\n",
       "                         [ 2.5228e-01, -1.4051e-01, -8.6471e-02]],\n",
       "               \n",
       "                        [[-6.5190e-02, -1.7026e-01, -9.0556e-02],\n",
       "                         [ 1.3915e-01, -3.3030e-02, -7.1347e-02],\n",
       "                         [-2.2762e-05, -1.7184e-01, -1.6950e-02]],\n",
       "               \n",
       "                        [[ 7.2244e-02,  7.6516e-02, -2.7654e-03],\n",
       "                         [ 1.0507e-01, -4.3255e-04,  5.2007e-02],\n",
       "                         [ 2.0332e-02,  1.0466e-01,  5.0690e-02]]]], device='cuda:0')),\n",
       "              ('conv_block1.bn1.weight',\n",
       "               tensor([1.0147, 1.8317, 0.8301, 1.2968, 0.5953, 0.7233, 0.7475, 1.2259, 0.7721,\n",
       "                       1.0568, 1.3650, 0.3360, 0.4459, 0.6781, 0.6541, 0.3440, 0.5908, 1.0499,\n",
       "                       0.6292, 0.5092, 0.6707, 2.1327, 1.5605, 0.8525, 0.6335, 0.9048, 0.8897,\n",
       "                       0.6496, 1.0510, 1.3799, 0.9359, 0.6482, 0.5818, 1.7507, 2.3637, 0.6982,\n",
       "                       0.9968, 0.4719, 0.5994, 0.5357, 0.7040, 2.0022, 0.6293, 0.2890, 0.5688,\n",
       "                       0.9239, 0.6793, 0.5159, 0.4398, 0.5231, 0.6452, 0.8483, 0.5375, 1.9732,\n",
       "                       0.8341, 0.7305, 1.1377, 1.0964, 0.8403, 0.4709, 0.7815, 1.3541, 0.9502,\n",
       "                       1.0875], device='cuda:0')),\n",
       "              ('conv_block1.bn1.bias',\n",
       "               tensor([ 0.6754,  0.1345,  0.0220,  1.3368, -0.6749,  0.0839, -1.3812, -1.3433,\n",
       "                       -0.7652,  0.2082, -1.0769,  0.1627,  0.0673,  0.0511,  0.1200,  0.1681,\n",
       "                        0.0150,  0.0098, -0.7188, -0.5221, -0.8065,  0.4152,  0.2131, -1.1045,\n",
       "                        0.0147, -1.0571,  0.0904, -0.7248, -0.9289, -0.0724,  0.0621, -0.8089,\n",
       "                        0.0928,  0.1172,  0.0503,  0.1471,  0.6545,  0.1610, -0.4684,  0.0174,\n",
       "                       -0.8001,  0.3992, -0.6326,  0.1002, -0.7923,  0.0503, -0.4399, -0.1764,\n",
       "                       -1.0168,  0.0272, -0.1202,  0.1499, -0.9979,  0.2602, -0.7370,  0.1048,\n",
       "                        0.8390, -0.2476,  0.0871,  0.0680,  0.1174,  1.5486, -1.0039, -1.6553],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn1.running_mean',\n",
       "               tensor([-0.0030, -0.0002, -0.0097,  0.0008, -0.0108,  0.0094, -0.0018, -0.0032,\n",
       "                       -0.0002, -0.0022,  0.0009, -0.0213,  0.0035, -0.0077,  0.0031, -0.0275,\n",
       "                       -0.0161, -0.0078, -0.0127, -0.0061,  0.0220,  0.0024,  0.0018,  0.0035,\n",
       "                       -0.0123, -0.0039,  0.0027,  0.0010,  0.0109,  0.0010,  0.0048, -0.0150,\n",
       "                        0.0156,  0.0009,  0.0008,  0.0050,  0.0055, -0.0204, -0.0695, -0.0294,\n",
       "                        0.0018, -0.0023, -0.0279, -0.0122, -0.0161, -0.0047, -0.0007,  0.0002,\n",
       "                       -0.0074,  0.0328,  0.0009,  0.0095, -0.0117, -0.0013,  0.0422,  0.0078,\n",
       "                       -0.0017,  0.0020, -0.0008,  0.0251,  0.0097,  0.0051,  0.0014,  0.0013],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn1.running_var',\n",
       "               tensor([0.1543, 0.0237, 0.0862, 0.0526, 0.0313, 0.1704, 0.0081, 0.1066, 0.0159,\n",
       "                       0.1204, 0.0105, 0.0897, 0.2165, 0.1375, 0.2466, 0.1312, 0.1832, 0.0805,\n",
       "                       0.0449, 0.0544, 0.0787, 0.0197, 0.1028, 0.0528, 0.1611, 0.0675, 0.0803,\n",
       "                       0.0510, 0.0249, 0.0835, 0.2510, 0.1207, 0.1927, 0.0362, 0.0125, 0.0803,\n",
       "                       0.1997, 0.1383, 0.6347, 0.1720, 0.0371, 0.0157, 0.1682, 0.0286, 0.0476,\n",
       "                       0.3584, 0.0377, 0.0152, 0.0391, 0.1976, 0.0495, 0.1186, 0.0258, 0.0243,\n",
       "                       0.3662, 0.0665, 0.0868, 0.0709, 0.0456, 0.1456, 0.0848, 0.0315, 0.0196,\n",
       "                       0.0608], device='cuda:0')),\n",
       "              ('conv_block1.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block1.bn2.weight',\n",
       "               tensor([1.4841, 1.2917, 1.0752, 0.9392, 1.3012, 0.5648, 0.7395, 1.2967, 0.3735,\n",
       "                       1.2988, 1.5531, 1.1796, 1.5098, 0.8108, 0.5671, 1.0800, 1.0263, 1.2715,\n",
       "                       1.3641, 1.3163, 1.5201, 0.6631, 1.1183, 1.1883, 1.2024, 0.8789, 1.3421,\n",
       "                       0.3771, 1.0490, 1.4551, 1.1245, 1.5359, 0.6782, 1.5352, 0.9282, 1.1248,\n",
       "                       1.3073, 0.9236, 1.2908, 1.3024, 0.4935, 1.0720, 0.8583, 1.5085, 1.4076,\n",
       "                       1.4440, 0.6413, 0.6526, 1.0588, 0.5574, 0.6595, 1.0363, 0.7635, 1.3950,\n",
       "                       1.3622, 1.1709, 0.8593, 0.5827, 0.9331, 1.3578, 1.2215, 0.9420, 0.5712,\n",
       "                       0.5443], device='cuda:0')),\n",
       "              ('conv_block1.bn2.bias',\n",
       "               tensor([-0.8234, -0.8081, -0.4838, -0.5944, -0.8566, -0.2404, -0.5236, -0.9160,\n",
       "                       -0.0529, -0.3748, -0.7467, -0.8183, -1.0355, -0.2404, -0.3608, -0.5537,\n",
       "                       -0.6094, -0.5815, -0.5941, -0.8944, -0.6258, -0.1631, -0.5619, -0.8486,\n",
       "                       -0.4367, -0.3251, -0.8718, -0.0486, -0.5740, -0.9323, -0.6806, -0.7423,\n",
       "                       -0.9645, -1.0283, -0.6479, -0.5786, -0.9397, -0.1561, -0.6581, -0.7995,\n",
       "                       -0.1054, -0.5006, -0.2690, -0.9833, -0.6177, -1.0039, -0.5419, -0.7335,\n",
       "                       -0.4527, -0.3228, -0.2103, -0.3911, -0.2588, -0.8303, -0.6102, -0.4021,\n",
       "                       -0.2842, -0.4564, -0.4216, -0.6266, -0.8774, -0.5110, -0.9052, -0.2076],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn2.running_mean',\n",
       "               tensor([ -7.9719,  -3.7649,  -7.8810,  -7.6889, -10.5837,  -4.0918,  -5.6065,\n",
       "                        -6.6311,   2.5603,  -7.6045,  -5.1107,  -4.1815,  -5.9455,  -3.2822,\n",
       "                        -0.6395,  -6.0870,  -6.7635,  -9.0023, -10.2618,  -7.7644,  -7.4981,\n",
       "                       -10.6928,  -5.4010,  -5.7467,  -4.5544, -14.6207,  -9.4568,   0.4363,\n",
       "                        -6.0029,  -4.7520, -10.0777, -19.3728,   7.3312,  -3.9146,  -4.1213,\n",
       "                        -4.5376, -10.3372, -11.7089,  -8.8880,  -4.1784,  -8.7844, -13.1679,\n",
       "                        -5.4957,  -5.8013,  -6.2711,  -5.9831,  -0.4317,   2.0526, -11.5915,\n",
       "                         0.2059, -10.6473,  -4.9260,  -1.5417,  -6.0039,  -5.3137,  -8.6857,\n",
       "                        -5.8778,   0.5054,  -4.8357, -11.6665,  -6.8932,  -5.2246,   3.5649,\n",
       "                       -13.4528], device='cuda:0')),\n",
       "              ('conv_block1.bn2.running_var',\n",
       "               tensor([104.4665,  52.4385,  91.5131,  81.1477, 122.0083, 126.2023,  42.4414,\n",
       "                        56.1025,  49.7538, 172.0671,  49.8468,  42.4662,  61.2207,  86.6769,\n",
       "                        18.0178,  74.0177, 108.8776, 173.0154, 178.2723,  87.5935,  94.7047,\n",
       "                       169.9219, 103.4164,  34.5758,  53.0822, 284.2262, 160.3335,  48.1477,\n",
       "                        71.1743,  55.5738, 114.1072, 412.1122,  25.4355,  31.5929,  33.4811,\n",
       "                        55.7246, 103.4648, 273.7428, 177.9740,  32.0147,  52.4685, 176.6447,\n",
       "                        43.8073,  53.1339,  80.3319,  43.6741,  16.8771,  37.1667, 248.7390,\n",
       "                        23.0678, 106.6639,  45.7877,  36.2760,  64.4575, 116.5747, 174.5919,\n",
       "                       161.6967,  24.6345,  87.6809, 261.5728,  88.1909,  33.4879,  24.3092,\n",
       "                       194.4015], device='cuda:0')),\n",
       "              ('conv_block1.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block2.conv1.weight',\n",
       "               tensor([[[[-6.6612e-02, -5.9600e-02, -3.3646e-02],\n",
       "                         [-9.0082e-03, -3.4218e-02, -1.2638e-01],\n",
       "                         [-1.5268e-01, -5.2480e-02, -6.7372e-02]],\n",
       "               \n",
       "                        [[ 1.1773e-01,  1.3273e-01,  1.4331e-01],\n",
       "                         [ 1.5485e-02, -5.2641e-02,  6.5574e-02],\n",
       "                         [ 3.9865e-02,  6.6218e-02,  1.6867e-01]],\n",
       "               \n",
       "                        [[ 9.3612e-03, -3.2874e-03, -5.0931e-03],\n",
       "                         [ 1.0213e-02,  2.7881e-02,  5.9696e-02],\n",
       "                         [ 2.5336e-03,  5.3899e-02,  1.0334e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.3382e-02,  6.7181e-02,  6.3629e-02],\n",
       "                         [-8.2463e-03,  3.0971e-02,  3.6543e-02],\n",
       "                         [-3.2838e-02, -5.4525e-02, -1.0010e-01]],\n",
       "               \n",
       "                        [[ 5.8703e-03, -5.4488e-03, -7.4210e-03],\n",
       "                         [-8.8855e-03,  9.4491e-03, -2.4393e-02],\n",
       "                         [ 4.0046e-02,  2.7267e-02, -2.4605e-02]],\n",
       "               \n",
       "                        [[ 3.4274e-03, -1.7679e-02, -1.0506e-02],\n",
       "                         [-6.6787e-02, -2.9965e-02, -3.4468e-02],\n",
       "                         [-4.4432e-02, -1.3806e-02, -4.1295e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.9368e-02, -4.6169e-02, -3.1849e-02],\n",
       "                         [ 1.1523e-01,  1.7957e-01,  4.6607e-02],\n",
       "                         [ 5.8586e-03,  1.2307e-01,  1.4036e-02]],\n",
       "               \n",
       "                        [[-1.8446e-01, -2.0808e-01, -7.5956e-02],\n",
       "                         [-2.9685e-01, -2.9554e-01,  5.7040e-02],\n",
       "                         [-2.7504e-01,  6.5192e-02,  2.9643e-02]],\n",
       "               \n",
       "                        [[ 3.1143e-02,  5.7940e-02,  5.3295e-02],\n",
       "                         [-1.4687e-01, -2.6303e-01,  4.0375e-02],\n",
       "                         [ 8.0275e-02, -1.9773e-01,  7.4133e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.7884e-02, -6.6429e-02, -6.8187e-03],\n",
       "                         [-8.8455e-02, -2.1068e-01, -1.0393e-01],\n",
       "                         [ 4.0991e-02, -1.4381e-01, -1.1891e-01]],\n",
       "               \n",
       "                        [[ 3.8864e-02, -7.3408e-02, -1.0042e-01],\n",
       "                         [ 6.2543e-02, -1.5229e-02,  3.8400e-02],\n",
       "                         [-4.9299e-02, -1.4120e-01, -1.5871e-01]],\n",
       "               \n",
       "                        [[ 1.2304e-01,  1.6561e-01,  1.1603e-01],\n",
       "                         [-3.1976e-03,  1.5427e-01,  1.0683e-01],\n",
       "                         [ 1.0294e-01,  1.0579e-01,  1.8109e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.3461e-01,  3.3709e-01, -1.2679e-01],\n",
       "                         [-1.1710e-01, -1.9431e-01, -2.6899e-01],\n",
       "                         [ 1.2496e-01, -2.3303e-01, -3.0178e-01]],\n",
       "               \n",
       "                        [[-7.5645e-01, -1.8989e-02, -1.4834e-01],\n",
       "                         [-1.5400e+00, -1.4846e+00, -2.8898e-01],\n",
       "                         [-1.9606e+00, -1.8870e+00, -6.1143e-01]],\n",
       "               \n",
       "                        [[ 7.4252e-02, -3.6760e-02,  2.5229e-01],\n",
       "                         [-5.4651e-03, -4.8606e-01,  6.3125e-02],\n",
       "                         [ 1.1650e-01, -6.2473e-01,  9.7307e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.3681e-02,  1.0975e-01, -1.4098e-01],\n",
       "                         [-1.3643e-02, -1.8806e-02, -1.1949e-01],\n",
       "                         [-1.5424e-01,  2.1139e-02, -1.2501e-01]],\n",
       "               \n",
       "                        [[-2.0506e-01, -3.0328e-01, -7.0644e-03],\n",
       "                         [ 6.5120e-02, -1.5298e-02,  8.4776e-02],\n",
       "                         [ 9.8368e-02,  2.2104e-01,  4.7331e-02]],\n",
       "               \n",
       "                        [[ 1.0543e-02, -3.8799e-02,  1.2879e-01],\n",
       "                         [-1.4161e-03, -1.6089e-01, -1.1688e-01],\n",
       "                         [ 1.8923e-01,  2.9672e-02, -8.9577e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 2.5869e-01,  2.4997e-01,  1.0919e-01],\n",
       "                         [ 8.0202e-02, -7.0330e-02, -1.1587e-01],\n",
       "                         [-1.7754e-01, -9.0353e-02, -1.1497e-02]],\n",
       "               \n",
       "                        [[ 3.2115e-01,  2.9448e-01, -5.0417e-02],\n",
       "                         [ 1.6544e-01,  5.9469e-02,  1.6220e-02],\n",
       "                         [-3.3938e-02, -2.0441e-02,  2.2820e-01]],\n",
       "               \n",
       "                        [[-2.6324e-01, -2.1927e-01,  1.9276e-02],\n",
       "                         [-1.1829e-01, -9.9668e-02, -3.7246e-02],\n",
       "                         [-1.5414e-01, -3.0073e-01, -3.8076e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.8569e-01, -8.8609e-02, -2.7967e-01],\n",
       "                         [-1.7912e-01, -1.2283e-01, -1.4729e-01],\n",
       "                         [-1.1130e-01, -1.5198e-01, -4.9355e-02]],\n",
       "               \n",
       "                        [[-1.5297e-01, -6.4467e-02, -1.4488e-02],\n",
       "                         [ 8.3452e-02,  1.1420e-01,  1.4201e-01],\n",
       "                         [ 6.5947e-02,  7.5174e-02,  1.4104e-02]],\n",
       "               \n",
       "                        [[-3.9835e-01, -4.4832e-01,  4.2174e-02],\n",
       "                         [-4.3757e-02,  3.5249e-03,  1.9157e-01],\n",
       "                         [ 5.1002e-01,  2.7074e-01,  2.1804e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.0083e-01, -2.0754e-01, -1.2930e-01],\n",
       "                         [-4.3015e-02,  7.0285e-02,  3.9884e-02],\n",
       "                         [ 4.1164e-03, -1.0237e-02, -2.3977e-01]],\n",
       "               \n",
       "                        [[-2.5900e-01, -4.4998e-01,  1.5604e-01],\n",
       "                         [-1.7697e-01, -4.5872e-01,  2.1617e-01],\n",
       "                         [ 3.7660e-02, -7.4408e-01,  6.8443e-02]],\n",
       "               \n",
       "                        [[-1.1396e-01, -5.3961e-02, -3.6279e-01],\n",
       "                         [ 1.1854e-01, -1.2681e-01, -2.1725e-01],\n",
       "                         [ 2.6696e-01, -3.6346e-01, -9.5176e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.7260e-04, -6.8171e-02,  8.3130e-02],\n",
       "                         [-6.1544e-02, -1.0541e-01,  1.3370e-01],\n",
       "                         [-1.3495e-02, -3.3459e-01, -3.7672e-01]],\n",
       "               \n",
       "                        [[ 4.4782e-02, -4.8111e-02, -3.0118e-01],\n",
       "                         [ 7.5534e-02,  1.4195e-02, -9.2084e-02],\n",
       "                         [ 5.9530e-02,  2.4830e-01, -1.9449e-02]],\n",
       "               \n",
       "                        [[-5.6514e-02, -4.7786e-01, -5.4551e-01],\n",
       "                         [ 6.7129e-02, -1.0447e-01, -3.5393e-01],\n",
       "                         [ 2.0524e-01,  1.4802e-01, -1.2159e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1755e-01,  1.8948e-01, -8.5609e-02],\n",
       "                         [ 1.8041e-03,  9.2940e-02,  4.3612e-03],\n",
       "                         [-2.8400e-02,  8.6866e-02,  5.8296e-02]],\n",
       "               \n",
       "                        [[ 1.5267e-01,  9.4688e-02,  1.0845e-01],\n",
       "                         [ 1.2109e-02,  1.7323e-02,  7.2662e-02],\n",
       "                         [ 1.5045e-01,  6.3335e-02,  1.3530e-01]],\n",
       "               \n",
       "                        [[-1.1404e-02, -6.6846e-05,  3.2670e-02],\n",
       "                         [ 1.3148e-02, -9.1374e-03,  7.4029e-02],\n",
       "                         [ 7.1019e-02, -1.2960e-02,  2.3726e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.7098e-02,  6.7599e-02,  1.4238e-02],\n",
       "                         [ 4.8238e-02,  1.3659e-02, -1.2117e-01],\n",
       "                         [ 1.4043e-02, -4.1660e-02, -1.5624e-01]],\n",
       "               \n",
       "                        [[ 7.8119e-02,  5.5463e-02, -4.3440e-02],\n",
       "                         [ 4.9839e-02,  1.5844e-02,  6.5254e-03],\n",
       "                         [-1.8330e-03,  3.8192e-02, -6.3780e-02]],\n",
       "               \n",
       "                        [[ 1.2015e-03, -5.0034e-02, -4.7408e-03],\n",
       "                         [-9.7093e-02, -1.0198e-01, -1.2352e-01],\n",
       "                         [-4.9896e-02, -4.3457e-02, -1.8967e-02]]]], device='cuda:0')),\n",
       "              ('conv_block2.conv2.weight',\n",
       "               tensor([[[[-1.2165e-01, -3.4758e-02, -3.1801e-02],\n",
       "                         [-2.2202e-01, -4.2053e-02, -8.9334e-03],\n",
       "                         [-2.1968e-01,  1.4105e-02, -7.2417e-02]],\n",
       "               \n",
       "                        [[-1.8230e-02,  4.9553e-02,  2.1746e-03],\n",
       "                         [-5.1542e-03,  1.5157e-01, -5.8213e-02],\n",
       "                         [-6.2584e-02,  8.8796e-02, -9.7473e-02]],\n",
       "               \n",
       "                        [[-7.6419e-02,  2.6815e-01, -4.1798e-01],\n",
       "                         [ 1.1087e-01,  1.8604e-01, -4.2441e-01],\n",
       "                         [ 6.6051e-01,  6.7546e-02, -2.2249e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.7164e-01,  6.9644e-02, -1.1054e-01],\n",
       "                         [-1.9934e-01,  1.2364e-01, -1.8217e-01],\n",
       "                         [ 1.9870e-01, -2.1927e-01, -4.7338e-01]],\n",
       "               \n",
       "                        [[ 6.0575e-01,  1.9189e-01, -3.9298e-01],\n",
       "                         [ 3.8937e-01, -5.2282e-01, -3.3441e-01],\n",
       "                         [ 5.0963e-02, -8.0754e-01,  2.1472e-01]],\n",
       "               \n",
       "                        [[-5.4394e-02, -4.4702e-02, -4.1633e-02],\n",
       "                         [-7.9942e-02,  2.0425e-02, -1.1764e-01],\n",
       "                         [-6.7712e-02, -4.8692e-02, -8.1700e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.8303e-02, -1.1456e-01, -6.3068e-02],\n",
       "                         [-3.1676e-02, -7.5469e-02, -8.8714e-02],\n",
       "                         [ 1.6190e-02, -1.3691e-01, -1.2982e-02]],\n",
       "               \n",
       "                        [[ 1.3800e-02,  4.3082e-02,  1.2921e-01],\n",
       "                         [-6.6615e-02,  3.9583e-02,  5.1345e-02],\n",
       "                         [-9.0941e-02, -3.3695e-02, -1.6292e-01]],\n",
       "               \n",
       "                        [[-2.9417e-01, -2.7346e-01, -2.8625e-01],\n",
       "                         [-4.8340e-01, -3.0853e-01, -2.9241e-01],\n",
       "                         [-4.6969e-01, -4.4771e-01, -2.2531e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.3768e-01, -1.3367e-01,  6.3965e-02],\n",
       "                         [-1.8034e-01, -1.0056e-01,  4.9152e-02],\n",
       "                         [ 6.9681e-02,  4.4886e-02, -1.5970e-02]],\n",
       "               \n",
       "                        [[ 6.3910e-02,  5.0630e-02, -1.5643e-01],\n",
       "                         [-1.2564e-02,  8.7770e-02, -2.5424e-01],\n",
       "                         [-1.5242e-01,  3.2650e-02, -3.4847e-01]],\n",
       "               \n",
       "                        [[-1.0796e-02, -6.4269e-02, -5.0478e-03],\n",
       "                         [-9.9691e-02, -6.7211e-02, -5.9294e-02],\n",
       "                         [-5.5320e-02, -4.8565e-02, -8.5714e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.3092e-01,  9.5969e-02,  1.5641e-01],\n",
       "                         [ 1.9266e-01,  1.9806e-01,  3.0072e-01],\n",
       "                         [ 1.0866e-01,  6.0311e-02,  1.0739e-01]],\n",
       "               \n",
       "                        [[-4.7209e-02, -7.3073e-02, -1.1407e-01],\n",
       "                         [ 3.4073e-02, -6.4070e-02,  7.7815e-02],\n",
       "                         [ 2.4749e-02, -6.8775e-02,  7.9206e-02]],\n",
       "               \n",
       "                        [[-2.8662e-02, -6.8921e-03, -1.5398e-01],\n",
       "                         [ 1.1468e-01,  1.0031e-01, -2.7129e-02],\n",
       "                         [ 1.9977e-01,  1.8576e-01,  5.5038e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.7789e-01, -1.6586e-01, -5.8020e-02],\n",
       "                         [-1.0732e-01, -1.4870e-01, -1.8783e-01],\n",
       "                         [ 1.1411e-01,  1.8217e-03,  6.5047e-03]],\n",
       "               \n",
       "                        [[ 5.4595e-02,  7.4122e-02, -2.3456e-01],\n",
       "                         [-1.3140e-01, -1.0850e-02, -2.9233e-01],\n",
       "                         [-3.5969e-02,  2.3044e-01, -1.8797e-01]],\n",
       "               \n",
       "                        [[ 1.4259e-01,  7.6576e-02,  9.8668e-02],\n",
       "                         [ 2.4371e-01,  1.9889e-01,  1.1936e-01],\n",
       "                         [ 1.4846e-01,  1.9596e-01,  1.3475e-01]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-2.1735e-02, -1.3602e-03, -6.8345e-03],\n",
       "                         [-3.9126e-02, -2.0053e-02, -6.9146e-02],\n",
       "                         [-4.7897e-02, -3.2232e-02, -3.0127e-02]],\n",
       "               \n",
       "                        [[-1.1223e-01, -2.3186e-03,  1.0385e-01],\n",
       "                         [-1.8395e-02, -9.9355e-03,  2.3772e-02],\n",
       "                         [ 9.9456e-03,  3.8746e-02,  3.2703e-02]],\n",
       "               \n",
       "                        [[ 5.2624e-01,  3.0441e-01, -2.7560e-02],\n",
       "                         [ 3.8298e-01,  3.3152e-01,  3.2366e-01],\n",
       "                         [-1.7045e-01, -1.2247e-01, -6.2685e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.2901e-01,  1.6458e-01, -5.7356e-02],\n",
       "                         [ 1.9583e-01,  1.6779e-01,  2.3444e-02],\n",
       "                         [-1.3751e-01, -1.7650e-01, -3.1298e-01]],\n",
       "               \n",
       "                        [[ 1.4263e-01, -1.8176e-01, -1.3101e-01],\n",
       "                         [-3.3003e-01, -1.7546e-01, -1.4912e-01],\n",
       "                         [-4.1653e-01, -2.7350e-01, -2.3506e-01]],\n",
       "               \n",
       "                        [[-3.4305e-03, -1.1950e-02, -2.6996e-02],\n",
       "                         [-3.5794e-02, -1.4185e-02, -2.9764e-02],\n",
       "                         [ 2.7390e-02, -6.2543e-02, -3.8219e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0635e-02, -2.6808e-03, -9.0777e-02],\n",
       "                         [-3.8485e-02,  3.2833e-02, -1.6659e-02],\n",
       "                         [-1.8095e-02,  8.3388e-03,  1.3049e-02]],\n",
       "               \n",
       "                        [[-4.0688e-02, -2.1189e-01, -1.4189e-01],\n",
       "                         [-4.1159e-02, -1.1777e-01, -3.9503e-02],\n",
       "                         [ 4.0488e-02,  6.5073e-02, -1.2451e-01]],\n",
       "               \n",
       "                        [[-1.9807e-01, -1.4593e-01, -3.1981e-01],\n",
       "                         [-2.6858e-01, -9.8892e-02, -2.4597e-01],\n",
       "                         [-3.9285e-01, -2.7522e-02, -2.4347e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2200e-01, -2.3795e-01, -4.5053e-01],\n",
       "                         [-4.3874e-01, -2.1310e-02, -6.6127e-02],\n",
       "                         [ 1.4589e-01,  1.8029e-01, -2.1881e-01]],\n",
       "               \n",
       "                        [[ 1.2308e-02,  3.8618e-01,  4.7723e-02],\n",
       "                         [ 1.1494e-02,  2.0954e-01,  1.6211e-02],\n",
       "                         [-1.2337e-01, -1.7129e-01, -2.3508e-01]],\n",
       "               \n",
       "                        [[-2.2188e-03, -2.6811e-02, -4.6226e-03],\n",
       "                         [-7.3100e-02, -4.6282e-02, -5.9734e-02],\n",
       "                         [ 1.5354e-02, -7.1094e-02, -4.0344e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9619e-02, -1.3767e-02, -6.4492e-02],\n",
       "                         [ 7.0084e-02,  2.1040e-02, -1.6778e-02],\n",
       "                         [ 2.5448e-02, -2.0526e-02, -1.5553e-02]],\n",
       "               \n",
       "                        [[ 6.7199e-02,  5.4012e-02, -5.1086e-02],\n",
       "                         [-1.6294e-02,  2.6211e-03, -5.9751e-02],\n",
       "                         [ 1.1546e-01,  7.7307e-02, -3.1984e-02]],\n",
       "               \n",
       "                        [[-1.3045e-01,  4.2094e-01,  3.6570e-01],\n",
       "                         [ 5.6246e-02,  7.0460e-01,  5.7300e-01],\n",
       "                         [-8.8699e-02,  4.3950e-01,  6.2013e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.6621e-01, -1.4640e-01,  1.2067e-01],\n",
       "                         [ 3.1655e-02,  3.4726e-01,  4.2844e-01],\n",
       "                         [-4.9609e-02,  3.7723e-01,  2.6148e-01]],\n",
       "               \n",
       "                        [[ 1.0608e-02,  5.0214e-01,  1.0745e-01],\n",
       "                         [-1.9865e-01,  2.3390e-01,  7.7547e-03],\n",
       "                         [-1.2779e-01,  2.3408e-01, -2.2846e-02]],\n",
       "               \n",
       "                        [[ 2.3396e-02, -2.1005e-02, -6.9662e-03],\n",
       "                         [-2.6809e-02, -3.2222e-02, -9.1260e-03],\n",
       "                         [-5.6296e-04, -2.4745e-03, -5.7847e-02]]]], device='cuda:0')),\n",
       "              ('conv_block2.bn1.weight',\n",
       "               tensor([0.7172, 1.1233, 1.1306, 1.0778, 1.2900, 1.3358, 1.0254, 0.9637, 1.0924,\n",
       "                       1.9560, 1.1531, 1.0244, 0.9168, 0.9906, 1.3675, 1.0856, 1.0364, 1.4014,\n",
       "                       0.6489, 1.1420, 1.0177, 1.0153, 0.4829, 1.3125, 1.0182, 1.2070, 0.8518,\n",
       "                       1.1346, 1.0194, 1.0389, 0.6530, 1.6765, 1.3377, 1.0420, 1.1963, 1.4562,\n",
       "                       1.2257, 0.8529, 1.2123, 1.0886, 1.2572, 0.9541, 1.2606, 1.1860, 0.7690,\n",
       "                       1.0909, 0.8198, 1.6815, 1.5043, 0.9400, 0.9319, 1.2516, 1.2181, 0.7739,\n",
       "                       1.5223, 1.2250, 0.5551, 0.8316, 1.1723, 0.6180, 1.2489, 1.3083, 1.2504,\n",
       "                       1.1648, 0.9319, 0.8519, 1.1785, 1.1199, 1.0065, 1.0437, 0.8517, 0.9715,\n",
       "                       1.1117, 0.8660, 1.2616, 0.6270, 1.4886, 0.8508, 1.6452, 0.9375, 0.9837,\n",
       "                       0.9614, 0.9463, 0.9444, 1.3023, 0.9668, 0.9989, 0.8529, 1.2239, 1.2258,\n",
       "                       0.8677, 1.0991, 1.2224, 1.3239, 1.0160, 0.8423, 0.7899, 1.0761, 0.9532,\n",
       "                       1.1130, 1.0155, 1.4508, 0.9422, 0.4902, 1.3575, 1.2227, 0.6806, 1.0196,\n",
       "                       1.1379, 1.3348, 0.8498, 1.1620, 1.0342, 1.0171, 0.7932, 1.2207, 1.0058,\n",
       "                       1.1235, 0.9424, 0.7260, 1.1394, 1.4980, 0.9080, 1.0551, 0.7560, 1.6658,\n",
       "                       1.0238, 0.7015], device='cuda:0')),\n",
       "              ('conv_block2.bn1.bias',\n",
       "               tensor([-1.3539, -0.9176, -0.3358, -0.6793, -0.2511, -0.5147,  0.1780,  0.0788,\n",
       "                       -0.9521, -3.2531, -0.3384, -0.2269, -0.1342, -0.4940, -0.5501, -0.7990,\n",
       "                       -0.2480, -0.7214, -1.2223, -0.8328,  0.1423, -0.7698, -0.0695, -0.9567,\n",
       "                       -0.6748, -0.8609, -1.0909, -0.6635, -0.5919, -0.3254, -0.5232, -1.0573,\n",
       "                       -0.5956,  0.2500, -1.2381, -0.9972, -1.1012, -0.7308, -0.9487, -0.4341,\n",
       "                       -0.7429, -0.7259, -0.9874, -0.2327, -1.4147, -0.8253, -0.5465, -2.2435,\n",
       "                       -0.7619, -0.4607, -1.0012, -0.7680,  0.0576, -0.1711, -0.9545, -0.4789,\n",
       "                       -0.2734, -0.1463, -0.9236, -0.4300, -1.3015, -0.8899, -1.5931, -0.5611,\n",
       "                       -0.2354,  0.1681, -0.6901, -0.1235, -0.6812, -0.5706, -0.0539, -0.2259,\n",
       "                       -0.7704, -0.1603, -0.9158, -1.2511, -1.1759, -0.4254, -1.5772,  0.0548,\n",
       "                       -0.3023, -0.2560, -0.9098,  0.1258, -0.8445,  0.2932, -0.5789, -1.4806,\n",
       "                       -0.7398, -0.6939, -0.2297, -0.3205, -1.0558, -0.5916, -0.7359, -0.6250,\n",
       "                        0.0800, -0.9542, -0.1950, -0.3094, -0.5269, -0.8853, -0.4104, -0.0767,\n",
       "                       -0.9139, -0.6508, -0.2267, -0.5620, -0.0352, -0.6384,  0.3548, -0.7505,\n",
       "                       -0.5176, -0.8099, -0.5966, -0.7521, -1.1145, -0.2763, -0.7157, -0.2710,\n",
       "                       -0.5462, -0.9088, -0.2783, -0.7310,  0.0219, -0.8976, -0.0224, -1.1168],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.running_mean',\n",
       "               tensor([-2.4131, -0.8904, -4.9010, -1.7769, -2.2053, -2.7407, -1.1921, -3.0030,\n",
       "                       -0.4156, -0.3795, -2.3029, -1.2883, -0.4116, -0.1081, -3.7642, -1.0190,\n",
       "                       -2.0777, -3.3611, -0.0486, -3.1341, -2.4077, -1.1157, -0.8847, -2.7711,\n",
       "                       -1.7424, -3.3486,  2.1937, -2.5235, -1.8268, -2.8369,  0.6379, -2.1238,\n",
       "                       -3.7224, -0.4414, -1.3879, -3.3340, -3.3817,  0.3282, -2.7800, -1.5432,\n",
       "                       -2.6469, -1.0276, -3.0478, -2.0544, -3.2316, -2.2868, -1.4719, -1.4437,\n",
       "                       -1.1511, -3.5797, -2.7565, -2.2685, -1.4782, -2.8771, -2.0487, -1.7757,\n",
       "                       -0.8824, -1.3743, -1.8331, -1.9949, -0.8457, -2.1034, -0.5533, -1.3504,\n",
       "                       -1.4081, -2.1844, -1.0006, -2.2973, -2.6539, -2.2386, -1.4796, -1.1708,\n",
       "                       -2.5862, -0.4609, -3.5191, -1.9588, -0.6882, -1.3655, -1.3016, -1.3824,\n",
       "                       -1.6750, -0.4051, -1.0312, -2.7010, -2.5754, -1.1560, -0.3630,  0.7148,\n",
       "                       -1.6863, -2.2299, -0.1336, -2.4699, -2.1001, -1.5359, -1.5326,  0.7923,\n",
       "                       -1.0251,  0.2001, -2.3583, -1.4120, -0.1170, -1.8230, -2.2582,  1.4584,\n",
       "                       -3.3188, -0.8856,  0.3503, -1.2154, -2.1023, -1.5781, -3.0069, -1.1046,\n",
       "                       -1.3731, -1.0934,  1.5682, -2.0638, -0.9050, -3.8840, -1.0200, -1.9753,\n",
       "                       -4.2705, -4.1954, -3.8186, -2.5487, -0.3516, -1.8321, -2.5454, -1.9434],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.running_var',\n",
       "               tensor([ 0.9786,  1.5125,  9.5856,  1.8743,  8.2790,  4.4735,  7.8640, 10.5432,\n",
       "                        1.2490,  2.9350,  6.8486,  6.3948,  3.2540,  1.1393,  9.0964,  1.5334,\n",
       "                        8.2834,  4.2068,  0.9122,  3.0292,  8.1301,  1.0579,  6.6738,  4.5364,\n",
       "                        2.0355,  4.1773,  1.8325,  4.3999,  4.2481,  6.3098,  2.5068,  9.3283,\n",
       "                        6.4492,  3.0384,  1.8923,  5.8473,  3.0599,  0.8678,  2.7243,  5.1903,\n",
       "                        4.7960,  4.2547,  2.5376,  2.5142,  2.3388,  3.6344,  1.5592,  2.2303,\n",
       "                        4.9886,  6.1556,  2.0378,  2.1848,  3.8695,  7.8191,  6.6059,  3.8878,\n",
       "                        3.6203,  4.7165,  1.8168,  2.2955,  1.4972,  2.4463,  2.0767,  7.1414,\n",
       "                        3.5790,  7.7162,  1.4699, 15.7467,  2.9050,  5.4722,  4.5844,  3.5854,\n",
       "                        3.4569,  4.2376,  4.6873,  0.7987,  1.1326,  3.8485,  1.5644,  3.9909,\n",
       "                        5.1989,  2.9923,  1.4127,  3.8168,  3.5553,  3.1785,  3.8540,  0.9011,\n",
       "                        1.4663,  3.4107,  2.3478,  3.1561,  2.1672,  5.4370,  3.1052,  1.8797,\n",
       "                        5.6606,  1.1486,  5.1894,  4.4640,  2.9727,  1.8161,  7.0791,  5.8385,\n",
       "                        4.8354,  2.8537,  2.3023,  5.0950,  3.7036,  3.9769, 11.8580,  1.1699,\n",
       "                        6.9196,  2.8060,  3.8003,  5.5325,  1.3808,  5.8572,  1.1803,  5.3702,\n",
       "                        8.7443,  8.8479,  5.3295,  4.1233,  6.9519,  8.7936,  5.9418,  1.0971],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block2.bn2.weight',\n",
       "               tensor([1.3141, 0.9743, 0.9400, 0.9704, 1.1382, 1.0515, 0.7056, 0.8917, 1.2728,\n",
       "                       0.8739, 0.8869, 1.0483, 0.6003, 0.7180, 0.9838, 0.9419, 1.2941, 1.2745,\n",
       "                       1.1587, 1.3949, 0.7573, 0.7964, 1.2028, 1.1286, 0.5101, 1.5309, 1.7043,\n",
       "                       1.0253, 1.2643, 1.5136, 0.9687, 1.1254, 0.9008, 1.0613, 1.2545, 1.9371,\n",
       "                       1.0074, 1.1867, 0.6400, 0.8690, 1.2913, 1.1891, 1.5210, 1.2264, 1.1337,\n",
       "                       1.5098, 0.7860, 1.1929, 0.9391, 1.0299, 0.8509, 1.0739, 1.1180, 1.0300,\n",
       "                       1.1998, 0.9821, 0.9817, 1.3478, 0.9603, 0.9633, 0.6857, 0.6026, 0.7475,\n",
       "                       0.7358, 0.7933, 0.9335, 0.9808, 1.0397, 0.8151, 0.7391, 0.6320, 1.2441,\n",
       "                       1.0984, 1.2876, 0.8579, 1.6905, 0.7509, 0.7957, 0.7060, 1.0145, 0.9281,\n",
       "                       0.8951, 1.7811, 1.0739, 1.3654, 1.0729, 0.7540, 0.7065, 1.2138, 1.0745,\n",
       "                       0.9565, 0.9216, 1.0931, 0.6989, 1.1158, 0.9414, 0.7919, 1.2018, 1.0087,\n",
       "                       1.4503, 0.6382, 0.8017, 0.9373, 1.1921, 1.0555, 1.2000, 1.3124, 1.1891,\n",
       "                       0.8393, 1.0704, 0.7054, 1.2592, 0.7358, 0.9641, 1.1372, 0.8094, 1.0117,\n",
       "                       1.2514, 1.1951, 1.0004, 0.8262, 0.7046, 0.8043, 1.1598, 0.6865, 1.4700,\n",
       "                       0.8981, 0.9085], device='cuda:0')),\n",
       "              ('conv_block2.bn2.bias',\n",
       "               tensor([-1.3503, -0.4413, -0.6789, -0.9455, -1.0849, -0.4448, -0.5752, -0.7186,\n",
       "                       -0.8108, -0.2051, -0.4654, -0.7822, -0.4704, -0.3479, -0.7247, -0.6463,\n",
       "                       -1.1507, -0.8867, -0.7556, -0.8274, -0.4405, -0.4568, -0.9801, -0.6102,\n",
       "                       -1.2241, -1.2244, -1.5618, -0.8782, -0.5003, -0.9520, -0.5820, -1.1252,\n",
       "                       -0.9082, -0.9316, -1.0885, -1.7258, -0.9305, -0.9675, -0.2319, -0.6314,\n",
       "                       -0.8341, -1.1461, -0.9772, -0.9146, -0.7383, -1.1380, -0.6114, -0.9168,\n",
       "                       -1.1098, -0.8108, -0.2102, -0.8518, -0.5361, -0.4911, -0.9719, -0.7816,\n",
       "                       -0.7263, -1.1259, -0.3177, -0.4689, -0.2683, -0.5677, -0.5023, -0.3059,\n",
       "                       -0.5004, -0.7979, -0.7226, -0.8363, -0.3814, -0.5096, -2.4209, -1.0990,\n",
       "                       -0.7452, -1.0950, -0.4069, -1.6483, -0.4548, -0.4833, -0.4344, -0.7627,\n",
       "                       -0.5733, -0.4171, -1.7487, -1.0344, -0.9407, -0.8883, -0.0773, -0.2880,\n",
       "                       -1.0581, -0.7470, -0.6575, -0.5272, -0.7539, -0.3000, -0.6706, -0.6163,\n",
       "                       -0.3594, -0.7435, -2.1373, -1.4771, -0.2047, -0.3021, -0.4441, -0.8505,\n",
       "                       -0.7633, -1.0400, -0.6749, -0.8543, -0.2337, -0.7890, -0.1617, -0.7715,\n",
       "                       -0.4618, -0.8388, -0.8737, -0.8112, -0.6466, -0.8895, -0.7215, -0.9477,\n",
       "                       -0.6900, -0.5412, -0.4516, -1.3314, -0.2638, -1.1401, -0.6788, -0.7952],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn2.running_mean',\n",
       "               tensor([ -7.3961,  -4.5891,  -5.8213,  -1.0133,  -2.2580,  -1.8642,  -3.5694,\n",
       "                        -6.0996,  -5.6499,  -2.5031,  -5.9163,  -2.2057,  -0.3819,  -1.8356,\n",
       "                        -4.1744,  -2.8422, -10.6328,  -5.2309,  -5.7686,  -2.5634,  -3.7643,\n",
       "                        -3.3726,  -4.8321,  -2.0769,   0.1582,  -3.8061,  -2.4051,  -3.5277,\n",
       "                        -3.9691,  -9.3103,  -8.0612,  -8.9360,  -1.8765,  -2.2820,  -5.7356,\n",
       "                        -4.4611,  -4.0259,  -2.2542,  -3.3550,  -6.5327,  -2.8121,  -2.8097,\n",
       "                        -6.0242,  -4.6169,  -6.0128,  -5.0973,  -3.0608,  -5.6782,   3.8616,\n",
       "                        -6.4063,  -3.3098,  -3.8689,  -7.3669,  -8.6131,  -3.6852,  -1.7822,\n",
       "                        -0.8158,  -2.0991,  -3.4854,  -6.3265,  -0.7037,  -1.9551,  -3.9395,\n",
       "                        -8.3529,  -6.3534,  -5.0519,  -9.2046,  -5.9804,  -3.8782,  -6.5263,\n",
       "                        -5.4163,  -5.5368,  -4.0463,  -3.8354,  -5.0896,  -6.0110,  -7.0405,\n",
       "                        -3.0010,  -6.2386,  -4.0346,  -0.3754,  -7.8277,  -6.0818,  -7.8651,\n",
       "                        -6.4240,  -4.4329,  -5.6176, -10.5690,  -4.8338,  -7.8223,  -8.5971,\n",
       "                        -4.2706,  -1.2760,  -3.1160,  -5.2439,  -6.0792,  -2.8554,  -4.7671,\n",
       "                       -10.1972,  -5.3260,  -1.2649,  -6.3484,  -3.9511,  -3.6146,  -3.9128,\n",
       "                        -2.9004,  -4.7150,  -3.9410,  -6.3880,  -4.4866,  -2.6650,  -6.4564,\n",
       "                        -1.9117,  -7.6207,  -2.6397,  -1.2198,  -6.7517,  -3.4818,  -6.2508,\n",
       "                        -5.4821,  -5.1062,   0.5175,  -5.7855,  -2.5263,  -1.4931,  -2.2290,\n",
       "                        -8.5932,  -7.5575], device='cuda:0')),\n",
       "              ('conv_block2.bn2.running_var',\n",
       "               tensor([39.4738, 50.2512, 22.0735, 19.9018, 19.8698, 20.9728,  7.8593, 25.9285,\n",
       "                       26.7521, 35.7524, 28.5406, 15.7397, 21.2985, 16.1114, 29.1470, 16.3477,\n",
       "                       46.2311, 21.5170, 24.7272, 21.8895, 30.1096, 32.5887, 24.2733, 34.2261,\n",
       "                        2.8262, 31.3546, 27.2281, 20.9851, 38.9086, 58.9054, 41.3042, 36.1662,\n",
       "                       18.2157, 18.5176, 14.1306, 34.1359, 18.4572, 34.3251, 31.8396, 19.9072,\n",
       "                       38.5039, 25.1795, 49.3835, 22.4839, 21.6583, 44.9227, 16.7198, 26.6548,\n",
       "                       14.7740, 30.8616, 37.0285, 14.4538, 35.8281, 49.5567, 20.6141, 18.0857,\n",
       "                       14.2632, 17.1822, 18.9241, 24.8222, 26.1890, 18.4515, 18.8614, 24.9102,\n",
       "                       25.8328, 20.0000, 19.6624, 20.5221, 10.0361, 25.1925,  6.1014, 29.3661,\n",
       "                       23.9723, 16.6776, 31.6900, 38.0337, 37.4205, 19.9710, 23.4294, 23.7631,\n",
       "                       14.4114, 42.7463, 21.7828, 29.3276, 22.0355, 30.7823, 27.8870, 50.3067,\n",
       "                       46.6016, 24.0858, 23.1349, 26.0429, 17.0057, 16.8542, 30.9906, 31.5861,\n",
       "                       24.1196, 21.7915, 22.6303, 24.3610, 26.3884, 19.4191, 31.9319, 17.5472,\n",
       "                       32.2729, 14.9530, 39.7351, 40.5044, 42.4207, 27.4097, 28.9811, 23.9798,\n",
       "                       19.2014, 29.4878, 21.0382, 19.4690, 35.1844, 46.0242, 28.0500, 18.4765,\n",
       "                       14.6201, 15.6444, 29.0666, 13.7840, 45.7339, 16.2414, 32.2088, 29.5621],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block3.conv1.weight',\n",
       "               tensor([[[[ 0.1918,  0.2914,  0.2449],\n",
       "                         [ 0.1409,  0.4522,  0.5067],\n",
       "                         [-0.0884,  0.0737,  0.0301]],\n",
       "               \n",
       "                        [[ 0.1019,  0.0240,  0.1687],\n",
       "                         [ 0.1553,  0.1560,  0.1272],\n",
       "                         [ 0.3152,  0.1944,  0.5959]],\n",
       "               \n",
       "                        [[-0.0959,  0.0195, -0.0181],\n",
       "                         [ 0.1306,  0.3360,  0.2106],\n",
       "                         [ 0.0172,  0.2755,  0.1774]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0589, -0.0836, -0.0707],\n",
       "                         [-0.0466, -0.0364, -0.0165],\n",
       "                         [-0.1360, -0.1182, -0.2067]],\n",
       "               \n",
       "                        [[ 0.1215, -0.0398,  0.0103],\n",
       "                         [ 0.2076,  0.1056,  0.0358],\n",
       "                         [ 0.2488,  0.1140,  0.0059]],\n",
       "               \n",
       "                        [[-0.1999,  0.1547, -0.0563],\n",
       "                         [ 0.0262,  0.1187,  0.0150],\n",
       "                         [-0.0092,  0.0139, -0.0758]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2419,  0.0038,  0.0491],\n",
       "                         [ 0.1142,  0.1323,  0.0855],\n",
       "                         [ 0.0182,  0.1687,  0.1369]],\n",
       "               \n",
       "                        [[ 0.0632, -0.0132, -0.2317],\n",
       "                         [-0.0641,  0.1044, -0.1256],\n",
       "                         [-0.2285, -0.0290, -0.1301]],\n",
       "               \n",
       "                        [[ 0.1610,  0.1163, -0.5981],\n",
       "                         [-0.1550,  0.0303, -0.5493],\n",
       "                         [-0.0474,  0.0092, -0.9042]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0083,  0.0083,  0.0075],\n",
       "                         [ 0.0145,  0.0950,  0.0511],\n",
       "                         [ 0.0830,  0.1164,  0.0494]],\n",
       "               \n",
       "                        [[ 0.2263,  0.1090,  0.0101],\n",
       "                         [ 0.1972,  0.0947,  0.0223],\n",
       "                         [ 0.2290,  0.0657,  0.0559]],\n",
       "               \n",
       "                        [[ 0.0564,  0.0782, -0.1155],\n",
       "                         [-0.0289,  0.0121, -0.1669],\n",
       "                         [-0.1572, -0.0734, -0.2753]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1550,  0.0760, -0.0711],\n",
       "                         [ 0.0081,  0.0031,  0.2342],\n",
       "                         [-0.0559, -0.0469,  0.0951]],\n",
       "               \n",
       "                        [[-0.2200, -0.1018,  0.0902],\n",
       "                         [-0.0272, -0.0195, -0.0870],\n",
       "                         [-0.0746,  0.0177, -0.0156]],\n",
       "               \n",
       "                        [[ 0.1937,  0.1846, -0.1088],\n",
       "                         [-0.0464, -0.0803, -0.1807],\n",
       "                         [-0.2460, -0.4201, -0.2906]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.2961,  0.0428,  0.0576],\n",
       "                         [-0.0060, -0.0896, -0.0119],\n",
       "                         [-0.0070, -0.1107, -0.0374]],\n",
       "               \n",
       "                        [[ 0.0958, -0.1339, -0.5265],\n",
       "                         [ 0.2807, -0.0662, -0.3240],\n",
       "                         [ 0.1958, -0.0395,  0.0079]],\n",
       "               \n",
       "                        [[-0.1234, -0.1167,  0.0425],\n",
       "                         [-0.1760, -0.0356,  0.1057],\n",
       "                         [ 0.0918,  0.0630,  0.0935]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1052,  0.0447, -0.0383],\n",
       "                         [ 0.3132, -0.0677,  0.2181],\n",
       "                         [ 0.3347,  0.1222,  0.1651]],\n",
       "               \n",
       "                        [[-0.1390, -0.1263, -0.2003],\n",
       "                         [ 0.0697,  0.2888,  0.1418],\n",
       "                         [-0.1250,  0.1076, -0.2513]],\n",
       "               \n",
       "                        [[ 0.1868,  0.4712, -0.2973],\n",
       "                         [ 0.4597,  0.3130,  0.0224],\n",
       "                         [ 0.6202,  0.3876,  0.2023]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1832, -0.2164, -0.1429],\n",
       "                         [-1.0208, -0.7868, -0.6915],\n",
       "                         [ 0.0429, -0.0640,  0.0734]],\n",
       "               \n",
       "                        [[ 0.3000, -0.1256, -0.1552],\n",
       "                         [ 0.3883,  0.0413, -0.0672],\n",
       "                         [-0.0734, -0.2630, -0.1852]],\n",
       "               \n",
       "                        [[-0.0130, -0.1501, -0.0803],\n",
       "                         [-0.0735, -0.1439, -0.1835],\n",
       "                         [-0.0352, -0.1001, -0.0571]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1292, -0.0475, -0.2751],\n",
       "                         [-0.0806, -0.0832, -0.1058],\n",
       "                         [-0.2897, -0.2348, -0.2851]],\n",
       "               \n",
       "                        [[ 0.3081, -0.0171,  0.0433],\n",
       "                         [ 0.3938, -0.0264,  0.0846],\n",
       "                         [-0.0721, -0.1088,  0.0143]],\n",
       "               \n",
       "                        [[-0.2201, -0.1279,  0.0128],\n",
       "                         [-0.0203, -0.0936,  0.2572],\n",
       "                         [-0.0513,  0.0027,  0.2839]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1582,  0.0710, -0.0582],\n",
       "                         [-0.1213,  0.0654,  0.0037],\n",
       "                         [-0.0399,  0.0586, -0.0409]],\n",
       "               \n",
       "                        [[ 0.1604, -0.0942, -0.0826],\n",
       "                         [ 0.0975,  0.0810,  0.0280],\n",
       "                         [ 0.1393,  0.1117,  0.0537]],\n",
       "               \n",
       "                        [[-0.0604, -0.2456, -0.2025],\n",
       "                         [ 0.0392, -0.1012, -0.0784],\n",
       "                         [-0.0073, -0.2827, -0.0562]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0430,  0.2113,  0.5149],\n",
       "                         [-0.0677,  0.0607,  0.4389],\n",
       "                         [-0.2325, -0.0065,  0.1742]],\n",
       "               \n",
       "                        [[-0.3542, -0.1437,  0.3854],\n",
       "                         [-0.2052, -0.2274,  0.2500],\n",
       "                         [-0.4057, -0.3395, -0.0143]],\n",
       "               \n",
       "                        [[-0.1930, -0.0256, -0.0375],\n",
       "                         [ 0.0103, -0.0207, -0.0794],\n",
       "                         [ 0.3867,  0.2394,  0.1966]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.1049,  0.0724, -0.0165],\n",
       "                         [ 0.0512,  0.0242, -0.0029],\n",
       "                         [ 0.0762,  0.0376,  0.0533]],\n",
       "               \n",
       "                        [[-0.0143,  0.0353,  0.0516],\n",
       "                         [-0.0515,  0.0574,  0.0636],\n",
       "                         [ 0.1108,  0.1316,  0.1324]],\n",
       "               \n",
       "                        [[ 0.2118, -0.2252,  0.0978],\n",
       "                         [ 0.4146, -0.1564,  0.0487],\n",
       "                         [ 0.1328, -0.3897, -0.1263]]]], device='cuda:0')),\n",
       "              ('conv_block3.conv2.weight',\n",
       "               tensor([[[[ 1.3757e-01,  4.3896e-02,  7.7711e-02],\n",
       "                         [ 3.9155e-02, -1.6810e-02, -5.3194e-03],\n",
       "                         [-7.1487e-02, -8.9337e-02, -9.6639e-02]],\n",
       "               \n",
       "                        [[ 1.0051e-01,  5.4529e-02,  2.5286e-01],\n",
       "                         [ 2.2643e-01,  1.0918e-01,  2.1707e-01],\n",
       "                         [ 2.2286e-01,  1.7694e-01,  1.8261e-01]],\n",
       "               \n",
       "                        [[ 1.0463e-01,  4.7260e-02,  1.4341e-01],\n",
       "                         [ 6.8646e-03,  3.5136e-02, -1.8568e-01],\n",
       "                         [ 1.4691e-02,  2.7523e-02, -8.4363e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.6073e-02, -1.0391e-01, -5.4284e-01],\n",
       "                         [-1.1898e-01, -1.1015e-01, -2.7668e-01],\n",
       "                         [-1.6836e-01, -1.7446e-01, -4.8569e-01]],\n",
       "               \n",
       "                        [[-2.9016e-01, -1.0900e-01, -5.3641e-02],\n",
       "                         [-2.6679e-01, -1.2469e-01, -1.4308e-01],\n",
       "                         [-1.3673e-01, -1.5387e-02,  1.9499e-02]],\n",
       "               \n",
       "                        [[-3.0667e-02, -2.2987e-01, -2.8192e-01],\n",
       "                         [-1.4152e-01, -1.1759e-01, -1.8855e-01],\n",
       "                         [-1.6718e-01, -2.3168e-01, -2.6251e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8786e-01,  1.6873e-01,  1.3946e-01],\n",
       "                         [-1.7823e-01,  5.2950e-02,  1.0508e-01],\n",
       "                         [ 3.9748e-02,  1.1322e-01,  9.1565e-02]],\n",
       "               \n",
       "                        [[ 1.6513e-01,  7.0866e-02,  2.9959e-02],\n",
       "                         [ 1.8623e-01,  8.5402e-02,  1.0393e-01],\n",
       "                         [ 1.6429e-01,  6.0174e-02,  9.9975e-02]],\n",
       "               \n",
       "                        [[-2.9346e-02,  2.7225e-01,  4.5111e-03],\n",
       "                         [-1.6765e-01,  8.2408e-02, -6.9969e-02],\n",
       "                         [-3.3864e-01, -3.1999e-01, -4.8076e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 8.7067e-02,  3.7755e-02,  1.4875e-01],\n",
       "                         [ 1.3623e-01,  5.7685e-02,  1.2049e-01],\n",
       "                         [-4.3463e-02,  8.5667e-02,  2.6807e-01]],\n",
       "               \n",
       "                        [[ 3.3094e-02, -3.1364e-02, -9.8045e-02],\n",
       "                         [ 5.5394e-02,  1.4516e-01,  4.4614e-02],\n",
       "                         [ 1.2437e-01,  6.7197e-02,  2.6299e-01]],\n",
       "               \n",
       "                        [[ 1.3716e-02,  2.9617e-02, -8.5375e-03],\n",
       "                         [-5.4299e-02, -9.0567e-03, -3.2639e-02],\n",
       "                         [-3.9753e-02, -3.7975e-02,  1.0959e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2729e-02,  1.2983e-02, -1.1082e-03],\n",
       "                         [-1.0104e-02, -2.4775e-03, -1.8996e-03],\n",
       "                         [-6.1798e-02, -5.7441e-02, -7.8250e-02]],\n",
       "               \n",
       "                        [[-1.8100e-02, -8.1336e-02,  8.5607e-03],\n",
       "                         [ 2.4292e-02,  3.0190e-03,  6.1094e-03],\n",
       "                         [ 5.0470e-02, -2.3951e-03,  3.9983e-02]],\n",
       "               \n",
       "                        [[-1.2726e-02, -9.6699e-02, -1.3851e-01],\n",
       "                         [-2.9790e-02, -8.6112e-02, -1.5020e-01],\n",
       "                         [-7.4393e-02, -9.5068e-02, -1.3827e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.0869e-02, -7.1531e-02, -3.1412e-03],\n",
       "                         [-2.2586e-02, -4.4022e-03, -1.1555e-02],\n",
       "                         [-3.3323e-02, -7.2141e-02, -3.3744e-02]],\n",
       "               \n",
       "                        [[ 3.9286e-02,  2.1935e-02, -1.1812e-02],\n",
       "                         [ 8.7210e-02,  4.9117e-02,  3.8273e-02],\n",
       "                         [ 7.9813e-03,  2.1938e-02, -2.2139e-02]],\n",
       "               \n",
       "                        [[-1.0034e-01, -6.9140e-02, -9.8685e-02],\n",
       "                         [ 7.6026e-03,  5.4144e-04, -2.7368e-02],\n",
       "                         [ 2.0734e-02,  2.5915e-02, -4.8275e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-3.3179e-03, -1.0582e-01, -7.0599e-02],\n",
       "                         [ 3.1258e-02,  2.8049e-02,  2.0656e-03],\n",
       "                         [ 1.3279e-01,  4.2829e-02,  9.6902e-02]],\n",
       "               \n",
       "                        [[-2.8050e-01, -2.3010e-01, -2.8824e-01],\n",
       "                         [-3.2654e-02,  7.5081e-02, -1.0713e-01],\n",
       "                         [ 2.2023e-01,  1.2251e-01, -3.1004e-02]],\n",
       "               \n",
       "                        [[-2.2567e-02, -1.0412e-01, -2.9561e-01],\n",
       "                         [-6.5547e-02, -1.8374e-01, -2.1960e-01],\n",
       "                         [ 4.5878e-02, -5.6491e-02, -1.8567e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2591e-01, -2.1784e-02, -4.0365e-02],\n",
       "                         [-5.7017e-02,  8.3478e-02, -3.8980e-02],\n",
       "                         [ 7.2135e-02,  1.7239e-01,  1.7608e-01]],\n",
       "               \n",
       "                        [[-3.4503e-01, -3.1989e-01, -3.2226e-01],\n",
       "                         [-1.6589e-01, -1.6011e-01, -1.2297e-01],\n",
       "                         [-7.5813e-02, -5.2137e-02, -5.5259e-02]],\n",
       "               \n",
       "                        [[-1.4890e-01,  1.2244e-02,  3.4804e-03],\n",
       "                         [ 9.9097e-02,  1.0039e-01,  1.1039e-01],\n",
       "                         [ 2.7918e-01,  2.4813e-01,  2.0999e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2763e-02,  3.3710e-02,  9.8060e-02],\n",
       "                         [ 4.1523e-02,  1.0447e-01,  1.1888e-01],\n",
       "                         [ 9.0085e-02,  1.0030e-01,  1.2675e-01]],\n",
       "               \n",
       "                        [[-2.0796e-02,  1.4305e-01, -8.5851e-02],\n",
       "                         [ 9.9763e-02,  1.7328e-01,  1.0501e-01],\n",
       "                         [ 9.9091e-02,  1.1628e-01,  5.7350e-02]],\n",
       "               \n",
       "                        [[-1.8043e-01, -6.2085e-02, -4.5798e-02],\n",
       "                         [-8.4020e-02,  1.2727e-01,  9.6284e-02],\n",
       "                         [ 1.7993e-01,  1.3537e-01,  1.8061e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.6259e-02, -5.4515e-02,  1.0738e-01],\n",
       "                         [-1.6335e-01, -1.6188e-01, -4.7400e-02],\n",
       "                         [-4.4075e-01, -2.0570e-01, -2.3790e-01]],\n",
       "               \n",
       "                        [[ 6.3876e-02,  5.0798e-02,  3.0333e-02],\n",
       "                         [ 1.7889e-02,  1.8676e-02,  2.0114e-02],\n",
       "                         [ 3.7309e-03,  6.1642e-02,  1.0740e-01]],\n",
       "               \n",
       "                        [[ 7.5402e-02,  6.8505e-02,  1.2329e-02],\n",
       "                         [ 9.4484e-02,  1.3652e-01,  7.6856e-02],\n",
       "                         [ 2.4983e-01,  2.6860e-01,  1.3195e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.5039e-02,  3.9122e-02, -4.0369e-03],\n",
       "                         [-1.2478e-01, -5.6188e-02, -2.4111e-02],\n",
       "                         [-6.4421e-02, -1.1154e-02,  3.1546e-02]],\n",
       "               \n",
       "                        [[ 6.7863e-02, -1.7155e-02,  8.1381e-02],\n",
       "                         [-3.2866e-02, -1.4610e-01, -7.5981e-03],\n",
       "                         [-9.6189e-02, -1.5031e-01, -2.5742e-02]],\n",
       "               \n",
       "                        [[-6.0012e-02,  7.6986e-02,  5.3144e-01],\n",
       "                         [ 1.6253e-01,  2.6311e-02,  2.9028e-01],\n",
       "                         [ 2.8924e-01,  4.3638e-01,  9.5001e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.4443e-02,  8.4047e-02,  9.4683e-02],\n",
       "                         [ 7.5064e-02,  8.1519e-03,  9.3771e-02],\n",
       "                         [ 4.4937e-02,  1.1582e-02,  3.0661e-02]],\n",
       "               \n",
       "                        [[-4.2403e-02,  5.5279e-02,  7.3614e-02],\n",
       "                         [-1.4714e-01, -1.1489e-01, -1.1970e-01],\n",
       "                         [-2.2739e-01, -2.6858e-01, -2.7262e-01]],\n",
       "               \n",
       "                        [[ 5.3812e-02,  1.3348e-01,  9.6792e-02],\n",
       "                         [ 1.7793e-02,  9.1173e-02,  1.9585e-02],\n",
       "                         [ 7.9299e-03,  8.6664e-02,  1.0111e-02]]]], device='cuda:0')),\n",
       "              ('conv_block3.bn1.weight',\n",
       "               tensor([1.0210, 1.0682, 1.3787, 1.2665, 1.1524, 1.2183, 0.7760, 0.9235, 1.3536,\n",
       "                       1.1974, 1.3259, 1.0340, 0.7915, 1.4988, 1.3355, 1.0443, 1.5879, 1.0444,\n",
       "                       1.4216, 1.0978, 0.9139, 1.1532, 1.1720, 1.4551, 0.9114, 1.1548, 0.2007,\n",
       "                       0.9233, 0.9801, 1.4392, 1.2658, 1.2461, 1.2587, 0.9034, 1.2150, 0.9803,\n",
       "                       0.9793, 1.0596, 1.2942, 1.0567, 0.9321, 1.1342, 1.5601, 1.0315, 1.2391,\n",
       "                       1.0022, 0.9950, 1.2044, 1.0443, 1.0558, 1.0039, 1.3602, 1.1981, 1.2316,\n",
       "                       1.3122, 1.0064, 0.7829, 1.3809, 1.1030, 1.4282, 0.9289, 1.1313, 1.3792,\n",
       "                       0.9184, 1.0905, 1.0623, 1.2476, 1.4465, 1.1163, 1.2293, 1.0798, 1.3139,\n",
       "                       1.7250, 0.8172, 1.5012, 1.3231, 1.0144, 1.1767, 0.8729, 1.1869, 0.9012,\n",
       "                       1.0563, 0.7078, 1.3326, 1.0936, 1.0224, 1.3593, 0.9392, 1.0068, 0.9863,\n",
       "                       1.1849, 0.9958, 1.2248, 0.9927, 0.3141, 1.3952, 1.0526, 0.9720, 1.1495,\n",
       "                       1.1253, 0.9783, 1.0597, 1.0248, 1.4366, 1.3393, 1.2572, 0.9937, 1.1931,\n",
       "                       1.1437, 0.8957, 1.2098, 0.2566, 1.0649, 1.3017, 1.0800, 0.5224, 1.0450,\n",
       "                       1.1513, 1.1263, 0.8780, 1.3537, 1.1516, 1.5164, 1.1235, 0.9574, 0.9924,\n",
       "                       1.1335, 1.0409, 0.9817, 0.9195, 0.9063, 0.7173, 1.1560, 1.2215, 1.1700,\n",
       "                       1.4139, 1.2205, 0.9432, 1.0820, 1.4721, 1.3174, 1.0905, 1.2970, 0.8261,\n",
       "                       0.9812, 1.0475, 1.2826, 1.2452, 0.8185, 1.0462, 1.0750, 1.5156, 1.1132,\n",
       "                       1.3410, 1.1077, 1.1155, 1.2860, 0.9671, 0.5262, 1.1721, 0.9906, 1.1165,\n",
       "                       1.2943, 0.9292, 1.0349, 1.1765, 1.1188, 1.1820, 0.9491, 0.9734, 1.3175,\n",
       "                       1.2034, 1.2084, 0.9865, 1.2615, 0.8739, 0.7807, 1.1073, 0.7385, 0.9734,\n",
       "                       1.4519, 0.9854, 1.0787, 1.0790, 1.0758, 1.1872, 1.0594, 0.9354, 0.5785,\n",
       "                       1.2671, 0.6805, 1.1030, 1.2096, 1.1690, 0.8356, 0.8897, 1.0657, 1.2187,\n",
       "                       0.9070, 0.7119, 0.9653, 0.9849, 1.0520, 0.2849, 0.9442, 1.1167, 1.2524,\n",
       "                       1.0367, 1.4768, 1.2307, 1.2085, 0.8254, 1.2146, 1.1639, 0.2181, 1.2649,\n",
       "                       1.1123, 1.2077, 1.2347, 1.0788, 1.5626, 1.0067, 1.1525, 1.1592, 1.1814,\n",
       "                       1.2216, 1.1346, 0.6273, 1.3089, 1.5136, 1.1486, 0.7495, 1.3114, 0.9355,\n",
       "                       1.1059, 1.4022, 1.3204, 1.5235, 1.3346, 1.1735, 1.1633, 1.0751, 1.3056,\n",
       "                       1.0540, 1.0776, 0.9134, 0.7332, 1.1821, 0.9479, 0.8942, 1.1816, 1.1299,\n",
       "                       0.9147, 1.0555, 0.8702, 1.0005], device='cuda:0')),\n",
       "              ('conv_block3.bn1.bias',\n",
       "               tensor([-0.8982, -0.5593, -0.8299, -0.8870, -0.6938, -0.3829, -1.0505, -0.7719,\n",
       "                       -0.6779, -0.5489, -0.8549, -0.9675, -0.3858, -1.1915, -0.7939, -0.5287,\n",
       "                       -1.0818, -0.6826, -1.1990, -0.5504, -0.6985, -0.5265, -0.7031, -0.7221,\n",
       "                       -0.6240, -0.7923, -0.7477, -0.6211, -0.4847, -0.9305, -0.8672, -0.9640,\n",
       "                       -0.5970, -0.7963, -1.0095, -0.7041, -0.6201, -0.8272, -0.8642, -0.7149,\n",
       "                       -0.1486, -0.8913, -1.5533, -0.5700, -0.7954, -0.9663, -0.5202, -1.0395,\n",
       "                       -1.0383, -0.8046, -0.7002, -1.1470, -0.5868, -0.7367, -0.7754, -0.4929,\n",
       "                       -0.6644, -0.7077, -0.7026, -0.8174, -0.6611, -0.5234, -0.6234, -0.5961,\n",
       "                       -0.5143, -0.7454, -0.6751, -0.6286, -1.0052, -1.2545, -0.4291, -1.1618,\n",
       "                       -0.8726, -0.8077, -1.0296, -0.9257, -1.2397, -0.9032, -1.1586, -0.6834,\n",
       "                       -0.3203, -0.7832,  0.3590, -0.7680, -0.7617, -0.9250, -0.9485, -0.8702,\n",
       "                       -0.5869, -0.2732, -1.1147, -0.6329, -0.7087, -0.5849, -1.2142, -0.8736,\n",
       "                       -1.2073, -0.4033, -0.6485, -0.9067, -0.1779, -0.7485, -1.5761, -0.8470,\n",
       "                       -0.5936, -1.3240, -0.8528, -0.7504, -0.8944, -0.4018, -0.9139, -0.2481,\n",
       "                       -1.2777, -0.6512, -0.5649,  0.1888, -0.9627, -0.8056, -0.6371, -0.6132,\n",
       "                       -1.0691, -0.5870, -1.7209, -0.3129, -0.5256, -1.5523, -0.5553, -0.8495,\n",
       "                       -0.0422, -0.3014, -0.5068, -0.6025, -0.5146, -1.0281, -0.7575, -1.0009,\n",
       "                       -0.9620, -0.3392, -0.7340, -0.9131, -1.0636, -0.7621, -0.8121, -0.3924,\n",
       "                       -1.2843, -0.4223, -0.8621, -0.7582, -0.4664, -0.6746, -0.9525, -0.7069,\n",
       "                       -0.6494, -1.2329, -0.9510, -0.5987, -0.8122, -0.2585, -2.3511, -0.4336,\n",
       "                       -0.4982, -1.0574, -0.6793, -0.3944, -0.4837, -0.6630, -1.0718, -0.7356,\n",
       "                       -0.3307, -0.7226, -0.8178, -0.3179, -0.6890, -0.4605, -1.2686, -0.4719,\n",
       "                       -0.4427, -0.6833, -0.3259, -0.6951, -1.1053, -0.9664, -0.7898, -0.8774,\n",
       "                       -0.1740, -0.9885, -0.3770, -0.7380, -1.2202, -1.1224, -0.1347, -0.7182,\n",
       "                       -0.7212, -0.3407, -0.2000, -0.8056, -0.8408, -0.6210, -1.0593, -3.0333,\n",
       "                       -0.3586, -1.0164, -0.5091, -0.7474, -0.7502, -0.5594, -0.7063, -0.6198,\n",
       "                       -1.2757, -0.9516, -0.7334, -0.6935, -0.7772, -0.7707, -0.4082, -1.0337,\n",
       "                       -0.6719, -0.8486, -0.8674, -0.7073, -0.8083, -0.7788, -0.8789, -0.3953,\n",
       "                       -1.1115, -0.7206, -0.9332,  0.0890, -0.8098, -0.9703, -1.0459, -0.3908,\n",
       "                       -0.4484, -0.9225, -0.8505, -0.7879, -0.9284, -1.4579, -1.1448, -0.5124,\n",
       "                       -0.8017, -0.4046, -0.8617, -0.6982, -0.5067, -0.4861, -0.2880, -0.7619,\n",
       "                       -0.6610, -0.4801, -0.9662, -0.7079, -0.0607, -0.8820, -0.4338, -0.8083],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.running_mean',\n",
       "               tensor([-3.7360, -4.6233, -3.6557, -4.6322, -4.8712, -6.6473,  2.6305, -2.3720,\n",
       "                       -5.6320, -4.4953, -5.4183, -4.5167, -0.6653, -1.5994, -3.9121, -4.2781,\n",
       "                       -5.1403, -6.3913, -2.0675, -2.6454, -2.2475, -3.3489, -3.0543, -3.3195,\n",
       "                       -3.7124, -2.8566,  0.2100, -1.1776, -2.3026, -5.0968, -1.6714, -3.2174,\n",
       "                       -4.1996, -3.7995, -4.8007, -1.2997, -5.3567, -6.7394, -3.0238, -3.8048,\n",
       "                       -5.4116, -1.9124, -3.5887, -3.7645, -3.0835,  0.4196, -0.1750, -0.8241,\n",
       "                       -3.8663, -5.2823, -1.4541, -0.5725, -3.8569, -1.6381, -7.6170, -2.1444,\n",
       "                       -4.5620, -5.6154, -4.2468, -5.3433, -5.3010, -2.4488, -6.4545, -2.8165,\n",
       "                        0.4223, -3.1771, -4.7437, -3.0589, -3.0745, -5.9238, -3.7874, -2.2076,\n",
       "                       -3.5404,  0.2015, -1.2456, -3.9242,  0.0954, -3.9417,  2.5984, -3.5945,\n",
       "                       -5.9171, -6.4251, -2.2578, -7.8775, -4.0284, -1.5283, -4.6262, -4.2763,\n",
       "                       -3.8058, -3.8550,  1.3800, -4.1743, -2.1319, -3.8210,  0.2053, -6.9632,\n",
       "                        1.3226, -2.8647, -3.8293, -1.0065, -4.6257, -2.2867, -0.0156, -1.9057,\n",
       "                       -3.9294, -1.8285, -0.6933, -7.2701, -0.6164, -6.3500, -2.5230, -0.1673,\n",
       "                       -0.9316, -4.1876, -2.7565, -3.4657, -4.0930, -1.9206, -3.3713,  1.5430,\n",
       "                       -3.6946, -6.0348, -4.5280, -3.2375, -1.6931,  5.8075, -4.1949, -1.6370,\n",
       "                       -1.5397, -2.7168, -4.1562, -2.2200, -4.1181, -4.4697, -1.1916, -2.0798,\n",
       "                       -3.4317, -1.1386, -3.6220, -2.8417, -4.7057, -2.8248, -2.5854, -8.3990,\n",
       "                        5.7105, -3.2966, -4.7009, -3.6105, -1.5590, -3.8793, -4.2679, -4.7801,\n",
       "                       -3.7535, -1.4472, -1.8453, -3.9892, -3.5442, -4.9556,  0.1412, -5.7569,\n",
       "                       -2.0001, -2.6130, -3.2370, -3.9707, -3.0764, -7.3013, -3.8480, -2.5359,\n",
       "                       -0.9426, -2.6543, -2.9104, -2.9212, -2.5907, -3.6120, -8.9578, -5.6857,\n",
       "                       -0.9836, -5.1064, -5.8374, -5.6726, -4.7037,  0.2951, -4.0062, -3.3184,\n",
       "                       -2.3170, -4.5064, -6.1815, -0.9618,  0.3356,  1.5998, -6.5894, -3.6475,\n",
       "                       -1.6931, -4.1432, -2.0141, -4.7789, -0.4445, -3.1385, -0.5600, -1.2760,\n",
       "                       -5.1539,  0.3197, -2.1731,  0.3439, -0.0959, -4.5920, -3.5617, -1.3553,\n",
       "                       -4.1359, -2.9156, -3.2453,  0.2077, -2.4971, -4.5291,  0.4152, -5.2192,\n",
       "                       -4.4310, -4.0784, -3.5517, -2.5801, -3.5983,  1.2604, -2.5246, -2.3927,\n",
       "                       -3.4935, -2.9094, -2.1389, -1.9884, -3.0646, -8.0526, -1.8004, -0.2110,\n",
       "                       -2.6031,  2.8122, -1.1262, -3.0278, -4.2276, -5.0716, -3.3233, -3.3826,\n",
       "                       -5.1959, -0.9382, -2.2691, -0.8058, -2.6139, -5.5010, -5.3529, -1.8328,\n",
       "                       -3.7692, -0.9625, -3.4762, -3.4709, -3.0176, -3.5250, -4.4706, -1.3083],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.running_var',\n",
       "               tensor([ 6.1906, 10.7009, 24.1509, 10.8535, 20.8408, 33.6762,  5.2201,  9.7729,\n",
       "                       23.8067, 10.8420, 21.0792,  9.0527, 12.4375,  6.0220, 12.7975,  4.4165,\n",
       "                       19.1036, 15.9470,  6.0773,  5.3244,  5.8844, 15.2656, 13.7625, 17.2115,\n",
       "                        9.5323, 18.9623,  0.3134,  9.9714, 19.6615, 26.4770,  7.6843,  8.8536,\n",
       "                       19.2414, 11.6547, 12.2803, 10.6438, 12.2425, 16.1193, 18.3075, 13.7481,\n",
       "                       13.2419,  9.7243,  9.2443,  9.2479, 13.4569,  9.9631, 10.7243,  8.8279,\n",
       "                        9.7693,  7.5803,  3.7514,  7.1608, 17.4216,  5.2497, 14.5373,  5.3475,\n",
       "                       14.0407, 21.1500, 12.7579, 19.2692, 11.1483, 16.4439, 27.9443, 12.0953,\n",
       "                       11.8162, 16.3111, 16.5706, 20.7969,  6.6163, 11.7927, 11.9599,  6.9639,\n",
       "                       27.2784,  2.5325, 10.3721, 19.2093,  4.0294,  8.4838,  6.6247, 10.4096,\n",
       "                       14.7797, 14.9003, 15.6197, 22.0655,  6.7335,  4.0474, 13.0321,  4.2047,\n",
       "                       19.2052, 20.2889,  5.2874,  7.2998, 14.2664,  7.5100,  0.7746, 15.2723,\n",
       "                        2.8366, 10.4677,  9.4623, 10.7298, 16.2824, 14.4357,  8.2096,  7.2522,\n",
       "                        9.0731,  6.8159,  5.1362, 13.4172,  5.0952, 14.4018, 15.6126,  0.6714,\n",
       "                        5.5315,  9.3035,  9.0678, 10.5202,  8.3224,  7.0902, 10.3108, 14.5298,\n",
       "                       12.4740, 16.5915, 10.1835, 15.5011,  8.4438, 10.5427, 11.1548,  7.0762,\n",
       "                       11.7243,  7.0338, 14.6593,  7.7724, 11.6558, 15.6894, 10.9430, 10.4501,\n",
       "                        7.1322, 16.6671,  9.2184, 14.6290, 20.1197, 11.5443,  7.8513, 18.9911,\n",
       "                        4.9606, 12.3159, 28.1145, 11.0436,  9.8462, 14.1108,  6.0178, 29.4965,\n",
       "                       14.3037,  7.9433,  5.8518,  8.9415, 22.8256, 13.0112,  0.8590, 29.0803,\n",
       "                       15.0455,  6.8791, 29.8244, 16.2032, 26.9033, 13.4011,  7.0414, 14.9736,\n",
       "                       11.0406,  7.4606,  6.3046,  7.9925,  7.9554,  9.7872, 12.8046, 11.6541,\n",
       "                        3.6507,  9.7574, 16.0379, 10.1677, 17.7478,  4.3765, 11.2913, 11.3733,\n",
       "                       14.5081,  7.4594, 13.1381,  9.7234,  1.3204,  6.6638, 16.0777,  5.1876,\n",
       "                       14.0519, 19.1653, 14.3280,  9.4319,  8.8464,  7.8796,  2.3688,  1.8170,\n",
       "                       10.6819,  2.9820,  8.9859,  0.6444, 10.0688, 16.8911, 16.1451, 11.7682,\n",
       "                       10.2172, 14.2086,  7.7493, 10.2250,  7.0203, 14.0146,  0.5052, 16.7758,\n",
       "                        6.6086, 10.6471, 12.1595,  9.1270, 23.1104,  5.8590, 10.6717, 14.7882,\n",
       "                       10.8837,  7.7072,  8.7823, 14.0688, 11.8872, 14.3936,  9.7891, 13.1332,\n",
       "                       22.6213,  6.3628, 14.6721, 14.4389, 15.3946, 16.4688, 10.7773,  6.6466,\n",
       "                       21.1301, 10.7116,  6.1879,  8.1472,  7.0374, 16.1513, 11.5553,  6.8429,\n",
       "                       12.0741, 11.5021, 10.7611, 12.5017, 14.9984, 15.8575, 19.4742,  8.1398],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block3.bn2.weight',\n",
       "               tensor([0.9051, 0.9394, 0.3467, 1.0366, 1.0479, 1.1572, 1.6049, 1.1137, 0.9935,\n",
       "                       1.1752, 0.8874, 1.0937, 0.6876, 1.1102, 1.4864, 1.3248, 0.9897, 1.4706,\n",
       "                       1.4177, 0.2613, 1.1516, 0.9729, 1.2617, 0.2820, 1.0827, 0.2616, 1.4487,\n",
       "                       1.0664, 1.4253, 1.3209, 1.0332, 1.2626, 0.9325, 1.1220, 0.8981, 1.0424,\n",
       "                       0.9619, 1.2507, 1.3945, 1.1734, 0.9084, 0.8654, 1.2673, 1.0337, 1.0987,\n",
       "                       1.3766, 1.6624, 0.8357, 1.0707, 0.9537, 0.2633, 0.9885, 0.9755, 1.3231,\n",
       "                       1.2518, 1.4758, 1.3703, 1.1539, 1.1889, 1.1905, 1.4671, 1.0795, 0.8962,\n",
       "                       0.8735, 1.1473, 1.0061, 0.9262, 0.9056, 0.9279, 1.1607, 1.1400, 1.3418,\n",
       "                       0.2692, 1.0091, 1.3077, 0.5176, 0.9112, 0.9307, 1.0229, 0.8897, 1.0297,\n",
       "                       0.9391, 1.0971, 0.4626, 0.9116, 1.4098, 1.0808, 1.0182, 1.5772, 1.0186,\n",
       "                       1.0702, 0.9926, 1.3717, 0.9138, 1.1040, 1.0963, 0.8279, 1.0532, 1.3980,\n",
       "                       1.2943, 1.0913, 0.8435, 1.0859, 0.9802, 1.0216, 0.2935, 1.1645, 0.9617,\n",
       "                       1.4009, 1.1233, 0.9578, 0.6571, 1.0725, 0.7002, 1.0372, 1.1292, 1.2509,\n",
       "                       0.9716, 1.5299, 1.2976, 1.0172, 1.2507, 1.0353, 1.0831, 0.9625, 0.9419,\n",
       "                       1.1977, 1.0909, 1.2755, 0.8902, 1.2145, 1.3266, 0.8319, 0.9505, 0.9411,\n",
       "                       1.1432, 0.9254, 1.1651, 1.1642, 0.2505, 1.2972, 1.1613, 0.9954, 1.1288,\n",
       "                       1.1554, 1.1024, 1.4579, 0.8870, 1.1077, 1.3331, 1.1827, 1.0637, 0.9267,\n",
       "                       1.1762, 1.0574, 1.2458, 1.3292, 0.9216, 1.0776, 1.2446, 1.3153, 1.2265,\n",
       "                       1.1726, 1.0782, 0.2623, 0.8875, 0.2963, 1.2376, 1.4084, 1.0460, 1.2456,\n",
       "                       1.2219, 1.0095, 1.0642, 0.9782, 1.2341, 1.0097, 1.0705, 0.8490, 0.9098,\n",
       "                       1.0768, 1.0270, 1.1807, 1.2606, 1.3560, 1.4065, 1.1395, 1.1043, 1.0956,\n",
       "                       0.9400, 0.9232, 0.9482, 1.0033, 0.7078, 1.1307, 1.1774, 0.9191, 1.1546,\n",
       "                       0.9854, 0.8554, 1.0341, 0.8977, 0.8860, 0.9033, 1.0850, 1.0711, 1.1451,\n",
       "                       0.9898, 1.1208, 1.0563, 1.3754, 0.8993, 1.0484, 0.8753, 0.9922, 1.2163,\n",
       "                       1.0892, 1.1947, 0.7565, 0.9142, 1.3299, 0.9942, 1.0805, 1.3669, 0.8534,\n",
       "                       1.3016, 1.4345, 1.2004, 1.1323, 0.7956, 0.9888, 1.0292, 1.1574, 1.1866,\n",
       "                       1.1543, 1.0344, 1.4174, 0.3030, 1.4229, 1.2801, 0.2937, 0.9351, 0.9618,\n",
       "                       1.1582, 1.2652, 0.9315, 1.1234, 1.0876, 1.0357, 1.2522, 0.9250, 1.1716,\n",
       "                       1.2080, 1.2942, 1.3198, 1.2777], device='cuda:0')),\n",
       "              ('conv_block3.bn2.bias',\n",
       "               tensor([-0.6634, -0.5544, -0.0422, -0.6581, -0.8572, -0.9712, -1.6261, -0.5950,\n",
       "                       -0.7201, -1.2496, -0.5318, -0.7978, -0.1393, -0.6118, -1.3631, -1.3863,\n",
       "                       -0.6188, -1.2326, -1.6330, -0.1872, -0.8443, -0.7549, -1.2820, -0.0505,\n",
       "                       -1.1499, -0.0781, -1.2581, -1.0880, -1.3273, -1.2754, -0.6035, -0.7674,\n",
       "                       -0.4481, -1.0971, -0.9998, -0.6411, -0.5971, -1.3235, -1.3134, -0.8110,\n",
       "                       -0.5895, -0.6744, -0.8855, -1.1614, -1.0477, -1.3588, -1.3315, -0.6502,\n",
       "                       -1.0932, -0.7254, -0.3861, -0.5992, -1.0614, -1.1524, -1.2114, -1.0342,\n",
       "                       -1.3392, -0.7853, -0.7540, -0.9350, -1.7840, -0.9019, -0.7942, -0.5565,\n",
       "                       -1.1643, -0.6610, -0.6357, -0.4942, -0.7252, -1.0780, -0.9504, -1.2680,\n",
       "                       -0.0283, -0.9093, -1.0604,  0.0534, -0.5707, -0.8475, -0.7689, -0.7964,\n",
       "                       -1.0437, -0.7244, -0.6308, -0.0799, -0.6952, -1.1794, -0.9914, -0.9248,\n",
       "                       -1.2379, -0.8964, -1.0408, -0.6191, -1.2270, -0.5548, -0.9034, -1.1669,\n",
       "                       -0.6484, -0.8183, -1.1430, -1.5660, -0.9298, -0.2687, -0.6611, -0.5908,\n",
       "                       -0.7479, -0.0536, -1.2109, -0.8190, -1.3240, -0.9726, -0.5736, -0.2446,\n",
       "                       -0.9323, -0.2670, -0.8135, -0.9782, -1.0693, -0.8946, -1.2197, -1.2017,\n",
       "                       -0.8493, -1.0271, -0.7801, -0.9973, -0.5407, -0.5843, -0.8183, -0.9339,\n",
       "                       -1.1637, -0.6353, -0.8803, -1.1417, -0.6053, -0.5750, -0.9905, -1.1236,\n",
       "                       -0.7335, -0.7768, -1.1079, -0.0484, -1.5820, -1.2682, -0.9510, -0.8856,\n",
       "                       -1.1036, -1.2498, -1.1422, -0.8046, -0.9191, -1.1010, -0.9548, -0.9208,\n",
       "                       -0.7223, -0.7993, -0.9130, -0.6914, -1.4146, -0.8214, -0.7783, -0.7009,\n",
       "                       -1.1782, -0.8517, -0.7981, -1.0004, -0.0658, -0.6777,  0.1841, -0.9849,\n",
       "                       -1.3402, -0.8736, -0.5267, -0.7914, -0.9291, -1.1181, -0.5579, -0.9340,\n",
       "                       -1.1616, -1.0515, -0.6710, -0.8138, -0.8020, -0.6899, -1.1364, -1.0139,\n",
       "                       -0.7805, -1.3099, -0.3936, -0.8767, -0.4665, -0.8453, -0.6968, -0.5989,\n",
       "                       -0.8351, -0.6806, -0.9338, -1.0715, -0.7662, -1.4438, -0.6182, -0.7659,\n",
       "                       -1.0537, -0.5319, -0.5135, -0.9045, -0.5828, -0.8373, -0.9134, -0.7420,\n",
       "                       -1.1932, -0.9939, -0.7015, -0.5463, -1.0515, -0.5218, -0.5948, -0.8505,\n",
       "                       -1.0803, -0.9453, -0.5138, -0.3713, -1.3711, -0.6823, -0.7744, -1.3687,\n",
       "                       -0.5889, -0.9297, -1.4539, -0.9427, -0.8768, -0.5206, -1.0093, -0.6510,\n",
       "                       -0.8140, -1.1389, -1.1334, -0.8144, -1.4738,  0.0231, -1.1460, -1.0632,\n",
       "                       -0.0401, -0.7883, -0.5025, -0.6524, -1.0350, -0.7857, -0.7549, -0.8493,\n",
       "                       -0.7969, -0.8876, -0.9356, -0.6092, -1.0583, -1.3752, -1.4297, -1.2696],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn2.running_mean',\n",
       "               tensor([-3.4911e+00, -9.6107e+00, -5.3826e+00, -1.6101e+01, -5.5888e+00,\n",
       "                       -8.8130e+00, -9.5321e+00, -6.3366e+00, -8.2244e+00, -8.4098e+00,\n",
       "                       -3.3756e+00, -7.0694e+00, -4.1885e+00, -8.6844e+00, -7.0230e+00,\n",
       "                       -1.5198e+01, -1.1964e+01, -7.8929e+00, -3.9568e+00, -3.9354e+00,\n",
       "                       -1.1699e+01,  2.0371e+00, -9.2795e+00,  5.9330e-02, -5.3359e+00,\n",
       "                        1.4149e-02, -6.5833e+00, -4.7250e-01, -1.2001e+01, -5.9918e+00,\n",
       "                       -1.3095e+01, -6.4204e+00, -2.2617e+00, -1.1366e+01, -6.1231e+00,\n",
       "                       -9.6574e+00, -1.2655e+01, -3.6809e+00, -6.0819e+00, -2.5524e+00,\n",
       "                        4.1935e+00, -3.6395e+00, -4.0330e+00, -4.5607e+00, -5.9919e+00,\n",
       "                       -1.3055e+01, -4.4051e+00, -4.5932e+00, -7.9964e+00, -6.3563e+00,\n",
       "                        7.8042e-02, -8.5461e+00, -4.2503e+00, -7.0154e+00, -8.0652e+00,\n",
       "                       -7.5181e+00, -9.9843e+00, -1.2088e+01, -8.2631e+00, -1.6709e+01,\n",
       "                       -8.9786e+00, -3.2740e+00, -3.0352e+00, -5.7816e+00, -1.0367e+00,\n",
       "                       -9.6153e+00, -1.2270e+00, -6.9112e+00, -5.0506e+00, -1.1475e+01,\n",
       "                       -7.0857e+00, -9.1037e+00, -2.5610e-02, -6.9558e+00, -8.9153e+00,\n",
       "                       -1.1920e+00, -9.7330e+00, -1.3303e+01, -1.0187e+01, -3.5070e+00,\n",
       "                       -3.8751e+00, -6.2426e+00, -7.3738e+00, -7.2214e+00, -7.7449e+00,\n",
       "                       -1.9124e+00, -4.3638e+00, -2.4460e+00, -8.4248e+00, -7.2303e+00,\n",
       "                       -5.0449e+00, -6.1708e+00, -6.7142e+00, -8.7842e+00, -1.4931e+01,\n",
       "                       -8.3758e+00,  4.8030e+00, -1.2311e+01, -5.9956e+00, -2.1967e+00,\n",
       "                       -2.2356e+00, -3.7703e+00, -5.8839e+00, -1.1787e+01, -1.0484e+01,\n",
       "                        9.5356e-02, -6.3985e+00, -6.5360e+00, -9.0980e+00, -9.6880e+00,\n",
       "                       -1.0938e+01, -8.2971e+00, -8.1249e+00, -3.1658e+00, -3.9382e+00,\n",
       "                       -5.5435e+00, -1.3640e+01, -1.0127e+01, -5.9742e+00, -9.9183e+00,\n",
       "                       -5.7110e+00, -2.7085e+00, -3.4386e+00, -9.2171e+00, -7.6556e+00,\n",
       "                       -8.4008e+00, -7.3623e+00, -9.9678e+00, -6.5990e+00, -1.0719e+01,\n",
       "                       -8.8565e+00, -2.6989e+00, -8.4863e+00, -4.6265e+00, -1.0382e+01,\n",
       "                       -9.7883e+00, -1.2193e+01, -6.3949e+00, -4.8447e+00,  5.8276e-03,\n",
       "                       -6.2136e+00, -1.0262e+01, -8.1288e+00, -2.5930e+00, -1.1328e+01,\n",
       "                       -3.8169e+00, -5.9234e+00, -1.1199e+01, -7.7389e+00, -8.8508e+00,\n",
       "                       -9.2099e+00, -1.2340e+01, -7.9534e+00, -7.4613e+00, -3.8052e+00,\n",
       "                       -6.5691e+00, -9.9729e+00, -1.3705e+00, -5.1512e+00, -1.0458e+00,\n",
       "                       -4.5330e+00, -1.1094e+01, -9.7869e+00, -5.6063e+00,  7.8726e-02,\n",
       "                       -2.8889e+00, -1.3183e+00, -3.8979e+00, -8.7061e+00, -9.4747e+00,\n",
       "                       -7.4667e+00, -6.6214e+00, -1.0910e+01, -4.1701e+00, -4.1629e+00,\n",
       "                       -7.0732e+00, -6.9208e+00, -6.2487e+00, -5.0185e+00, -5.0112e+00,\n",
       "                       -1.0220e+01, -1.0323e+01, -6.2955e+00, -5.8233e+00, -1.1548e+01,\n",
       "                       -6.7834e+00, -4.5839e+00, -1.3402e+01, -4.6271e+00, -1.2829e+01,\n",
       "                       -6.7772e+00, -6.7742e+00, -8.2506e+00,  4.2465e-01, -1.3567e+01,\n",
       "                       -3.2647e+00, -6.7446e+00,  3.3160e-01, -6.1321e+00, -6.4997e+00,\n",
       "                       -8.8729e+00, -5.6220e+00, -3.4813e+00, -5.9370e+00, -1.0709e+01,\n",
       "                       -6.4628e+00, -1.1719e+01, -3.9484e+00,  3.1026e+00, -6.6003e+00,\n",
       "                       -9.4827e+00, -8.4693e+00, -9.2676e+00, -1.1096e+01, -5.9350e+00,\n",
       "                       -9.8378e+00,  2.6526e+00, -9.2605e+00, -3.1468e+00, -9.9574e+00,\n",
       "                        2.6649e+00, -1.0790e+01, -7.9090e+00, -1.0677e+01, -7.9327e+00,\n",
       "                       -7.8905e+00, -6.0571e+00, -7.4595e+00, -1.0302e+01, -1.7779e+00,\n",
       "                       -6.6011e+00, -4.6557e+00, -1.1171e+01, -6.7969e+00, -3.7002e+00,\n",
       "                       -1.0312e+01, -1.0197e+01,  2.4224e+00, -5.5731e+00, -6.1909e+00,\n",
       "                        2.6746e-02, -1.0855e+01, -1.0937e+01, -1.0483e+01, -6.3921e+00,\n",
       "                       -7.5746e+00, -2.4169e+00, -1.0476e+01, -7.3055e-01, -4.6117e+00,\n",
       "                       -7.9135e+00, -6.3495e+00, -5.4649e+00, -9.6260e+00, -6.5566e+00,\n",
       "                       -9.5391e+00], device='cuda:0')),\n",
       "              ('conv_block3.bn2.running_var',\n",
       "               tensor([32.6233, 51.5683, 12.6306, 65.5238, 32.6754, 44.7554, 64.5536, 27.7206,\n",
       "                       39.5589, 38.3092, 26.6532, 33.9899, 30.0790, 54.5678, 51.9654, 59.6498,\n",
       "                       30.5240, 46.6019, 27.9788,  6.7656, 67.2831, 29.2543, 63.4173,  4.0350,\n",
       "                       27.5978,  2.7838, 46.1793, 22.1832, 76.4300, 27.9449, 36.9475, 48.0723,\n",
       "                       45.7297, 53.8783, 28.5872, 56.5120, 47.0346, 60.6090, 60.9651, 25.6091,\n",
       "                       42.1833, 48.8448, 35.1397, 50.1726, 56.0075, 34.9519, 36.2864, 35.8140,\n",
       "                       37.3637, 29.9512,  2.6348, 26.1510, 42.6052, 53.2502, 25.8395, 35.5810,\n",
       "                       40.8477, 38.8935, 45.3449, 51.7833, 39.9969, 43.2109, 25.6505, 36.0094,\n",
       "                       33.2648, 62.1977, 39.1122, 57.3670, 33.4389, 38.1868, 52.7368, 54.3924,\n",
       "                        3.6088, 64.9561, 36.4023, 15.0502, 40.6238, 54.7768, 29.0203, 38.0345,\n",
       "                       65.5473, 53.0213, 29.6840, 11.6785, 36.9148, 31.7697, 59.0567, 56.0098,\n",
       "                       53.6699, 58.3168, 48.9750, 37.4606, 42.3741, 51.5572, 94.3404, 24.0388,\n",
       "                       25.0426, 38.1994, 50.9014, 22.3653, 39.0551, 24.0783, 40.2843, 49.7629,\n",
       "                       37.6483,  3.2578, 38.6164, 40.2132, 63.3210, 47.4026, 42.1460, 22.7260,\n",
       "                       44.6575, 34.8594, 43.7083, 44.9351, 45.3688, 48.0210, 33.4751, 45.1288,\n",
       "                       53.3950, 32.8214, 57.7978, 36.8290, 41.1461, 38.3068, 33.7378, 57.2282,\n",
       "                       33.2330, 48.1275, 42.6299, 27.8076, 46.1160, 46.7283, 42.1512, 28.0513,\n",
       "                       57.9283, 39.8380, 43.2196,  3.5073, 28.0107, 46.1415, 68.1599, 48.5282,\n",
       "                       56.3766, 35.8305, 39.1425, 44.9112, 59.0459, 36.1491, 35.4118, 41.4488,\n",
       "                       45.1702, 27.1920, 49.6938, 47.7060, 31.0848, 15.4609, 26.2254, 29.7920,\n",
       "                       23.0079, 73.6208, 41.7077, 37.2194,  2.4906, 26.4361,  8.6566, 37.1917,\n",
       "                       42.9030, 79.9636, 34.5892, 25.0802, 57.8477, 48.7814, 38.4691, 44.0872,\n",
       "                       38.7179, 67.8061, 36.7731, 20.4657, 46.1175, 40.5765, 36.2589, 49.1754,\n",
       "                       39.0490, 35.3677, 44.1855, 75.3239, 30.7163, 40.1691, 43.4779, 36.5468,\n",
       "                       39.9022, 23.8207, 47.7200, 35.6861, 49.6604, 36.0345, 42.3438, 26.6729,\n",
       "                       38.3238, 25.3345, 33.1475, 36.2977, 30.7630, 33.7805, 52.9490, 27.6904,\n",
       "                       37.3234, 65.8518, 69.2531, 35.1666, 37.9871, 40.7733, 24.8778, 32.4508,\n",
       "                       39.5215, 46.5822, 29.6104, 39.9276, 35.4048, 68.5465, 58.7924, 26.3959,\n",
       "                       44.8660, 41.4652, 37.1311, 36.3811, 38.8422, 38.1316, 46.0219, 37.1965,\n",
       "                       53.9513, 32.3594, 31.7732, 46.6417, 45.2628,  7.0563, 49.5439, 32.8643,\n",
       "                        3.0042, 29.8262, 41.4070, 42.1796, 28.3282, 47.5921, 33.2856, 51.8637,\n",
       "                       34.3875, 31.0627, 32.7539, 48.3618, 42.0343, 42.5362, 42.4494, 46.9895],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block4.conv1.weight',\n",
       "               tensor([[[[-2.8117e-01, -1.9448e-01, -3.2072e-01],\n",
       "                         [ 1.6667e-01,  7.5469e-03, -1.2761e-01],\n",
       "                         [ 1.5804e-01,  1.4452e-01,  5.4735e-03]],\n",
       "               \n",
       "                        [[ 5.7425e-03, -1.6190e-02, -4.9775e-01],\n",
       "                         [ 6.9577e-02,  3.7016e-02, -2.2179e-01],\n",
       "                         [-2.1399e-01, -1.8292e-01, -2.7259e-01]],\n",
       "               \n",
       "                        [[-3.2275e-02,  6.3697e-02,  3.6232e-02],\n",
       "                         [-1.0834e-02,  2.3389e-01, -1.6246e-02],\n",
       "                         [ 1.3494e-01,  1.3342e-01, -1.4910e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.0493e-01,  6.6150e-03,  9.4810e-02],\n",
       "                         [ 7.5323e-02, -8.4515e-02, -2.6031e-01],\n",
       "                         [-4.4923e-02,  1.3767e-01, -1.3903e-02]],\n",
       "               \n",
       "                        [[ 5.8768e-02,  3.0249e-03,  1.2129e-01],\n",
       "                         [-1.4058e-02, -1.4894e-02,  1.1285e-01],\n",
       "                         [ 7.8302e-02, -5.2702e-03,  1.2461e-01]],\n",
       "               \n",
       "                        [[-2.8437e-02, -1.5080e-01, -1.7280e-02],\n",
       "                         [ 2.3192e-01, -1.1718e-02, -4.4942e-02],\n",
       "                         [ 6.1271e-01,  2.4129e-01,  1.4843e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8397e-01,  1.0231e-01, -3.6553e-04],\n",
       "                         [ 3.4619e-01,  2.6139e-01,  2.4499e-01],\n",
       "                         [ 3.5390e-01,  2.8168e-01,  3.8342e-01]],\n",
       "               \n",
       "                        [[ 8.4976e-02,  2.6384e-01,  9.5468e-02],\n",
       "                         [-2.7714e-02, -2.2332e-02, -4.8102e-02],\n",
       "                         [-1.7257e-01,  6.8492e-02,  1.0205e-01]],\n",
       "               \n",
       "                        [[-2.5342e-02, -1.5528e-02, -6.1688e-02],\n",
       "                         [-2.7608e-02, -2.5081e-02, -6.0266e-02],\n",
       "                         [ 6.7514e-04, -1.2479e-03, -4.8764e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2393e-01, -9.4306e-02, -1.9476e-01],\n",
       "                         [ 5.8398e-03, -7.9925e-02, -4.1517e-01],\n",
       "                         [-5.0327e-02, -1.9655e-01, -1.1735e-01]],\n",
       "               \n",
       "                        [[ 2.7297e-01, -4.6044e-02,  2.8592e-02],\n",
       "                         [ 7.4112e-01, -5.0212e-02, -1.0976e-01],\n",
       "                         [ 6.0514e-01, -6.1636e-02,  1.5829e-01]],\n",
       "               \n",
       "                        [[-8.9858e-02, -1.4299e-01, -8.8171e-02],\n",
       "                         [-2.7729e-02, -5.3546e-02,  1.1596e-03],\n",
       "                         [ 1.9970e-01,  5.9318e-02,  1.9625e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.5145e-02, -7.8992e-02, -2.5136e-02],\n",
       "                         [-4.0007e-02, -3.4993e-02, -4.9632e-02],\n",
       "                         [ 2.2835e-02, -8.2773e-02, -1.4480e-01]],\n",
       "               \n",
       "                        [[ 8.8546e-02, -1.3631e-03,  7.4954e-05],\n",
       "                         [ 2.7300e-02, -2.4629e-02, -6.8863e-02],\n",
       "                         [ 9.9173e-02,  2.9239e-02, -1.0297e-02]],\n",
       "               \n",
       "                        [[ 1.6983e-02,  3.6542e-03, -6.4787e-02],\n",
       "                         [ 9.0322e-02,  2.4170e-02, -5.2050e-02],\n",
       "                         [ 6.6579e-02,  4.9823e-02, -2.5309e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.4695e-02,  4.1721e-02, -5.1636e-02],\n",
       "                         [-6.5091e-02, -4.3530e-02, -1.4238e-01],\n",
       "                         [-5.6960e-02, -3.9052e-02, -1.4414e-01]],\n",
       "               \n",
       "                        [[ 1.1531e-02,  5.8840e-02,  4.7447e-02],\n",
       "                         [ 6.2048e-02,  1.1637e-01,  5.8397e-02],\n",
       "                         [ 5.2231e-03, -4.5418e-03, -3.0628e-02]],\n",
       "               \n",
       "                        [[ 5.5873e-03,  3.9302e-02, -1.9303e-02],\n",
       "                         [-8.0556e-02,  4.2154e-03, -8.2461e-02],\n",
       "                         [-1.3790e-01, -1.9746e-02, -1.8784e-01]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-1.5198e-01, -3.6075e-02, -1.4837e-01],\n",
       "                         [-2.3885e-01, -2.8460e-02, -1.0875e-01],\n",
       "                         [-1.4545e-01, -7.0426e-02, -6.8133e-02]],\n",
       "               \n",
       "                        [[-5.5952e-02, -4.0911e-02, -3.3310e-02],\n",
       "                         [-1.7451e-01, -8.7108e-02,  1.2693e-02],\n",
       "                         [-7.0759e-02, -4.8385e-02, -3.3718e-03]],\n",
       "               \n",
       "                        [[ 2.9875e-02,  6.5026e-03, -1.0522e-01],\n",
       "                         [ 9.7180e-02,  5.2470e-02, -5.8483e-02],\n",
       "                         [ 1.0137e-02,  2.4127e-02, -2.8789e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.7989e-02,  1.1075e-01,  9.5427e-02],\n",
       "                         [ 2.2058e-02,  4.7560e-02,  4.7533e-02],\n",
       "                         [-1.4979e-02, -4.1187e-02, -8.4268e-03]],\n",
       "               \n",
       "                        [[-5.8950e-03, -4.3256e-02, -1.0115e-01],\n",
       "                         [-4.2977e-02,  7.3435e-04, -1.7013e-02],\n",
       "                         [-1.0561e-01, -1.1956e-01, -4.2652e-02]],\n",
       "               \n",
       "                        [[-3.0934e-02, -1.9715e-02, -4.4373e-02],\n",
       "                         [ 1.9279e-01,  1.6256e-01,  1.3915e-01],\n",
       "                         [ 4.7260e-02,  1.3291e-01, -8.4166e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.3602e-02,  2.0539e-02,  1.2633e-01],\n",
       "                         [-2.9732e-02,  6.9290e-02,  1.5418e-01],\n",
       "                         [ 7.1638e-02,  9.3394e-02,  1.5287e-01]],\n",
       "               \n",
       "                        [[-1.8831e-02,  1.6386e-02, -3.7939e-02],\n",
       "                         [-5.5418e-02,  3.2672e-03, -3.0469e-02],\n",
       "                         [ 1.9739e-03,  4.9307e-02, -2.8697e-02]],\n",
       "               \n",
       "                        [[ 1.1110e-02, -9.3922e-03, -1.0620e-01],\n",
       "                         [ 5.1250e-02,  4.8479e-02, -1.5916e-01],\n",
       "                         [ 2.6691e-02,  6.9313e-02, -1.7979e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.3847e-02, -1.4713e-02, -1.0052e-01],\n",
       "                         [ 1.9321e-02,  8.7875e-03, -5.4893e-02],\n",
       "                         [ 3.4401e-02,  1.7562e-02,  1.9163e-02]],\n",
       "               \n",
       "                        [[-1.8030e-04,  7.7708e-02,  1.5777e-01],\n",
       "                         [ 1.7430e-02,  5.9972e-02,  1.0575e-01],\n",
       "                         [-6.3385e-03,  6.1964e-02,  2.0596e-01]],\n",
       "               \n",
       "                        [[ 4.0382e-02,  1.6917e-01,  1.4179e-01],\n",
       "                         [ 6.5023e-02,  7.9723e-02,  1.8729e-01],\n",
       "                         [ 4.7586e-02,  1.4556e-01,  8.0061e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9561e-02,  1.6063e-02,  4.5139e-02],\n",
       "                         [-1.0781e-01, -1.5374e-02,  8.8728e-05],\n",
       "                         [-4.4376e-02,  5.6114e-03,  6.6437e-02]],\n",
       "               \n",
       "                        [[-2.1091e-02,  1.9502e-03, -5.8937e-02],\n",
       "                         [-4.3717e-02, -4.9178e-03, -1.5190e-01],\n",
       "                         [ 6.7578e-02,  5.1915e-02,  2.1604e-02]],\n",
       "               \n",
       "                        [[ 2.7038e-03, -4.4696e-02, -8.6027e-02],\n",
       "                         [ 8.1351e-02,  3.4863e-02, -1.7840e-01],\n",
       "                         [ 3.4614e-02,  3.6288e-02, -1.2641e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.3675e-03,  1.8449e-02, -4.5892e-02],\n",
       "                         [ 3.9285e-02,  1.1169e-02, -4.6597e-02],\n",
       "                         [ 1.1016e-02, -1.7599e-02, -4.0958e-02]],\n",
       "               \n",
       "                        [[ 1.7124e-02,  4.0852e-02,  7.1878e-02],\n",
       "                         [ 1.9256e-02,  2.0039e-02,  6.9166e-02],\n",
       "                         [ 8.0109e-02,  1.0178e-01,  1.2642e-01]],\n",
       "               \n",
       "                        [[-1.3671e-02,  2.6154e-02, -1.1227e-03],\n",
       "                         [-5.0951e-02,  1.0144e-02, -8.1067e-02],\n",
       "                         [-4.0022e-02, -1.2864e-02, -1.0272e-01]]]], device='cuda:0')),\n",
       "              ('conv_block4.conv2.weight',\n",
       "               tensor([[[[-1.3141e-01, -1.7014e-01, -3.1536e-01],\n",
       "                         [ 1.4788e-04, -1.2086e-01, -3.0856e-01],\n",
       "                         [-5.1835e-02, -1.7605e-01, -3.0941e-01]],\n",
       "               \n",
       "                        [[-1.5246e-01, -1.2831e-01, -4.4812e-02],\n",
       "                         [-1.6314e-01, -1.2917e-01, -7.5320e-02],\n",
       "                         [-1.5122e-01, -1.1717e-01, -1.5710e-01]],\n",
       "               \n",
       "                        [[-5.3818e-02, -5.1342e-02, -1.5757e-01],\n",
       "                         [-7.5635e-02, -9.9171e-02, -2.1828e-01],\n",
       "                         [-1.0729e-03, -1.0431e-01, -2.2602e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.4321e-02, -2.2552e-02, -8.8848e-02],\n",
       "                         [-2.5956e-02, -3.5327e-02, -1.3773e-01],\n",
       "                         [ 8.9133e-03,  3.0740e-03, -1.0050e-01]],\n",
       "               \n",
       "                        [[ 6.3828e-02,  1.4987e-05, -3.2330e-02],\n",
       "                         [ 1.6951e-03, -2.7668e-02, -1.7322e-01],\n",
       "                         [-6.9142e-03, -5.0586e-02, -1.9127e-01]],\n",
       "               \n",
       "                        [[-3.0931e-02, -6.4165e-02, -1.4262e-01],\n",
       "                         [-5.3583e-02, -1.3207e-01, -2.6642e-01],\n",
       "                         [-4.2838e-02, -6.4026e-02, -2.8391e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 9.9623e-02, -6.3867e-02,  2.5452e-02],\n",
       "                         [ 1.1098e-01, -3.8810e-02,  1.3309e-01],\n",
       "                         [ 1.2145e-01, -2.1395e-02,  1.1927e-01]],\n",
       "               \n",
       "                        [[ 2.8668e-01,  1.7305e-02,  8.8408e-02],\n",
       "                         [ 2.5384e-01, -1.9117e-01, -2.0238e-01],\n",
       "                         [ 2.4004e-01, -2.0833e-01, -1.6091e-01]],\n",
       "               \n",
       "                        [[-2.6671e-02, -1.1001e-01,  3.0393e-02],\n",
       "                         [ 4.0007e-04, -1.1037e-01,  4.0861e-03],\n",
       "                         [-1.8974e-02, -1.4899e-01,  2.3437e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.5335e-02, -6.9298e-02, -4.2384e-03],\n",
       "                         [-3.2748e-02, -7.9837e-02, -3.2012e-02],\n",
       "                         [-9.6534e-02, -1.6497e-01, -8.8456e-02]],\n",
       "               \n",
       "                        [[-1.4191e-02, -5.7730e-02,  7.7663e-02],\n",
       "                         [-1.6944e-02, -1.2329e-01,  6.6457e-02],\n",
       "                         [-3.9793e-02, -5.5077e-02,  1.8633e-02]],\n",
       "               \n",
       "                        [[-4.3596e-02, -1.3971e-01,  1.0534e-02],\n",
       "                         [-4.4777e-02, -1.0370e-01,  2.5256e-02],\n",
       "                         [-2.9126e-02, -1.2420e-01,  1.6884e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2084e-01, -6.4760e-02,  1.3030e-01],\n",
       "                         [-1.3044e-01, -2.5075e-02,  1.6151e-02],\n",
       "                         [-8.7644e-02,  1.5531e-03,  1.7084e-02]],\n",
       "               \n",
       "                        [[ 1.0630e-01,  6.8825e-02,  1.0841e-01],\n",
       "                         [ 6.3294e-02,  5.6313e-02,  9.1738e-02],\n",
       "                         [-8.5978e-02,  4.0142e-03,  4.2442e-02]],\n",
       "               \n",
       "                        [[-7.9506e-02, -5.3952e-01, -4.3850e-02],\n",
       "                         [-1.0070e-01, -6.0278e-01, -6.0825e-02],\n",
       "                         [-4.1294e-02, -4.5038e-01, -5.5793e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.0779e-02, -9.0226e-03,  3.3375e-03],\n",
       "                         [ 8.1960e-04, -7.6463e-02, -3.6247e-02],\n",
       "                         [ 1.9942e-02, -4.3963e-02, -3.7640e-02]],\n",
       "               \n",
       "                        [[-4.5117e-02, -9.3657e-02, -1.9836e-03],\n",
       "                         [-5.8529e-02, -8.0018e-02, -3.1515e-02],\n",
       "                         [-1.2475e-02, -7.1371e-02, -4.3010e-03]],\n",
       "               \n",
       "                        [[-5.3049e-02, -1.5731e-01, -2.5275e-02],\n",
       "                         [-5.1301e-02, -2.0356e-01, -2.3456e-02],\n",
       "                         [-2.6011e-02, -1.6314e-01, -5.0286e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.3632e-03, -1.2925e-02,  6.8488e-04],\n",
       "                         [-9.8775e-02, -8.1714e-02, -3.4547e-02],\n",
       "                         [-1.1710e-02, -7.6958e-02, -6.0914e-02]],\n",
       "               \n",
       "                        [[-1.0509e-01, -1.0036e-01, -3.5899e-02],\n",
       "                         [-1.3978e-01, -1.4804e-01, -3.0534e-02],\n",
       "                         [-1.9116e-01, -1.2482e-01, -7.7175e-02]],\n",
       "               \n",
       "                        [[ 1.0296e-02, -6.9565e-02,  7.9738e-02],\n",
       "                         [ 2.8699e-02, -1.6072e-01,  6.3567e-02],\n",
       "                         [ 1.6107e-02, -1.5727e-01,  4.8203e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.1035e-02, -1.2945e-01,  1.2868e-02],\n",
       "                         [-1.6226e-01, -2.2084e-01, -4.9709e-03],\n",
       "                         [-2.6686e-02, -8.8472e-02,  4.4570e-02]],\n",
       "               \n",
       "                        [[-5.2616e-03, -5.7111e-02,  5.4005e-02],\n",
       "                         [-2.7419e-02, -9.5018e-02,  4.9039e-02],\n",
       "                         [-2.7858e-04, -2.4506e-02,  3.1993e-02]],\n",
       "               \n",
       "                        [[-3.8276e-02, -7.3607e-02, -9.0714e-03],\n",
       "                         [-5.5761e-02, -1.2196e-01,  4.7025e-03],\n",
       "                         [-1.7847e-02, -1.2619e-01,  4.5440e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.4819e-02, -1.4828e-01, -1.0668e-01],\n",
       "                         [ 4.5886e-02,  2.8900e-02,  4.0922e-02],\n",
       "                         [ 1.8913e-03,  2.3505e-02,  1.6824e-01]],\n",
       "               \n",
       "                        [[ 1.5831e-01,  1.1025e-01,  3.2725e-01],\n",
       "                         [ 3.3227e-01,  2.0414e-01,  3.9934e-01],\n",
       "                         [ 3.2118e-01,  2.7469e-01,  3.1816e-01]],\n",
       "               \n",
       "                        [[ 4.3839e-03, -1.8127e-01,  3.0586e-02],\n",
       "                         [-5.1334e-02, -2.2614e-01,  6.0986e-02],\n",
       "                         [-9.7718e-03, -2.2800e-01,  7.6102e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.9273e-02, -9.4798e-02, -1.8765e-02],\n",
       "                         [ 2.7452e-02, -1.2884e-01, -6.5547e-03],\n",
       "                         [-1.1060e-01, -2.2181e-01, -8.4998e-02]],\n",
       "               \n",
       "                        [[-1.2539e-02, -9.0758e-02,  3.2262e-02],\n",
       "                         [-2.7983e-02, -1.2655e-01,  1.7510e-03],\n",
       "                         [-7.8804e-03, -1.0630e-01,  3.6500e-02]],\n",
       "               \n",
       "                        [[-4.5780e-02, -1.7082e-01,  3.4723e-02],\n",
       "                         [-4.5897e-02, -2.2459e-01, -1.2138e-02],\n",
       "                         [-5.9276e-02, -1.9904e-01, -7.6359e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 6.4527e-02,  2.3626e-03,  3.5323e-02],\n",
       "                         [ 5.2964e-02,  8.6002e-03,  9.5076e-02],\n",
       "                         [ 2.5534e-01,  2.2776e-01,  6.3691e-01]],\n",
       "               \n",
       "                        [[-3.1473e-01, -1.5584e-01, -2.4066e-01],\n",
       "                         [-5.6614e-01, -2.5919e-01, -4.8721e-01],\n",
       "                         [-4.7625e-01, -4.3592e-01, -5.6699e-01]],\n",
       "               \n",
       "                        [[-8.0138e-02, -2.7227e-01, -3.8287e-03],\n",
       "                         [-8.9857e-02, -3.3922e-01, -7.3446e-03],\n",
       "                         [-8.2277e-02, -2.2914e-01, -2.5482e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.4436e-02, -1.6535e-01, -6.6169e-02],\n",
       "                         [-1.0076e-01, -1.9541e-01, -2.1543e-02],\n",
       "                         [-4.8573e-02, -2.3831e-01, -7.6474e-02]],\n",
       "               \n",
       "                        [[-6.5030e-02, -1.0340e-01, -1.7654e-02],\n",
       "                         [-4.2388e-02, -9.1843e-02, -4.4946e-02],\n",
       "                         [-5.0771e-02, -9.4325e-02, -3.5689e-02]],\n",
       "               \n",
       "                        [[-1.0607e-01, -1.3761e-01, -1.6891e-01],\n",
       "                         [-7.1688e-02, -1.0667e-01, -9.9844e-02],\n",
       "                         [-6.6565e-02, -1.0376e-01, -2.3241e-02]]]], device='cuda:0')),\n",
       "              ('conv_block4.bn1.weight',\n",
       "               tensor([1.0171, 0.5798, 0.5005, 0.9467, 0.4131, 0.9769, 0.4462, 1.0130, 0.9361,\n",
       "                       1.1435, 1.0755, 0.8172, 1.2160, 1.1708, 0.8326, 1.0605, 1.3565, 1.1408,\n",
       "                       0.9933, 1.1301, 1.0148, 1.1272, 0.9770, 0.5058, 0.8135, 0.6770, 1.1596,\n",
       "                       1.0459, 1.0975, 1.0943, 1.0097, 0.8133, 1.1153, 0.8899, 1.0428, 1.2536,\n",
       "                       0.9832, 0.6203, 0.9139, 0.8731, 0.6918, 1.1260, 0.2733, 1.0130, 1.0926,\n",
       "                       1.0720, 1.1631, 1.1839, 0.5973, 1.1405, 1.1763, 0.9800, 1.0225, 1.0436,\n",
       "                       0.8502, 1.1530, 0.9835, 1.3239, 0.6362, 0.9547, 0.8648, 0.7036, 0.9891,\n",
       "                       0.8956, 0.6684, 1.0972, 0.9076, 0.6384, 0.8603, 1.0418, 0.8226, 0.9889,\n",
       "                       0.4692, 0.4991, 0.8975, 0.8536, 1.2099, 0.9635, 1.1211, 1.0741, 1.1748,\n",
       "                       1.0328, 0.9639, 0.8464, 0.9222, 0.8646, 0.9812, 1.0259, 0.9026, 1.0985,\n",
       "                       1.3200, 1.3520, 0.8091, 0.8493, 1.0194, 0.5287, 0.9658, 0.9977, 0.9788,\n",
       "                       1.3655, 0.4898, 0.7785, 0.9938, 0.4714, 0.3356, 0.9735, 0.8762, 0.8690,\n",
       "                       1.3053, 0.7439, 0.7643, 0.6878, 1.0019, 1.0641, 1.0696, 1.1539, 1.1049,\n",
       "                       0.8718, 1.3012, 0.9538, 0.9531, 0.5643, 1.0746, 0.9723, 0.8656, 1.3475,\n",
       "                       0.9380, 0.8953, 1.3727, 0.4535, 1.1457, 0.6542, 1.0409, 1.0981, 0.9023,\n",
       "                       1.1144, 1.0815, 1.2134, 0.8978, 0.9925, 0.8624, 1.0421, 1.3380, 1.1504,\n",
       "                       0.9870, 0.4670, 1.0330, 1.1302, 1.1419, 1.2744, 1.2785, 1.2513, 1.0941,\n",
       "                       1.1802, 1.2290, 1.3752, 0.9396, 0.9662, 0.9707, 1.0778, 0.3860, 0.9183,\n",
       "                       1.1586, 0.8619, 0.6188, 1.1147, 1.3675, 1.0019, 1.1476, 1.0775, 1.0792,\n",
       "                       1.1930, 0.9706, 0.9071, 0.9174, 0.9868, 0.7037, 0.7321, 0.8768, 1.0496,\n",
       "                       0.9915, 1.0660, 0.8966, 0.9964, 0.8852, 1.2159, 1.1580, 0.7111, 0.4730,\n",
       "                       1.0353, 1.0192, 0.8928, 1.2706, 1.4263, 0.9980, 0.3532, 0.4918, 0.9829,\n",
       "                       0.7474, 1.0839, 0.5446, 1.0956, 1.0380, 1.0943, 1.0517, 0.7094, 1.0557,\n",
       "                       0.6625, 1.1248, 1.0023, 1.5281, 1.3572, 1.0759, 0.7746, 1.2011, 1.1546,\n",
       "                       0.5964, 0.9852, 0.8495, 0.9046, 0.9232, 1.2807, 0.5028, 0.9053, 1.1093,\n",
       "                       1.2315, 1.0267, 1.0194, 1.2623, 0.9689, 1.0482, 1.0786, 0.8586, 0.4864,\n",
       "                       1.2161, 1.0685, 1.0953, 0.9853, 0.8778, 1.0397, 1.2730, 0.9377, 1.2230,\n",
       "                       0.9753, 1.0981, 0.5209, 0.9376, 0.6086, 0.4151, 0.7702, 0.9797, 1.2388,\n",
       "                       1.0349, 0.9509, 0.8632, 1.2876, 1.6126, 1.1258, 0.4149, 1.0089, 1.0519,\n",
       "                       0.8221, 1.2245, 1.0256, 1.0461, 0.9651, 0.8645, 1.0192, 1.0774, 1.0158,\n",
       "                       1.1035, 0.9729, 1.2657, 1.1162, 1.0492, 0.8497, 1.1300, 1.0705, 0.9149,\n",
       "                       0.5904, 0.9442, 1.1462, 0.9009, 1.3760, 0.4095, 1.0837, 1.2117, 0.5813,\n",
       "                       1.1220, 1.3137, 0.5588, 1.1104, 0.7647, 0.8270, 1.7138, 1.0442, 0.9528,\n",
       "                       1.1511, 0.8160, 1.0942, 1.2062, 1.0723, 0.9839, 1.4398, 1.0917, 1.1048,\n",
       "                       1.0294, 1.0739, 1.1939, 1.0529, 1.0129, 1.0052, 1.4338, 1.0208, 0.9004,\n",
       "                       1.1145, 0.8237, 1.2433, 0.9026, 1.0068, 1.1364, 0.9539, 0.7693, 1.0401,\n",
       "                       1.3652, 0.4287, 1.0163, 0.9942, 1.1042, 0.4577, 0.9942, 0.9551, 0.9146,\n",
       "                       1.0011, 1.1516, 0.9862, 0.7260, 1.1630, 1.0532, 0.9281, 0.9433, 0.6011,\n",
       "                       0.6257, 1.1354, 0.9504, 0.9805, 0.9760, 0.9792, 0.4477, 0.7953, 0.9629,\n",
       "                       0.8023, 1.1022, 1.1797, 0.8836, 1.0323, 0.5699, 1.0605, 1.1273, 1.0621,\n",
       "                       0.7290, 0.9571, 0.8671, 0.6478, 0.3853, 0.9439, 0.8821, 0.8617, 0.4659,\n",
       "                       1.0389, 0.3590, 1.1582, 0.9726, 1.0988, 1.0964, 0.8692, 1.2900, 0.8554,\n",
       "                       1.1174, 0.9015, 0.9937, 1.2691, 0.9923, 0.9630, 1.0504, 0.7922, 0.5388,\n",
       "                       1.0412, 1.0914, 0.9493, 1.1033, 0.9571, 0.9168, 0.9361, 1.1429, 0.4560,\n",
       "                       1.0962, 1.0570, 0.6944, 1.0913, 1.0084, 0.9310, 0.8042, 0.9676, 1.1645,\n",
       "                       1.0108, 0.9704, 0.8509, 0.8505, 0.9832, 0.9930, 1.0751, 0.9806, 1.0307,\n",
       "                       1.1843, 1.0450, 0.8979, 0.8262, 0.7724, 0.8858, 0.9827, 1.0757, 1.1863,\n",
       "                       0.9124, 0.8604, 1.0140, 1.1726, 0.8133, 0.9450, 0.7757, 0.9359, 0.8902,\n",
       "                       0.4347, 0.8054, 0.9967, 0.8918, 1.1201, 0.8330, 1.3714, 0.6347, 0.6996,\n",
       "                       0.9285, 0.9511, 1.2236, 1.0164, 0.8717, 1.0107, 1.2076, 0.9399, 1.1091,\n",
       "                       0.9706, 1.1365, 1.0346, 1.1798, 1.2603, 1.0090, 0.9313, 0.8644, 1.0968,\n",
       "                       0.7437, 1.1048, 1.1171, 0.9892, 0.9939, 1.4142, 1.0721, 1.1209, 1.0621,\n",
       "                       1.1425, 0.8798, 1.1274, 0.9831, 1.0430, 0.9428, 0.3956, 0.9816, 1.0278,\n",
       "                       0.9393, 0.9891, 1.3775, 1.0050, 0.8539, 0.9556, 1.1961, 1.1283, 1.0901,\n",
       "                       0.9547, 1.0527, 1.6421, 1.0322, 1.0283, 0.7542, 0.9550, 1.1278, 0.9013,\n",
       "                       1.0847, 1.1320, 0.8843, 1.1033, 1.0025, 1.0018, 1.0766, 0.2731, 1.0976,\n",
       "                       1.3175, 1.2517, 1.0063, 1.2144, 1.1150, 0.8921, 0.4834, 0.4870],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.bias',\n",
       "               tensor([-0.9268, -0.6266, -0.5309, -0.6357, -0.5046, -1.1536, -0.5173, -1.4939,\n",
       "                       -0.7832, -1.5075, -0.6342, -0.5730, -1.1893, -1.1652, -0.7942, -1.0887,\n",
       "                       -1.3104, -1.3070, -0.8438, -1.5253, -0.9678, -1.0071, -0.9260, -0.5962,\n",
       "                       -1.2304, -0.2258, -0.6201, -0.8741, -0.9973, -0.2882, -1.0181, -0.0473,\n",
       "                       -1.2342, -0.8188, -0.9273, -1.0032, -1.1131, -0.5810, -0.9244, -0.8191,\n",
       "                       -0.4738, -0.7664, -0.1053, -1.1785, -1.2238, -1.2519, -1.0774, -1.7462,\n",
       "                       -1.2521, -1.0098, -1.3732, -1.0013, -0.9384, -0.9089, -0.7262, -1.2270,\n",
       "                       -1.0483, -1.5191, -0.4390, -1.0361, -0.8670, -0.8597, -1.4813, -0.6777,\n",
       "                       -0.4823, -1.1131, -0.8683, -0.1681, -0.6160, -1.1000, -0.6691, -0.6610,\n",
       "                        0.1074, -0.4299, -0.8592, -0.8151, -1.7040, -1.0895, -0.9872, -1.5288,\n",
       "                       -1.1496, -0.6807, -0.8016, -0.7891, -0.9479, -0.6210, -1.0759, -1.1950,\n",
       "                       -0.9956, -1.2665, -1.5158, -1.7583, -0.7382, -0.5999, -0.9451, -0.5500,\n",
       "                       -1.0278, -0.6882, -1.0760, -1.4877, -0.7106, -0.9699, -1.1468, -0.5725,\n",
       "                       -0.2269, -1.4250, -0.7481, -0.9016, -1.3545, -0.4090, -0.5920, -0.7844,\n",
       "                       -1.2422, -1.0947, -1.3283, -1.2184, -1.1426, -0.8193, -1.3204, -0.8605,\n",
       "                       -0.7378, -0.5170, -1.3469, -1.0916, -0.9371, -1.4747, -1.0785, -1.3800,\n",
       "                       -1.3396, -0.4237, -1.3274, -0.8327, -0.8605, -1.2755, -0.9883, -1.0643,\n",
       "                       -1.1332, -1.2407, -1.0683, -0.9353, -0.8443, -1.0549, -1.1899, -1.0002,\n",
       "                       -1.4368, -0.4605, -0.8931, -1.3795, -1.1537, -1.2295, -1.5573, -1.3294,\n",
       "                       -1.2111, -1.4382, -1.0037, -1.4445, -0.7545, -1.1937, -1.0555, -0.8604,\n",
       "                       -0.3483, -0.8547, -1.4832, -0.9992, -0.6245, -1.1271, -1.8393, -0.8570,\n",
       "                       -1.1873, -0.9002, -1.1650, -1.4616, -1.0966, -1.0338, -0.8798, -1.0539,\n",
       "                       -0.5295, -0.5991, -0.5281, -1.1401, -1.3800, -1.1607, -1.0025, -0.7102,\n",
       "                       -0.9779, -1.1512, -1.1975, -0.7246, -0.4748, -0.9941, -0.7571, -0.8653,\n",
       "                       -1.4647, -1.8294, -0.6385, -0.2421, -0.4240, -0.7561, -0.7323, -1.0429,\n",
       "                       -0.5567, -0.7589, -0.8982, -1.1422, -1.3670, -0.8966, -0.7570, -0.8501,\n",
       "                       -1.4752, -1.3566, -1.5417, -1.3120, -1.4789, -0.8098, -1.1903, -1.1919,\n",
       "                       -0.5641, -1.0068, -0.6368, -1.1082, -0.6602, -1.2209, -0.5706, -0.8450,\n",
       "                       -1.4457, -1.1181, -0.5517, -1.0157, -1.0188, -1.3320, -1.1227, -0.8480,\n",
       "                       -0.9637, -0.3996, -1.1952, -1.4615, -1.0471, -0.8518, -1.3566, -1.1436,\n",
       "                       -1.2017, -0.7486, -1.5245, -0.9609, -1.2642, -0.4812, -1.1266, -0.8732,\n",
       "                       -0.4258, -0.7096, -0.8881, -1.1568, -1.1495, -1.0584, -0.5065, -2.0450,\n",
       "                       -1.8439, -1.0001, -0.4478, -1.3064, -1.2587, -0.7340, -0.7342, -0.9460,\n",
       "                       -1.0269, -0.9412, -0.7271, -0.9116, -0.7955, -1.3599, -1.3335, -1.3596,\n",
       "                       -2.0832, -1.4160, -0.9864, -0.7417, -0.7941, -1.4409, -0.8184, -0.5528,\n",
       "                       -0.7167, -1.1789, -0.8158, -1.4325, -0.2628, -1.1581, -1.9050, -0.4080,\n",
       "                       -1.2944, -1.1235, -0.6202, -1.1652, -0.9671, -1.1774, -1.8213, -0.8847,\n",
       "                       -0.6611, -1.5906, -0.7409, -1.0386, -1.0712, -1.1633, -1.0001, -1.3512,\n",
       "                       -0.9485, -1.2225, -1.0768, -1.1959, -1.0779, -1.0752, -1.1522, -0.9081,\n",
       "                       -1.0947, -0.8541, -0.9721, -1.3169, -0.8332, -1.1959, -0.8614, -1.2096,\n",
       "                       -1.2910, -1.3517, -0.7324, -0.7874, -1.2204, -0.3987, -1.2808, -1.0477,\n",
       "                       -1.0734, -0.4106, -0.8290, -0.8418, -1.1694, -1.0074, -1.2381, -1.2645,\n",
       "                       -0.4686, -0.9527, -0.7772, -0.9946, -0.5623, -0.7630, -0.8910, -1.0892,\n",
       "                       -0.8300, -0.9807, -0.9775, -1.3635, -0.4377, -0.6563, -1.3178, -0.7624,\n",
       "                       -1.1922, -1.3888, -1.3011, -0.8241, -0.6315, -1.0948, -1.0740, -1.1862,\n",
       "                       -1.2401, -0.8922, -0.8188, -0.4529, -0.3196, -0.9116, -0.5977, -0.7753,\n",
       "                       -0.3463, -0.9359, -0.2351, -1.1351, -0.8505, -1.2622, -0.8808, -0.8275,\n",
       "                       -1.4604, -0.6374, -0.9875, -0.5543, -0.9385, -1.4324, -1.0252, -0.7666,\n",
       "                       -1.3167, -0.6675, -0.3785, -0.6188, -1.1109, -0.7665, -0.6459, -1.3750,\n",
       "                       -0.9565, -0.8162, -1.1617, -0.2942, -1.1032, -0.9313, -0.6704, -0.9382,\n",
       "                       -1.4996, -0.6677, -0.9241, -0.9116, -1.5874, -1.2366, -0.9990, -0.7313,\n",
       "                       -0.6550, -0.9268, -0.9094, -1.2075, -0.7507, -1.5805, -1.3963, -1.1001,\n",
       "                       -0.8197, -0.6291, -0.5572, -0.6652, -1.0816, -1.0449, -1.2613, -0.6382,\n",
       "                       -0.4380, -1.4386, -1.2137, -0.5551, -1.0229, -0.9086, -0.8036, -0.8823,\n",
       "                       -0.4433, -0.5666, -1.3386, -0.8249, -1.0241, -0.9359, -1.3669, -0.1792,\n",
       "                       -0.4910, -0.6613, -0.6006, -1.2904, -1.2362, -0.9800, -0.7748, -0.8731,\n",
       "                       -0.9160, -1.3455, -0.6145, -1.3676, -0.9559, -0.8511, -1.0169, -1.0877,\n",
       "                       -0.6715, -0.8468, -0.9053, -0.6382, -0.7508, -1.1323, -1.2330, -1.0002,\n",
       "                       -1.0657, -1.0172, -1.3319, -1.0393, -1.2256, -0.7244, -1.3001, -1.1020,\n",
       "                       -1.2895, -0.6108, -0.4768, -1.4196, -1.3897, -0.7835, -1.0923, -1.2570,\n",
       "                       -0.9177, -0.8924, -0.9494, -0.8150, -1.1034, -1.1010, -0.7710, -1.2923,\n",
       "                       -1.7607, -0.8246, -1.0299, -0.7357, -0.8449, -1.3700, -0.9031, -1.1970,\n",
       "                       -1.0119, -0.7387, -1.1051, -1.0061, -1.1059, -0.8715, -0.2503, -0.7411,\n",
       "                       -1.5400, -1.4532, -0.8578, -1.6902, -1.4873, -0.8968, -0.5279, -0.5539],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.running_mean',\n",
       "               tensor([-10.9466,  -4.7064,   0.4896, -13.0394,   1.0596,  -5.1966,   2.5946,\n",
       "                        -6.1204,  -4.9037,  -9.0592,  -4.7538,  -7.4809, -10.2353,  -4.2202,\n",
       "                       -11.6675,  -6.0336,  -7.8942,  -5.2304,  -5.9133,  -4.6640,  -6.5091,\n",
       "                        -8.8374,  -5.8615,  -0.1198,  -3.0118,  -5.2285,   3.0720,  -9.0669,\n",
       "                        -8.2644,  -2.2407, -16.7493,  -3.2580,  -6.2603,  -3.2431,  -8.6461,\n",
       "                        -5.1161,  -6.8665,   1.6716,  -2.8061,  -2.2973,  -6.4704,   0.0351,\n",
       "                         1.7752, -12.2334,  -7.8868,  -4.4822,  -6.7287,  -1.5001,  -1.8367,\n",
       "                        -9.2483,  -5.0554,  -7.2483,  -5.0116,  -2.3397,  -5.7115,  -7.1529,\n",
       "                        -4.5376,  -8.3607,  -3.2629,  -4.0760,  -8.0348,  -4.2006,  -6.1257,\n",
       "                        -3.2869,  -1.5678,  -5.3736,  -4.9567,  -0.0239,  -8.7057,  -6.1706,\n",
       "                        -9.4158,  -1.2394,  -0.2976,   2.0511,  -2.4322,  -7.2357,  -5.7281,\n",
       "                        -3.8909,  -6.6181,  -6.5762,  -6.2335,  -7.7848,  -3.6213,  -4.4694,\n",
       "                        -6.5564,  -1.7735,  -6.3409,  -3.5482,  -4.7265,  -9.7434,  -5.2787,\n",
       "                        -4.4089,  -8.5867,  -8.9784,  -8.3622,  -1.1242,  -1.6125,  -6.1353,\n",
       "                        -1.8334,  -6.4470,   1.9517,  -4.0501,  -7.9616,  -0.0614,   1.8526,\n",
       "                        -8.1184,  -7.6924,  -3.5090, -13.9613,  -1.8541,  -6.5741,  -1.1032,\n",
       "                        -7.2868,  -5.5170, -13.6198,  -8.7831,  -6.9043,  -9.8543,  -8.1938,\n",
       "                       -10.9025,  -1.5706,   0.2536,  -6.2698,  -4.7969,  -2.5400,  -6.6330,\n",
       "                        -8.2245,  -8.3690,  -3.3294,   1.4847,  -5.6580,  -0.6512,  -2.6138,\n",
       "                        -5.4812,  -8.3086,  -6.6517,  -0.9511,  -6.5308,  -0.4880, -10.0147,\n",
       "                       -10.0530,  -8.8695,  -8.9923,  -9.2739,  -5.5759,   1.4889,  -5.5971,\n",
       "                        -6.5623,  -6.1954,  -6.9607,  -4.3671, -10.0267,  -6.3242,  -1.5743,\n",
       "                        -5.8862,  -8.4250,  -9.6883,  -0.3161,  -6.0573,  -0.9220,   2.8667,\n",
       "                        -3.4738,  -5.6987,  -4.2769,  -1.2995,  -6.1807, -10.4538, -10.6439,\n",
       "                        -6.4368,  -7.6672,  -6.1779,  -6.6622, -12.6275,  -5.0543, -13.3042,\n",
       "                        -9.2222,  -2.8990,  -1.0521, -10.5863, -12.6526,  -5.7583,  -6.1315,\n",
       "                        -4.1107,  -7.5637,  -8.3993,  -3.6659,  -1.5571,  -5.7016,   0.4822,\n",
       "                        -4.1579,  -4.2678,  -3.1378,  -7.7058,  -5.8783,  -6.5717,   1.4404,\n",
       "                         0.1798,  -6.9300,  -2.0510,  -6.2335,   0.7833,  -5.9191,  -9.1841,\n",
       "                        -3.7911,  -7.2584,  -3.9278,  -5.4451,  -1.0859,  -8.4004,  -4.5896,\n",
       "                        -3.7839,  -2.1272,  -0.8305,  -3.9474,  -5.0292,  -4.3324,   1.6887,\n",
       "                        -5.2468,  -9.3235, -12.2824,  -5.9639,  -6.0610,   1.1145,  -4.4179,\n",
       "                        -6.1781,  -7.4969,  -6.3649,  -8.0785,  -5.8291,  -7.1095,   0.0293,\n",
       "                        -7.3850,  -5.0077,  -4.7580,  -2.4646,  -4.9892,  -6.5832,  -8.1314,\n",
       "                        -3.3271,  -6.9148,  -5.1012,  -6.6263,  -6.5491,  -5.4777,  -4.7112,\n",
       "                        -1.7681,  -2.9845,  -0.6280,   0.6161,  -4.8205,  -5.8634,  -3.7613,\n",
       "                       -12.9779,  -4.8706,  -3.6795,  -3.5789,  -7.1662,  -6.3291,   2.0748,\n",
       "                        -6.3364,  -5.2135,  -5.4410,  -3.6490,  -1.8804,  -6.5819,  -6.4984,\n",
       "                       -11.3954,  -9.8010, -11.5818,  -5.1824,  -4.9084,  -6.3417,  -7.3625,\n",
       "                       -11.8305, -11.8492,  -5.2052,  -3.5223,  -1.8082,  -4.9645,  -1.7844,\n",
       "                        -6.9489,  -7.0825,  -2.0701,  -4.3015,   0.9403,  -7.6335,  -8.7052,\n",
       "                        -0.3232,  -8.0548,  -6.3594,   0.0384, -10.3239,  -5.7635,   1.2717,\n",
       "                       -10.4732,  -6.6686,  -1.0650,  -2.5657,  -9.0322,  -6.0299,  -7.6969,\n",
       "                        -8.4339,  -5.6820,  -6.2278,  -6.9537,  -7.1906,  -9.3338,  -3.2026,\n",
       "                        -0.8080,  -8.3156,  -3.4238,  -6.3102,  -6.0365,  -7.9017,  -6.0254,\n",
       "                        -3.1737,  -3.8924,  -1.3887,  -7.4180,  -8.3821,  -6.3889,   0.2771,\n",
       "                       -13.0124,  -7.0043,  -6.5420,   0.5211, -10.5753,  -4.8199,  -8.8597,\n",
       "                         0.7271,  -6.9438,  -5.8706,  -6.6012, -11.7251,  -9.9602,  -3.5897,\n",
       "                        -3.7250,   1.3409,  -6.2583,  -8.7168,  -4.7366,   0.7047,   0.6778,\n",
       "                        -3.3599,  -5.2760,  -7.6540,  -7.4514,  -5.3712,   0.7601,  -9.1521,\n",
       "                        -4.2634,  -8.8234,  -7.7530,  -2.1752,  -6.7177,  -7.7468,   1.3792,\n",
       "                        -7.6447,  -4.8029, -10.1590,   0.7072,  -6.5925,  -4.7821,  -6.2494,\n",
       "                         2.2727,  -4.8053,  -7.1708,  -1.1976,  -0.4371,  -7.4698,   2.2801,\n",
       "                       -10.9002,  -7.5096,  -6.9487,  -6.1443,  -0.9438, -11.0681,  -5.3732,\n",
       "                        -6.2433,  -3.4355,  -7.4783,  -2.8342,  -2.9182,  -2.5896,  -2.3832,\n",
       "                        -3.8353,   1.1935,  -5.2662,  -8.6400,  -2.4046,  -4.8689,  -6.6092,\n",
       "                        -0.7686,  -5.4240,  -6.4915,  -0.1485,  -7.4101,  -5.3624,  -3.9568,\n",
       "                        -8.2369,  -6.2680,  -7.4459,  -1.5998, -12.1062,  -6.4252,  -4.5093,\n",
       "                        -9.1467,  -1.7616,  -4.1337,  -7.5233, -11.9482,  -9.0477,  -0.1674,\n",
       "                        -6.2516,  -5.3855, -13.4576,  -7.5187,  -8.5937,  -8.9846,  -7.8837,\n",
       "                        -7.2620,  -8.1858, -10.8179,   0.6603,  -8.9839,  -6.2542, -10.4111,\n",
       "                        -7.0609,  -5.5050,  -0.5491,  -4.2341,  -4.2832,   1.9065,  -6.6364,\n",
       "                        -9.1535,  -7.1616,  -5.9491,  -4.5903,  -6.4505,  -3.0236,  -6.1423,\n",
       "                        -2.2690,  -3.9202,  -6.1200, -10.3187, -10.1729,  -6.7391,  -7.7427,\n",
       "                        -8.7977, -11.9383,  -5.3453,  -5.8036,  -6.7242,   0.4427,  -9.2209,\n",
       "                        -3.7368,  -4.7518,  -9.7832,  -4.4224,   1.3990,  -2.4374,  -4.9322,\n",
       "                        -3.9685,  -8.2084,  -5.6697,  -4.8616,  -7.2400,  -9.3516,  -6.3486,\n",
       "                        -4.4132,  -8.5907,  -7.9852,  -3.4281,  -7.5983,   0.6316,  -4.0236,\n",
       "                        -4.1680,  -6.6564,  -7.3984,  -5.0515,  -9.8773,  -5.5165,  -3.4083,\n",
       "                        -4.0908,  -5.4502,  -7.5116,  -4.7940,  -6.8727,  -6.4855,  -3.8047,\n",
       "                        -4.6048,   2.2831,  -0.6845,  -9.2537,   2.3546,  -7.3868,  -6.5038,\n",
       "                        -8.1104,  -4.6953,  -6.2870,  -5.7926,  -7.7083,   1.6947,  -6.8570,\n",
       "                        -4.1531,  -4.1234,  -9.3761,  -7.1345,  -5.3935,  -2.3333,   1.9098,\n",
       "                         1.1853], device='cuda:0')),\n",
       "              ('conv_block4.bn1.running_var',\n",
       "               tensor([30.5615, 19.5194,  6.8431, 33.2307,  7.7484, 19.5720,  5.7041, 16.7709,\n",
       "                       20.6506, 32.5822, 12.8072, 25.8494, 28.5697,  9.8946, 38.2908, 12.4467,\n",
       "                       22.7973, 15.6550, 30.3211, 15.4183, 13.8769, 20.1674, 13.4068,  5.2064,\n",
       "                        9.3205, 19.1652, 13.3040, 28.8858, 23.1700, 17.6359, 36.8522, 17.2134,\n",
       "                       22.6639, 14.3213, 17.0298, 16.1659, 17.5653,  5.6243,  8.1378, 23.6647,\n",
       "                       17.6713, 10.8439,  6.3442, 18.7229, 28.5044, 15.1650, 16.8111, 27.2365,\n",
       "                       13.7515, 18.3758, 15.7615, 18.0450, 18.5931, 15.1795, 30.1187, 16.0600,\n",
       "                       18.4562, 15.7618,  6.0597,  9.8101, 25.0701, 10.5290, 20.8149,  8.2874,\n",
       "                       10.5557, 36.5706, 20.3083, 10.9105, 26.9362, 24.1466, 27.5407,  7.9009,\n",
       "                       10.2477,  7.5243,  7.9346, 31.0490, 16.5714, 16.9582, 15.1790, 15.1728,\n",
       "                       11.0975, 17.7968,  9.3774, 17.2617, 18.0170, 11.2026, 10.0479, 21.4738,\n",
       "                       12.8184, 27.9929, 34.9499,  8.7972, 20.2416, 38.6349, 35.8775, 26.6058,\n",
       "                        8.6860, 16.5672,  8.6107,  9.6205,  4.9644, 12.9083, 37.8021,  5.3654,\n",
       "                        4.3570, 33.3336, 28.2035,  9.7090, 34.4627, 10.1998, 32.1513,  6.2575,\n",
       "                       17.9305, 12.3358, 35.8649, 17.6484, 13.4068, 34.7466, 20.6096, 24.9320,\n",
       "                       12.1647,  5.1258, 15.6527, 36.4144, 13.6576, 15.8207, 12.5088, 21.6173,\n",
       "                       13.0574,  5.9408, 17.3958,  8.3152,  6.9040, 11.4219, 22.0784, 15.1430,\n",
       "                       15.8226, 26.2072, 13.5272, 31.2710, 25.6707, 19.4369, 19.3787, 27.3696,\n",
       "                       16.0319,  5.6787, 22.4620, 22.5795, 10.0631, 19.1722, 10.5147, 28.1664,\n",
       "                       12.4213, 25.4380, 12.6300, 23.6269, 41.7899, 11.3836, 18.0569,  8.7249,\n",
       "                        8.8377,  7.6490, 19.9988, 36.8825,  8.3112, 10.9120, 29.6565, 20.1334,\n",
       "                       13.5106, 28.7123, 16.1448, 27.9076, 31.5709, 19.4292, 30.4554, 25.3627,\n",
       "                       10.2696, 13.9052, 40.8040, 32.9910, 15.3921, 17.6103, 13.1719, 29.6313,\n",
       "                       18.9846, 22.1142, 12.7236, 18.7990,  5.8783, 13.0427, 12.2896,  5.8145,\n",
       "                       23.3267, 19.1351, 14.7191,  8.4226,  4.0103, 14.8062, 13.1337, 12.5089,\n",
       "                        5.3677, 21.5225, 24.8644, 17.3675, 13.8637, 14.5169, 15.1201,  6.6010,\n",
       "                       18.9283, 18.7039, 15.5907, 11.7995, 15.9959,  7.8538, 13.7008, 10.5229,\n",
       "                        4.6169, 13.7895, 36.4701, 28.8091, 16.2106, 11.9121,  4.6951, 12.1054,\n",
       "                       11.0117, 34.8793, 11.1683, 17.6856, 20.5549, 19.9955,  8.9615, 20.1625,\n",
       "                        9.6848, 19.9802, 14.8742, 17.6910, 19.3254, 24.4685, 21.4280, 29.3899,\n",
       "                       15.4179, 10.9351, 24.2829,  9.6252, 12.0946,  5.1307, 13.8964,  7.6012,\n",
       "                        6.3450, 14.6780, 14.1869, 24.8011, 26.2712, 22.6321, 14.2291, 18.8901,\n",
       "                       17.4181, 16.2870,  5.9781, 14.9376, 11.4820, 22.6166, 19.5444, 14.1481,\n",
       "                       14.4549, 16.9543, 19.7434, 27.3365, 32.2359, 20.6217, 26.1336, 24.1979,\n",
       "                       10.0762, 37.4724, 41.0546, 13.7372, 14.8969, 14.4313, 13.2454,  5.9549,\n",
       "                       14.9837, 19.6615, 10.9641, 12.4789,  4.1697, 20.6397, 20.3398,  4.9947,\n",
       "                       18.0992, 15.6661,  6.3609, 21.8676, 10.3437,  7.0835, 31.1422, 18.8504,\n",
       "                       12.8874, 12.5800, 25.5613, 21.8090, 15.6999, 21.7496, 22.0028, 15.8032,\n",
       "                       14.4817, 13.5646, 36.0756, 19.3523, 14.9007, 20.0335,  8.7787, 20.0837,\n",
       "                       17.5363, 12.9350, 13.9228, 12.1984,  7.4850, 18.1529, 15.2906, 15.3669,\n",
       "                       15.1041, 10.5410, 34.7928, 16.7722, 37.1760,  5.0407, 41.1197, 15.3174,\n",
       "                       27.7526,  2.9424, 16.8891, 20.1124, 14.4424, 34.8773, 22.7271, 20.1915,\n",
       "                        9.4582, 13.8497, 14.3264, 23.0631, 10.5649,  4.2221,  6.9832,  8.8682,\n",
       "                       18.3566, 20.9455, 20.9889, 22.7778,  7.7765, 26.7661,  7.1429, 13.2231,\n",
       "                       21.4396, 12.0353, 22.3188, 13.8094,  8.5693, 17.9074, 11.7283, 24.9059,\n",
       "                        8.4410, 11.4587, 16.0788, 37.7887,  6.3968, 15.5928, 10.7083,  7.3945,\n",
       "                        7.8200, 13.3485,  3.1345, 23.7982, 25.3734, 10.9349, 13.1362, 13.6335,\n",
       "                       24.6937, 23.0011, 18.5087, 23.0593, 15.7291, 13.5202, 15.2368, 10.1596,\n",
       "                       13.8289,  8.0219,  6.9101, 17.6363, 23.8544, 13.7632, 21.9881, 19.5875,\n",
       "                        7.7525, 13.8248, 12.9938,  5.0650, 14.1804, 29.8344, 12.4386, 20.9369,\n",
       "                        9.7813, 22.8497,  6.1871, 34.4481, 28.4984, 15.5763, 32.3126, 27.9873,\n",
       "                       28.5361, 21.9034, 29.6870, 19.2119, 15.0388, 12.2173, 16.7385, 36.1602,\n",
       "                       24.9092, 24.9316, 30.5120, 24.6249, 19.2227, 11.0939, 26.7466,  6.8273,\n",
       "                       12.3371, 20.9441, 39.4448, 14.4986, 11.7440,  6.7282, 15.6753, 23.5683,\n",
       "                        5.7090, 18.3468, 18.0073, 23.0290, 16.6334, 19.7900, 15.3393, 21.3345,\n",
       "                       11.5967, 10.6765, 24.2350, 16.5404, 35.5970, 35.3758, 10.5018, 15.7377,\n",
       "                       24.5646, 25.9001, 15.3133, 19.3552, 21.6175,  9.0542, 22.2412, 15.1988,\n",
       "                        6.7641, 17.1693, 23.0440,  5.8231,  6.8925, 10.3310, 16.7413, 15.4752,\n",
       "                       15.6510, 16.4781, 20.7925, 35.9258, 13.2031, 10.9192, 23.5391, 19.5459,\n",
       "                       17.7848, 12.5372,  3.6360, 11.2511, 10.7330, 14.0641,  9.4343, 13.3173,\n",
       "                       31.3042, 20.5273, 27.5875, 12.0333, 20.2981, 13.8537, 11.4676, 14.6925,\n",
       "                       16.4561, 14.0791, 15.1365,  6.3850,  7.7605, 27.7311, 18.7079, 18.9606,\n",
       "                       37.4239, 24.0474, 12.9374, 19.4589, 20.7373, 21.8877,  7.4155, 18.6823,\n",
       "                       22.3549, 14.1555, 25.8358, 15.2212, 22.2576,  8.2511,  6.0334,  4.6805],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block4.bn2.weight',\n",
       "               tensor([0.8692, 1.0196, 0.9362, 0.9131, 1.0375, 1.0444, 1.0132, 1.0092, 1.0608,\n",
       "                       1.0743, 1.0304, 1.1891, 1.0405, 1.0412, 1.0269, 0.9653, 1.0626, 1.0576,\n",
       "                       1.0416, 1.0394, 1.0032, 0.9530, 1.0887, 1.1196, 1.2284, 1.1845, 1.2006,\n",
       "                       1.0038, 0.9120, 0.9737, 1.0074, 1.0234, 0.9587, 0.9566, 1.1203, 1.0380,\n",
       "                       1.2199, 1.0974, 1.0536, 0.7612, 0.9293, 1.2127, 1.0957, 1.0487, 1.0060,\n",
       "                       0.9303, 1.1301, 0.9962, 0.9253, 0.9390, 1.0552, 1.0215, 0.6022, 1.1631,\n",
       "                       1.0075, 0.9166, 1.1436, 1.1242, 0.9639, 0.8867, 0.8757, 1.0242, 1.0773,\n",
       "                       1.0337, 1.0872, 0.9788, 0.9669, 0.9332, 0.7769, 1.0834, 1.1052, 1.0670,\n",
       "                       1.2093, 1.0479, 0.8535, 1.0409, 1.0113, 0.8261, 0.9043, 1.0220, 1.0291,\n",
       "                       1.0649, 0.9358, 1.2345, 0.9310, 0.9950, 1.1893, 1.0115, 0.7559, 1.0712,\n",
       "                       1.0209, 0.9954, 0.8501, 1.0186, 1.1557, 0.9994, 0.9954, 1.0819, 1.0597,\n",
       "                       1.0474, 1.0162, 0.9761, 0.9244, 0.9922, 0.9519, 1.1067, 0.9372, 0.9337,\n",
       "                       1.1715, 1.0161, 1.0217, 1.0195, 1.1220, 1.0149, 1.1270, 1.1602, 0.9379,\n",
       "                       1.0706, 1.1358, 1.0445, 0.9419, 1.0347, 0.9873, 1.0045, 0.9723, 1.0441,\n",
       "                       0.8574, 1.0103, 1.0524, 0.9981, 0.9770, 1.0063, 1.0351, 1.0704, 1.0712,\n",
       "                       1.1775, 1.0923, 1.0152, 1.0871, 1.0963, 0.9691, 1.0647, 0.6194, 1.0080,\n",
       "                       1.0311, 1.1069, 0.9379, 1.0183, 1.0397, 0.9723, 1.0926, 0.9570, 1.1201,\n",
       "                       0.6124, 1.0335, 1.0131, 1.0401, 1.0126, 0.9381, 1.0591, 1.0451, 0.6448,\n",
       "                       1.2713, 0.8568, 1.0401, 0.9968, 0.9266, 0.9932, 1.0042, 1.0146, 0.9523,\n",
       "                       1.0785, 1.0504, 1.0440, 0.8292, 1.0258, 0.8946, 1.0836, 0.9695, 1.1255,\n",
       "                       1.0539, 1.0798, 1.0433, 0.9571, 1.0015, 1.0899, 0.9283, 1.0606, 0.9519,\n",
       "                       0.7614, 0.7617, 0.9541, 1.1838, 0.9471, 1.0733, 1.1440, 1.0788, 1.0504,\n",
       "                       0.9725, 0.7654, 1.0277, 0.7071, 0.9312, 1.0306, 1.0887, 1.1121, 0.9629,\n",
       "                       1.0552, 1.0747, 1.1719, 0.8791, 1.0809, 1.0920, 0.8258, 1.0560, 0.9856,\n",
       "                       1.0623, 0.8904, 0.9770, 0.9496, 1.1909, 0.8231, 0.9825, 0.9999, 1.0781,\n",
       "                       1.0322, 0.9479, 0.6987, 1.0529, 0.9777, 1.0731, 1.0085, 1.0309, 0.9760,\n",
       "                       1.1300, 1.0308, 0.9500, 0.8970, 1.0981, 0.9828, 1.0356, 1.0897, 1.0457,\n",
       "                       1.1373, 1.0823, 1.0683, 1.1204, 1.0674, 1.1082, 1.0366, 1.0477, 0.7976,\n",
       "                       1.0946, 1.0202, 0.9869, 0.9141, 0.9358, 1.0071, 1.0090, 0.9882, 1.2007,\n",
       "                       0.9805, 0.9280, 0.9648, 1.1031, 1.0952, 1.0682, 0.9051, 0.9703, 0.9847,\n",
       "                       1.0507, 1.0302, 1.0373, 1.0126, 1.1133, 0.9373, 1.0751, 1.0259, 0.8999,\n",
       "                       0.9758, 1.0634, 0.9822, 0.9974, 1.1841, 1.0385, 0.9460, 1.0757, 1.0571,\n",
       "                       0.8684, 0.7430, 1.0869, 1.0043, 0.8735, 0.9567, 1.0572, 1.0317, 1.0294,\n",
       "                       1.0523, 1.0352, 1.0453, 1.1801, 1.1518, 1.0357, 1.0031, 1.0059, 1.0505,\n",
       "                       0.8497, 0.8277, 0.7445, 1.0762, 1.0021, 1.1202, 1.0641, 0.9924, 1.1110,\n",
       "                       1.0767, 0.9756, 1.0253, 1.1018, 0.9259, 0.9461, 1.0254, 1.0322, 0.9632,\n",
       "                       1.0843, 0.8916, 0.8301, 1.1465, 0.9954, 0.9512, 0.9322, 0.9779, 0.9065,\n",
       "                       0.9694, 0.5169, 1.1076, 1.0327, 0.9517, 1.1000, 0.9666, 0.9286, 0.9862,\n",
       "                       1.1279, 0.9118, 0.9248, 0.8618, 0.8209, 0.7729, 0.9371, 0.8842, 0.9992,\n",
       "                       1.0429, 1.0914, 0.8012, 1.0192, 1.0117, 1.0623, 1.0231, 1.0377, 1.1539,\n",
       "                       0.8518, 0.6366, 1.0854, 0.9593, 0.9821, 0.8839, 1.2614, 0.9315, 0.8245,\n",
       "                       0.9191, 1.0720, 0.9815, 0.7630, 1.0368, 1.0000, 1.0597, 0.9025, 1.0035,\n",
       "                       1.1145, 0.9382, 1.0012, 0.9382, 0.9492, 1.0129, 0.7285, 1.0805, 0.9569,\n",
       "                       1.0730, 1.0464, 0.8662, 0.5841, 0.9371, 0.7384, 0.9628, 1.1045, 0.9737,\n",
       "                       1.0557, 1.1154, 1.1908, 0.9917, 0.9906, 0.7624, 1.0398, 0.9751, 1.0418,\n",
       "                       1.0149, 0.8918, 0.9710, 0.9319, 0.9814, 0.9381, 0.9196, 1.1777, 1.0211,\n",
       "                       1.0665, 0.9604, 1.0621, 1.0200, 0.8991, 0.9888, 0.8206, 1.0428, 1.0212,\n",
       "                       1.0214, 1.0759, 1.0050, 0.9450, 0.9638, 1.0861, 1.0789, 0.9607, 0.7226,\n",
       "                       0.8935, 1.0180, 0.9566, 1.1027, 0.9531, 0.9753, 1.1532, 1.0002, 0.9920,\n",
       "                       1.0342, 0.9385, 0.8641, 0.9388, 0.9327, 1.0506, 1.0106, 1.0389, 0.9956,\n",
       "                       1.0707, 1.0160, 1.1350, 1.1605, 0.9819, 0.9502, 1.0184, 1.0517, 1.0610,\n",
       "                       1.0803, 0.9218, 0.9971, 1.0046, 1.0675, 0.9909, 1.1060, 0.7715, 1.0106,\n",
       "                       0.9804, 1.0199, 1.0249, 1.0042, 1.0969, 0.8566, 1.0517, 0.6326, 1.0388,\n",
       "                       1.0691, 1.0669, 0.9527, 1.0403, 1.0416, 0.7403, 1.1037, 1.0038, 1.0177,\n",
       "                       0.5930, 0.9599, 1.0896, 0.9358, 0.9490, 0.9979, 1.0591, 0.9622, 0.9875,\n",
       "                       0.9553, 1.0062, 1.0119, 1.1283, 1.0414, 1.0745, 1.0687, 0.8101, 1.0115,\n",
       "                       1.1221, 1.0903, 0.9864, 1.1624, 1.0129, 1.0907, 0.9775, 0.7475],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn2.bias',\n",
       "               tensor([-0.6357, -0.8527, -0.7240, -0.7183, -0.9574, -0.9813, -0.7130, -0.8558,\n",
       "                       -0.8158, -0.8945, -0.7349, -0.9749, -1.0785, -0.7781, -0.8201, -0.7343,\n",
       "                       -1.2163, -0.9349, -0.9170, -0.7448, -0.8741, -0.8969, -1.0082, -0.9573,\n",
       "                       -1.1156, -1.2825, -1.2379, -0.9295, -0.6968, -1.0297, -0.9719, -0.8778,\n",
       "                       -0.6440, -0.7050, -1.0121, -1.0072, -1.1827, -0.8992, -0.8494, -0.6630,\n",
       "                       -0.6907, -1.1151, -0.9045, -1.0034, -0.8512, -0.8988, -1.0106, -0.6670,\n",
       "                       -0.6949, -0.8435, -1.0474, -0.8233, -0.4661, -1.0223, -0.9171, -0.9080,\n",
       "                       -1.1544, -1.0028, -1.1745, -0.8494, -0.5735, -1.0519, -0.8442, -0.8575,\n",
       "                       -1.1057, -0.8953, -0.8886, -0.8457, -0.5678, -1.0093, -0.9063, -0.9730,\n",
       "                       -1.3149, -0.9343, -0.6227, -0.9176, -0.9047, -0.6808, -0.7603, -0.9709,\n",
       "                       -0.9282, -1.0250, -0.7901, -1.1732, -0.9183, -0.8938, -1.0894, -0.7654,\n",
       "                       -0.7095, -1.1964, -0.8708, -0.8142, -0.8661, -0.9949, -1.1258, -0.9737,\n",
       "                       -0.7671, -0.9461, -0.8957, -0.9559, -0.8173, -0.8774, -0.8777, -0.9807,\n",
       "                       -0.6896, -0.9080, -0.7666, -0.7901, -0.9920, -1.0560, -0.9186, -0.8876,\n",
       "                       -0.9487, -0.8476, -0.9140, -1.0839, -0.7586, -1.0032, -1.0627, -0.9870,\n",
       "                       -0.6890, -0.7998, -0.8275, -0.7153, -0.7468, -0.9308, -0.5439, -0.7082,\n",
       "                       -0.9491, -0.8077, -0.7686, -0.8005, -1.1216, -1.0302, -0.8449, -1.2532,\n",
       "                       -1.0404, -0.8978, -0.8028, -1.0356, -0.8640, -0.9739, -0.3478, -0.7908,\n",
       "                       -1.0078, -1.0894, -0.6264, -0.9284, -0.8441, -0.6705, -0.9099, -0.6895,\n",
       "                       -1.0781, -0.4041, -0.9598, -0.9002, -0.8591, -0.8593, -0.9035, -0.9717,\n",
       "                       -0.8061, -0.4209, -1.1186, -0.6594, -0.9079, -0.8793, -0.6905, -0.7890,\n",
       "                       -0.7763, -0.8181, -0.7768, -0.9247, -1.1757, -0.9052, -0.6392, -0.9119,\n",
       "                       -0.8816, -1.1514, -0.6032, -1.1121, -1.0446, -0.9701, -0.9160, -0.7903,\n",
       "                       -0.9031, -0.9186, -0.8806, -0.9007, -0.8075, -0.5293, -0.7690, -0.7966,\n",
       "                       -1.0551, -0.7402, -0.9771, -1.1216, -1.0144, -0.7270, -0.8152, -0.4969,\n",
       "                       -0.9188, -0.5080, -0.6954, -0.8943, -0.9111, -0.9846, -0.7691, -0.7996,\n",
       "                       -0.9310, -0.9318, -0.7881, -1.0120, -1.1179, -0.6427, -0.8588, -0.8852,\n",
       "                       -0.9369, -0.6432, -0.8372, -0.7708, -1.0399, -0.5446, -0.8622, -1.0342,\n",
       "                       -1.0385, -0.9053, -0.7958, -0.5640, -1.0736, -0.7351, -0.9306, -0.7655,\n",
       "                       -0.9475, -0.9423, -1.0223, -0.8780, -0.8575, -0.8953, -1.0348, -0.9474,\n",
       "                       -1.0599, -0.8597, -0.9905, -0.8517, -0.8602, -1.0753, -0.9481, -1.0397,\n",
       "                       -0.9873, -0.9807, -0.9107, -0.8368, -0.9407, -0.9491, -0.9919, -0.6827,\n",
       "                       -1.0033, -0.8495, -0.9439, -0.7659, -0.9812, -0.7008, -0.6716, -0.7872,\n",
       "                       -0.7998, -0.9925, -0.7968, -0.6551, -0.9045, -0.9280, -1.0423, -0.9507,\n",
       "                       -0.8546, -0.7400, -1.2037, -0.9359, -0.8926, -0.8114, -0.8905, -0.9073,\n",
       "                       -0.9369, -0.8521, -0.9964, -0.9729, -0.9072, -0.6744, -0.9125, -0.8992,\n",
       "                       -0.6318, -0.5347, -0.9464, -1.0394, -0.8523, -0.7701, -0.8907, -0.9499,\n",
       "                       -1.0483, -0.9705, -0.9066, -0.9237, -1.2272, -1.3275, -0.8460, -0.7763,\n",
       "                       -0.6645, -0.9437, -0.4811, -0.6286, -0.5974, -0.9572, -0.8808, -0.9409,\n",
       "                       -0.9350, -0.8788, -0.9325, -0.9302, -0.9094, -0.8218, -1.0726, -0.7214,\n",
       "                       -0.9896, -0.8111, -1.0361, -0.7955, -0.7910, -0.7099, -0.6057, -0.9668,\n",
       "                       -0.8110, -0.9454, -0.8162, -0.7066, -0.6406, -0.9381, -0.2838, -1.2096,\n",
       "                       -0.8564, -0.9551, -1.0171, -0.8412, -0.7527, -0.7537, -0.9505, -0.7497,\n",
       "                       -0.8901, -0.6481, -0.7140, -0.4668, -0.8714, -0.9210, -1.0737, -0.9736,\n",
       "                       -0.9253, -0.8462, -0.9520, -0.7971, -1.1652, -0.9690, -0.9288, -0.8844,\n",
       "                       -0.7713, -0.4085, -0.9273, -0.7709, -0.9965, -0.7296, -1.0591, -0.8909,\n",
       "                       -0.6816, -0.7582, -0.8895, -1.0022, -0.4112, -0.9052, -0.8330, -0.7699,\n",
       "                       -0.6271, -0.7419, -0.9814, -0.8401, -0.8756, -0.7851, -0.8853, -0.9722,\n",
       "                       -0.4361, -1.0040, -0.8905, -0.9258, -0.8468, -0.6977, -0.3273, -0.7692,\n",
       "                       -0.5724, -0.7710, -0.9961, -0.9429, -1.0810, -1.0256, -1.0846, -0.8732,\n",
       "                       -0.8395, -0.6623, -0.7299, -0.7672, -1.0518, -0.8442, -0.7411, -1.0576,\n",
       "                       -1.0265, -0.9971, -0.9094, -0.6428, -1.1716, -0.7394, -0.8364, -0.8228,\n",
       "                       -0.9271, -0.7503, -0.7941, -0.9165, -0.6003, -0.7904, -0.8405, -1.0136,\n",
       "                       -0.8585, -0.9383, -0.6179, -0.9837, -1.0112, -0.8642, -0.8000, -0.4619,\n",
       "                       -0.7208, -0.9207, -0.8988, -0.8371, -0.9391, -0.8320, -0.9519, -0.8000,\n",
       "                       -0.8909, -0.9169, -0.8799, -0.7483, -0.7430, -0.9219, -0.8550, -0.8171,\n",
       "                       -0.7724, -0.8056, -0.8571, -0.8749, -1.1316, -1.0753, -1.0479, -0.9392,\n",
       "                       -0.8136, -0.8701, -0.9236, -0.9709, -0.8798, -0.6883, -0.9078, -0.9579,\n",
       "                       -0.9275, -1.1071, -0.5766, -0.9774, -0.8089, -0.9832, -1.1391, -0.9514,\n",
       "                       -0.9571, -0.8613, -0.9184, -0.5020, -1.0454, -0.9861, -0.8187, -0.9366,\n",
       "                       -0.9146, -0.9690, -0.4672, -1.0258, -0.9856, -0.9362, -0.3431, -0.7617,\n",
       "                       -0.8894, -0.7865, -0.8302, -0.9095, -0.8643, -0.8991, -0.9230, -0.7429,\n",
       "                       -0.7601, -0.8827, -1.0443, -0.8199, -0.9924, -0.9508, -0.6007, -0.8046,\n",
       "                       -0.9269, -0.9579, -0.7895, -0.9726, -0.8318, -1.0327, -0.9359, -0.5078],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn2.running_mean',\n",
       "               tensor([ -7.0704,  -9.1402,  -7.7512, -11.1341,  -9.7865, -10.2807,  -9.2352,\n",
       "                       -11.5114, -11.2539, -11.2583, -10.6623, -12.7442,  -9.5280, -10.9777,\n",
       "                        -9.3166,  -9.5266, -10.3923,  -9.1503, -11.8856, -12.7874,  -9.3444,\n",
       "                        -8.8380, -11.3720, -10.5587, -14.1978,  -8.0652, -12.6958, -13.7487,\n",
       "                        -5.7113,  -6.2154, -13.2550, -13.7632,  -7.7563,  -8.4884, -15.6846,\n",
       "                       -12.8679, -12.5408, -10.1373, -11.0303,  -8.8317,  -8.6962, -11.2265,\n",
       "                       -13.3940, -12.6671, -10.5173, -11.1147,  -9.7191,  -9.3235, -10.5189,\n",
       "                        -9.2362,  -9.7928, -11.5436,  -5.3139, -11.4657,  -8.1820,  -9.7276,\n",
       "                       -12.8487, -12.4356, -11.3890,  -8.5416,  -7.0600, -12.1388,  -9.2885,\n",
       "                       -10.2390,  -8.3354,  -8.1266,  -7.4188,  -9.0289,  -6.1786, -13.6227,\n",
       "                       -11.5395,  -8.3719, -11.4114,  -9.3470, -10.4304, -11.7534,  -6.6131,\n",
       "                        -6.4860,  -7.7830, -14.2819,  -9.1729,  -9.4956,  -8.8200, -14.3914,\n",
       "                        -9.2733,  -9.3520, -13.5086,  -8.6649,  -7.7513, -12.5135, -13.1946,\n",
       "                       -12.8133,  -7.7209, -10.5792, -14.4326, -11.0646,  -9.8393, -13.3821,\n",
       "                       -10.0047, -10.6789, -11.1940,  -8.6306, -14.4514, -11.5956,  -9.7265,\n",
       "                       -15.0767, -12.2830, -10.7356,  -9.0361,  -6.8977,  -8.7512,  -9.1303,\n",
       "                        -8.6288,  -8.0765, -10.9246, -12.0117, -10.5883,  -8.1081, -12.3401,\n",
       "                       -12.3190, -12.3612, -11.6358,  -8.5028,  -9.4126, -12.0485,  -6.3837,\n",
       "                       -11.4244, -10.0863, -15.5683,  -9.1223, -12.6953, -11.5748,  -8.9412,\n",
       "                       -11.3644,  -8.8625, -12.2167, -11.1881,  -7.3360,  -8.7879, -10.7554,\n",
       "                        -7.0423, -11.7585,  -8.4510,  -9.6842, -10.4855,  -7.7066,  -6.3143,\n",
       "                        -9.5375,  -8.0087,  -9.2176, -12.3142,  -7.4595, -11.3879,  -4.9095,\n",
       "                        -7.0090, -10.2986, -12.8484,  -7.3264, -10.5119, -10.7336, -10.8010,\n",
       "                        -8.6696, -17.8151,  -9.2606,  -9.9283, -11.1807,  -7.9112,  -6.7784,\n",
       "                       -10.9137,  -8.0106,  -6.9620, -11.6688,  -9.5805,  -8.5959,  -9.7636,\n",
       "                        -8.5198, -12.2389,  -9.1478,  -8.1453, -12.4756,  -9.4083,  -7.3629,\n",
       "                       -13.1045,  -9.6270,  -9.6665,  -9.8933,  -7.9381, -10.6922,  -9.2425,\n",
       "                        -7.8954,  -9.3268, -11.8413, -13.3432, -10.3631, -10.5183, -10.0359,\n",
       "                        -9.9202,  -7.8625,  -8.1335,  -8.9402, -11.4192,  -5.9625,  -9.5392,\n",
       "                        -7.0874,  -8.0605,  -9.4473, -11.1855, -12.7950, -10.7949, -12.3419,\n",
       "                        -7.6562, -14.0854, -10.3612,  -9.8623, -10.4224,  -9.1409, -14.9591,\n",
       "                       -11.8854,  -8.6520, -10.1927, -11.4755, -10.1710,  -9.4750,  -7.7925,\n",
       "                       -10.2812, -12.2564,  -7.7537,  -6.6620, -10.8340, -10.4059, -11.9272,\n",
       "                       -11.0039, -12.3004, -10.3599,  -8.9955, -12.5240, -11.8692,  -9.8073,\n",
       "                       -10.7393, -10.6546, -12.2049, -10.8643, -10.2018, -11.6912, -11.3565,\n",
       "                        -9.4278, -12.8465,  -9.0102, -13.0422, -11.7360, -11.8573,  -9.6732,\n",
       "                       -13.5239, -11.4994, -11.8104,  -8.9863,  -9.1722,  -9.2032,  -9.9717,\n",
       "                       -11.1541,  -9.3149, -10.5394,  -9.8313,  -7.8685, -14.3521, -11.8711,\n",
       "                        -8.4968,  -6.1572, -12.4332,  -7.9072,  -9.5356,  -8.9708,  -7.0380,\n",
       "                       -14.7917, -13.4908,  -7.9742, -10.2905, -10.6549,  -9.9388,  -9.2936,\n",
       "                       -13.1623, -11.8600, -10.0409, -10.6516,  -7.1750,  -8.7823,  -9.1282,\n",
       "                       -11.7259, -12.0622,  -8.9568,  -8.7477, -12.5159,  -8.3625,  -9.3127,\n",
       "                       -10.3506,  -8.5225,  -8.0484, -11.9778,  -7.7152, -12.3258, -11.5251,\n",
       "                       -10.6074,  -9.3330, -11.6243,  -7.4509, -12.0330,  -8.5127,  -9.2744,\n",
       "                        -8.0115,  -8.7962, -11.2252,  -7.7782, -10.5103, -10.7580, -14.4433,\n",
       "                       -12.4094, -12.7848, -11.1887, -11.2455,  -8.8453,  -8.7306, -10.3607,\n",
       "                       -10.7794,  -7.5537, -10.0302, -12.2000,  -8.8585, -13.6904, -10.2506,\n",
       "                       -12.8044, -11.9870,  -8.5768, -10.6659, -11.1175,  -5.8667, -11.2665,\n",
       "                        -9.6447, -12.2697,  -7.1850, -11.4209,  -4.9475, -11.3445, -11.0180,\n",
       "                       -10.6976, -12.0633,  -9.4174, -10.2803,  -9.7666,  -8.6389, -12.2479,\n",
       "                        -8.8226, -16.4966, -12.9197, -10.8278, -10.5766,  -8.5228, -10.4537,\n",
       "                       -14.5190, -12.3608, -10.0704,  -7.2365,  -8.9748,  -8.5510, -13.3488,\n",
       "                        -6.3004,  -4.8657,  -9.5620, -11.1047, -10.6984, -12.2717,  -8.1002,\n",
       "                       -12.3814,  -6.1011, -10.1579, -11.3373,  -8.9346,  -7.1032, -10.6421,\n",
       "                        -8.5353,  -8.8176,  -8.6552, -10.7790, -11.1876,  -8.9152,  -8.6046,\n",
       "                       -10.1903, -13.3491, -10.9219, -11.4192,  -8.0122,  -5.0803,  -7.1907,\n",
       "                        -9.2910,  -6.4443, -11.2285, -11.1397, -11.4683,  -9.4067,  -9.7184,\n",
       "                        -8.4264,  -9.8142,  -5.1804, -14.5606, -12.8593, -11.3980,  -9.0743,\n",
       "                       -13.2523,  -9.1607, -11.2102,  -7.6098,  -9.4769,  -9.2939,  -9.0630,\n",
       "                       -10.9464, -12.5919, -11.1671,  -8.9951,  -8.9873, -10.7743,  -9.5763,\n",
       "                        -8.8532,  -6.3426, -11.5980,  -9.5338, -11.9581, -10.1507,  -7.6085,\n",
       "                        -7.8964, -16.3195,  -7.9698, -11.2983,  -6.1035, -10.8961, -14.8799,\n",
       "                        -8.5117,  -9.6699,  -6.9834,  -9.0393, -10.1701, -11.1316, -10.9523,\n",
       "                        -8.6811, -11.9509, -12.3365,  -8.9529,  -8.8247, -11.8243, -13.2038,\n",
       "                       -10.8081,  -7.0179, -11.2472, -10.8153, -11.1608, -14.5949, -10.3344,\n",
       "                        -9.6759, -10.2307,  -9.8480, -15.7847, -10.8683,  -5.9520, -10.4720,\n",
       "                        -8.1118,  -8.9037,  -9.4431, -11.0172, -11.3063, -10.3130, -10.1860,\n",
       "                       -14.6933,  -9.0615, -10.6036, -11.3590,  -8.2459,  -7.5740,  -5.9723,\n",
       "                       -12.3277, -11.0075, -14.9161,  -9.8716,  -8.6900,  -9.5916,  -5.1327,\n",
       "                        -9.1199, -12.2774, -10.8230,  -6.6812,  -8.3982,  -9.7224,  -8.3312,\n",
       "                        -6.6135, -11.8535, -12.5668,  -9.0417,  -7.1228, -10.2076,  -8.1796,\n",
       "                        -8.7434, -15.6028, -10.1699, -12.5138,  -9.8046, -11.9482,  -9.7467,\n",
       "                       -11.5575, -10.9710,  -5.8092, -10.2086, -11.6999, -10.3494, -15.2646,\n",
       "                        -7.8103], device='cuda:0')),\n",
       "              ('conv_block4.bn2.running_var',\n",
       "               tensor([119.5330, 111.5851, 105.8014, 194.3960, 145.1584, 151.1561, 170.7872,\n",
       "                       168.1288, 169.7325, 246.5773, 183.6257, 201.1760,  90.3726, 235.3835,\n",
       "                       136.1833, 151.5590, 101.7934,  94.6865, 159.6302, 232.4375,  98.5792,\n",
       "                        93.2172, 166.5209, 154.0410, 183.5350,  73.4258, 103.5562, 228.6407,\n",
       "                        65.5826,  34.5725, 184.1561, 244.0851, 165.4411, 139.0002, 209.6452,\n",
       "                       160.1482, 166.1909, 149.4473, 197.4758,  98.0435, 122.8118, 115.8345,\n",
       "                       191.0247, 147.4830, 144.7492, 102.1568, 111.2490, 178.6992, 177.2030,\n",
       "                        91.5468,  92.0047, 178.1482, 100.3087, 138.4312,  77.9875,  88.8078,\n",
       "                       142.7540, 176.0923,  75.0477, 113.5099, 117.4905,  93.1809, 104.7753,\n",
       "                       177.5880,  54.8149, 112.3250,  53.3386, 124.4382,  84.0634, 165.6850,\n",
       "                       164.8729, 100.4674, 109.0026, 107.4236, 151.6819, 193.3995,  55.3059,\n",
       "                       106.1447,  84.0162, 209.6905, 126.8873, 106.6894, 127.1495, 166.2238,\n",
       "                        64.3243, 171.6260, 167.2073, 121.4679,  67.4339, 137.6332, 173.0528,\n",
       "                       252.8767, 100.0092, 127.1863, 139.5112,  84.4245, 186.3425, 247.4683,\n",
       "                       146.9553, 155.3842, 137.5345,  75.3665, 207.3246, 126.8592, 214.1089,\n",
       "                       209.7989, 148.8357, 182.2472, 100.6449,  49.5003, 100.7825,  93.1085,\n",
       "                        71.4692,  83.5189, 136.7704, 158.8071, 147.4560,  93.2384, 131.4757,\n",
       "                       137.1293, 202.9832, 152.5964, 108.1116, 216.2217, 239.0280,  76.2350,\n",
       "                       140.5914, 153.3451, 260.5764, 172.4119, 169.4218, 197.7206,  80.6323,\n",
       "                       101.7465, 104.0214, 106.3632, 113.2930,  57.2918, 113.4499, 126.2890,\n",
       "                        72.6041, 137.7473, 211.8665,  87.2345,  82.5531,  80.0018, 108.3961,\n",
       "                        97.3852, 104.7040, 240.5546, 190.8302, 114.5864, 130.0359,  90.7443,\n",
       "                        64.4102, 139.4491, 165.0707,  84.4786,  95.4657, 101.3506, 175.5658,\n",
       "                       131.7360, 281.9009, 146.9190, 150.1954, 161.3970, 109.4073,  95.7615,\n",
       "                       182.3277,  96.4348,  73.4839, 115.9752,  99.4877, 137.9911, 166.9402,\n",
       "                        91.8582, 125.5850,  95.9300, 185.0470, 132.8921,  63.0050,  94.5155,\n",
       "                       174.8960, 150.6762,  76.0643, 121.6214,  64.4462, 157.4700, 121.1129,\n",
       "                       109.1967,  90.4049, 124.2251, 240.2950, 145.4362, 115.4441,  83.2565,\n",
       "                        92.3168, 167.5009,  89.1367, 160.1980, 179.0705, 108.8378, 124.8380,\n",
       "                        62.1686,  86.0124, 159.5369, 188.2807, 239.6436, 194.1266, 152.7062,\n",
       "                        91.3488, 181.7483, 103.0574, 125.0780, 102.0396,  76.1436, 230.8262,\n",
       "                       159.3068, 131.1642, 183.1092, 154.2262, 284.9601, 109.3947,  50.4844,\n",
       "                        77.8616, 153.9754,  98.7566, 124.5419,  93.7722, 167.6795, 185.0094,\n",
       "                       200.0618, 179.7574,  87.7052,  76.7539, 136.9572, 161.2445,  76.2044,\n",
       "                       123.4741,  98.5624, 123.3278, 201.6077, 105.0393, 207.5891, 177.8371,\n",
       "                        79.6234, 183.8452,  76.3404, 190.6858, 128.7299, 186.1456,  79.0408,\n",
       "                       194.2552, 167.2675, 143.1439, 208.0128,  93.1392, 134.3249,  97.7061,\n",
       "                       131.9269, 134.8008, 234.3669, 289.1217,  83.8410, 243.2776, 166.5899,\n",
       "                       138.5753,  93.8360, 135.3104, 102.1121, 130.6812,  88.0845,  87.4273,\n",
       "                       354.1793, 120.9376,  49.8033, 108.2608, 191.9858,  83.2218, 124.6435,\n",
       "                       198.9207, 151.3005, 114.5484, 187.6745,  80.2599, 128.1988, 115.1032,\n",
       "                       290.1814, 238.4541, 149.8992, 125.2472, 111.4082,  72.5357, 121.9289,\n",
       "                       138.8316, 105.3264,  81.6092, 150.1974,  96.3888, 165.7158, 101.1007,\n",
       "                        66.8240, 127.8578, 161.8440, 107.5237, 163.1043, 186.2200, 122.2260,\n",
       "                       129.0678,  98.6127, 102.1676,  73.6693, 138.8832, 144.4659, 208.6830,\n",
       "                       176.8513, 120.0968, 162.8605, 143.4462, 162.6996,  69.2330, 128.3018,\n",
       "                       133.2198, 112.4777, 174.3360, 258.6885, 207.6651, 204.3252, 165.8202,\n",
       "                       132.7782, 156.4254, 125.7472, 294.2368, 126.8540, 155.4616,  79.2299,\n",
       "                       123.1838, 105.4637,  66.7107, 156.1684,  70.9858, 182.2789, 158.8055,\n",
       "                       186.7225, 146.6785, 152.9809,  99.1145, 168.4443,  83.2520, 137.6243,\n",
       "                        68.5944, 237.3921, 201.5072, 105.9986, 118.1479, 134.5408,  87.5844,\n",
       "                       242.6606, 172.6103, 138.2726,  75.9145, 133.1461,  86.2201, 310.4858,\n",
       "                        45.1279,  77.7772, 123.9231, 114.0875, 139.8184, 162.8016, 140.3397,\n",
       "                        96.5330, 167.8691, 138.7544, 171.2143, 135.1889, 125.9986, 175.9455,\n",
       "                        81.4727,  89.3942,  81.5546, 122.4892, 134.6115,  83.5224,  94.3160,\n",
       "                       121.9861, 168.8695, 144.2761, 198.3965,  89.1466, 237.1340,  98.3379,\n",
       "                       186.9334,  59.1445, 144.5183, 105.5614, 113.5008, 122.7501, 101.8751,\n",
       "                        83.4345, 160.4523,  88.1170, 319.9019, 152.8835, 123.0919,  91.8793,\n",
       "                       199.7066,  96.4695,  98.2488,  60.2616,  92.5484, 172.1201,  80.0252,\n",
       "                       211.5920, 169.3102, 206.1817, 120.4552, 144.4899, 123.4716,  79.5671,\n",
       "                       113.1695,  83.3126, 222.6195,  83.9858, 176.4949, 132.8481, 148.8628,\n",
       "                        52.2881, 246.3003,  96.7397, 203.4213, 119.4787, 223.7660, 277.8627,\n",
       "                       124.3682, 131.0021,  59.6992, 108.7543, 137.5425, 206.7273, 142.7591,\n",
       "                        88.6648, 104.4339, 207.0668, 119.0594,  67.7863, 203.4793, 217.6955,\n",
       "                       184.5082,  83.2572, 108.5184, 182.4813, 112.8087, 159.0301, 109.1860,\n",
       "                        99.9105, 148.3253, 132.4963, 237.3271, 184.7216,  54.4456, 222.5535,\n",
       "                        95.5209,  95.9788,  83.0696, 104.1740, 256.7545, 112.8713, 214.7532,\n",
       "                       224.7012,  56.6445,  99.2389, 126.1396,  78.9249,  87.1820,  76.5859,\n",
       "                       144.2391, 131.5220, 268.1415,  70.4655, 139.8484,  78.6657,  99.4189,\n",
       "                       124.7197, 115.7797,  92.5335, 174.9718, 168.3002, 117.1443, 112.4444,\n",
       "                        84.0920, 159.9541, 203.4507,  80.1847,  81.9829, 186.1985, 118.6786,\n",
       "                       106.9935, 172.8516, 150.0677, 230.2883, 186.6628, 200.1913, 131.3280,\n",
       "                       185.2038, 122.9916, 113.0203, 149.2874, 144.6691, 110.0487, 158.8798,\n",
       "                       158.9126], device='cuda:0')),\n",
       "              ('conv_block4.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('fc1.weight',\n",
       "               tensor([[-0.0162,  0.2051,  0.1045,  ..., -0.0675,  0.0420,  0.0474],\n",
       "                       [-0.1089, -0.0935, -0.1332,  ...,  0.1064,  0.1283,  0.1095],\n",
       "                       [-0.0769,  0.1070, -0.0794,  ..., -0.1325, -0.1202, -0.0031],\n",
       "                       ...,\n",
       "                       [-0.2049,  0.0241, -0.2252,  ..., -0.5683,  0.1057,  0.0919],\n",
       "                       [-0.1168, -0.1704,  0.0327,  ..., -0.0705, -0.1603,  0.0641],\n",
       "                       [ 0.0408, -0.0130, -0.0847,  ..., -0.0846,  0.0335,  0.0355]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc1.bias',\n",
       "               tensor([ 0.5390,  0.5386,  0.0718, -0.2857,  0.0245, -0.0327,  0.7104,  0.5407,\n",
       "                       -0.0533, -0.3832, -0.0618,  0.0038,  0.7356, -0.0791, -0.0786,  0.4660,\n",
       "                       -0.0875,  0.3958,  0.8654,  0.0343,  1.0210,  0.1983,  0.5465,  0.6340,\n",
       "                       -0.2606, -0.1079,  0.5308,  0.7250,  0.8561,  0.0458, -0.0163,  1.4613,\n",
       "                        0.1459,  0.5657,  0.0974, -0.3957,  0.4825,  0.0538, -0.2921,  0.6931,\n",
       "                        0.3894,  0.0033,  0.6783, -0.0054, -0.4779, -0.1824,  0.5314, -0.4128,\n",
       "                        0.3976,  0.6597, -0.3526,  0.4103,  0.6220, -0.0259, -0.2060,  0.2368,\n",
       "                       -0.0545,  0.0995,  0.1890,  0.7222, -0.0065,  0.9948,  0.0051, -0.0179,\n",
       "                       -0.2542, -0.0503,  0.2423,  0.0585,  0.7288, -0.2077,  1.3685, -0.0125,\n",
       "                        0.0168,  0.5329,  0.5047, -0.3545,  0.8285,  0.9625,  0.4309,  0.0344,\n",
       "                        0.6676, -0.1120, -0.0795,  0.2257, -0.1322,  0.7685, -0.2873, -0.1637,\n",
       "                        0.7472, -0.2636, -0.6023,  0.1480, -0.2895,  0.3800,  0.3542,  0.0336,\n",
       "                       -0.1534, -0.0077, -0.2535,  0.7723,  0.7742,  0.0843,  0.4135,  0.5900,\n",
       "                        0.7188,  0.5165,  0.5607,  1.4848, -0.2240,  0.7909, -0.0338,  0.8326,\n",
       "                        0.0656,  0.0045,  0.2118, -0.0539,  0.0855,  0.6208,  0.0530, -0.1141,\n",
       "                        0.2065,  0.2361,  1.0296,  0.0438,  0.4333,  0.3641, -0.0523,  0.7411,\n",
       "                        0.6331,  0.6274,  0.6925, -1.2867,  0.8086,  0.0173, -0.1901, -0.3369,\n",
       "                       -0.0032,  0.1064,  0.5409,  0.0720,  0.2645, -0.0785,  0.0313, -0.2220,\n",
       "                        0.2901,  0.5120, -0.0407,  0.4435, -0.4844,  0.0249,  0.7821,  0.6862,\n",
       "                       -0.7986, -0.0193,  0.8213,  1.0957, -0.3831,  0.6909, -0.0031, -0.0315,\n",
       "                        0.3736,  0.5035, -0.3834,  0.0250, -0.4908,  0.6797,  0.2503,  0.0392,\n",
       "                        0.0334,  0.0328,  0.7076,  0.6202,  0.6192, -0.0043,  0.5458, -0.2643,\n",
       "                       -0.7342, -0.0907,  0.7569,  0.0824,  0.0046, -0.1082,  0.0774, -0.0584,\n",
       "                       -0.0353,  0.0615,  0.5795, -0.2930,  0.6952,  0.2286,  0.4080,  0.6492,\n",
       "                       -0.1935,  0.8778,  0.5847,  0.0619,  0.7006,  1.0230,  0.6471,  0.6449,\n",
       "                        0.0760,  0.0229, -0.0660,  0.1966,  0.0250,  0.9624, -1.0504,  0.0090,\n",
       "                        0.5280,  0.8886, -0.3967,  0.3304,  0.3099, -0.0214,  1.0731,  0.7956,\n",
       "                        0.8134,  0.2016,  0.6136, -0.2428,  0.1177,  0.4334,  0.0131,  0.8510,\n",
       "                        0.0610,  0.7948,  0.5155, -0.0663,  0.4911, -0.8763,  0.8510,  0.7228,\n",
       "                        0.8229, -0.0220,  0.0983,  0.0610,  0.6902,  0.1753,  0.7661,  0.0874,\n",
       "                       -0.0046,  0.4422,  0.0411,  1.0061, -0.2448,  0.2282,  0.4859, -0.0152,\n",
       "                       -0.8320,  0.3044,  0.3033,  0.2701,  0.6300,  0.2581,  0.9366, -0.3989,\n",
       "                       -0.0423, -0.0848,  0.7038,  0.3513,  0.8420, -0.0679,  0.0851,  0.1601,\n",
       "                        0.8619,  0.9919, -0.0899,  0.6976, -0.0237,  1.0497,  0.4629, -0.0838,\n",
       "                        0.8751,  0.1089,  0.0120,  0.4143, -0.0554,  0.4155,  0.1813,  0.3214,\n",
       "                       -0.0190,  0.9575, -0.6662,  0.0173,  0.8417,  1.0557,  0.6580,  1.0432,\n",
       "                        0.1036,  0.5181, -0.3942,  0.4714, -0.6981,  0.5184,  0.0654,  0.5405,\n",
       "                        0.5567,  0.0060, -0.0396, -0.5671,  0.0902,  0.5639, -0.6331,  0.1842,\n",
       "                        0.0451, -0.1490, -0.2121,  0.8105,  0.0405,  0.0342,  0.5684,  0.3533,\n",
       "                        0.0036,  0.4902,  0.1283,  0.4577, -0.0264, -0.2958,  0.6845,  1.0332,\n",
       "                        0.6011,  0.6495,  0.8831,  0.0350,  0.7828,  0.9590, -0.0278,  0.9186,\n",
       "                        0.6269, -0.0297,  0.1410,  0.7537,  0.0240,  0.0256,  0.4615,  0.7308,\n",
       "                        0.1071, -0.9078,  0.1964,  0.4996,  0.5870, -0.0044, -0.1103,  0.1263,\n",
       "                        1.8711,  0.6102,  0.1896,  0.5381, -0.6056,  0.0078,  0.6531, -0.2677,\n",
       "                        0.0208,  0.5778,  0.0198,  0.2121,  0.0217,  0.1653, -0.0612,  0.0035,\n",
       "                       -1.0666, -0.0879, -0.0541, -0.1329,  0.6626,  0.7638,  0.2922,  0.0853,\n",
       "                        0.5237,  0.2026, -0.0352, -0.1551,  0.0853,  0.6013,  0.9664, -0.2932,\n",
       "                       -0.0207,  0.1017,  0.3746,  0.6826, -0.0119,  0.5998,  0.0069,  0.7347,\n",
       "                        0.3851, -0.0292, -0.6627,  0.7156,  0.9222,  0.1129,  0.8253, -0.0920,\n",
       "                        1.9585,  0.2107,  0.7375,  0.6403,  0.0144,  0.0324, -0.0371,  1.0825,\n",
       "                        0.1428,  0.7617,  0.2419,  0.3425,  0.7588, -0.0280,  0.8388,  0.0687,\n",
       "                        0.6463,  0.2129,  1.0098, -0.0627,  0.7320,  0.6724, -0.5646,  0.6478,\n",
       "                        0.9435,  0.7642, -0.5676, -0.0020,  0.4888,  0.5415,  0.0286, -0.0444,\n",
       "                        0.3874,  1.0348,  0.8692, -0.1861, -0.4097, -0.4449, -0.0587,  0.1921,\n",
       "                        0.1430,  0.1148, -0.0817,  0.2384,  0.1298,  0.5131,  0.4706,  0.2027,\n",
       "                        0.5833,  0.4381,  0.6469,  0.8394,  0.4661,  0.2742,  0.0402,  0.5458,\n",
       "                        0.0116,  0.1196,  0.9895, -0.3875,  0.7393, -0.0311,  0.3565,  0.0899,\n",
       "                       -0.0582,  0.3803, -0.0535,  0.4975,  0.3216, -0.4744,  0.2178,  0.6991,\n",
       "                       -0.1516,  0.1003,  0.6228,  0.1111,  0.7130,  0.8505,  0.5158,  0.7247,\n",
       "                        0.3823, -0.0385,  0.8897, -0.0693,  0.1624,  0.7634,  0.7517,  0.0310,\n",
       "                       -0.1659, -0.0226,  0.1614, -0.0026,  0.5967,  0.6866, -0.0344, -0.0937,\n",
       "                        0.9474,  0.6435,  0.5628, -0.1668,  0.1525,  0.6969,  0.5165, -0.0336,\n",
       "                        0.9038,  0.1055,  0.7125,  0.6618,  0.8524,  0.0132, -0.0358,  0.5847,\n",
       "                        0.5924,  0.0588,  0.0119, -0.1043, -0.5310,  0.3961,  0.5049,  0.0200],\n",
       "                      device='cuda:0')),\n",
       "              ('fc_audioset.weight',\n",
       "               tensor([[-0.0073,  0.0060, -0.0283,  ...,  0.1203,  0.0217,  0.0070],\n",
       "                       [-0.0506, -0.0685, -0.0697,  ..., -0.4943, -0.0545, -0.0633],\n",
       "                       [-0.0703,  0.0848, -0.0423,  ..., -0.3457, -0.1200, -0.0484],\n",
       "                       ...,\n",
       "                       [-0.2180,  0.1204, -0.0582,  ..., -0.4413, -0.1044,  0.0347],\n",
       "                       [-0.1677, -0.0202,  0.0103,  ..., -0.2483, -0.0535,  0.0531],\n",
       "                       [ 0.0720, -0.0735, -0.0046,  ..., -0.1864, -0.0848, -0.0013]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc_audioset.bias',\n",
       "               tensor([-0.3537, -0.2475, -0.4678, -0.3557, -0.2614, -0.1378, -0.2048, -0.1257,\n",
       "                       -0.1749, -0.2945, -0.3129, -0.2637, -0.1914, -0.1700, -0.3302, -0.1657,\n",
       "                       -0.2608, -0.2377, -0.1867, -0.2388, -0.1955, -0.2924, -0.2105, -0.3577,\n",
       "                       -0.2468, -0.1999, -0.1309, -0.5515, -0.3622, -0.1173, -0.2123, -0.1828,\n",
       "                       -0.2515, -0.1763, -0.3372, -0.1570, -0.0807, -0.1679, -0.2259, -0.1356,\n",
       "                       -0.1636, -0.2332, -0.1912, -0.0908, -0.1744, -0.2277, -0.3101, -0.2606,\n",
       "                       -0.3547, -0.3004, -0.1540, -0.2947, -0.3089, -0.2579, -0.2052, -0.2061,\n",
       "                       -0.1698, -0.1022, -0.1111, -0.3086, -0.1498, -0.2120, -0.1458, -0.1753,\n",
       "                       -0.2398, -0.3907, -0.2612, -0.0982, -0.1615, -0.3293, -0.1837, -0.1444,\n",
       "                       -0.3892, -0.4273, -0.3540, -0.3073, -0.4383, -0.1952, -0.2886, -0.3588,\n",
       "                       -0.3360, -0.2398, -0.1421, -0.1347, -0.3262, -0.1405, -0.4570, -0.2578,\n",
       "                       -0.1269, -0.1527, -0.4155, -0.2492, -0.1334, -0.4670, -0.1903, -0.2552,\n",
       "                       -0.2842, -0.2360, -0.4018, -0.2526, -0.2655, -0.2518, -0.2827, -0.3671,\n",
       "                       -0.3984, -0.3830, -0.3744, -0.3047, -0.1646, -0.1996, -0.2509, -0.3250,\n",
       "                       -0.5594, -0.5244, -0.1877, -0.2838, -0.2151, -0.1936, -0.2393, -0.1575,\n",
       "                       -0.1752, -0.2057, -0.2905, -0.1186, -0.2225, -0.1959, -0.4943, -0.1772,\n",
       "                       -0.2159, -0.3115, -0.3668, -0.3608, -0.2743, -0.3169, -0.1906, -0.2425,\n",
       "                       -0.3258, -0.0824, -0.3836, -0.4122, -0.4331, -0.2660, -0.2795, -0.3327,\n",
       "                       -0.1466, -0.2250, -0.2795, -0.3054, -0.1550, -0.1840, -0.1815, -0.1592,\n",
       "                       -0.4298, -0.4890, -0.2363, -0.1592, -0.1590, -0.2616, -0.3309, -0.3767,\n",
       "                       -0.2094, -0.3770, -0.3146, -0.2613, -0.3801, -0.3506, -0.3313, -0.2533,\n",
       "                       -0.2320, -0.2512, -0.1647, -0.3419, -0.2479, -0.1421, -0.1017, -0.2116,\n",
       "                       -0.1598, -0.1726, -0.2312, -0.3537, -0.3291, -0.2786, -0.1483, -0.1008,\n",
       "                       -0.4618, -0.2376, -0.2810, -0.3911, -0.2135, -0.4936, -0.2967, -0.1877,\n",
       "                       -0.2395, -0.4240, -0.3124, -0.2018, -0.1087, -0.1425, -0.1351, -0.1676,\n",
       "                       -0.1632, -0.1270, -0.2043, -0.2486, -0.1300, -0.2162, -0.1435, -0.2751,\n",
       "                       -0.3062, -0.1338, -0.0713, -0.0956, -0.1972, -0.1580, -0.0643, -0.1403,\n",
       "                       -0.4107, -0.2211, -0.1588, -0.4987, -0.2738, -0.2291, -0.2731, -0.2987,\n",
       "                       -0.1822, -0.1467, -0.2558, -0.1972, -0.2504, -0.4129, -0.1368, -0.2726,\n",
       "                       -0.3382, -0.4004, -0.2259, -0.2899, -0.4035, -0.3396, -0.1842, -0.3142,\n",
       "                       -0.3869, -0.1684, -0.2231, -0.2617, -0.2228, -0.3131, -0.1719, -0.2044,\n",
       "                       -0.2608, -0.1847, -0.2231, -0.5349, -0.2338, -0.2676, -0.2062, -0.1604,\n",
       "                       -0.2111, -0.3981, -0.5671, -0.2596, -0.2773, -0.2150, -0.1242, -0.1820,\n",
       "                       -0.2427, -0.2429, -0.3614, -0.4391, -0.2054, -0.3485, -0.4412, -0.1954,\n",
       "                       -0.0835, -0.4123, -0.5304, -0.1837, -0.2821, -0.2137, -0.4026, -0.4592,\n",
       "                       -0.2952, -0.1925, -0.1274, -0.4139, -0.2321, -0.2406, -0.1972, -0.1861,\n",
       "                       -0.3665, -0.2442, -0.3615, -0.2871, -0.2453, -0.1878, -0.3397, -0.3027,\n",
       "                       -0.2172, -0.4743, -0.3484, -0.3001, -0.2101, -0.2944, -0.3144, -0.1834,\n",
       "                       -0.2437, -0.2355, -0.3975, -0.3203, -0.1148, -0.2099, -0.2535, -0.2963,\n",
       "                       -0.1439, -0.2473, -0.1720, -0.1529, -0.5164, -0.2371, -0.1876, -0.1773,\n",
       "                       -0.1149, -0.2334, -0.2916, -0.2899, -0.2943, -0.2745, -0.1975, -0.2519,\n",
       "                       -0.4191, -0.3885, -0.2116, -0.2630, -0.3070, -0.2339, -0.4336, -0.3425,\n",
       "                       -0.2274, -0.2695, -0.2546, -0.2056, -0.3684, -0.2268, -0.1964, -0.3175,\n",
       "                       -0.1842, -0.1835, -0.1965, -0.2230, -0.1884, -0.2829, -0.1854, -0.3985,\n",
       "                       -0.1619, -0.1548, -0.3096, -0.1665, -0.4278, -0.2216, -0.2344, -0.2738,\n",
       "                       -0.2025, -0.1480, -0.1634, -0.1746, -0.4287, -0.2180, -0.1856, -0.3711,\n",
       "                       -0.2545, -0.3254, -0.2575, -0.3963, -0.2103, -0.2107, -0.3120, -0.2376,\n",
       "                       -0.2510, -0.4727, -0.1735, -0.1642, -0.1472, -0.1427, -0.1937, -0.1302,\n",
       "                       -0.2861, -0.2194, -0.1853, -0.1560, -0.1799, -0.2459, -0.2076, -0.4442,\n",
       "                       -0.2122, -0.1669, -0.1696, -0.1358, -0.3067, -0.1089, -0.2226, -0.2297,\n",
       "                       -0.1976, -0.1133, -0.1483, -0.1591, -0.2220, -0.2332, -0.2406, -0.2138,\n",
       "                       -0.2284, -0.2109, -0.1738, -0.2394, -0.2299, -0.2842, -0.1720, -0.1865,\n",
       "                       -0.3023, -0.2254, -0.3218, -0.4740, -0.4103, -0.1863, -0.2450, -0.3028,\n",
       "                       -0.4664, -0.2292, -0.2503, -0.3617, -0.2133, -0.0949, -0.2192, -0.1527,\n",
       "                       -0.1928, -0.2296, -0.2942, -0.3051, -0.1859, -0.4133, -0.2166, -0.3207,\n",
       "                       -0.2160, -0.2232, -0.3179, -0.1327, -0.2912, -0.1611, -0.1601, -0.3654,\n",
       "                       -0.1933, -0.2057, -0.3190, -0.1902, -0.2419, -0.1603, -0.2589, -0.1674,\n",
       "                       -0.2111, -0.1031, -0.2695, -0.4614, -0.2496, -0.2255, -0.3635, -0.4138,\n",
       "                       -0.2433, -0.1642, -0.3051, -0.1986, -0.1814, -0.1407, -0.1998, -0.2335,\n",
       "                       -0.1610, -0.2577, -0.2172, -0.3175, -0.2816, -0.2251, -0.2851, -0.1637,\n",
       "                       -0.1873, -0.3904, -0.3235, -0.3839, -0.1854, -0.1589, -0.1304, -0.2944,\n",
       "                       -0.2398, -0.2792, -0.2389, -0.0767, -0.2468, -0.1448, -0.2242, -0.2961,\n",
       "                       -0.2477, -0.2238, -0.1844, -0.4480, -0.2059, -0.2270, -0.2432, -0.3335,\n",
       "                       -0.3057, -0.2527, -0.8537, -0.7422, -0.2719, -0.7250, -0.8501, -0.1985,\n",
       "                       -0.2027, -0.2493, -0.2233, -0.3995, -0.1986, -0.2389, -0.1356, -0.1837,\n",
       "                       -0.2550, -0.2296, -0.2841, -0.2581, -0.2493, -0.0848, -0.2910],\n",
       "                      device='cuda:0'))])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa7453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b68bfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85049d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Transfer_Cnn10(freeze_base=True,pretrain_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d589a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:base.bn0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.bn0.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 1, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block4.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 256, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "#model parameter 확인\n",
    "for name, param in cnn.named_parameters(): \n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str = 'Hello world, Python!'\n",
    "if str.startswith('Hello'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6db15c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea5aab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer , fc 풀기 2개 \n",
    "for name, param in cnn.named_parameters():\n",
    "    if name.startswith('base.conv_block4'):\n",
    "        param.requires_grad=True\n",
    "    \n",
    "    #elif name.startswith('base.conv_block3'):\n",
    "    #    param.requires_grad=True\n",
    "    \n",
    "    #elif name.startswith('base.fc'):\n",
    "    #    param.requires_grad=True\n",
    "    else:\n",
    "        param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1274d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_base=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ae7ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn14,Transfer_Cnn14,init_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e0614a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd291a302b8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "from data_handling import get_clotho_loader, get_test_data_loader\n",
    "#from model import TransformerModel  # , RNNModel, RNNModelSmall\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "from util import get_file_list, get_padding, print_hparams, greedy_decode, \\\n",
    "    calculate_bleu, calculate_spider, LabelSmoothingLoss, beam_search, align_word_embedding, gen_str\n",
    "from hparams import hparams\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "\n",
    "hp = hparams()\n",
    "parser = argparse.ArgumentParser(description='hparams for model')\n",
    "\n",
    "device = torch.device('cuda')\n",
    "np.random.seed(hp.seed)\n",
    "torch.manual_seed(hp.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13a5c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn10,init_layer\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, batch_size, dropout=0.5,pretrain_cnn=None,\n",
    "                 pretrain_emb=None,freeze_cnn=True):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.model_type = 'cnn+transformer'\n",
    "        decoder_layers = TransformerDecoderLayer(d_model=nhid, nhead=nhead, dropout=dropout)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "        self.word_emb = nn.Embedding(ntoken, nhid)\n",
    "        self.ninp = ninp\n",
    "        self.nhid = nhid\n",
    "        self.fc = nn.Linear(512, 512, bias=True)\n",
    "        self.fc1 = nn.Linear(512, nhid, bias=True)\n",
    "        self.dec_fc = nn.Linear(nhid, ntoken)\n",
    "        self.batch_size = batch_size\n",
    "        self.ntoken = ntoken\n",
    "        self.encoder = Cnn10()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pos_encoder = PositionalEncoding(nhid, dropout)\n",
    "        self.generator = nn.Softmax(dim=-1)\n",
    "        self.init_weights()\n",
    "\n",
    "        if pretrain_cnn is not None:\n",
    "            dict_trained = pretrain_cnn\n",
    "            dict_new = self.encoder.state_dict().copy()\n",
    "            new_list = list(self.encoder.state_dict().keys())\n",
    "            trained_list = list(dict_trained.keys())\n",
    "            for i in range(len(new_list)):\n",
    "                dict_new[new_list[i]] = dict_trained[trained_list[i]]\n",
    "            self.encoder.load_state_dict(dict_new)\n",
    "        if freeze_cnn:\n",
    "            self.freeze_cnn()\n",
    "\n",
    "        if pretrain_emb is not None:\n",
    "            self.word_emb.weight.data = pretrain_emb\n",
    "\n",
    "    def freeze_cnn(self):\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc)\n",
    "        self.word_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dec_fc.bias.data.zero_()\n",
    "        self.dec_fc.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def encode(self, src, input_mask=None):\n",
    "        x = self.encoder(src)  # (batch_size, 512, T/16, mel_bins/16)\n",
    "        x = torch.mean(x, dim=3)  # (batch_size, 512, T/16)\n",
    "        x = x.permute(2, 0, 1)  # (T/16,batch_size,512)\n",
    "        x = F.relu_(self.fc(x))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "    def decode(self, mem, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # tgt:(batch_size,T_out)\n",
    "        # mem:(T_mem,batch_size,nhid)\n",
    "\n",
    "        tgt = tgt.transpose(0, 1)  # (T_out,batch_size)\n",
    "        if target_mask is None or target_mask.size(0) != len(tgt):\n",
    "            device = tgt.device\n",
    "            target_mask = self.generate_square_subsequent_mask(len(tgt)).to(device)\n",
    "\n",
    "        tgt = self.dropout(self.word_emb(tgt)) * math.sqrt(self.nhid)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        # mem = self.pos_encoder(mem)\n",
    "        output = self.transformer_decoder(tgt, mem, memory_mask=input_mask, tgt_mask=target_mask,\n",
    "                                          tgt_key_padding_mask=target_padding_mask)\n",
    "        output = self.dec_fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, src, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # src:(batch_size,T_in,feature_dim)\n",
    "        # tgt:(batch_size,T_out)\n",
    "        mem = self.encode(src)\n",
    "        output = self.decode(mem, tgt, input_mask=input_mask, target_mask=target_mask,\n",
    "                             target_padding_mask=target_padding_mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c62d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transfer_Cnn10(nn.Module):\n",
    "    def __init__(self, freeze_base=True, pretrain_checkpoint=None):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_Cnn10, self).__init__()\n",
    "\n",
    "        audioset_classes_num = 527\n",
    "        self.base = Cnn10()\n",
    "\n",
    "        #self.init_weights()\n",
    "\n",
    "        if pretrain_checkpoint:\n",
    "            self.load_from_pretrain(pretrain_checkpoint)\n",
    "            \n",
    "        #self.base.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        # 안쓰이는이유는 multi-class clasification을 생략하기 때문,\n",
    "\n",
    "        if freeze_base:\n",
    "            # 2단계 freeze / 3단계 freeze X\n",
    "            # Freeze AudioSet pretrained layers\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    #def init_weights(self):\n",
    "        #init_layer(self.fc_transfer)\n",
    "\n",
    "    def load_from_pretrain(self, pretrained_checkpoint):\n",
    "        pretrained_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\"\n",
    "        checkpoint = torch.load(pretrained_checkpoint)\n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_imag.weight')#가중치 삭제  \n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_real.weight')#가중치 삭제\n",
    "        checkpoint['model'].pop('logmel_extractor.melW')#가중치 삭제\n",
    "        checkpoint['model'].pop('fc1.weight')\n",
    "        checkpoint['model'].pop('fc1.bias')\n",
    "        checkpoint['model'].pop('fc_audioset.weight')\n",
    "        checkpoint['model'].pop('fc_audioset.bias')\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        output = self.base(input)\n",
    "\n",
    "        #embedding = output_dict['embedding']\n",
    "        #clipwise_output = output_dict['clipwise_output']\n",
    "\n",
    "        return output #, clipwise_output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee395297",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_cnn=torch.load(\"/home/hj20/dcase_2020_T6/models/cnn10_best_48.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc67f90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_emb): Embedding(4371, 192)\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=512, out_features=192, bias=True)\n",
       "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
       "  (encoder): Cnn10(\n",
       "    (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_block1): ConvBlock(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block2): ConvBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block3): ConvBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block4): ConvBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (generator): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a37e6ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('transformer_decoder.layers.0.self_attn.in_proj_weight',\n",
       "              tensor([[-0.1121,  0.1543, -0.0988,  ..., -0.0251, -0.0537, -0.0022],\n",
       "                      [ 0.0296,  0.0604, -0.1261,  ..., -0.0366, -0.0391, -0.0789],\n",
       "                      [-0.0670,  0.0440, -0.0538,  ..., -0.0826, -0.0667, -0.0441],\n",
       "                      ...,\n",
       "                      [ 0.0519,  0.0259,  0.0380,  ..., -0.0424,  0.0839, -0.0298],\n",
       "                      [-0.1306,  0.0024,  0.0710,  ...,  0.0484, -0.0190, -0.0325],\n",
       "                      [-0.0671, -0.0377,  0.0468,  ..., -0.0534, -0.0323, -0.0415]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.self_attn.in_proj_bias',\n",
       "              tensor([-4.8882e-02,  1.4886e-02, -1.3403e-02, -3.1634e-02,  2.4075e-02,\n",
       "                       6.1872e-02,  3.3191e-02,  4.9238e-03, -2.4707e-02, -2.9865e-02,\n",
       "                      -8.4079e-02,  6.5329e-04,  2.5111e-02, -7.4482e-02, -5.5098e-02,\n",
       "                       3.9614e-02,  3.6864e-02,  5.8129e-03, -8.2433e-03, -4.9785e-02,\n",
       "                       4.7040e-02,  3.5419e-02, -7.7811e-02, -2.3538e-02, -3.2797e-02,\n",
       "                       5.0955e-02,  1.2973e-02,  8.2237e-02, -6.7934e-02, -4.8609e-03,\n",
       "                       5.2928e-03, -1.4551e-02, -4.8945e-02, -2.8405e-03,  1.1080e-01,\n",
       "                      -1.1835e-02, -7.7633e-02, -3.2229e-02, -3.3883e-02,  1.1286e-02,\n",
       "                       9.5591e-02,  7.0906e-02, -5.2854e-02, -8.2858e-02,  1.4638e-02,\n",
       "                       1.1863e-02,  5.4218e-02,  3.7832e-03,  2.1142e-02,  4.5759e-02,\n",
       "                      -1.3421e-03, -5.1448e-02,  2.7143e-02, -1.3486e-02, -1.7756e-02,\n",
       "                      -2.6771e-03,  1.0478e-02, -3.1756e-02,  4.3664e-02,  5.6513e-02,\n",
       "                      -2.2516e-02,  2.3603e-02, -2.7578e-02, -1.8583e-02, -1.6563e-03,\n",
       "                       2.1780e-02, -2.1138e-02,  2.5185e-02, -3.9830e-02,  5.6972e-02,\n",
       "                      -1.8557e-02,  5.4048e-02,  3.6929e-02, -4.3725e-02, -3.5584e-02,\n",
       "                       5.2630e-02,  1.8012e-02,  2.9198e-02, -2.1126e-02, -3.6502e-02,\n",
       "                       1.4218e-02,  2.3038e-02, -4.4794e-02, -1.9552e-02,  6.1013e-02,\n",
       "                      -7.8966e-03,  8.0278e-03, -1.1486e-02, -2.0190e-02, -1.6710e-02,\n",
       "                       2.8131e-02,  3.0692e-02,  3.6090e-02, -4.1345e-02,  4.4258e-02,\n",
       "                       7.3780e-03,  3.4233e-02, -1.8111e-02, -1.3227e-02,  7.3515e-02,\n",
       "                       1.1337e-02,  9.9177e-03, -8.6224e-02,  2.2670e-02,  1.3303e-02,\n",
       "                       5.5076e-02,  6.2373e-02, -3.1701e-02,  7.1008e-02, -2.3537e-02,\n",
       "                       3.1060e-02,  2.6192e-02, -3.2962e-02, -4.7220e-02,  4.7160e-02,\n",
       "                       2.0929e-02,  6.2649e-02,  6.2644e-02,  5.8579e-02,  6.6606e-02,\n",
       "                      -4.8528e-02,  1.0226e-02, -3.0267e-02, -3.7159e-02, -1.1162e-02,\n",
       "                       3.7877e-04,  2.0019e-02, -1.9767e-02, -4.1481e-02, -7.0210e-02,\n",
       "                       2.8430e-02,  6.9786e-02,  2.0005e-02,  9.6821e-04, -8.2378e-03,\n",
       "                       8.2414e-03,  2.7708e-02, -4.9569e-02, -2.1599e-02, -8.0262e-02,\n",
       "                      -1.6523e-02, -4.0349e-02,  4.2360e-04, -9.3588e-02, -3.0103e-02,\n",
       "                       4.3306e-02,  2.5295e-02,  1.0102e-02,  1.3036e-02, -7.6830e-02,\n",
       "                       4.2402e-02, -2.7280e-02, -2.2149e-02, -6.9022e-03,  6.0508e-02,\n",
       "                      -9.8263e-06, -1.4295e-03,  5.8245e-02, -7.0920e-03, -2.0126e-02,\n",
       "                      -2.1960e-02, -3.1308e-03,  1.7412e-02, -1.4055e-02,  5.1541e-02,\n",
       "                      -6.4362e-02,  1.2900e-02,  6.3986e-02, -2.5059e-02, -1.2995e-02,\n",
       "                       5.8593e-02, -3.5203e-02, -5.3229e-02,  5.3457e-02,  3.4618e-02,\n",
       "                       5.5110e-02, -6.3361e-02,  1.6490e-03,  8.1990e-02,  1.7448e-02,\n",
       "                      -5.6289e-02, -1.2129e-02, -9.0056e-02, -5.8310e-02,  1.1758e-03,\n",
       "                       2.8986e-02, -5.3037e-03,  1.7086e-03, -3.7347e-02, -5.2185e-02,\n",
       "                       1.0463e-02, -3.6608e-02,  1.8068e-05,  5.9495e-07,  5.7673e-06,\n",
       "                      -2.7862e-07, -4.4372e-06, -8.0239e-07, -1.1467e-05,  7.6796e-06,\n",
       "                      -1.3956e-06,  5.1741e-06,  2.1183e-06,  7.7048e-06, -9.7893e-06,\n",
       "                      -1.4522e-05,  3.4087e-07,  1.8796e-05, -2.6494e-06,  1.4365e-05,\n",
       "                      -8.7614e-06, -1.1120e-05, -1.8833e-05,  2.8068e-05, -3.8711e-06,\n",
       "                      -8.2170e-06,  1.2640e-07,  6.2034e-06,  2.6308e-05,  4.4106e-06,\n",
       "                       3.0250e-06, -1.1356e-05,  1.1416e-07,  4.0462e-07,  2.8889e-06,\n",
       "                      -6.8269e-07,  3.5595e-06, -3.1678e-06, -6.0499e-06,  1.2191e-05,\n",
       "                       3.8592e-06,  1.4879e-05,  7.7183e-06,  2.5749e-06,  1.5579e-05,\n",
       "                       1.2576e-05,  1.7262e-05, -8.3990e-06,  1.9338e-05, -2.4847e-06,\n",
       "                       1.4755e-05,  1.7367e-05,  3.9021e-06, -2.3688e-05, -4.8710e-06,\n",
       "                      -1.4862e-06, -1.0407e-05,  7.0105e-06,  8.7756e-06, -1.0468e-06,\n",
       "                       1.9916e-05, -6.6776e-07, -1.2132e-05,  2.0989e-06, -2.8841e-05,\n",
       "                      -6.4898e-06,  5.5858e-06,  3.1141e-06, -4.8956e-06, -7.8123e-06,\n",
       "                       1.3019e-06,  1.0751e-05, -1.9872e-05,  1.4185e-05,  1.9184e-05,\n",
       "                      -2.1530e-05,  1.4479e-05,  2.1295e-05, -1.0091e-05, -1.2123e-05,\n",
       "                      -4.9186e-06,  2.5457e-06, -5.5626e-06,  2.2077e-07, -1.5818e-05,\n",
       "                      -9.4985e-06,  1.2390e-05, -6.5742e-06, -4.6334e-06, -2.0278e-06,\n",
       "                      -3.0525e-06, -4.4899e-06, -6.5110e-06,  1.5640e-05,  9.6016e-06,\n",
       "                      -3.8675e-06,  9.9518e-06,  9.3398e-06,  7.4123e-06, -1.1731e-05,\n",
       "                      -8.2104e-06, -9.5115e-06, -3.3973e-06, -4.0556e-06, -1.0658e-05,\n",
       "                      -1.4509e-05,  2.2110e-05,  8.0925e-07,  1.4756e-05,  9.0053e-06,\n",
       "                      -3.4359e-06, -4.4677e-06, -1.7822e-06, -1.3005e-05, -1.3517e-05,\n",
       "                       1.6259e-05, -4.7014e-06, -8.7356e-06, -6.7677e-07,  1.5488e-05,\n",
       "                      -5.6666e-06, -4.0197e-06,  8.7348e-06, -6.6217e-06,  2.0163e-06,\n",
       "                       3.4504e-06, -7.3133e-06, -8.6196e-06,  6.1361e-06,  1.1035e-05,\n",
       "                       1.3948e-05,  9.1823e-06,  1.0121e-05,  4.3631e-06, -1.1018e-05,\n",
       "                      -8.7860e-06,  1.1358e-05,  1.4105e-05,  1.6605e-05, -1.7249e-05,\n",
       "                      -1.9136e-07,  5.9873e-06,  8.4071e-06, -8.9901e-06, -5.5589e-06,\n",
       "                       4.9634e-06, -7.8524e-06, -5.3248e-06,  1.9807e-05, -1.6503e-05,\n",
       "                       9.4166e-06,  6.9066e-06, -8.5433e-06,  2.9994e-06, -2.8097e-06,\n",
       "                      -2.7189e-05,  6.4151e-06, -1.2244e-05,  5.6847e-06, -5.6364e-06,\n",
       "                      -1.6330e-06, -1.2545e-06,  1.0316e-05,  1.4496e-05,  1.2129e-05,\n",
       "                       1.1116e-05,  4.1328e-06, -1.1332e-05,  3.8587e-06, -1.0591e-05,\n",
       "                      -1.4575e-06, -2.7460e-06,  9.7502e-09,  4.0198e-06,  2.8573e-06,\n",
       "                      -1.0807e-05, -1.0168e-05,  6.9058e-06,  8.4973e-06,  1.2796e-05,\n",
       "                      -6.8630e-06, -3.0286e-06,  1.3395e-05,  5.7577e-06, -6.8268e-07,\n",
       "                       5.6857e-06, -1.6506e-05, -1.4703e-06,  4.1138e-06, -8.2722e-06,\n",
       "                       8.3598e-06, -3.7493e-06,  7.0791e-06, -9.0113e-07,  1.6303e-03,\n",
       "                      -9.6012e-03, -5.4251e-04, -7.9567e-03,  2.0648e-02,  1.8485e-02,\n",
       "                      -2.5845e-04, -1.6929e-02, -1.5671e-02, -1.0191e-02,  6.3123e-03,\n",
       "                      -1.3405e-03,  3.1166e-02, -1.8430e-02, -3.2544e-03, -4.0480e-03,\n",
       "                       4.0280e-04,  3.3984e-04,  1.6234e-02, -2.1567e-03, -1.4890e-02,\n",
       "                      -7.9630e-03,  1.6148e-03, -1.0456e-02, -1.6454e-02, -1.2794e-02,\n",
       "                       7.7591e-03,  1.2401e-02, -7.8674e-03,  4.8117e-03, -2.7521e-02,\n",
       "                       5.3664e-03,  6.1583e-03,  1.0492e-02, -3.7021e-03, -1.1865e-02,\n",
       "                       1.2562e-02,  1.3275e-02,  1.1872e-02,  5.1559e-03, -1.3351e-02,\n",
       "                      -5.9799e-03, -1.3111e-02,  9.7624e-04, -2.5651e-02, -4.5339e-04,\n",
       "                       5.2899e-03, -1.0601e-02, -3.6222e-03, -1.1123e-02, -1.9616e-02,\n",
       "                      -4.8156e-03,  6.0370e-03,  8.0743e-03, -6.2176e-03,  4.4354e-05,\n",
       "                       6.1760e-03,  2.0883e-02, -1.8602e-02, -1.0920e-02, -1.0792e-02,\n",
       "                       6.0563e-03, -1.0085e-02,  9.5700e-03,  9.4747e-03,  1.1323e-02,\n",
       "                      -1.1852e-02,  3.3083e-03,  5.6840e-03, -1.0192e-02,  2.0097e-02,\n",
       "                      -1.3658e-02, -2.3602e-02, -9.2293e-03, -1.5105e-03, -1.1637e-03,\n",
       "                       5.3992e-03, -9.3063e-03,  2.1969e-03, -9.6324e-03,  8.6117e-03,\n",
       "                      -1.1540e-02,  5.4705e-03,  4.4957e-03, -1.6253e-02, -3.9632e-03,\n",
       "                       2.3247e-04, -2.7323e-03, -8.9022e-03,  9.7149e-03, -4.3621e-03,\n",
       "                      -8.9750e-03,  1.9970e-02,  1.7519e-04, -6.3800e-03,  5.2539e-03,\n",
       "                       4.1380e-03, -1.6113e-02, -2.4926e-02, -1.8221e-02,  3.0167e-03,\n",
       "                      -1.4001e-03, -5.5736e-03, -2.0499e-04, -4.2547e-03, -1.6165e-02,\n",
       "                       4.1057e-03,  3.8345e-03, -6.1370e-03, -1.2611e-02, -3.7280e-04,\n",
       "                      -1.2744e-03, -3.8480e-03,  1.6761e-02, -5.9505e-03,  3.1695e-03,\n",
       "                       1.7846e-02, -5.1126e-03, -1.4647e-02,  2.6612e-03, -4.3751e-03,\n",
       "                       8.5199e-03,  1.3615e-02, -3.1236e-03, -1.5956e-03,  3.4538e-02,\n",
       "                       1.0163e-02,  9.5487e-03, -9.4259e-03,  3.0504e-03, -9.4489e-03,\n",
       "                      -1.9994e-02, -4.1760e-03,  1.6245e-02,  5.4962e-03,  1.3091e-02,\n",
       "                       2.1879e-02, -3.4830e-02,  6.2942e-03, -1.6166e-02, -1.9049e-02,\n",
       "                      -8.9314e-03,  8.2999e-03,  3.4078e-03,  3.1725e-03, -4.0692e-03,\n",
       "                       6.8395e-03, -7.1589e-03, -3.0603e-03,  1.1652e-02,  1.1986e-02,\n",
       "                       1.2687e-02,  2.9401e-03,  1.8258e-02,  2.0876e-02,  1.5723e-02,\n",
       "                      -6.3720e-03, -1.2507e-02, -3.5083e-04,  1.3760e-04,  2.1818e-02,\n",
       "                       3.8723e-03, -1.0731e-02,  1.2925e-02,  6.9276e-03,  7.0941e-03,\n",
       "                       1.6803e-02,  8.9527e-03,  2.8582e-03,  1.6302e-03,  1.8747e-02,\n",
       "                      -2.5962e-02,  1.1765e-02,  2.2601e-02, -2.0326e-04,  4.0143e-03,\n",
       "                      -1.9114e-02, -2.4557e-02,  2.4854e-02, -2.4203e-02,  8.3314e-03,\n",
       "                       1.6553e-02,  9.2608e-04, -8.0551e-03,  1.6081e-02, -6.5435e-03,\n",
       "                      -1.4003e-03,  5.9490e-03, -3.6475e-03, -6.4959e-04, -2.2006e-02,\n",
       "                       1.8325e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.self_attn.out_proj.weight',\n",
       "              tensor([[ 0.0071, -0.0170,  0.0544,  ...,  0.0417, -0.0457,  0.0115],\n",
       "                      [ 0.0116, -0.0627,  0.0536,  ..., -0.0290,  0.0505, -0.0429],\n",
       "                      [ 0.0030, -0.0363,  0.0468,  ...,  0.0435,  0.0419,  0.0496],\n",
       "                      ...,\n",
       "                      [-0.0251, -0.0649,  0.0008,  ...,  0.0273, -0.0087, -0.0659],\n",
       "                      [-0.0135,  0.0043, -0.0222,  ...,  0.0163, -0.0711,  0.0409],\n",
       "                      [ 0.0986, -0.0893, -0.0425,  ..., -0.0275, -0.0433,  0.0447]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.self_attn.out_proj.bias',\n",
       "              tensor([ 4.5005e-02, -5.7770e-02,  2.2619e-02, -4.7946e-02,  1.2709e-02,\n",
       "                       4.0395e-03,  5.0262e-03,  1.8686e-02,  6.1701e-02,  1.5990e-02,\n",
       "                      -1.6832e-02,  1.3102e-02,  3.2107e-03,  8.3510e-03, -1.6098e-02,\n",
       "                      -5.0668e-03, -3.2309e-02,  1.7314e-02, -1.1023e-02,  5.4407e-02,\n",
       "                      -8.1607e-03, -2.3525e-02, -4.5785e-02, -1.1861e-02, -3.2681e-02,\n",
       "                       1.9470e-02, -3.5496e-02,  3.7925e-03,  3.4880e-02, -3.2732e-02,\n",
       "                      -3.4458e-02, -3.0290e-02, -5.9235e-03, -1.0048e-02, -4.7402e-02,\n",
       "                      -1.7985e-02, -1.9088e-02, -1.5136e-02, -8.5931e-03,  2.7678e-02,\n",
       "                      -3.9901e-02, -5.3573e-03, -1.4800e-02, -1.8086e-02, -1.7363e-02,\n",
       "                      -1.7534e-02,  2.3187e-02, -4.8089e-03,  2.2995e-02, -3.2562e-02,\n",
       "                       2.6960e-02, -9.6114e-03, -2.0635e-02,  1.2320e-02, -1.9474e-03,\n",
       "                       2.8542e-02,  6.2370e-03, -2.5571e-03, -4.9565e-03, -1.7610e-02,\n",
       "                      -1.1158e-02,  2.6874e-02, -4.2357e-02,  9.5133e-03, -8.9433e-02,\n",
       "                      -3.2635e-02,  8.6950e-03, -1.3292e-02,  1.1847e-02,  3.7086e-03,\n",
       "                       3.1326e-02,  2.4883e-02,  1.1376e-03, -1.1957e-02, -6.7654e-03,\n",
       "                       1.4580e-03, -1.1571e-03, -8.3807e-03,  1.4737e-02,  2.9075e-03,\n",
       "                       2.2689e-02,  1.8249e-02, -1.9737e-02,  4.0774e-02, -3.3194e-03,\n",
       "                      -3.7961e-03, -1.9316e-02,  8.0790e-02, -3.0340e-02, -4.2859e-03,\n",
       "                       4.0717e-02,  2.8951e-02, -1.7661e-02,  3.8694e-02,  3.1667e-02,\n",
       "                       3.5434e-02,  4.6041e-03,  7.7567e-04,  6.1045e-03, -3.5738e-02,\n",
       "                      -6.2822e-03, -1.1982e-02,  1.1408e-02,  4.7743e-03, -1.3419e-02,\n",
       "                       1.7808e-02, -7.2443e-03,  2.5336e-02, -1.9320e-02,  1.8701e-02,\n",
       "                       2.4112e-02, -1.0928e-02, -1.5588e-02, -3.1790e-02, -4.0040e-02,\n",
       "                       9.0055e-03,  1.4874e-02,  3.3433e-02, -8.2995e-03,  4.8370e-03,\n",
       "                       2.1514e-02, -1.2159e-03,  3.6464e-02,  2.1912e-02,  7.6836e-03,\n",
       "                       5.5695e-02,  8.7656e-03,  1.7148e-02, -2.9240e-02,  3.0324e-02,\n",
       "                       1.0201e-02,  4.1016e-02, -1.1358e-02,  3.1722e-03,  3.3864e-03,\n",
       "                       1.0282e-02, -9.5728e-03,  2.3971e-02,  1.2634e-02, -3.6492e-02,\n",
       "                       5.9735e-03,  3.5276e-02, -1.4573e-02, -3.4076e-03, -1.4085e-02,\n",
       "                      -1.4274e-02,  1.5589e-02, -8.6285e-04,  2.8017e-02, -2.8156e-03,\n",
       "                      -6.9918e-03,  3.4997e-02, -6.6776e-03, -2.0914e-02, -1.9886e-02,\n",
       "                      -1.6349e-03,  1.2484e-02,  1.2373e-02, -9.2129e-03,  2.1557e-02,\n",
       "                      -1.4658e-03, -3.2431e-02,  2.1798e-02,  5.5920e-02,  1.0223e-02,\n",
       "                      -1.2436e-03, -1.9993e-02,  3.5559e-02,  1.0937e-03,  1.6642e-02,\n",
       "                       2.2836e-02, -2.3831e-02,  1.2063e-02,  1.3795e-02,  1.5220e-02,\n",
       "                      -2.7483e-03,  1.0863e-02,  3.8898e-02, -2.4596e-02,  6.0935e-03,\n",
       "                      -2.9736e-02, -1.3506e-03,  2.2078e-02, -4.0607e-02,  1.0178e-02,\n",
       "                       1.5563e-02,  3.4041e-02, -3.2595e-02, -2.3743e-02,  3.5603e-02,\n",
       "                       4.0861e-05,  1.2753e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.in_proj_weight',\n",
       "              tensor([[-0.0510,  0.0235,  0.0390,  ...,  0.0022, -0.0389,  0.0308],\n",
       "                      [-0.0576,  0.1312,  0.0614,  ..., -0.0323, -0.0187,  0.0050],\n",
       "                      [ 0.0004,  0.0592, -0.0743,  ..., -0.0778, -0.0405,  0.0197],\n",
       "                      ...,\n",
       "                      [ 0.0793, -0.0213, -0.0250,  ..., -0.0374,  0.0299, -0.0058],\n",
       "                      [ 0.0236,  0.0140, -0.1080,  ..., -0.0605,  0.1349, -0.0244],\n",
       "                      [ 0.0547, -0.0423, -0.0525,  ...,  0.0670, -0.0364,  0.1099]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.in_proj_bias',\n",
       "              tensor([ 1.5719e-02, -6.5023e-02, -7.4259e-02, -3.2016e-02, -1.2725e-02,\n",
       "                      -1.6205e-02,  2.7985e-02,  4.2385e-02,  8.4327e-02, -4.9016e-02,\n",
       "                      -6.6608e-03, -1.7063e-03,  1.2185e-01,  1.1178e-01,  2.0014e-02,\n",
       "                       4.9659e-02,  1.0708e-01,  1.8618e-01,  1.7622e-01,  5.4289e-02,\n",
       "                       8.4650e-02,  1.2694e-03, -6.8204e-03, -1.7957e-01,  4.0825e-02,\n",
       "                      -5.8345e-02,  2.0193e-02, -1.4281e-01,  9.9162e-02,  1.6082e-02,\n",
       "                       3.8716e-03,  9.5413e-02,  2.1360e-02,  8.1995e-02, -3.2427e-03,\n",
       "                      -6.2873e-02,  5.1095e-02, -4.6009e-02,  4.1415e-02,  1.3450e-01,\n",
       "                       5.7405e-02, -1.6322e-01,  1.6365e-01, -1.0268e-01, -1.6924e-01,\n",
       "                       4.0478e-04,  1.1233e-01,  5.2837e-02, -4.8728e-02, -9.0370e-02,\n",
       "                       1.9675e-01,  1.4328e-01, -1.2257e-01,  1.1671e-01, -2.0108e-01,\n",
       "                      -5.3182e-02, -8.8471e-02,  9.9866e-02, -1.1494e-01,  1.8033e-01,\n",
       "                      -2.4498e-02,  1.4649e-01,  1.2888e-01, -1.3570e-01, -5.3837e-02,\n",
       "                       1.4408e-01,  1.2218e-01, -1.6364e-01,  1.6133e-01,  8.3091e-02,\n",
       "                      -1.6595e-01, -1.8332e-01,  1.5886e-02,  1.6835e-01, -9.5366e-02,\n",
       "                       2.0251e-01, -3.4824e-02,  1.7640e-01,  1.4353e-01,  1.4627e-01,\n",
       "                       8.7901e-02,  1.5454e-01, -5.5306e-02,  8.3272e-02, -1.8956e-01,\n",
       "                      -5.8504e-02,  6.4809e-02, -1.0490e-01,  1.4487e-01, -1.4120e-01,\n",
       "                       1.9036e-01, -1.5010e-01, -1.6259e-01, -1.1575e-02,  5.8022e-02,\n",
       "                       1.0943e-01,  1.2804e-01,  9.0255e-02,  6.8738e-02, -4.1632e-02,\n",
       "                       7.5363e-02,  5.9557e-02,  5.6483e-03,  8.4279e-02, -6.2927e-02,\n",
       "                      -9.7351e-02,  2.4894e-02, -3.0917e-02,  6.0600e-02, -1.3552e-01,\n",
       "                       2.6484e-02,  7.5328e-02,  3.3857e-02,  1.6079e-02,  6.9198e-02,\n",
       "                      -5.9800e-02,  1.2569e-01, -3.3195e-03,  7.0211e-02, -2.0361e-02,\n",
       "                      -2.3659e-02, -6.8085e-02, -8.2717e-03, -9.2561e-02,  6.4189e-02,\n",
       "                       5.4724e-02, -2.5061e-02, -6.9251e-02, -1.1177e-03, -1.5826e-02,\n",
       "                      -1.5914e-02, -1.4413e-02,  1.2587e-01,  1.4106e-01, -3.5848e-02,\n",
       "                       3.1298e-04,  4.9775e-02, -1.9188e-02,  5.2998e-03,  5.6199e-02,\n",
       "                      -3.0183e-02, -4.1522e-02,  5.5708e-02,  9.6429e-02,  1.0489e-01,\n",
       "                       1.8989e-01,  2.3053e-01,  5.4516e-03, -1.4345e-02,  6.4166e-02,\n",
       "                       8.1795e-02,  3.2163e-02, -1.9433e-01, -1.7814e-01,  1.5610e-01,\n",
       "                       4.6796e-02,  1.6577e-01, -1.7953e-01,  1.9409e-01, -3.2803e-02,\n",
       "                      -9.1183e-03, -1.3341e-01, -8.4511e-02,  1.3134e-01, -1.7424e-01,\n",
       "                      -7.4281e-02, -2.2600e-01,  1.0690e-01,  1.5900e-01,  1.0985e-01,\n",
       "                      -1.8252e-01,  6.8460e-02,  9.5344e-02, -7.9874e-02, -5.5933e-02,\n",
       "                      -1.1369e-02, -6.6311e-02, -1.5390e-01, -1.0869e-01,  2.5441e-02,\n",
       "                      -2.2509e-01,  1.0533e-01,  2.0403e-02, -1.1195e-01, -2.2535e-01,\n",
       "                       2.9697e-03,  3.1386e-02, -2.9968e-03,  3.7162e-02,  5.4720e-02,\n",
       "                      -1.1231e-01,  1.4205e-01, -6.5057e-06, -7.0764e-06,  3.7421e-06,\n",
       "                      -2.0166e-06, -1.2356e-05, -2.5593e-06, -3.1904e-06,  4.6997e-06,\n",
       "                      -7.7547e-06, -1.9689e-06, -1.0125e-05, -1.1658e-05, -1.0043e-05,\n",
       "                       1.4630e-05, -4.9768e-06,  7.2710e-07, -4.1527e-07, -5.7933e-06,\n",
       "                      -8.6928e-06,  7.2949e-06, -1.4098e-05, -7.5106e-06,  9.2135e-06,\n",
       "                       5.1398e-06, -1.5048e-06, -6.7764e-06,  7.6130e-07,  5.3331e-06,\n",
       "                      -1.3136e-06, -7.1179e-06, -7.4296e-06, -7.5033e-06, -5.0354e-06,\n",
       "                       2.3946e-06, -7.1851e-06, -3.7053e-06,  2.8297e-06, -2.2827e-06,\n",
       "                      -5.3683e-06,  3.3629e-06, -1.3121e-06, -7.6834e-06,  4.8597e-07,\n",
       "                      -5.3724e-06,  5.7536e-06, -7.2392e-06, -1.0158e-05, -5.1635e-07,\n",
       "                      -1.5685e-06,  8.0575e-06, -8.6190e-06, -4.0266e-06,  2.1771e-06,\n",
       "                       6.1807e-06, -1.0185e-05,  1.4256e-06, -6.6482e-06, -9.3988e-07,\n",
       "                       1.0484e-05,  6.2684e-06, -2.4461e-06,  1.2868e-06,  3.3807e-06,\n",
       "                      -9.6079e-06, -1.0451e-06,  5.6985e-06,  3.8938e-06,  1.5543e-06,\n",
       "                      -6.1950e-06,  4.7622e-06,  4.9368e-06,  5.3637e-06, -1.9757e-06,\n",
       "                       7.1534e-06,  9.4358e-06, -1.5044e-06, -7.6798e-06,  3.1864e-06,\n",
       "                      -3.3255e-06,  8.5677e-06,  1.8699e-06,  9.3920e-06,  4.2862e-06,\n",
       "                       3.6217e-06,  2.0951e-05,  5.9336e-06, -4.4011e-06, -1.2528e-05,\n",
       "                       1.5726e-05,  4.2865e-06, -8.0846e-06,  1.6137e-06, -5.2794e-06,\n",
       "                       3.8477e-06, -3.0863e-06,  1.4422e-06, -1.8195e-06, -2.7978e-06,\n",
       "                      -3.4908e-06,  3.9427e-06,  1.0204e-05, -4.6609e-07, -1.4795e-06,\n",
       "                       3.4507e-06, -1.5536e-06, -1.5025e-06, -3.8499e-06,  5.5031e-07,\n",
       "                      -2.5372e-06, -6.6340e-06, -6.9294e-06, -1.9167e-07, -1.9270e-06,\n",
       "                      -1.1534e-06,  2.3052e-06,  5.4208e-06,  8.7959e-07,  6.5298e-07,\n",
       "                       7.5313e-08,  2.5505e-06,  2.3096e-06,  8.8688e-06,  4.4825e-06,\n",
       "                       1.7142e-06, -5.5938e-06,  8.1063e-07, -1.6574e-07,  4.8960e-06,\n",
       "                       5.1882e-06, -7.9997e-06, -5.0402e-06, -8.2934e-06,  6.3917e-06,\n",
       "                       4.9754e-06,  6.7534e-06,  5.0178e-06, -1.7724e-06,  7.4930e-07,\n",
       "                      -6.2737e-06, -1.3607e-06,  6.1511e-07,  3.1505e-07,  5.0712e-07,\n",
       "                      -8.6979e-07,  3.1747e-07,  8.9290e-06, -3.5459e-07, -1.0801e-05,\n",
       "                      -1.1407e-05,  9.3820e-06, -5.8160e-07, -3.8076e-06, -9.3735e-06,\n",
       "                       4.5460e-06,  8.2010e-06,  2.8333e-06,  1.5056e-08, -1.2404e-05,\n",
       "                      -3.8821e-06, -3.2701e-07, -1.8181e-06, -6.9650e-06, -6.7588e-06,\n",
       "                      -1.7403e-06,  2.1445e-06,  3.8730e-06, -1.3280e-06,  3.7354e-06,\n",
       "                       1.1475e-05,  5.1851e-06, -2.6614e-06, -2.1292e-07,  5.7815e-07,\n",
       "                      -7.2227e-06,  4.9871e-06, -9.2567e-07, -4.4973e-06, -2.3517e-06,\n",
       "                      -1.2250e-06,  5.6164e-06,  5.9067e-06,  5.9379e-06,  4.6954e-06,\n",
       "                       6.9731e-07, -4.3795e-07, -2.2880e-06,  7.7874e-06, -5.1595e-06,\n",
       "                      -1.7105e-06, -5.5070e-06,  5.7244e-06,  5.4474e-06,  3.0089e-02,\n",
       "                       1.1338e-02,  3.9437e-02,  1.7516e-02,  1.7094e-03, -1.8524e-02,\n",
       "                       2.3037e-02, -4.1646e-02, -2.9902e-02,  1.4140e-02, -1.8229e-02,\n",
       "                       2.9954e-02, -6.1651e-03, -1.0826e-02,  3.9289e-02, -1.8914e-02,\n",
       "                      -4.3496e-02, -2.1388e-02,  2.5527e-02, -1.4475e-03, -3.5708e-02,\n",
       "                      -1.0787e-02,  2.8714e-02, -3.8172e-02, -1.9748e-02, -5.1771e-02,\n",
       "                       4.1120e-02, -5.5818e-02,  4.0496e-02,  5.4719e-02,  1.7898e-02,\n",
       "                      -1.6385e-02,  3.8480e-02, -6.0435e-02, -4.2043e-02,  1.4359e-02,\n",
       "                       3.5543e-02, -9.7380e-03, -6.5012e-03, -8.0451e-03, -4.4921e-03,\n",
       "                       1.0385e-02, -3.3786e-03,  7.0143e-02, -1.2088e-02,  9.3490e-03,\n",
       "                       6.8397e-03, -3.3300e-02,  4.8289e-02, -1.2607e-02,  4.5281e-02,\n",
       "                       4.0373e-02, -4.3526e-02, -8.5757e-03,  1.6170e-02, -4.7732e-02,\n",
       "                       5.9965e-03, -2.2384e-02,  2.7536e-02,  3.4251e-02, -4.3974e-02,\n",
       "                      -2.2144e-02,  5.8228e-03,  1.9570e-02, -4.9301e-02,  2.2661e-02,\n",
       "                       2.4072e-02, -3.3470e-02,  2.3383e-02, -2.6210e-02,  4.9462e-03,\n",
       "                       1.4282e-02, -1.5927e-02, -2.7038e-02,  1.0392e-02, -1.4839e-02,\n",
       "                      -1.1217e-02, -1.5057e-02,  2.9870e-02,  4.1216e-02, -3.2408e-02,\n",
       "                      -1.4546e-02, -5.5052e-02, -2.4855e-02,  4.1109e-02,  2.6727e-02,\n",
       "                       3.1205e-02, -2.5827e-02,  6.7742e-03, -1.2371e-02,  4.5097e-02,\n",
       "                       1.4142e-02,  2.5086e-02,  3.9702e-03, -2.9593e-02, -1.8877e-02,\n",
       "                       2.9677e-02,  2.1262e-02,  1.2180e-02,  4.0362e-02,  5.3087e-02,\n",
       "                       1.4109e-02, -2.5317e-02,  5.1055e-02, -2.2661e-02, -4.1945e-02,\n",
       "                      -5.4231e-02, -1.4030e-02, -1.9288e-02, -6.7270e-03,  4.3133e-03,\n",
       "                      -5.0349e-02,  5.0856e-02,  3.8530e-02,  2.0852e-02,  4.9339e-02,\n",
       "                      -1.9208e-02,  3.5886e-02,  1.1789e-02, -2.3316e-02,  2.9358e-02,\n",
       "                      -3.0367e-02,  2.1460e-02, -2.9498e-02, -1.1441e-02,  3.7770e-02,\n",
       "                       4.0026e-02, -3.9712e-02, -1.1151e-02, -4.9935e-02, -2.9651e-02,\n",
       "                      -1.1969e-02, -1.0445e-02,  1.9312e-02,  5.9869e-02,  4.3904e-02,\n",
       "                      -1.9319e-02, -4.9591e-02,  1.4821e-02, -2.2988e-02, -2.5593e-03,\n",
       "                       2.1945e-02,  1.1452e-02,  2.5535e-02,  2.5589e-03, -4.1116e-02,\n",
       "                      -4.6135e-03,  2.0691e-02, -6.2429e-03,  8.9878e-03,  5.2409e-03,\n",
       "                      -3.8400e-02, -7.2674e-03,  5.8039e-04,  1.3122e-02, -3.9467e-02,\n",
       "                      -2.0036e-02,  3.9264e-02, -2.0630e-02, -1.7365e-02, -2.7057e-03,\n",
       "                       9.6599e-03, -2.2532e-03,  1.6172e-02, -2.0917e-02,  2.0165e-02,\n",
       "                      -3.7379e-02,  1.0594e-02, -5.3276e-03,  1.7460e-02,  1.4661e-02,\n",
       "                      -1.3612e-03, -1.3143e-02, -3.8006e-03,  4.4998e-02,  2.1867e-02,\n",
       "                       3.3483e-02, -3.4989e-03,  1.8276e-02,  9.6856e-03,  1.0981e-02,\n",
       "                      -2.9643e-02,  4.7454e-03, -4.4657e-02,  2.6200e-02, -2.2193e-02,\n",
       "                      -1.6045e-02, -1.1433e-02, -1.4035e-02,  1.4923e-02, -3.3914e-03,\n",
       "                      -8.7830e-03], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.out_proj.weight',\n",
       "              tensor([[-0.0264, -0.0084,  0.0109,  ..., -0.0427,  0.1266,  0.0344],\n",
       "                      [-0.0119,  0.0977, -0.0310,  ..., -0.0671, -0.0113,  0.0943],\n",
       "                      [-0.0424, -0.1197,  0.0708,  ...,  0.0140,  0.0529,  0.0096],\n",
       "                      ...,\n",
       "                      [-0.0667,  0.0559, -0.0101,  ..., -0.0844, -0.0235,  0.0197],\n",
       "                      [ 0.0158,  0.0050,  0.0737,  ..., -0.0350, -0.0613, -0.0410],\n",
       "                      [ 0.0093,  0.0534, -0.0330,  ..., -0.0644, -0.0587, -0.0672]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.out_proj.bias',\n",
       "              tensor([ 2.0904e-02, -3.6296e-02, -7.8835e-03, -5.1018e-03, -2.2020e-02,\n",
       "                       1.8243e-02,  2.0913e-03, -3.3842e-02,  2.6335e-02,  9.0636e-03,\n",
       "                      -1.5588e-03,  3.0777e-03, -5.7296e-03, -1.8244e-02,  1.6449e-02,\n",
       "                      -3.7050e-03, -2.6354e-03, -3.5835e-03,  9.1720e-03,  2.6901e-02,\n",
       "                      -2.1391e-02,  1.7155e-03,  8.0978e-03,  5.0808e-03, -8.1524e-03,\n",
       "                      -5.3720e-03, -9.1375e-04,  2.8753e-02,  2.8714e-02,  7.4894e-03,\n",
       "                      -2.3505e-02,  2.6058e-03, -2.7097e-02, -1.7899e-02, -4.0675e-02,\n",
       "                      -1.7815e-02, -9.6137e-04,  9.1175e-03, -1.8800e-03,  1.7129e-02,\n",
       "                      -1.7099e-02, -4.9817e-03, -2.2179e-02, -2.5716e-03, -4.6505e-02,\n",
       "                      -1.4379e-03, -1.8797e-02,  7.4819e-03, -1.9169e-02,  3.2904e-03,\n",
       "                      -7.3656e-03,  3.7000e-03,  2.4859e-03, -6.6691e-05, -5.6468e-03,\n",
       "                       4.1991e-02, -3.5084e-02,  1.1769e-03,  2.1795e-02,  2.1057e-02,\n",
       "                       2.5820e-02,  1.8087e-02,  1.5780e-02,  3.4255e-02, -4.2019e-02,\n",
       "                      -2.0092e-03, -3.3550e-02, -7.3025e-05, -1.6785e-02, -3.0603e-04,\n",
       "                       8.4711e-03,  3.7302e-02, -1.1655e-02, -1.6676e-02, -1.0991e-02,\n",
       "                       2.4692e-02,  1.2275e-03,  5.0395e-03, -8.7636e-03,  1.6138e-02,\n",
       "                       1.4094e-02,  5.4869e-03, -2.3130e-02,  3.3993e-02, -4.6707e-03,\n",
       "                       3.9233e-02, -1.9759e-02,  8.0727e-02, -2.6531e-02, -2.6402e-02,\n",
       "                      -4.5838e-03,  1.3373e-02, -2.8444e-03,  1.9404e-02,  1.1335e-02,\n",
       "                       3.7114e-02,  3.7549e-03,  1.2272e-02,  5.1075e-03,  6.8545e-03,\n",
       "                      -6.1033e-03,  2.2125e-03, -9.9100e-03,  1.5353e-02, -4.2213e-02,\n",
       "                       2.4608e-02,  2.4468e-02,  2.6330e-02, -2.0711e-02,  2.1468e-02,\n",
       "                       2.0510e-02, -7.7880e-03,  1.6115e-02, -1.7265e-03, -3.0733e-02,\n",
       "                       2.7025e-02,  4.3766e-03,  2.2566e-02, -4.3188e-03, -6.6172e-03,\n",
       "                       5.5764e-03, -2.6051e-03,  1.9897e-02,  3.6237e-02, -1.8636e-02,\n",
       "                       2.6804e-02, -4.2881e-03,  1.0497e-02,  9.7343e-03,  4.3110e-02,\n",
       "                      -2.0788e-04,  2.7730e-02,  3.3249e-04,  4.4489e-03,  3.2401e-03,\n",
       "                       1.5728e-02, -1.3369e-02, -5.4831e-03, -4.5281e-03, -1.8961e-03,\n",
       "                      -2.5931e-02,  3.2226e-02, -2.3925e-02,  8.3698e-03, -2.1098e-02,\n",
       "                      -9.1900e-04,  4.9404e-03,  1.7156e-02,  1.2565e-02, -2.6390e-02,\n",
       "                      -2.3665e-02,  3.1074e-02, -1.7944e-02, -1.3680e-02, -4.7381e-02,\n",
       "                      -9.9717e-03,  1.9179e-02,  2.7189e-02, -2.1728e-03,  1.9534e-02,\n",
       "                      -3.2275e-02, -3.0420e-02, -4.7778e-03,  2.3953e-02, -1.6428e-02,\n",
       "                       2.1846e-02,  1.9485e-02,  3.5273e-02,  4.5470e-04,  1.6808e-02,\n",
       "                      -2.8650e-02,  8.0416e-03, -2.3454e-02,  4.0284e-02,  9.8438e-03,\n",
       "                      -2.9774e-02, -1.6604e-02,  4.0165e-02, -8.4055e-03, -4.4613e-03,\n",
       "                       8.2839e-03, -3.1439e-02,  5.1451e-03, -5.2206e-03,  5.6546e-03,\n",
       "                      -2.2619e-03, -1.6286e-02, -1.0356e-02, -3.1248e-02,  1.7470e-02,\n",
       "                      -2.0780e-02, -5.5476e-03], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear1.weight',\n",
       "              tensor([[ 0.0504,  0.0055, -0.0186,  ...,  0.0315, -0.0197,  0.0049],\n",
       "                      [-0.0415, -0.0060, -0.0021,  ...,  0.0308, -0.0030,  0.0122],\n",
       "                      [ 0.0020,  0.0323,  0.0387,  ..., -0.0270, -0.0628, -0.0952],\n",
       "                      ...,\n",
       "                      [-0.0364, -0.0565, -0.0524,  ...,  0.0619, -0.0237, -0.0261],\n",
       "                      [-0.0203,  0.0205,  0.0206,  ...,  0.0488,  0.0131, -0.0311],\n",
       "                      [-0.0199, -0.0565,  0.0026,  ...,  0.0409, -0.0237,  0.0592]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear1.bias',\n",
       "              tensor([-0.0242, -0.0738, -0.0703,  ..., -0.0637, -0.0254, -0.1045],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear2.weight',\n",
       "              tensor([[ 0.0407, -0.0163, -0.0402,  ...,  0.0033, -0.0159, -0.0044],\n",
       "                      [ 0.0535, -0.0424,  0.0337,  ..., -0.0392,  0.0355,  0.0015],\n",
       "                      [ 0.0340, -0.0130,  0.0208,  ..., -0.0171,  0.0216, -0.0292],\n",
       "                      ...,\n",
       "                      [ 0.0120,  0.0138, -0.0165,  ...,  0.0191, -0.0421, -0.0044],\n",
       "                      [ 0.0430, -0.0357,  0.0194,  ...,  0.0337, -0.0402,  0.0631],\n",
       "                      [ 0.0117,  0.0087,  0.0234,  ...,  0.0453, -0.0381, -0.0415]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear2.bias',\n",
       "              tensor([-0.0593,  0.0648,  0.0023,  0.0535,  0.0226,  0.0122,  0.0188,  0.0426,\n",
       "                      -0.0361, -0.0361,  0.0128,  0.0045, -0.0443,  0.0586, -0.0031,  0.0337,\n",
       "                       0.0360,  0.0098, -0.0133, -0.0164,  0.0541,  0.0435,  0.0094,  0.0255,\n",
       "                       0.0196,  0.0554, -0.0191, -0.0200, -0.0528,  0.0335,  0.0294, -0.0343,\n",
       "                      -0.0021,  0.0031,  0.0313,  0.0388, -0.0150,  0.0062,  0.0072, -0.0646,\n",
       "                       0.0396,  0.0384, -0.0321,  0.0113,  0.0357, -0.0401,  0.0092,  0.0107,\n",
       "                       0.0265, -0.0070, -0.0185,  0.0216,  0.0243, -0.0265,  0.0465, -0.0569,\n",
       "                       0.0457,  0.0141, -0.0238, -0.0367, -0.0237, -0.0651, -0.0339, -0.0417,\n",
       "                       0.0720,  0.0034,  0.0097, -0.0270, -0.0034, -0.0080, -0.0257, -0.0237,\n",
       "                       0.0390,  0.0051,  0.0313, -0.0394,  0.0031, -0.0124,  0.0261, -0.0414,\n",
       "                       0.0210, -0.0075, -0.0165, -0.0097,  0.0019, -0.0256,  0.0557, -0.0994,\n",
       "                       0.0632,  0.0436,  0.0091,  0.0008,  0.0108, -0.0382, -0.0076, -0.0345,\n",
       "                      -0.0041, -0.0655, -0.0157,  0.0029,  0.0295,  0.0089, -0.0063, -0.0376,\n",
       "                       0.0347, -0.0009,  0.0025, -0.0151,  0.0502, -0.0274, -0.0101, -0.0190,\n",
       "                      -0.0305,  0.0292,  0.0388, -0.0833,  0.0431, -0.0566,  0.0625, -0.0125,\n",
       "                      -0.0343, -0.0196, -0.0432, -0.0851,  0.0098, -0.0447,  0.0360, -0.0172,\n",
       "                       0.0253, -0.0719,  0.0321, -0.0618,  0.0097, -0.0004,  0.0162,  0.0122,\n",
       "                      -0.0092, -0.0200, -0.0183, -0.0253,  0.0440, -0.0472,  0.0652, -0.0365,\n",
       "                       0.0265, -0.0083, -0.0130, -0.0326, -0.0118,  0.0450,  0.0297, -0.0418,\n",
       "                       0.0632, -0.0308,  0.0790,  0.0477,  0.0165, -0.0370,  0.0019, -0.0569,\n",
       "                       0.0397,  0.0545, -0.0142, -0.0424,  0.0241, -0.0529,  0.0214, -0.0698,\n",
       "                      -0.0014, -0.0665,  0.0320, -0.0298,  0.0085, -0.0479, -0.0221,  0.0115,\n",
       "                       0.0378, -0.0738,  0.0567, -0.0145,  0.0060, -0.0011, -0.0271,  0.0269,\n",
       "                       0.0256, -0.0158, -0.0002,  0.0308,  0.0350, -0.0646,  0.0467,  0.0217],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm1.weight',\n",
       "              tensor([1.0122, 1.0732, 1.0125, 1.0210, 1.0419, 1.0138, 0.9997, 0.9772, 0.9951,\n",
       "                      1.0300, 0.9524, 1.0194, 0.9656, 1.0051, 0.9797, 1.0167, 1.0122, 0.9929,\n",
       "                      0.9762, 0.9869, 1.0062, 1.0185, 1.0091, 1.0150, 0.9800, 1.0136, 0.9989,\n",
       "                      0.9809, 1.0030, 0.9640, 0.9693, 0.9960, 0.9668, 1.0201, 0.9832, 0.9945,\n",
       "                      0.9349, 0.9979, 0.9513, 1.0317, 0.9487, 1.0099, 0.9532, 1.0094, 0.9604,\n",
       "                      0.9876, 0.9999, 0.9870, 0.9991, 0.9716, 0.9971, 0.9631, 1.0068, 0.9360,\n",
       "                      1.0292, 0.9317, 1.0063, 0.9248, 1.0179, 0.9477, 1.0142, 0.9318, 1.0214,\n",
       "                      0.9137, 1.0768, 0.9036, 1.0288, 0.8940, 1.0545, 0.8833, 1.0464, 0.9185,\n",
       "                      1.0753, 0.9014, 1.0653, 0.9105, 1.0339, 0.9169, 1.0686, 0.9421, 1.0594,\n",
       "                      0.9258, 0.9851, 0.9194, 1.0410, 0.9125, 1.0941, 0.9806, 1.0655, 0.8837,\n",
       "                      1.0784, 0.9110, 1.0630, 0.9186, 1.0332, 0.9188, 1.0714, 0.8587, 1.0477,\n",
       "                      0.8790, 1.0546, 0.9161, 1.0712, 0.8889, 1.0803, 0.9000, 1.0678, 0.9159,\n",
       "                      1.0430, 0.8937, 1.0413, 0.9287, 1.0302, 0.8803, 1.0467, 0.9223, 1.0748,\n",
       "                      0.9033, 1.0590, 0.9242, 1.0510, 0.9030, 1.1041, 0.9772, 1.0555, 0.9036,\n",
       "                      1.0430, 0.9185, 1.0606, 0.9328, 1.0745, 0.8873, 1.0444, 0.9406, 1.0735,\n",
       "                      0.9098, 1.0662, 0.9133, 1.0484, 0.9219, 1.0408, 0.9180, 1.0523, 0.9104,\n",
       "                      1.0890, 0.9043, 1.0655, 0.9031, 1.0411, 0.8859, 1.0664, 0.9345, 1.0536,\n",
       "                      0.9042, 1.0687, 0.9107, 1.0676, 0.9206, 1.0770, 0.9249, 1.0646, 0.9140,\n",
       "                      1.0554, 0.9444, 1.0579, 0.8974, 1.0733, 0.9318, 1.0696, 0.9192, 1.0699,\n",
       "                      0.9183, 1.0461, 0.8980, 1.0579, 0.9057, 1.0620, 0.9138, 1.0648, 0.9078,\n",
       "                      1.0314, 0.8800, 1.0751, 0.8980, 1.0852, 0.9375, 1.0621, 0.9114, 1.0517,\n",
       "                      0.9108, 1.0575, 0.8997], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm1.bias',\n",
       "              tensor([ 0.1107, -0.1105,  0.0496, -0.0711, -0.0341, -0.0068, -0.0040, -0.0071,\n",
       "                       0.1108,  0.0745, -0.0282,  0.0257, -0.0214, -0.0482,  0.0447, -0.0122,\n",
       "                      -0.0516,  0.0527,  0.0271,  0.1116, -0.0979, -0.0502, -0.0666, -0.0212,\n",
       "                      -0.0298,  0.0120,  0.0105, -0.0026,  0.1012, -0.0616, -0.0766, -0.0177,\n",
       "                      -0.0647, -0.0232, -0.1045, -0.1019, -0.0128, -0.0210,  0.0015,  0.0742,\n",
       "                      -0.1152, -0.0361, -0.0178, -0.0401, -0.1391,  0.0491,  0.0402,  0.0449,\n",
       "                      -0.0142, -0.0738,  0.0123, -0.0344, -0.0853,  0.0185, -0.0318,  0.1416,\n",
       "                      -0.0769,  0.0086,  0.0450,  0.0627,  0.0608,  0.0846,  0.0451,  0.0763,\n",
       "                      -0.1909, -0.0391, -0.0807,  0.0162, -0.0203, -0.0602,  0.0529,  0.0860,\n",
       "                      -0.0598, -0.0744, -0.0359,  0.0775, -0.0142,  0.0135, -0.0017,  0.0920,\n",
       "                       0.0179, -0.0025,  0.0311,  0.1181, -0.0474,  0.0281, -0.1158,  0.2363,\n",
       "                      -0.1158, -0.0379, -0.0127,  0.0199,  0.0235,  0.1015,  0.1062,  0.1071,\n",
       "                       0.0157,  0.0700,  0.0134, -0.0070, -0.0442, -0.0338, -0.0091,  0.0182,\n",
       "                      -0.1253,  0.0119,  0.0025,  0.0746, -0.0627,  0.0907,  0.0853,  0.0460,\n",
       "                       0.0127, -0.0586, -0.0785,  0.0717, -0.0135,  0.1364, -0.0514, -0.0420,\n",
       "                       0.0746,  0.0532,  0.0724,  0.0705,  0.0064,  0.0954, -0.0350, -0.0228,\n",
       "                      -0.0019,  0.1074, -0.0501,  0.1210, -0.0309, -0.0090,  0.0117,  0.0397,\n",
       "                      -0.0191,  0.0781,  0.0157, -0.0224, -0.0531,  0.1213, -0.0753,  0.0318,\n",
       "                      -0.0489, -0.0286, -0.0240,  0.0443,  0.0576, -0.0560, -0.0525,  0.0670,\n",
       "                      -0.0253,  0.0133, -0.1166, -0.0552,  0.0496,  0.0752,  0.0044,  0.0562,\n",
       "                      -0.0612, -0.0961,  0.0582,  0.1190, -0.0170,  0.0406, -0.0037,  0.0483,\n",
       "                      -0.0307,  0.0424, -0.0927,  0.0434, -0.0154,  0.0824,  0.0781, -0.0372,\n",
       "                      -0.0501,  0.0865, -0.0628,  0.0427, -0.0351, -0.0664,  0.0587, -0.0522,\n",
       "                      -0.0056,  0.0581,  0.0198, -0.0723, -0.1109,  0.0646, -0.0722,  0.0223],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm2.weight',\n",
       "              tensor([1.0179, 1.0780, 1.0126, 1.0245, 1.0368, 1.0148, 1.0004, 0.9973, 0.9954,\n",
       "                      1.0242, 0.9610, 1.0176, 0.9661, 1.0038, 0.9771, 1.0069, 1.0138, 0.9862,\n",
       "                      0.9822, 0.9989, 1.0134, 1.0158, 1.0164, 1.0063, 0.9849, 1.0131, 0.9946,\n",
       "                      0.9769, 1.0073, 0.9663, 0.9743, 1.0026, 0.9754, 1.0182, 1.0050, 1.0075,\n",
       "                      0.9494, 0.9891, 0.9623, 1.0261, 0.9676, 1.0208, 0.9640, 1.0114, 0.9900,\n",
       "                      0.9900, 1.0026, 0.9848, 0.9980, 0.9749, 1.0175, 0.9707, 1.0124, 0.9466,\n",
       "                      1.0244, 0.9471, 1.0200, 0.9237, 1.0246, 0.9495, 1.0107, 0.9368, 1.0245,\n",
       "                      0.9377, 1.0849, 0.9113, 1.0276, 0.9026, 1.0566, 0.9028, 1.0459, 0.9296,\n",
       "                      1.0689, 0.9119, 1.0572, 0.9257, 1.0365, 0.9196, 1.0682, 0.9518, 1.0529,\n",
       "                      0.9270, 0.9998, 0.9432, 1.0373, 0.9161, 1.0907, 1.0134, 1.0677, 0.8848,\n",
       "                      1.0799, 0.8987, 1.0636, 0.9392, 1.0497, 0.9317, 1.0644, 0.9099, 1.0361,\n",
       "                      0.9083, 1.0636, 0.9178, 1.0551, 0.9057, 1.0758, 0.9163, 1.0595, 0.9243,\n",
       "                      1.0533, 0.9081, 1.0497, 0.9409, 1.0353, 0.9191, 1.0395, 0.9340, 1.0625,\n",
       "                      0.9380, 1.0580, 0.9292, 1.0476, 0.9215, 1.0977, 0.9766, 1.0637, 0.9124,\n",
       "                      1.0480, 0.9320, 1.0593, 0.9379, 1.0677, 0.9058, 1.0523, 0.9471, 1.0738,\n",
       "                      0.9203, 1.0599, 0.9117, 1.0487, 0.9261, 1.0460, 0.9576, 1.0513, 0.9157,\n",
       "                      1.0760, 0.9118, 1.0646, 0.9294, 1.0426, 0.9058, 1.0636, 0.9399, 1.0513,\n",
       "                      0.9161, 1.0795, 0.9241, 1.0698, 0.9350, 1.0667, 0.9393, 1.0637, 0.9291,\n",
       "                      1.0588, 0.9559, 1.0590, 0.9056, 1.0649, 0.9282, 1.0616, 0.9335, 1.0678,\n",
       "                      0.9228, 1.0520, 0.9031, 1.0559, 0.9199, 1.0595, 0.9272, 1.0650, 0.9128,\n",
       "                      1.0262, 0.9000, 1.0648, 0.8981, 1.0777, 0.9428, 1.0665, 0.9076, 1.0513,\n",
       "                      0.9087, 1.0690, 0.9085], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm2.bias',\n",
       "              tensor([ 0.1014, -0.1061,  0.0455, -0.0666, -0.0225, -0.0088, -0.0059, -0.0009,\n",
       "                       0.0996,  0.0780, -0.0276,  0.0248, -0.0255, -0.0378,  0.0368, -0.0152,\n",
       "                      -0.0538,  0.0463,  0.0192,  0.1225, -0.0884, -0.0507, -0.0788, -0.0237,\n",
       "                      -0.0378,  0.0237,  0.0039, -0.0089,  0.0932, -0.0682, -0.0835, -0.0252,\n",
       "                      -0.0596, -0.0267, -0.1022, -0.1000, -0.0265, -0.0375, -0.0025,  0.0681,\n",
       "                      -0.1205, -0.0338, -0.0247, -0.0453, -0.1385,  0.0407,  0.0401,  0.0434,\n",
       "                      -0.0108, -0.0830,  0.0135, -0.0395, -0.0824,  0.0023, -0.0366,  0.1196,\n",
       "                      -0.0691,  0.0036,  0.0386,  0.0525,  0.0614,  0.0708,  0.0419,  0.0557,\n",
       "                      -0.1815, -0.0453, -0.0672,  0.0109, -0.0235, -0.0705,  0.0541,  0.0686,\n",
       "                      -0.0597, -0.0829, -0.0309,  0.0649, -0.0150,  0.0047,  0.0010,  0.0715,\n",
       "                       0.0136, -0.0232,  0.0495,  0.1002, -0.0482,  0.0010, -0.1133,  0.2212,\n",
       "                      -0.1045, -0.0366, -0.0113, -0.0070,  0.0272,  0.0853,  0.1088,  0.0785,\n",
       "                       0.0104,  0.0586,  0.0203, -0.0089, -0.0409, -0.0498, -0.0135,  0.0030,\n",
       "                      -0.1149, -0.0031, -0.0124,  0.0541, -0.0558,  0.0746,  0.0801,  0.0359,\n",
       "                       0.0117, -0.0725, -0.0714,  0.0500, -0.0162,  0.1242, -0.0445, -0.0558,\n",
       "                       0.0707,  0.0431,  0.0680,  0.0546,  0.0152,  0.0749, -0.0323, -0.0346,\n",
       "                      -0.0044,  0.0859, -0.0531,  0.1042, -0.0277, -0.0171,  0.0126,  0.0321,\n",
       "                      -0.0116,  0.0734,  0.0210, -0.0457, -0.0493,  0.0997, -0.0695,  0.0197,\n",
       "                      -0.0376, -0.0389, -0.0258,  0.0323,  0.0549, -0.0537, -0.0480,  0.0431,\n",
       "                      -0.0185,  0.0071, -0.1089, -0.0722,  0.0471,  0.0525,  0.0004,  0.0380,\n",
       "                      -0.0500, -0.0884,  0.0599,  0.1011, -0.0150,  0.0241, -0.0125,  0.0295,\n",
       "                      -0.0248,  0.0204, -0.0919,  0.0168, -0.0124,  0.0682,  0.0804, -0.0443,\n",
       "                      -0.0452,  0.0596, -0.0648,  0.0405, -0.0365, -0.0617,  0.0548, -0.0661,\n",
       "                      -0.0099,  0.0466,  0.0256, -0.0793, -0.1022,  0.0429, -0.0657,  0.0170],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm3.weight',\n",
       "              tensor([0.9704, 0.9299, 0.9906, 0.9871, 0.9566, 1.0009, 0.9909, 0.9906, 0.9556,\n",
       "                      0.9729, 0.9873, 0.9965, 0.9713, 1.0177, 0.9836, 1.0138, 0.9997, 1.0266,\n",
       "                      0.9871, 0.9951, 1.0052, 0.9767, 1.0150, 1.0148, 0.9912, 0.9958, 0.9466,\n",
       "                      0.9665, 0.9432, 0.9599, 1.0083, 0.9962, 0.9882, 1.0278, 0.9524, 1.0219,\n",
       "                      0.9347, 1.0097, 1.0020, 1.0014, 1.0170, 1.0301, 0.9876, 1.0356, 0.9579,\n",
       "                      1.0341, 1.0085, 0.9933, 1.0325, 0.9722, 0.9999, 1.0307, 1.0152, 0.9656,\n",
       "                      1.0010, 0.9552, 1.0033, 0.9582, 1.0234, 0.9963, 0.9959, 0.9948, 1.0433,\n",
       "                      0.9546, 0.9508, 0.9521, 1.0146, 0.9707, 1.0278, 0.9685, 1.0417, 0.9564,\n",
       "                      1.0150, 1.0045, 1.0417, 0.9766, 1.0236, 1.0021, 1.0576, 0.9780, 1.0302,\n",
       "                      0.9388, 0.9841, 0.9510, 1.0077, 1.0176, 1.0340, 0.8882, 0.9906, 0.9648,\n",
       "                      1.0379, 0.9292, 1.0169, 0.9412, 1.0340, 0.9455, 1.0523, 0.9684, 1.0751,\n",
       "                      0.9692, 1.0397, 0.9625, 1.0200, 0.9849, 1.0261, 0.9567, 1.0339, 0.9725,\n",
       "                      0.9883, 0.9726, 1.0254, 0.9565, 0.9767, 0.9881, 0.9972, 0.9585, 1.0063,\n",
       "                      0.9301, 1.0600, 0.9656, 1.0346, 0.9806, 1.0373, 0.9476, 1.0638, 0.9389,\n",
       "                      1.0426, 0.9996, 1.0355, 0.9510, 1.0236, 0.9602, 0.9650, 1.0166, 1.0684,\n",
       "                      0.9755, 1.0366, 0.9692, 1.0366, 0.9113, 0.9994, 0.9517, 1.0284, 0.9968,\n",
       "                      1.0168, 0.9740, 1.0417, 0.9682, 1.0064, 0.9483, 1.0214, 0.8978, 1.0285,\n",
       "                      1.0042, 0.9877, 0.9764, 1.0640, 0.9491, 1.0285, 0.9888, 1.0234, 0.9234,\n",
       "                      1.0143, 0.9336, 1.0299, 0.9573, 1.0374, 0.9343, 1.0366, 0.9737, 1.0612,\n",
       "                      0.9878, 1.0303, 0.9684, 1.0386, 0.9614, 1.0201, 0.9445, 1.0575, 0.9753,\n",
       "                      0.9903, 0.9470, 1.0381, 0.9586, 1.0582, 1.0133, 1.0631, 0.9656, 0.9376,\n",
       "                      0.9516, 1.0466, 0.9843], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm3.bias',\n",
       "              tensor([ 0.0529, -0.0911,  0.0329, -0.0132,  0.0664, -0.0029,  0.0616,  0.0147,\n",
       "                       0.0431,  0.1139,  0.0084,  0.0243,  0.1082, -0.0237,  0.0654, -0.0247,\n",
       "                      -0.0440,  0.0400,  0.0214,  0.0937, -0.0573, -0.0013, -0.0126,  0.0333,\n",
       "                      -0.0606,  0.0376,  0.0162,  0.0690,  0.0361, -0.0089, -0.0672,  0.0823,\n",
       "                      -0.0204, -0.0596, -0.0441, -0.0544, -0.0791, -0.0370, -0.0289,  0.0339,\n",
       "                      -0.0481, -0.0240,  0.0173, -0.0358, -0.0630,  0.0040,  0.0222, -0.0208,\n",
       "                      -0.0569, -0.0605,  0.0126, -0.0439, -0.0294, -0.0367, -0.0366,  0.0320,\n",
       "                      -0.0375, -0.0785,  0.0285,  0.0224,  0.0989, -0.0199,  0.0328,  0.0051,\n",
       "                      -0.0123, -0.0303, -0.0282, -0.0178,  0.0178, -0.0466,  0.0882,  0.0036,\n",
       "                       0.0284, -0.0623, -0.0882, -0.0007,  0.0608, -0.0239,  0.0135, -0.0408,\n",
       "                       0.0091, -0.0628,  0.0785,  0.0049, -0.0107, -0.0059, -0.0565,  0.0932,\n",
       "                      -0.0017, -0.0661, -0.0071, -0.0885,  0.0305,  0.0094,  0.0466, -0.0492,\n",
       "                       0.0611,  0.0378,  0.0952, -0.0158,  0.0466, -0.0963,  0.0065,  0.0155,\n",
       "                      -0.0525, -0.0753,  0.0405, -0.0970,  0.0085, -0.0202,  0.0352, -0.0183,\n",
       "                       0.1410, -0.0673,  0.0349, -0.0435,  0.0050,  0.0497,  0.0345, -0.0938,\n",
       "                       0.0698,  0.0010,  0.1195,  0.0386,  0.0402, -0.0186,  0.0223, -0.0609,\n",
       "                       0.0132,  0.0059, -0.0640,  0.0218,  0.1428, -0.0804,  0.0660, -0.0976,\n",
       "                      -0.0011, -0.0046,  0.1008, -0.1065,  0.0060, -0.0158, -0.0553, -0.0149,\n",
       "                       0.0440, -0.0690,  0.0309, -0.0206,  0.0804, -0.0607, -0.0064, -0.0962,\n",
       "                      -0.0244,  0.0118, -0.0059, -0.1390,  0.0514,  0.0225,  0.0490,  0.0075,\n",
       "                       0.0084, -0.0225,  0.0754, -0.0261, -0.0165,  0.0044,  0.0245, -0.0490,\n",
       "                      -0.0124,  0.0130, -0.0293, -0.0210,  0.0605, -0.0185,  0.1439, -0.1134,\n",
       "                       0.0602, -0.0202, -0.0148,  0.0211,  0.0202, -0.0560,  0.0824, -0.0446,\n",
       "                       0.0396, -0.0311,  0.0298, -0.0469, -0.0192, -0.0154, -0.0183, -0.0422],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.in_proj_weight',\n",
       "              tensor([[-0.1119,  0.0588,  0.0002,  ...,  0.0133, -0.0133,  0.0116],\n",
       "                      [ 0.0301, -0.0270, -0.1334,  ..., -0.0421,  0.0298, -0.0486],\n",
       "                      [-0.0188,  0.0825, -0.0291,  ..., -0.1244, -0.0764, -0.0075],\n",
       "                      ...,\n",
       "                      [ 0.0014,  0.0188,  0.0348,  ..., -0.0706,  0.0439,  0.0133],\n",
       "                      [-0.0917,  0.0005,  0.0726,  ...,  0.0730,  0.0314,  0.0048],\n",
       "                      [-0.1028, -0.0489,  0.1067,  ..., -0.0096, -0.0822,  0.0110]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.in_proj_bias',\n",
       "              tensor([-4.6883e-02, -1.7689e-02, -3.5032e-02,  1.9831e-02, -4.0250e-03,\n",
       "                       6.4847e-02,  4.4583e-02, -1.7099e-03, -1.2833e-02,  1.2622e-03,\n",
       "                      -2.2965e-02, -1.9850e-02,  2.0853e-03, -2.4800e-02, -6.0025e-02,\n",
       "                      -4.0198e-03,  6.5970e-02, -1.9065e-03, -5.2621e-02, -5.6490e-02,\n",
       "                       9.1652e-02,  3.0203e-02, -5.5018e-03,  3.0497e-02, -6.4178e-02,\n",
       "                       8.2146e-02,  3.5095e-02,  3.9055e-03,  3.0006e-02, -5.3455e-02,\n",
       "                       7.8429e-02,  2.2789e-02, -3.7786e-03, -6.5885e-02,  6.2286e-02,\n",
       "                       5.3171e-02, -3.7818e-02,  3.8454e-02, -1.0112e-01, -2.0054e-02,\n",
       "                       4.3922e-02,  4.9698e-03, -6.7393e-03, -3.9034e-02, -1.1273e-03,\n",
       "                       7.6299e-02, -3.0213e-02, -4.7463e-03, -2.6794e-02,  2.8705e-02,\n",
       "                       6.7507e-02, -3.5129e-02, -3.1392e-02, -1.6337e-02, -2.5238e-02,\n",
       "                       1.0285e-01, -1.3067e-02, -9.6286e-03,  1.6271e-02,  5.8257e-02,\n",
       "                      -1.0560e-02,  9.2034e-02, -2.2250e-02, -9.0629e-02, -3.8578e-02,\n",
       "                      -1.4965e-02,  2.8649e-02,  6.5088e-02, -5.0830e-02,  9.4831e-02,\n",
       "                      -5.7366e-02,  4.7760e-02, -7.0443e-02, -8.0418e-02,  2.1831e-07,\n",
       "                      -1.0751e-02,  1.0435e-01,  4.5741e-02, -8.8505e-02, -2.7445e-02,\n",
       "                       2.2839e-02, -1.5149e-02, -2.7207e-02,  3.4977e-03,  4.9749e-02,\n",
       "                      -4.2513e-02, -1.1560e-02,  3.0572e-02, -4.0768e-03, -8.4038e-02,\n",
       "                       1.8262e-02,  6.3885e-02, -5.3466e-02,  7.1422e-04,  9.0777e-02,\n",
       "                       9.3107e-02,  3.4152e-02,  4.4870e-03, -5.1810e-02,  1.2621e-01,\n",
       "                      -3.2467e-02, -3.7477e-02, -6.9751e-02,  4.9383e-02, -5.6180e-02,\n",
       "                       5.6727e-02,  1.1718e-02, -2.7198e-03,  2.1034e-02, -6.5690e-02,\n",
       "                       1.6238e-03,  7.2895e-02, -1.3576e-02,  2.0290e-02,  4.0003e-02,\n",
       "                      -1.6992e-02,  3.6560e-02,  6.2649e-02,  5.2250e-02, -8.7838e-02,\n",
       "                      -2.9428e-02, -3.6050e-02, -3.2043e-02, -5.7541e-02, -3.6915e-03,\n",
       "                       1.8416e-02, -4.0111e-02, -3.0585e-03,  8.1765e-02, -6.9614e-03,\n",
       "                       3.0550e-02,  7.6814e-02, -2.5128e-03,  3.5678e-03, -7.4245e-03,\n",
       "                       4.9970e-02,  2.0363e-02,  7.4293e-02, -3.9016e-02, -6.8782e-02,\n",
       "                      -1.9240e-02, -4.9059e-02,  2.3087e-02, -7.5147e-02, -9.5646e-03,\n",
       "                      -6.2987e-02, -4.3627e-02,  1.5153e-02, -6.0074e-02, -8.8119e-02,\n",
       "                       4.4028e-02, -3.2256e-02,  2.4366e-02,  4.6890e-03, -1.5686e-02,\n",
       "                       7.6131e-02, -7.9720e-02,  6.8249e-02, -5.9612e-02, -5.6961e-02,\n",
       "                       4.0447e-02, -5.4531e-02,  1.1257e-02, -6.4836e-02,  3.2665e-02,\n",
       "                      -1.1279e-02, -6.8678e-02,  8.1423e-02,  6.4479e-03,  8.7029e-02,\n",
       "                       6.6353e-03, -4.0897e-02, -4.7400e-02, -2.1320e-02, -9.2970e-03,\n",
       "                       1.2130e-02, -4.1210e-02,  5.4055e-02,  1.6114e-02,  4.8390e-02,\n",
       "                       6.8868e-02,  7.2520e-02, -7.9469e-02,  8.9908e-02, -2.6710e-02,\n",
       "                      -2.5450e-02, -4.7421e-02,  9.1955e-02,  4.6766e-02, -5.6362e-02,\n",
       "                      -5.1963e-02, -9.0686e-02,  6.7066e-07, -6.8542e-06, -1.0412e-05,\n",
       "                       1.8717e-05,  4.9458e-06,  1.5089e-05,  3.6870e-06, -7.0318e-06,\n",
       "                       8.5687e-06, -1.4225e-05, -2.8814e-06, -8.9961e-07, -1.9802e-05,\n",
       "                      -2.2285e-06, -9.2259e-06,  1.2833e-05, -4.3311e-07, -4.9876e-06,\n",
       "                       1.2974e-05, -1.2378e-05,  4.4406e-06,  8.1023e-06, -1.6453e-05,\n",
       "                       8.8154e-06, -2.1751e-06,  1.6634e-06,  5.0101e-07,  1.4763e-05,\n",
       "                      -8.9392e-06, -1.1927e-05,  7.3410e-07, -1.8079e-06, -1.0112e-06,\n",
       "                       2.1312e-06, -1.3294e-06,  6.4454e-06,  1.5292e-05, -2.2782e-06,\n",
       "                       1.4620e-05,  2.3917e-06,  3.5869e-06,  5.1180e-06,  1.4277e-05,\n",
       "                       1.6190e-06,  9.3059e-06,  3.4910e-06,  1.3219e-05, -8.7786e-06,\n",
       "                      -8.9638e-06,  3.2758e-05, -5.6812e-06,  1.2096e-05, -1.8322e-06,\n",
       "                       1.1415e-05, -5.2610e-06, -9.1960e-06,  2.4595e-06,  5.8087e-06,\n",
       "                      -1.4308e-05, -7.9415e-06, -8.2228e-06, -3.2715e-05, -1.0647e-05,\n",
       "                       8.8445e-07, -4.0231e-06,  2.3951e-06, -4.1686e-06,  2.3579e-05,\n",
       "                      -1.4601e-06, -2.3998e-05, -1.1285e-05, -6.9366e-06,  2.5404e-06,\n",
       "                      -1.5187e-05,  5.0074e-07,  7.5442e-06, -2.2652e-06, -2.2262e-05,\n",
       "                       6.0181e-07,  1.2068e-05,  2.6521e-06, -6.1183e-06,  1.9119e-05,\n",
       "                       4.4352e-06, -1.0421e-05,  2.3038e-06, -5.9336e-06,  6.2893e-06,\n",
       "                      -5.2309e-06,  9.0303e-06,  4.5187e-06,  8.7036e-06, -1.2103e-06,\n",
       "                      -7.0735e-06, -1.0518e-05,  1.6272e-05, -1.2516e-05,  4.7558e-06,\n",
       "                       1.0142e-05,  6.8331e-06, -1.1170e-05,  7.9071e-06,  8.7836e-06,\n",
       "                      -4.0817e-06,  9.5960e-06, -1.0453e-05,  1.0371e-05,  5.9365e-07,\n",
       "                      -8.8530e-06, -8.3707e-06,  2.0282e-07,  1.5774e-05, -1.5736e-06,\n",
       "                      -5.3639e-06,  1.4631e-05, -9.6260e-07, -1.7075e-05, -5.5270e-06,\n",
       "                      -1.3181e-05,  4.0289e-06,  8.6837e-06,  1.2179e-05,  9.3846e-06,\n",
       "                       6.7348e-06,  1.5191e-05, -3.7660e-06,  7.4114e-06, -1.4243e-06,\n",
       "                      -1.2655e-05, -4.4605e-06, -3.9999e-06, -1.1263e-05,  8.2569e-07,\n",
       "                       2.6240e-06,  1.5060e-05, -4.3887e-06, -5.5399e-06, -1.1687e-05,\n",
       "                       2.3589e-06,  8.1158e-06,  6.9327e-07, -1.2371e-06,  6.4682e-06,\n",
       "                      -1.8930e-06, -2.3744e-06, -5.3860e-06, -7.1082e-06, -7.0457e-06,\n",
       "                      -1.2718e-05,  1.5667e-06,  1.3732e-05,  5.2376e-07,  2.6724e-06,\n",
       "                       2.7801e-06, -1.3938e-05, -6.9093e-06,  6.9195e-06,  1.4301e-05,\n",
       "                       3.2901e-06,  1.3307e-05, -1.8844e-06, -6.1952e-06, -4.8320e-06,\n",
       "                      -5.0136e-06,  6.3665e-06,  5.6536e-06,  2.8044e-05, -6.4470e-06,\n",
       "                       6.2553e-06,  3.4509e-06,  7.7146e-06,  6.3251e-06, -1.6008e-05,\n",
       "                      -2.3275e-05, -8.8323e-07, -1.6839e-05,  1.0590e-05,  7.6439e-06,\n",
       "                      -1.8164e-06, -1.0996e-05, -3.3013e-06, -6.5375e-09,  1.1906e-05,\n",
       "                       7.7347e-06,  7.0320e-06,  1.2623e-06,  4.8321e-06,  7.8364e-06,\n",
       "                      -1.3552e-05, -1.5539e-05, -1.9772e-06, -1.4583e-05, -1.4083e-02,\n",
       "                       1.1176e-02,  9.7251e-03,  1.5138e-02, -6.0981e-03,  7.6033e-03,\n",
       "                      -2.9974e-02, -1.1989e-02,  8.4238e-03,  1.7924e-02, -1.1342e-02,\n",
       "                       1.7498e-02,  1.7233e-02,  2.4611e-02, -3.2326e-03, -6.2816e-03,\n",
       "                      -2.0022e-02, -7.6461e-03,  1.8008e-02,  5.6165e-03,  1.1291e-02,\n",
       "                       4.6782e-03,  1.9247e-02,  3.8092e-03,  1.0551e-02,  3.8759e-03,\n",
       "                       6.4586e-04,  3.2884e-03, -5.4096e-04, -1.0096e-02,  1.2916e-02,\n",
       "                      -6.5504e-03,  4.5368e-03, -4.4401e-03,  7.0199e-03,  4.4013e-03,\n",
       "                      -1.4619e-02,  1.2791e-02,  1.3249e-02, -2.4694e-02, -4.8855e-03,\n",
       "                      -5.3836e-03, -5.8164e-03,  1.1458e-02,  2.7668e-02, -1.4218e-02,\n",
       "                       1.2458e-02, -1.6016e-02,  8.8222e-03,  7.5653e-04, -8.6830e-04,\n",
       "                       1.1913e-02, -9.5163e-03, -1.2947e-02,  6.9819e-03, -1.8076e-02,\n",
       "                       7.1307e-03, -2.3290e-02,  1.6420e-02, -5.2034e-03,  1.6884e-02,\n",
       "                       1.4874e-02, -1.1817e-02, -4.6706e-03,  3.9306e-02,  1.0370e-02,\n",
       "                      -1.2274e-02,  7.6153e-03,  7.2630e-03, -9.8423e-03,  1.7785e-02,\n",
       "                       2.0041e-03, -1.4072e-02,  1.3066e-02,  1.2530e-02, -1.0354e-02,\n",
       "                       1.3929e-02, -1.8552e-02,  3.0378e-02, -7.1660e-03, -1.0186e-03,\n",
       "                       1.0420e-02,  9.9631e-03, -6.0956e-03, -1.2155e-02, -6.5960e-03,\n",
       "                       1.4070e-02, -1.5161e-02,  1.6140e-02,  1.2424e-02, -6.8124e-05,\n",
       "                       2.1549e-02,  5.4264e-03,  1.8213e-02,  7.1934e-03, -1.9516e-02,\n",
       "                       9.9552e-03,  5.3198e-04, -1.3909e-03, -2.4340e-02, -1.0219e-02,\n",
       "                       6.9933e-03,  1.3917e-03, -8.6553e-03,  2.0894e-02, -2.3368e-02,\n",
       "                      -2.0220e-03, -1.5113e-02, -7.0708e-03, -7.0731e-03, -5.6691e-03,\n",
       "                       5.3663e-03,  2.8587e-02, -1.3280e-02,  1.3504e-02, -1.3050e-02,\n",
       "                      -5.1631e-03,  1.9800e-03, -8.1878e-03,  1.4707e-02, -1.1270e-02,\n",
       "                      -3.1284e-02,  1.2387e-02,  3.2550e-03,  2.0075e-02, -2.2253e-04,\n",
       "                       2.4929e-02,  2.5022e-02,  7.6679e-03,  2.1497e-02, -3.5650e-03,\n",
       "                      -1.7133e-02, -2.4663e-03,  5.8851e-03,  2.0289e-02,  9.5215e-04,\n",
       "                       1.9021e-02,  5.2186e-03,  7.6804e-03,  1.2181e-02, -9.6251e-03,\n",
       "                       4.2442e-02,  3.4983e-02,  7.6254e-03,  1.2292e-02, -1.0654e-02,\n",
       "                      -2.3302e-02, -5.5196e-03,  6.6391e-03, -6.3755e-03,  2.7376e-02,\n",
       "                       1.0261e-02, -1.0865e-02,  6.1418e-03,  1.3693e-02,  7.0305e-03,\n",
       "                      -6.9481e-03, -1.5277e-02,  8.0434e-03, -1.8173e-02,  1.3320e-02,\n",
       "                       6.0668e-03,  7.3001e-03,  1.1019e-02,  3.6146e-03,  1.2082e-02,\n",
       "                      -1.6947e-02, -3.7481e-03, -1.0476e-02,  5.9758e-03, -1.7444e-03,\n",
       "                      -2.5558e-02, -1.3555e-02,  1.0794e-02, -5.6015e-03,  2.1191e-02,\n",
       "                      -1.1795e-02,  1.5423e-02,  2.2444e-02, -2.8323e-03,  9.9287e-03,\n",
       "                       2.6240e-02,  1.9329e-03, -3.3978e-03,  1.5984e-02,  1.4085e-02,\n",
       "                      -8.8675e-03, -1.9650e-02,  1.1788e-02, -2.9695e-03, -7.8964e-03,\n",
       "                      -5.3159e-04], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0008, -0.0805,  0.0672,  ...,  0.1154, -0.0272,  0.0385],\n",
       "                      [ 0.0514, -0.0521,  0.0722,  ..., -0.0322, -0.0197, -0.0190],\n",
       "                      [ 0.0093,  0.0065,  0.0328,  ...,  0.0313,  0.0241,  0.0342],\n",
       "                      ...,\n",
       "                      [-0.0304, -0.0854,  0.0255,  ...,  0.0012,  0.0079, -0.0530],\n",
       "                      [ 0.0110,  0.0005, -0.0343,  ...,  0.0320, -0.0869,  0.0306],\n",
       "                      [ 0.0671, -0.0503, -0.0378,  ..., -0.0256, -0.0091,  0.0425]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.out_proj.bias',\n",
       "              tensor([ 0.0330, -0.0086,  0.0069, -0.0247,  0.0413,  0.0059,  0.0425,  0.0049,\n",
       "                       0.0296,  0.0073, -0.0126,  0.0047,  0.0249, -0.0200,  0.0255, -0.0344,\n",
       "                      -0.0136,  0.0036, -0.0006,  0.0256, -0.0090, -0.0240, -0.0387,  0.0024,\n",
       "                      -0.0373, -0.0038,  0.0210,  0.0173, -0.0134,  0.0180, -0.0298,  0.0486,\n",
       "                       0.0087,  0.0013, -0.0209, -0.0106, -0.0313, -0.0179, -0.0076,  0.0152,\n",
       "                      -0.0087, -0.0066,  0.0159, -0.0239,  0.0308, -0.0124,  0.0285, -0.0031,\n",
       "                       0.0013,  0.0120,  0.0249, -0.0023,  0.0029,  0.0230, -0.0436,  0.0203,\n",
       "                       0.0069, -0.0399, -0.0151, -0.0027,  0.0145,  0.0027, -0.0326,  0.0138,\n",
       "                      -0.0405,  0.0280,  0.0150, -0.0249,  0.0024, -0.0131,  0.0456,  0.0098,\n",
       "                       0.0092,  0.0217, -0.0280,  0.0013,  0.0143, -0.0158, -0.0063, -0.0307,\n",
       "                      -0.0246, -0.0197, -0.0005,  0.0065, -0.0031, -0.0207, -0.0020,  0.0236,\n",
       "                       0.0240, -0.0029,  0.0201, -0.0196, -0.0036, -0.0084, -0.0172, -0.0191,\n",
       "                       0.0059,  0.0231,  0.0641,  0.0007,  0.0243, -0.0290, -0.0008,  0.0530,\n",
       "                      -0.0144,  0.0193, -0.0001, -0.0353, -0.0212,  0.0075, -0.0112, -0.0287,\n",
       "                       0.0294, -0.0274,  0.0054, -0.0298,  0.0206,  0.0265,  0.0230, -0.0034,\n",
       "                      -0.0035, -0.0109,  0.0283,  0.0058, -0.0089,  0.0193,  0.0105, -0.0088,\n",
       "                      -0.0238, -0.0008, -0.0313, -0.0031,  0.0528, -0.0233,  0.0214, -0.0085,\n",
       "                      -0.0221,  0.0255,  0.0156, -0.0317, -0.0063,  0.0044, -0.0143, -0.0028,\n",
       "                       0.0225, -0.0331, -0.0011, -0.0173,  0.0334, -0.0445, -0.0180, -0.0330,\n",
       "                      -0.0080,  0.0131,  0.0252, -0.0228, -0.0057,  0.0147,  0.0099, -0.0004,\n",
       "                      -0.0257,  0.0080,  0.0321, -0.0160, -0.0098,  0.0135, -0.0089,  0.0008,\n",
       "                      -0.0195,  0.0014,  0.0252, -0.0274, -0.0098,  0.0190,  0.0490, -0.0125,\n",
       "                       0.0228,  0.0243,  0.0114,  0.0238, -0.0131,  0.0032,  0.0416,  0.0151,\n",
       "                       0.0042, -0.0165, -0.0025,  0.0041, -0.0142,  0.0024, -0.0105, -0.0061],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.in_proj_weight',\n",
       "              tensor([[ 0.0400, -0.0830,  0.1026,  ...,  0.0482, -0.0199, -0.0458],\n",
       "                      [-0.1486,  0.0807, -0.0066,  ..., -0.0112, -0.0836,  0.0269],\n",
       "                      [-0.0611,  0.0616, -0.1253,  ..., -0.0843, -0.0113,  0.1073],\n",
       "                      ...,\n",
       "                      [ 0.0686,  0.0005, -0.0231,  ..., -0.0429, -0.0058, -0.0189],\n",
       "                      [ 0.0458, -0.0076, -0.0780,  ..., -0.0622,  0.1324, -0.0213],\n",
       "                      [ 0.1321, -0.0259,  0.0002,  ...,  0.1245, -0.0017,  0.1072]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.in_proj_bias',\n",
       "              tensor([ 1.5504e-01, -5.6370e-02, -1.1369e-01, -1.3652e-01,  4.3207e-03,\n",
       "                       1.6370e-01,  6.3209e-02,  1.5051e-01,  1.3203e-01,  1.8422e-01,\n",
       "                      -2.0319e-02, -6.3878e-02,  1.6497e-01,  1.8327e-01, -1.1724e-01,\n",
       "                       1.9724e-02, -5.9973e-02, -1.4914e-01,  1.6350e-01, -1.2836e-01,\n",
       "                       1.8582e-01, -1.9367e-01, -3.6031e-02,  1.1585e-01,  9.7958e-02,\n",
       "                      -1.6164e-01, -8.6266e-02,  9.3083e-02,  2.2463e-02, -1.1063e-01,\n",
       "                       4.3902e-03,  1.9732e-01, -5.2724e-02,  1.7754e-01, -8.7357e-03,\n",
       "                      -1.6333e-01,  1.6326e-01, -2.0917e-01,  1.5877e-01, -7.8540e-02,\n",
       "                      -9.2886e-02, -2.0304e-02, -1.7338e-02, -7.0090e-02, -6.6697e-02,\n",
       "                      -9.4168e-02,  6.0382e-02, -1.6986e-01,  1.9997e-02,  7.6481e-02,\n",
       "                       4.0379e-02,  2.1728e-02, -1.7251e-01, -6.7962e-02, -9.3912e-02,\n",
       "                      -2.2624e-01, -2.0715e-02, -4.2494e-03,  5.2871e-02,  9.5855e-02,\n",
       "                       1.2396e-01,  4.4612e-02,  1.3755e-01, -6.1753e-03, -4.1619e-02,\n",
       "                      -3.4560e-02,  1.6320e-01, -5.0872e-02,  2.9179e-02, -6.7443e-03,\n",
       "                      -5.3601e-02, -1.5044e-01,  2.1788e-02, -2.2430e-02,  9.0122e-02,\n",
       "                       1.5626e-02,  7.9398e-02,  6.5898e-02,  1.3770e-01,  1.6014e-02,\n",
       "                      -4.9615e-02,  1.0683e-02, -1.2002e-01,  4.0162e-02, -2.5270e-02,\n",
       "                      -1.0023e-01,  1.1434e-01,  7.4981e-02,  8.7075e-03,  5.3735e-02,\n",
       "                      -5.9318e-02,  4.3582e-02, -1.2041e-01, -5.0116e-02,  9.8981e-02,\n",
       "                      -1.0764e-01,  5.4857e-02,  1.7231e-02, -2.5794e-02,  2.0714e-01,\n",
       "                       1.1127e-01, -2.2029e-02, -1.4357e-02,  1.6007e-01,  9.1329e-02,\n",
       "                      -2.4932e-01, -2.6011e-02,  4.3957e-02,  1.1908e-01,  2.3245e-02,\n",
       "                      -1.0138e-01, -2.6802e-02,  1.9162e-02, -4.7787e-02,  1.7835e-01,\n",
       "                      -2.5350e-02,  1.3947e-01,  4.5914e-02,  1.6342e-01,  1.1585e-02,\n",
       "                      -2.7268e-02, -7.0741e-02, -7.3770e-02, -1.6192e-02,  1.1991e-01,\n",
       "                      -9.3042e-02,  7.6398e-02,  9.6625e-04,  1.1429e-01, -5.5349e-02,\n",
       "                      -6.4933e-02, -2.1002e-01,  4.3806e-03,  7.9301e-03,  4.4888e-03,\n",
       "                       1.1197e-01, -1.0898e-01,  1.6126e-01, -5.6258e-02,  6.8537e-02,\n",
       "                      -5.4987e-02,  2.0874e-02,  1.6675e-02, -2.8978e-02,  2.0904e-01,\n",
       "                       1.1457e-01,  1.1815e-01,  7.5224e-02,  2.9395e-03,  1.5691e-02,\n",
       "                       9.7557e-02, -1.8913e-02,  1.2209e-01, -8.4427e-02, -1.1219e-01,\n",
       "                       2.4342e-02,  1.1368e-01, -3.0334e-03,  1.8703e-01,  1.0674e-01,\n",
       "                       3.5884e-02,  3.6150e-02, -4.2148e-02,  7.0939e-02, -5.2510e-02,\n",
       "                      -1.0394e-01, -6.2265e-02,  2.4612e-02, -1.1659e-01,  9.9583e-02,\n",
       "                      -1.2409e-01,  1.2987e-01, -1.0682e-01,  1.2009e-01, -7.3495e-02,\n",
       "                       5.7528e-02,  2.3724e-02, -2.0681e-01, -1.9926e-02,  2.1003e-02,\n",
       "                      -2.0856e-01, -1.0600e-01,  7.1733e-02,  9.6997e-03, -1.8087e-01,\n",
       "                       8.5025e-02, -2.5274e-02,  9.8903e-03, -3.2104e-02,  2.0084e-01,\n",
       "                       1.4788e-02, -3.2493e-02, -4.1117e-05,  2.7223e-05,  2.3324e-05,\n",
       "                       3.2174e-05,  5.7001e-06,  9.8032e-06, -2.2645e-05, -2.6448e-05,\n",
       "                      -2.6261e-05,  1.0807e-05,  1.0529e-05,  1.2598e-06, -2.3210e-05,\n",
       "                      -1.0075e-05,  2.1350e-05,  3.2488e-07,  1.1537e-05,  4.0996e-05,\n",
       "                      -1.4404e-05,  3.4469e-05, -2.4751e-05,  3.4033e-05,  9.5206e-07,\n",
       "                      -2.8565e-05, -8.5411e-06,  2.8874e-05,  2.5878e-05, -7.0027e-06,\n",
       "                       1.6861e-05,  2.9996e-05, -8.7277e-06, -1.9519e-05,  9.9292e-06,\n",
       "                      -2.9802e-05,  9.2801e-06,  2.9021e-05,  7.6878e-06,  3.6465e-05,\n",
       "                      -2.3759e-05,  1.7893e-05,  2.3316e-05,  5.8334e-06, -1.1728e-05,\n",
       "                      -5.2025e-07,  4.9771e-06,  1.7426e-05,  1.6842e-05,  3.5901e-05,\n",
       "                       8.7873e-06, -4.0516e-06,  3.4098e-05, -2.2415e-05, -1.5125e-05,\n",
       "                      -8.1865e-06, -1.6379e-05, -2.3339e-05, -3.7938e-05, -1.7359e-06,\n",
       "                       1.5998e-05, -1.3250e-05,  3.0115e-05,  1.5000e-08,  2.5526e-05,\n",
       "                      -1.2002e-05, -1.0470e-05,  1.6522e-05,  2.4301e-05, -8.7592e-06,\n",
       "                       7.2650e-06, -1.7554e-06,  1.6833e-05, -3.1818e-05,  1.1607e-05,\n",
       "                       5.1269e-06,  8.3411e-06,  2.9685e-05,  6.3310e-07,  2.0194e-05,\n",
       "                       2.6849e-05,  4.9527e-06,  4.5823e-06,  1.7965e-05,  6.4048e-08,\n",
       "                       1.8796e-05, -6.2739e-06,  9.2189e-06, -1.7924e-06, -3.2760e-06,\n",
       "                       3.5532e-05,  2.8542e-06,  3.0002e-06, -2.1351e-05,  2.7228e-06,\n",
       "                       2.0856e-05, -4.4865e-06, -1.5871e-05, -1.2225e-05,  2.4682e-06,\n",
       "                       2.0390e-05,  2.6879e-05, -7.3732e-06,  3.0236e-05, -2.5342e-05,\n",
       "                       2.3276e-06, -1.2996e-05, -1.5867e-05,  2.4153e-05, -1.5543e-05,\n",
       "                      -4.9561e-06, -3.5113e-05,  2.7491e-05,  1.5965e-05, -2.1344e-05,\n",
       "                       1.8548e-05,  5.1225e-06, -1.6444e-05,  5.7850e-06, -1.1872e-05,\n",
       "                      -3.5670e-06, -1.2509e-05, -5.3082e-05, -2.6372e-05,  9.1574e-06,\n",
       "                      -1.1352e-05,  6.7288e-06,  1.3977e-05, -2.0874e-05, -2.1436e-05,\n",
       "                      -3.6495e-06,  6.0960e-06, -4.7473e-06, -6.5239e-06,  1.9219e-05,\n",
       "                       3.4517e-05, -1.8189e-05, -6.4308e-06,  1.0599e-05,  1.0881e-05,\n",
       "                       1.3807e-05, -3.0880e-06,  1.1149e-05, -2.1470e-05,  3.2241e-05,\n",
       "                       2.1026e-06,  2.1317e-05, -6.7991e-06, -6.3864e-06,  1.1661e-05,\n",
       "                       1.6584e-05,  3.2481e-06, -7.0850e-06, -5.8154e-06, -1.6962e-06,\n",
       "                       9.0267e-06,  8.7907e-06,  1.0688e-05, -6.3721e-06,  1.6851e-06,\n",
       "                       8.5621e-06,  2.0328e-06,  3.0053e-06, -4.3057e-06, -1.1476e-06,\n",
       "                       5.0789e-06,  1.0789e-05,  1.2439e-06,  2.1969e-06, -1.1371e-06,\n",
       "                       2.1700e-07,  1.1706e-05,  7.9329e-06, -4.7321e-06, -3.4912e-07,\n",
       "                       4.5306e-06,  1.1237e-05,  7.6618e-07, -5.4868e-06, -1.2031e-05,\n",
       "                       1.2998e-05, -3.0944e-06, -1.8788e-06,  1.4276e-05, -6.0703e-07,\n",
       "                       9.2726e-07,  1.6793e-05,  1.8843e-06,  1.3697e-05,  1.8897e-06,\n",
       "                      -2.0896e-06, -1.1035e-05, -1.4035e-05,  3.0443e-06, -1.2417e-03,\n",
       "                       1.2986e-02,  1.7110e-02,  2.8946e-02, -2.5770e-02, -2.2517e-02,\n",
       "                      -1.6412e-02, -2.6122e-02,  6.4382e-03, -2.9509e-02,  1.3172e-02,\n",
       "                       5.9058e-03,  7.4972e-03,  8.5920e-03,  2.4156e-02,  5.1145e-03,\n",
       "                      -2.6836e-02, -3.2139e-02,  3.4703e-02, -2.0623e-02, -5.3632e-03,\n",
       "                      -4.5038e-03, -9.3564e-03, -2.0998e-02, -2.6330e-02, -2.6907e-02,\n",
       "                       5.0041e-02, -1.3542e-02,  3.9234e-03,  5.7549e-02,  1.7672e-02,\n",
       "                       4.5998e-03,  4.3968e-02, -2.1731e-02, -3.5134e-02,  1.5940e-02,\n",
       "                       4.1254e-02, -1.5624e-02, -1.4713e-03,  2.0806e-03, -2.4027e-02,\n",
       "                       1.0437e-02, -5.0316e-02,  3.3368e-02,  2.1649e-03,  3.8862e-03,\n",
       "                       2.1318e-02, -2.1336e-02,  1.6735e-02, -8.0728e-03,  1.4615e-02,\n",
       "                       6.2820e-03, -7.2301e-03, -1.8009e-02,  2.9891e-02, -1.8430e-02,\n",
       "                      -7.9581e-03, -1.0302e-02, -2.0487e-02,  2.0978e-02, -2.6380e-02,\n",
       "                      -2.4799e-02, -4.5737e-03, -4.4790e-03, -3.0404e-02, -8.8197e-03,\n",
       "                       4.8223e-03,  2.4362e-02,  1.9523e-02, -1.5462e-02, -2.1916e-02,\n",
       "                      -1.8568e-02,  4.0839e-03, -1.2365e-02, -3.6640e-03, -7.4302e-03,\n",
       "                       6.3905e-03,  2.0606e-03, -2.2020e-03,  1.6706e-02, -1.8979e-02,\n",
       "                       2.0243e-02, -2.4288e-02, -3.9204e-02,  4.0020e-03, -9.8654e-03,\n",
       "                       1.8450e-03,  2.9801e-02, -8.4133e-03,  1.3646e-02,  1.8222e-02,\n",
       "                      -1.3713e-02, -4.2595e-03, -2.2416e-04,  1.1639e-02, -1.4164e-02,\n",
       "                       2.1221e-02,  2.4912e-02,  8.2495e-03,  5.8912e-03,  1.7524e-02,\n",
       "                       2.2233e-02, -2.6181e-02, -2.2839e-03, -2.0001e-02, -8.3314e-03,\n",
       "                      -2.4315e-02,  2.6870e-02, -2.0131e-02, -4.3033e-02,  1.9417e-02,\n",
       "                      -9.2477e-03,  7.5161e-03,  1.1657e-02, -2.4600e-02, -1.6079e-03,\n",
       "                      -1.1613e-02,  2.3990e-03, -3.9418e-03,  1.0759e-02,  1.6646e-02,\n",
       "                       6.1001e-03, -2.8120e-04, -9.0739e-03, -8.7504e-03, -9.8231e-03,\n",
       "                       1.6593e-02,  3.1811e-03, -2.0796e-02, -4.3438e-03, -2.3748e-02,\n",
       "                      -2.9214e-03, -2.4150e-02,  1.1972e-02,  2.0657e-02,  2.0410e-02,\n",
       "                      -2.4166e-02, -1.1841e-02,  9.0982e-03, -1.6724e-02,  3.8315e-02,\n",
       "                       1.7728e-02,  1.4104e-03,  6.0435e-03,  5.3134e-03, -8.8090e-04,\n",
       "                       2.7553e-03,  3.0202e-02, -1.4383e-02,  1.6060e-02,  6.6492e-03,\n",
       "                      -3.5899e-02, -2.8970e-02, -2.1914e-02,  1.1662e-02, -5.6504e-02,\n",
       "                      -2.1874e-02,  1.5731e-02,  4.3625e-03, -3.3903e-02,  3.3354e-03,\n",
       "                       9.8275e-04,  6.8465e-04,  1.8499e-02,  3.2426e-02,  6.2430e-02,\n",
       "                       6.2513e-03, -3.3024e-03, -1.1179e-02, -2.5409e-03,  1.4897e-02,\n",
       "                      -1.6796e-02, -2.3393e-02, -1.0614e-02,  4.5039e-02, -1.4194e-02,\n",
       "                       2.8163e-02,  9.0386e-03, -4.2222e-03, -3.1192e-02,  7.6414e-03,\n",
       "                      -2.5173e-02, -2.4883e-02, -2.2236e-02,  4.4253e-02, -4.6075e-06,\n",
       "                      -2.7811e-02,  9.4191e-03, -3.3411e-02, -7.6351e-03,  1.5647e-03,\n",
       "                      -1.4231e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.out_proj.weight',\n",
       "              tensor([[-0.0059,  0.0194,  0.0176,  ..., -0.0292,  0.0565,  0.0259],\n",
       "                      [ 0.0185, -0.0124, -0.0953,  ...,  0.0345, -0.0260,  0.0659],\n",
       "                      [-0.0256, -0.0572,  0.0228,  ...,  0.0291,  0.0632,  0.0159],\n",
       "                      ...,\n",
       "                      [-0.0546,  0.0549, -0.0161,  ..., -0.0509, -0.0635,  0.0253],\n",
       "                      [ 0.0032, -0.0369,  0.0664,  ..., -0.0100, -0.0601,  0.0399],\n",
       "                      [ 0.0765,  0.0205, -0.0186,  ..., -0.0496, -0.0788, -0.0422]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.out_proj.bias',\n",
       "              tensor([-0.0046, -0.0390, -0.0213,  0.0041, -0.0133,  0.0255,  0.0131, -0.0110,\n",
       "                       0.0093,  0.0288,  0.0300,  0.0075,  0.0213, -0.0053,  0.0313, -0.0094,\n",
       "                       0.0030,  0.0099,  0.0037,  0.0432, -0.0034, -0.0020,  0.0028,  0.0200,\n",
       "                      -0.0218,  0.0318,  0.0109,  0.0560,  0.0434, -0.0144, -0.0268,  0.0173,\n",
       "                      -0.0095, -0.0119, -0.0198, -0.0083, -0.0297,  0.0154,  0.0116,  0.0057,\n",
       "                      -0.0145, -0.0016,  0.0119,  0.0030, -0.0191,  0.0091,  0.0134, -0.0010,\n",
       "                      -0.0080, -0.0055,  0.0062,  0.0026,  0.0146, -0.0415, -0.0024, -0.0013,\n",
       "                      -0.0172,  0.0127,  0.0254,  0.0166,  0.0322,  0.0038,  0.0069,  0.0182,\n",
       "                       0.0129,  0.0120, -0.0217, -0.0100, -0.0262,  0.0065,  0.0059,  0.0133,\n",
       "                       0.0148, -0.0301, -0.0139, -0.0144,  0.0209, -0.0129, -0.0274, -0.0055,\n",
       "                      -0.0176, -0.0116,  0.0064,  0.0098, -0.0010,  0.0266, -0.0059,  0.0448,\n",
       "                       0.0126, -0.0032, -0.0306,  0.0099, -0.0085, -0.0051,  0.0221, -0.0005,\n",
       "                      -0.0008, -0.0072,  0.0263, -0.0060, -0.0043, -0.0212, -0.0244, -0.0057,\n",
       "                      -0.0159,  0.0009,  0.0251, -0.0106, -0.0172, -0.0027,  0.0011, -0.0136,\n",
       "                       0.0402,  0.0243, -0.0023,  0.0054,  0.0274,  0.0048,  0.0297, -0.0070,\n",
       "                      -0.0200,  0.0033,  0.0073,  0.0115, -0.0380,  0.0022,  0.0298,  0.0092,\n",
       "                       0.0055,  0.0277, -0.0236, -0.0019,  0.0163, -0.0184,  0.0004, -0.0122,\n",
       "                       0.0005, -0.0268,  0.0013, -0.0336, -0.0122,  0.0113,  0.0137,  0.0034,\n",
       "                      -0.0182, -0.0154,  0.0276, -0.0253,  0.0123, -0.0533,  0.0128,  0.0073,\n",
       "                      -0.0157, -0.0139, -0.0295, -0.0181,  0.0296,  0.0030,  0.0008, -0.0124,\n",
       "                      -0.0151, -0.0158, -0.0128,  0.0025, -0.0088,  0.0237, -0.0107, -0.0217,\n",
       "                       0.0003, -0.0268, -0.0175, -0.0081, -0.0430, -0.0006,  0.0335, -0.0352,\n",
       "                      -0.0070, -0.0085, -0.0054,  0.0167,  0.0291, -0.0116,  0.0151, -0.0091,\n",
       "                       0.0039, -0.0374, -0.0186,  0.0028,  0.0069, -0.0265, -0.0110,  0.0177],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear1.weight',\n",
       "              tensor([[ 0.0315,  0.0020, -0.0214,  ...,  0.0625, -0.0140,  0.0430],\n",
       "                      [-0.0332, -0.0116, -0.0333,  ...,  0.0123,  0.0962,  0.0318],\n",
       "                      [ 0.0176,  0.0624,  0.0023,  ...,  0.0043, -0.0408, -0.0713],\n",
       "                      ...,\n",
       "                      [ 0.0034, -0.0222, -0.0172,  ...,  0.0616, -0.0484, -0.0138],\n",
       "                      [-0.0903,  0.1201,  0.0455,  ...,  0.0744,  0.0083, -0.0166],\n",
       "                      [ 0.0174, -0.0477,  0.0110,  ...,  0.0345,  0.0207, -0.0004]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear1.bias',\n",
       "              tensor([-0.0123, -0.0777, -0.1128,  ..., -0.0315, -0.0392, -0.1384],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear2.weight',\n",
       "              tensor([[-0.0004, -0.0038, -0.0331,  ...,  0.0354, -0.0150,  0.0024],\n",
       "                      [ 0.0365, -0.0252, -0.0177,  ...,  0.0002,  0.0386,  0.0061],\n",
       "                      [ 0.0007, -0.0517,  0.0137,  ..., -0.0052,  0.0227, -0.0482],\n",
       "                      ...,\n",
       "                      [ 0.0326,  0.0009, -0.0065,  ..., -0.0114,  0.0102,  0.0077],\n",
       "                      [ 0.0342, -0.0072,  0.0182,  ...,  0.0495,  0.0420, -0.0258],\n",
       "                      [ 0.0363,  0.0280,  0.0295,  ...,  0.0480, -0.0108,  0.0228]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear2.bias',\n",
       "              tensor([-0.0728,  0.0723, -0.0512,  0.0804, -0.0300,  0.0526,  0.0555,  0.0696,\n",
       "                      -0.0574, -0.0719,  0.0583,  0.0234, -0.0683,  0.1099, -0.0511,  0.0811,\n",
       "                       0.0261, -0.0471, -0.0725,  0.0384,  0.0786,  0.0769,  0.0104,  0.0503,\n",
       "                      -0.0355,  0.0548, -0.0192, -0.0366, -0.0683,  0.0580,  0.0499, -0.0842,\n",
       "                       0.0502,  0.0561,  0.0447,  0.0171,  0.0201,  0.0572,  0.0450, -0.0725,\n",
       "                       0.0780,  0.0468, -0.0439,  0.0454,  0.0638, -0.0927, -0.0427, -0.0281,\n",
       "                       0.0752,  0.0562, -0.0777,  0.0534,  0.0663, -0.0388,  0.0682, -0.0765,\n",
       "                       0.0948,  0.0716,  0.0091, -0.0602, -0.0377, -0.0689, -0.0661, -0.0538,\n",
       "                       0.0344,  0.0584,  0.0329, -0.0520, -0.0124,  0.0563, -0.0630, -0.0340,\n",
       "                       0.0377,  0.0391,  0.0627, -0.0854, -0.0138, -0.0651,  0.0372, -0.0558,\n",
       "                      -0.0178, -0.0322, -0.0804, -0.0608,  0.0079, -0.0209,  0.0522, -0.0765,\n",
       "                       0.0517,  0.0731,  0.0145,  0.0681, -0.0408, -0.0925, -0.0676, -0.0315,\n",
       "                      -0.0133, -0.1050, -0.0100, -0.0068,  0.0684,  0.0593,  0.0403,  0.0149,\n",
       "                       0.0581,  0.0197,  0.0100, -0.0056,  0.0545, -0.0304, -0.0657, -0.0251,\n",
       "                      -0.0581,  0.0793,  0.0424, -0.0865,  0.0749, -0.0933,  0.0927,  0.0431,\n",
       "                      -0.0673, -0.0661, -0.0136, -0.0408, -0.0432, -0.0688,  0.0893,  0.0784,\n",
       "                      -0.0007, -0.0659,  0.0664, -0.0348, -0.0613, -0.0126,  0.0096,  0.0386,\n",
       "                       0.0082, -0.0103, -0.0681, -0.0163, -0.0317, -0.0590,  0.0967, -0.0443,\n",
       "                       0.0330,  0.0531,  0.0273, -0.0614, -0.0460,  0.0621,  0.0620,  0.0021,\n",
       "                       0.0637, -0.0263,  0.0843,  0.0391, -0.0222, -0.0303, -0.0017, -0.0741,\n",
       "                       0.0401,  0.0648, -0.0611, -0.0372,  0.0425, -0.0816, -0.0172, -0.0705,\n",
       "                      -0.0371, -0.1074,  0.0532,  0.0011, -0.0363, -0.0571, -0.0407,  0.0491,\n",
       "                      -0.0022, -0.0471,  0.0585, -0.0725, -0.0345,  0.0369, -0.0409,  0.0142,\n",
       "                       0.0480, -0.0611, -0.0693,  0.0912,  0.0636, -0.0551,  0.0640,  0.0256],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm1.weight',\n",
       "              tensor([0.9731, 0.8455, 0.9837, 1.0036, 0.9621, 0.9957, 0.9784, 0.9806, 0.9593,\n",
       "                      0.9068, 0.9514, 0.9911, 0.9506, 1.0348, 0.9797, 0.9808, 0.9744, 0.9782,\n",
       "                      0.9860, 0.9780, 1.0024, 0.9764, 1.0013, 0.9711, 0.9924, 0.9625, 0.9387,\n",
       "                      0.9430, 0.8797, 0.9367, 1.0149, 0.9653, 0.9861, 1.0104, 0.9464, 1.0102,\n",
       "                      0.9693, 0.9710, 0.9649, 0.9702, 1.0018, 1.0131, 0.9428, 1.0015, 0.9554,\n",
       "                      1.0018, 0.9960, 0.9837, 0.9992, 1.0006, 0.9862, 0.9970, 0.9938, 0.9823,\n",
       "                      0.9613, 0.9825, 0.9944, 0.9515, 0.9984, 0.9970, 0.9892, 0.9772, 0.9622,\n",
       "                      0.9577, 0.8811, 0.9697, 0.9908, 0.9699, 0.9944, 0.9795, 1.0141, 1.0081,\n",
       "                      0.9742, 0.9797, 1.0149, 0.9584, 0.9850, 0.9971, 1.0124, 0.9546, 1.0109,\n",
       "                      0.9359, 0.9818, 0.9832, 0.9814, 1.0288, 0.9974, 0.9397, 1.0160, 0.9666,\n",
       "                      1.0069, 0.9276, 0.9554, 0.9330, 1.0347, 0.9899, 1.0282, 0.9848, 1.0288,\n",
       "                      0.9977, 1.0132, 0.9613, 0.9992, 0.9769, 0.9951, 0.9632, 1.0041, 0.9878,\n",
       "                      0.9869, 1.0040, 1.0105, 0.9984, 1.0036, 1.0026, 0.9865, 0.9458, 0.9694,\n",
       "                      0.9669, 0.9967, 0.9480, 0.9669, 1.0065, 0.9947, 0.9305, 1.0410, 0.9450,\n",
       "                      1.0363, 0.9947, 1.0298, 0.9041, 1.0149, 0.9766, 0.9643, 0.9549, 1.0312,\n",
       "                      0.9675, 1.0077, 0.9833, 1.0071, 0.9420, 1.0136, 0.9795, 0.9982, 1.0080,\n",
       "                      1.0197, 0.9631, 1.0128, 0.9857, 0.9721, 0.9482, 1.0020, 0.9332, 0.9949,\n",
       "                      0.9902, 0.9549, 0.9517, 0.9958, 0.9875, 1.0339, 0.9789, 1.0125, 0.9474,\n",
       "                      0.9837, 0.9026, 1.0183, 0.9507, 1.0527, 0.9604, 1.0299, 0.9629, 1.0224,\n",
       "                      0.9452, 0.9818, 0.9830, 1.0441, 0.9945, 0.9615, 0.9455, 1.0376, 0.9900,\n",
       "                      0.9857, 0.9615, 1.0278, 0.9556, 1.0060, 1.0015, 1.0358, 0.9474, 0.9050,\n",
       "                      0.9742, 1.0229, 0.9913], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm1.bias',\n",
       "              tensor([ 0.0198, -0.0869,  0.0126, -0.0674,  0.0581, -0.0429,  0.0935,  0.0003,\n",
       "                       0.0501,  0.1397, -0.0256, -0.0095,  0.1157, -0.0771,  0.1142, -0.0662,\n",
       "                      -0.0338,  0.0047,  0.0477,  0.1550, -0.0794, -0.0682, -0.0354,  0.0389,\n",
       "                      -0.0712,  0.0525,  0.0436,  0.0689,  0.0550, -0.0285, -0.1059,  0.1068,\n",
       "                      -0.0190, -0.1067, -0.0418, -0.0710, -0.1003, -0.0755, -0.0256,  0.0569,\n",
       "                      -0.1083, -0.0130,  0.0313, -0.0317, -0.0942,  0.0184,  0.0650,  0.0326,\n",
       "                      -0.0592, -0.0801,  0.0189, -0.0276, -0.0660, -0.0598, -0.0486,  0.0616,\n",
       "                      -0.0889, -0.1056,  0.0841,  0.0904,  0.1379, -0.0034,  0.0332,  0.0366,\n",
       "                       0.0367, -0.0464, -0.0651, -0.0215, -0.0330, -0.0781,  0.1470,  0.0598,\n",
       "                       0.0352, -0.0929, -0.1209,  0.0768,  0.0355, -0.0047, -0.0092, -0.0115,\n",
       "                      -0.0098, -0.0993,  0.1376,  0.0528, -0.0365,  0.0321, -0.0874,  0.1204,\n",
       "                      -0.0297, -0.0483, -0.0123, -0.1384,  0.0777,  0.0461,  0.0854, -0.0174,\n",
       "                       0.0564,  0.0787,  0.1205,  0.0074,  0.0752, -0.1571, -0.0133,  0.0455,\n",
       "                      -0.0957, -0.0833,  0.0182, -0.1271, -0.0036,  0.0162,  0.0601,  0.0190,\n",
       "                       0.1787, -0.0917,  0.0319, -0.0501, -0.0059,  0.1064,  0.0314, -0.1634,\n",
       "                       0.0655,  0.0594,  0.0747,  0.0355,  0.0278,  0.0098,  0.0036, -0.0641,\n",
       "                      -0.0152,  0.0107, -0.1165,  0.0419,  0.2074, -0.0610,  0.0572, -0.0853,\n",
       "                      -0.0377,  0.0434,  0.1225, -0.1124, -0.0291,  0.0578, -0.0687,  0.0232,\n",
       "                       0.0508, -0.0772, -0.0152, -0.0011,  0.0820, -0.0721, -0.0457, -0.1113,\n",
       "                      -0.0302,  0.0409, -0.0213, -0.1605,  0.0651,  0.0701,  0.0296,  0.0032,\n",
       "                      -0.0193,  0.0060,  0.1141, -0.0261, -0.0179,  0.0563,  0.0035, -0.0646,\n",
       "                      -0.0505,  0.0320, -0.0691, -0.0640,  0.0690,  0.0529,  0.1879, -0.1739,\n",
       "                       0.0594, -0.0182, -0.0813,  0.0973,  0.0430, -0.0603,  0.1456, -0.0096,\n",
       "                       0.0439,  0.0018,  0.0080, -0.0532, -0.0253, -0.0576, -0.0771, -0.0186],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm2.weight',\n",
       "              tensor([0.9742, 0.8801, 0.9925, 1.0076, 0.9853, 1.0096, 0.9951, 1.0002, 0.9659,\n",
       "                      0.9282, 0.9661, 0.9978, 0.9790, 1.0367, 0.9862, 0.9805, 0.9821, 0.9732,\n",
       "                      0.9930, 1.0025, 1.0099, 0.9891, 1.0105, 0.9630, 1.0084, 0.9679, 0.9538,\n",
       "                      0.9524, 0.9181, 0.9618, 1.0292, 0.9847, 1.0018, 1.0069, 0.9671, 1.0225,\n",
       "                      1.0126, 0.9757, 0.9812, 0.9737, 1.0053, 1.0297, 0.9820, 1.0080, 0.9823,\n",
       "                      1.0176, 0.9977, 0.9868, 1.0124, 1.0061, 1.0137, 1.0125, 1.0068, 1.0081,\n",
       "                      0.9690, 0.9846, 1.0079, 0.9991, 1.0257, 0.9994, 1.0046, 0.9850, 0.9766,\n",
       "                      0.9791, 0.8851, 0.9933, 1.0005, 0.9850, 1.0057, 1.0012, 1.0231, 1.0268,\n",
       "                      0.9809, 0.9930, 1.0223, 0.9670, 1.0029, 1.0076, 1.0276, 0.9635, 1.0022,\n",
       "                      0.9630, 1.0138, 0.9847, 0.9826, 1.0317, 1.0011, 0.9550, 1.0192, 0.9650,\n",
       "                      1.0355, 0.9717, 0.9788, 0.9537, 1.0243, 0.9922, 1.0266, 0.9929, 1.0278,\n",
       "                      1.0074, 1.0352, 0.9793, 0.9930, 1.0136, 1.0113, 0.9750, 0.9958, 0.9881,\n",
       "                      1.0054, 1.0002, 1.0151, 1.0088, 1.0201, 1.0294, 1.0005, 0.9633, 0.9834,\n",
       "                      0.9772, 1.0177, 0.9903, 0.9630, 1.0071, 0.9940, 0.9375, 1.0521, 0.9581,\n",
       "                      1.0328, 0.9951, 1.0322, 0.9090, 1.0275, 0.9719, 0.9926, 0.9622, 1.0347,\n",
       "                      0.9659, 1.0227, 0.9895, 1.0429, 0.9608, 1.0346, 0.9927, 1.0206, 1.0072,\n",
       "                      1.0072, 0.9722, 1.0197, 0.9781, 0.9958, 0.9757, 1.0086, 0.9489, 1.0016,\n",
       "                      1.0070, 0.9726, 1.0091, 1.0300, 0.9934, 1.0247, 0.9843, 0.9973, 0.9706,\n",
       "                      0.9963, 0.9191, 1.0301, 0.9525, 1.0398, 0.9668, 1.0269, 0.9723, 1.0349,\n",
       "                      0.9451, 1.0042, 0.9918, 1.0562, 1.0271, 0.9564, 0.9491, 1.0341, 1.0058,\n",
       "                      1.0063, 0.9541, 1.0300, 0.9608, 1.0119, 1.0126, 1.0391, 0.9559, 0.9391,\n",
       "                      0.9776, 1.0254, 0.9866], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm2.bias',\n",
       "              tensor([-6.8920e-03, -7.2111e-02,  7.9891e-03, -5.9260e-02,  5.5812e-02,\n",
       "                      -4.0608e-02,  1.0242e-01,  1.8335e-03,  1.9658e-02,  1.2593e-01,\n",
       "                      -3.3519e-02, -1.4055e-02,  1.0899e-01, -6.4207e-02,  1.0087e-01,\n",
       "                      -6.2346e-02, -2.5078e-02, -2.2093e-02,  2.8857e-02,  1.6391e-01,\n",
       "                      -6.0728e-02, -6.6126e-02, -3.3980e-02,  4.5222e-02, -8.5235e-02,\n",
       "                       5.1175e-02,  2.3125e-02,  4.2020e-02,  2.6068e-02, -2.8990e-02,\n",
       "                      -9.2827e-02,  8.8299e-02, -5.6933e-03, -9.7521e-02, -3.1562e-02,\n",
       "                      -4.4766e-02, -8.0784e-02, -8.1661e-02, -3.1638e-02,  5.7038e-02,\n",
       "                      -1.0289e-01, -1.0766e-02, -1.4374e-03, -3.1641e-02, -9.6235e-02,\n",
       "                       5.0753e-03,  4.7085e-02,  1.9778e-02, -6.0350e-02, -5.9486e-02,\n",
       "                       8.1317e-03, -3.0062e-02, -5.6837e-02, -6.1819e-02, -4.3450e-02,\n",
       "                       4.1574e-02, -7.2482e-02, -1.0855e-01,  8.8677e-02,  8.3320e-02,\n",
       "                       1.3007e-01, -2.1862e-02,  2.1758e-02,  1.5764e-02,  5.9907e-02,\n",
       "                      -4.0504e-02, -5.4790e-02, -2.3311e-02, -5.3295e-02, -7.9235e-02,\n",
       "                       1.4554e-01,  5.0846e-02,  3.3909e-02, -8.2725e-02, -1.1319e-01,\n",
       "                       5.7359e-02,  2.2162e-02, -1.8503e-02, -4.6059e-03, -3.1436e-02,\n",
       "                      -2.1263e-02, -1.2375e-01,  1.3234e-01,  3.2774e-02, -3.1062e-02,\n",
       "                       4.0217e-03, -8.6824e-02,  9.1485e-02, -2.1540e-02, -3.7683e-02,\n",
       "                      -1.2644e-02, -1.4852e-01,  7.8963e-02,  3.6596e-02,  5.6371e-02,\n",
       "                      -5.4107e-02,  4.6956e-02,  6.4316e-02,  1.1535e-01, -4.2919e-05,\n",
       "                       9.6756e-02, -1.5499e-01, -1.5210e-02,  2.8213e-02, -8.4908e-02,\n",
       "                      -9.3644e-02,  1.5095e-02, -1.4895e-01, -4.0220e-05, -8.2155e-03,\n",
       "                       4.6576e-02,  1.8349e-02,  1.4895e-01, -9.7923e-02,  4.1825e-02,\n",
       "                      -7.2580e-02, -1.1028e-02,  8.9832e-02,  4.7372e-02, -1.6943e-01,\n",
       "                       5.6088e-02,  5.8194e-02,  7.6173e-02,  2.4986e-02,  3.7966e-02,\n",
       "                       2.6056e-03,  9.8641e-04, -5.4875e-02, -1.0071e-02, -1.8660e-02,\n",
       "                      -9.9124e-02,  1.8528e-02,  1.9838e-01, -6.5790e-02,  3.8815e-02,\n",
       "                      -9.2702e-02, -3.3865e-02,  3.2837e-02,  1.1691e-01, -1.2156e-01,\n",
       "                      -3.4788e-02,  2.5079e-02, -7.2349e-02, -1.3093e-03,  6.1893e-02,\n",
       "                      -6.5288e-02, -2.6841e-02, -7.9301e-03,  7.3063e-02, -4.9616e-02,\n",
       "                      -2.6508e-02, -1.2164e-01, -1.6969e-02,  3.7896e-02, -2.6305e-03,\n",
       "                      -1.7341e-01,  3.5728e-02,  6.8970e-02,  2.7231e-02, -5.8719e-03,\n",
       "                       1.0030e-02,  3.1528e-02,  1.0657e-01, -4.8645e-02, -8.1379e-03,\n",
       "                       3.9293e-02, -1.1886e-02, -7.2036e-02, -6.1012e-02,  1.7504e-02,\n",
       "                      -5.3645e-02, -8.0437e-02,  7.9758e-02,  4.7421e-02,  1.8195e-01,\n",
       "                      -1.6304e-01,  5.7535e-02, -4.0829e-02, -7.4070e-02,  9.5699e-02,\n",
       "                       3.9215e-02, -4.3308e-02,  1.4764e-01, -1.1513e-02,  5.2592e-02,\n",
       "                      -1.6017e-02,  1.7335e-02, -4.3716e-02, -2.9863e-02, -7.7705e-02,\n",
       "                      -6.0049e-02, -3.3052e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm3.weight',\n",
       "              tensor([1.5975, 1.2724, 1.6548, 1.5620, 1.5888, 1.4758, 1.6184, 1.6951, 1.5243,\n",
       "                      1.4638, 1.5494, 1.4919, 1.4811, 1.4739, 1.4174, 1.4991, 1.6934, 1.6613,\n",
       "                      1.5637, 1.5082, 1.5144, 1.4759, 1.5891, 1.6599, 1.6046, 1.5935, 1.5738,\n",
       "                      1.5326, 1.4682, 1.4928, 1.5036, 1.5927, 1.5237, 1.5367, 1.5264, 1.6365,\n",
       "                      1.6331, 1.5854, 1.6481, 1.5102, 1.5754, 1.6723, 1.7262, 1.6386, 1.4230,\n",
       "                      1.6149, 1.6269, 1.5825, 1.5622, 1.4946, 1.6169, 1.5873, 1.5803, 1.6863,\n",
       "                      1.5078, 1.4214, 1.5883, 1.5988, 1.6939, 1.5567, 1.5356, 1.6329, 1.4972,\n",
       "                      1.5688, 1.4995, 1.5494, 1.5703, 1.6860, 1.6307, 1.5239, 1.4986, 1.3610,\n",
       "                      1.6621, 1.5923, 1.5038, 1.5266, 1.6668, 1.6143, 1.5333, 1.6409, 1.7163,\n",
       "                      1.5194, 1.6427, 1.5934, 1.6433, 1.5330, 1.3579, 1.1677, 1.4122, 1.5534,\n",
       "                      1.5612, 1.5729, 1.5860, 1.5081, 1.6167, 1.4766, 1.6344, 1.5414, 1.5861,\n",
       "                      1.6728, 1.6470, 1.5270, 1.6229, 1.6673, 1.5391, 1.6425, 1.5835, 1.4465,\n",
       "                      1.6218, 1.6223, 1.5890, 1.6183, 1.4834, 1.5697, 1.5915, 1.6561, 1.5420,\n",
       "                      1.4091, 1.6105, 1.5370, 1.5680, 1.5285, 1.4782, 1.3529, 1.6642, 1.5768,\n",
       "                      1.6011, 1.5639, 1.6438, 1.4897, 1.5292, 1.5429, 1.3970, 1.6128, 1.6716,\n",
       "                      1.5921, 1.6126, 1.6582, 1.5526, 1.4635, 1.4761, 1.6187, 1.4952, 1.6069,\n",
       "                      1.4046, 1.5375, 1.5449, 1.6226, 1.6520, 1.5129, 1.6531, 1.5954, 1.6067,\n",
       "                      1.6175, 1.5102, 1.3445, 1.6366, 1.4525, 1.6684, 1.5970, 1.6105, 1.5532,\n",
       "                      1.6115, 1.5977, 1.6835, 1.4844, 1.6495, 1.5761, 1.5711, 1.5903, 1.5764,\n",
       "                      1.5800, 1.6468, 1.4435, 1.4853, 1.5279, 1.5721, 1.6540, 1.4830, 1.4447,\n",
       "                      1.4530, 1.6237, 1.4736, 1.5924, 1.7227, 1.6058, 1.7411, 1.4939, 1.5363,\n",
       "                      1.4588, 1.6092, 1.6925], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm3.bias',\n",
       "              tensor([-2.1745e-02, -3.7432e-02,  9.1398e-02, -4.1320e-02,  3.1379e-02,\n",
       "                      -6.1644e-02,  9.6546e-02,  2.8034e-02, -3.1854e-02,  6.8596e-02,\n",
       "                      -1.2323e-01,  1.1661e-02,  1.6202e-02, -1.2381e-01,  8.6480e-02,\n",
       "                      -5.8939e-02,  2.9780e-02, -1.2212e-03,  6.2275e-02, -3.1589e-02,\n",
       "                      -8.3103e-02,  1.1854e-03,  1.2437e-02,  4.1205e-02,  4.1702e-02,\n",
       "                       9.3354e-02, -4.5256e-02,  4.3816e-03, -4.4604e-02,  5.3999e-02,\n",
       "                      -1.9950e-02,  1.2070e-01, -1.7267e-02, -1.6632e-01,  8.4606e-02,\n",
       "                       1.8302e-02, -1.2448e-02,  1.2394e-02,  1.3967e-02,  8.4074e-03,\n",
       "                      -6.2931e-02,  8.9536e-02, -8.0722e-02, -1.1229e-03, -2.6511e-02,\n",
       "                       1.9918e-02,  3.9635e-02,  1.3602e-02, -4.6308e-02, -4.1713e-02,\n",
       "                       7.2625e-02, -3.7655e-03,  5.8490e-02, -8.1118e-02,  1.7010e-02,\n",
       "                      -2.1432e-02, -6.9998e-02, -4.1613e-02,  5.8596e-02,  7.4762e-02,\n",
       "                       3.3998e-02, -1.8953e-02, -4.4246e-02, -2.5177e-02,  1.3385e-01,\n",
       "                      -3.5204e-02, -1.8826e-02,  4.2173e-02, -6.9824e-02, -5.1474e-02,\n",
       "                       8.0345e-02, -2.2259e-02,  7.4933e-02,  3.9226e-03, -8.5856e-02,\n",
       "                      -1.5467e-03, -5.7900e-02,  3.4713e-02, -6.3154e-02, -6.3245e-02,\n",
       "                      -1.8890e-02, -4.6423e-02,  1.0968e-01,  7.3472e-02, -2.3538e-03,\n",
       "                       3.4127e-02,  5.6415e-02, -4.6972e-02,  9.3600e-04, -3.3573e-02,\n",
       "                       2.3302e-02, -1.0016e-01,  8.3620e-02,  8.4229e-02,  2.8950e-02,\n",
       "                      -3.6067e-02, -3.6434e-03,  8.7206e-02,  8.3662e-02, -3.3972e-02,\n",
       "                       5.6259e-02, -3.2464e-02, -6.7635e-02, -9.7480e-02, -4.9164e-02,\n",
       "                      -1.0579e-01,  6.9177e-02, -4.9910e-02,  1.2666e-01, -6.0323e-02,\n",
       "                       6.7384e-03,  1.3177e-02,  1.0023e-01, -6.8097e-02,  4.8643e-02,\n",
       "                      -6.8356e-02,  3.6083e-02,  1.0359e-01,  4.7605e-02, -8.2346e-02,\n",
       "                       4.0556e-02,  7.5959e-02, -7.4442e-02, -6.0737e-02,  4.5956e-02,\n",
       "                       2.3323e-02, -3.7467e-02, -4.0692e-02, -1.7497e-02, -1.7762e-02,\n",
       "                      -5.7937e-02, -8.8918e-02,  9.5461e-02,  4.9966e-03,  3.5089e-02,\n",
       "                      -2.9846e-02,  7.0613e-03, -6.9217e-02,  9.9124e-02, -5.5895e-02,\n",
       "                       7.3908e-02,  4.2186e-03, -6.6830e-02,  2.2228e-03,  1.3826e-03,\n",
       "                      -5.0106e-02, -8.1044e-02,  8.6144e-02,  9.9316e-02,  5.8107e-02,\n",
       "                      -4.2341e-03, -1.2161e-01,  1.7558e-02, -2.0554e-02,  6.4554e-02,\n",
       "                       6.3170e-02, -5.9232e-02,  3.0071e-02, -9.1322e-02,  1.1285e-02,\n",
       "                       1.0183e-01,  9.0252e-02,  6.0811e-02, -5.7993e-02, -8.9038e-03,\n",
       "                       3.9626e-02, -3.0313e-02, -6.0946e-02, -6.2827e-02,  5.1603e-02,\n",
       "                      -4.9608e-02, -1.0293e-01,  9.8684e-02,  5.9090e-02,  8.2171e-02,\n",
       "                      -1.2210e-01,  2.2958e-02,  1.0011e-04,  1.1252e-02,  1.1200e-01,\n",
       "                       4.7166e-02, -3.9170e-02,  7.1433e-02,  5.6726e-02,  1.1172e-01,\n",
       "                       3.0972e-02,  1.0202e-01, -2.1346e-02, -1.0029e-03, -2.3210e-02,\n",
       "                       4.9386e-02,  1.7554e-02], device='cuda:0')),\n",
       "             ('word_emb.weight',\n",
       "              tensor([[-0.0231, -0.1089, -0.0314,  ..., -0.0823,  0.0072, -0.0278],\n",
       "                      [-0.0085, -0.1220,  0.0351,  ..., -0.0374,  0.0094, -0.0614],\n",
       "                      [-0.0476,  0.0218, -0.0224,  ...,  0.0235, -0.0009, -0.0247],\n",
       "                      ...,\n",
       "                      [-0.0081, -0.0108,  0.0223,  ...,  0.0252,  0.0296,  0.0094],\n",
       "                      [-0.0247, -0.0056, -0.0418,  ...,  0.0059, -0.0127, -0.0348],\n",
       "                      [ 0.0083, -0.0188,  0.0275,  ...,  0.0063,  0.0331,  0.0015]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.weight',\n",
       "              tensor([[ 0.1444,  0.0340,  0.0644,  ..., -0.0600,  0.0713,  0.0388],\n",
       "                      [-0.0251,  0.0054, -0.0187,  ..., -0.0408,  0.0636, -0.0873],\n",
       "                      [-0.0032,  0.0023, -0.0051,  ...,  0.0436, -0.0230,  0.0074],\n",
       "                      ...,\n",
       "                      [-0.1845,  0.0455,  0.0306,  ..., -0.0771,  0.1305, -0.0463],\n",
       "                      [ 0.0742,  0.0575,  0.0213,  ..., -0.0602, -0.1442,  0.0134],\n",
       "                      [-0.0883, -0.0248, -0.0477,  ..., -0.0651,  0.1710,  0.0396]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.bias',\n",
       "              tensor([ 0.0367,  0.0367,  0.0446,  0.0219,  0.0460,  0.0366,  0.0208,  0.0368,\n",
       "                       0.0274,  0.0283,  0.0334,  0.0452,  0.0585,  0.0373,  0.0305,  0.0137,\n",
       "                       0.0124,  0.0298,  0.0421,  0.0277,  0.0452,  0.0322,  0.0301,  0.0492,\n",
       "                       0.0437,  0.0297,  0.0410,  0.0243,  0.0189,  0.0304,  0.0339,  0.0521,\n",
       "                       0.0296,  0.0292,  0.0365,  0.0424,  0.0394,  0.0260,  0.0290, -0.1153,\n",
       "                       0.0482,  0.0323,  0.0422,  0.0447,  0.0325,  0.0543,  0.0319,  0.0278,\n",
       "                       0.0530,  0.0400,  0.0210,  0.0288,  0.0223,  0.0430,  0.0277,  0.0460,\n",
       "                       0.0547,  0.0531,  0.0318,  0.0242,  0.0095,  0.0335,  0.0366,  0.0305,\n",
       "                       0.0343,  0.0316, -0.1597, -0.0946,  0.0412,  0.0336,  0.0254,  0.0271,\n",
       "                       0.0375,  0.0436,  0.0252,  0.0342,  0.0261,  0.0067,  0.0355,  0.0286,\n",
       "                       0.0010,  0.0413,  0.0498,  0.0209,  0.0460,  0.0273,  0.0414,  0.0326,\n",
       "                       0.0336,  0.0391,  0.0352,  0.0262,  0.0508,  0.0134, -0.0046,  0.0165,\n",
       "                       0.0193, -0.0025,  0.0485,  0.0472,  0.0201,  0.0363,  0.0423,  0.0370,\n",
       "                       0.0229,  0.0158,  0.0182,  0.0356,  0.0272,  0.0355,  0.0479,  0.0462,\n",
       "                       0.0214,  0.0181,  0.0375,  0.0341,  0.0451,  0.0350,  0.0255,  0.0278,\n",
       "                       0.0413,  0.0445,  0.0490,  0.0332,  0.0314,  0.0382,  0.0394,  0.0175,\n",
       "                       0.0292,  0.0529,  0.0226,  0.0281,  0.0379,  0.0319,  0.0512,  0.0271,\n",
       "                      -0.0647,  0.0412,  0.0312,  0.0391,  0.0211,  0.0336,  0.0289,  0.0191,\n",
       "                       0.0337,  0.0268,  0.0303,  0.0473,  0.0328,  0.0516,  0.0380,  0.0246,\n",
       "                       0.0456,  0.0212,  0.0294,  0.0486,  0.0393,  0.0429,  0.0533,  0.0540,\n",
       "                       0.0356,  0.0228,  0.0508,  0.0241,  0.0382,  0.0146,  0.0449,  0.0329,\n",
       "                      -0.0008,  0.0428,  0.0238,  0.0272,  0.0252,  0.0412,  0.0356,  0.0387,\n",
       "                       0.0285,  0.0429,  0.0443,  0.0244,  0.0293,  0.0614,  0.0343,  0.0398,\n",
       "                       0.0358,  0.0491,  0.0581,  0.0435,  0.0199,  0.0336,  0.0417,  0.0509,\n",
       "                       0.0435,  0.0375, -0.1228,  0.0485,  0.0345,  0.0338,  0.0488,  0.0187,\n",
       "                       0.0395,  0.0460,  0.0413,  0.0592,  0.0222,  0.0452,  0.0471,  0.0249,\n",
       "                       0.0293,  0.0283,  0.0338,  0.0372,  0.0125,  0.0387,  0.0422,  0.0441,\n",
       "                       0.0643,  0.0339,  0.0435,  0.0504,  0.0268,  0.0346,  0.0377,  0.0376,\n",
       "                       0.0362,  0.0357,  0.0412,  0.0415,  0.0405,  0.0390,  0.0456,  0.0138,\n",
       "                       0.0539,  0.0319,  0.0322,  0.0483,  0.0394,  0.0345,  0.0548,  0.0461,\n",
       "                       0.0425,  0.0331,  0.0341,  0.0517,  0.0350,  0.0444,  0.0211,  0.0616,\n",
       "                       0.0328,  0.0437,  0.0298,  0.0275,  0.0497,  0.0511,  0.0505,  0.0459,\n",
       "                       0.0424,  0.0362,  0.0318,  0.0293,  0.0406,  0.0104, -0.0026,  0.0369,\n",
       "                       0.0401,  0.0542,  0.0514,  0.0374,  0.0310,  0.0505,  0.0122,  0.0537,\n",
       "                       0.0231,  0.0114,  0.0334,  0.0269,  0.0314,  0.0742,  0.0416,  0.0607,\n",
       "                       0.0224,  0.0553,  0.0150,  0.0325,  0.0202,  0.0368,  0.0151,  0.0342,\n",
       "                       0.0258,  0.0234,  0.0251,  0.0300,  0.0288,  0.0273,  0.0321,  0.0297,\n",
       "                       0.0494,  0.0158,  0.0285,  0.0372,  0.0474,  0.0394,  0.0414,  0.0234,\n",
       "                       0.0215,  0.0232,  0.0512,  0.0542,  0.0233,  0.0346,  0.0339,  0.0299,\n",
       "                       0.0217,  0.0494,  0.0446,  0.0281,  0.0337,  0.0264,  0.0284,  0.0275,\n",
       "                       0.0436,  0.0378,  0.0382,  0.0647,  0.0230,  0.0205,  0.0480,  0.0513,\n",
       "                       0.0315,  0.0357,  0.0339,  0.0303,  0.0326,  0.0506,  0.0328,  0.0204,\n",
       "                       0.0381,  0.0416,  0.0173,  0.0411,  0.0272,  0.0085,  0.0156,  0.0360,\n",
       "                       0.0204,  0.0305,  0.0407,  0.0119,  0.0505,  0.0621,  0.0526,  0.0305,\n",
       "                       0.0336,  0.0358,  0.0229,  0.0184,  0.0481,  0.0507,  0.0355,  0.0514,\n",
       "                       0.0353,  0.0256,  0.0560,  0.0376,  0.0208,  0.0431,  0.0445,  0.0349,\n",
       "                       0.0406,  0.0528,  0.0362,  0.0411,  0.0235,  0.0435,  0.0254,  0.0380,\n",
       "                       0.0340,  0.0437,  0.0214,  0.0261,  0.0569,  0.0366,  0.0340,  0.0397,\n",
       "                       0.0292,  0.0318,  0.0499,  0.0217,  0.0362,  0.0489,  0.0325,  0.0299,\n",
       "                       0.0347,  0.0140,  0.0401,  0.0337,  0.0293,  0.0319,  0.0401,  0.0166,\n",
       "                       0.0409,  0.0283,  0.0460,  0.0292, -0.0452,  0.0404,  0.0409,  0.0639,\n",
       "                       0.0544,  0.0192,  0.0343,  0.0396,  0.0338,  0.0390,  0.0247,  0.0402,\n",
       "                       0.0303,  0.0520,  0.0566,  0.0459,  0.0324,  0.0446,  0.0416,  0.0417,\n",
       "                       0.0429,  0.0408,  0.0326,  0.0238,  0.0261,  0.0343,  0.0249,  0.0375,\n",
       "                       0.0517,  0.0296,  0.0351,  0.0362,  0.0383,  0.0249,  0.0307,  0.0346,\n",
       "                       0.0210,  0.0310,  0.0382,  0.0436,  0.0326,  0.0161,  0.0220,  0.0578,\n",
       "                       0.0383,  0.0368,  0.0376,  0.0232,  0.0282,  0.0396,  0.0293,  0.0221,\n",
       "                       0.0396,  0.0393,  0.0216,  0.0416,  0.0284,  0.0104,  0.0295,  0.0528,\n",
       "                       0.0223,  0.0359,  0.0386,  0.0502,  0.0375,  0.0359,  0.0299,  0.0444,\n",
       "                       0.0233,  0.0225,  0.0430,  0.0231,  0.0368,  0.0465,  0.0291,  0.0449,\n",
       "                       0.0453, -0.0254,  0.0386,  0.0067,  0.0203,  0.0294,  0.0479,  0.0145,\n",
       "                       0.0424,  0.0439,  0.0434,  0.0364,  0.0114,  0.0381,  0.0510,  0.0276,\n",
       "                       0.0504,  0.0410,  0.0253,  0.0479,  0.0389,  0.0160,  0.0780,  0.0393,\n",
       "                       0.0206,  0.0410,  0.0437,  0.0506,  0.0463,  0.0419,  0.0185,  0.0493],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0307,  0.1376, -0.1259,  ...,  0.1168, -0.0896,  0.1418],\n",
       "                      [-0.0776,  0.0154,  0.0732,  ...,  0.1017,  0.0250,  0.1068],\n",
       "                      [ 0.1295,  0.0259,  0.0450,  ...,  0.0666, -0.1836,  0.0254],\n",
       "                      ...,\n",
       "                      [-0.0734,  0.1149, -0.0034,  ...,  0.0244,  0.0729,  0.0403],\n",
       "                      [ 0.0233, -0.0057, -0.1105,  ...,  0.0581,  0.0574,  0.0630],\n",
       "                      [ 0.0348, -0.0349, -0.0884,  ..., -0.0703,  0.0813, -0.0675]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.0504,  0.0212,  0.0022,  0.0093,  0.0279,  0.0439,  0.0426,  0.0800,\n",
       "                       0.0185,  0.0387,  0.0355, -0.0141,  0.0065,  0.0312,  0.0551,  0.0058,\n",
       "                       0.0553,  0.0417,  0.0232,  0.0351,  0.0283,  0.0414,  0.0464,  0.0411,\n",
       "                       0.0505,  0.0191,  0.0164, -0.0267,  0.0300,  0.0226,  0.0367,  0.0480,\n",
       "                       0.0487,  0.0170,  0.0403,  0.0387,  0.0288,  0.0126,  0.0152,  0.0068,\n",
       "                      -0.0252,  0.0085,  0.0476,  0.0299,  0.0429,  0.0683, -0.0072,  0.0150,\n",
       "                       0.0333,  0.0331,  0.0442,  0.0381,  0.0241,  0.0525,  0.0020,  0.0364,\n",
       "                       0.0290,  0.0310,  0.0431,  0.0215, -0.0232,  0.0296,  0.0324,  0.0382,\n",
       "                       0.0364,  0.0607,  0.0559,  0.0478,  0.0713,  0.0584,  0.0340,  0.0627,\n",
       "                       0.0277,  0.0508,  0.0381,  0.0389,  0.0223,  0.0102,  0.0263,  0.0363,\n",
       "                       0.0284,  0.0330,  0.0585,  0.0214,  0.0577,  0.0327,  0.0353,  0.0040,\n",
       "                       0.0646,  0.0359,  0.0555,  0.0409,  0.0464,  0.0225,  0.0331,  0.1127,\n",
       "                       0.0509,  0.0386,  0.0013,  0.0639,  0.0400,  0.0592,  0.0370,  0.0509,\n",
       "                       0.0241,  0.0281,  0.0544,  0.0423,  0.0530,  0.0372,  0.0399,  0.0856,\n",
       "                       0.0171, -0.0294,  0.0445,  0.0151,  0.0490,  0.0433,  0.0189,  0.0435,\n",
       "                       0.0258,  0.0083,  0.0336,  0.0276,  0.0512,  0.0406,  0.0370,  0.0197,\n",
       "                       0.0316,  0.0330,  0.0477,  0.0169,  0.0220,  0.0433,  0.0575,  0.0413,\n",
       "                       0.0679,  0.0384, -0.0251,  0.0254,  0.0546,  0.0362,  0.0482,  0.0326,\n",
       "                       0.0263, -0.0047, -0.0019,  0.0080, -0.0008,  0.0616, -0.0103,  0.0510,\n",
       "                       0.0318,  0.0506,  0.0032,  0.0481,  0.0234,  0.0524,  0.0317,  0.0267,\n",
       "                       0.0231,  0.0564, -0.0108,  0.0599,  0.0200,  0.0225,  0.0330,  0.0373,\n",
       "                       0.0364,  0.0255,  0.0035,  0.0215,  0.0492,  0.0392,  0.0290,  0.0336,\n",
       "                       0.0435,  0.0183,  0.0220,  0.0075,  0.0397,  0.0468,  0.0087,  0.0283,\n",
       "                       0.0179,  0.0056,  0.0041,  0.0308,  0.0331,  0.0268,  0.0514,  0.0010],\n",
       "                     device='cuda:0')),\n",
       "             ('dec_fc.weight',\n",
       "              tensor([[-0.0114,  0.0572, -0.0272,  ..., -0.0415,  0.0233,  0.0115],\n",
       "                      [-0.0003, -0.0729,  0.0486,  ...,  0.0926, -0.0621, -0.0563],\n",
       "                      [-0.0375, -0.0020, -0.0117,  ..., -0.0593,  0.0189,  0.0245],\n",
       "                      ...,\n",
       "                      [-0.0326,  0.0691, -0.0299,  ..., -0.0161,  0.0336,  0.0115],\n",
       "                      [-0.0013,  0.0943,  0.0008,  ..., -0.0436,  0.0268,  0.0173],\n",
       "                      [-0.0258,  0.0902, -0.0465,  ..., -0.0315,  0.0217,  0.0177]],\n",
       "                     device='cuda:0')),\n",
       "             ('dec_fc.bias',\n",
       "              tensor([-0.1765,  0.1406, -0.0783,  ..., -0.0784, -0.0632, -0.0761],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.bn0.weight',\n",
       "              tensor([1.2579, 1.2287, 1.1752, 1.1472, 1.1341, 1.1017, 1.0914, 1.0787, 1.0651,\n",
       "                      1.0756, 1.0683, 1.0589, 1.0478, 1.0323, 1.0432, 1.0094, 1.0038, 1.0202,\n",
       "                      1.0210, 1.0268, 1.0409, 1.0565, 1.0200, 1.0603, 1.0618, 1.0505, 1.0631,\n",
       "                      1.0512, 1.0770, 1.0790, 1.0833, 1.0788, 1.0826, 1.0741, 1.0893, 1.0994,\n",
       "                      1.1181, 1.1037, 1.1052, 1.1233, 1.1174, 1.1264, 1.1512, 1.1866, 1.2267,\n",
       "                      1.2610, 1.2632, 1.3015, 1.2884, 1.3413, 1.3513, 1.3659, 1.3383, 1.3445,\n",
       "                      1.3790, 1.3468, 1.3447, 1.3394, 1.2890, 1.2610, 1.2722, 1.2695, 1.2540,\n",
       "                      1.2942], device='cuda:0')),\n",
       "             ('encoder.base.bn0.bias',\n",
       "              tensor([ 0.1418,  0.1614,  0.2051,  0.2250,  0.2054,  0.2128,  0.2234,  0.2539,\n",
       "                       0.2251,  0.2122,  0.2185,  0.2002,  0.2017,  0.1822,  0.1683,  0.1444,\n",
       "                       0.1269,  0.1714,  0.1422,  0.1387,  0.1513,  0.1419,  0.1510,  0.1334,\n",
       "                       0.1520,  0.1332,  0.1163,  0.1276,  0.1073,  0.1257,  0.1314,  0.1131,\n",
       "                       0.1414,  0.1328,  0.1064,  0.1035,  0.0991,  0.1022,  0.1113,  0.1031,\n",
       "                       0.0918,  0.0667,  0.0340,  0.0058, -0.0343, -0.0510, -0.0735, -0.0952,\n",
       "                      -0.1210, -0.1620, -0.1719, -0.1713, -0.1978, -0.1898, -0.2296, -0.2104,\n",
       "                      -0.2010, -0.2143, -0.1837, -0.2698, -0.2991, -0.3428, -0.3216, -0.2706],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.bn0.running_mean',\n",
       "              tensor([-11.1140, -11.0367, -11.6734, -12.0733, -12.2690, -13.1829, -12.8244,\n",
       "                      -13.8654, -13.6266, -14.1256, -14.2417, -14.2807, -15.1179, -14.4914,\n",
       "                      -15.3485, -15.0152, -15.6214, -15.3768, -15.8950, -15.9210, -16.0077,\n",
       "                      -16.3230, -16.5533, -16.4185, -16.8656, -16.9338, -17.1143, -17.2644,\n",
       "                      -17.5348, -17.6393, -17.8601, -18.0469, -18.2951, -18.5422, -18.7396,\n",
       "                      -18.8787, -19.0903, -19.3984, -19.7062, -19.8755, -20.3276, -20.6704,\n",
       "                      -20.9696, -21.2577, -21.5934, -21.9502, -22.1573, -22.3885, -22.6773,\n",
       "                      -23.0146, -23.3851, -23.7347, -23.9969, -24.3780, -24.8172, -25.1915,\n",
       "                      -25.6874, -26.2066, -26.6295, -27.0645, -27.5256, -27.8966, -28.4427,\n",
       "                      -29.7023], device='cuda:0')),\n",
       "             ('encoder.base.bn0.running_var',\n",
       "              tensor([108.5400, 100.5474, 104.6310, 106.9863, 107.7479, 114.1496, 111.6755,\n",
       "                      120.0199, 117.8161, 121.8113, 122.4541, 121.5557, 126.3898, 121.3896,\n",
       "                      127.6692, 124.6137, 129.6735, 125.9474, 126.5959, 126.0733, 128.5122,\n",
       "                      131.1895, 132.9866, 131.1968, 136.2513, 136.4128, 137.8435, 138.7266,\n",
       "                      140.4252, 142.1982, 143.6312, 146.2618, 149.1181, 150.0039, 152.3840,\n",
       "                      154.4992, 157.6141, 161.5698, 165.2521, 167.2338, 169.0995, 172.5907,\n",
       "                      176.6368, 178.3062, 181.3046, 186.4619, 188.5393, 190.9229, 195.1447,\n",
       "                      199.3110, 203.5005, 207.1522, 209.5275, 213.5443, 217.1879, 221.1509,\n",
       "                      225.1093, 229.9661, 233.8673, 238.2281, 244.0726, 246.9852, 253.2982,\n",
       "                      270.9163], device='cuda:0')),\n",
       "             ('encoder.base.bn0.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.conv1.weight',\n",
       "              tensor([[[[-3.7039e-02, -4.2758e-01,  4.6078e-01],\n",
       "                        [-9.8838e-02, -4.7424e-01,  3.5086e-01],\n",
       "                        [ 5.4757e-02, -2.9605e-01,  4.8484e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3487e-01, -2.7748e-01, -2.2969e-01],\n",
       "                        [-2.5529e-03, -1.0134e-01, -9.9216e-02],\n",
       "                        [ 8.8498e-02,  4.3399e-01,  3.1902e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8117e-01,  2.1679e-01,  8.6598e-03],\n",
       "                        [-3.0433e-01,  4.2776e-01, -2.8384e-02],\n",
       "                        [-3.1323e-01,  3.7712e-01, -8.6349e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1328e-01, -4.7214e-01, -1.5421e-01],\n",
       "                        [-7.4739e-03,  1.5373e-01, -9.9434e-02],\n",
       "                        [ 5.1257e-01,  3.8470e-01,  2.0314e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2202e-01,  1.1475e-01,  1.7375e-01],\n",
       "                        [ 4.6711e-02, -2.4738e-01, -1.1763e-01],\n",
       "                        [-1.2941e-01, -1.4176e-01, -8.9102e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.6680e-01, -5.6923e-01, -3.8833e-01],\n",
       "                        [ 7.2493e-01, -2.7824e-01,  9.7279e-03],\n",
       "                        [ 2.4725e-01, -1.6016e-01,  9.7753e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4617e-01,  1.1877e-01,  9.5465e-02],\n",
       "                        [ 5.3723e-02,  1.6259e-02,  3.4303e-02],\n",
       "                        [-2.3713e-01, -1.7044e-01, -7.7720e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7280e-01,  5.4870e-01, -3.0124e-01],\n",
       "                        [-3.1358e-01,  4.4885e-01, -2.8404e-01],\n",
       "                        [-1.4353e-01,  5.0320e-01, -2.3500e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.4014e-04, -6.3007e-02, -2.5290e-01],\n",
       "                        [-1.3695e-02, -7.0924e-02, -1.0243e-01],\n",
       "                        [ 1.5860e-01,  2.4922e-01,  7.3565e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2324e-01, -2.8807e-01,  7.9693e-01],\n",
       "                        [-2.5401e-01, -1.1556e-01,  2.5972e-01],\n",
       "                        [-2.0476e-01, -4.7462e-01, -3.4198e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0406e-01,  5.1279e-02, -3.6834e-01],\n",
       "                        [-2.3591e-01,  2.6704e-01,  1.5689e-01],\n",
       "                        [-2.8982e-01, -2.9980e-02,  1.7038e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.3808e-02, -2.1475e-01,  2.4791e-01],\n",
       "                        [-1.5626e-01, -2.8334e-01,  9.1087e-02],\n",
       "                        [-8.4360e-02, -1.1746e-01,  1.6794e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2985e-01, -1.6245e-01, -3.5523e-01],\n",
       "                        [ 5.0251e-01, -1.0382e-01, -3.8975e-01],\n",
       "                        [ 2.4276e-01,  5.4808e-02, -2.7259e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4744e-01,  2.3009e-01,  8.3530e-01],\n",
       "                        [-1.4976e-01, -2.8275e-01,  2.4763e-01],\n",
       "                        [-1.9248e-01, -3.3660e-01, -1.4239e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.4622e-02, -5.6861e-02, -4.1197e-01],\n",
       "                        [ 5.7208e-01, -5.0864e-02, -4.3210e-01],\n",
       "                        [ 5.4853e-01,  5.0650e-02, -3.2082e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6556e-01, -5.3412e-01, -2.3066e-01],\n",
       "                        [-2.8875e-02,  2.4764e-02, -1.6386e-01],\n",
       "                        [-3.9200e-03,  5.5788e-01,  2.6252e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1720e-01, -4.7870e-01,  1.1784e-01],\n",
       "                        [-2.0684e-01,  6.2280e-02,  4.1311e-01],\n",
       "                        [ 5.6433e-02,  4.4781e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1200e-01,  2.7321e-01, -3.9600e-02],\n",
       "                        [-3.1901e-01,  3.1452e-01, -2.7479e-03],\n",
       "                        [-3.3993e-01,  3.6536e-01,  5.1426e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2003e-01,  1.8998e-01,  1.2129e-01],\n",
       "                        [-2.7666e-01,  9.2499e-02, -4.6375e-02],\n",
       "                        [-1.4448e-01,  6.8090e-02,  7.0098e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.7226e-02, -1.2127e-01,  2.3658e-01],\n",
       "                        [-2.4300e-01, -1.9383e-01,  1.1952e-01],\n",
       "                        [ 2.2897e-02, -8.7058e-02,  3.2172e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.3028e-02, -2.3576e-01,  4.1035e-02],\n",
       "                        [ 1.6508e-01, -1.1036e-01,  9.5125e-02],\n",
       "                        [-2.9840e-03,  1.8085e-01,  2.6306e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4316e-01,  1.1665e+00, -4.3412e-01],\n",
       "                        [ 6.2403e-02, -5.5574e-01,  1.2445e-01],\n",
       "                        [ 5.2582e-02, -3.2262e-01,  1.8072e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5395e-01,  6.7191e-01, -4.2608e-01],\n",
       "                        [ 1.4435e-01,  7.4019e-01, -1.7308e-01],\n",
       "                        [-2.6455e-01, -1.5263e-02, -2.0942e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5521e-01, -2.1611e-01,  7.1947e-02],\n",
       "                        [ 3.0966e-01, -3.0091e-01, -7.8164e-03],\n",
       "                        [ 3.0483e-01, -3.1466e-01,  1.5690e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9823e-01, -4.2168e-01,  6.0279e-02],\n",
       "                        [-3.2808e-01, -3.3818e-01,  3.4307e-01],\n",
       "                        [-9.1788e-02,  2.4978e-01,  6.2914e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0916e-01, -1.0632e-02,  4.5488e-01],\n",
       "                        [ 1.1837e-02, -5.0426e-01,  5.5825e-02],\n",
       "                        [ 1.8273e-01, -5.3850e-01,  8.3406e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.7359e-01, -1.8598e-01,  2.1945e-02],\n",
       "                        [ 2.8800e-01, -1.5747e-01, -1.0243e-01],\n",
       "                        [ 1.2883e-01, -3.4466e-01, -1.4244e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6872e-01, -1.4464e-01,  2.2020e-01],\n",
       "                        [-2.9175e-01,  2.2592e-01,  2.0379e-01],\n",
       "                        [-1.6604e-01,  2.6496e-01, -8.3792e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.5360e-02,  3.8966e-01,  1.4031e-01],\n",
       "                        [ 1.2257e-02,  2.1597e-02, -4.7005e-02],\n",
       "                        [ 9.1067e-02, -1.6526e-01, -1.9378e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0163e-01, -4.5580e-01,  3.1707e-01],\n",
       "                        [ 1.8935e-01, -4.5179e-01,  2.3650e-01],\n",
       "                        [ 2.7485e-01, -4.0986e-01,  2.1443e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7262e-01, -1.0266e-01, -4.1695e-01],\n",
       "                        [ 4.8492e-01, -2.3177e-03, -4.4562e-01],\n",
       "                        [ 3.3022e-01,  6.2551e-02, -3.2547e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2101e-01,  1.0126e-01, -3.6913e-02],\n",
       "                        [ 1.4700e-01,  6.9705e-02, -3.9404e-02],\n",
       "                        [-5.5072e-02, -1.1184e-01, -6.6921e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.8531e-01, -4.7569e-02, -2.3400e-01],\n",
       "                        [ 3.4791e-01, -7.7497e-02, -2.4477e-01],\n",
       "                        [ 3.7497e-01, -1.4277e-01, -3.4089e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1033e+00,  1.2753e-01, -6.2010e-03],\n",
       "                        [-7.2243e-01, -4.6420e-01, -5.2412e-03],\n",
       "                        [-3.7374e-01,  4.0990e-01, -7.4779e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1552e-01,  5.3512e-01,  8.1034e-02],\n",
       "                        [-1.1637e-01,  3.2702e-02,  9.7668e-03],\n",
       "                        [ 7.4868e-01, -5.4375e-01, -1.1775e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.5149e-01,  1.8367e-01,  5.9942e-01],\n",
       "                        [ 6.4945e-02, -3.3298e-01,  4.7456e-02],\n",
       "                        [-7.2457e-02, -6.4503e-01, -2.3545e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3996e-01, -4.6708e-01,  6.5029e-02],\n",
       "                        [ 4.1431e-01, -5.8810e-01, -1.2947e-01],\n",
       "                        [ 6.3620e-01, -4.6198e-01,  8.9512e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8400e-01,  6.0769e-01,  3.9696e-01],\n",
       "                        [-1.0041e-01, -5.5067e-02, -6.5041e-02],\n",
       "                        [-4.0160e-01, -5.5484e-01, -4.9943e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.7577e-01,  9.2406e-02,  9.8464e-02],\n",
       "                        [-2.4153e-01, -1.5672e-02,  1.2420e-01],\n",
       "                        [-6.3149e-01, -2.6339e-02,  4.9605e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.2362e-01, -4.3782e-01, -5.7199e-01],\n",
       "                        [ 5.7036e-02,  1.7327e-01,  5.8640e-02],\n",
       "                        [ 3.2428e-01,  2.6780e-01,  1.1553e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.2817e-02,  2.5345e-01, -2.3407e-01],\n",
       "                        [ 6.5310e-02,  1.0996e-01, -1.5513e-01],\n",
       "                        [-2.7904e-02,  2.7827e-01, -2.4337e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1770e-01,  3.1490e-01, -9.0855e-01],\n",
       "                        [-1.3766e-01,  3.3192e-03,  7.7066e-01],\n",
       "                        [-5.3093e-02, -3.6863e-01,  2.3213e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.5213e-02, -4.4828e-01,  6.2535e-02],\n",
       "                        [ 5.3619e-02, -4.0840e-01,  4.2392e-03],\n",
       "                        [ 2.0112e-01, -2.2866e-01,  3.0056e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9792e-01,  2.0081e-01,  1.9037e-01],\n",
       "                        [-2.4127e-01, -3.5608e-01, -2.4821e-01],\n",
       "                        [-3.8929e-02,  1.7353e-01, -4.8857e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0018e-01,  1.3077e-03, -2.7321e-01],\n",
       "                        [ 2.7165e-02,  3.3843e-02, -7.1168e-02],\n",
       "                        [ 5.3553e-02,  2.3183e-01, -4.2740e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8983e-01, -3.7882e-02,  7.5205e-01],\n",
       "                        [-4.3510e-01, -2.7665e-01,  5.3879e-01],\n",
       "                        [-3.7065e-01, -1.9793e-01,  3.8153e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0559e-01,  3.1273e-01,  1.5594e-01],\n",
       "                        [ 1.7393e-01, -6.1596e-02, -2.1482e-01],\n",
       "                        [ 1.0072e-01, -3.6248e-01, -2.6370e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0709e-01, -2.5422e-01,  5.1832e-02],\n",
       "                        [ 2.1006e-01, -1.3040e-01, -6.3120e-02],\n",
       "                        [ 6.7084e-02, -9.1186e-02,  8.9826e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0937e-01,  3.9595e-01,  2.2122e-01],\n",
       "                        [-1.6386e-01,  2.8206e-02, -1.7149e-01],\n",
       "                        [-4.2785e-01, -1.2610e-01, -1.6499e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4867e-01, -2.5180e-01, -3.5126e-01],\n",
       "                        [-1.1301e-01, -1.2536e-01, -8.0463e-02],\n",
       "                        [ 8.8822e-01,  3.9861e-01,  2.1695e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0753e-02,  4.4991e-02, -2.4421e-01],\n",
       "                        [ 9.5658e-03,  2.3654e-01, -2.5991e-01],\n",
       "                        [ 2.4366e-02,  3.8166e-01, -2.2451e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.7838e-01, -5.9983e-02,  1.4472e-01],\n",
       "                        [ 2.1890e-01, -8.2260e-02,  3.5236e-02],\n",
       "                        [-1.6305e-01, -5.5475e-01, -3.4149e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1640e-01,  7.8737e-02, -1.7762e-01],\n",
       "                        [-1.4516e-02,  1.3225e-01,  2.5413e-02],\n",
       "                        [-2.8115e-02,  1.8151e-01, -3.3639e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3240e-01, -3.6960e-01, -1.5010e-01],\n",
       "                        [ 6.2620e-02,  2.2893e-02,  1.1247e-01],\n",
       "                        [ 2.6827e-01,  3.7458e-01, -8.5182e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0860e-01,  1.1462e+00, -4.2346e-02],\n",
       "                        [-1.4127e-01,  3.0784e-01, -4.1399e-02],\n",
       "                        [-3.6094e-01, -1.9679e-01, -2.6113e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3481e-01, -2.5167e-01,  3.8530e-01],\n",
       "                        [-1.3977e-01, -3.6216e-01,  1.1309e-03],\n",
       "                        [ 2.0413e-01, -4.5980e-01,  2.9574e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.7680e-02,  2.6627e-01, -2.8784e-01],\n",
       "                        [-3.3592e-01,  2.4736e-01, -1.2399e-01],\n",
       "                        [-2.8255e-01,  8.0267e-01, -4.0267e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3659e-01, -5.6885e-01, -5.8263e-02],\n",
       "                        [ 2.3202e-01, -3.7275e-01,  4.3137e-02],\n",
       "                        [ 2.3751e-01, -1.1991e-01,  2.6967e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7833e-01,  6.2141e-01,  4.1701e-01],\n",
       "                        [-9.2735e-02, -3.6468e-02, -3.5021e-01],\n",
       "                        [-5.1336e-02,  1.1924e-01, -1.3558e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.9185e-01,  2.7757e-01,  1.5429e-01],\n",
       "                        [ 2.0638e-01, -9.3221e-02, -4.2492e-02],\n",
       "                        [-3.6869e-01, -2.5070e-01, -3.6196e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1912e-01, -3.4506e-01, -2.0505e-01],\n",
       "                        [-3.5524e-02,  5.3625e-02,  3.3577e-01],\n",
       "                        [ 1.5814e-01, -1.6911e-02,  5.5144e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1422e-01, -9.4341e-02,  4.3752e-02],\n",
       "                        [ 1.3863e+00, -7.7188e-02,  1.9691e-02],\n",
       "                        [-3.5302e-01, -1.1650e-01, -4.4031e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.5821e-01,  1.7370e-01,  3.0065e-01],\n",
       "                        [-4.7475e-01, -6.5231e-01, -4.0496e-01],\n",
       "                        [ 1.6438e-01,  4.0722e-01,  1.4705e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6765e-01, -3.5122e-01, -3.0718e-01],\n",
       "                        [-3.7997e-02, -1.8845e-01,  5.6407e-02],\n",
       "                        [ 2.3948e-01,  2.0316e-01,  6.8780e-01]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.conv2.weight',\n",
       "              tensor([[[[ 3.7716e-02,  3.8377e-01, -2.6829e-02],\n",
       "                        [ 1.4405e-02, -2.7071e-02, -1.1790e-01],\n",
       "                        [ 3.1483e-02, -1.2675e-01,  1.0402e-01]],\n",
       "              \n",
       "                       [[-1.3191e-01,  5.1577e-02,  9.3906e-02],\n",
       "                        [-1.0973e-01,  1.2606e-01,  6.9330e-02],\n",
       "                        [-7.9789e-02,  1.4824e-01, -2.2891e-01]],\n",
       "              \n",
       "                       [[ 8.4112e-02, -6.5050e-02,  2.2053e-02],\n",
       "                        [-1.6003e-02,  3.6255e-02, -1.0961e-01],\n",
       "                        [ 2.1383e-03,  1.7355e-01, -2.0730e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.2900e-01, -9.4333e-02, -4.8292e-01],\n",
       "                        [ 1.5381e-01, -8.5188e-03,  2.9697e-02],\n",
       "                        [ 1.7547e-01,  5.9568e-02,  4.1180e-01]],\n",
       "              \n",
       "                       [[-6.4412e-02,  2.3372e-02, -8.3541e-02],\n",
       "                        [-5.3537e-02, -8.9693e-02, -1.3112e-02],\n",
       "                        [-5.3418e-02, -4.0995e-02,  1.0250e-01]],\n",
       "              \n",
       "                       [[-2.1671e-01,  2.8036e-02, -1.3197e-04],\n",
       "                        [-3.4290e-02,  5.9299e-02, -1.8906e-02],\n",
       "                        [-5.3243e-02, -4.2178e-02,  2.6321e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0785e+00, -2.0748e-01,  7.5568e-02],\n",
       "                        [ 2.0621e-01, -5.9543e-02,  6.3722e-02],\n",
       "                        [-6.5188e-01, -1.2228e-02,  1.1816e-01]],\n",
       "              \n",
       "                       [[-1.2173e-01,  1.9149e-01,  8.3929e-02],\n",
       "                        [ 8.3358e-02, -2.0013e-01, -1.1041e-02],\n",
       "                        [ 2.7151e-01, -3.6403e-01, -4.3889e-02]],\n",
       "              \n",
       "                       [[-1.7432e-01,  1.5744e-01, -2.0128e-01],\n",
       "                        [ 2.6894e-02, -1.1746e-01, -5.5749e-03],\n",
       "                        [ 2.9326e-01, -4.2377e-01,  5.7002e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.5385e-01, -8.2642e-01,  3.3079e-01],\n",
       "                        [-4.6052e-02, -1.7915e-01,  1.1808e-01],\n",
       "                        [-5.4963e-01,  1.0333e+00, -2.4473e-01]],\n",
       "              \n",
       "                       [[-6.9922e-02,  1.3253e-01,  8.7043e-02],\n",
       "                        [ 1.5732e-01,  1.6859e-01, -2.4649e-02],\n",
       "                        [ 4.5574e-02, -1.4071e-01, -1.5539e-01]],\n",
       "              \n",
       "                       [[ 1.2706e-01,  3.1828e-02,  1.1200e-01],\n",
       "                        [ 9.8312e-02,  3.1909e-02,  8.6010e-02],\n",
       "                        [ 1.4542e-02, -3.4562e-04,  8.4735e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.7297e-02, -1.1035e-01, -1.1087e-01],\n",
       "                        [-7.3131e-02, -9.5376e-02, -9.5487e-02],\n",
       "                        [-8.0729e-02, -9.2381e-04,  2.4190e-02]],\n",
       "              \n",
       "                       [[-1.7203e-01, -4.6300e-01,  2.5281e-01],\n",
       "                        [-1.5188e-01, -4.7515e-01, -3.0280e-02],\n",
       "                        [ 6.9937e-02, -1.2466e-01,  4.5305e-01]],\n",
       "              \n",
       "                       [[ 8.2297e-02,  1.0682e-01,  2.8612e-02],\n",
       "                        [ 1.3627e-01,  4.2858e-02, -3.2870e-02],\n",
       "                        [-3.5023e-02, -7.2602e-02, -2.1970e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.8166e-02,  1.6987e-01,  2.3324e-01],\n",
       "                        [ 2.0293e-01, -1.0903e-02, -1.6093e-01],\n",
       "                        [ 1.5683e-01, -1.1523e-01, -3.9176e-01]],\n",
       "              \n",
       "                       [[ 2.7918e-02, -5.2651e-02, -3.0204e-02],\n",
       "                        [-6.0518e-02, -1.3612e-01, -2.5142e-01],\n",
       "                        [ 8.2353e-02, -6.1556e-02,  5.9971e-02]],\n",
       "              \n",
       "                       [[-7.5691e-02, -5.9457e-03, -4.2270e-02],\n",
       "                        [-4.8160e-02, -3.5608e-02, -2.8247e-02],\n",
       "                        [-1.7834e-02, -7.6805e-02,  2.5366e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-4.9454e-02, -5.7105e-03, -8.8107e-02],\n",
       "                        [-3.6103e-02,  2.0379e-01,  3.4189e-01],\n",
       "                        [-4.2215e-02, -2.1860e-01, -2.4045e-01]],\n",
       "              \n",
       "                       [[-3.0638e-01, -1.8374e-01, -3.8692e-01],\n",
       "                        [ 4.3731e-01,  6.7990e-01,  3.9994e-01],\n",
       "                        [-3.8064e-01, -3.3509e-01, -6.1751e-01]],\n",
       "              \n",
       "                       [[-1.5306e-02, -1.0777e-02, -4.1142e-02],\n",
       "                        [-8.7511e-02, -1.0601e-01, -1.5231e-01],\n",
       "                        [-1.8568e-02,  3.6170e-02, -7.9173e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.1569e-01,  2.8898e-01,  3.5592e-01],\n",
       "                        [-1.0991e+00, -7.5708e-01, -8.5644e-01],\n",
       "                        [ 6.9730e-01,  1.2808e-01,  4.9305e-01]],\n",
       "              \n",
       "                       [[-6.9309e-02, -2.3946e-02, -6.7120e-02],\n",
       "                        [ 7.7438e-02,  7.9852e-02, -2.2187e-02],\n",
       "                        [-5.7858e-02, -7.3175e-03, -4.6205e-02]],\n",
       "              \n",
       "                       [[ 2.4485e-01,  3.5203e-01,  1.8942e-01],\n",
       "                        [-2.1788e-01, -1.4184e-01, -1.8707e-01],\n",
       "                        [-1.7722e-01, -9.8066e-02, -2.2995e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2625e-02,  1.0379e-02, -8.0609e-02],\n",
       "                        [ 5.3149e-02, -9.3726e-02, -1.0543e-01],\n",
       "                        [ 4.8197e-02, -5.4563e-02, -4.1949e-02]],\n",
       "              \n",
       "                       [[ 1.4315e-02,  7.2706e-02, -6.4910e-02],\n",
       "                        [-3.9319e-02, -1.9981e-01, -9.3217e-02],\n",
       "                        [ 5.4948e-02,  7.2174e-02,  5.5379e-02]],\n",
       "              \n",
       "                       [[-2.6129e-02, -1.1373e-02, -1.9768e-02],\n",
       "                        [ 2.1967e-02,  6.3522e-02,  1.2756e-02],\n",
       "                        [ 9.7849e-02,  8.7106e-02,  4.9843e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5595e-02, -1.5106e-01,  2.8897e-01],\n",
       "                        [ 9.5800e-02, -1.1059e-01,  1.5325e-01],\n",
       "                        [ 2.9394e-02, -2.9501e-02,  1.2501e-01]],\n",
       "              \n",
       "                       [[ 1.2613e-01,  6.3016e-02,  2.7176e-02],\n",
       "                        [-5.3751e-02, -8.8469e-02, -2.4307e-02],\n",
       "                        [ 7.0750e-02,  2.2604e-02,  1.4919e-02]],\n",
       "              \n",
       "                       [[ 2.6332e-02, -2.9871e-02,  7.3902e-02],\n",
       "                        [ 5.8938e-02,  8.6006e-02,  3.4223e-02],\n",
       "                        [-2.8744e-02,  8.2594e-03,  1.7609e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7435e-01,  4.7874e-02,  7.0055e-02],\n",
       "                        [ 8.6948e-02,  3.3030e-01,  1.3110e-01],\n",
       "                        [ 1.5556e-01,  3.2963e-01,  1.5869e-01]],\n",
       "              \n",
       "                       [[-6.3539e-01, -6.0424e-01, -2.4252e-01],\n",
       "                        [-1.3502e-01, -1.3486e-01, -3.6140e-01],\n",
       "                        [-5.2280e-01, -4.7667e-01, -5.4187e-01]],\n",
       "              \n",
       "                       [[ 1.0034e-01, -3.9097e-01, -6.2816e-01],\n",
       "                        [-5.8587e-02, -3.5102e-01, -4.4382e-01],\n",
       "                        [-1.9356e-02, -2.9316e-01, -2.4458e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.3339e-01, -3.5807e-01, -7.3283e-03],\n",
       "                        [ 9.7241e-03, -1.2542e-01,  4.9291e-02],\n",
       "                        [ 2.5228e-01, -1.4051e-01, -8.6471e-02]],\n",
       "              \n",
       "                       [[-6.5190e-02, -1.7026e-01, -9.0556e-02],\n",
       "                        [ 1.3915e-01, -3.3030e-02, -7.1347e-02],\n",
       "                        [-2.2762e-05, -1.7184e-01, -1.6950e-02]],\n",
       "              \n",
       "                       [[ 7.2244e-02,  7.6516e-02, -2.7654e-03],\n",
       "                        [ 1.0507e-01, -4.3255e-04,  5.2007e-02],\n",
       "                        [ 2.0332e-02,  1.0466e-01,  5.0690e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.weight',\n",
       "              tensor([1.0147, 1.8317, 0.8301, 1.2968, 0.5953, 0.7233, 0.7475, 1.2259, 0.7721,\n",
       "                      1.0568, 1.3650, 0.3360, 0.4459, 0.6781, 0.6541, 0.3440, 0.5908, 1.0499,\n",
       "                      0.6292, 0.5092, 0.6707, 2.1327, 1.5605, 0.8525, 0.6335, 0.9048, 0.8897,\n",
       "                      0.6496, 1.0510, 1.3799, 0.9359, 0.6482, 0.5818, 1.7507, 2.3637, 0.6982,\n",
       "                      0.9968, 0.4719, 0.5994, 0.5357, 0.7040, 2.0022, 0.6293, 0.2890, 0.5688,\n",
       "                      0.9239, 0.6793, 0.5159, 0.4398, 0.5231, 0.6452, 0.8483, 0.5375, 1.9732,\n",
       "                      0.8341, 0.7305, 1.1377, 1.0964, 0.8403, 0.4709, 0.7815, 1.3541, 0.9502,\n",
       "                      1.0875], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.bias',\n",
       "              tensor([ 0.6754,  0.1345,  0.0220,  1.3368, -0.6749,  0.0839, -1.3812, -1.3433,\n",
       "                      -0.7652,  0.2082, -1.0769,  0.1627,  0.0673,  0.0511,  0.1200,  0.1681,\n",
       "                       0.0150,  0.0098, -0.7188, -0.5221, -0.8065,  0.4152,  0.2131, -1.1045,\n",
       "                       0.0147, -1.0571,  0.0904, -0.7248, -0.9289, -0.0724,  0.0621, -0.8089,\n",
       "                       0.0928,  0.1172,  0.0503,  0.1471,  0.6545,  0.1610, -0.4684,  0.0174,\n",
       "                      -0.8001,  0.3992, -0.6326,  0.1002, -0.7923,  0.0503, -0.4399, -0.1764,\n",
       "                      -1.0168,  0.0272, -0.1202,  0.1499, -0.9979,  0.2602, -0.7370,  0.1048,\n",
       "                       0.8390, -0.2476,  0.0871,  0.0680,  0.1174,  1.5486, -1.0039, -1.6553],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.running_mean',\n",
       "              tensor([-2.6442e-03, -1.0105e-03, -7.4347e-03, -5.6551e-04, -5.9022e-03,\n",
       "                       8.1001e-03, -7.3443e-04, -3.3866e-03, -3.5781e-06, -1.8388e-03,\n",
       "                       2.9289e-04, -1.3109e-02,  4.9675e-03, -5.5409e-03,  4.4445e-03,\n",
       "                      -1.7432e-02, -1.1836e-02, -6.5054e-03, -8.9932e-03, -4.7090e-03,\n",
       "                       1.2896e-02,  1.2038e-03,  1.9172e-04,  3.8127e-03, -9.4586e-03,\n",
       "                      -1.5608e-03,  3.7078e-03, -9.7344e-04,  6.8434e-03,  1.3096e-03,\n",
       "                       5.8198e-03, -7.2441e-03,  1.2007e-02,  3.0239e-04,  6.6009e-04,\n",
       "                       4.3699e-03,  6.0325e-03, -1.0725e-02, -4.3649e-02, -1.8055e-02,\n",
       "                       1.5195e-03, -1.7206e-03, -1.6533e-02, -7.0380e-03, -9.7681e-03,\n",
       "                      -5.4719e-03,  5.8173e-04,  8.5079e-04, -4.3638e-03,  1.9839e-02,\n",
       "                       7.8969e-04,  8.3074e-03, -7.5507e-03, -1.3189e-03,  2.5798e-02,\n",
       "                       5.1496e-03, -2.1499e-03,  2.5010e-03, -1.7609e-03,  1.6992e-02,\n",
       "                       4.3116e-03,  3.5006e-03,  6.6559e-04, -7.5510e-04], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.running_var',\n",
       "              tensor([0.0990, 0.0290, 0.0589, 0.0637, 0.0521, 0.1160, 0.0099, 0.0679, 0.0146,\n",
       "                      0.0908, 0.0122, 0.1292, 0.1407, 0.1051, 0.1647, 0.2356, 0.1505, 0.0526,\n",
       "                      0.0477, 0.0382, 0.1537, 0.0292, 0.0740, 0.0330, 0.1240, 0.0544, 0.0538,\n",
       "                      0.0369, 0.0421, 0.0523, 0.1617, 0.1542, 0.1353, 0.0649, 0.0190, 0.0816,\n",
       "                      0.1264, 0.2075, 1.1808, 0.3108, 0.0238, 0.0288, 0.2683, 0.0547, 0.0837,\n",
       "                      0.2347, 0.0352, 0.0102, 0.0502, 0.3289, 0.0327, 0.1034, 0.0380, 0.0303,\n",
       "                      0.6256, 0.0560, 0.0578, 0.0475, 0.0395, 0.2082, 0.0961, 0.0619, 0.0489,\n",
       "                      0.0635], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.weight',\n",
       "              tensor([1.4841, 1.2917, 1.0752, 0.9392, 1.3012, 0.5648, 0.7395, 1.2967, 0.3735,\n",
       "                      1.2988, 1.5531, 1.1796, 1.5098, 0.8108, 0.5671, 1.0800, 1.0263, 1.2715,\n",
       "                      1.3641, 1.3163, 1.5201, 0.6631, 1.1183, 1.1883, 1.2024, 0.8789, 1.3421,\n",
       "                      0.3771, 1.0490, 1.4551, 1.1245, 1.5359, 0.6782, 1.5352, 0.9282, 1.1248,\n",
       "                      1.3073, 0.9236, 1.2908, 1.3024, 0.4935, 1.0720, 0.8583, 1.5085, 1.4076,\n",
       "                      1.4440, 0.6413, 0.6526, 1.0588, 0.5574, 0.6595, 1.0363, 0.7635, 1.3950,\n",
       "                      1.3622, 1.1709, 0.8593, 0.5827, 0.9331, 1.3578, 1.2215, 0.9420, 0.5712,\n",
       "                      0.5443], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.bias',\n",
       "              tensor([-0.8234, -0.8081, -0.4838, -0.5944, -0.8566, -0.2404, -0.5236, -0.9160,\n",
       "                      -0.0529, -0.3748, -0.7467, -0.8183, -1.0355, -0.2404, -0.3608, -0.5537,\n",
       "                      -0.6094, -0.5815, -0.5941, -0.8944, -0.6258, -0.1631, -0.5619, -0.8486,\n",
       "                      -0.4367, -0.3251, -0.8718, -0.0486, -0.5740, -0.9323, -0.6806, -0.7423,\n",
       "                      -0.9645, -1.0283, -0.6479, -0.5786, -0.9397, -0.1561, -0.6581, -0.7995,\n",
       "                      -0.1054, -0.5006, -0.2690, -0.9833, -0.6177, -1.0039, -0.5419, -0.7335,\n",
       "                      -0.4527, -0.3228, -0.2103, -0.3911, -0.2588, -0.8303, -0.6102, -0.4021,\n",
       "                      -0.2842, -0.4564, -0.4216, -0.6266, -0.8774, -0.5110, -0.9052, -0.2076],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.running_mean',\n",
       "              tensor([ -7.5214,  -3.5263,  -7.6195,  -7.3292, -10.1689,  -3.5676,  -5.5123,\n",
       "                       -6.4482,   2.5568,  -7.0457,  -4.9308,  -4.0243,  -5.7459,  -3.0006,\n",
       "                       -0.4771,  -5.7695,  -6.4044,  -8.2480,  -9.8571,  -7.5985,  -7.1609,\n",
       "                      -10.7915,  -5.2936,  -5.5477,  -4.2093, -14.3836,  -9.0733,   0.5924,\n",
       "                       -5.9486,  -4.5786,  -9.5296, -18.9389,   7.1328,  -3.7252,  -4.3018,\n",
       "                       -4.3027,  -9.6727, -11.4089,  -8.2913,  -4.0851,  -8.5113, -13.2303,\n",
       "                       -5.4044,  -5.5494,  -6.0409,  -5.7176,  -0.3189,   2.1054, -11.1128,\n",
       "                        0.1121, -10.7496,  -4.8157,  -1.3577,  -5.7857,  -4.9932,  -8.8108,\n",
       "                       -5.8132,   0.7328,  -4.6833, -11.2964,  -6.6940,  -5.2393,   3.5756,\n",
       "                      -13.2411], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.running_var',\n",
       "              tensor([ 83.4874,  49.2280,  79.8500,  65.7017, 104.6649, 147.6423,  30.4582,\n",
       "                       79.2726,  38.4524, 135.0762,  43.4954,  34.0307,  43.2262,  56.8076,\n",
       "                       15.2798,  73.5737, 124.5944, 136.4150, 159.5756,  71.4369,  73.7142,\n",
       "                      121.5120,  84.3253,  40.6370,  41.4570, 250.3013, 146.4842,  39.3805,\n",
       "                      119.0096,  81.0722,  91.1335, 299.9778,  30.1207,  33.7678,  31.2618,\n",
       "                       38.2270,  95.4588, 211.1729, 157.5682,  25.0145,  58.4743, 142.2299,\n",
       "                       40.8495,  94.0520,  56.1689,  40.2752,  15.1789,  34.4148, 209.8351,\n",
       "                       20.2163,  81.0546,  39.9090,  31.7404,  59.5921,  76.8075, 138.7216,\n",
       "                      183.5796,  25.3117,  73.6397, 243.3807,  62.6100,  55.8699,  17.5195,\n",
       "                      227.4245], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.conv1.weight',\n",
       "              tensor([[[[-6.6612e-02, -5.9600e-02, -3.3646e-02],\n",
       "                        [-9.0082e-03, -3.4218e-02, -1.2638e-01],\n",
       "                        [-1.5268e-01, -5.2480e-02, -6.7372e-02]],\n",
       "              \n",
       "                       [[ 1.1773e-01,  1.3273e-01,  1.4331e-01],\n",
       "                        [ 1.5485e-02, -5.2641e-02,  6.5574e-02],\n",
       "                        [ 3.9865e-02,  6.6218e-02,  1.6867e-01]],\n",
       "              \n",
       "                       [[ 9.3612e-03, -3.2874e-03, -5.0931e-03],\n",
       "                        [ 1.0213e-02,  2.7881e-02,  5.9696e-02],\n",
       "                        [ 2.5336e-03,  5.3899e-02,  1.0334e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.3382e-02,  6.7181e-02,  6.3629e-02],\n",
       "                        [-8.2463e-03,  3.0971e-02,  3.6543e-02],\n",
       "                        [-3.2838e-02, -5.4525e-02, -1.0010e-01]],\n",
       "              \n",
       "                       [[ 5.8703e-03, -5.4488e-03, -7.4210e-03],\n",
       "                        [-8.8855e-03,  9.4491e-03, -2.4393e-02],\n",
       "                        [ 4.0046e-02,  2.7267e-02, -2.4605e-02]],\n",
       "              \n",
       "                       [[ 3.4274e-03, -1.7679e-02, -1.0506e-02],\n",
       "                        [-6.6787e-02, -2.9965e-02, -3.4468e-02],\n",
       "                        [-4.4432e-02, -1.3806e-02, -4.1295e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.9368e-02, -4.6169e-02, -3.1849e-02],\n",
       "                        [ 1.1523e-01,  1.7957e-01,  4.6607e-02],\n",
       "                        [ 5.8586e-03,  1.2307e-01,  1.4036e-02]],\n",
       "              \n",
       "                       [[-1.8446e-01, -2.0808e-01, -7.5956e-02],\n",
       "                        [-2.9685e-01, -2.9554e-01,  5.7040e-02],\n",
       "                        [-2.7504e-01,  6.5192e-02,  2.9643e-02]],\n",
       "              \n",
       "                       [[ 3.1143e-02,  5.7940e-02,  5.3295e-02],\n",
       "                        [-1.4687e-01, -2.6303e-01,  4.0375e-02],\n",
       "                        [ 8.0275e-02, -1.9773e-01,  7.4133e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.7884e-02, -6.6429e-02, -6.8187e-03],\n",
       "                        [-8.8455e-02, -2.1068e-01, -1.0393e-01],\n",
       "                        [ 4.0991e-02, -1.4381e-01, -1.1891e-01]],\n",
       "              \n",
       "                       [[ 3.8864e-02, -7.3408e-02, -1.0042e-01],\n",
       "                        [ 6.2543e-02, -1.5229e-02,  3.8400e-02],\n",
       "                        [-4.9299e-02, -1.4120e-01, -1.5871e-01]],\n",
       "              \n",
       "                       [[ 1.2304e-01,  1.6561e-01,  1.1603e-01],\n",
       "                        [-3.1976e-03,  1.5427e-01,  1.0683e-01],\n",
       "                        [ 1.0294e-01,  1.0579e-01,  1.8109e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3461e-01,  3.3709e-01, -1.2679e-01],\n",
       "                        [-1.1710e-01, -1.9431e-01, -2.6899e-01],\n",
       "                        [ 1.2496e-01, -2.3303e-01, -3.0178e-01]],\n",
       "              \n",
       "                       [[-7.5645e-01, -1.8989e-02, -1.4834e-01],\n",
       "                        [-1.5400e+00, -1.4846e+00, -2.8898e-01],\n",
       "                        [-1.9606e+00, -1.8870e+00, -6.1143e-01]],\n",
       "              \n",
       "                       [[ 7.4252e-02, -3.6760e-02,  2.5229e-01],\n",
       "                        [-5.4651e-03, -4.8606e-01,  6.3125e-02],\n",
       "                        [ 1.1650e-01, -6.2473e-01,  9.7307e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.3681e-02,  1.0975e-01, -1.4098e-01],\n",
       "                        [-1.3643e-02, -1.8806e-02, -1.1949e-01],\n",
       "                        [-1.5424e-01,  2.1139e-02, -1.2501e-01]],\n",
       "              \n",
       "                       [[-2.0506e-01, -3.0328e-01, -7.0644e-03],\n",
       "                        [ 6.5120e-02, -1.5298e-02,  8.4776e-02],\n",
       "                        [ 9.8368e-02,  2.2104e-01,  4.7331e-02]],\n",
       "              \n",
       "                       [[ 1.0543e-02, -3.8799e-02,  1.2879e-01],\n",
       "                        [-1.4161e-03, -1.6089e-01, -1.1688e-01],\n",
       "                        [ 1.8923e-01,  2.9672e-02, -8.9577e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5869e-01,  2.4997e-01,  1.0919e-01],\n",
       "                        [ 8.0202e-02, -7.0330e-02, -1.1587e-01],\n",
       "                        [-1.7754e-01, -9.0353e-02, -1.1497e-02]],\n",
       "              \n",
       "                       [[ 3.2115e-01,  2.9448e-01, -5.0417e-02],\n",
       "                        [ 1.6544e-01,  5.9469e-02,  1.6220e-02],\n",
       "                        [-3.3938e-02, -2.0441e-02,  2.2820e-01]],\n",
       "              \n",
       "                       [[-2.6324e-01, -2.1927e-01,  1.9276e-02],\n",
       "                        [-1.1829e-01, -9.9668e-02, -3.7246e-02],\n",
       "                        [-1.5414e-01, -3.0073e-01, -3.8076e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.8569e-01, -8.8609e-02, -2.7967e-01],\n",
       "                        [-1.7912e-01, -1.2283e-01, -1.4729e-01],\n",
       "                        [-1.1130e-01, -1.5198e-01, -4.9355e-02]],\n",
       "              \n",
       "                       [[-1.5297e-01, -6.4467e-02, -1.4488e-02],\n",
       "                        [ 8.3452e-02,  1.1420e-01,  1.4201e-01],\n",
       "                        [ 6.5947e-02,  7.5174e-02,  1.4104e-02]],\n",
       "              \n",
       "                       [[-3.9835e-01, -4.4832e-01,  4.2174e-02],\n",
       "                        [-4.3757e-02,  3.5249e-03,  1.9157e-01],\n",
       "                        [ 5.1002e-01,  2.7074e-01,  2.1804e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0083e-01, -2.0754e-01, -1.2930e-01],\n",
       "                        [-4.3015e-02,  7.0285e-02,  3.9884e-02],\n",
       "                        [ 4.1164e-03, -1.0237e-02, -2.3977e-01]],\n",
       "              \n",
       "                       [[-2.5900e-01, -4.4998e-01,  1.5604e-01],\n",
       "                        [-1.7697e-01, -4.5872e-01,  2.1617e-01],\n",
       "                        [ 3.7660e-02, -7.4408e-01,  6.8443e-02]],\n",
       "              \n",
       "                       [[-1.1396e-01, -5.3961e-02, -3.6279e-01],\n",
       "                        [ 1.1854e-01, -1.2681e-01, -2.1725e-01],\n",
       "                        [ 2.6696e-01, -3.6346e-01, -9.5176e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.7260e-04, -6.8171e-02,  8.3130e-02],\n",
       "                        [-6.1544e-02, -1.0541e-01,  1.3370e-01],\n",
       "                        [-1.3495e-02, -3.3459e-01, -3.7672e-01]],\n",
       "              \n",
       "                       [[ 4.4782e-02, -4.8111e-02, -3.0118e-01],\n",
       "                        [ 7.5534e-02,  1.4195e-02, -9.2084e-02],\n",
       "                        [ 5.9530e-02,  2.4830e-01, -1.9449e-02]],\n",
       "              \n",
       "                       [[-5.6514e-02, -4.7786e-01, -5.4551e-01],\n",
       "                        [ 6.7129e-02, -1.0447e-01, -3.5393e-01],\n",
       "                        [ 2.0524e-01,  1.4802e-01, -1.2159e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1755e-01,  1.8948e-01, -8.5609e-02],\n",
       "                        [ 1.8041e-03,  9.2940e-02,  4.3612e-03],\n",
       "                        [-2.8400e-02,  8.6866e-02,  5.8296e-02]],\n",
       "              \n",
       "                       [[ 1.5267e-01,  9.4688e-02,  1.0845e-01],\n",
       "                        [ 1.2109e-02,  1.7323e-02,  7.2662e-02],\n",
       "                        [ 1.5045e-01,  6.3335e-02,  1.3530e-01]],\n",
       "              \n",
       "                       [[-1.1404e-02, -6.6846e-05,  3.2670e-02],\n",
       "                        [ 1.3148e-02, -9.1374e-03,  7.4029e-02],\n",
       "                        [ 7.1019e-02, -1.2960e-02,  2.3726e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.7098e-02,  6.7599e-02,  1.4238e-02],\n",
       "                        [ 4.8238e-02,  1.3659e-02, -1.2117e-01],\n",
       "                        [ 1.4043e-02, -4.1660e-02, -1.5624e-01]],\n",
       "              \n",
       "                       [[ 7.8119e-02,  5.5463e-02, -4.3440e-02],\n",
       "                        [ 4.9839e-02,  1.5844e-02,  6.5254e-03],\n",
       "                        [-1.8330e-03,  3.8192e-02, -6.3780e-02]],\n",
       "              \n",
       "                       [[ 1.2015e-03, -5.0034e-02, -4.7408e-03],\n",
       "                        [-9.7093e-02, -1.0198e-01, -1.2352e-01],\n",
       "                        [-4.9896e-02, -4.3457e-02, -1.8967e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.conv2.weight',\n",
       "              tensor([[[[-1.2165e-01, -3.4758e-02, -3.1801e-02],\n",
       "                        [-2.2202e-01, -4.2053e-02, -8.9334e-03],\n",
       "                        [-2.1968e-01,  1.4105e-02, -7.2417e-02]],\n",
       "              \n",
       "                       [[-1.8230e-02,  4.9553e-02,  2.1746e-03],\n",
       "                        [-5.1542e-03,  1.5157e-01, -5.8213e-02],\n",
       "                        [-6.2584e-02,  8.8796e-02, -9.7473e-02]],\n",
       "              \n",
       "                       [[-7.6419e-02,  2.6815e-01, -4.1798e-01],\n",
       "                        [ 1.1087e-01,  1.8604e-01, -4.2441e-01],\n",
       "                        [ 6.6051e-01,  6.7546e-02, -2.2249e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.7164e-01,  6.9644e-02, -1.1054e-01],\n",
       "                        [-1.9934e-01,  1.2364e-01, -1.8217e-01],\n",
       "                        [ 1.9870e-01, -2.1927e-01, -4.7338e-01]],\n",
       "              \n",
       "                       [[ 6.0575e-01,  1.9189e-01, -3.9298e-01],\n",
       "                        [ 3.8937e-01, -5.2282e-01, -3.3441e-01],\n",
       "                        [ 5.0963e-02, -8.0754e-01,  2.1472e-01]],\n",
       "              \n",
       "                       [[-5.4394e-02, -4.4702e-02, -4.1633e-02],\n",
       "                        [-7.9942e-02,  2.0425e-02, -1.1764e-01],\n",
       "                        [-6.7712e-02, -4.8692e-02, -8.1700e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.8303e-02, -1.1456e-01, -6.3068e-02],\n",
       "                        [-3.1676e-02, -7.5469e-02, -8.8714e-02],\n",
       "                        [ 1.6190e-02, -1.3691e-01, -1.2982e-02]],\n",
       "              \n",
       "                       [[ 1.3800e-02,  4.3082e-02,  1.2921e-01],\n",
       "                        [-6.6615e-02,  3.9583e-02,  5.1345e-02],\n",
       "                        [-9.0941e-02, -3.3695e-02, -1.6292e-01]],\n",
       "              \n",
       "                       [[-2.9417e-01, -2.7346e-01, -2.8625e-01],\n",
       "                        [-4.8340e-01, -3.0853e-01, -2.9241e-01],\n",
       "                        [-4.6969e-01, -4.4771e-01, -2.2531e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3768e-01, -1.3367e-01,  6.3965e-02],\n",
       "                        [-1.8034e-01, -1.0056e-01,  4.9152e-02],\n",
       "                        [ 6.9681e-02,  4.4886e-02, -1.5970e-02]],\n",
       "              \n",
       "                       [[ 6.3910e-02,  5.0630e-02, -1.5643e-01],\n",
       "                        [-1.2564e-02,  8.7770e-02, -2.5424e-01],\n",
       "                        [-1.5242e-01,  3.2650e-02, -3.4847e-01]],\n",
       "              \n",
       "                       [[-1.0796e-02, -6.4269e-02, -5.0478e-03],\n",
       "                        [-9.9691e-02, -6.7211e-02, -5.9294e-02],\n",
       "                        [-5.5320e-02, -4.8565e-02, -8.5714e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3092e-01,  9.5969e-02,  1.5641e-01],\n",
       "                        [ 1.9266e-01,  1.9806e-01,  3.0072e-01],\n",
       "                        [ 1.0866e-01,  6.0311e-02,  1.0739e-01]],\n",
       "              \n",
       "                       [[-4.7209e-02, -7.3073e-02, -1.1407e-01],\n",
       "                        [ 3.4073e-02, -6.4070e-02,  7.7815e-02],\n",
       "                        [ 2.4749e-02, -6.8775e-02,  7.9206e-02]],\n",
       "              \n",
       "                       [[-2.8662e-02, -6.8921e-03, -1.5398e-01],\n",
       "                        [ 1.1468e-01,  1.0031e-01, -2.7129e-02],\n",
       "                        [ 1.9977e-01,  1.8576e-01,  5.5038e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.7789e-01, -1.6586e-01, -5.8020e-02],\n",
       "                        [-1.0732e-01, -1.4870e-01, -1.8783e-01],\n",
       "                        [ 1.1411e-01,  1.8217e-03,  6.5047e-03]],\n",
       "              \n",
       "                       [[ 5.4595e-02,  7.4122e-02, -2.3456e-01],\n",
       "                        [-1.3140e-01, -1.0850e-02, -2.9233e-01],\n",
       "                        [-3.5969e-02,  2.3044e-01, -1.8797e-01]],\n",
       "              \n",
       "                       [[ 1.4259e-01,  7.6576e-02,  9.8668e-02],\n",
       "                        [ 2.4371e-01,  1.9889e-01,  1.1936e-01],\n",
       "                        [ 1.4846e-01,  1.9596e-01,  1.3475e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.1735e-02, -1.3602e-03, -6.8345e-03],\n",
       "                        [-3.9126e-02, -2.0053e-02, -6.9146e-02],\n",
       "                        [-4.7897e-02, -3.2232e-02, -3.0127e-02]],\n",
       "              \n",
       "                       [[-1.1223e-01, -2.3186e-03,  1.0385e-01],\n",
       "                        [-1.8395e-02, -9.9355e-03,  2.3772e-02],\n",
       "                        [ 9.9456e-03,  3.8746e-02,  3.2703e-02]],\n",
       "              \n",
       "                       [[ 5.2624e-01,  3.0441e-01, -2.7560e-02],\n",
       "                        [ 3.8298e-01,  3.3152e-01,  3.2366e-01],\n",
       "                        [-1.7045e-01, -1.2247e-01, -6.2685e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.2901e-01,  1.6458e-01, -5.7356e-02],\n",
       "                        [ 1.9583e-01,  1.6779e-01,  2.3444e-02],\n",
       "                        [-1.3751e-01, -1.7650e-01, -3.1298e-01]],\n",
       "              \n",
       "                       [[ 1.4263e-01, -1.8176e-01, -1.3101e-01],\n",
       "                        [-3.3003e-01, -1.7546e-01, -1.4912e-01],\n",
       "                        [-4.1653e-01, -2.7350e-01, -2.3506e-01]],\n",
       "              \n",
       "                       [[-3.4305e-03, -1.1950e-02, -2.6996e-02],\n",
       "                        [-3.5794e-02, -1.4185e-02, -2.9764e-02],\n",
       "                        [ 2.7390e-02, -6.2543e-02, -3.8219e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0635e-02, -2.6808e-03, -9.0777e-02],\n",
       "                        [-3.8485e-02,  3.2833e-02, -1.6659e-02],\n",
       "                        [-1.8095e-02,  8.3388e-03,  1.3049e-02]],\n",
       "              \n",
       "                       [[-4.0688e-02, -2.1189e-01, -1.4189e-01],\n",
       "                        [-4.1159e-02, -1.1777e-01, -3.9503e-02],\n",
       "                        [ 4.0488e-02,  6.5073e-02, -1.2451e-01]],\n",
       "              \n",
       "                       [[-1.9807e-01, -1.4593e-01, -3.1981e-01],\n",
       "                        [-2.6858e-01, -9.8892e-02, -2.4597e-01],\n",
       "                        [-3.9285e-01, -2.7522e-02, -2.4347e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2200e-01, -2.3795e-01, -4.5053e-01],\n",
       "                        [-4.3874e-01, -2.1310e-02, -6.6127e-02],\n",
       "                        [ 1.4589e-01,  1.8029e-01, -2.1881e-01]],\n",
       "              \n",
       "                       [[ 1.2308e-02,  3.8618e-01,  4.7723e-02],\n",
       "                        [ 1.1494e-02,  2.0954e-01,  1.6211e-02],\n",
       "                        [-1.2337e-01, -1.7129e-01, -2.3508e-01]],\n",
       "              \n",
       "                       [[-2.2188e-03, -2.6811e-02, -4.6226e-03],\n",
       "                        [-7.3100e-02, -4.6282e-02, -5.9734e-02],\n",
       "                        [ 1.5354e-02, -7.1094e-02, -4.0344e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9619e-02, -1.3767e-02, -6.4492e-02],\n",
       "                        [ 7.0084e-02,  2.1040e-02, -1.6778e-02],\n",
       "                        [ 2.5448e-02, -2.0526e-02, -1.5553e-02]],\n",
       "              \n",
       "                       [[ 6.7199e-02,  5.4012e-02, -5.1086e-02],\n",
       "                        [-1.6294e-02,  2.6211e-03, -5.9751e-02],\n",
       "                        [ 1.1546e-01,  7.7307e-02, -3.1984e-02]],\n",
       "              \n",
       "                       [[-1.3045e-01,  4.2094e-01,  3.6570e-01],\n",
       "                        [ 5.6246e-02,  7.0460e-01,  5.7300e-01],\n",
       "                        [-8.8699e-02,  4.3950e-01,  6.2013e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.6621e-01, -1.4640e-01,  1.2067e-01],\n",
       "                        [ 3.1655e-02,  3.4726e-01,  4.2844e-01],\n",
       "                        [-4.9609e-02,  3.7723e-01,  2.6148e-01]],\n",
       "              \n",
       "                       [[ 1.0608e-02,  5.0214e-01,  1.0745e-01],\n",
       "                        [-1.9865e-01,  2.3390e-01,  7.7547e-03],\n",
       "                        [-1.2779e-01,  2.3408e-01, -2.2846e-02]],\n",
       "              \n",
       "                       [[ 2.3396e-02, -2.1005e-02, -6.9662e-03],\n",
       "                        [-2.6809e-02, -3.2222e-02, -9.1260e-03],\n",
       "                        [-5.6296e-04, -2.4745e-03, -5.7847e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.weight',\n",
       "              tensor([0.7172, 1.1233, 1.1306, 1.0778, 1.2900, 1.3358, 1.0254, 0.9637, 1.0924,\n",
       "                      1.9560, 1.1531, 1.0244, 0.9168, 0.9906, 1.3675, 1.0856, 1.0364, 1.4014,\n",
       "                      0.6489, 1.1420, 1.0177, 1.0153, 0.4829, 1.3125, 1.0182, 1.2070, 0.8518,\n",
       "                      1.1346, 1.0194, 1.0389, 0.6530, 1.6765, 1.3377, 1.0420, 1.1963, 1.4562,\n",
       "                      1.2257, 0.8529, 1.2123, 1.0886, 1.2572, 0.9541, 1.2606, 1.1860, 0.7690,\n",
       "                      1.0909, 0.8198, 1.6815, 1.5043, 0.9400, 0.9319, 1.2516, 1.2181, 0.7739,\n",
       "                      1.5223, 1.2250, 0.5551, 0.8316, 1.1723, 0.6180, 1.2489, 1.3083, 1.2504,\n",
       "                      1.1648, 0.9319, 0.8519, 1.1785, 1.1199, 1.0065, 1.0437, 0.8517, 0.9715,\n",
       "                      1.1117, 0.8660, 1.2616, 0.6270, 1.4886, 0.8508, 1.6452, 0.9375, 0.9837,\n",
       "                      0.9614, 0.9463, 0.9444, 1.3023, 0.9668, 0.9989, 0.8529, 1.2239, 1.2258,\n",
       "                      0.8677, 1.0991, 1.2224, 1.3239, 1.0160, 0.8423, 0.7899, 1.0761, 0.9532,\n",
       "                      1.1130, 1.0155, 1.4508, 0.9422, 0.4902, 1.3575, 1.2227, 0.6806, 1.0196,\n",
       "                      1.1379, 1.3348, 0.8498, 1.1620, 1.0342, 1.0171, 0.7932, 1.2207, 1.0058,\n",
       "                      1.1235, 0.9424, 0.7260, 1.1394, 1.4980, 0.9080, 1.0551, 0.7560, 1.6658,\n",
       "                      1.0238, 0.7015], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.bias',\n",
       "              tensor([-1.3539, -0.9176, -0.3358, -0.6793, -0.2511, -0.5147,  0.1780,  0.0788,\n",
       "                      -0.9521, -3.2531, -0.3384, -0.2269, -0.1342, -0.4940, -0.5501, -0.7990,\n",
       "                      -0.2480, -0.7214, -1.2223, -0.8328,  0.1423, -0.7698, -0.0695, -0.9567,\n",
       "                      -0.6748, -0.8609, -1.0909, -0.6635, -0.5919, -0.3254, -0.5232, -1.0573,\n",
       "                      -0.5956,  0.2500, -1.2381, -0.9972, -1.1012, -0.7308, -0.9487, -0.4341,\n",
       "                      -0.7429, -0.7259, -0.9874, -0.2327, -1.4147, -0.8253, -0.5465, -2.2435,\n",
       "                      -0.7619, -0.4607, -1.0012, -0.7680,  0.0576, -0.1711, -0.9545, -0.4789,\n",
       "                      -0.2734, -0.1463, -0.9236, -0.4300, -1.3015, -0.8899, -1.5931, -0.5611,\n",
       "                      -0.2354,  0.1681, -0.6901, -0.1235, -0.6812, -0.5706, -0.0539, -0.2259,\n",
       "                      -0.7704, -0.1603, -0.9158, -1.2511, -1.1759, -0.4254, -1.5772,  0.0548,\n",
       "                      -0.3023, -0.2560, -0.9098,  0.1258, -0.8445,  0.2932, -0.5789, -1.4806,\n",
       "                      -0.7398, -0.6939, -0.2297, -0.3205, -1.0558, -0.5916, -0.7359, -0.6250,\n",
       "                       0.0800, -0.9542, -0.1950, -0.3094, -0.5269, -0.8853, -0.4104, -0.0767,\n",
       "                      -0.9139, -0.6508, -0.2267, -0.5620, -0.0352, -0.6384,  0.3548, -0.7505,\n",
       "                      -0.5176, -0.8099, -0.5966, -0.7521, -1.1145, -0.2763, -0.7157, -0.2710,\n",
       "                      -0.5462, -0.9088, -0.2783, -0.7310,  0.0219, -0.8976, -0.0224, -1.1168],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.running_mean',\n",
       "              tensor([-2.3564e+00, -7.8623e-01, -4.6387e+00, -1.5049e+00, -2.2726e+00,\n",
       "                      -2.7921e+00, -7.8990e-01, -2.8141e+00, -5.9426e-01, -2.2119e-01,\n",
       "                      -2.2360e+00, -1.1295e+00, -4.6336e-01, -6.6574e-02, -3.6455e+00,\n",
       "                      -8.3942e-01, -2.1146e+00, -3.3238e+00, -1.4186e-01, -3.0691e+00,\n",
       "                      -2.2668e+00, -1.1178e+00, -8.3395e-01, -2.8017e+00, -1.6393e+00,\n",
       "                      -3.2161e+00,  2.2586e+00, -2.7256e+00, -1.5868e+00, -2.5973e+00,\n",
       "                       5.9631e-01, -2.0146e+00, -3.9246e+00, -4.6789e-01, -1.3337e+00,\n",
       "                      -2.9259e+00, -3.4471e+00,  4.0029e-01, -2.7329e+00, -1.4647e+00,\n",
       "                      -2.7654e+00, -7.8124e-01, -2.8880e+00, -2.2220e+00, -3.1499e+00,\n",
       "                      -2.0553e+00, -1.3198e+00, -1.3732e+00, -1.1723e+00, -3.7504e+00,\n",
       "                      -2.9886e+00, -2.1853e+00, -1.5485e+00, -3.1541e+00, -2.1112e+00,\n",
       "                      -1.7010e+00, -7.4233e-01, -1.2257e+00, -1.9303e+00, -1.8361e+00,\n",
       "                      -8.7065e-01, -1.9204e+00, -7.5239e-01, -1.1576e+00, -1.1160e+00,\n",
       "                      -2.2270e+00, -9.1154e-01, -2.0062e+00, -2.4841e+00, -2.2993e+00,\n",
       "                      -1.4874e+00, -1.1571e+00, -2.4260e+00, -3.6369e-01, -3.3601e+00,\n",
       "                      -1.9821e+00, -7.2913e-01, -1.6621e+00, -1.3400e+00, -1.2716e+00,\n",
       "                      -1.3281e+00, -2.1497e-01, -1.1626e+00, -2.3756e+00, -2.5502e+00,\n",
       "                      -1.1670e+00, -6.4745e-01,  5.7326e-01, -1.6173e+00, -2.3845e+00,\n",
       "                       4.2936e-03, -2.3031e+00, -2.2605e+00, -1.4771e+00, -1.5212e+00,\n",
       "                       6.9390e-01, -9.1834e-01,  2.9509e-01, -2.1181e+00, -1.3780e+00,\n",
       "                      -2.6048e-02, -1.7809e+00, -2.0320e+00,  1.7299e+00, -3.1834e+00,\n",
       "                      -8.1315e-01,  3.8306e-01, -1.1156e+00, -1.8082e+00, -1.4379e+00,\n",
       "                      -2.8346e+00, -1.0881e+00, -1.2295e+00, -1.1997e+00,  1.3506e+00,\n",
       "                      -1.8708e+00, -7.6548e-01, -3.8635e+00, -9.9921e-01, -2.0282e+00,\n",
       "                      -4.2747e+00, -3.8394e+00, -3.5665e+00, -2.8408e+00, -2.4622e-01,\n",
       "                      -1.8582e+00, -2.5839e+00, -1.9727e+00], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.running_var',\n",
       "              tensor([ 1.1628,  2.2944,  8.6532,  2.7921,  6.7483,  3.9477,  6.2737, 11.0114,\n",
       "                       1.1497,  2.9575,  6.1196,  4.8618,  2.6658,  1.2191,  9.8697,  1.8588,\n",
       "                       7.7485,  3.2064,  0.7007,  2.6209,  7.0998,  0.9956,  8.4282,  4.6423,\n",
       "                       1.8855,  3.9211,  2.0303,  6.6025,  3.2229,  4.9314,  4.0883,  8.9942,\n",
       "                       5.5522,  2.3270,  1.9216,  5.1352,  2.6981,  1.1372,  2.9688,  3.6854,\n",
       "                       7.6050,  7.3443,  2.6095,  2.1476,  2.4595,  3.0240,  4.5101,  2.0808,\n",
       "                       4.8284,  6.4665,  2.4399,  2.4437,  3.4446,  6.3414,  8.9221,  3.9288,\n",
       "                       4.5559,  4.1219,  1.5601,  7.2267,  1.0878,  2.0362,  1.5766,  6.8748,\n",
       "                       3.5607,  6.7264,  1.2537, 15.1972,  3.8910,  5.8348,  4.1857,  3.3512,\n",
       "                       2.7344,  3.2213,  4.6379,  1.4182,  1.2774, 10.6226,  1.4496,  3.8304,\n",
       "                       5.4729,  2.5310,  1.2216,  3.1023,  3.2071,  2.9372,  5.2183,  0.7089,\n",
       "                       1.9102,  3.0293,  1.9638,  2.7152,  1.6664,  4.4831,  2.3184,  1.3854,\n",
       "                       5.7960,  0.8607,  3.7067,  3.5862,  3.1024,  1.7274,  6.0427,  8.3279,\n",
       "                       4.1307,  2.4674,  2.2121,  4.5371,  2.9238,  2.9484, 12.1494,  0.9848,\n",
       "                       4.5319,  2.2995,  8.1437,  6.4259,  2.4978,  5.0054,  1.7669,  6.3232,\n",
       "                       9.9577,  8.3383,  5.7918,  5.6132,  5.2834,  7.8332,  4.3388,  1.1185],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.weight',\n",
       "              tensor([1.3141, 0.9743, 0.9400, 0.9704, 1.1382, 1.0515, 0.7056, 0.8917, 1.2728,\n",
       "                      0.8739, 0.8869, 1.0483, 0.6003, 0.7180, 0.9838, 0.9419, 1.2941, 1.2745,\n",
       "                      1.1587, 1.3949, 0.7573, 0.7964, 1.2028, 1.1286, 0.5101, 1.5309, 1.7043,\n",
       "                      1.0253, 1.2643, 1.5136, 0.9687, 1.1254, 0.9008, 1.0613, 1.2545, 1.9371,\n",
       "                      1.0074, 1.1867, 0.6400, 0.8690, 1.2913, 1.1891, 1.5210, 1.2264, 1.1337,\n",
       "                      1.5098, 0.7860, 1.1929, 0.9391, 1.0299, 0.8509, 1.0739, 1.1180, 1.0300,\n",
       "                      1.1998, 0.9821, 0.9817, 1.3478, 0.9603, 0.9633, 0.6857, 0.6026, 0.7475,\n",
       "                      0.7358, 0.7933, 0.9335, 0.9808, 1.0397, 0.8151, 0.7391, 0.6320, 1.2441,\n",
       "                      1.0984, 1.2876, 0.8579, 1.6905, 0.7509, 0.7957, 0.7060, 1.0145, 0.9281,\n",
       "                      0.8951, 1.7811, 1.0739, 1.3654, 1.0729, 0.7540, 0.7065, 1.2138, 1.0745,\n",
       "                      0.9565, 0.9216, 1.0931, 0.6989, 1.1158, 0.9414, 0.7919, 1.2018, 1.0087,\n",
       "                      1.4503, 0.6382, 0.8017, 0.9373, 1.1921, 1.0555, 1.2000, 1.3124, 1.1891,\n",
       "                      0.8393, 1.0704, 0.7054, 1.2592, 0.7358, 0.9641, 1.1372, 0.8094, 1.0117,\n",
       "                      1.2514, 1.1951, 1.0004, 0.8262, 0.7046, 0.8043, 1.1598, 0.6865, 1.4700,\n",
       "                      0.8981, 0.9085], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.bias',\n",
       "              tensor([-1.3503, -0.4413, -0.6789, -0.9455, -1.0849, -0.4448, -0.5752, -0.7186,\n",
       "                      -0.8108, -0.2051, -0.4654, -0.7822, -0.4704, -0.3479, -0.7247, -0.6463,\n",
       "                      -1.1507, -0.8867, -0.7556, -0.8274, -0.4405, -0.4568, -0.9801, -0.6102,\n",
       "                      -1.2241, -1.2244, -1.5618, -0.8782, -0.5003, -0.9520, -0.5820, -1.1252,\n",
       "                      -0.9082, -0.9316, -1.0885, -1.7258, -0.9305, -0.9675, -0.2319, -0.6314,\n",
       "                      -0.8341, -1.1461, -0.9772, -0.9146, -0.7383, -1.1380, -0.6114, -0.9168,\n",
       "                      -1.1098, -0.8108, -0.2102, -0.8518, -0.5361, -0.4911, -0.9719, -0.7816,\n",
       "                      -0.7263, -1.1259, -0.3177, -0.4689, -0.2683, -0.5677, -0.5023, -0.3059,\n",
       "                      -0.5004, -0.7979, -0.7226, -0.8363, -0.3814, -0.5096, -2.4209, -1.0990,\n",
       "                      -0.7452, -1.0950, -0.4069, -1.6483, -0.4548, -0.4833, -0.4344, -0.7627,\n",
       "                      -0.5733, -0.4171, -1.7487, -1.0344, -0.9407, -0.8883, -0.0773, -0.2880,\n",
       "                      -1.0581, -0.7470, -0.6575, -0.5272, -0.7539, -0.3000, -0.6706, -0.6163,\n",
       "                      -0.3594, -0.7435, -2.1373, -1.4771, -0.2047, -0.3021, -0.4441, -0.8505,\n",
       "                      -0.7633, -1.0400, -0.6749, -0.8543, -0.2337, -0.7890, -0.1617, -0.7715,\n",
       "                      -0.4618, -0.8388, -0.8737, -0.8112, -0.6466, -0.8895, -0.7215, -0.9477,\n",
       "                      -0.6900, -0.5412, -0.4516, -1.3314, -0.2638, -1.1401, -0.6788, -0.7952],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.running_mean',\n",
       "              tensor([-6.9297, -4.3337, -5.7589, -0.8863, -2.2412, -1.4413, -3.4932, -6.0370,\n",
       "                      -5.2845, -2.1129, -5.9746, -2.2982, -0.1805, -1.9609, -3.9859, -2.5096,\n",
       "                      -9.8723, -4.8601, -5.3042, -2.1145, -3.4193, -3.2424, -4.6652, -1.9158,\n",
       "                       0.2138, -3.6972, -1.9212, -3.2995, -3.1840, -8.4560, -7.4588, -8.7266,\n",
       "                      -1.2513, -1.9974, -5.5300, -4.2195, -3.7250, -2.1256, -3.6457, -6.0307,\n",
       "                      -2.3493, -1.5394, -5.7551, -4.4863, -5.5497, -4.5754, -3.0556, -5.5282,\n",
       "                       4.0172, -6.1605, -3.4883, -3.7118, -7.3187, -8.2365, -3.5258, -1.8673,\n",
       "                      -0.7454, -1.8293, -3.3306, -6.0135, -0.3439, -1.7986, -4.1060, -8.0788,\n",
       "                      -6.2054, -4.6057, -8.8555, -5.2569, -3.6296, -6.3634, -4.6917, -5.0731,\n",
       "                      -3.5708, -3.3057, -4.4096, -5.6592, -7.4107, -2.9892, -6.6684, -3.7112,\n",
       "                      -0.1329, -7.2910, -5.4560, -7.7363, -6.1466, -4.1547, -5.3513, -9.7286,\n",
       "                      -4.6962, -7.7151, -8.1191, -3.9913, -1.1417, -2.8012, -5.0069, -5.7323,\n",
       "                      -2.7388, -4.5593, -8.8022, -4.6429, -1.6462, -6.3479, -3.9436, -3.4581,\n",
       "                      -3.9018, -2.6764, -4.2597, -3.6427, -5.7447, -4.2069, -2.9528, -6.0274,\n",
       "                      -2.2515, -7.0223, -2.5649, -0.8349, -6.6115, -3.0227, -5.8236, -5.4464,\n",
       "                      -4.9398,  0.5112, -5.7200, -2.4090, -1.9134, -1.6693, -8.4573, -7.5632],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.running_var',\n",
       "              tensor([30.6659, 44.3200, 18.3157, 20.5948, 15.7070, 15.0497,  6.2826, 38.1174,\n",
       "                      17.1388, 41.9682, 27.3024, 12.1402, 22.9494, 13.0412, 24.8706, 15.3759,\n",
       "                      34.4519, 18.4692, 20.1711, 17.2156, 29.4188, 23.2388, 16.7092, 22.9201,\n",
       "                       2.3241, 25.2681, 19.5696, 18.9731, 31.4712, 37.6598, 30.9196, 35.2994,\n",
       "                      12.7409, 12.1795, 10.5677, 24.4400, 32.0738, 23.1013, 22.0267, 24.0519,\n",
       "                      30.1795, 28.6623, 35.2770, 17.5137, 14.4632, 34.9817, 13.1082, 22.4076,\n",
       "                      12.2356, 27.6757, 42.7241, 11.3820, 23.2812, 39.8190, 16.6850, 16.6628,\n",
       "                      11.7425, 13.5440, 14.1517, 16.3527, 17.1861, 17.4135, 15.5357, 22.4912,\n",
       "                      20.4443, 15.9669, 16.4832, 17.2318,  7.1193, 20.2935,  6.8821, 24.5627,\n",
       "                      20.3342, 14.7529, 22.7395, 34.7625, 61.4325, 17.0555, 45.7971, 19.0875,\n",
       "                      13.7665, 27.6330, 16.5559, 25.3476, 20.9822, 23.3057, 16.2179, 45.1180,\n",
       "                      34.5436, 18.5065, 19.3175, 20.1623, 11.7982, 19.0447, 22.6937, 27.3784,\n",
       "                      17.4375, 14.3894, 23.7390, 21.1173, 32.1722, 13.5240, 26.1376, 13.4418,\n",
       "                      26.0792, 11.1197, 22.5386, 34.6845, 43.4385, 20.0209, 30.8511, 14.8955,\n",
       "                      25.5031, 25.1505, 13.1208, 45.8165, 26.7770, 35.5371, 17.3669, 15.0885,\n",
       "                      11.7473, 12.7117, 25.2792, 11.6972, 56.6025, 13.2156, 36.0186, 25.4881],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.conv1.weight',\n",
       "              tensor([[[[ 0.1918,  0.2914,  0.2449],\n",
       "                        [ 0.1409,  0.4522,  0.5067],\n",
       "                        [-0.0884,  0.0737,  0.0301]],\n",
       "              \n",
       "                       [[ 0.1019,  0.0240,  0.1687],\n",
       "                        [ 0.1553,  0.1560,  0.1272],\n",
       "                        [ 0.3152,  0.1944,  0.5959]],\n",
       "              \n",
       "                       [[-0.0959,  0.0195, -0.0181],\n",
       "                        [ 0.1306,  0.3360,  0.2106],\n",
       "                        [ 0.0172,  0.2755,  0.1774]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0589, -0.0836, -0.0707],\n",
       "                        [-0.0466, -0.0364, -0.0165],\n",
       "                        [-0.1360, -0.1182, -0.2067]],\n",
       "              \n",
       "                       [[ 0.1215, -0.0398,  0.0103],\n",
       "                        [ 0.2076,  0.1056,  0.0358],\n",
       "                        [ 0.2488,  0.1140,  0.0059]],\n",
       "              \n",
       "                       [[-0.1999,  0.1547, -0.0563],\n",
       "                        [ 0.0262,  0.1187,  0.0150],\n",
       "                        [-0.0092,  0.0139, -0.0758]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2419,  0.0038,  0.0491],\n",
       "                        [ 0.1142,  0.1323,  0.0855],\n",
       "                        [ 0.0182,  0.1687,  0.1369]],\n",
       "              \n",
       "                       [[ 0.0632, -0.0132, -0.2317],\n",
       "                        [-0.0641,  0.1044, -0.1256],\n",
       "                        [-0.2285, -0.0290, -0.1301]],\n",
       "              \n",
       "                       [[ 0.1610,  0.1163, -0.5981],\n",
       "                        [-0.1550,  0.0303, -0.5493],\n",
       "                        [-0.0474,  0.0092, -0.9042]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0083,  0.0083,  0.0075],\n",
       "                        [ 0.0145,  0.0950,  0.0511],\n",
       "                        [ 0.0830,  0.1164,  0.0494]],\n",
       "              \n",
       "                       [[ 0.2263,  0.1090,  0.0101],\n",
       "                        [ 0.1972,  0.0947,  0.0223],\n",
       "                        [ 0.2290,  0.0657,  0.0559]],\n",
       "              \n",
       "                       [[ 0.0564,  0.0782, -0.1155],\n",
       "                        [-0.0289,  0.0121, -0.1669],\n",
       "                        [-0.1572, -0.0734, -0.2753]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1550,  0.0760, -0.0711],\n",
       "                        [ 0.0081,  0.0031,  0.2342],\n",
       "                        [-0.0559, -0.0469,  0.0951]],\n",
       "              \n",
       "                       [[-0.2200, -0.1018,  0.0902],\n",
       "                        [-0.0272, -0.0195, -0.0870],\n",
       "                        [-0.0746,  0.0177, -0.0156]],\n",
       "              \n",
       "                       [[ 0.1937,  0.1846, -0.1088],\n",
       "                        [-0.0464, -0.0803, -0.1807],\n",
       "                        [-0.2460, -0.4201, -0.2906]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2961,  0.0428,  0.0576],\n",
       "                        [-0.0060, -0.0896, -0.0119],\n",
       "                        [-0.0070, -0.1107, -0.0374]],\n",
       "              \n",
       "                       [[ 0.0958, -0.1339, -0.5265],\n",
       "                        [ 0.2807, -0.0662, -0.3240],\n",
       "                        [ 0.1958, -0.0395,  0.0079]],\n",
       "              \n",
       "                       [[-0.1234, -0.1167,  0.0425],\n",
       "                        [-0.1760, -0.0356,  0.1057],\n",
       "                        [ 0.0918,  0.0630,  0.0935]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1052,  0.0447, -0.0383],\n",
       "                        [ 0.3132, -0.0677,  0.2181],\n",
       "                        [ 0.3347,  0.1222,  0.1651]],\n",
       "              \n",
       "                       [[-0.1390, -0.1263, -0.2003],\n",
       "                        [ 0.0697,  0.2888,  0.1418],\n",
       "                        [-0.1250,  0.1076, -0.2513]],\n",
       "              \n",
       "                       [[ 0.1868,  0.4712, -0.2973],\n",
       "                        [ 0.4597,  0.3130,  0.0224],\n",
       "                        [ 0.6202,  0.3876,  0.2023]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1832, -0.2164, -0.1429],\n",
       "                        [-1.0208, -0.7868, -0.6915],\n",
       "                        [ 0.0429, -0.0640,  0.0734]],\n",
       "              \n",
       "                       [[ 0.3000, -0.1256, -0.1552],\n",
       "                        [ 0.3883,  0.0413, -0.0672],\n",
       "                        [-0.0734, -0.2630, -0.1852]],\n",
       "              \n",
       "                       [[-0.0130, -0.1501, -0.0803],\n",
       "                        [-0.0735, -0.1439, -0.1835],\n",
       "                        [-0.0352, -0.1001, -0.0571]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1292, -0.0475, -0.2751],\n",
       "                        [-0.0806, -0.0832, -0.1058],\n",
       "                        [-0.2897, -0.2348, -0.2851]],\n",
       "              \n",
       "                       [[ 0.3081, -0.0171,  0.0433],\n",
       "                        [ 0.3938, -0.0264,  0.0846],\n",
       "                        [-0.0721, -0.1088,  0.0143]],\n",
       "              \n",
       "                       [[-0.2201, -0.1279,  0.0128],\n",
       "                        [-0.0203, -0.0936,  0.2572],\n",
       "                        [-0.0513,  0.0027,  0.2839]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1582,  0.0710, -0.0582],\n",
       "                        [-0.1213,  0.0654,  0.0037],\n",
       "                        [-0.0399,  0.0586, -0.0409]],\n",
       "              \n",
       "                       [[ 0.1604, -0.0942, -0.0826],\n",
       "                        [ 0.0975,  0.0810,  0.0280],\n",
       "                        [ 0.1393,  0.1117,  0.0537]],\n",
       "              \n",
       "                       [[-0.0604, -0.2456, -0.2025],\n",
       "                        [ 0.0392, -0.1012, -0.0784],\n",
       "                        [-0.0073, -0.2827, -0.0562]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0430,  0.2113,  0.5149],\n",
       "                        [-0.0677,  0.0607,  0.4389],\n",
       "                        [-0.2325, -0.0065,  0.1742]],\n",
       "              \n",
       "                       [[-0.3542, -0.1437,  0.3854],\n",
       "                        [-0.2052, -0.2274,  0.2500],\n",
       "                        [-0.4057, -0.3395, -0.0143]],\n",
       "              \n",
       "                       [[-0.1930, -0.0256, -0.0375],\n",
       "                        [ 0.0103, -0.0207, -0.0794],\n",
       "                        [ 0.3867,  0.2394,  0.1966]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1049,  0.0724, -0.0165],\n",
       "                        [ 0.0512,  0.0242, -0.0029],\n",
       "                        [ 0.0762,  0.0376,  0.0533]],\n",
       "              \n",
       "                       [[-0.0143,  0.0353,  0.0516],\n",
       "                        [-0.0515,  0.0574,  0.0636],\n",
       "                        [ 0.1108,  0.1316,  0.1324]],\n",
       "              \n",
       "                       [[ 0.2118, -0.2252,  0.0978],\n",
       "                        [ 0.4146, -0.1564,  0.0487],\n",
       "                        [ 0.1328, -0.3897, -0.1263]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.conv2.weight',\n",
       "              tensor([[[[ 1.3757e-01,  4.3896e-02,  7.7711e-02],\n",
       "                        [ 3.9155e-02, -1.6810e-02, -5.3194e-03],\n",
       "                        [-7.1487e-02, -8.9337e-02, -9.6639e-02]],\n",
       "              \n",
       "                       [[ 1.0051e-01,  5.4529e-02,  2.5286e-01],\n",
       "                        [ 2.2643e-01,  1.0918e-01,  2.1707e-01],\n",
       "                        [ 2.2286e-01,  1.7694e-01,  1.8261e-01]],\n",
       "              \n",
       "                       [[ 1.0463e-01,  4.7260e-02,  1.4341e-01],\n",
       "                        [ 6.8646e-03,  3.5136e-02, -1.8568e-01],\n",
       "                        [ 1.4691e-02,  2.7523e-02, -8.4363e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.6073e-02, -1.0391e-01, -5.4284e-01],\n",
       "                        [-1.1898e-01, -1.1015e-01, -2.7668e-01],\n",
       "                        [-1.6836e-01, -1.7446e-01, -4.8569e-01]],\n",
       "              \n",
       "                       [[-2.9016e-01, -1.0900e-01, -5.3641e-02],\n",
       "                        [-2.6679e-01, -1.2469e-01, -1.4308e-01],\n",
       "                        [-1.3673e-01, -1.5387e-02,  1.9499e-02]],\n",
       "              \n",
       "                       [[-3.0667e-02, -2.2987e-01, -2.8192e-01],\n",
       "                        [-1.4152e-01, -1.1759e-01, -1.8855e-01],\n",
       "                        [-1.6718e-01, -2.3168e-01, -2.6251e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8786e-01,  1.6873e-01,  1.3946e-01],\n",
       "                        [-1.7823e-01,  5.2950e-02,  1.0508e-01],\n",
       "                        [ 3.9748e-02,  1.1322e-01,  9.1565e-02]],\n",
       "              \n",
       "                       [[ 1.6513e-01,  7.0866e-02,  2.9959e-02],\n",
       "                        [ 1.8623e-01,  8.5402e-02,  1.0393e-01],\n",
       "                        [ 1.6429e-01,  6.0174e-02,  9.9975e-02]],\n",
       "              \n",
       "                       [[-2.9346e-02,  2.7225e-01,  4.5111e-03],\n",
       "                        [-1.6765e-01,  8.2408e-02, -6.9969e-02],\n",
       "                        [-3.3864e-01, -3.1999e-01, -4.8076e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.7067e-02,  3.7755e-02,  1.4875e-01],\n",
       "                        [ 1.3623e-01,  5.7685e-02,  1.2049e-01],\n",
       "                        [-4.3463e-02,  8.5667e-02,  2.6807e-01]],\n",
       "              \n",
       "                       [[ 3.3094e-02, -3.1364e-02, -9.8045e-02],\n",
       "                        [ 5.5394e-02,  1.4516e-01,  4.4614e-02],\n",
       "                        [ 1.2437e-01,  6.7197e-02,  2.6299e-01]],\n",
       "              \n",
       "                       [[ 1.3716e-02,  2.9617e-02, -8.5375e-03],\n",
       "                        [-5.4299e-02, -9.0567e-03, -3.2639e-02],\n",
       "                        [-3.9753e-02, -3.7975e-02,  1.0959e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2729e-02,  1.2983e-02, -1.1082e-03],\n",
       "                        [-1.0104e-02, -2.4775e-03, -1.8996e-03],\n",
       "                        [-6.1798e-02, -5.7441e-02, -7.8250e-02]],\n",
       "              \n",
       "                       [[-1.8100e-02, -8.1336e-02,  8.5607e-03],\n",
       "                        [ 2.4292e-02,  3.0190e-03,  6.1094e-03],\n",
       "                        [ 5.0470e-02, -2.3951e-03,  3.9983e-02]],\n",
       "              \n",
       "                       [[-1.2726e-02, -9.6699e-02, -1.3851e-01],\n",
       "                        [-2.9790e-02, -8.6112e-02, -1.5020e-01],\n",
       "                        [-7.4393e-02, -9.5068e-02, -1.3827e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.0869e-02, -7.1531e-02, -3.1412e-03],\n",
       "                        [-2.2586e-02, -4.4022e-03, -1.1555e-02],\n",
       "                        [-3.3323e-02, -7.2141e-02, -3.3744e-02]],\n",
       "              \n",
       "                       [[ 3.9286e-02,  2.1935e-02, -1.1812e-02],\n",
       "                        [ 8.7210e-02,  4.9117e-02,  3.8273e-02],\n",
       "                        [ 7.9813e-03,  2.1938e-02, -2.2139e-02]],\n",
       "              \n",
       "                       [[-1.0034e-01, -6.9140e-02, -9.8685e-02],\n",
       "                        [ 7.6026e-03,  5.4144e-04, -2.7368e-02],\n",
       "                        [ 2.0734e-02,  2.5915e-02, -4.8275e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.3179e-03, -1.0582e-01, -7.0599e-02],\n",
       "                        [ 3.1258e-02,  2.8049e-02,  2.0656e-03],\n",
       "                        [ 1.3279e-01,  4.2829e-02,  9.6902e-02]],\n",
       "              \n",
       "                       [[-2.8050e-01, -2.3010e-01, -2.8824e-01],\n",
       "                        [-3.2654e-02,  7.5081e-02, -1.0713e-01],\n",
       "                        [ 2.2023e-01,  1.2251e-01, -3.1004e-02]],\n",
       "              \n",
       "                       [[-2.2567e-02, -1.0412e-01, -2.9561e-01],\n",
       "                        [-6.5547e-02, -1.8374e-01, -2.1960e-01],\n",
       "                        [ 4.5878e-02, -5.6491e-02, -1.8567e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2591e-01, -2.1784e-02, -4.0365e-02],\n",
       "                        [-5.7017e-02,  8.3478e-02, -3.8980e-02],\n",
       "                        [ 7.2135e-02,  1.7239e-01,  1.7608e-01]],\n",
       "              \n",
       "                       [[-3.4503e-01, -3.1989e-01, -3.2226e-01],\n",
       "                        [-1.6589e-01, -1.6011e-01, -1.2297e-01],\n",
       "                        [-7.5813e-02, -5.2137e-02, -5.5259e-02]],\n",
       "              \n",
       "                       [[-1.4890e-01,  1.2244e-02,  3.4804e-03],\n",
       "                        [ 9.9097e-02,  1.0039e-01,  1.1039e-01],\n",
       "                        [ 2.7918e-01,  2.4813e-01,  2.0999e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2763e-02,  3.3710e-02,  9.8060e-02],\n",
       "                        [ 4.1523e-02,  1.0447e-01,  1.1888e-01],\n",
       "                        [ 9.0085e-02,  1.0030e-01,  1.2675e-01]],\n",
       "              \n",
       "                       [[-2.0796e-02,  1.4305e-01, -8.5851e-02],\n",
       "                        [ 9.9763e-02,  1.7328e-01,  1.0501e-01],\n",
       "                        [ 9.9091e-02,  1.1628e-01,  5.7350e-02]],\n",
       "              \n",
       "                       [[-1.8043e-01, -6.2085e-02, -4.5798e-02],\n",
       "                        [-8.4020e-02,  1.2727e-01,  9.6284e-02],\n",
       "                        [ 1.7993e-01,  1.3537e-01,  1.8061e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.6259e-02, -5.4515e-02,  1.0738e-01],\n",
       "                        [-1.6335e-01, -1.6188e-01, -4.7400e-02],\n",
       "                        [-4.4075e-01, -2.0570e-01, -2.3790e-01]],\n",
       "              \n",
       "                       [[ 6.3876e-02,  5.0798e-02,  3.0333e-02],\n",
       "                        [ 1.7889e-02,  1.8676e-02,  2.0114e-02],\n",
       "                        [ 3.7309e-03,  6.1642e-02,  1.0740e-01]],\n",
       "              \n",
       "                       [[ 7.5402e-02,  6.8505e-02,  1.2329e-02],\n",
       "                        [ 9.4484e-02,  1.3652e-01,  7.6856e-02],\n",
       "                        [ 2.4983e-01,  2.6860e-01,  1.3195e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5039e-02,  3.9122e-02, -4.0369e-03],\n",
       "                        [-1.2478e-01, -5.6188e-02, -2.4111e-02],\n",
       "                        [-6.4421e-02, -1.1154e-02,  3.1546e-02]],\n",
       "              \n",
       "                       [[ 6.7863e-02, -1.7155e-02,  8.1381e-02],\n",
       "                        [-3.2866e-02, -1.4610e-01, -7.5981e-03],\n",
       "                        [-9.6189e-02, -1.5031e-01, -2.5742e-02]],\n",
       "              \n",
       "                       [[-6.0012e-02,  7.6986e-02,  5.3144e-01],\n",
       "                        [ 1.6253e-01,  2.6311e-02,  2.9028e-01],\n",
       "                        [ 2.8924e-01,  4.3638e-01,  9.5001e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.4443e-02,  8.4047e-02,  9.4683e-02],\n",
       "                        [ 7.5064e-02,  8.1519e-03,  9.3771e-02],\n",
       "                        [ 4.4937e-02,  1.1582e-02,  3.0661e-02]],\n",
       "              \n",
       "                       [[-4.2403e-02,  5.5279e-02,  7.3614e-02],\n",
       "                        [-1.4714e-01, -1.1489e-01, -1.1970e-01],\n",
       "                        [-2.2739e-01, -2.6858e-01, -2.7262e-01]],\n",
       "              \n",
       "                       [[ 5.3812e-02,  1.3348e-01,  9.6792e-02],\n",
       "                        [ 1.7793e-02,  9.1173e-02,  1.9585e-02],\n",
       "                        [ 7.9299e-03,  8.6664e-02,  1.0111e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.weight',\n",
       "              tensor([1.0210, 1.0682, 1.3787, 1.2665, 1.1524, 1.2183, 0.7760, 0.9235, 1.3536,\n",
       "                      1.1974, 1.3259, 1.0340, 0.7915, 1.4988, 1.3355, 1.0443, 1.5879, 1.0444,\n",
       "                      1.4216, 1.0978, 0.9139, 1.1532, 1.1720, 1.4551, 0.9114, 1.1548, 0.2007,\n",
       "                      0.9233, 0.9801, 1.4392, 1.2658, 1.2461, 1.2587, 0.9034, 1.2150, 0.9803,\n",
       "                      0.9793, 1.0596, 1.2942, 1.0567, 0.9321, 1.1342, 1.5601, 1.0315, 1.2391,\n",
       "                      1.0022, 0.9950, 1.2044, 1.0443, 1.0558, 1.0039, 1.3602, 1.1981, 1.2316,\n",
       "                      1.3122, 1.0064, 0.7829, 1.3809, 1.1030, 1.4282, 0.9289, 1.1313, 1.3792,\n",
       "                      0.9184, 1.0905, 1.0623, 1.2476, 1.4465, 1.1163, 1.2293, 1.0798, 1.3139,\n",
       "                      1.7250, 0.8172, 1.5012, 1.3231, 1.0144, 1.1767, 0.8729, 1.1869, 0.9012,\n",
       "                      1.0563, 0.7078, 1.3326, 1.0936, 1.0224, 1.3593, 0.9392, 1.0068, 0.9863,\n",
       "                      1.1849, 0.9958, 1.2248, 0.9927, 0.3141, 1.3952, 1.0526, 0.9720, 1.1495,\n",
       "                      1.1253, 0.9783, 1.0597, 1.0248, 1.4366, 1.3393, 1.2572, 0.9937, 1.1931,\n",
       "                      1.1437, 0.8957, 1.2098, 0.2566, 1.0649, 1.3017, 1.0800, 0.5224, 1.0450,\n",
       "                      1.1513, 1.1263, 0.8780, 1.3537, 1.1516, 1.5164, 1.1235, 0.9574, 0.9924,\n",
       "                      1.1335, 1.0409, 0.9817, 0.9195, 0.9063, 0.7173, 1.1560, 1.2215, 1.1700,\n",
       "                      1.4139, 1.2205, 0.9432, 1.0820, 1.4721, 1.3174, 1.0905, 1.2970, 0.8261,\n",
       "                      0.9812, 1.0475, 1.2826, 1.2452, 0.8185, 1.0462, 1.0750, 1.5156, 1.1132,\n",
       "                      1.3410, 1.1077, 1.1155, 1.2860, 0.9671, 0.5262, 1.1721, 0.9906, 1.1165,\n",
       "                      1.2943, 0.9292, 1.0349, 1.1765, 1.1188, 1.1820, 0.9491, 0.9734, 1.3175,\n",
       "                      1.2034, 1.2084, 0.9865, 1.2615, 0.8739, 0.7807, 1.1073, 0.7385, 0.9734,\n",
       "                      1.4519, 0.9854, 1.0787, 1.0790, 1.0758, 1.1872, 1.0594, 0.9354, 0.5785,\n",
       "                      1.2671, 0.6805, 1.1030, 1.2096, 1.1690, 0.8356, 0.8897, 1.0657, 1.2187,\n",
       "                      0.9070, 0.7119, 0.9653, 0.9849, 1.0520, 0.2849, 0.9442, 1.1167, 1.2524,\n",
       "                      1.0367, 1.4768, 1.2307, 1.2085, 0.8254, 1.2146, 1.1639, 0.2181, 1.2649,\n",
       "                      1.1123, 1.2077, 1.2347, 1.0788, 1.5626, 1.0067, 1.1525, 1.1592, 1.1814,\n",
       "                      1.2216, 1.1346, 0.6273, 1.3089, 1.5136, 1.1486, 0.7495, 1.3114, 0.9355,\n",
       "                      1.1059, 1.4022, 1.3204, 1.5235, 1.3346, 1.1735, 1.1633, 1.0751, 1.3056,\n",
       "                      1.0540, 1.0776, 0.9134, 0.7332, 1.1821, 0.9479, 0.8942, 1.1816, 1.1299,\n",
       "                      0.9147, 1.0555, 0.8702, 1.0005], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.bias',\n",
       "              tensor([-0.8982, -0.5593, -0.8299, -0.8870, -0.6938, -0.3829, -1.0505, -0.7719,\n",
       "                      -0.6779, -0.5489, -0.8549, -0.9675, -0.3858, -1.1915, -0.7939, -0.5287,\n",
       "                      -1.0818, -0.6826, -1.1990, -0.5504, -0.6985, -0.5265, -0.7031, -0.7221,\n",
       "                      -0.6240, -0.7923, -0.7477, -0.6211, -0.4847, -0.9305, -0.8672, -0.9640,\n",
       "                      -0.5970, -0.7963, -1.0095, -0.7041, -0.6201, -0.8272, -0.8642, -0.7149,\n",
       "                      -0.1486, -0.8913, -1.5533, -0.5700, -0.7954, -0.9663, -0.5202, -1.0395,\n",
       "                      -1.0383, -0.8046, -0.7002, -1.1470, -0.5868, -0.7367, -0.7754, -0.4929,\n",
       "                      -0.6644, -0.7077, -0.7026, -0.8174, -0.6611, -0.5234, -0.6234, -0.5961,\n",
       "                      -0.5143, -0.7454, -0.6751, -0.6286, -1.0052, -1.2545, -0.4291, -1.1618,\n",
       "                      -0.8726, -0.8077, -1.0296, -0.9257, -1.2397, -0.9032, -1.1586, -0.6834,\n",
       "                      -0.3203, -0.7832,  0.3590, -0.7680, -0.7617, -0.9250, -0.9485, -0.8702,\n",
       "                      -0.5869, -0.2732, -1.1147, -0.6329, -0.7087, -0.5849, -1.2142, -0.8736,\n",
       "                      -1.2073, -0.4033, -0.6485, -0.9067, -0.1779, -0.7485, -1.5761, -0.8470,\n",
       "                      -0.5936, -1.3240, -0.8528, -0.7504, -0.8944, -0.4018, -0.9139, -0.2481,\n",
       "                      -1.2777, -0.6512, -0.5649,  0.1888, -0.9627, -0.8056, -0.6371, -0.6132,\n",
       "                      -1.0691, -0.5870, -1.7209, -0.3129, -0.5256, -1.5523, -0.5553, -0.8495,\n",
       "                      -0.0422, -0.3014, -0.5068, -0.6025, -0.5146, -1.0281, -0.7575, -1.0009,\n",
       "                      -0.9620, -0.3392, -0.7340, -0.9131, -1.0636, -0.7621, -0.8121, -0.3924,\n",
       "                      -1.2843, -0.4223, -0.8621, -0.7582, -0.4664, -0.6746, -0.9525, -0.7069,\n",
       "                      -0.6494, -1.2329, -0.9510, -0.5987, -0.8122, -0.2585, -2.3511, -0.4336,\n",
       "                      -0.4982, -1.0574, -0.6793, -0.3944, -0.4837, -0.6630, -1.0718, -0.7356,\n",
       "                      -0.3307, -0.7226, -0.8178, -0.3179, -0.6890, -0.4605, -1.2686, -0.4719,\n",
       "                      -0.4427, -0.6833, -0.3259, -0.6951, -1.1053, -0.9664, -0.7898, -0.8774,\n",
       "                      -0.1740, -0.9885, -0.3770, -0.7380, -1.2202, -1.1224, -0.1347, -0.7182,\n",
       "                      -0.7212, -0.3407, -0.2000, -0.8056, -0.8408, -0.6210, -1.0593, -3.0333,\n",
       "                      -0.3586, -1.0164, -0.5091, -0.7474, -0.7502, -0.5594, -0.7063, -0.6198,\n",
       "                      -1.2757, -0.9516, -0.7334, -0.6935, -0.7772, -0.7707, -0.4082, -1.0337,\n",
       "                      -0.6719, -0.8486, -0.8674, -0.7073, -0.8083, -0.7788, -0.8789, -0.3953,\n",
       "                      -1.1115, -0.7206, -0.9332,  0.0890, -0.8098, -0.9703, -1.0459, -0.3908,\n",
       "                      -0.4484, -0.9225, -0.8505, -0.7879, -0.9284, -1.4579, -1.1448, -0.5124,\n",
       "                      -0.8017, -0.4046, -0.8617, -0.6982, -0.5067, -0.4861, -0.2880, -0.7619,\n",
       "                      -0.6610, -0.4801, -0.9662, -0.7079, -0.0607, -0.8820, -0.4338, -0.8083],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.running_mean',\n",
       "              tensor([-3.6716, -4.4998, -3.3928, -4.3136, -4.6425, -6.1826,  2.4349, -2.4528,\n",
       "                      -5.3190, -4.4415, -5.0642, -4.3423, -0.9123, -1.6092, -3.6615, -4.2036,\n",
       "                      -5.0053, -5.8946, -1.9175, -2.6510, -2.0259, -3.2013, -2.9067, -3.4250,\n",
       "                      -3.6012, -2.8132,  0.2122, -1.4167, -2.3176, -4.8757, -1.5723, -3.1555,\n",
       "                      -3.8470, -3.5484, -4.6692, -1.2059, -5.4423, -6.5821, -2.9674, -3.6584,\n",
       "                      -5.3014, -2.0395, -3.5407, -3.4778, -3.0371,  0.2025, -0.0142, -0.6985,\n",
       "                      -3.6262, -5.2778, -1.2839, -0.6250, -3.5389, -1.7519, -7.4743, -1.9592,\n",
       "                      -5.1269, -5.5833, -3.8974, -5.2696, -4.9513, -2.1108, -5.9900, -2.8826,\n",
       "                       0.3543, -2.9952, -4.6341, -2.8891, -3.0032, -5.8718, -3.6505, -2.1396,\n",
       "                      -3.3803,  0.5207, -1.3521, -3.7571, -0.0504, -3.8170,  2.6244, -3.5578,\n",
       "                      -5.7465, -5.9931, -2.0362, -7.6235, -3.8140, -1.5547, -4.4511, -4.1878,\n",
       "                      -3.8005, -3.5834,  1.3269, -3.9786, -1.9909, -3.7507,  0.1906, -6.9346,\n",
       "                       1.3870, -2.8135, -3.8540, -1.1593, -4.5123, -2.3343,  0.0959, -1.7825,\n",
       "                      -3.6221, -1.7327, -0.6540, -6.8581, -0.6884, -6.3777, -2.5159, -0.2136,\n",
       "                      -0.7809, -4.1160, -2.5850, -3.2121, -4.0634, -1.8600, -3.4295,  1.6156,\n",
       "                      -3.2638, -5.7367, -4.3896, -3.4009, -1.5803,  5.5251, -3.7837, -1.5342,\n",
       "                      -1.6288, -2.4254, -4.1731, -1.9629, -4.0375, -4.3813, -1.0746, -1.9116,\n",
       "                      -3.3286, -1.3124, -3.1905, -2.5201, -4.8249, -2.8369, -2.2420, -8.3987,\n",
       "                       5.3649, -3.0550, -4.4956, -3.3828, -1.4829, -3.6053, -4.1002, -4.3864,\n",
       "                      -3.4545, -1.2725, -1.7832, -3.7080, -3.4804, -4.7292,  0.0678, -5.4915,\n",
       "                      -2.0888, -2.6093, -2.9651, -3.9596, -3.0122, -6.6763, -3.8709, -2.6090,\n",
       "                      -0.7712, -2.2966, -2.8729, -2.7528, -2.3835, -3.5038, -8.4375, -5.2468,\n",
       "                      -1.0841, -4.8295, -5.4690, -5.4507, -4.4401,  0.3135, -4.0276, -3.3131,\n",
       "                      -2.2113, -4.1910, -6.2188, -0.8436,  0.2293,  1.4562, -6.2594, -3.6078,\n",
       "                      -1.6662, -3.9950, -2.1669, -4.7181, -0.4500, -3.1043, -0.6794, -1.1833,\n",
       "                      -4.7434,  0.2188, -2.0610,  0.3194, -0.1356, -4.5057, -3.3635, -1.3687,\n",
       "                      -4.0310, -2.8598, -3.1592, -0.2566, -2.2996, -4.2440,  0.4073, -4.5379,\n",
       "                      -4.2696, -3.6634, -3.5430, -2.7403, -3.3694,  1.1686, -2.6047, -2.3251,\n",
       "                      -3.5192, -2.8872, -1.9932, -2.2582, -3.1104, -7.5036, -1.8841, -0.2710,\n",
       "                      -2.5072,  2.6645, -1.1727, -3.0118, -4.0894, -5.0187, -3.1375, -3.0995,\n",
       "                      -4.8769, -0.5808, -2.1449, -0.8675, -2.4263, -5.6197, -5.6222, -1.7829,\n",
       "                      -3.5098, -1.2072, -3.4861, -3.3749, -3.2012, -3.6895, -4.1671, -1.3001],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.running_var',\n",
       "              tensor([5.7976e+00, 1.0303e+01, 1.8532e+01, 8.1071e+00, 1.4653e+01, 3.4577e+01,\n",
       "                      6.6280e+00, 1.8159e+01, 1.8759e+01, 9.0697e+00, 1.4710e+01, 7.8978e+00,\n",
       "                      1.3225e+01, 5.6688e+00, 1.2380e+01, 5.3476e+00, 1.6595e+01, 1.1957e+01,\n",
       "                      4.3686e+00, 5.3855e+00, 7.4871e+00, 1.5339e+01, 1.3848e+01, 1.3873e+01,\n",
       "                      7.8771e+00, 2.1859e+01, 3.1837e-01, 9.6762e+00, 2.1956e+01, 1.9514e+01,\n",
       "                      5.6002e+00, 8.6276e+00, 1.2053e+01, 1.1066e+01, 1.0630e+01, 1.0872e+01,\n",
       "                      1.0524e+01, 1.3720e+01, 1.5714e+01, 1.2064e+01, 1.4017e+01, 1.1442e+01,\n",
       "                      8.7009e+00, 7.3242e+00, 1.1817e+01, 1.1544e+01, 1.1481e+01, 7.0910e+00,\n",
       "                      7.4718e+00, 6.3352e+00, 3.4908e+00, 7.1058e+00, 1.2840e+01, 4.7154e+00,\n",
       "                      1.7992e+01, 4.9718e+00, 1.1630e+01, 1.3115e+01, 1.5667e+01, 1.6031e+01,\n",
       "                      9.7328e+00, 1.1478e+01, 1.5452e+01, 1.1953e+01, 1.5424e+01, 1.4640e+01,\n",
       "                      1.1706e+01, 1.8597e+01, 6.2712e+00, 1.6643e+01, 9.9804e+00, 5.3885e+00,\n",
       "                      2.4392e+01, 3.0136e+00, 9.2681e+00, 1.4552e+01, 3.7358e+00, 1.0519e+01,\n",
       "                      5.7727e+00, 8.1866e+00, 1.3902e+01, 9.1539e+00, 1.3845e+01, 1.7084e+01,\n",
       "                      5.6192e+00, 3.4896e+00, 8.8599e+00, 6.4242e+00, 1.5906e+01, 1.4505e+01,\n",
       "                      4.7681e+00, 5.7155e+00, 1.1734e+01, 6.9707e+00, 5.5136e-01, 1.6104e+01,\n",
       "                      2.5965e+00, 1.0944e+01, 8.1110e+00, 1.0195e+01, 1.6952e+01, 1.3493e+01,\n",
       "                      6.0901e+00, 8.9571e+00, 8.6324e+00, 6.5912e+00, 3.7050e+00, 1.6901e+01,\n",
       "                      4.3927e+00, 1.3979e+01, 1.5108e+01, 2.7228e-01, 5.8820e+00, 7.7603e+00,\n",
       "                      9.9676e+00, 1.1688e+01, 5.9136e+00, 7.2226e+00, 9.1692e+00, 1.8006e+01,\n",
       "                      1.0924e+01, 1.6213e+01, 9.1611e+00, 1.4584e+01, 8.2220e+00, 1.5949e+01,\n",
       "                      8.6650e+00, 5.9576e+00, 1.2013e+01, 6.9288e+00, 1.4488e+01, 7.2608e+00,\n",
       "                      1.0110e+01, 1.5923e+01, 1.0383e+01, 8.5505e+00, 6.5930e+00, 1.4222e+01,\n",
       "                      8.4192e+00, 9.4597e+00, 2.0852e+01, 9.6252e+00, 6.1861e+00, 1.9565e+01,\n",
       "                      6.1862e+00, 1.0905e+01, 2.3752e+01, 1.0633e+01, 8.1979e+00, 1.2115e+01,\n",
       "                      5.8161e+00, 2.5614e+01, 1.5373e+01, 6.8529e+00, 4.8582e+00, 7.2487e+00,\n",
       "                      2.3886e+01, 1.2444e+01, 9.5726e-03, 2.1607e+01, 1.3386e+01, 8.6087e+00,\n",
       "                      1.9674e+01, 1.5994e+01, 1.9218e+01, 1.3990e+01, 5.4658e+00, 1.3306e+01,\n",
       "                      1.0966e+01, 7.3778e+00, 4.8761e+00, 7.2859e+00, 5.9489e+00, 7.2654e+00,\n",
       "                      1.2752e+01, 9.5316e+00, 3.8809e+00, 1.2131e+01, 1.4180e+01, 7.5931e+00,\n",
       "                      1.1456e+01, 5.7739e+00, 1.1338e+01, 1.2067e+01, 1.4043e+01, 7.3046e+00,\n",
       "                      1.2074e+01, 9.8756e+00, 4.7968e-01, 6.9488e+00, 9.4756e+00, 4.8433e+00,\n",
       "                      1.2606e+01, 1.4359e+01, 1.3846e+01, 1.1663e+01, 6.2291e+00, 7.9061e+00,\n",
       "                      2.4580e+00, 2.8053e+00, 8.1402e+00, 3.1479e+00, 6.6411e+00, 3.8595e-01,\n",
       "                      8.5913e+00, 1.4635e+01, 1.4451e+01, 1.1988e+01, 8.3239e+00, 1.5531e+01,\n",
       "                      6.2787e+00, 1.2057e+01, 8.8100e+00, 1.2882e+01, 3.0027e-01, 1.1884e+01,\n",
       "                      7.3730e+00, 1.1336e+01, 9.5796e+00, 6.9708e+00, 2.2095e+01, 5.0976e+00,\n",
       "                      8.6211e+00, 1.3601e+01, 1.0556e+01, 6.3089e+00, 7.0896e+00, 1.6363e+01,\n",
       "                      1.1323e+01, 1.5216e+01, 9.0809e+00, 1.5924e+01, 1.8947e+01, 6.5797e+00,\n",
       "                      1.5773e+01, 1.1652e+01, 1.3167e+01, 1.4312e+01, 8.1882e+00, 7.4336e+00,\n",
       "                      1.5864e+01, 9.0699e+00, 4.2691e+00, 9.8060e+00, 4.7070e+00, 1.8503e+01,\n",
       "                      1.4675e+01, 6.3952e+00, 1.0764e+01, 1.0295e+01, 1.0047e+01, 1.5425e+01,\n",
       "                      1.5972e+01, 1.4392e+01, 1.6011e+01, 8.0134e+00], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.weight',\n",
       "              tensor([0.9051, 0.9394, 0.3467, 1.0366, 1.0479, 1.1572, 1.6049, 1.1137, 0.9935,\n",
       "                      1.1752, 0.8874, 1.0937, 0.6876, 1.1102, 1.4864, 1.3248, 0.9897, 1.4706,\n",
       "                      1.4177, 0.2613, 1.1516, 0.9729, 1.2617, 0.2820, 1.0827, 0.2616, 1.4487,\n",
       "                      1.0664, 1.4253, 1.3209, 1.0332, 1.2626, 0.9325, 1.1220, 0.8981, 1.0424,\n",
       "                      0.9619, 1.2507, 1.3945, 1.1734, 0.9084, 0.8654, 1.2673, 1.0337, 1.0987,\n",
       "                      1.3766, 1.6624, 0.8357, 1.0707, 0.9537, 0.2633, 0.9885, 0.9755, 1.3231,\n",
       "                      1.2518, 1.4758, 1.3703, 1.1539, 1.1889, 1.1905, 1.4671, 1.0795, 0.8962,\n",
       "                      0.8735, 1.1473, 1.0061, 0.9262, 0.9056, 0.9279, 1.1607, 1.1400, 1.3418,\n",
       "                      0.2692, 1.0091, 1.3077, 0.5176, 0.9112, 0.9307, 1.0229, 0.8897, 1.0297,\n",
       "                      0.9391, 1.0971, 0.4626, 0.9116, 1.4098, 1.0808, 1.0182, 1.5772, 1.0186,\n",
       "                      1.0702, 0.9926, 1.3717, 0.9138, 1.1040, 1.0963, 0.8279, 1.0532, 1.3980,\n",
       "                      1.2943, 1.0913, 0.8435, 1.0859, 0.9802, 1.0216, 0.2935, 1.1645, 0.9617,\n",
       "                      1.4009, 1.1233, 0.9578, 0.6571, 1.0725, 0.7002, 1.0372, 1.1292, 1.2509,\n",
       "                      0.9716, 1.5299, 1.2976, 1.0172, 1.2507, 1.0353, 1.0831, 0.9625, 0.9419,\n",
       "                      1.1977, 1.0909, 1.2755, 0.8902, 1.2145, 1.3266, 0.8319, 0.9505, 0.9411,\n",
       "                      1.1432, 0.9254, 1.1651, 1.1642, 0.2505, 1.2972, 1.1613, 0.9954, 1.1288,\n",
       "                      1.1554, 1.1024, 1.4579, 0.8870, 1.1077, 1.3331, 1.1827, 1.0637, 0.9267,\n",
       "                      1.1762, 1.0574, 1.2458, 1.3292, 0.9216, 1.0776, 1.2446, 1.3153, 1.2265,\n",
       "                      1.1726, 1.0782, 0.2623, 0.8875, 0.2963, 1.2376, 1.4084, 1.0460, 1.2456,\n",
       "                      1.2219, 1.0095, 1.0642, 0.9782, 1.2341, 1.0097, 1.0705, 0.8490, 0.9098,\n",
       "                      1.0768, 1.0270, 1.1807, 1.2606, 1.3560, 1.4065, 1.1395, 1.1043, 1.0956,\n",
       "                      0.9400, 0.9232, 0.9482, 1.0033, 0.7078, 1.1307, 1.1774, 0.9191, 1.1546,\n",
       "                      0.9854, 0.8554, 1.0341, 0.8977, 0.8860, 0.9033, 1.0850, 1.0711, 1.1451,\n",
       "                      0.9898, 1.1208, 1.0563, 1.3754, 0.8993, 1.0484, 0.8753, 0.9922, 1.2163,\n",
       "                      1.0892, 1.1947, 0.7565, 0.9142, 1.3299, 0.9942, 1.0805, 1.3669, 0.8534,\n",
       "                      1.3016, 1.4345, 1.2004, 1.1323, 0.7956, 0.9888, 1.0292, 1.1574, 1.1866,\n",
       "                      1.1543, 1.0344, 1.4174, 0.3030, 1.4229, 1.2801, 0.2937, 0.9351, 0.9618,\n",
       "                      1.1582, 1.2652, 0.9315, 1.1234, 1.0876, 1.0357, 1.2522, 0.9250, 1.1716,\n",
       "                      1.2080, 1.2942, 1.3198, 1.2777], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.bias',\n",
       "              tensor([-0.6634, -0.5544, -0.0422, -0.6581, -0.8572, -0.9712, -1.6261, -0.5950,\n",
       "                      -0.7201, -1.2496, -0.5318, -0.7978, -0.1393, -0.6118, -1.3631, -1.3863,\n",
       "                      -0.6188, -1.2326, -1.6330, -0.1872, -0.8443, -0.7549, -1.2820, -0.0505,\n",
       "                      -1.1499, -0.0781, -1.2581, -1.0880, -1.3273, -1.2754, -0.6035, -0.7674,\n",
       "                      -0.4481, -1.0971, -0.9998, -0.6411, -0.5971, -1.3235, -1.3134, -0.8110,\n",
       "                      -0.5895, -0.6744, -0.8855, -1.1614, -1.0477, -1.3588, -1.3315, -0.6502,\n",
       "                      -1.0932, -0.7254, -0.3861, -0.5992, -1.0614, -1.1524, -1.2114, -1.0342,\n",
       "                      -1.3392, -0.7853, -0.7540, -0.9350, -1.7840, -0.9019, -0.7942, -0.5565,\n",
       "                      -1.1643, -0.6610, -0.6357, -0.4942, -0.7252, -1.0780, -0.9504, -1.2680,\n",
       "                      -0.0283, -0.9093, -1.0604,  0.0534, -0.5707, -0.8475, -0.7689, -0.7964,\n",
       "                      -1.0437, -0.7244, -0.6308, -0.0799, -0.6952, -1.1794, -0.9914, -0.9248,\n",
       "                      -1.2379, -0.8964, -1.0408, -0.6191, -1.2270, -0.5548, -0.9034, -1.1669,\n",
       "                      -0.6484, -0.8183, -1.1430, -1.5660, -0.9298, -0.2687, -0.6611, -0.5908,\n",
       "                      -0.7479, -0.0536, -1.2109, -0.8190, -1.3240, -0.9726, -0.5736, -0.2446,\n",
       "                      -0.9323, -0.2670, -0.8135, -0.9782, -1.0693, -0.8946, -1.2197, -1.2017,\n",
       "                      -0.8493, -1.0271, -0.7801, -0.9973, -0.5407, -0.5843, -0.8183, -0.9339,\n",
       "                      -1.1637, -0.6353, -0.8803, -1.1417, -0.6053, -0.5750, -0.9905, -1.1236,\n",
       "                      -0.7335, -0.7768, -1.1079, -0.0484, -1.5820, -1.2682, -0.9510, -0.8856,\n",
       "                      -1.1036, -1.2498, -1.1422, -0.8046, -0.9191, -1.1010, -0.9548, -0.9208,\n",
       "                      -0.7223, -0.7993, -0.9130, -0.6914, -1.4146, -0.8214, -0.7783, -0.7009,\n",
       "                      -1.1782, -0.8517, -0.7981, -1.0004, -0.0658, -0.6777,  0.1841, -0.9849,\n",
       "                      -1.3402, -0.8736, -0.5267, -0.7914, -0.9291, -1.1181, -0.5579, -0.9340,\n",
       "                      -1.1616, -1.0515, -0.6710, -0.8138, -0.8020, -0.6899, -1.1364, -1.0139,\n",
       "                      -0.7805, -1.3099, -0.3936, -0.8767, -0.4665, -0.8453, -0.6968, -0.5989,\n",
       "                      -0.8351, -0.6806, -0.9338, -1.0715, -0.7662, -1.4438, -0.6182, -0.7659,\n",
       "                      -1.0537, -0.5319, -0.5135, -0.9045, -0.5828, -0.8373, -0.9134, -0.7420,\n",
       "                      -1.1932, -0.9939, -0.7015, -0.5463, -1.0515, -0.5218, -0.5948, -0.8505,\n",
       "                      -1.0803, -0.9453, -0.5138, -0.3713, -1.3711, -0.6823, -0.7744, -1.3687,\n",
       "                      -0.5889, -0.9297, -1.4539, -0.9427, -0.8768, -0.5206, -1.0093, -0.6510,\n",
       "                      -0.8140, -1.1389, -1.1334, -0.8144, -1.4738,  0.0231, -1.1460, -1.0632,\n",
       "                      -0.0401, -0.7883, -0.5025, -0.6524, -1.0350, -0.7857, -0.7549, -0.8493,\n",
       "                      -0.7969, -0.8876, -0.9356, -0.6092, -1.0583, -1.3752, -1.4297, -1.2696],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.running_mean',\n",
       "              tensor([-3.7632e+00, -9.0942e+00, -5.2324e+00, -1.6265e+01, -5.5120e+00,\n",
       "                      -8.4833e+00, -9.1915e+00, -6.0935e+00, -8.4992e+00, -8.5229e+00,\n",
       "                      -2.8742e+00, -7.1312e+00, -3.9346e+00, -8.3223e+00, -6.6446e+00,\n",
       "                      -1.4633e+01, -1.2050e+01, -7.4102e+00, -4.1665e+00, -3.8852e+00,\n",
       "                      -1.1782e+01,  2.0337e+00, -8.9674e+00, -3.5421e-02, -5.4318e+00,\n",
       "                      -6.3430e-02, -6.1789e+00, -6.2252e-01, -1.2175e+01, -5.7403e+00,\n",
       "                      -1.2922e+01, -5.8772e+00, -2.4498e+00, -1.0857e+01, -5.8939e+00,\n",
       "                      -9.4072e+00, -1.1868e+01, -3.9199e+00, -5.9831e+00, -2.7893e+00,\n",
       "                       3.7596e+00, -3.8224e+00, -3.7453e+00, -4.5187e+00, -5.4211e+00,\n",
       "                      -1.2399e+01, -4.2647e+00, -4.7974e+00, -8.3507e+00, -6.2286e+00,\n",
       "                      -8.4950e-04, -8.1919e+00, -4.1917e+00, -6.9957e+00, -7.5349e+00,\n",
       "                      -6.9743e+00, -9.6604e+00, -1.1177e+01, -7.9157e+00, -1.6553e+01,\n",
       "                      -9.1609e+00, -3.0231e+00, -2.9965e+00, -5.3564e+00, -9.3424e-01,\n",
       "                      -9.2723e+00, -1.2275e+00, -7.0908e+00, -4.9050e+00, -1.0858e+01,\n",
       "                      -7.0457e+00, -9.2624e+00, -1.0445e-01, -7.1027e+00, -8.7540e+00,\n",
       "                      -1.2387e+00, -9.5546e+00, -1.3784e+01, -9.9896e+00, -3.3787e+00,\n",
       "                      -3.7355e+00, -5.9943e+00, -7.1598e+00, -7.0738e+00, -7.9076e+00,\n",
       "                      -1.8110e+00, -4.4033e+00, -1.7395e+00, -8.2204e+00, -6.1652e+00,\n",
       "                      -4.9114e+00, -5.9712e+00, -7.1176e+00, -8.5425e+00, -1.4877e+01,\n",
       "                      -8.2049e+00,  5.1621e+00, -1.2247e+01, -5.9140e+00, -1.8665e+00,\n",
       "                      -1.9099e+00, -3.5394e+00, -5.9519e+00, -1.1243e+01, -1.0292e+01,\n",
       "                       1.1542e-02, -6.1347e+00, -6.6159e+00, -9.0597e+00, -8.9896e+00,\n",
       "                      -1.0409e+01, -7.9867e+00, -8.1136e+00, -3.0078e+00, -3.3415e+00,\n",
       "                      -5.1625e+00, -1.3732e+01, -1.0659e+01, -5.9755e+00, -1.0130e+01,\n",
       "                      -5.5045e+00, -2.5274e+00, -3.5657e+00, -9.2018e+00, -7.4413e+00,\n",
       "                      -7.7006e+00, -7.7164e+00, -9.6146e+00, -6.2727e+00, -1.0488e+01,\n",
       "                      -8.7456e+00, -2.5740e+00, -8.4706e+00, -4.7237e+00, -1.0442e+01,\n",
       "                      -9.2775e+00, -1.2671e+01, -6.6309e+00, -4.2030e+00, -7.1187e-02,\n",
       "                      -6.0836e+00, -1.0300e+01, -8.1018e+00, -2.2341e+00, -1.0689e+01,\n",
       "                      -3.6317e+00, -6.1755e+00, -1.0596e+01, -7.7081e+00, -8.6579e+00,\n",
       "                      -8.9929e+00, -1.1972e+01, -7.4886e+00, -7.2483e+00, -3.7808e+00,\n",
       "                      -6.2587e+00, -9.2261e+00, -1.3240e+00, -5.2833e+00, -9.6430e-01,\n",
       "                      -4.5933e+00, -1.0360e+01, -9.6514e+00, -5.7713e+00,  2.4909e-03,\n",
       "                      -2.9826e+00, -1.4669e+00, -3.6351e+00, -8.7625e+00, -9.2196e+00,\n",
       "                      -7.2660e+00, -6.4894e+00, -1.0512e+01, -4.7800e+00, -4.0744e+00,\n",
       "                      -6.5161e+00, -6.5730e+00, -6.1712e+00, -5.0224e+00, -4.8053e+00,\n",
       "                      -9.2358e+00, -1.0091e+01, -6.6775e+00, -5.6374e+00, -1.1505e+01,\n",
       "                      -6.4864e+00, -4.7991e+00, -1.3428e+01, -4.4413e+00, -1.2248e+01,\n",
       "                      -6.2546e+00, -6.6766e+00, -8.0788e+00,  3.5028e-01, -1.3248e+01,\n",
       "                      -3.1043e+00, -6.8361e+00,  4.3378e-01, -6.2018e+00, -6.6109e+00,\n",
       "                      -8.8146e+00, -5.1341e+00, -3.5145e+00, -5.8523e+00, -1.0397e+01,\n",
       "                      -6.2023e+00, -1.1400e+01, -3.9769e+00,  3.1227e+00, -6.3729e+00,\n",
       "                      -9.1428e+00, -8.1317e+00, -8.6478e+00, -1.1008e+01, -5.5727e+00,\n",
       "                      -9.6256e+00,  2.6206e+00, -8.8840e+00, -3.4394e+00, -1.0024e+01,\n",
       "                       2.8129e+00, -1.0264e+01, -7.9636e+00, -1.0159e+01, -7.5524e+00,\n",
       "                      -7.6272e+00, -5.8084e+00, -7.2452e+00, -1.0212e+01, -2.0675e+00,\n",
       "                      -6.7425e+00, -4.5466e+00, -1.0737e+01, -6.6364e+00, -3.5613e+00,\n",
       "                      -1.0022e+01, -1.0441e+01,  2.3489e+00, -5.4235e+00, -5.9015e+00,\n",
       "                      -5.0889e-02, -1.1071e+01, -1.1174e+01, -1.0034e+01, -6.0598e+00,\n",
       "                      -7.0747e+00, -2.3704e+00, -1.0295e+01, -1.0242e+00, -4.4956e+00,\n",
       "                      -8.1543e+00, -6.5005e+00, -5.4108e+00, -9.8053e+00, -6.2623e+00,\n",
       "                      -9.3068e+00], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.running_var',\n",
       "              tensor([ 40.5723,  65.7030,  11.8584,  67.4836,  26.6316,  50.4351,  54.1779,\n",
       "                       30.1589,  42.8167,  49.9692,  28.4224,  31.3713,  32.0274,  46.6070,\n",
       "                       48.1286,  58.4122,  31.7544,  44.7766,  27.0445,   4.2099,  77.1243,\n",
       "                       30.4201,  58.8890,   0.4141,  20.1350,   0.2635,  45.1380,  20.2287,\n",
       "                       68.0608,  23.5049,  37.5302,  53.7064,  54.6602,  58.0534,  29.1404,\n",
       "                       47.6535,  51.5917,  63.7634,  55.1338,  25.2223,  41.3617,  52.7705,\n",
       "                       34.5100,  53.7506,  58.5715,  46.6809,  34.5419,  36.1039,  36.5626,\n",
       "                       25.8292,   0.2981,  28.9679,  40.5153,  60.2064,  33.9075,  30.9585,\n",
       "                       36.4447,  51.0632,  52.7367,  81.1930,  42.4597,  43.4219,  22.2235,\n",
       "                       40.2748,  34.3417,  72.5276,  45.0313,  53.1840,  34.8067,  42.1514,\n",
       "                       47.2410,  58.1298,   0.4201,  56.7860,  30.6251,  20.6250,  42.2545,\n",
       "                       76.7949,  25.8407,  49.3553,  76.2543,  51.0976,  22.5277,  15.0258,\n",
       "                       38.6420,  30.9443,  61.9598,  59.8144,  44.0024,  55.4643,  46.6360,\n",
       "                       43.7867,  43.8053,  51.5570,  97.5555,  23.4702,  22.3750,  35.2476,\n",
       "                       50.9145,  19.7545,  36.8942,  21.6182,  36.6579,  56.8219,  43.5087,\n",
       "                        0.3208,  36.8081,  42.6586,  53.6447,  42.7517,  53.7115,  24.3025,\n",
       "                       44.2902,  32.6030,  67.9141,  46.2343,  49.2114,  41.4842,  31.3825,\n",
       "                       52.1681,  76.2221,  33.6903,  59.1630,  35.9490,  39.6129,  37.6400,\n",
       "                       32.5703,  65.5450,  30.8750,  45.4082,  45.8819,  26.3946,  47.4205,\n",
       "                       49.1348,  43.3766,  27.2011,  75.8063,  63.7155,  46.3493,   0.3979,\n",
       "                       26.5054,  45.8701,  69.3298,  56.8755,  59.8682,  42.5232,  41.1253,\n",
       "                       43.6935,  53.3741,  32.5585,  35.8902,  43.9328,  45.5414,  31.5621,\n",
       "                       48.7838,  47.2220,  29.6616,  15.5673,  22.2395,  28.9994,  24.2479,\n",
       "                      102.9704,  39.9512,  32.3244,   0.2558,  24.3601,   5.2302,  29.5106,\n",
       "                       41.3319,  75.3155,  37.3672,  22.4993,  59.5364,  46.9117,  39.3268,\n",
       "                       40.9311,  52.5730,  72.9468,  33.1480,  19.0017,  71.2979,  35.3832,\n",
       "                       37.9487,  45.4771,  41.7069,  36.8463,  41.5128,  85.9343,  30.5077,\n",
       "                       42.6010,  37.2925,  42.0592,  56.6934,  15.7602,  47.6612,  30.0385,\n",
       "                       47.0208,  33.2221,  44.7548,  24.5391,  45.9706,  31.9674,  36.1938,\n",
       "                       60.4913,  29.1829,  31.4370,  53.4403,  28.3113,  34.7869,  70.9355,\n",
       "                       68.1365,  40.4803,  36.3636,  47.1711,  22.1173,  38.4825,  39.3975,\n",
       "                       43.7432,  29.4210,  34.8596,  30.4687,  68.7060,  67.3378,  26.3805,\n",
       "                       41.5847,  35.6842,  35.0291,  37.1290,  36.2059,  46.2787,  39.5105,\n",
       "                       37.2341,  50.8404,  27.8260,  38.5722,  46.0524,  38.2611,  10.2442,\n",
       "                       46.6448,  30.8053,   0.3152,  29.1311,  45.0049,  35.8925,  31.2280,\n",
       "                       37.7955,  27.8912,  45.8276,  33.1744,  29.8663,  32.7236,  57.9544,\n",
       "                       47.7023,  37.2118,  48.3244,  38.3405], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.conv1.weight',\n",
       "              tensor([[[[-2.8117e-01, -1.9448e-01, -3.2072e-01],\n",
       "                        [ 1.6667e-01,  7.5469e-03, -1.2761e-01],\n",
       "                        [ 1.5804e-01,  1.4452e-01,  5.4735e-03]],\n",
       "              \n",
       "                       [[ 5.7425e-03, -1.6190e-02, -4.9775e-01],\n",
       "                        [ 6.9577e-02,  3.7016e-02, -2.2179e-01],\n",
       "                        [-2.1399e-01, -1.8292e-01, -2.7259e-01]],\n",
       "              \n",
       "                       [[-3.2275e-02,  6.3697e-02,  3.6232e-02],\n",
       "                        [-1.0834e-02,  2.3389e-01, -1.6246e-02],\n",
       "                        [ 1.3494e-01,  1.3342e-01, -1.4910e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0493e-01,  6.6150e-03,  9.4810e-02],\n",
       "                        [ 7.5323e-02, -8.4515e-02, -2.6031e-01],\n",
       "                        [-4.4923e-02,  1.3767e-01, -1.3903e-02]],\n",
       "              \n",
       "                       [[ 5.8768e-02,  3.0249e-03,  1.2129e-01],\n",
       "                        [-1.4058e-02, -1.4894e-02,  1.1285e-01],\n",
       "                        [ 7.8302e-02, -5.2702e-03,  1.2461e-01]],\n",
       "              \n",
       "                       [[-2.8437e-02, -1.5080e-01, -1.7280e-02],\n",
       "                        [ 2.3192e-01, -1.1718e-02, -4.4942e-02],\n",
       "                        [ 6.1271e-01,  2.4129e-01,  1.4843e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8397e-01,  1.0231e-01, -3.6553e-04],\n",
       "                        [ 3.4619e-01,  2.6139e-01,  2.4499e-01],\n",
       "                        [ 3.5390e-01,  2.8168e-01,  3.8342e-01]],\n",
       "              \n",
       "                       [[ 8.4976e-02,  2.6384e-01,  9.5468e-02],\n",
       "                        [-2.7714e-02, -2.2332e-02, -4.8102e-02],\n",
       "                        [-1.7257e-01,  6.8492e-02,  1.0205e-01]],\n",
       "              \n",
       "                       [[-2.5342e-02, -1.5528e-02, -6.1688e-02],\n",
       "                        [-2.7608e-02, -2.5081e-02, -6.0266e-02],\n",
       "                        [ 6.7514e-04, -1.2479e-03, -4.8764e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2393e-01, -9.4306e-02, -1.9476e-01],\n",
       "                        [ 5.8398e-03, -7.9925e-02, -4.1517e-01],\n",
       "                        [-5.0327e-02, -1.9655e-01, -1.1735e-01]],\n",
       "              \n",
       "                       [[ 2.7297e-01, -4.6044e-02,  2.8592e-02],\n",
       "                        [ 7.4112e-01, -5.0212e-02, -1.0976e-01],\n",
       "                        [ 6.0514e-01, -6.1636e-02,  1.5829e-01]],\n",
       "              \n",
       "                       [[-8.9858e-02, -1.4299e-01, -8.8171e-02],\n",
       "                        [-2.7729e-02, -5.3546e-02,  1.1596e-03],\n",
       "                        [ 1.9970e-01,  5.9318e-02,  1.9625e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5145e-02, -7.8992e-02, -2.5136e-02],\n",
       "                        [-4.0007e-02, -3.4993e-02, -4.9632e-02],\n",
       "                        [ 2.2835e-02, -8.2773e-02, -1.4480e-01]],\n",
       "              \n",
       "                       [[ 8.8546e-02, -1.3631e-03,  7.4954e-05],\n",
       "                        [ 2.7300e-02, -2.4629e-02, -6.8863e-02],\n",
       "                        [ 9.9173e-02,  2.9239e-02, -1.0297e-02]],\n",
       "              \n",
       "                       [[ 1.6983e-02,  3.6542e-03, -6.4787e-02],\n",
       "                        [ 9.0322e-02,  2.4170e-02, -5.2050e-02],\n",
       "                        [ 6.6579e-02,  4.9823e-02, -2.5309e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.4695e-02,  4.1721e-02, -5.1636e-02],\n",
       "                        [-6.5091e-02, -4.3530e-02, -1.4238e-01],\n",
       "                        [-5.6960e-02, -3.9052e-02, -1.4414e-01]],\n",
       "              \n",
       "                       [[ 1.1531e-02,  5.8840e-02,  4.7447e-02],\n",
       "                        [ 6.2048e-02,  1.1637e-01,  5.8397e-02],\n",
       "                        [ 5.2231e-03, -4.5418e-03, -3.0628e-02]],\n",
       "              \n",
       "                       [[ 5.5873e-03,  3.9302e-02, -1.9303e-02],\n",
       "                        [-8.0556e-02,  4.2154e-03, -8.2461e-02],\n",
       "                        [-1.3790e-01, -1.9746e-02, -1.8784e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.5198e-01, -3.6075e-02, -1.4837e-01],\n",
       "                        [-2.3885e-01, -2.8460e-02, -1.0875e-01],\n",
       "                        [-1.4545e-01, -7.0426e-02, -6.8133e-02]],\n",
       "              \n",
       "                       [[-5.5952e-02, -4.0911e-02, -3.3310e-02],\n",
       "                        [-1.7451e-01, -8.7108e-02,  1.2693e-02],\n",
       "                        [-7.0759e-02, -4.8385e-02, -3.3718e-03]],\n",
       "              \n",
       "                       [[ 2.9875e-02,  6.5026e-03, -1.0522e-01],\n",
       "                        [ 9.7180e-02,  5.2470e-02, -5.8483e-02],\n",
       "                        [ 1.0137e-02,  2.4127e-02, -2.8789e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.7989e-02,  1.1075e-01,  9.5427e-02],\n",
       "                        [ 2.2058e-02,  4.7560e-02,  4.7533e-02],\n",
       "                        [-1.4979e-02, -4.1187e-02, -8.4268e-03]],\n",
       "              \n",
       "                       [[-5.8950e-03, -4.3256e-02, -1.0115e-01],\n",
       "                        [-4.2977e-02,  7.3435e-04, -1.7013e-02],\n",
       "                        [-1.0561e-01, -1.1956e-01, -4.2652e-02]],\n",
       "              \n",
       "                       [[-3.0934e-02, -1.9715e-02, -4.4373e-02],\n",
       "                        [ 1.9279e-01,  1.6256e-01,  1.3915e-01],\n",
       "                        [ 4.7260e-02,  1.3291e-01, -8.4166e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3602e-02,  2.0539e-02,  1.2633e-01],\n",
       "                        [-2.9732e-02,  6.9290e-02,  1.5418e-01],\n",
       "                        [ 7.1638e-02,  9.3394e-02,  1.5287e-01]],\n",
       "              \n",
       "                       [[-1.8831e-02,  1.6386e-02, -3.7939e-02],\n",
       "                        [-5.5418e-02,  3.2672e-03, -3.0469e-02],\n",
       "                        [ 1.9739e-03,  4.9307e-02, -2.8697e-02]],\n",
       "              \n",
       "                       [[ 1.1110e-02, -9.3922e-03, -1.0620e-01],\n",
       "                        [ 5.1250e-02,  4.8479e-02, -1.5916e-01],\n",
       "                        [ 2.6691e-02,  6.9313e-02, -1.7979e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.3847e-02, -1.4713e-02, -1.0052e-01],\n",
       "                        [ 1.9321e-02,  8.7875e-03, -5.4893e-02],\n",
       "                        [ 3.4401e-02,  1.7562e-02,  1.9163e-02]],\n",
       "              \n",
       "                       [[-1.8030e-04,  7.7708e-02,  1.5777e-01],\n",
       "                        [ 1.7430e-02,  5.9972e-02,  1.0575e-01],\n",
       "                        [-6.3385e-03,  6.1964e-02,  2.0596e-01]],\n",
       "              \n",
       "                       [[ 4.0382e-02,  1.6917e-01,  1.4179e-01],\n",
       "                        [ 6.5023e-02,  7.9723e-02,  1.8729e-01],\n",
       "                        [ 4.7586e-02,  1.4556e-01,  8.0061e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9561e-02,  1.6063e-02,  4.5139e-02],\n",
       "                        [-1.0781e-01, -1.5374e-02,  8.8728e-05],\n",
       "                        [-4.4376e-02,  5.6114e-03,  6.6437e-02]],\n",
       "              \n",
       "                       [[-2.1091e-02,  1.9502e-03, -5.8937e-02],\n",
       "                        [-4.3717e-02, -4.9178e-03, -1.5190e-01],\n",
       "                        [ 6.7578e-02,  5.1915e-02,  2.1604e-02]],\n",
       "              \n",
       "                       [[ 2.7038e-03, -4.4696e-02, -8.6027e-02],\n",
       "                        [ 8.1351e-02,  3.4863e-02, -1.7840e-01],\n",
       "                        [ 3.4614e-02,  3.6288e-02, -1.2641e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.3675e-03,  1.8449e-02, -4.5892e-02],\n",
       "                        [ 3.9285e-02,  1.1169e-02, -4.6597e-02],\n",
       "                        [ 1.1016e-02, -1.7599e-02, -4.0958e-02]],\n",
       "              \n",
       "                       [[ 1.7124e-02,  4.0852e-02,  7.1878e-02],\n",
       "                        [ 1.9256e-02,  2.0039e-02,  6.9166e-02],\n",
       "                        [ 8.0109e-02,  1.0178e-01,  1.2642e-01]],\n",
       "              \n",
       "                       [[-1.3671e-02,  2.6154e-02, -1.1227e-03],\n",
       "                        [-5.0951e-02,  1.0144e-02, -8.1067e-02],\n",
       "                        [-4.0022e-02, -1.2864e-02, -1.0272e-01]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.conv2.weight',\n",
       "              tensor([[[[-1.3141e-01, -1.7014e-01, -3.1536e-01],\n",
       "                        [ 1.4788e-04, -1.2086e-01, -3.0856e-01],\n",
       "                        [-5.1835e-02, -1.7605e-01, -3.0941e-01]],\n",
       "              \n",
       "                       [[-1.5246e-01, -1.2831e-01, -4.4812e-02],\n",
       "                        [-1.6314e-01, -1.2917e-01, -7.5320e-02],\n",
       "                        [-1.5122e-01, -1.1717e-01, -1.5710e-01]],\n",
       "              \n",
       "                       [[-5.3818e-02, -5.1342e-02, -1.5757e-01],\n",
       "                        [-7.5635e-02, -9.9171e-02, -2.1828e-01],\n",
       "                        [-1.0729e-03, -1.0431e-01, -2.2602e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4321e-02, -2.2552e-02, -8.8848e-02],\n",
       "                        [-2.5956e-02, -3.5327e-02, -1.3773e-01],\n",
       "                        [ 8.9133e-03,  3.0740e-03, -1.0050e-01]],\n",
       "              \n",
       "                       [[ 6.3828e-02,  1.4987e-05, -3.2330e-02],\n",
       "                        [ 1.6951e-03, -2.7668e-02, -1.7322e-01],\n",
       "                        [-6.9142e-03, -5.0586e-02, -1.9127e-01]],\n",
       "              \n",
       "                       [[-3.0931e-02, -6.4165e-02, -1.4262e-01],\n",
       "                        [-5.3583e-02, -1.3207e-01, -2.6642e-01],\n",
       "                        [-4.2838e-02, -6.4026e-02, -2.8391e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.9623e-02, -6.3867e-02,  2.5452e-02],\n",
       "                        [ 1.1098e-01, -3.8810e-02,  1.3309e-01],\n",
       "                        [ 1.2145e-01, -2.1395e-02,  1.1927e-01]],\n",
       "              \n",
       "                       [[ 2.8668e-01,  1.7305e-02,  8.8408e-02],\n",
       "                        [ 2.5384e-01, -1.9117e-01, -2.0238e-01],\n",
       "                        [ 2.4004e-01, -2.0833e-01, -1.6091e-01]],\n",
       "              \n",
       "                       [[-2.6671e-02, -1.1001e-01,  3.0393e-02],\n",
       "                        [ 4.0007e-04, -1.1037e-01,  4.0861e-03],\n",
       "                        [-1.8974e-02, -1.4899e-01,  2.3437e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.5335e-02, -6.9298e-02, -4.2384e-03],\n",
       "                        [-3.2748e-02, -7.9837e-02, -3.2012e-02],\n",
       "                        [-9.6534e-02, -1.6497e-01, -8.8456e-02]],\n",
       "              \n",
       "                       [[-1.4191e-02, -5.7730e-02,  7.7663e-02],\n",
       "                        [-1.6944e-02, -1.2329e-01,  6.6457e-02],\n",
       "                        [-3.9793e-02, -5.5077e-02,  1.8633e-02]],\n",
       "              \n",
       "                       [[-4.3596e-02, -1.3971e-01,  1.0534e-02],\n",
       "                        [-4.4777e-02, -1.0370e-01,  2.5256e-02],\n",
       "                        [-2.9126e-02, -1.2420e-01,  1.6884e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2084e-01, -6.4760e-02,  1.3030e-01],\n",
       "                        [-1.3044e-01, -2.5075e-02,  1.6151e-02],\n",
       "                        [-8.7644e-02,  1.5531e-03,  1.7084e-02]],\n",
       "              \n",
       "                       [[ 1.0630e-01,  6.8825e-02,  1.0841e-01],\n",
       "                        [ 6.3294e-02,  5.6313e-02,  9.1738e-02],\n",
       "                        [-8.5978e-02,  4.0142e-03,  4.2442e-02]],\n",
       "              \n",
       "                       [[-7.9506e-02, -5.3952e-01, -4.3850e-02],\n",
       "                        [-1.0070e-01, -6.0278e-01, -6.0825e-02],\n",
       "                        [-4.1294e-02, -4.5038e-01, -5.5793e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.0779e-02, -9.0226e-03,  3.3375e-03],\n",
       "                        [ 8.1960e-04, -7.6463e-02, -3.6247e-02],\n",
       "                        [ 1.9942e-02, -4.3963e-02, -3.7640e-02]],\n",
       "              \n",
       "                       [[-4.5117e-02, -9.3657e-02, -1.9836e-03],\n",
       "                        [-5.8529e-02, -8.0018e-02, -3.1515e-02],\n",
       "                        [-1.2475e-02, -7.1371e-02, -4.3010e-03]],\n",
       "              \n",
       "                       [[-5.3049e-02, -1.5731e-01, -2.5275e-02],\n",
       "                        [-5.1301e-02, -2.0356e-01, -2.3456e-02],\n",
       "                        [-2.6011e-02, -1.6314e-01, -5.0286e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3632e-03, -1.2925e-02,  6.8488e-04],\n",
       "                        [-9.8775e-02, -8.1714e-02, -3.4547e-02],\n",
       "                        [-1.1710e-02, -7.6958e-02, -6.0914e-02]],\n",
       "              \n",
       "                       [[-1.0509e-01, -1.0036e-01, -3.5899e-02],\n",
       "                        [-1.3978e-01, -1.4804e-01, -3.0534e-02],\n",
       "                        [-1.9116e-01, -1.2482e-01, -7.7175e-02]],\n",
       "              \n",
       "                       [[ 1.0296e-02, -6.9565e-02,  7.9738e-02],\n",
       "                        [ 2.8699e-02, -1.6072e-01,  6.3567e-02],\n",
       "                        [ 1.6107e-02, -1.5727e-01,  4.8203e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.1035e-02, -1.2945e-01,  1.2868e-02],\n",
       "                        [-1.6226e-01, -2.2084e-01, -4.9709e-03],\n",
       "                        [-2.6686e-02, -8.8472e-02,  4.4570e-02]],\n",
       "              \n",
       "                       [[-5.2616e-03, -5.7111e-02,  5.4005e-02],\n",
       "                        [-2.7419e-02, -9.5018e-02,  4.9039e-02],\n",
       "                        [-2.7858e-04, -2.4506e-02,  3.1993e-02]],\n",
       "              \n",
       "                       [[-3.8276e-02, -7.3607e-02, -9.0714e-03],\n",
       "                        [-5.5761e-02, -1.2196e-01,  4.7025e-03],\n",
       "                        [-1.7847e-02, -1.2619e-01,  4.5440e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.4819e-02, -1.4828e-01, -1.0668e-01],\n",
       "                        [ 4.5886e-02,  2.8900e-02,  4.0922e-02],\n",
       "                        [ 1.8913e-03,  2.3505e-02,  1.6824e-01]],\n",
       "              \n",
       "                       [[ 1.5831e-01,  1.1025e-01,  3.2725e-01],\n",
       "                        [ 3.3227e-01,  2.0414e-01,  3.9934e-01],\n",
       "                        [ 3.2118e-01,  2.7469e-01,  3.1816e-01]],\n",
       "              \n",
       "                       [[ 4.3839e-03, -1.8127e-01,  3.0586e-02],\n",
       "                        [-5.1334e-02, -2.2614e-01,  6.0986e-02],\n",
       "                        [-9.7718e-03, -2.2800e-01,  7.6102e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.9273e-02, -9.4798e-02, -1.8765e-02],\n",
       "                        [ 2.7452e-02, -1.2884e-01, -6.5547e-03],\n",
       "                        [-1.1060e-01, -2.2181e-01, -8.4998e-02]],\n",
       "              \n",
       "                       [[-1.2539e-02, -9.0758e-02,  3.2262e-02],\n",
       "                        [-2.7983e-02, -1.2655e-01,  1.7510e-03],\n",
       "                        [-7.8804e-03, -1.0630e-01,  3.6500e-02]],\n",
       "              \n",
       "                       [[-4.5780e-02, -1.7082e-01,  3.4723e-02],\n",
       "                        [-4.5897e-02, -2.2459e-01, -1.2138e-02],\n",
       "                        [-5.9276e-02, -1.9904e-01, -7.6359e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.4527e-02,  2.3626e-03,  3.5323e-02],\n",
       "                        [ 5.2964e-02,  8.6002e-03,  9.5076e-02],\n",
       "                        [ 2.5534e-01,  2.2776e-01,  6.3691e-01]],\n",
       "              \n",
       "                       [[-3.1473e-01, -1.5584e-01, -2.4066e-01],\n",
       "                        [-5.6614e-01, -2.5919e-01, -4.8721e-01],\n",
       "                        [-4.7625e-01, -4.3592e-01, -5.6699e-01]],\n",
       "              \n",
       "                       [[-8.0138e-02, -2.7227e-01, -3.8287e-03],\n",
       "                        [-8.9857e-02, -3.3922e-01, -7.3446e-03],\n",
       "                        [-8.2277e-02, -2.2914e-01, -2.5482e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.4436e-02, -1.6535e-01, -6.6169e-02],\n",
       "                        [-1.0076e-01, -1.9541e-01, -2.1543e-02],\n",
       "                        [-4.8573e-02, -2.3831e-01, -7.6474e-02]],\n",
       "              \n",
       "                       [[-6.5030e-02, -1.0340e-01, -1.7654e-02],\n",
       "                        [-4.2388e-02, -9.1843e-02, -4.4946e-02],\n",
       "                        [-5.0771e-02, -9.4325e-02, -3.5689e-02]],\n",
       "              \n",
       "                       [[-1.0607e-01, -1.3761e-01, -1.6891e-01],\n",
       "                        [-7.1688e-02, -1.0667e-01, -9.9844e-02],\n",
       "                        [-6.6565e-02, -1.0376e-01, -2.3241e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.weight',\n",
       "              tensor([1.0171, 0.5798, 0.5005, 0.9467, 0.4131, 0.9769, 0.4462, 1.0130, 0.9361,\n",
       "                      1.1435, 1.0755, 0.8172, 1.2160, 1.1708, 0.8326, 1.0605, 1.3565, 1.1408,\n",
       "                      0.9933, 1.1301, 1.0148, 1.1272, 0.9770, 0.5058, 0.8135, 0.6770, 1.1596,\n",
       "                      1.0459, 1.0975, 1.0943, 1.0097, 0.8133, 1.1153, 0.8899, 1.0428, 1.2536,\n",
       "                      0.9832, 0.6203, 0.9139, 0.8731, 0.6918, 1.1260, 0.2733, 1.0130, 1.0926,\n",
       "                      1.0720, 1.1631, 1.1839, 0.5973, 1.1405, 1.1763, 0.9800, 1.0225, 1.0436,\n",
       "                      0.8502, 1.1530, 0.9835, 1.3239, 0.6362, 0.9547, 0.8648, 0.7036, 0.9891,\n",
       "                      0.8956, 0.6684, 1.0972, 0.9076, 0.6384, 0.8603, 1.0418, 0.8226, 0.9889,\n",
       "                      0.4692, 0.4991, 0.8975, 0.8536, 1.2099, 0.9635, 1.1211, 1.0741, 1.1748,\n",
       "                      1.0328, 0.9639, 0.8464, 0.9222, 0.8646, 0.9812, 1.0259, 0.9026, 1.0985,\n",
       "                      1.3200, 1.3520, 0.8091, 0.8493, 1.0194, 0.5287, 0.9658, 0.9977, 0.9788,\n",
       "                      1.3655, 0.4898, 0.7785, 0.9938, 0.4714, 0.3356, 0.9735, 0.8762, 0.8690,\n",
       "                      1.3053, 0.7439, 0.7643, 0.6878, 1.0019, 1.0641, 1.0696, 1.1539, 1.1049,\n",
       "                      0.8718, 1.3012, 0.9538, 0.9531, 0.5643, 1.0746, 0.9723, 0.8656, 1.3475,\n",
       "                      0.9380, 0.8953, 1.3727, 0.4535, 1.1457, 0.6542, 1.0409, 1.0981, 0.9023,\n",
       "                      1.1144, 1.0815, 1.2134, 0.8978, 0.9925, 0.8624, 1.0421, 1.3380, 1.1504,\n",
       "                      0.9870, 0.4670, 1.0330, 1.1302, 1.1419, 1.2744, 1.2785, 1.2513, 1.0941,\n",
       "                      1.1802, 1.2290, 1.3752, 0.9396, 0.9662, 0.9707, 1.0778, 0.3860, 0.9183,\n",
       "                      1.1586, 0.8619, 0.6188, 1.1147, 1.3675, 1.0019, 1.1476, 1.0775, 1.0792,\n",
       "                      1.1930, 0.9706, 0.9071, 0.9174, 0.9868, 0.7037, 0.7321, 0.8768, 1.0496,\n",
       "                      0.9915, 1.0660, 0.8966, 0.9964, 0.8852, 1.2159, 1.1580, 0.7111, 0.4730,\n",
       "                      1.0353, 1.0192, 0.8928, 1.2706, 1.4263, 0.9980, 0.3532, 0.4918, 0.9829,\n",
       "                      0.7474, 1.0839, 0.5446, 1.0956, 1.0380, 1.0943, 1.0517, 0.7094, 1.0557,\n",
       "                      0.6625, 1.1248, 1.0023, 1.5281, 1.3572, 1.0759, 0.7746, 1.2011, 1.1546,\n",
       "                      0.5964, 0.9852, 0.8495, 0.9046, 0.9232, 1.2807, 0.5028, 0.9053, 1.1093,\n",
       "                      1.2315, 1.0267, 1.0194, 1.2623, 0.9689, 1.0482, 1.0786, 0.8586, 0.4864,\n",
       "                      1.2161, 1.0685, 1.0953, 0.9853, 0.8778, 1.0397, 1.2730, 0.9377, 1.2230,\n",
       "                      0.9753, 1.0981, 0.5209, 0.9376, 0.6086, 0.4151, 0.7702, 0.9797, 1.2388,\n",
       "                      1.0349, 0.9509, 0.8632, 1.2876, 1.6126, 1.1258, 0.4149, 1.0089, 1.0519,\n",
       "                      0.8221, 1.2245, 1.0256, 1.0461, 0.9651, 0.8645, 1.0192, 1.0774, 1.0158,\n",
       "                      1.1035, 0.9729, 1.2657, 1.1162, 1.0492, 0.8497, 1.1300, 1.0705, 0.9149,\n",
       "                      0.5904, 0.9442, 1.1462, 0.9009, 1.3760, 0.4095, 1.0837, 1.2117, 0.5813,\n",
       "                      1.1220, 1.3137, 0.5588, 1.1104, 0.7647, 0.8270, 1.7138, 1.0442, 0.9528,\n",
       "                      1.1511, 0.8160, 1.0942, 1.2062, 1.0723, 0.9839, 1.4398, 1.0917, 1.1048,\n",
       "                      1.0294, 1.0739, 1.1939, 1.0529, 1.0129, 1.0052, 1.4338, 1.0208, 0.9004,\n",
       "                      1.1145, 0.8237, 1.2433, 0.9026, 1.0068, 1.1364, 0.9539, 0.7693, 1.0401,\n",
       "                      1.3652, 0.4287, 1.0163, 0.9942, 1.1042, 0.4577, 0.9942, 0.9551, 0.9146,\n",
       "                      1.0011, 1.1516, 0.9862, 0.7260, 1.1630, 1.0532, 0.9281, 0.9433, 0.6011,\n",
       "                      0.6257, 1.1354, 0.9504, 0.9805, 0.9760, 0.9792, 0.4477, 0.7953, 0.9629,\n",
       "                      0.8023, 1.1022, 1.1797, 0.8836, 1.0323, 0.5699, 1.0605, 1.1273, 1.0621,\n",
       "                      0.7290, 0.9571, 0.8671, 0.6478, 0.3853, 0.9439, 0.8821, 0.8617, 0.4659,\n",
       "                      1.0389, 0.3590, 1.1582, 0.9726, 1.0988, 1.0964, 0.8692, 1.2900, 0.8554,\n",
       "                      1.1174, 0.9015, 0.9937, 1.2691, 0.9923, 0.9630, 1.0504, 0.7922, 0.5388,\n",
       "                      1.0412, 1.0914, 0.9493, 1.1033, 0.9571, 0.9168, 0.9361, 1.1429, 0.4560,\n",
       "                      1.0962, 1.0570, 0.6944, 1.0913, 1.0084, 0.9310, 0.8042, 0.9676, 1.1645,\n",
       "                      1.0108, 0.9704, 0.8509, 0.8505, 0.9832, 0.9930, 1.0751, 0.9806, 1.0307,\n",
       "                      1.1843, 1.0450, 0.8979, 0.8262, 0.7724, 0.8858, 0.9827, 1.0757, 1.1863,\n",
       "                      0.9124, 0.8604, 1.0140, 1.1726, 0.8133, 0.9450, 0.7757, 0.9359, 0.8902,\n",
       "                      0.4347, 0.8054, 0.9967, 0.8918, 1.1201, 0.8330, 1.3714, 0.6347, 0.6996,\n",
       "                      0.9285, 0.9511, 1.2236, 1.0164, 0.8717, 1.0107, 1.2076, 0.9399, 1.1091,\n",
       "                      0.9706, 1.1365, 1.0346, 1.1798, 1.2603, 1.0090, 0.9313, 0.8644, 1.0968,\n",
       "                      0.7437, 1.1048, 1.1171, 0.9892, 0.9939, 1.4142, 1.0721, 1.1209, 1.0621,\n",
       "                      1.1425, 0.8798, 1.1274, 0.9831, 1.0430, 0.9428, 0.3956, 0.9816, 1.0278,\n",
       "                      0.9393, 0.9891, 1.3775, 1.0050, 0.8539, 0.9556, 1.1961, 1.1283, 1.0901,\n",
       "                      0.9547, 1.0527, 1.6421, 1.0322, 1.0283, 0.7542, 0.9550, 1.1278, 0.9013,\n",
       "                      1.0847, 1.1320, 0.8843, 1.1033, 1.0025, 1.0018, 1.0766, 0.2731, 1.0976,\n",
       "                      1.3175, 1.2517, 1.0063, 1.2144, 1.1150, 0.8921, 0.4834, 0.4870],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.bias',\n",
       "              tensor([-0.9268, -0.6266, -0.5309, -0.6357, -0.5046, -1.1536, -0.5173, -1.4939,\n",
       "                      -0.7832, -1.5075, -0.6342, -0.5730, -1.1893, -1.1652, -0.7942, -1.0887,\n",
       "                      -1.3104, -1.3070, -0.8438, -1.5253, -0.9678, -1.0071, -0.9260, -0.5962,\n",
       "                      -1.2304, -0.2258, -0.6201, -0.8741, -0.9973, -0.2882, -1.0181, -0.0473,\n",
       "                      -1.2342, -0.8188, -0.9273, -1.0032, -1.1131, -0.5810, -0.9244, -0.8191,\n",
       "                      -0.4738, -0.7664, -0.1053, -1.1785, -1.2238, -1.2519, -1.0774, -1.7462,\n",
       "                      -1.2521, -1.0098, -1.3732, -1.0013, -0.9384, -0.9089, -0.7262, -1.2270,\n",
       "                      -1.0483, -1.5191, -0.4390, -1.0361, -0.8670, -0.8597, -1.4813, -0.6777,\n",
       "                      -0.4823, -1.1131, -0.8683, -0.1681, -0.6160, -1.1000, -0.6691, -0.6610,\n",
       "                       0.1074, -0.4299, -0.8592, -0.8151, -1.7040, -1.0895, -0.9872, -1.5288,\n",
       "                      -1.1496, -0.6807, -0.8016, -0.7891, -0.9479, -0.6210, -1.0759, -1.1950,\n",
       "                      -0.9956, -1.2665, -1.5158, -1.7583, -0.7382, -0.5999, -0.9451, -0.5500,\n",
       "                      -1.0278, -0.6882, -1.0760, -1.4877, -0.7106, -0.9699, -1.1468, -0.5725,\n",
       "                      -0.2269, -1.4250, -0.7481, -0.9016, -1.3545, -0.4090, -0.5920, -0.7844,\n",
       "                      -1.2422, -1.0947, -1.3283, -1.2184, -1.1426, -0.8193, -1.3204, -0.8605,\n",
       "                      -0.7378, -0.5170, -1.3469, -1.0916, -0.9371, -1.4747, -1.0785, -1.3800,\n",
       "                      -1.3396, -0.4237, -1.3274, -0.8327, -0.8605, -1.2755, -0.9883, -1.0643,\n",
       "                      -1.1332, -1.2407, -1.0683, -0.9353, -0.8443, -1.0549, -1.1899, -1.0002,\n",
       "                      -1.4368, -0.4605, -0.8931, -1.3795, -1.1537, -1.2295, -1.5573, -1.3294,\n",
       "                      -1.2111, -1.4382, -1.0037, -1.4445, -0.7545, -1.1937, -1.0555, -0.8604,\n",
       "                      -0.3483, -0.8547, -1.4832, -0.9992, -0.6245, -1.1271, -1.8393, -0.8570,\n",
       "                      -1.1873, -0.9002, -1.1650, -1.4616, -1.0966, -1.0338, -0.8798, -1.0539,\n",
       "                      -0.5295, -0.5991, -0.5281, -1.1401, -1.3800, -1.1607, -1.0025, -0.7102,\n",
       "                      -0.9779, -1.1512, -1.1975, -0.7246, -0.4748, -0.9941, -0.7571, -0.8653,\n",
       "                      -1.4647, -1.8294, -0.6385, -0.2421, -0.4240, -0.7561, -0.7323, -1.0429,\n",
       "                      -0.5567, -0.7589, -0.8982, -1.1422, -1.3670, -0.8966, -0.7570, -0.8501,\n",
       "                      -1.4752, -1.3566, -1.5417, -1.3120, -1.4789, -0.8098, -1.1903, -1.1919,\n",
       "                      -0.5641, -1.0068, -0.6368, -1.1082, -0.6602, -1.2209, -0.5706, -0.8450,\n",
       "                      -1.4457, -1.1181, -0.5517, -1.0157, -1.0188, -1.3320, -1.1227, -0.8480,\n",
       "                      -0.9637, -0.3996, -1.1952, -1.4615, -1.0471, -0.8518, -1.3566, -1.1436,\n",
       "                      -1.2017, -0.7486, -1.5245, -0.9609, -1.2642, -0.4812, -1.1266, -0.8732,\n",
       "                      -0.4258, -0.7096, -0.8881, -1.1568, -1.1495, -1.0584, -0.5065, -2.0450,\n",
       "                      -1.8439, -1.0001, -0.4478, -1.3064, -1.2587, -0.7340, -0.7342, -0.9460,\n",
       "                      -1.0269, -0.9412, -0.7271, -0.9116, -0.7955, -1.3599, -1.3335, -1.3596,\n",
       "                      -2.0832, -1.4160, -0.9864, -0.7417, -0.7941, -1.4409, -0.8184, -0.5528,\n",
       "                      -0.7167, -1.1789, -0.8158, -1.4325, -0.2628, -1.1581, -1.9050, -0.4080,\n",
       "                      -1.2944, -1.1235, -0.6202, -1.1652, -0.9671, -1.1774, -1.8213, -0.8847,\n",
       "                      -0.6611, -1.5906, -0.7409, -1.0386, -1.0712, -1.1633, -1.0001, -1.3512,\n",
       "                      -0.9485, -1.2225, -1.0768, -1.1959, -1.0779, -1.0752, -1.1522, -0.9081,\n",
       "                      -1.0947, -0.8541, -0.9721, -1.3169, -0.8332, -1.1959, -0.8614, -1.2096,\n",
       "                      -1.2910, -1.3517, -0.7324, -0.7874, -1.2204, -0.3987, -1.2808, -1.0477,\n",
       "                      -1.0734, -0.4106, -0.8290, -0.8418, -1.1694, -1.0074, -1.2381, -1.2645,\n",
       "                      -0.4686, -0.9527, -0.7772, -0.9946, -0.5623, -0.7630, -0.8910, -1.0892,\n",
       "                      -0.8300, -0.9807, -0.9775, -1.3635, -0.4377, -0.6563, -1.3178, -0.7624,\n",
       "                      -1.1922, -1.3888, -1.3011, -0.8241, -0.6315, -1.0948, -1.0740, -1.1862,\n",
       "                      -1.2401, -0.8922, -0.8188, -0.4529, -0.3196, -0.9116, -0.5977, -0.7753,\n",
       "                      -0.3463, -0.9359, -0.2351, -1.1351, -0.8505, -1.2622, -0.8808, -0.8275,\n",
       "                      -1.4604, -0.6374, -0.9875, -0.5543, -0.9385, -1.4324, -1.0252, -0.7666,\n",
       "                      -1.3167, -0.6675, -0.3785, -0.6188, -1.1109, -0.7665, -0.6459, -1.3750,\n",
       "                      -0.9565, -0.8162, -1.1617, -0.2942, -1.1032, -0.9313, -0.6704, -0.9382,\n",
       "                      -1.4996, -0.6677, -0.9241, -0.9116, -1.5874, -1.2366, -0.9990, -0.7313,\n",
       "                      -0.6550, -0.9268, -0.9094, -1.2075, -0.7507, -1.5805, -1.3963, -1.1001,\n",
       "                      -0.8197, -0.6291, -0.5572, -0.6652, -1.0816, -1.0449, -1.2613, -0.6382,\n",
       "                      -0.4380, -1.4386, -1.2137, -0.5551, -1.0229, -0.9086, -0.8036, -0.8823,\n",
       "                      -0.4433, -0.5666, -1.3386, -0.8249, -1.0241, -0.9359, -1.3669, -0.1792,\n",
       "                      -0.4910, -0.6613, -0.6006, -1.2904, -1.2362, -0.9800, -0.7748, -0.8731,\n",
       "                      -0.9160, -1.3455, -0.6145, -1.3676, -0.9559, -0.8511, -1.0169, -1.0877,\n",
       "                      -0.6715, -0.8468, -0.9053, -0.6382, -0.7508, -1.1323, -1.2330, -1.0002,\n",
       "                      -1.0657, -1.0172, -1.3319, -1.0393, -1.2256, -0.7244, -1.3001, -1.1020,\n",
       "                      -1.2895, -0.6108, -0.4768, -1.4196, -1.3897, -0.7835, -1.0923, -1.2570,\n",
       "                      -0.9177, -0.8924, -0.9494, -0.8150, -1.1034, -1.1010, -0.7710, -1.2923,\n",
       "                      -1.7607, -0.8246, -1.0299, -0.7357, -0.8449, -1.3700, -0.9031, -1.1970,\n",
       "                      -1.0119, -0.7387, -1.1051, -1.0061, -1.1059, -0.8715, -0.2503, -0.7411,\n",
       "                      -1.5400, -1.4532, -0.8578, -1.6902, -1.4873, -0.8968, -0.5279, -0.5539],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.running_mean',\n",
       "              tensor([-10.2793,  -5.1050,   0.5770, -12.2499,   1.1114,  -5.0149,   2.6296,\n",
       "                       -5.7523,  -4.7333,  -9.0336,  -4.5115,  -7.6067,  -9.8591,  -4.0122,\n",
       "                      -10.7823,  -5.9085,  -7.6807,  -4.9074,  -5.2075,  -5.1058,  -6.3960,\n",
       "                       -8.2817,  -5.2456,   0.0449,  -2.5947,  -5.1229,   3.0265,  -9.0198,\n",
       "                       -7.9768,  -2.0162, -16.2726,  -3.1200,  -5.7590,  -3.1134,  -8.1856,\n",
       "                       -5.2627,  -6.8978,   1.6054,  -2.5897,  -2.4606,  -6.4149,  -0.0205,\n",
       "                        1.8035, -11.9931,  -7.4352,  -4.6106,  -6.3099,  -1.2977,  -1.6846,\n",
       "                       -9.3642,  -5.2194,  -6.9079,  -4.9136,  -2.1780,  -5.5695,  -6.6912,\n",
       "                       -4.2017,  -7.7757,  -3.1779,  -4.0478,  -8.0861,  -3.7367,  -5.8779,\n",
       "                       -3.1723,  -1.7294,  -6.1344,  -4.8933,   0.0762,  -8.5907,  -5.8002,\n",
       "                       -9.0861,  -1.2178,  -0.4124,   2.0606,  -2.1005,  -7.2921,  -5.3342,\n",
       "                       -3.6185,  -6.3721,  -6.5325,  -6.0726,  -7.7600,  -3.4875,  -4.4815,\n",
       "                       -6.0967,  -1.5140,  -6.1712,  -3.2782,  -4.4434,  -9.1119,  -5.0394,\n",
       "                       -4.1701,  -8.7567,  -8.5084,  -7.7246,  -1.0465,  -1.7473,  -5.7842,\n",
       "                       -1.8228,  -6.2296,   2.0070,  -3.7328,  -7.6452,   0.0470,   1.9210,\n",
       "                       -8.1234,  -7.0801,  -3.7098, -13.6400,  -1.5657,  -6.4982,  -0.9597,\n",
       "                       -7.3450,  -5.1298, -13.1911,  -8.3593,  -6.5813,  -9.8701,  -8.2120,\n",
       "                      -10.2244,  -1.7166,   0.3624,  -6.1199,  -5.2311,  -2.4564,  -6.3264,\n",
       "                       -7.9257,  -7.9577,  -3.4013,   1.5921,  -5.8668,  -0.8193,  -2.5089,\n",
       "                       -5.0900,  -8.0176,  -6.4210,  -1.1759,  -6.7921,  -0.3481,  -9.2427,\n",
       "                       -9.9008,  -8.3225,  -9.3032,  -8.9493,  -5.2085,   1.5023,  -5.2136,\n",
       "                       -6.0105,  -6.2447,  -6.5079,  -4.2751,  -9.7660,  -6.1132,  -1.8229,\n",
       "                       -5.8968,  -8.7571,  -9.2568,  -0.3043,  -5.9986,  -0.7422,   2.8028,\n",
       "                       -3.2696,  -5.3210,  -3.5418,  -1.2045,  -5.7917, -10.0467, -10.2704,\n",
       "                       -6.2779,  -7.2943,  -5.7070,  -6.7291, -11.9753,  -4.7874, -12.9624,\n",
       "                       -8.8783,  -2.5503,  -0.9713, -10.5295, -12.2764,  -5.5694,  -6.0106,\n",
       "                       -4.0255,  -7.1279,  -8.2322,  -3.4059,  -1.6601,  -5.5689,   0.5852,\n",
       "                       -3.9591,  -4.6329,  -3.0914,  -7.8443,  -6.0076,  -6.4779,   1.6296,\n",
       "                        0.1636,  -6.4931,  -1.9335,  -6.2480,   0.8268,  -5.4800,  -9.3580,\n",
       "                       -3.8273,  -6.9180,  -3.8009,  -5.3921,  -1.0332,  -7.8456,  -4.3468,\n",
       "                       -3.9134,  -2.0628,  -0.8970,  -3.7377,  -5.2491,  -3.9716,   1.7836,\n",
       "                       -4.8697,  -9.8217, -12.0063,  -5.8720,  -6.0146,   1.1641,  -4.2303,\n",
       "                       -6.2902,  -7.7341,  -6.0825,  -7.5879,  -5.5148,  -6.5780,   0.0881,\n",
       "                       -7.2020,  -5.0114,  -4.3173,  -2.5251,  -4.9577,  -6.3364,  -7.3803,\n",
       "                       -2.9454,  -6.4389,  -5.0101,  -6.6061,  -6.5512,  -5.1629,  -4.6097,\n",
       "                       -1.5746,  -2.8374,  -0.5122,   0.7712,  -4.4144,  -5.8370,  -3.9464,\n",
       "                      -12.3806,  -4.7935,  -3.9609,  -3.2923,  -7.0694,  -6.3033,   2.0305,\n",
       "                       -6.3570,  -5.0539,  -5.1913,  -3.5339,  -2.1619,  -6.7763,  -6.3931,\n",
       "                      -11.1211,  -9.3622, -11.0594,  -5.0233,  -4.9589,  -6.3624,  -7.0158,\n",
       "                      -12.1250, -11.4559,  -5.3347,  -3.3384,  -1.9951,  -4.3446,  -1.8381,\n",
       "                       -6.8602,  -6.8828,  -1.9819,  -3.8376,   0.9528,  -7.9761,  -8.2387,\n",
       "                       -0.2785,  -7.7605,  -5.6871,   0.1998, -10.1335,  -5.3290,   1.1781,\n",
       "                      -10.0592,  -6.3349,  -0.9074,  -2.5916,  -8.9815,  -5.5814,  -7.6576,\n",
       "                       -7.7590,  -5.6901,  -5.7995,  -6.4633,  -7.0798,  -9.2863,  -3.3237,\n",
       "                       -0.7928,  -8.3835,  -3.3632,  -5.5329,  -5.8154,  -7.5749,  -5.4600,\n",
       "                       -3.2018,  -3.7958,  -1.2822,  -7.5610,  -8.0757,  -6.4004,   0.0784,\n",
       "                      -12.9392,  -7.0685,  -6.5679,   0.6536,  -9.9785,  -4.6147,  -8.3518,\n",
       "                        0.6975,  -7.0733,  -6.0345,  -6.5054, -11.3228, -10.2335,  -3.2918,\n",
       "                       -3.5762,   1.4748,  -5.7224,  -8.3526,  -4.4862,   0.8099,   0.4632,\n",
       "                       -3.3076,  -4.9378,  -7.3780,  -6.9124,  -4.9742,   0.9185,  -8.1968,\n",
       "                       -4.2707,  -8.3432,  -7.4695,  -2.3438,  -6.6042,  -7.4780,   1.3620,\n",
       "                       -7.4275,  -4.6859,  -9.7884,   0.5683,  -6.4116,  -4.6786,  -6.0446,\n",
       "                        2.2747,  -4.5395,  -7.1189,  -1.0410,  -0.2631,  -7.2017,   2.1779,\n",
       "                      -10.9636,  -6.8035,  -6.5435,  -6.0287,  -0.9497, -10.6271,  -5.2722,\n",
       "                       -6.2655,  -3.8363,  -7.2287,  -2.5849,  -2.7195,  -2.5114,  -2.4181,\n",
       "                       -3.6162,   1.2660,  -4.8813,  -7.8794,  -2.1826,  -5.0133,  -5.9276,\n",
       "                       -1.0022,  -5.2859,  -6.3448,  -0.0995,  -7.2606,  -4.8345,  -3.4389,\n",
       "                       -7.7076,  -6.0039,  -7.0864,  -1.5581, -11.9516,  -6.6842,  -4.7997,\n",
       "                       -7.9832,  -1.8929,  -3.8697,  -7.2771, -11.0676,  -8.2769,  -0.1662,\n",
       "                       -5.9941,  -5.0723, -12.7834,  -7.3765,  -8.0371,  -8.8059,  -7.5946,\n",
       "                       -6.9716,  -8.1132, -10.4097,   0.7244,  -8.5828,  -6.2128,  -9.7671,\n",
       "                       -6.6599,  -5.2965,  -0.7537,  -3.7555,  -4.3002,   2.1005,  -6.0888,\n",
       "                       -8.4214,  -6.9165,  -5.9569,  -4.5327,  -6.1004,  -2.8920,  -6.0032,\n",
       "                       -2.2724,  -3.9450,  -5.6058, -10.2554,  -9.5931,  -6.6777,  -7.4380,\n",
       "                       -8.7531, -11.3134,  -4.8196,  -5.7835,  -6.5160,   0.3841,  -8.8216,\n",
       "                       -3.3551,  -4.4611,  -9.0977,  -4.4484,   1.4702,  -2.2733,  -4.6829,\n",
       "                       -3.5563,  -7.8723,  -5.1950,  -4.8242,  -7.0583,  -8.7942,  -5.7782,\n",
       "                       -4.5458,  -8.1177,  -7.6210,  -3.1566,  -7.1672,   0.6632,  -4.1542,\n",
       "                       -4.2291,  -6.6208,  -7.1946,  -5.2934,  -9.6849,  -5.4624,  -3.5769,\n",
       "                       -3.4177,  -5.3127,  -6.7569,  -4.6155,  -6.7661,  -6.3095,  -3.6367,\n",
       "                       -4.8903,   2.3502,  -0.6025,  -9.1916,   2.1711,  -7.7282,  -5.9922,\n",
       "                       -8.2701,  -4.6847,  -5.7975,  -5.2849,  -7.1303,   1.8561,  -6.2341,\n",
       "                       -4.0587,  -4.0731,  -8.7921,  -6.9323,  -5.1966,  -2.1089,   1.8824,\n",
       "                        1.2020], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.running_var',\n",
       "              tensor([25.9477, 16.5733,  4.9564, 28.6898,  7.1413, 17.8488,  3.8144, 14.5970,\n",
       "                      17.3948, 38.2940, 13.0234, 29.2071, 31.1680,  8.8923, 30.8701, 12.7928,\n",
       "                      19.2679, 14.7399, 21.9500, 15.5500, 10.6833, 21.7241, 11.5524,  4.0457,\n",
       "                       7.9603, 16.8295, 15.5251, 32.9095, 23.1123, 14.0936, 37.5358, 12.4848,\n",
       "                      21.5845, 15.5798, 19.2634, 15.0854, 18.4694,  5.2985,  7.7973, 27.5669,\n",
       "                      15.9851,  9.6565,  3.9385, 20.3290, 28.3304, 12.5070, 14.7064, 26.1982,\n",
       "                       3.9066, 18.9662, 13.9175, 19.6702, 24.5714, 13.0022, 53.1503, 14.5090,\n",
       "                      14.9587, 12.9142,  4.3092, 14.5339, 24.8722, 10.7357, 28.5289,  8.0343,\n",
       "                       8.1199, 39.9542, 19.8778, 10.3461, 30.5962, 19.5617, 20.5699,  7.4316,\n",
       "                       7.8675,  7.7964,  7.1674, 33.1144, 13.7808, 20.8220, 15.3775, 13.9209,\n",
       "                      11.9177, 22.2030,  7.4819, 18.6825, 16.9285,  9.8723, 10.3241, 28.9917,\n",
       "                      16.9282, 27.4749, 34.3637,  8.9852, 22.4466, 38.7172, 34.9716, 11.5602,\n",
       "                      13.5902, 13.6143,  9.9763, 12.4859,  4.4295,  8.3284, 37.5300,  4.3734,\n",
       "                       3.0895, 41.6860, 34.0726, 10.5124, 36.2825,  8.2954, 29.2960,  6.3537,\n",
       "                      20.5536,  9.4501, 36.9986, 20.8720, 12.8368, 37.7083, 24.7643, 23.0841,\n",
       "                      12.6122,  4.0673, 14.8067, 38.4710, 14.2712, 13.7243, 10.6322, 19.8489,\n",
       "                      12.2712,  4.8436, 19.0219,  6.3717,  7.0603, 12.1327, 20.4187, 20.3443,\n",
       "                      13.9391, 32.7323, 13.4792, 28.6418, 26.6187, 31.5201, 23.0340, 22.5258,\n",
       "                      15.2911,  4.4022, 17.8964, 18.6309, 11.5805, 17.1843, 10.7487, 27.3265,\n",
       "                      11.7636, 27.5499, 13.4789, 26.4110, 48.1084, 10.9896, 19.1405, 11.0402,\n",
       "                       6.7606,  9.4307, 20.0629, 32.8033,  6.7211, 14.6987, 30.0069, 18.2410,\n",
       "                      14.6452, 26.7315, 14.6979, 28.7509, 37.2557, 21.9850, 32.0598, 26.7120,\n",
       "                       7.0789, 10.0965, 44.3797, 33.8998, 24.1027, 13.7562, 10.4648, 25.6448,\n",
       "                      23.1698, 24.1747, 13.5981, 19.5093,  4.4610, 11.9872, 11.1300,  4.4206,\n",
       "                      22.5331, 23.6396, 15.7599,  6.3538,  3.2810, 14.8751, 16.0796, 10.9207,\n",
       "                       5.1066, 16.0795, 31.8497, 20.7898, 13.5729, 17.2899, 15.2702,  7.9741,\n",
       "                      16.0184, 16.0046, 15.0117, 11.9559, 17.4703,  8.5567, 16.5416,  8.6536,\n",
       "                       3.1471, 13.3657, 36.9750, 29.1694, 13.3317, 11.3734,  4.7904, 11.2839,\n",
       "                      12.1372, 31.8972, 11.1363, 15.1774, 16.3388, 19.4651,  8.1487, 21.0309,\n",
       "                       9.1159, 11.8341, 15.9305, 18.3443, 19.2887, 23.6510, 19.0304, 25.6219,\n",
       "                      13.7310, 11.1023, 28.5880,  8.2523, 11.3362,  3.9850, 11.8526,  5.8452,\n",
       "                       4.6486, 13.1018, 18.2617, 25.5351, 26.5429, 22.0399, 14.0497, 18.8683,\n",
       "                      15.0423, 19.3316,  4.9169, 17.1923, 11.2731, 20.3997, 17.1153, 14.7711,\n",
       "                      13.1216, 14.6626, 18.7908, 33.7767, 31.1224, 16.8063, 19.4649, 26.5509,\n",
       "                      10.4670, 40.6961, 56.8420, 13.9113, 19.8506, 15.9927, 13.1833,  5.3747,\n",
       "                      12.9164, 19.6825, 11.7234, 10.5552,  3.2164, 19.0529, 18.6243,  3.8479,\n",
       "                      17.3073, 17.8297,  6.0869, 19.2629,  9.5786,  7.3701, 27.4588, 17.7705,\n",
       "                      17.8569, 10.5123, 23.3862, 21.5240, 13.3133, 22.4450, 18.8869, 15.9933,\n",
       "                      20.2897, 15.5485, 30.0565, 23.1910, 13.0794, 21.1492,  7.7913, 14.5334,\n",
       "                      17.4401, 11.9952, 13.4288, 12.8075,  7.4606, 21.0727, 18.0289, 19.0485,\n",
       "                      16.3264,  8.6855, 34.4725, 16.3944, 38.3138,  4.3363, 39.7006, 13.5680,\n",
       "                      25.1719,  2.3369, 14.6388, 22.5186, 15.4152, 31.3699, 20.9004, 18.2541,\n",
       "                       8.4245, 14.0153, 10.9995, 29.2076,  7.6909,  3.7396,  8.4154, 10.0600,\n",
       "                      16.5012, 19.1621, 21.0240, 20.0611,  5.7387, 18.8005,  6.1813, 12.2710,\n",
       "                      22.5044, 15.4921, 21.4759, 13.4136,  6.9473, 17.1352, 13.0289, 22.4990,\n",
       "                       6.0225, 10.6556, 16.2021, 32.8283,  4.7706, 14.8738, 11.1560,  5.3743,\n",
       "                       5.7921, 13.3604,  2.7482, 21.5029, 18.7508, 10.4992, 11.8807, 12.2436,\n",
       "                      20.7739, 19.8033, 14.8469, 29.4510, 16.5537, 11.8768, 14.7347,  8.0578,\n",
       "                      19.0071,  7.7629,  5.1596, 14.3560, 22.3317, 13.3205, 19.7466, 24.0590,\n",
       "                       6.4785, 15.4873, 12.4923,  3.4095, 13.0653, 28.5847, 11.8347, 21.4392,\n",
       "                       9.8598, 21.0303,  6.1335, 41.6386, 38.8693, 13.3092, 37.4739, 24.0293,\n",
       "                      29.3321, 20.2335, 25.1091, 15.4169, 20.7976, 11.3012, 18.0666, 31.7064,\n",
       "                      29.0671, 22.3197, 24.9146, 26.9031, 16.6671, 10.1967, 28.5814,  4.7615,\n",
       "                      12.0240, 24.9222, 47.2419, 14.4547, 15.7475,  8.2459, 14.8922, 18.0402,\n",
       "                       4.3960, 17.3405, 18.5886, 20.8925, 20.4716, 24.4640, 12.8354, 22.0989,\n",
       "                      11.8033,  8.9580, 29.3541, 14.4815, 44.2939, 45.6635, 12.4235, 14.7183,\n",
       "                      30.9570, 20.2884, 17.1768, 23.2277, 23.9515, 10.5962, 23.8915, 13.6565,\n",
       "                       5.5642, 14.8275, 18.0266,  6.5589,  6.7854, 11.0593, 15.2008, 14.4204,\n",
       "                      15.2472, 15.3347, 23.7237, 35.7539, 16.3468, 10.1289, 19.9992, 24.8273,\n",
       "                      20.1210, 10.2618,  2.7819, 10.3906,  9.9954, 16.3208, 10.1581, 13.0410,\n",
       "                      44.9760, 20.8118, 20.8414, 10.9393, 19.6904, 12.4679, 10.3500, 15.2428,\n",
       "                      15.8127, 14.6952, 11.2404,  6.7499,  7.6787, 20.9956, 15.3474, 27.1440,\n",
       "                      43.7911, 31.7482, 11.0519, 18.2463, 19.6826, 21.1500,  5.7881, 14.8946,\n",
       "                      20.2056, 12.6739, 27.8798, 16.1588, 19.6985,  6.2127,  5.5244,  3.4680],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.weight',\n",
       "              tensor([0.8692, 1.0196, 0.9362, 0.9131, 1.0375, 1.0444, 1.0132, 1.0092, 1.0608,\n",
       "                      1.0743, 1.0304, 1.1891, 1.0405, 1.0412, 1.0269, 0.9653, 1.0626, 1.0576,\n",
       "                      1.0416, 1.0394, 1.0032, 0.9530, 1.0887, 1.1196, 1.2284, 1.1845, 1.2006,\n",
       "                      1.0038, 0.9120, 0.9737, 1.0074, 1.0234, 0.9587, 0.9566, 1.1203, 1.0380,\n",
       "                      1.2199, 1.0974, 1.0536, 0.7612, 0.9293, 1.2127, 1.0957, 1.0487, 1.0060,\n",
       "                      0.9303, 1.1301, 0.9962, 0.9253, 0.9390, 1.0552, 1.0215, 0.6022, 1.1631,\n",
       "                      1.0075, 0.9166, 1.1436, 1.1242, 0.9639, 0.8867, 0.8757, 1.0242, 1.0773,\n",
       "                      1.0337, 1.0872, 0.9788, 0.9669, 0.9332, 0.7769, 1.0834, 1.1052, 1.0670,\n",
       "                      1.2093, 1.0479, 0.8535, 1.0409, 1.0113, 0.8261, 0.9043, 1.0220, 1.0291,\n",
       "                      1.0649, 0.9358, 1.2345, 0.9310, 0.9950, 1.1893, 1.0115, 0.7559, 1.0712,\n",
       "                      1.0209, 0.9954, 0.8501, 1.0186, 1.1557, 0.9994, 0.9954, 1.0819, 1.0597,\n",
       "                      1.0474, 1.0162, 0.9761, 0.9244, 0.9922, 0.9519, 1.1067, 0.9372, 0.9337,\n",
       "                      1.1715, 1.0161, 1.0217, 1.0195, 1.1220, 1.0149, 1.1270, 1.1602, 0.9379,\n",
       "                      1.0706, 1.1358, 1.0445, 0.9419, 1.0347, 0.9873, 1.0045, 0.9723, 1.0441,\n",
       "                      0.8574, 1.0103, 1.0524, 0.9981, 0.9770, 1.0063, 1.0351, 1.0704, 1.0712,\n",
       "                      1.1775, 1.0923, 1.0152, 1.0871, 1.0963, 0.9691, 1.0647, 0.6194, 1.0080,\n",
       "                      1.0311, 1.1069, 0.9379, 1.0183, 1.0397, 0.9723, 1.0926, 0.9570, 1.1201,\n",
       "                      0.6124, 1.0335, 1.0131, 1.0401, 1.0126, 0.9381, 1.0591, 1.0451, 0.6448,\n",
       "                      1.2713, 0.8568, 1.0401, 0.9968, 0.9266, 0.9932, 1.0042, 1.0146, 0.9523,\n",
       "                      1.0785, 1.0504, 1.0440, 0.8292, 1.0258, 0.8946, 1.0836, 0.9695, 1.1255,\n",
       "                      1.0539, 1.0798, 1.0433, 0.9571, 1.0015, 1.0899, 0.9283, 1.0606, 0.9519,\n",
       "                      0.7614, 0.7617, 0.9541, 1.1838, 0.9471, 1.0733, 1.1440, 1.0788, 1.0504,\n",
       "                      0.9725, 0.7654, 1.0277, 0.7071, 0.9312, 1.0306, 1.0887, 1.1121, 0.9629,\n",
       "                      1.0552, 1.0747, 1.1719, 0.8791, 1.0809, 1.0920, 0.8258, 1.0560, 0.9856,\n",
       "                      1.0623, 0.8904, 0.9770, 0.9496, 1.1909, 0.8231, 0.9825, 0.9999, 1.0781,\n",
       "                      1.0322, 0.9479, 0.6987, 1.0529, 0.9777, 1.0731, 1.0085, 1.0309, 0.9760,\n",
       "                      1.1300, 1.0308, 0.9500, 0.8970, 1.0981, 0.9828, 1.0356, 1.0897, 1.0457,\n",
       "                      1.1373, 1.0823, 1.0683, 1.1204, 1.0674, 1.1082, 1.0366, 1.0477, 0.7976,\n",
       "                      1.0946, 1.0202, 0.9869, 0.9141, 0.9358, 1.0071, 1.0090, 0.9882, 1.2007,\n",
       "                      0.9805, 0.9280, 0.9648, 1.1031, 1.0952, 1.0682, 0.9051, 0.9703, 0.9847,\n",
       "                      1.0507, 1.0302, 1.0373, 1.0126, 1.1133, 0.9373, 1.0751, 1.0259, 0.8999,\n",
       "                      0.9758, 1.0634, 0.9822, 0.9974, 1.1841, 1.0385, 0.9460, 1.0757, 1.0571,\n",
       "                      0.8684, 0.7430, 1.0869, 1.0043, 0.8735, 0.9567, 1.0572, 1.0317, 1.0294,\n",
       "                      1.0523, 1.0352, 1.0453, 1.1801, 1.1518, 1.0357, 1.0031, 1.0059, 1.0505,\n",
       "                      0.8497, 0.8277, 0.7445, 1.0762, 1.0021, 1.1202, 1.0641, 0.9924, 1.1110,\n",
       "                      1.0767, 0.9756, 1.0253, 1.1018, 0.9259, 0.9461, 1.0254, 1.0322, 0.9632,\n",
       "                      1.0843, 0.8916, 0.8301, 1.1465, 0.9954, 0.9512, 0.9322, 0.9779, 0.9065,\n",
       "                      0.9694, 0.5169, 1.1076, 1.0327, 0.9517, 1.1000, 0.9666, 0.9286, 0.9862,\n",
       "                      1.1279, 0.9118, 0.9248, 0.8618, 0.8209, 0.7729, 0.9371, 0.8842, 0.9992,\n",
       "                      1.0429, 1.0914, 0.8012, 1.0192, 1.0117, 1.0623, 1.0231, 1.0377, 1.1539,\n",
       "                      0.8518, 0.6366, 1.0854, 0.9593, 0.9821, 0.8839, 1.2614, 0.9315, 0.8245,\n",
       "                      0.9191, 1.0720, 0.9815, 0.7630, 1.0368, 1.0000, 1.0597, 0.9025, 1.0035,\n",
       "                      1.1145, 0.9382, 1.0012, 0.9382, 0.9492, 1.0129, 0.7285, 1.0805, 0.9569,\n",
       "                      1.0730, 1.0464, 0.8662, 0.5841, 0.9371, 0.7384, 0.9628, 1.1045, 0.9737,\n",
       "                      1.0557, 1.1154, 1.1908, 0.9917, 0.9906, 0.7624, 1.0398, 0.9751, 1.0418,\n",
       "                      1.0149, 0.8918, 0.9710, 0.9319, 0.9814, 0.9381, 0.9196, 1.1777, 1.0211,\n",
       "                      1.0665, 0.9604, 1.0621, 1.0200, 0.8991, 0.9888, 0.8206, 1.0428, 1.0212,\n",
       "                      1.0214, 1.0759, 1.0050, 0.9450, 0.9638, 1.0861, 1.0789, 0.9607, 0.7226,\n",
       "                      0.8935, 1.0180, 0.9566, 1.1027, 0.9531, 0.9753, 1.1532, 1.0002, 0.9920,\n",
       "                      1.0342, 0.9385, 0.8641, 0.9388, 0.9327, 1.0506, 1.0106, 1.0389, 0.9956,\n",
       "                      1.0707, 1.0160, 1.1350, 1.1605, 0.9819, 0.9502, 1.0184, 1.0517, 1.0610,\n",
       "                      1.0803, 0.9218, 0.9971, 1.0046, 1.0675, 0.9909, 1.1060, 0.7715, 1.0106,\n",
       "                      0.9804, 1.0199, 1.0249, 1.0042, 1.0969, 0.8566, 1.0517, 0.6326, 1.0388,\n",
       "                      1.0691, 1.0669, 0.9527, 1.0403, 1.0416, 0.7403, 1.1037, 1.0038, 1.0177,\n",
       "                      0.5930, 0.9599, 1.0896, 0.9358, 0.9490, 0.9979, 1.0591, 0.9622, 0.9875,\n",
       "                      0.9553, 1.0062, 1.0119, 1.1283, 1.0414, 1.0745, 1.0687, 0.8101, 1.0115,\n",
       "                      1.1221, 1.0903, 0.9864, 1.1624, 1.0129, 1.0907, 0.9775, 0.7475],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.bias',\n",
       "              tensor([-0.6357, -0.8527, -0.7240, -0.7183, -0.9574, -0.9813, -0.7130, -0.8558,\n",
       "                      -0.8158, -0.8945, -0.7349, -0.9749, -1.0785, -0.7781, -0.8201, -0.7343,\n",
       "                      -1.2163, -0.9349, -0.9170, -0.7448, -0.8741, -0.8969, -1.0082, -0.9573,\n",
       "                      -1.1156, -1.2825, -1.2379, -0.9295, -0.6968, -1.0297, -0.9719, -0.8778,\n",
       "                      -0.6440, -0.7050, -1.0121, -1.0072, -1.1827, -0.8992, -0.8494, -0.6630,\n",
       "                      -0.6907, -1.1151, -0.9045, -1.0034, -0.8512, -0.8988, -1.0106, -0.6670,\n",
       "                      -0.6949, -0.8435, -1.0474, -0.8233, -0.4661, -1.0223, -0.9171, -0.9080,\n",
       "                      -1.1544, -1.0028, -1.1745, -0.8494, -0.5735, -1.0519, -0.8442, -0.8575,\n",
       "                      -1.1057, -0.8953, -0.8886, -0.8457, -0.5678, -1.0093, -0.9063, -0.9730,\n",
       "                      -1.3149, -0.9343, -0.6227, -0.9176, -0.9047, -0.6808, -0.7603, -0.9709,\n",
       "                      -0.9282, -1.0250, -0.7901, -1.1732, -0.9183, -0.8938, -1.0894, -0.7654,\n",
       "                      -0.7095, -1.1964, -0.8708, -0.8142, -0.8661, -0.9949, -1.1258, -0.9737,\n",
       "                      -0.7671, -0.9461, -0.8957, -0.9559, -0.8173, -0.8774, -0.8777, -0.9807,\n",
       "                      -0.6896, -0.9080, -0.7666, -0.7901, -0.9920, -1.0560, -0.9186, -0.8876,\n",
       "                      -0.9487, -0.8476, -0.9140, -1.0839, -0.7586, -1.0032, -1.0627, -0.9870,\n",
       "                      -0.6890, -0.7998, -0.8275, -0.7153, -0.7468, -0.9308, -0.5439, -0.7082,\n",
       "                      -0.9491, -0.8077, -0.7686, -0.8005, -1.1216, -1.0302, -0.8449, -1.2532,\n",
       "                      -1.0404, -0.8978, -0.8028, -1.0356, -0.8640, -0.9739, -0.3478, -0.7908,\n",
       "                      -1.0078, -1.0894, -0.6264, -0.9284, -0.8441, -0.6705, -0.9099, -0.6895,\n",
       "                      -1.0781, -0.4041, -0.9598, -0.9002, -0.8591, -0.8593, -0.9035, -0.9717,\n",
       "                      -0.8061, -0.4209, -1.1186, -0.6594, -0.9079, -0.8793, -0.6905, -0.7890,\n",
       "                      -0.7763, -0.8181, -0.7768, -0.9247, -1.1757, -0.9052, -0.6392, -0.9119,\n",
       "                      -0.8816, -1.1514, -0.6032, -1.1121, -1.0446, -0.9701, -0.9160, -0.7903,\n",
       "                      -0.9031, -0.9186, -0.8806, -0.9007, -0.8075, -0.5293, -0.7690, -0.7966,\n",
       "                      -1.0551, -0.7402, -0.9771, -1.1216, -1.0144, -0.7270, -0.8152, -0.4969,\n",
       "                      -0.9188, -0.5080, -0.6954, -0.8943, -0.9111, -0.9846, -0.7691, -0.7996,\n",
       "                      -0.9310, -0.9318, -0.7881, -1.0120, -1.1179, -0.6427, -0.8588, -0.8852,\n",
       "                      -0.9369, -0.6432, -0.8372, -0.7708, -1.0399, -0.5446, -0.8622, -1.0342,\n",
       "                      -1.0385, -0.9053, -0.7958, -0.5640, -1.0736, -0.7351, -0.9306, -0.7655,\n",
       "                      -0.9475, -0.9423, -1.0223, -0.8780, -0.8575, -0.8953, -1.0348, -0.9474,\n",
       "                      -1.0599, -0.8597, -0.9905, -0.8517, -0.8602, -1.0753, -0.9481, -1.0397,\n",
       "                      -0.9873, -0.9807, -0.9107, -0.8368, -0.9407, -0.9491, -0.9919, -0.6827,\n",
       "                      -1.0033, -0.8495, -0.9439, -0.7659, -0.9812, -0.7008, -0.6716, -0.7872,\n",
       "                      -0.7998, -0.9925, -0.7968, -0.6551, -0.9045, -0.9280, -1.0423, -0.9507,\n",
       "                      -0.8546, -0.7400, -1.2037, -0.9359, -0.8926, -0.8114, -0.8905, -0.9073,\n",
       "                      -0.9369, -0.8521, -0.9964, -0.9729, -0.9072, -0.6744, -0.9125, -0.8992,\n",
       "                      -0.6318, -0.5347, -0.9464, -1.0394, -0.8523, -0.7701, -0.8907, -0.9499,\n",
       "                      -1.0483, -0.9705, -0.9066, -0.9237, -1.2272, -1.3275, -0.8460, -0.7763,\n",
       "                      -0.6645, -0.9437, -0.4811, -0.6286, -0.5974, -0.9572, -0.8808, -0.9409,\n",
       "                      -0.9350, -0.8788, -0.9325, -0.9302, -0.9094, -0.8218, -1.0726, -0.7214,\n",
       "                      -0.9896, -0.8111, -1.0361, -0.7955, -0.7910, -0.7099, -0.6057, -0.9668,\n",
       "                      -0.8110, -0.9454, -0.8162, -0.7066, -0.6406, -0.9381, -0.2838, -1.2096,\n",
       "                      -0.8564, -0.9551, -1.0171, -0.8412, -0.7527, -0.7537, -0.9505, -0.7497,\n",
       "                      -0.8901, -0.6481, -0.7140, -0.4668, -0.8714, -0.9210, -1.0737, -0.9736,\n",
       "                      -0.9253, -0.8462, -0.9520, -0.7971, -1.1652, -0.9690, -0.9288, -0.8844,\n",
       "                      -0.7713, -0.4085, -0.9273, -0.7709, -0.9965, -0.7296, -1.0591, -0.8909,\n",
       "                      -0.6816, -0.7582, -0.8895, -1.0022, -0.4112, -0.9052, -0.8330, -0.7699,\n",
       "                      -0.6271, -0.7419, -0.9814, -0.8401, -0.8756, -0.7851, -0.8853, -0.9722,\n",
       "                      -0.4361, -1.0040, -0.8905, -0.9258, -0.8468, -0.6977, -0.3273, -0.7692,\n",
       "                      -0.5724, -0.7710, -0.9961, -0.9429, -1.0810, -1.0256, -1.0846, -0.8732,\n",
       "                      -0.8395, -0.6623, -0.7299, -0.7672, -1.0518, -0.8442, -0.7411, -1.0576,\n",
       "                      -1.0265, -0.9971, -0.9094, -0.6428, -1.1716, -0.7394, -0.8364, -0.8228,\n",
       "                      -0.9271, -0.7503, -0.7941, -0.9165, -0.6003, -0.7904, -0.8405, -1.0136,\n",
       "                      -0.8585, -0.9383, -0.6179, -0.9837, -1.0112, -0.8642, -0.8000, -0.4619,\n",
       "                      -0.7208, -0.9207, -0.8988, -0.8371, -0.9391, -0.8320, -0.9519, -0.8000,\n",
       "                      -0.8909, -0.9169, -0.8799, -0.7483, -0.7430, -0.9219, -0.8550, -0.8171,\n",
       "                      -0.7724, -0.8056, -0.8571, -0.8749, -1.1316, -1.0753, -1.0479, -0.9392,\n",
       "                      -0.8136, -0.8701, -0.9236, -0.9709, -0.8798, -0.6883, -0.9078, -0.9579,\n",
       "                      -0.9275, -1.1071, -0.5766, -0.9774, -0.8089, -0.9832, -1.1391, -0.9514,\n",
       "                      -0.9571, -0.8613, -0.9184, -0.5020, -1.0454, -0.9861, -0.8187, -0.9366,\n",
       "                      -0.9146, -0.9690, -0.4672, -1.0258, -0.9856, -0.9362, -0.3431, -0.7617,\n",
       "                      -0.8894, -0.7865, -0.8302, -0.9095, -0.8643, -0.8991, -0.9230, -0.7429,\n",
       "                      -0.7601, -0.8827, -1.0443, -0.8199, -0.9924, -0.9508, -0.6007, -0.8046,\n",
       "                      -0.9269, -0.9579, -0.7895, -0.9726, -0.8318, -1.0327, -0.9359, -0.5078],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.running_mean',\n",
       "              tensor([ -7.2217,  -9.4223,  -7.8555, -11.1171, -10.0695, -10.1816,  -9.7072,\n",
       "                      -11.7213, -11.2590, -11.6571, -11.2408, -12.6502,  -9.2718, -11.3189,\n",
       "                       -9.7495,  -9.7426, -10.5952,  -9.2792, -12.3860, -12.8628,  -9.4238,\n",
       "                       -9.1996, -11.4070, -10.2552, -14.0790,  -8.0529, -12.4514, -13.6325,\n",
       "                       -6.2170,  -6.2160, -13.5863, -14.3095,  -7.6623,  -8.5154, -15.6250,\n",
       "                      -12.8607, -12.8907, -10.0198, -11.2232,  -8.9098,  -8.9619, -11.4442,\n",
       "                      -13.6419, -12.4959, -10.6334, -10.8593,  -9.7524,  -9.5926, -10.5570,\n",
       "                       -9.5048,  -9.8907, -11.6446,  -5.3319, -11.6572,  -8.4265,  -9.6813,\n",
       "                      -13.1681, -13.0823, -11.3458,  -8.7367,  -7.2302, -12.3392,  -9.5577,\n",
       "                      -10.3921,  -8.5522,  -8.0391,  -7.5973,  -9.0618,  -6.4561, -13.9282,\n",
       "                      -11.7446,  -8.7068, -11.7447,  -9.6265, -10.5582, -11.7715,  -6.6955,\n",
       "                       -6.5593,  -7.6174, -14.4919,  -9.2879,  -9.6648,  -8.8314, -14.4307,\n",
       "                       -9.2314,  -9.1620, -13.7911,  -8.6315,  -7.4932, -12.4490, -13.6174,\n",
       "                      -12.8365,  -8.1795, -11.0466, -14.5331, -11.1737, -10.7006, -13.7215,\n",
       "                      -10.2419, -10.5857, -11.3194,  -8.6429, -14.4091, -11.8756, -10.0178,\n",
       "                      -15.7342, -12.2482, -10.7726,  -9.0064,  -7.0679,  -8.7856,  -9.3819,\n",
       "                       -8.7810,  -8.2171, -11.0313, -12.0236, -10.7850,  -8.3264, -12.4882,\n",
       "                      -12.3049, -12.1004, -11.7934,  -8.6513,  -9.9407, -12.6059,  -6.4946,\n",
       "                      -11.3678, -10.3008, -15.7178,  -9.4577, -12.9797, -11.8957,  -9.2470,\n",
       "                      -11.4784,  -8.8219, -12.2327, -11.2816,  -7.2670,  -9.0750, -10.4724,\n",
       "                       -7.4391, -11.9796,  -9.0265,  -9.7816, -10.7094,  -7.7733,  -6.4624,\n",
       "                       -9.9683,  -8.1779,  -9.5215, -12.2368,  -7.7565, -11.2028,  -4.9102,\n",
       "                       -7.1140, -10.6850, -12.9298,  -7.5132, -10.5257, -10.9926, -10.7832,\n",
       "                       -8.8580, -18.0062,  -9.4415, -10.2365, -11.5155,  -8.0074,  -6.9057,\n",
       "                      -11.1964,  -8.3443,  -6.8587, -11.6304,  -9.6873,  -8.6372,  -9.6715,\n",
       "                       -8.7017, -11.9263,  -9.1683,  -8.5967, -12.6367,  -9.3720,  -7.4918,\n",
       "                      -13.1590, -10.0388,  -9.7203, -10.3351,  -7.9317, -10.7264,  -9.6274,\n",
       "                       -8.1217,  -9.2193, -12.2071, -13.4013, -10.6536, -10.3623, -10.3160,\n",
       "                      -10.0965,  -8.1060,  -8.5414,  -9.2067, -11.1811,  -6.1787,  -9.7677,\n",
       "                       -7.1946,  -8.3545,  -9.4483, -11.4419, -13.4036, -10.8391, -12.5806,\n",
       "                       -7.6436, -14.4315, -10.3716, -10.1163, -10.5008,  -9.3274, -15.0703,\n",
       "                      -12.0637,  -9.0438, -10.4931, -11.8402, -10.3053,  -9.4609,  -7.6577,\n",
       "                      -10.5881, -12.5979,  -8.0026,  -6.9366, -11.1863, -10.6480, -12.0001,\n",
       "                      -11.1000, -12.4991, -10.0910,  -8.9072, -12.4983, -12.2681, -10.1324,\n",
       "                      -11.1406, -10.9403, -12.6944, -11.3389, -10.4013, -11.9818, -11.3081,\n",
       "                       -9.9142, -13.1472,  -9.2163, -13.2241, -11.7402, -11.6737,  -9.6230,\n",
       "                      -13.4140, -12.1015, -11.5829,  -8.9552,  -9.0485,  -9.6531,  -9.9278,\n",
       "                      -11.3367,  -9.3939, -10.8233,  -9.8794,  -8.1579, -14.4697, -11.9489,\n",
       "                       -8.7169,  -6.3876, -12.5473,  -7.8143,  -9.4044,  -9.3503,  -7.3239,\n",
       "                      -15.4242, -13.2306,  -8.0393, -10.4300, -11.2145,  -9.9549,  -9.5331,\n",
       "                      -13.3521, -11.4589, -10.0917, -10.9457,  -6.9367,  -8.9972,  -9.4621,\n",
       "                      -12.0825, -12.3788,  -9.2887,  -8.7469, -12.6476,  -8.6055,  -9.1447,\n",
       "                      -10.5725,  -8.6255,  -8.3522, -12.0912,  -7.6991, -12.8994, -11.6844,\n",
       "                      -10.7394,  -9.3927, -11.6476,  -7.7208, -11.9528,  -8.8031,  -9.6025,\n",
       "                       -8.3256,  -9.1556, -11.2885,  -7.9890, -10.5148, -10.8330, -14.7228,\n",
       "                      -12.7514, -12.7055, -11.4063, -11.3698,  -9.0356,  -8.7748, -10.5433,\n",
       "                      -11.1318,  -7.7884, -10.5276, -12.0900,  -9.2404, -13.7438, -10.4205,\n",
       "                      -12.8268, -12.3967,  -8.6786, -10.9816, -10.9238,  -5.9067, -11.4906,\n",
       "                      -10.0465, -12.1413,  -7.2672, -11.3725,  -4.9285, -11.6286, -10.8008,\n",
       "                      -10.3324, -12.3026,  -9.6679, -10.3923,  -9.8403,  -8.6109, -12.4986,\n",
       "                       -8.9889, -16.8392, -13.0485, -11.0315, -10.8717,  -8.3067, -10.5114,\n",
       "                      -14.8787, -12.6069, -10.4141,  -7.3667,  -9.0827,  -8.5039, -13.4819,\n",
       "                       -6.4613,  -5.1190,  -9.6952, -11.0072, -10.8268, -12.5833,  -7.9105,\n",
       "                      -12.5562,  -6.2074, -10.0806, -11.3504,  -9.3440,  -7.1545, -10.8582,\n",
       "                       -8.7306,  -9.0149,  -8.8829, -10.9102, -11.2524,  -8.9335,  -8.7774,\n",
       "                      -10.2540, -13.7164, -11.3447, -11.1530,  -8.0848,  -5.1182,  -7.2847,\n",
       "                       -9.5097,  -6.8421, -11.2962, -11.4274, -11.5100,  -9.4415,  -9.5615,\n",
       "                       -8.6290, -10.4914,  -5.1203, -14.6960, -12.8453, -11.7213,  -9.3324,\n",
       "                      -13.3476,  -9.4075, -11.5146,  -7.7887,  -9.4822,  -9.4678,  -9.3904,\n",
       "                      -11.4133, -12.7036, -11.6822,  -9.2775,  -8.9780, -11.1748,  -9.4884,\n",
       "                       -8.8757,  -6.3992, -11.8633,  -9.8954, -12.3142, -10.4113,  -8.0166,\n",
       "                       -8.0830, -16.9970,  -8.0023, -11.6493,  -6.2276, -11.0222, -14.8319,\n",
       "                       -8.3396,  -9.7679,  -7.3102,  -9.2206, -10.8120, -11.0586, -10.9502,\n",
       "                       -8.7739, -11.9664, -12.3467,  -9.1712,  -8.8585, -11.9318, -13.1968,\n",
       "                      -10.9864,  -7.0135, -11.3529, -10.9490, -10.8191, -14.6997,  -9.9752,\n",
       "                       -9.8470, -10.3471,  -9.8631, -16.0614, -11.2940,  -6.3747, -10.9368,\n",
       "                       -8.2019,  -9.1173,  -9.5453, -11.2364, -11.6317, -10.6414, -10.2458,\n",
       "                      -15.1182,  -8.8647, -10.5941, -11.7257,  -8.2518,  -7.7674,  -6.1582,\n",
       "                      -12.5324, -10.5480, -15.6717,  -9.8634,  -8.9418,  -9.5094,  -5.1978,\n",
       "                       -9.5818, -12.6270, -11.0348,  -6.8526,  -8.4254,  -9.6214,  -8.7497,\n",
       "                       -6.8091, -11.9404, -12.8351,  -9.0511,  -7.4129, -10.5719,  -8.1175,\n",
       "                       -9.1278, -15.8671, -10.2872, -13.2889,  -9.5792, -12.3235,  -9.9624,\n",
       "                      -11.6903, -10.9088,  -5.9552, -10.1533, -11.9592, -10.2975, -15.1941,\n",
       "                       -8.0593], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.running_var',\n",
       "              tensor([110.1013,  96.6726,  98.5284, 169.1435, 125.3366, 131.8992, 157.7085,\n",
       "                      141.3341, 149.2600, 217.5996, 176.2289, 182.7384,  80.2694, 209.9898,\n",
       "                      125.8025, 135.3296,  91.9456,  91.7280, 142.9655, 209.0277,  88.5425,\n",
       "                       82.1984, 148.4225, 135.6134, 160.7234,  63.7350,  93.9494, 200.4517,\n",
       "                       66.7372,  31.2505, 165.5277, 217.5831, 150.6635, 124.6320, 186.7790,\n",
       "                      148.4877, 144.1012, 131.7364, 189.5228,  83.9388, 107.3515, 102.9139,\n",
       "                      165.2373, 128.3841, 136.5176,  88.6900,  97.4081, 174.6878, 156.0142,\n",
       "                       84.7350,  80.9815, 166.5275,  87.9052, 121.1472,  66.6285,  81.6391,\n",
       "                      121.2194, 158.9013,  67.9545, 115.1811, 103.4202,  78.5062,  92.2965,\n",
       "                      158.7301,  49.4481, 102.7154,  47.7885, 108.4013,  73.1864, 152.3747,\n",
       "                      143.2400,  86.5247,  96.5657,  98.6674, 143.7276, 166.4690,  50.6137,\n",
       "                       93.5723,  74.5582, 185.1402, 110.8337,  94.8524, 114.5059, 142.2812,\n",
       "                       58.9620, 148.6631, 143.0482, 116.4142,  57.8174, 119.7907, 159.5803,\n",
       "                      235.4661,  87.1023, 116.2071, 124.5230,  72.2186, 168.6625, 220.6602,\n",
       "                      132.6162, 140.5872, 119.5533,  67.9487, 179.9690, 114.5721, 200.1702,\n",
       "                      190.9090, 133.7323, 166.5645,  90.8927,  44.1526,  89.1107,  81.5050,\n",
       "                       69.9309,  75.3521, 121.8020, 143.3390, 136.8282,  81.7913, 119.4934,\n",
       "                      128.8568, 183.8851, 135.8139,  92.1185, 190.1746, 202.9908,  66.4810,\n",
       "                      116.3261, 147.3400, 223.4248, 160.3358, 151.2916, 169.2514,  71.6559,\n",
       "                       90.9859,  96.6361,  92.7306,  98.1640,  50.6953,  97.8228, 109.0772,\n",
       "                       62.8536, 121.9632, 177.8334,  76.8715,  74.1420,  80.4216,  97.8073,\n",
       "                       87.0813,  86.5070, 211.5015, 168.8579, 103.6034, 111.8142,  81.8090,\n",
       "                       55.8474, 122.8912, 149.1518,  70.3364,  86.0826,  82.7988, 155.4536,\n",
       "                      120.4539, 239.7780, 127.3867, 146.4868, 139.6124, 100.1240,  84.6870,\n",
       "                      161.9178,  84.3400,  68.0607, 111.1455,  90.4961, 120.1926, 146.9254,\n",
       "                       78.8875, 108.2526,  83.5099, 170.5288, 114.0824,  57.6681,  83.1408,\n",
       "                      154.8800, 130.4887,  69.8103, 114.7006,  58.8390, 130.3068, 112.9413,\n",
       "                       95.5596,  76.9168, 107.3800, 221.2277, 131.5453, 101.0562,  74.8707,\n",
       "                       79.0981, 148.5423,  78.7560, 143.8539, 160.5497,  91.7535, 114.0328,\n",
       "                       56.7479,  86.7435, 140.3108, 175.3329, 207.8251, 169.8280, 132.7879,\n",
       "                       90.0089, 162.7866,  90.4319, 104.3550,  93.4183,  70.2525, 193.8038,\n",
       "                      145.8176, 119.6230, 180.1873, 130.2723, 249.5124,  95.7630,  43.2008,\n",
       "                       71.8060, 133.5331,  85.6062, 107.4483,  81.1492, 157.1075, 161.8346,\n",
       "                      184.4619, 162.2600,  74.3426,  70.5584, 120.7091, 144.7428,  68.3063,\n",
       "                      110.9502,  85.8114, 105.6033, 189.9105,  94.4094, 185.3419, 158.1815,\n",
       "                       69.1600, 161.4762,  65.7762, 166.5166, 111.9396, 163.1152,  72.1205,\n",
       "                      174.4374, 158.1032, 122.6268, 183.1980,  79.2362, 124.0882,  86.4705,\n",
       "                      127.4449, 113.9221, 213.7068, 273.2770,  84.5255, 223.4370, 151.7839,\n",
       "                      122.4230,  91.7628, 118.4312,  93.5417, 118.1462,  78.5812,  77.4551,\n",
       "                      310.5958, 106.2299,  46.5142,  96.5988, 170.8459,  72.7737, 110.2889,\n",
       "                      172.8573, 141.7009, 100.1371, 166.6598,  70.4011, 120.2401, 110.3596,\n",
       "                      257.4808, 206.7974, 128.4669, 112.8255,  94.8757,  70.4902, 117.4317,\n",
       "                      125.2519,  91.7481,  72.0719, 127.7492,  94.7460, 144.4422,  89.8823,\n",
       "                       58.0244, 112.2464, 141.9746,  97.7469, 148.0883, 158.9829, 114.1908,\n",
       "                      112.5693,  86.8755,  95.8040,  68.1667, 123.8803, 132.8888, 183.8204,\n",
       "                      157.2871, 108.9738, 145.1028, 126.2896, 152.6040,  58.9737, 114.8399,\n",
       "                      129.9149, 101.2524, 155.0703, 228.5103, 187.0171, 184.6077, 150.3114,\n",
       "                      120.3314, 138.5758, 114.6693, 275.3282, 111.4841, 144.9713,  72.2476,\n",
       "                      107.7681,  89.2029,  57.9141, 130.5548,  62.9172, 157.2776, 138.3540,\n",
       "                      166.7440, 131.0383, 137.9407,  83.9371, 153.9592,  73.4197, 127.9162,\n",
       "                       62.7614, 201.9830, 171.1706,  96.5811, 105.9448, 120.7381,  82.2109,\n",
       "                      212.9325, 152.6997, 132.3338,  69.9235, 111.8345,  73.2308, 292.5711,\n",
       "                       42.3482,  77.1124, 108.5411,  97.8758, 128.8943, 150.3757, 124.9101,\n",
       "                       85.6510, 147.2085, 125.9798, 157.2897, 128.7485, 117.7546, 164.0232,\n",
       "                       71.6350,  81.0349,  73.1138, 102.3292, 124.0345,  71.3246,  81.5554,\n",
       "                      107.3662, 149.7952, 125.9802, 175.7148,  76.6589, 213.6187,  90.5383,\n",
       "                      160.0675,  57.0136, 129.2416,  95.9125, 100.5742, 105.0315,  90.8378,\n",
       "                       72.2433, 139.2287,  81.7090, 282.4514, 147.1225, 111.8001,  84.1852,\n",
       "                      181.8748,  85.6247,  83.1833,  51.0131,  80.0823, 158.6868,  68.2417,\n",
       "                      183.6794, 146.5224, 187.7189, 100.0812, 130.7287, 105.3006,  70.1932,\n",
       "                       97.1133,  77.9340, 190.2665,  79.4642, 160.6101, 118.4879, 130.7286,\n",
       "                       47.0878, 217.4846,  89.7300, 177.2421, 109.4929, 201.4668, 246.0836,\n",
       "                      119.2581, 115.1693,  52.8004,  97.3680, 120.0003, 194.6324, 124.6765,\n",
       "                       80.3927,  91.8537, 184.7792, 106.4194,  64.6763, 165.3777, 196.0274,\n",
       "                      167.1150,  70.6278,  97.2015, 161.7706, 103.0451, 142.7020,  95.7354,\n",
       "                       90.0979, 134.3394, 120.6295, 206.8418, 165.7470,  48.3387, 189.5372,\n",
       "                       85.3331,  85.3150,  73.5294,  92.7901, 220.5452,  99.2099, 196.0856,\n",
       "                      202.2265,  51.3303,  86.5851, 114.2133,  68.9200,  75.2077,  66.1028,\n",
       "                      122.0823, 117.7750, 245.7526,  66.1286, 123.7523,  65.8125,  87.0287,\n",
       "                      104.8593, 113.6976,  81.1487, 157.0695, 153.1468, 102.4417, 109.2315,\n",
       "                       72.9572, 148.5748, 182.4391,  71.6832,  72.7795, 162.9872, 106.4467,\n",
       "                       93.8314, 162.9913, 129.5555, 196.3907, 164.7498, 165.6248, 114.9831,\n",
       "                      168.4438, 115.9995, 101.6505, 129.2027, 130.0742,  97.4615, 142.0679,\n",
       "                      144.2227], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('pos_encoder.pe',\n",
       "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                         0.0000e+00,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 8.4147e-01,  5.4030e-01,  7.8859e-01,  ...,  1.0000e+00,\n",
       "                         1.1007e-04,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 9.0930e-01, -4.1615e-01,  9.6984e-01,  ...,  1.0000e+00,\n",
       "                         2.2014e-04,  1.0000e+00]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 3.7961e-01, -9.2515e-01,  1.6091e-01,  ...,  9.9993e-01,\n",
       "                         1.0677e-02,  9.9994e-01]],\n",
       "              \n",
       "                      [[-5.7338e-01, -8.1929e-01,  8.7726e-01,  ...,  9.9993e-01,\n",
       "                         1.0787e-02,  9.9994e-01]],\n",
       "              \n",
       "                      [[-9.9921e-01,  3.9821e-02,  9.1797e-01,  ...,  9.9993e-01,\n",
       "                         1.0897e-02,  9.9994e-01]]], device='cuda:0'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "476ccfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(hp.ntoken, hp.ninp, hp.nhead, hp.nhid, hp.nlayers, hp.batch_size, dropout=0.2,\n",
    "                             pretrain_cnn=None, pretrain_emb=pretrain_emb, freeze_cnn=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b2881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e95451b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('transformer_decoder.layers.0.self_attn.in_proj_weight',\n",
       "              tensor([[-0.1121,  0.1543, -0.0988,  ..., -0.0251, -0.0537, -0.0022],\n",
       "                      [ 0.0296,  0.0604, -0.1261,  ..., -0.0366, -0.0391, -0.0789],\n",
       "                      [-0.0670,  0.0440, -0.0538,  ..., -0.0826, -0.0667, -0.0441],\n",
       "                      ...,\n",
       "                      [ 0.0519,  0.0259,  0.0380,  ..., -0.0424,  0.0839, -0.0298],\n",
       "                      [-0.1306,  0.0024,  0.0710,  ...,  0.0484, -0.0190, -0.0325],\n",
       "                      [-0.0671, -0.0377,  0.0468,  ..., -0.0534, -0.0323, -0.0415]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.self_attn.in_proj_bias',\n",
       "              tensor([-4.8882e-02,  1.4886e-02, -1.3403e-02, -3.1634e-02,  2.4075e-02,\n",
       "                       6.1872e-02,  3.3191e-02,  4.9238e-03, -2.4707e-02, -2.9865e-02,\n",
       "                      -8.4079e-02,  6.5329e-04,  2.5111e-02, -7.4482e-02, -5.5098e-02,\n",
       "                       3.9614e-02,  3.6864e-02,  5.8129e-03, -8.2433e-03, -4.9785e-02,\n",
       "                       4.7040e-02,  3.5419e-02, -7.7811e-02, -2.3538e-02, -3.2797e-02,\n",
       "                       5.0955e-02,  1.2973e-02,  8.2237e-02, -6.7934e-02, -4.8609e-03,\n",
       "                       5.2928e-03, -1.4551e-02, -4.8945e-02, -2.8405e-03,  1.1080e-01,\n",
       "                      -1.1835e-02, -7.7633e-02, -3.2229e-02, -3.3883e-02,  1.1286e-02,\n",
       "                       9.5591e-02,  7.0906e-02, -5.2854e-02, -8.2858e-02,  1.4638e-02,\n",
       "                       1.1863e-02,  5.4218e-02,  3.7832e-03,  2.1142e-02,  4.5759e-02,\n",
       "                      -1.3421e-03, -5.1448e-02,  2.7143e-02, -1.3486e-02, -1.7756e-02,\n",
       "                      -2.6771e-03,  1.0478e-02, -3.1756e-02,  4.3664e-02,  5.6513e-02,\n",
       "                      -2.2516e-02,  2.3603e-02, -2.7578e-02, -1.8583e-02, -1.6563e-03,\n",
       "                       2.1780e-02, -2.1138e-02,  2.5185e-02, -3.9830e-02,  5.6972e-02,\n",
       "                      -1.8557e-02,  5.4048e-02,  3.6929e-02, -4.3725e-02, -3.5584e-02,\n",
       "                       5.2630e-02,  1.8012e-02,  2.9198e-02, -2.1126e-02, -3.6502e-02,\n",
       "                       1.4218e-02,  2.3038e-02, -4.4794e-02, -1.9552e-02,  6.1013e-02,\n",
       "                      -7.8966e-03,  8.0278e-03, -1.1486e-02, -2.0190e-02, -1.6710e-02,\n",
       "                       2.8131e-02,  3.0692e-02,  3.6090e-02, -4.1345e-02,  4.4258e-02,\n",
       "                       7.3780e-03,  3.4233e-02, -1.8111e-02, -1.3227e-02,  7.3515e-02,\n",
       "                       1.1337e-02,  9.9177e-03, -8.6224e-02,  2.2670e-02,  1.3303e-02,\n",
       "                       5.5076e-02,  6.2373e-02, -3.1701e-02,  7.1008e-02, -2.3537e-02,\n",
       "                       3.1060e-02,  2.6192e-02, -3.2962e-02, -4.7220e-02,  4.7160e-02,\n",
       "                       2.0929e-02,  6.2649e-02,  6.2644e-02,  5.8579e-02,  6.6606e-02,\n",
       "                      -4.8528e-02,  1.0226e-02, -3.0267e-02, -3.7159e-02, -1.1162e-02,\n",
       "                       3.7877e-04,  2.0019e-02, -1.9767e-02, -4.1481e-02, -7.0210e-02,\n",
       "                       2.8430e-02,  6.9786e-02,  2.0005e-02,  9.6821e-04, -8.2378e-03,\n",
       "                       8.2414e-03,  2.7708e-02, -4.9569e-02, -2.1599e-02, -8.0262e-02,\n",
       "                      -1.6523e-02, -4.0349e-02,  4.2360e-04, -9.3588e-02, -3.0103e-02,\n",
       "                       4.3306e-02,  2.5295e-02,  1.0102e-02,  1.3036e-02, -7.6830e-02,\n",
       "                       4.2402e-02, -2.7280e-02, -2.2149e-02, -6.9022e-03,  6.0508e-02,\n",
       "                      -9.8263e-06, -1.4295e-03,  5.8245e-02, -7.0920e-03, -2.0126e-02,\n",
       "                      -2.1960e-02, -3.1308e-03,  1.7412e-02, -1.4055e-02,  5.1541e-02,\n",
       "                      -6.4362e-02,  1.2900e-02,  6.3986e-02, -2.5059e-02, -1.2995e-02,\n",
       "                       5.8593e-02, -3.5203e-02, -5.3229e-02,  5.3457e-02,  3.4618e-02,\n",
       "                       5.5110e-02, -6.3361e-02,  1.6490e-03,  8.1990e-02,  1.7448e-02,\n",
       "                      -5.6289e-02, -1.2129e-02, -9.0056e-02, -5.8310e-02,  1.1758e-03,\n",
       "                       2.8986e-02, -5.3037e-03,  1.7086e-03, -3.7347e-02, -5.2185e-02,\n",
       "                       1.0463e-02, -3.6608e-02,  1.8068e-05,  5.9495e-07,  5.7673e-06,\n",
       "                      -2.7862e-07, -4.4372e-06, -8.0239e-07, -1.1467e-05,  7.6796e-06,\n",
       "                      -1.3956e-06,  5.1741e-06,  2.1183e-06,  7.7048e-06, -9.7893e-06,\n",
       "                      -1.4522e-05,  3.4087e-07,  1.8796e-05, -2.6494e-06,  1.4365e-05,\n",
       "                      -8.7614e-06, -1.1120e-05, -1.8833e-05,  2.8068e-05, -3.8711e-06,\n",
       "                      -8.2170e-06,  1.2640e-07,  6.2034e-06,  2.6308e-05,  4.4106e-06,\n",
       "                       3.0250e-06, -1.1356e-05,  1.1416e-07,  4.0462e-07,  2.8889e-06,\n",
       "                      -6.8269e-07,  3.5595e-06, -3.1678e-06, -6.0499e-06,  1.2191e-05,\n",
       "                       3.8592e-06,  1.4879e-05,  7.7183e-06,  2.5749e-06,  1.5579e-05,\n",
       "                       1.2576e-05,  1.7262e-05, -8.3990e-06,  1.9338e-05, -2.4847e-06,\n",
       "                       1.4755e-05,  1.7367e-05,  3.9021e-06, -2.3688e-05, -4.8710e-06,\n",
       "                      -1.4862e-06, -1.0407e-05,  7.0105e-06,  8.7756e-06, -1.0468e-06,\n",
       "                       1.9916e-05, -6.6776e-07, -1.2132e-05,  2.0989e-06, -2.8841e-05,\n",
       "                      -6.4898e-06,  5.5858e-06,  3.1141e-06, -4.8956e-06, -7.8123e-06,\n",
       "                       1.3019e-06,  1.0751e-05, -1.9872e-05,  1.4185e-05,  1.9184e-05,\n",
       "                      -2.1530e-05,  1.4479e-05,  2.1295e-05, -1.0091e-05, -1.2123e-05,\n",
       "                      -4.9186e-06,  2.5457e-06, -5.5626e-06,  2.2077e-07, -1.5818e-05,\n",
       "                      -9.4985e-06,  1.2390e-05, -6.5742e-06, -4.6334e-06, -2.0278e-06,\n",
       "                      -3.0525e-06, -4.4899e-06, -6.5110e-06,  1.5640e-05,  9.6016e-06,\n",
       "                      -3.8675e-06,  9.9518e-06,  9.3398e-06,  7.4123e-06, -1.1731e-05,\n",
       "                      -8.2104e-06, -9.5115e-06, -3.3973e-06, -4.0556e-06, -1.0658e-05,\n",
       "                      -1.4509e-05,  2.2110e-05,  8.0925e-07,  1.4756e-05,  9.0053e-06,\n",
       "                      -3.4359e-06, -4.4677e-06, -1.7822e-06, -1.3005e-05, -1.3517e-05,\n",
       "                       1.6259e-05, -4.7014e-06, -8.7356e-06, -6.7677e-07,  1.5488e-05,\n",
       "                      -5.6666e-06, -4.0197e-06,  8.7348e-06, -6.6217e-06,  2.0163e-06,\n",
       "                       3.4504e-06, -7.3133e-06, -8.6196e-06,  6.1361e-06,  1.1035e-05,\n",
       "                       1.3948e-05,  9.1823e-06,  1.0121e-05,  4.3631e-06, -1.1018e-05,\n",
       "                      -8.7860e-06,  1.1358e-05,  1.4105e-05,  1.6605e-05, -1.7249e-05,\n",
       "                      -1.9136e-07,  5.9873e-06,  8.4071e-06, -8.9901e-06, -5.5589e-06,\n",
       "                       4.9634e-06, -7.8524e-06, -5.3248e-06,  1.9807e-05, -1.6503e-05,\n",
       "                       9.4166e-06,  6.9066e-06, -8.5433e-06,  2.9994e-06, -2.8097e-06,\n",
       "                      -2.7189e-05,  6.4151e-06, -1.2244e-05,  5.6847e-06, -5.6364e-06,\n",
       "                      -1.6330e-06, -1.2545e-06,  1.0316e-05,  1.4496e-05,  1.2129e-05,\n",
       "                       1.1116e-05,  4.1328e-06, -1.1332e-05,  3.8587e-06, -1.0591e-05,\n",
       "                      -1.4575e-06, -2.7460e-06,  9.7502e-09,  4.0198e-06,  2.8573e-06,\n",
       "                      -1.0807e-05, -1.0168e-05,  6.9058e-06,  8.4973e-06,  1.2796e-05,\n",
       "                      -6.8630e-06, -3.0286e-06,  1.3395e-05,  5.7577e-06, -6.8268e-07,\n",
       "                       5.6857e-06, -1.6506e-05, -1.4703e-06,  4.1138e-06, -8.2722e-06,\n",
       "                       8.3598e-06, -3.7493e-06,  7.0791e-06, -9.0113e-07,  1.6303e-03,\n",
       "                      -9.6012e-03, -5.4251e-04, -7.9567e-03,  2.0648e-02,  1.8485e-02,\n",
       "                      -2.5845e-04, -1.6929e-02, -1.5671e-02, -1.0191e-02,  6.3123e-03,\n",
       "                      -1.3405e-03,  3.1166e-02, -1.8430e-02, -3.2544e-03, -4.0480e-03,\n",
       "                       4.0280e-04,  3.3984e-04,  1.6234e-02, -2.1567e-03, -1.4890e-02,\n",
       "                      -7.9630e-03,  1.6148e-03, -1.0456e-02, -1.6454e-02, -1.2794e-02,\n",
       "                       7.7591e-03,  1.2401e-02, -7.8674e-03,  4.8117e-03, -2.7521e-02,\n",
       "                       5.3664e-03,  6.1583e-03,  1.0492e-02, -3.7021e-03, -1.1865e-02,\n",
       "                       1.2562e-02,  1.3275e-02,  1.1872e-02,  5.1559e-03, -1.3351e-02,\n",
       "                      -5.9799e-03, -1.3111e-02,  9.7624e-04, -2.5651e-02, -4.5339e-04,\n",
       "                       5.2899e-03, -1.0601e-02, -3.6222e-03, -1.1123e-02, -1.9616e-02,\n",
       "                      -4.8156e-03,  6.0370e-03,  8.0743e-03, -6.2176e-03,  4.4354e-05,\n",
       "                       6.1760e-03,  2.0883e-02, -1.8602e-02, -1.0920e-02, -1.0792e-02,\n",
       "                       6.0563e-03, -1.0085e-02,  9.5700e-03,  9.4747e-03,  1.1323e-02,\n",
       "                      -1.1852e-02,  3.3083e-03,  5.6840e-03, -1.0192e-02,  2.0097e-02,\n",
       "                      -1.3658e-02, -2.3602e-02, -9.2293e-03, -1.5105e-03, -1.1637e-03,\n",
       "                       5.3992e-03, -9.3063e-03,  2.1969e-03, -9.6324e-03,  8.6117e-03,\n",
       "                      -1.1540e-02,  5.4705e-03,  4.4957e-03, -1.6253e-02, -3.9632e-03,\n",
       "                       2.3247e-04, -2.7323e-03, -8.9022e-03,  9.7149e-03, -4.3621e-03,\n",
       "                      -8.9750e-03,  1.9970e-02,  1.7519e-04, -6.3800e-03,  5.2539e-03,\n",
       "                       4.1380e-03, -1.6113e-02, -2.4926e-02, -1.8221e-02,  3.0167e-03,\n",
       "                      -1.4001e-03, -5.5736e-03, -2.0499e-04, -4.2547e-03, -1.6165e-02,\n",
       "                       4.1057e-03,  3.8345e-03, -6.1370e-03, -1.2611e-02, -3.7280e-04,\n",
       "                      -1.2744e-03, -3.8480e-03,  1.6761e-02, -5.9505e-03,  3.1695e-03,\n",
       "                       1.7846e-02, -5.1126e-03, -1.4647e-02,  2.6612e-03, -4.3751e-03,\n",
       "                       8.5199e-03,  1.3615e-02, -3.1236e-03, -1.5956e-03,  3.4538e-02,\n",
       "                       1.0163e-02,  9.5487e-03, -9.4259e-03,  3.0504e-03, -9.4489e-03,\n",
       "                      -1.9994e-02, -4.1760e-03,  1.6245e-02,  5.4962e-03,  1.3091e-02,\n",
       "                       2.1879e-02, -3.4830e-02,  6.2942e-03, -1.6166e-02, -1.9049e-02,\n",
       "                      -8.9314e-03,  8.2999e-03,  3.4078e-03,  3.1725e-03, -4.0692e-03,\n",
       "                       6.8395e-03, -7.1589e-03, -3.0603e-03,  1.1652e-02,  1.1986e-02,\n",
       "                       1.2687e-02,  2.9401e-03,  1.8258e-02,  2.0876e-02,  1.5723e-02,\n",
       "                      -6.3720e-03, -1.2507e-02, -3.5083e-04,  1.3760e-04,  2.1818e-02,\n",
       "                       3.8723e-03, -1.0731e-02,  1.2925e-02,  6.9276e-03,  7.0941e-03,\n",
       "                       1.6803e-02,  8.9527e-03,  2.8582e-03,  1.6302e-03,  1.8747e-02,\n",
       "                      -2.5962e-02,  1.1765e-02,  2.2601e-02, -2.0326e-04,  4.0143e-03,\n",
       "                      -1.9114e-02, -2.4557e-02,  2.4854e-02, -2.4203e-02,  8.3314e-03,\n",
       "                       1.6553e-02,  9.2608e-04, -8.0551e-03,  1.6081e-02, -6.5435e-03,\n",
       "                      -1.4003e-03,  5.9490e-03, -3.6475e-03, -6.4959e-04, -2.2006e-02,\n",
       "                       1.8325e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.self_attn.out_proj.weight',\n",
       "              tensor([[ 0.0071, -0.0170,  0.0544,  ...,  0.0417, -0.0457,  0.0115],\n",
       "                      [ 0.0116, -0.0627,  0.0536,  ..., -0.0290,  0.0505, -0.0429],\n",
       "                      [ 0.0030, -0.0363,  0.0468,  ...,  0.0435,  0.0419,  0.0496],\n",
       "                      ...,\n",
       "                      [-0.0251, -0.0649,  0.0008,  ...,  0.0273, -0.0087, -0.0659],\n",
       "                      [-0.0135,  0.0043, -0.0222,  ...,  0.0163, -0.0711,  0.0409],\n",
       "                      [ 0.0986, -0.0893, -0.0425,  ..., -0.0275, -0.0433,  0.0447]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.self_attn.out_proj.bias',\n",
       "              tensor([ 4.5005e-02, -5.7770e-02,  2.2619e-02, -4.7946e-02,  1.2709e-02,\n",
       "                       4.0395e-03,  5.0262e-03,  1.8686e-02,  6.1701e-02,  1.5990e-02,\n",
       "                      -1.6832e-02,  1.3102e-02,  3.2107e-03,  8.3510e-03, -1.6098e-02,\n",
       "                      -5.0668e-03, -3.2309e-02,  1.7314e-02, -1.1023e-02,  5.4407e-02,\n",
       "                      -8.1607e-03, -2.3525e-02, -4.5785e-02, -1.1861e-02, -3.2681e-02,\n",
       "                       1.9470e-02, -3.5496e-02,  3.7925e-03,  3.4880e-02, -3.2732e-02,\n",
       "                      -3.4458e-02, -3.0290e-02, -5.9235e-03, -1.0048e-02, -4.7402e-02,\n",
       "                      -1.7985e-02, -1.9088e-02, -1.5136e-02, -8.5931e-03,  2.7678e-02,\n",
       "                      -3.9901e-02, -5.3573e-03, -1.4800e-02, -1.8086e-02, -1.7363e-02,\n",
       "                      -1.7534e-02,  2.3187e-02, -4.8089e-03,  2.2995e-02, -3.2562e-02,\n",
       "                       2.6960e-02, -9.6114e-03, -2.0635e-02,  1.2320e-02, -1.9474e-03,\n",
       "                       2.8542e-02,  6.2370e-03, -2.5571e-03, -4.9565e-03, -1.7610e-02,\n",
       "                      -1.1158e-02,  2.6874e-02, -4.2357e-02,  9.5133e-03, -8.9433e-02,\n",
       "                      -3.2635e-02,  8.6950e-03, -1.3292e-02,  1.1847e-02,  3.7086e-03,\n",
       "                       3.1326e-02,  2.4883e-02,  1.1376e-03, -1.1957e-02, -6.7654e-03,\n",
       "                       1.4580e-03, -1.1571e-03, -8.3807e-03,  1.4737e-02,  2.9075e-03,\n",
       "                       2.2689e-02,  1.8249e-02, -1.9737e-02,  4.0774e-02, -3.3194e-03,\n",
       "                      -3.7961e-03, -1.9316e-02,  8.0790e-02, -3.0340e-02, -4.2859e-03,\n",
       "                       4.0717e-02,  2.8951e-02, -1.7661e-02,  3.8694e-02,  3.1667e-02,\n",
       "                       3.5434e-02,  4.6041e-03,  7.7567e-04,  6.1045e-03, -3.5738e-02,\n",
       "                      -6.2822e-03, -1.1982e-02,  1.1408e-02,  4.7743e-03, -1.3419e-02,\n",
       "                       1.7808e-02, -7.2443e-03,  2.5336e-02, -1.9320e-02,  1.8701e-02,\n",
       "                       2.4112e-02, -1.0928e-02, -1.5588e-02, -3.1790e-02, -4.0040e-02,\n",
       "                       9.0055e-03,  1.4874e-02,  3.3433e-02, -8.2995e-03,  4.8370e-03,\n",
       "                       2.1514e-02, -1.2159e-03,  3.6464e-02,  2.1912e-02,  7.6836e-03,\n",
       "                       5.5695e-02,  8.7656e-03,  1.7148e-02, -2.9240e-02,  3.0324e-02,\n",
       "                       1.0201e-02,  4.1016e-02, -1.1358e-02,  3.1722e-03,  3.3864e-03,\n",
       "                       1.0282e-02, -9.5728e-03,  2.3971e-02,  1.2634e-02, -3.6492e-02,\n",
       "                       5.9735e-03,  3.5276e-02, -1.4573e-02, -3.4076e-03, -1.4085e-02,\n",
       "                      -1.4274e-02,  1.5589e-02, -8.6285e-04,  2.8017e-02, -2.8156e-03,\n",
       "                      -6.9918e-03,  3.4997e-02, -6.6776e-03, -2.0914e-02, -1.9886e-02,\n",
       "                      -1.6349e-03,  1.2484e-02,  1.2373e-02, -9.2129e-03,  2.1557e-02,\n",
       "                      -1.4658e-03, -3.2431e-02,  2.1798e-02,  5.5920e-02,  1.0223e-02,\n",
       "                      -1.2436e-03, -1.9993e-02,  3.5559e-02,  1.0937e-03,  1.6642e-02,\n",
       "                       2.2836e-02, -2.3831e-02,  1.2063e-02,  1.3795e-02,  1.5220e-02,\n",
       "                      -2.7483e-03,  1.0863e-02,  3.8898e-02, -2.4596e-02,  6.0935e-03,\n",
       "                      -2.9736e-02, -1.3506e-03,  2.2078e-02, -4.0607e-02,  1.0178e-02,\n",
       "                       1.5563e-02,  3.4041e-02, -3.2595e-02, -2.3743e-02,  3.5603e-02,\n",
       "                       4.0861e-05,  1.2753e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.in_proj_weight',\n",
       "              tensor([[-0.0510,  0.0235,  0.0390,  ...,  0.0022, -0.0389,  0.0308],\n",
       "                      [-0.0576,  0.1312,  0.0614,  ..., -0.0323, -0.0187,  0.0050],\n",
       "                      [ 0.0004,  0.0592, -0.0743,  ..., -0.0778, -0.0405,  0.0197],\n",
       "                      ...,\n",
       "                      [ 0.0793, -0.0213, -0.0250,  ..., -0.0374,  0.0299, -0.0058],\n",
       "                      [ 0.0236,  0.0140, -0.1080,  ..., -0.0605,  0.1349, -0.0244],\n",
       "                      [ 0.0547, -0.0423, -0.0525,  ...,  0.0670, -0.0364,  0.1099]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.in_proj_bias',\n",
       "              tensor([ 1.5719e-02, -6.5023e-02, -7.4259e-02, -3.2016e-02, -1.2725e-02,\n",
       "                      -1.6205e-02,  2.7985e-02,  4.2385e-02,  8.4327e-02, -4.9016e-02,\n",
       "                      -6.6608e-03, -1.7063e-03,  1.2185e-01,  1.1178e-01,  2.0014e-02,\n",
       "                       4.9659e-02,  1.0708e-01,  1.8618e-01,  1.7622e-01,  5.4289e-02,\n",
       "                       8.4650e-02,  1.2694e-03, -6.8204e-03, -1.7957e-01,  4.0825e-02,\n",
       "                      -5.8345e-02,  2.0193e-02, -1.4281e-01,  9.9162e-02,  1.6082e-02,\n",
       "                       3.8716e-03,  9.5413e-02,  2.1360e-02,  8.1995e-02, -3.2427e-03,\n",
       "                      -6.2873e-02,  5.1095e-02, -4.6009e-02,  4.1415e-02,  1.3450e-01,\n",
       "                       5.7405e-02, -1.6322e-01,  1.6365e-01, -1.0268e-01, -1.6924e-01,\n",
       "                       4.0478e-04,  1.1233e-01,  5.2837e-02, -4.8728e-02, -9.0370e-02,\n",
       "                       1.9675e-01,  1.4328e-01, -1.2257e-01,  1.1671e-01, -2.0108e-01,\n",
       "                      -5.3182e-02, -8.8471e-02,  9.9866e-02, -1.1494e-01,  1.8033e-01,\n",
       "                      -2.4498e-02,  1.4649e-01,  1.2888e-01, -1.3570e-01, -5.3837e-02,\n",
       "                       1.4408e-01,  1.2218e-01, -1.6364e-01,  1.6133e-01,  8.3091e-02,\n",
       "                      -1.6595e-01, -1.8332e-01,  1.5886e-02,  1.6835e-01, -9.5366e-02,\n",
       "                       2.0251e-01, -3.4824e-02,  1.7640e-01,  1.4353e-01,  1.4627e-01,\n",
       "                       8.7901e-02,  1.5454e-01, -5.5306e-02,  8.3272e-02, -1.8956e-01,\n",
       "                      -5.8504e-02,  6.4809e-02, -1.0490e-01,  1.4487e-01, -1.4120e-01,\n",
       "                       1.9036e-01, -1.5010e-01, -1.6259e-01, -1.1575e-02,  5.8022e-02,\n",
       "                       1.0943e-01,  1.2804e-01,  9.0255e-02,  6.8738e-02, -4.1632e-02,\n",
       "                       7.5363e-02,  5.9557e-02,  5.6483e-03,  8.4279e-02, -6.2927e-02,\n",
       "                      -9.7351e-02,  2.4894e-02, -3.0917e-02,  6.0600e-02, -1.3552e-01,\n",
       "                       2.6484e-02,  7.5328e-02,  3.3857e-02,  1.6079e-02,  6.9198e-02,\n",
       "                      -5.9800e-02,  1.2569e-01, -3.3195e-03,  7.0211e-02, -2.0361e-02,\n",
       "                      -2.3659e-02, -6.8085e-02, -8.2717e-03, -9.2561e-02,  6.4189e-02,\n",
       "                       5.4724e-02, -2.5061e-02, -6.9251e-02, -1.1177e-03, -1.5826e-02,\n",
       "                      -1.5914e-02, -1.4413e-02,  1.2587e-01,  1.4106e-01, -3.5848e-02,\n",
       "                       3.1298e-04,  4.9775e-02, -1.9188e-02,  5.2998e-03,  5.6199e-02,\n",
       "                      -3.0183e-02, -4.1522e-02,  5.5708e-02,  9.6429e-02,  1.0489e-01,\n",
       "                       1.8989e-01,  2.3053e-01,  5.4516e-03, -1.4345e-02,  6.4166e-02,\n",
       "                       8.1795e-02,  3.2163e-02, -1.9433e-01, -1.7814e-01,  1.5610e-01,\n",
       "                       4.6796e-02,  1.6577e-01, -1.7953e-01,  1.9409e-01, -3.2803e-02,\n",
       "                      -9.1183e-03, -1.3341e-01, -8.4511e-02,  1.3134e-01, -1.7424e-01,\n",
       "                      -7.4281e-02, -2.2600e-01,  1.0690e-01,  1.5900e-01,  1.0985e-01,\n",
       "                      -1.8252e-01,  6.8460e-02,  9.5344e-02, -7.9874e-02, -5.5933e-02,\n",
       "                      -1.1369e-02, -6.6311e-02, -1.5390e-01, -1.0869e-01,  2.5441e-02,\n",
       "                      -2.2509e-01,  1.0533e-01,  2.0403e-02, -1.1195e-01, -2.2535e-01,\n",
       "                       2.9697e-03,  3.1386e-02, -2.9968e-03,  3.7162e-02,  5.4720e-02,\n",
       "                      -1.1231e-01,  1.4205e-01, -6.5057e-06, -7.0764e-06,  3.7421e-06,\n",
       "                      -2.0166e-06, -1.2356e-05, -2.5593e-06, -3.1904e-06,  4.6997e-06,\n",
       "                      -7.7547e-06, -1.9689e-06, -1.0125e-05, -1.1658e-05, -1.0043e-05,\n",
       "                       1.4630e-05, -4.9768e-06,  7.2710e-07, -4.1527e-07, -5.7933e-06,\n",
       "                      -8.6928e-06,  7.2949e-06, -1.4098e-05, -7.5106e-06,  9.2135e-06,\n",
       "                       5.1398e-06, -1.5048e-06, -6.7764e-06,  7.6130e-07,  5.3331e-06,\n",
       "                      -1.3136e-06, -7.1179e-06, -7.4296e-06, -7.5033e-06, -5.0354e-06,\n",
       "                       2.3946e-06, -7.1851e-06, -3.7053e-06,  2.8297e-06, -2.2827e-06,\n",
       "                      -5.3683e-06,  3.3629e-06, -1.3121e-06, -7.6834e-06,  4.8597e-07,\n",
       "                      -5.3724e-06,  5.7536e-06, -7.2392e-06, -1.0158e-05, -5.1635e-07,\n",
       "                      -1.5685e-06,  8.0575e-06, -8.6190e-06, -4.0266e-06,  2.1771e-06,\n",
       "                       6.1807e-06, -1.0185e-05,  1.4256e-06, -6.6482e-06, -9.3988e-07,\n",
       "                       1.0484e-05,  6.2684e-06, -2.4461e-06,  1.2868e-06,  3.3807e-06,\n",
       "                      -9.6079e-06, -1.0451e-06,  5.6985e-06,  3.8938e-06,  1.5543e-06,\n",
       "                      -6.1950e-06,  4.7622e-06,  4.9368e-06,  5.3637e-06, -1.9757e-06,\n",
       "                       7.1534e-06,  9.4358e-06, -1.5044e-06, -7.6798e-06,  3.1864e-06,\n",
       "                      -3.3255e-06,  8.5677e-06,  1.8699e-06,  9.3920e-06,  4.2862e-06,\n",
       "                       3.6217e-06,  2.0951e-05,  5.9336e-06, -4.4011e-06, -1.2528e-05,\n",
       "                       1.5726e-05,  4.2865e-06, -8.0846e-06,  1.6137e-06, -5.2794e-06,\n",
       "                       3.8477e-06, -3.0863e-06,  1.4422e-06, -1.8195e-06, -2.7978e-06,\n",
       "                      -3.4908e-06,  3.9427e-06,  1.0204e-05, -4.6609e-07, -1.4795e-06,\n",
       "                       3.4507e-06, -1.5536e-06, -1.5025e-06, -3.8499e-06,  5.5031e-07,\n",
       "                      -2.5372e-06, -6.6340e-06, -6.9294e-06, -1.9167e-07, -1.9270e-06,\n",
       "                      -1.1534e-06,  2.3052e-06,  5.4208e-06,  8.7959e-07,  6.5298e-07,\n",
       "                       7.5313e-08,  2.5505e-06,  2.3096e-06,  8.8688e-06,  4.4825e-06,\n",
       "                       1.7142e-06, -5.5938e-06,  8.1063e-07, -1.6574e-07,  4.8960e-06,\n",
       "                       5.1882e-06, -7.9997e-06, -5.0402e-06, -8.2934e-06,  6.3917e-06,\n",
       "                       4.9754e-06,  6.7534e-06,  5.0178e-06, -1.7724e-06,  7.4930e-07,\n",
       "                      -6.2737e-06, -1.3607e-06,  6.1511e-07,  3.1505e-07,  5.0712e-07,\n",
       "                      -8.6979e-07,  3.1747e-07,  8.9290e-06, -3.5459e-07, -1.0801e-05,\n",
       "                      -1.1407e-05,  9.3820e-06, -5.8160e-07, -3.8076e-06, -9.3735e-06,\n",
       "                       4.5460e-06,  8.2010e-06,  2.8333e-06,  1.5056e-08, -1.2404e-05,\n",
       "                      -3.8821e-06, -3.2701e-07, -1.8181e-06, -6.9650e-06, -6.7588e-06,\n",
       "                      -1.7403e-06,  2.1445e-06,  3.8730e-06, -1.3280e-06,  3.7354e-06,\n",
       "                       1.1475e-05,  5.1851e-06, -2.6614e-06, -2.1292e-07,  5.7815e-07,\n",
       "                      -7.2227e-06,  4.9871e-06, -9.2567e-07, -4.4973e-06, -2.3517e-06,\n",
       "                      -1.2250e-06,  5.6164e-06,  5.9067e-06,  5.9379e-06,  4.6954e-06,\n",
       "                       6.9731e-07, -4.3795e-07, -2.2880e-06,  7.7874e-06, -5.1595e-06,\n",
       "                      -1.7105e-06, -5.5070e-06,  5.7244e-06,  5.4474e-06,  3.0089e-02,\n",
       "                       1.1338e-02,  3.9437e-02,  1.7516e-02,  1.7094e-03, -1.8524e-02,\n",
       "                       2.3037e-02, -4.1646e-02, -2.9902e-02,  1.4140e-02, -1.8229e-02,\n",
       "                       2.9954e-02, -6.1651e-03, -1.0826e-02,  3.9289e-02, -1.8914e-02,\n",
       "                      -4.3496e-02, -2.1388e-02,  2.5527e-02, -1.4475e-03, -3.5708e-02,\n",
       "                      -1.0787e-02,  2.8714e-02, -3.8172e-02, -1.9748e-02, -5.1771e-02,\n",
       "                       4.1120e-02, -5.5818e-02,  4.0496e-02,  5.4719e-02,  1.7898e-02,\n",
       "                      -1.6385e-02,  3.8480e-02, -6.0435e-02, -4.2043e-02,  1.4359e-02,\n",
       "                       3.5543e-02, -9.7380e-03, -6.5012e-03, -8.0451e-03, -4.4921e-03,\n",
       "                       1.0385e-02, -3.3786e-03,  7.0143e-02, -1.2088e-02,  9.3490e-03,\n",
       "                       6.8397e-03, -3.3300e-02,  4.8289e-02, -1.2607e-02,  4.5281e-02,\n",
       "                       4.0373e-02, -4.3526e-02, -8.5757e-03,  1.6170e-02, -4.7732e-02,\n",
       "                       5.9965e-03, -2.2384e-02,  2.7536e-02,  3.4251e-02, -4.3974e-02,\n",
       "                      -2.2144e-02,  5.8228e-03,  1.9570e-02, -4.9301e-02,  2.2661e-02,\n",
       "                       2.4072e-02, -3.3470e-02,  2.3383e-02, -2.6210e-02,  4.9462e-03,\n",
       "                       1.4282e-02, -1.5927e-02, -2.7038e-02,  1.0392e-02, -1.4839e-02,\n",
       "                      -1.1217e-02, -1.5057e-02,  2.9870e-02,  4.1216e-02, -3.2408e-02,\n",
       "                      -1.4546e-02, -5.5052e-02, -2.4855e-02,  4.1109e-02,  2.6727e-02,\n",
       "                       3.1205e-02, -2.5827e-02,  6.7742e-03, -1.2371e-02,  4.5097e-02,\n",
       "                       1.4142e-02,  2.5086e-02,  3.9702e-03, -2.9593e-02, -1.8877e-02,\n",
       "                       2.9677e-02,  2.1262e-02,  1.2180e-02,  4.0362e-02,  5.3087e-02,\n",
       "                       1.4109e-02, -2.5317e-02,  5.1055e-02, -2.2661e-02, -4.1945e-02,\n",
       "                      -5.4231e-02, -1.4030e-02, -1.9288e-02, -6.7270e-03,  4.3133e-03,\n",
       "                      -5.0349e-02,  5.0856e-02,  3.8530e-02,  2.0852e-02,  4.9339e-02,\n",
       "                      -1.9208e-02,  3.5886e-02,  1.1789e-02, -2.3316e-02,  2.9358e-02,\n",
       "                      -3.0367e-02,  2.1460e-02, -2.9498e-02, -1.1441e-02,  3.7770e-02,\n",
       "                       4.0026e-02, -3.9712e-02, -1.1151e-02, -4.9935e-02, -2.9651e-02,\n",
       "                      -1.1969e-02, -1.0445e-02,  1.9312e-02,  5.9869e-02,  4.3904e-02,\n",
       "                      -1.9319e-02, -4.9591e-02,  1.4821e-02, -2.2988e-02, -2.5593e-03,\n",
       "                       2.1945e-02,  1.1452e-02,  2.5535e-02,  2.5589e-03, -4.1116e-02,\n",
       "                      -4.6135e-03,  2.0691e-02, -6.2429e-03,  8.9878e-03,  5.2409e-03,\n",
       "                      -3.8400e-02, -7.2674e-03,  5.8039e-04,  1.3122e-02, -3.9467e-02,\n",
       "                      -2.0036e-02,  3.9264e-02, -2.0630e-02, -1.7365e-02, -2.7057e-03,\n",
       "                       9.6599e-03, -2.2532e-03,  1.6172e-02, -2.0917e-02,  2.0165e-02,\n",
       "                      -3.7379e-02,  1.0594e-02, -5.3276e-03,  1.7460e-02,  1.4661e-02,\n",
       "                      -1.3612e-03, -1.3143e-02, -3.8006e-03,  4.4998e-02,  2.1867e-02,\n",
       "                       3.3483e-02, -3.4989e-03,  1.8276e-02,  9.6856e-03,  1.0981e-02,\n",
       "                      -2.9643e-02,  4.7454e-03, -4.4657e-02,  2.6200e-02, -2.2193e-02,\n",
       "                      -1.6045e-02, -1.1433e-02, -1.4035e-02,  1.4923e-02, -3.3914e-03,\n",
       "                      -8.7830e-03], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.out_proj.weight',\n",
       "              tensor([[-0.0264, -0.0084,  0.0109,  ..., -0.0427,  0.1266,  0.0344],\n",
       "                      [-0.0119,  0.0977, -0.0310,  ..., -0.0671, -0.0113,  0.0943],\n",
       "                      [-0.0424, -0.1197,  0.0708,  ...,  0.0140,  0.0529,  0.0096],\n",
       "                      ...,\n",
       "                      [-0.0667,  0.0559, -0.0101,  ..., -0.0844, -0.0235,  0.0197],\n",
       "                      [ 0.0158,  0.0050,  0.0737,  ..., -0.0350, -0.0613, -0.0410],\n",
       "                      [ 0.0093,  0.0534, -0.0330,  ..., -0.0644, -0.0587, -0.0672]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.out_proj.bias',\n",
       "              tensor([ 2.0904e-02, -3.6296e-02, -7.8835e-03, -5.1018e-03, -2.2020e-02,\n",
       "                       1.8243e-02,  2.0913e-03, -3.3842e-02,  2.6335e-02,  9.0636e-03,\n",
       "                      -1.5588e-03,  3.0777e-03, -5.7296e-03, -1.8244e-02,  1.6449e-02,\n",
       "                      -3.7050e-03, -2.6354e-03, -3.5835e-03,  9.1720e-03,  2.6901e-02,\n",
       "                      -2.1391e-02,  1.7155e-03,  8.0978e-03,  5.0808e-03, -8.1524e-03,\n",
       "                      -5.3720e-03, -9.1375e-04,  2.8753e-02,  2.8714e-02,  7.4894e-03,\n",
       "                      -2.3505e-02,  2.6058e-03, -2.7097e-02, -1.7899e-02, -4.0675e-02,\n",
       "                      -1.7815e-02, -9.6137e-04,  9.1175e-03, -1.8800e-03,  1.7129e-02,\n",
       "                      -1.7099e-02, -4.9817e-03, -2.2179e-02, -2.5716e-03, -4.6505e-02,\n",
       "                      -1.4379e-03, -1.8797e-02,  7.4819e-03, -1.9169e-02,  3.2904e-03,\n",
       "                      -7.3656e-03,  3.7000e-03,  2.4859e-03, -6.6691e-05, -5.6468e-03,\n",
       "                       4.1991e-02, -3.5084e-02,  1.1769e-03,  2.1795e-02,  2.1057e-02,\n",
       "                       2.5820e-02,  1.8087e-02,  1.5780e-02,  3.4255e-02, -4.2019e-02,\n",
       "                      -2.0092e-03, -3.3550e-02, -7.3025e-05, -1.6785e-02, -3.0603e-04,\n",
       "                       8.4711e-03,  3.7302e-02, -1.1655e-02, -1.6676e-02, -1.0991e-02,\n",
       "                       2.4692e-02,  1.2275e-03,  5.0395e-03, -8.7636e-03,  1.6138e-02,\n",
       "                       1.4094e-02,  5.4869e-03, -2.3130e-02,  3.3993e-02, -4.6707e-03,\n",
       "                       3.9233e-02, -1.9759e-02,  8.0727e-02, -2.6531e-02, -2.6402e-02,\n",
       "                      -4.5838e-03,  1.3373e-02, -2.8444e-03,  1.9404e-02,  1.1335e-02,\n",
       "                       3.7114e-02,  3.7549e-03,  1.2272e-02,  5.1075e-03,  6.8545e-03,\n",
       "                      -6.1033e-03,  2.2125e-03, -9.9100e-03,  1.5353e-02, -4.2213e-02,\n",
       "                       2.4608e-02,  2.4468e-02,  2.6330e-02, -2.0711e-02,  2.1468e-02,\n",
       "                       2.0510e-02, -7.7880e-03,  1.6115e-02, -1.7265e-03, -3.0733e-02,\n",
       "                       2.7025e-02,  4.3766e-03,  2.2566e-02, -4.3188e-03, -6.6172e-03,\n",
       "                       5.5764e-03, -2.6051e-03,  1.9897e-02,  3.6237e-02, -1.8636e-02,\n",
       "                       2.6804e-02, -4.2881e-03,  1.0497e-02,  9.7343e-03,  4.3110e-02,\n",
       "                      -2.0788e-04,  2.7730e-02,  3.3249e-04,  4.4489e-03,  3.2401e-03,\n",
       "                       1.5728e-02, -1.3369e-02, -5.4831e-03, -4.5281e-03, -1.8961e-03,\n",
       "                      -2.5931e-02,  3.2226e-02, -2.3925e-02,  8.3698e-03, -2.1098e-02,\n",
       "                      -9.1900e-04,  4.9404e-03,  1.7156e-02,  1.2565e-02, -2.6390e-02,\n",
       "                      -2.3665e-02,  3.1074e-02, -1.7944e-02, -1.3680e-02, -4.7381e-02,\n",
       "                      -9.9717e-03,  1.9179e-02,  2.7189e-02, -2.1728e-03,  1.9534e-02,\n",
       "                      -3.2275e-02, -3.0420e-02, -4.7778e-03,  2.3953e-02, -1.6428e-02,\n",
       "                       2.1846e-02,  1.9485e-02,  3.5273e-02,  4.5470e-04,  1.6808e-02,\n",
       "                      -2.8650e-02,  8.0416e-03, -2.3454e-02,  4.0284e-02,  9.8438e-03,\n",
       "                      -2.9774e-02, -1.6604e-02,  4.0165e-02, -8.4055e-03, -4.4613e-03,\n",
       "                       8.2839e-03, -3.1439e-02,  5.1451e-03, -5.2206e-03,  5.6546e-03,\n",
       "                      -2.2619e-03, -1.6286e-02, -1.0356e-02, -3.1248e-02,  1.7470e-02,\n",
       "                      -2.0780e-02, -5.5476e-03], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear1.weight',\n",
       "              tensor([[ 0.0504,  0.0055, -0.0186,  ...,  0.0315, -0.0197,  0.0049],\n",
       "                      [-0.0415, -0.0060, -0.0021,  ...,  0.0308, -0.0030,  0.0122],\n",
       "                      [ 0.0020,  0.0323,  0.0387,  ..., -0.0270, -0.0628, -0.0952],\n",
       "                      ...,\n",
       "                      [-0.0364, -0.0565, -0.0524,  ...,  0.0619, -0.0237, -0.0261],\n",
       "                      [-0.0203,  0.0205,  0.0206,  ...,  0.0488,  0.0131, -0.0311],\n",
       "                      [-0.0199, -0.0565,  0.0026,  ...,  0.0409, -0.0237,  0.0592]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear1.bias',\n",
       "              tensor([-0.0242, -0.0738, -0.0703,  ..., -0.0637, -0.0254, -0.1045],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear2.weight',\n",
       "              tensor([[ 0.0407, -0.0163, -0.0402,  ...,  0.0033, -0.0159, -0.0044],\n",
       "                      [ 0.0535, -0.0424,  0.0337,  ..., -0.0392,  0.0355,  0.0015],\n",
       "                      [ 0.0340, -0.0130,  0.0208,  ..., -0.0171,  0.0216, -0.0292],\n",
       "                      ...,\n",
       "                      [ 0.0120,  0.0138, -0.0165,  ...,  0.0191, -0.0421, -0.0044],\n",
       "                      [ 0.0430, -0.0357,  0.0194,  ...,  0.0337, -0.0402,  0.0631],\n",
       "                      [ 0.0117,  0.0087,  0.0234,  ...,  0.0453, -0.0381, -0.0415]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear2.bias',\n",
       "              tensor([-0.0593,  0.0648,  0.0023,  0.0535,  0.0226,  0.0122,  0.0188,  0.0426,\n",
       "                      -0.0361, -0.0361,  0.0128,  0.0045, -0.0443,  0.0586, -0.0031,  0.0337,\n",
       "                       0.0360,  0.0098, -0.0133, -0.0164,  0.0541,  0.0435,  0.0094,  0.0255,\n",
       "                       0.0196,  0.0554, -0.0191, -0.0200, -0.0528,  0.0335,  0.0294, -0.0343,\n",
       "                      -0.0021,  0.0031,  0.0313,  0.0388, -0.0150,  0.0062,  0.0072, -0.0646,\n",
       "                       0.0396,  0.0384, -0.0321,  0.0113,  0.0357, -0.0401,  0.0092,  0.0107,\n",
       "                       0.0265, -0.0070, -0.0185,  0.0216,  0.0243, -0.0265,  0.0465, -0.0569,\n",
       "                       0.0457,  0.0141, -0.0238, -0.0367, -0.0237, -0.0651, -0.0339, -0.0417,\n",
       "                       0.0720,  0.0034,  0.0097, -0.0270, -0.0034, -0.0080, -0.0257, -0.0237,\n",
       "                       0.0390,  0.0051,  0.0313, -0.0394,  0.0031, -0.0124,  0.0261, -0.0414,\n",
       "                       0.0210, -0.0075, -0.0165, -0.0097,  0.0019, -0.0256,  0.0557, -0.0994,\n",
       "                       0.0632,  0.0436,  0.0091,  0.0008,  0.0108, -0.0382, -0.0076, -0.0345,\n",
       "                      -0.0041, -0.0655, -0.0157,  0.0029,  0.0295,  0.0089, -0.0063, -0.0376,\n",
       "                       0.0347, -0.0009,  0.0025, -0.0151,  0.0502, -0.0274, -0.0101, -0.0190,\n",
       "                      -0.0305,  0.0292,  0.0388, -0.0833,  0.0431, -0.0566,  0.0625, -0.0125,\n",
       "                      -0.0343, -0.0196, -0.0432, -0.0851,  0.0098, -0.0447,  0.0360, -0.0172,\n",
       "                       0.0253, -0.0719,  0.0321, -0.0618,  0.0097, -0.0004,  0.0162,  0.0122,\n",
       "                      -0.0092, -0.0200, -0.0183, -0.0253,  0.0440, -0.0472,  0.0652, -0.0365,\n",
       "                       0.0265, -0.0083, -0.0130, -0.0326, -0.0118,  0.0450,  0.0297, -0.0418,\n",
       "                       0.0632, -0.0308,  0.0790,  0.0477,  0.0165, -0.0370,  0.0019, -0.0569,\n",
       "                       0.0397,  0.0545, -0.0142, -0.0424,  0.0241, -0.0529,  0.0214, -0.0698,\n",
       "                      -0.0014, -0.0665,  0.0320, -0.0298,  0.0085, -0.0479, -0.0221,  0.0115,\n",
       "                       0.0378, -0.0738,  0.0567, -0.0145,  0.0060, -0.0011, -0.0271,  0.0269,\n",
       "                       0.0256, -0.0158, -0.0002,  0.0308,  0.0350, -0.0646,  0.0467,  0.0217],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm1.weight',\n",
       "              tensor([1.0122, 1.0732, 1.0125, 1.0210, 1.0419, 1.0138, 0.9997, 0.9772, 0.9951,\n",
       "                      1.0300, 0.9524, 1.0194, 0.9656, 1.0051, 0.9797, 1.0167, 1.0122, 0.9929,\n",
       "                      0.9762, 0.9869, 1.0062, 1.0185, 1.0091, 1.0150, 0.9800, 1.0136, 0.9989,\n",
       "                      0.9809, 1.0030, 0.9640, 0.9693, 0.9960, 0.9668, 1.0201, 0.9832, 0.9945,\n",
       "                      0.9349, 0.9979, 0.9513, 1.0317, 0.9487, 1.0099, 0.9532, 1.0094, 0.9604,\n",
       "                      0.9876, 0.9999, 0.9870, 0.9991, 0.9716, 0.9971, 0.9631, 1.0068, 0.9360,\n",
       "                      1.0292, 0.9317, 1.0063, 0.9248, 1.0179, 0.9477, 1.0142, 0.9318, 1.0214,\n",
       "                      0.9137, 1.0768, 0.9036, 1.0288, 0.8940, 1.0545, 0.8833, 1.0464, 0.9185,\n",
       "                      1.0753, 0.9014, 1.0653, 0.9105, 1.0339, 0.9169, 1.0686, 0.9421, 1.0594,\n",
       "                      0.9258, 0.9851, 0.9194, 1.0410, 0.9125, 1.0941, 0.9806, 1.0655, 0.8837,\n",
       "                      1.0784, 0.9110, 1.0630, 0.9186, 1.0332, 0.9188, 1.0714, 0.8587, 1.0477,\n",
       "                      0.8790, 1.0546, 0.9161, 1.0712, 0.8889, 1.0803, 0.9000, 1.0678, 0.9159,\n",
       "                      1.0430, 0.8937, 1.0413, 0.9287, 1.0302, 0.8803, 1.0467, 0.9223, 1.0748,\n",
       "                      0.9033, 1.0590, 0.9242, 1.0510, 0.9030, 1.1041, 0.9772, 1.0555, 0.9036,\n",
       "                      1.0430, 0.9185, 1.0606, 0.9328, 1.0745, 0.8873, 1.0444, 0.9406, 1.0735,\n",
       "                      0.9098, 1.0662, 0.9133, 1.0484, 0.9219, 1.0408, 0.9180, 1.0523, 0.9104,\n",
       "                      1.0890, 0.9043, 1.0655, 0.9031, 1.0411, 0.8859, 1.0664, 0.9345, 1.0536,\n",
       "                      0.9042, 1.0687, 0.9107, 1.0676, 0.9206, 1.0770, 0.9249, 1.0646, 0.9140,\n",
       "                      1.0554, 0.9444, 1.0579, 0.8974, 1.0733, 0.9318, 1.0696, 0.9192, 1.0699,\n",
       "                      0.9183, 1.0461, 0.8980, 1.0579, 0.9057, 1.0620, 0.9138, 1.0648, 0.9078,\n",
       "                      1.0314, 0.8800, 1.0751, 0.8980, 1.0852, 0.9375, 1.0621, 0.9114, 1.0517,\n",
       "                      0.9108, 1.0575, 0.8997], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm1.bias',\n",
       "              tensor([ 0.1107, -0.1105,  0.0496, -0.0711, -0.0341, -0.0068, -0.0040, -0.0071,\n",
       "                       0.1108,  0.0745, -0.0282,  0.0257, -0.0214, -0.0482,  0.0447, -0.0122,\n",
       "                      -0.0516,  0.0527,  0.0271,  0.1116, -0.0979, -0.0502, -0.0666, -0.0212,\n",
       "                      -0.0298,  0.0120,  0.0105, -0.0026,  0.1012, -0.0616, -0.0766, -0.0177,\n",
       "                      -0.0647, -0.0232, -0.1045, -0.1019, -0.0128, -0.0210,  0.0015,  0.0742,\n",
       "                      -0.1152, -0.0361, -0.0178, -0.0401, -0.1391,  0.0491,  0.0402,  0.0449,\n",
       "                      -0.0142, -0.0738,  0.0123, -0.0344, -0.0853,  0.0185, -0.0318,  0.1416,\n",
       "                      -0.0769,  0.0086,  0.0450,  0.0627,  0.0608,  0.0846,  0.0451,  0.0763,\n",
       "                      -0.1909, -0.0391, -0.0807,  0.0162, -0.0203, -0.0602,  0.0529,  0.0860,\n",
       "                      -0.0598, -0.0744, -0.0359,  0.0775, -0.0142,  0.0135, -0.0017,  0.0920,\n",
       "                       0.0179, -0.0025,  0.0311,  0.1181, -0.0474,  0.0281, -0.1158,  0.2363,\n",
       "                      -0.1158, -0.0379, -0.0127,  0.0199,  0.0235,  0.1015,  0.1062,  0.1071,\n",
       "                       0.0157,  0.0700,  0.0134, -0.0070, -0.0442, -0.0338, -0.0091,  0.0182,\n",
       "                      -0.1253,  0.0119,  0.0025,  0.0746, -0.0627,  0.0907,  0.0853,  0.0460,\n",
       "                       0.0127, -0.0586, -0.0785,  0.0717, -0.0135,  0.1364, -0.0514, -0.0420,\n",
       "                       0.0746,  0.0532,  0.0724,  0.0705,  0.0064,  0.0954, -0.0350, -0.0228,\n",
       "                      -0.0019,  0.1074, -0.0501,  0.1210, -0.0309, -0.0090,  0.0117,  0.0397,\n",
       "                      -0.0191,  0.0781,  0.0157, -0.0224, -0.0531,  0.1213, -0.0753,  0.0318,\n",
       "                      -0.0489, -0.0286, -0.0240,  0.0443,  0.0576, -0.0560, -0.0525,  0.0670,\n",
       "                      -0.0253,  0.0133, -0.1166, -0.0552,  0.0496,  0.0752,  0.0044,  0.0562,\n",
       "                      -0.0612, -0.0961,  0.0582,  0.1190, -0.0170,  0.0406, -0.0037,  0.0483,\n",
       "                      -0.0307,  0.0424, -0.0927,  0.0434, -0.0154,  0.0824,  0.0781, -0.0372,\n",
       "                      -0.0501,  0.0865, -0.0628,  0.0427, -0.0351, -0.0664,  0.0587, -0.0522,\n",
       "                      -0.0056,  0.0581,  0.0198, -0.0723, -0.1109,  0.0646, -0.0722,  0.0223],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm2.weight',\n",
       "              tensor([1.0179, 1.0780, 1.0126, 1.0245, 1.0368, 1.0148, 1.0004, 0.9973, 0.9954,\n",
       "                      1.0242, 0.9610, 1.0176, 0.9661, 1.0038, 0.9771, 1.0069, 1.0138, 0.9862,\n",
       "                      0.9822, 0.9989, 1.0134, 1.0158, 1.0164, 1.0063, 0.9849, 1.0131, 0.9946,\n",
       "                      0.9769, 1.0073, 0.9663, 0.9743, 1.0026, 0.9754, 1.0182, 1.0050, 1.0075,\n",
       "                      0.9494, 0.9891, 0.9623, 1.0261, 0.9676, 1.0208, 0.9640, 1.0114, 0.9900,\n",
       "                      0.9900, 1.0026, 0.9848, 0.9980, 0.9749, 1.0175, 0.9707, 1.0124, 0.9466,\n",
       "                      1.0244, 0.9471, 1.0200, 0.9237, 1.0246, 0.9495, 1.0107, 0.9368, 1.0245,\n",
       "                      0.9377, 1.0849, 0.9113, 1.0276, 0.9026, 1.0566, 0.9028, 1.0459, 0.9296,\n",
       "                      1.0689, 0.9119, 1.0572, 0.9257, 1.0365, 0.9196, 1.0682, 0.9518, 1.0529,\n",
       "                      0.9270, 0.9998, 0.9432, 1.0373, 0.9161, 1.0907, 1.0134, 1.0677, 0.8848,\n",
       "                      1.0799, 0.8987, 1.0636, 0.9392, 1.0497, 0.9317, 1.0644, 0.9099, 1.0361,\n",
       "                      0.9083, 1.0636, 0.9178, 1.0551, 0.9057, 1.0758, 0.9163, 1.0595, 0.9243,\n",
       "                      1.0533, 0.9081, 1.0497, 0.9409, 1.0353, 0.9191, 1.0395, 0.9340, 1.0625,\n",
       "                      0.9380, 1.0580, 0.9292, 1.0476, 0.9215, 1.0977, 0.9766, 1.0637, 0.9124,\n",
       "                      1.0480, 0.9320, 1.0593, 0.9379, 1.0677, 0.9058, 1.0523, 0.9471, 1.0738,\n",
       "                      0.9203, 1.0599, 0.9117, 1.0487, 0.9261, 1.0460, 0.9576, 1.0513, 0.9157,\n",
       "                      1.0760, 0.9118, 1.0646, 0.9294, 1.0426, 0.9058, 1.0636, 0.9399, 1.0513,\n",
       "                      0.9161, 1.0795, 0.9241, 1.0698, 0.9350, 1.0667, 0.9393, 1.0637, 0.9291,\n",
       "                      1.0588, 0.9559, 1.0590, 0.9056, 1.0649, 0.9282, 1.0616, 0.9335, 1.0678,\n",
       "                      0.9228, 1.0520, 0.9031, 1.0559, 0.9199, 1.0595, 0.9272, 1.0650, 0.9128,\n",
       "                      1.0262, 0.9000, 1.0648, 0.8981, 1.0777, 0.9428, 1.0665, 0.9076, 1.0513,\n",
       "                      0.9087, 1.0690, 0.9085], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm2.bias',\n",
       "              tensor([ 0.1014, -0.1061,  0.0455, -0.0666, -0.0225, -0.0088, -0.0059, -0.0009,\n",
       "                       0.0996,  0.0780, -0.0276,  0.0248, -0.0255, -0.0378,  0.0368, -0.0152,\n",
       "                      -0.0538,  0.0463,  0.0192,  0.1225, -0.0884, -0.0507, -0.0788, -0.0237,\n",
       "                      -0.0378,  0.0237,  0.0039, -0.0089,  0.0932, -0.0682, -0.0835, -0.0252,\n",
       "                      -0.0596, -0.0267, -0.1022, -0.1000, -0.0265, -0.0375, -0.0025,  0.0681,\n",
       "                      -0.1205, -0.0338, -0.0247, -0.0453, -0.1385,  0.0407,  0.0401,  0.0434,\n",
       "                      -0.0108, -0.0830,  0.0135, -0.0395, -0.0824,  0.0023, -0.0366,  0.1196,\n",
       "                      -0.0691,  0.0036,  0.0386,  0.0525,  0.0614,  0.0708,  0.0419,  0.0557,\n",
       "                      -0.1815, -0.0453, -0.0672,  0.0109, -0.0235, -0.0705,  0.0541,  0.0686,\n",
       "                      -0.0597, -0.0829, -0.0309,  0.0649, -0.0150,  0.0047,  0.0010,  0.0715,\n",
       "                       0.0136, -0.0232,  0.0495,  0.1002, -0.0482,  0.0010, -0.1133,  0.2212,\n",
       "                      -0.1045, -0.0366, -0.0113, -0.0070,  0.0272,  0.0853,  0.1088,  0.0785,\n",
       "                       0.0104,  0.0586,  0.0203, -0.0089, -0.0409, -0.0498, -0.0135,  0.0030,\n",
       "                      -0.1149, -0.0031, -0.0124,  0.0541, -0.0558,  0.0746,  0.0801,  0.0359,\n",
       "                       0.0117, -0.0725, -0.0714,  0.0500, -0.0162,  0.1242, -0.0445, -0.0558,\n",
       "                       0.0707,  0.0431,  0.0680,  0.0546,  0.0152,  0.0749, -0.0323, -0.0346,\n",
       "                      -0.0044,  0.0859, -0.0531,  0.1042, -0.0277, -0.0171,  0.0126,  0.0321,\n",
       "                      -0.0116,  0.0734,  0.0210, -0.0457, -0.0493,  0.0997, -0.0695,  0.0197,\n",
       "                      -0.0376, -0.0389, -0.0258,  0.0323,  0.0549, -0.0537, -0.0480,  0.0431,\n",
       "                      -0.0185,  0.0071, -0.1089, -0.0722,  0.0471,  0.0525,  0.0004,  0.0380,\n",
       "                      -0.0500, -0.0884,  0.0599,  0.1011, -0.0150,  0.0241, -0.0125,  0.0295,\n",
       "                      -0.0248,  0.0204, -0.0919,  0.0168, -0.0124,  0.0682,  0.0804, -0.0443,\n",
       "                      -0.0452,  0.0596, -0.0648,  0.0405, -0.0365, -0.0617,  0.0548, -0.0661,\n",
       "                      -0.0099,  0.0466,  0.0256, -0.0793, -0.1022,  0.0429, -0.0657,  0.0170],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm3.weight',\n",
       "              tensor([0.9704, 0.9299, 0.9906, 0.9871, 0.9566, 1.0009, 0.9909, 0.9906, 0.9556,\n",
       "                      0.9729, 0.9873, 0.9965, 0.9713, 1.0177, 0.9836, 1.0138, 0.9997, 1.0266,\n",
       "                      0.9871, 0.9951, 1.0052, 0.9767, 1.0150, 1.0148, 0.9912, 0.9958, 0.9466,\n",
       "                      0.9665, 0.9432, 0.9599, 1.0083, 0.9962, 0.9882, 1.0278, 0.9524, 1.0219,\n",
       "                      0.9347, 1.0097, 1.0020, 1.0014, 1.0170, 1.0301, 0.9876, 1.0356, 0.9579,\n",
       "                      1.0341, 1.0085, 0.9933, 1.0325, 0.9722, 0.9999, 1.0307, 1.0152, 0.9656,\n",
       "                      1.0010, 0.9552, 1.0033, 0.9582, 1.0234, 0.9963, 0.9959, 0.9948, 1.0433,\n",
       "                      0.9546, 0.9508, 0.9521, 1.0146, 0.9707, 1.0278, 0.9685, 1.0417, 0.9564,\n",
       "                      1.0150, 1.0045, 1.0417, 0.9766, 1.0236, 1.0021, 1.0576, 0.9780, 1.0302,\n",
       "                      0.9388, 0.9841, 0.9510, 1.0077, 1.0176, 1.0340, 0.8882, 0.9906, 0.9648,\n",
       "                      1.0379, 0.9292, 1.0169, 0.9412, 1.0340, 0.9455, 1.0523, 0.9684, 1.0751,\n",
       "                      0.9692, 1.0397, 0.9625, 1.0200, 0.9849, 1.0261, 0.9567, 1.0339, 0.9725,\n",
       "                      0.9883, 0.9726, 1.0254, 0.9565, 0.9767, 0.9881, 0.9972, 0.9585, 1.0063,\n",
       "                      0.9301, 1.0600, 0.9656, 1.0346, 0.9806, 1.0373, 0.9476, 1.0638, 0.9389,\n",
       "                      1.0426, 0.9996, 1.0355, 0.9510, 1.0236, 0.9602, 0.9650, 1.0166, 1.0684,\n",
       "                      0.9755, 1.0366, 0.9692, 1.0366, 0.9113, 0.9994, 0.9517, 1.0284, 0.9968,\n",
       "                      1.0168, 0.9740, 1.0417, 0.9682, 1.0064, 0.9483, 1.0214, 0.8978, 1.0285,\n",
       "                      1.0042, 0.9877, 0.9764, 1.0640, 0.9491, 1.0285, 0.9888, 1.0234, 0.9234,\n",
       "                      1.0143, 0.9336, 1.0299, 0.9573, 1.0374, 0.9343, 1.0366, 0.9737, 1.0612,\n",
       "                      0.9878, 1.0303, 0.9684, 1.0386, 0.9614, 1.0201, 0.9445, 1.0575, 0.9753,\n",
       "                      0.9903, 0.9470, 1.0381, 0.9586, 1.0582, 1.0133, 1.0631, 0.9656, 0.9376,\n",
       "                      0.9516, 1.0466, 0.9843], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm3.bias',\n",
       "              tensor([ 0.0529, -0.0911,  0.0329, -0.0132,  0.0664, -0.0029,  0.0616,  0.0147,\n",
       "                       0.0431,  0.1139,  0.0084,  0.0243,  0.1082, -0.0237,  0.0654, -0.0247,\n",
       "                      -0.0440,  0.0400,  0.0214,  0.0937, -0.0573, -0.0013, -0.0126,  0.0333,\n",
       "                      -0.0606,  0.0376,  0.0162,  0.0690,  0.0361, -0.0089, -0.0672,  0.0823,\n",
       "                      -0.0204, -0.0596, -0.0441, -0.0544, -0.0791, -0.0370, -0.0289,  0.0339,\n",
       "                      -0.0481, -0.0240,  0.0173, -0.0358, -0.0630,  0.0040,  0.0222, -0.0208,\n",
       "                      -0.0569, -0.0605,  0.0126, -0.0439, -0.0294, -0.0367, -0.0366,  0.0320,\n",
       "                      -0.0375, -0.0785,  0.0285,  0.0224,  0.0989, -0.0199,  0.0328,  0.0051,\n",
       "                      -0.0123, -0.0303, -0.0282, -0.0178,  0.0178, -0.0466,  0.0882,  0.0036,\n",
       "                       0.0284, -0.0623, -0.0882, -0.0007,  0.0608, -0.0239,  0.0135, -0.0408,\n",
       "                       0.0091, -0.0628,  0.0785,  0.0049, -0.0107, -0.0059, -0.0565,  0.0932,\n",
       "                      -0.0017, -0.0661, -0.0071, -0.0885,  0.0305,  0.0094,  0.0466, -0.0492,\n",
       "                       0.0611,  0.0378,  0.0952, -0.0158,  0.0466, -0.0963,  0.0065,  0.0155,\n",
       "                      -0.0525, -0.0753,  0.0405, -0.0970,  0.0085, -0.0202,  0.0352, -0.0183,\n",
       "                       0.1410, -0.0673,  0.0349, -0.0435,  0.0050,  0.0497,  0.0345, -0.0938,\n",
       "                       0.0698,  0.0010,  0.1195,  0.0386,  0.0402, -0.0186,  0.0223, -0.0609,\n",
       "                       0.0132,  0.0059, -0.0640,  0.0218,  0.1428, -0.0804,  0.0660, -0.0976,\n",
       "                      -0.0011, -0.0046,  0.1008, -0.1065,  0.0060, -0.0158, -0.0553, -0.0149,\n",
       "                       0.0440, -0.0690,  0.0309, -0.0206,  0.0804, -0.0607, -0.0064, -0.0962,\n",
       "                      -0.0244,  0.0118, -0.0059, -0.1390,  0.0514,  0.0225,  0.0490,  0.0075,\n",
       "                       0.0084, -0.0225,  0.0754, -0.0261, -0.0165,  0.0044,  0.0245, -0.0490,\n",
       "                      -0.0124,  0.0130, -0.0293, -0.0210,  0.0605, -0.0185,  0.1439, -0.1134,\n",
       "                       0.0602, -0.0202, -0.0148,  0.0211,  0.0202, -0.0560,  0.0824, -0.0446,\n",
       "                       0.0396, -0.0311,  0.0298, -0.0469, -0.0192, -0.0154, -0.0183, -0.0422],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.in_proj_weight',\n",
       "              tensor([[-0.1119,  0.0588,  0.0002,  ...,  0.0133, -0.0133,  0.0116],\n",
       "                      [ 0.0301, -0.0270, -0.1334,  ..., -0.0421,  0.0298, -0.0486],\n",
       "                      [-0.0188,  0.0825, -0.0291,  ..., -0.1244, -0.0764, -0.0075],\n",
       "                      ...,\n",
       "                      [ 0.0014,  0.0188,  0.0348,  ..., -0.0706,  0.0439,  0.0133],\n",
       "                      [-0.0917,  0.0005,  0.0726,  ...,  0.0730,  0.0314,  0.0048],\n",
       "                      [-0.1028, -0.0489,  0.1067,  ..., -0.0096, -0.0822,  0.0110]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.in_proj_bias',\n",
       "              tensor([-4.6883e-02, -1.7689e-02, -3.5032e-02,  1.9831e-02, -4.0250e-03,\n",
       "                       6.4847e-02,  4.4583e-02, -1.7099e-03, -1.2833e-02,  1.2622e-03,\n",
       "                      -2.2965e-02, -1.9850e-02,  2.0853e-03, -2.4800e-02, -6.0025e-02,\n",
       "                      -4.0198e-03,  6.5970e-02, -1.9065e-03, -5.2621e-02, -5.6490e-02,\n",
       "                       9.1652e-02,  3.0203e-02, -5.5018e-03,  3.0497e-02, -6.4178e-02,\n",
       "                       8.2146e-02,  3.5095e-02,  3.9055e-03,  3.0006e-02, -5.3455e-02,\n",
       "                       7.8429e-02,  2.2789e-02, -3.7786e-03, -6.5885e-02,  6.2286e-02,\n",
       "                       5.3171e-02, -3.7818e-02,  3.8454e-02, -1.0112e-01, -2.0054e-02,\n",
       "                       4.3922e-02,  4.9698e-03, -6.7393e-03, -3.9034e-02, -1.1273e-03,\n",
       "                       7.6299e-02, -3.0213e-02, -4.7463e-03, -2.6794e-02,  2.8705e-02,\n",
       "                       6.7507e-02, -3.5129e-02, -3.1392e-02, -1.6337e-02, -2.5238e-02,\n",
       "                       1.0285e-01, -1.3067e-02, -9.6286e-03,  1.6271e-02,  5.8257e-02,\n",
       "                      -1.0560e-02,  9.2034e-02, -2.2250e-02, -9.0629e-02, -3.8578e-02,\n",
       "                      -1.4965e-02,  2.8649e-02,  6.5088e-02, -5.0830e-02,  9.4831e-02,\n",
       "                      -5.7366e-02,  4.7760e-02, -7.0443e-02, -8.0418e-02,  2.1831e-07,\n",
       "                      -1.0751e-02,  1.0435e-01,  4.5741e-02, -8.8505e-02, -2.7445e-02,\n",
       "                       2.2839e-02, -1.5149e-02, -2.7207e-02,  3.4977e-03,  4.9749e-02,\n",
       "                      -4.2513e-02, -1.1560e-02,  3.0572e-02, -4.0768e-03, -8.4038e-02,\n",
       "                       1.8262e-02,  6.3885e-02, -5.3466e-02,  7.1422e-04,  9.0777e-02,\n",
       "                       9.3107e-02,  3.4152e-02,  4.4870e-03, -5.1810e-02,  1.2621e-01,\n",
       "                      -3.2467e-02, -3.7477e-02, -6.9751e-02,  4.9383e-02, -5.6180e-02,\n",
       "                       5.6727e-02,  1.1718e-02, -2.7198e-03,  2.1034e-02, -6.5690e-02,\n",
       "                       1.6238e-03,  7.2895e-02, -1.3576e-02,  2.0290e-02,  4.0003e-02,\n",
       "                      -1.6992e-02,  3.6560e-02,  6.2649e-02,  5.2250e-02, -8.7838e-02,\n",
       "                      -2.9428e-02, -3.6050e-02, -3.2043e-02, -5.7541e-02, -3.6915e-03,\n",
       "                       1.8416e-02, -4.0111e-02, -3.0585e-03,  8.1765e-02, -6.9614e-03,\n",
       "                       3.0550e-02,  7.6814e-02, -2.5128e-03,  3.5678e-03, -7.4245e-03,\n",
       "                       4.9970e-02,  2.0363e-02,  7.4293e-02, -3.9016e-02, -6.8782e-02,\n",
       "                      -1.9240e-02, -4.9059e-02,  2.3087e-02, -7.5147e-02, -9.5646e-03,\n",
       "                      -6.2987e-02, -4.3627e-02,  1.5153e-02, -6.0074e-02, -8.8119e-02,\n",
       "                       4.4028e-02, -3.2256e-02,  2.4366e-02,  4.6890e-03, -1.5686e-02,\n",
       "                       7.6131e-02, -7.9720e-02,  6.8249e-02, -5.9612e-02, -5.6961e-02,\n",
       "                       4.0447e-02, -5.4531e-02,  1.1257e-02, -6.4836e-02,  3.2665e-02,\n",
       "                      -1.1279e-02, -6.8678e-02,  8.1423e-02,  6.4479e-03,  8.7029e-02,\n",
       "                       6.6353e-03, -4.0897e-02, -4.7400e-02, -2.1320e-02, -9.2970e-03,\n",
       "                       1.2130e-02, -4.1210e-02,  5.4055e-02,  1.6114e-02,  4.8390e-02,\n",
       "                       6.8868e-02,  7.2520e-02, -7.9469e-02,  8.9908e-02, -2.6710e-02,\n",
       "                      -2.5450e-02, -4.7421e-02,  9.1955e-02,  4.6766e-02, -5.6362e-02,\n",
       "                      -5.1963e-02, -9.0686e-02,  6.7066e-07, -6.8542e-06, -1.0412e-05,\n",
       "                       1.8717e-05,  4.9458e-06,  1.5089e-05,  3.6870e-06, -7.0318e-06,\n",
       "                       8.5687e-06, -1.4225e-05, -2.8814e-06, -8.9961e-07, -1.9802e-05,\n",
       "                      -2.2285e-06, -9.2259e-06,  1.2833e-05, -4.3311e-07, -4.9876e-06,\n",
       "                       1.2974e-05, -1.2378e-05,  4.4406e-06,  8.1023e-06, -1.6453e-05,\n",
       "                       8.8154e-06, -2.1751e-06,  1.6634e-06,  5.0101e-07,  1.4763e-05,\n",
       "                      -8.9392e-06, -1.1927e-05,  7.3410e-07, -1.8079e-06, -1.0112e-06,\n",
       "                       2.1312e-06, -1.3294e-06,  6.4454e-06,  1.5292e-05, -2.2782e-06,\n",
       "                       1.4620e-05,  2.3917e-06,  3.5869e-06,  5.1180e-06,  1.4277e-05,\n",
       "                       1.6190e-06,  9.3059e-06,  3.4910e-06,  1.3219e-05, -8.7786e-06,\n",
       "                      -8.9638e-06,  3.2758e-05, -5.6812e-06,  1.2096e-05, -1.8322e-06,\n",
       "                       1.1415e-05, -5.2610e-06, -9.1960e-06,  2.4595e-06,  5.8087e-06,\n",
       "                      -1.4308e-05, -7.9415e-06, -8.2228e-06, -3.2715e-05, -1.0647e-05,\n",
       "                       8.8445e-07, -4.0231e-06,  2.3951e-06, -4.1686e-06,  2.3579e-05,\n",
       "                      -1.4601e-06, -2.3998e-05, -1.1285e-05, -6.9366e-06,  2.5404e-06,\n",
       "                      -1.5187e-05,  5.0074e-07,  7.5442e-06, -2.2652e-06, -2.2262e-05,\n",
       "                       6.0181e-07,  1.2068e-05,  2.6521e-06, -6.1183e-06,  1.9119e-05,\n",
       "                       4.4352e-06, -1.0421e-05,  2.3038e-06, -5.9336e-06,  6.2893e-06,\n",
       "                      -5.2309e-06,  9.0303e-06,  4.5187e-06,  8.7036e-06, -1.2103e-06,\n",
       "                      -7.0735e-06, -1.0518e-05,  1.6272e-05, -1.2516e-05,  4.7558e-06,\n",
       "                       1.0142e-05,  6.8331e-06, -1.1170e-05,  7.9071e-06,  8.7836e-06,\n",
       "                      -4.0817e-06,  9.5960e-06, -1.0453e-05,  1.0371e-05,  5.9365e-07,\n",
       "                      -8.8530e-06, -8.3707e-06,  2.0282e-07,  1.5774e-05, -1.5736e-06,\n",
       "                      -5.3639e-06,  1.4631e-05, -9.6260e-07, -1.7075e-05, -5.5270e-06,\n",
       "                      -1.3181e-05,  4.0289e-06,  8.6837e-06,  1.2179e-05,  9.3846e-06,\n",
       "                       6.7348e-06,  1.5191e-05, -3.7660e-06,  7.4114e-06, -1.4243e-06,\n",
       "                      -1.2655e-05, -4.4605e-06, -3.9999e-06, -1.1263e-05,  8.2569e-07,\n",
       "                       2.6240e-06,  1.5060e-05, -4.3887e-06, -5.5399e-06, -1.1687e-05,\n",
       "                       2.3589e-06,  8.1158e-06,  6.9327e-07, -1.2371e-06,  6.4682e-06,\n",
       "                      -1.8930e-06, -2.3744e-06, -5.3860e-06, -7.1082e-06, -7.0457e-06,\n",
       "                      -1.2718e-05,  1.5667e-06,  1.3732e-05,  5.2376e-07,  2.6724e-06,\n",
       "                       2.7801e-06, -1.3938e-05, -6.9093e-06,  6.9195e-06,  1.4301e-05,\n",
       "                       3.2901e-06,  1.3307e-05, -1.8844e-06, -6.1952e-06, -4.8320e-06,\n",
       "                      -5.0136e-06,  6.3665e-06,  5.6536e-06,  2.8044e-05, -6.4470e-06,\n",
       "                       6.2553e-06,  3.4509e-06,  7.7146e-06,  6.3251e-06, -1.6008e-05,\n",
       "                      -2.3275e-05, -8.8323e-07, -1.6839e-05,  1.0590e-05,  7.6439e-06,\n",
       "                      -1.8164e-06, -1.0996e-05, -3.3013e-06, -6.5375e-09,  1.1906e-05,\n",
       "                       7.7347e-06,  7.0320e-06,  1.2623e-06,  4.8321e-06,  7.8364e-06,\n",
       "                      -1.3552e-05, -1.5539e-05, -1.9772e-06, -1.4583e-05, -1.4083e-02,\n",
       "                       1.1176e-02,  9.7251e-03,  1.5138e-02, -6.0981e-03,  7.6033e-03,\n",
       "                      -2.9974e-02, -1.1989e-02,  8.4238e-03,  1.7924e-02, -1.1342e-02,\n",
       "                       1.7498e-02,  1.7233e-02,  2.4611e-02, -3.2326e-03, -6.2816e-03,\n",
       "                      -2.0022e-02, -7.6461e-03,  1.8008e-02,  5.6165e-03,  1.1291e-02,\n",
       "                       4.6782e-03,  1.9247e-02,  3.8092e-03,  1.0551e-02,  3.8759e-03,\n",
       "                       6.4586e-04,  3.2884e-03, -5.4096e-04, -1.0096e-02,  1.2916e-02,\n",
       "                      -6.5504e-03,  4.5368e-03, -4.4401e-03,  7.0199e-03,  4.4013e-03,\n",
       "                      -1.4619e-02,  1.2791e-02,  1.3249e-02, -2.4694e-02, -4.8855e-03,\n",
       "                      -5.3836e-03, -5.8164e-03,  1.1458e-02,  2.7668e-02, -1.4218e-02,\n",
       "                       1.2458e-02, -1.6016e-02,  8.8222e-03,  7.5653e-04, -8.6830e-04,\n",
       "                       1.1913e-02, -9.5163e-03, -1.2947e-02,  6.9819e-03, -1.8076e-02,\n",
       "                       7.1307e-03, -2.3290e-02,  1.6420e-02, -5.2034e-03,  1.6884e-02,\n",
       "                       1.4874e-02, -1.1817e-02, -4.6706e-03,  3.9306e-02,  1.0370e-02,\n",
       "                      -1.2274e-02,  7.6153e-03,  7.2630e-03, -9.8423e-03,  1.7785e-02,\n",
       "                       2.0041e-03, -1.4072e-02,  1.3066e-02,  1.2530e-02, -1.0354e-02,\n",
       "                       1.3929e-02, -1.8552e-02,  3.0378e-02, -7.1660e-03, -1.0186e-03,\n",
       "                       1.0420e-02,  9.9631e-03, -6.0956e-03, -1.2155e-02, -6.5960e-03,\n",
       "                       1.4070e-02, -1.5161e-02,  1.6140e-02,  1.2424e-02, -6.8124e-05,\n",
       "                       2.1549e-02,  5.4264e-03,  1.8213e-02,  7.1934e-03, -1.9516e-02,\n",
       "                       9.9552e-03,  5.3198e-04, -1.3909e-03, -2.4340e-02, -1.0219e-02,\n",
       "                       6.9933e-03,  1.3917e-03, -8.6553e-03,  2.0894e-02, -2.3368e-02,\n",
       "                      -2.0220e-03, -1.5113e-02, -7.0708e-03, -7.0731e-03, -5.6691e-03,\n",
       "                       5.3663e-03,  2.8587e-02, -1.3280e-02,  1.3504e-02, -1.3050e-02,\n",
       "                      -5.1631e-03,  1.9800e-03, -8.1878e-03,  1.4707e-02, -1.1270e-02,\n",
       "                      -3.1284e-02,  1.2387e-02,  3.2550e-03,  2.0075e-02, -2.2253e-04,\n",
       "                       2.4929e-02,  2.5022e-02,  7.6679e-03,  2.1497e-02, -3.5650e-03,\n",
       "                      -1.7133e-02, -2.4663e-03,  5.8851e-03,  2.0289e-02,  9.5215e-04,\n",
       "                       1.9021e-02,  5.2186e-03,  7.6804e-03,  1.2181e-02, -9.6251e-03,\n",
       "                       4.2442e-02,  3.4983e-02,  7.6254e-03,  1.2292e-02, -1.0654e-02,\n",
       "                      -2.3302e-02, -5.5196e-03,  6.6391e-03, -6.3755e-03,  2.7376e-02,\n",
       "                       1.0261e-02, -1.0865e-02,  6.1418e-03,  1.3693e-02,  7.0305e-03,\n",
       "                      -6.9481e-03, -1.5277e-02,  8.0434e-03, -1.8173e-02,  1.3320e-02,\n",
       "                       6.0668e-03,  7.3001e-03,  1.1019e-02,  3.6146e-03,  1.2082e-02,\n",
       "                      -1.6947e-02, -3.7481e-03, -1.0476e-02,  5.9758e-03, -1.7444e-03,\n",
       "                      -2.5558e-02, -1.3555e-02,  1.0794e-02, -5.6015e-03,  2.1191e-02,\n",
       "                      -1.1795e-02,  1.5423e-02,  2.2444e-02, -2.8323e-03,  9.9287e-03,\n",
       "                       2.6240e-02,  1.9329e-03, -3.3978e-03,  1.5984e-02,  1.4085e-02,\n",
       "                      -8.8675e-03, -1.9650e-02,  1.1788e-02, -2.9695e-03, -7.8964e-03,\n",
       "                      -5.3159e-04], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0008, -0.0805,  0.0672,  ...,  0.1154, -0.0272,  0.0385],\n",
       "                      [ 0.0514, -0.0521,  0.0722,  ..., -0.0322, -0.0197, -0.0190],\n",
       "                      [ 0.0093,  0.0065,  0.0328,  ...,  0.0313,  0.0241,  0.0342],\n",
       "                      ...,\n",
       "                      [-0.0304, -0.0854,  0.0255,  ...,  0.0012,  0.0079, -0.0530],\n",
       "                      [ 0.0110,  0.0005, -0.0343,  ...,  0.0320, -0.0869,  0.0306],\n",
       "                      [ 0.0671, -0.0503, -0.0378,  ..., -0.0256, -0.0091,  0.0425]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.out_proj.bias',\n",
       "              tensor([ 0.0330, -0.0086,  0.0069, -0.0247,  0.0413,  0.0059,  0.0425,  0.0049,\n",
       "                       0.0296,  0.0073, -0.0126,  0.0047,  0.0249, -0.0200,  0.0255, -0.0344,\n",
       "                      -0.0136,  0.0036, -0.0006,  0.0256, -0.0090, -0.0240, -0.0387,  0.0024,\n",
       "                      -0.0373, -0.0038,  0.0210,  0.0173, -0.0134,  0.0180, -0.0298,  0.0486,\n",
       "                       0.0087,  0.0013, -0.0209, -0.0106, -0.0313, -0.0179, -0.0076,  0.0152,\n",
       "                      -0.0087, -0.0066,  0.0159, -0.0239,  0.0308, -0.0124,  0.0285, -0.0031,\n",
       "                       0.0013,  0.0120,  0.0249, -0.0023,  0.0029,  0.0230, -0.0436,  0.0203,\n",
       "                       0.0069, -0.0399, -0.0151, -0.0027,  0.0145,  0.0027, -0.0326,  0.0138,\n",
       "                      -0.0405,  0.0280,  0.0150, -0.0249,  0.0024, -0.0131,  0.0456,  0.0098,\n",
       "                       0.0092,  0.0217, -0.0280,  0.0013,  0.0143, -0.0158, -0.0063, -0.0307,\n",
       "                      -0.0246, -0.0197, -0.0005,  0.0065, -0.0031, -0.0207, -0.0020,  0.0236,\n",
       "                       0.0240, -0.0029,  0.0201, -0.0196, -0.0036, -0.0084, -0.0172, -0.0191,\n",
       "                       0.0059,  0.0231,  0.0641,  0.0007,  0.0243, -0.0290, -0.0008,  0.0530,\n",
       "                      -0.0144,  0.0193, -0.0001, -0.0353, -0.0212,  0.0075, -0.0112, -0.0287,\n",
       "                       0.0294, -0.0274,  0.0054, -0.0298,  0.0206,  0.0265,  0.0230, -0.0034,\n",
       "                      -0.0035, -0.0109,  0.0283,  0.0058, -0.0089,  0.0193,  0.0105, -0.0088,\n",
       "                      -0.0238, -0.0008, -0.0313, -0.0031,  0.0528, -0.0233,  0.0214, -0.0085,\n",
       "                      -0.0221,  0.0255,  0.0156, -0.0317, -0.0063,  0.0044, -0.0143, -0.0028,\n",
       "                       0.0225, -0.0331, -0.0011, -0.0173,  0.0334, -0.0445, -0.0180, -0.0330,\n",
       "                      -0.0080,  0.0131,  0.0252, -0.0228, -0.0057,  0.0147,  0.0099, -0.0004,\n",
       "                      -0.0257,  0.0080,  0.0321, -0.0160, -0.0098,  0.0135, -0.0089,  0.0008,\n",
       "                      -0.0195,  0.0014,  0.0252, -0.0274, -0.0098,  0.0190,  0.0490, -0.0125,\n",
       "                       0.0228,  0.0243,  0.0114,  0.0238, -0.0131,  0.0032,  0.0416,  0.0151,\n",
       "                       0.0042, -0.0165, -0.0025,  0.0041, -0.0142,  0.0024, -0.0105, -0.0061],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.in_proj_weight',\n",
       "              tensor([[ 0.0400, -0.0830,  0.1026,  ...,  0.0482, -0.0199, -0.0458],\n",
       "                      [-0.1486,  0.0807, -0.0066,  ..., -0.0112, -0.0836,  0.0269],\n",
       "                      [-0.0611,  0.0616, -0.1253,  ..., -0.0843, -0.0113,  0.1073],\n",
       "                      ...,\n",
       "                      [ 0.0686,  0.0005, -0.0231,  ..., -0.0429, -0.0058, -0.0189],\n",
       "                      [ 0.0458, -0.0076, -0.0780,  ..., -0.0622,  0.1324, -0.0213],\n",
       "                      [ 0.1321, -0.0259,  0.0002,  ...,  0.1245, -0.0017,  0.1072]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.in_proj_bias',\n",
       "              tensor([ 1.5504e-01, -5.6370e-02, -1.1369e-01, -1.3652e-01,  4.3207e-03,\n",
       "                       1.6370e-01,  6.3209e-02,  1.5051e-01,  1.3203e-01,  1.8422e-01,\n",
       "                      -2.0319e-02, -6.3878e-02,  1.6497e-01,  1.8327e-01, -1.1724e-01,\n",
       "                       1.9724e-02, -5.9973e-02, -1.4914e-01,  1.6350e-01, -1.2836e-01,\n",
       "                       1.8582e-01, -1.9367e-01, -3.6031e-02,  1.1585e-01,  9.7958e-02,\n",
       "                      -1.6164e-01, -8.6266e-02,  9.3083e-02,  2.2463e-02, -1.1063e-01,\n",
       "                       4.3902e-03,  1.9732e-01, -5.2724e-02,  1.7754e-01, -8.7357e-03,\n",
       "                      -1.6333e-01,  1.6326e-01, -2.0917e-01,  1.5877e-01, -7.8540e-02,\n",
       "                      -9.2886e-02, -2.0304e-02, -1.7338e-02, -7.0090e-02, -6.6697e-02,\n",
       "                      -9.4168e-02,  6.0382e-02, -1.6986e-01,  1.9997e-02,  7.6481e-02,\n",
       "                       4.0379e-02,  2.1728e-02, -1.7251e-01, -6.7962e-02, -9.3912e-02,\n",
       "                      -2.2624e-01, -2.0715e-02, -4.2494e-03,  5.2871e-02,  9.5855e-02,\n",
       "                       1.2396e-01,  4.4612e-02,  1.3755e-01, -6.1753e-03, -4.1619e-02,\n",
       "                      -3.4560e-02,  1.6320e-01, -5.0872e-02,  2.9179e-02, -6.7443e-03,\n",
       "                      -5.3601e-02, -1.5044e-01,  2.1788e-02, -2.2430e-02,  9.0122e-02,\n",
       "                       1.5626e-02,  7.9398e-02,  6.5898e-02,  1.3770e-01,  1.6014e-02,\n",
       "                      -4.9615e-02,  1.0683e-02, -1.2002e-01,  4.0162e-02, -2.5270e-02,\n",
       "                      -1.0023e-01,  1.1434e-01,  7.4981e-02,  8.7075e-03,  5.3735e-02,\n",
       "                      -5.9318e-02,  4.3582e-02, -1.2041e-01, -5.0116e-02,  9.8981e-02,\n",
       "                      -1.0764e-01,  5.4857e-02,  1.7231e-02, -2.5794e-02,  2.0714e-01,\n",
       "                       1.1127e-01, -2.2029e-02, -1.4357e-02,  1.6007e-01,  9.1329e-02,\n",
       "                      -2.4932e-01, -2.6011e-02,  4.3957e-02,  1.1908e-01,  2.3245e-02,\n",
       "                      -1.0138e-01, -2.6802e-02,  1.9162e-02, -4.7787e-02,  1.7835e-01,\n",
       "                      -2.5350e-02,  1.3947e-01,  4.5914e-02,  1.6342e-01,  1.1585e-02,\n",
       "                      -2.7268e-02, -7.0741e-02, -7.3770e-02, -1.6192e-02,  1.1991e-01,\n",
       "                      -9.3042e-02,  7.6398e-02,  9.6625e-04,  1.1429e-01, -5.5349e-02,\n",
       "                      -6.4933e-02, -2.1002e-01,  4.3806e-03,  7.9301e-03,  4.4888e-03,\n",
       "                       1.1197e-01, -1.0898e-01,  1.6126e-01, -5.6258e-02,  6.8537e-02,\n",
       "                      -5.4987e-02,  2.0874e-02,  1.6675e-02, -2.8978e-02,  2.0904e-01,\n",
       "                       1.1457e-01,  1.1815e-01,  7.5224e-02,  2.9395e-03,  1.5691e-02,\n",
       "                       9.7557e-02, -1.8913e-02,  1.2209e-01, -8.4427e-02, -1.1219e-01,\n",
       "                       2.4342e-02,  1.1368e-01, -3.0334e-03,  1.8703e-01,  1.0674e-01,\n",
       "                       3.5884e-02,  3.6150e-02, -4.2148e-02,  7.0939e-02, -5.2510e-02,\n",
       "                      -1.0394e-01, -6.2265e-02,  2.4612e-02, -1.1659e-01,  9.9583e-02,\n",
       "                      -1.2409e-01,  1.2987e-01, -1.0682e-01,  1.2009e-01, -7.3495e-02,\n",
       "                       5.7528e-02,  2.3724e-02, -2.0681e-01, -1.9926e-02,  2.1003e-02,\n",
       "                      -2.0856e-01, -1.0600e-01,  7.1733e-02,  9.6997e-03, -1.8087e-01,\n",
       "                       8.5025e-02, -2.5274e-02,  9.8903e-03, -3.2104e-02,  2.0084e-01,\n",
       "                       1.4788e-02, -3.2493e-02, -4.1117e-05,  2.7223e-05,  2.3324e-05,\n",
       "                       3.2174e-05,  5.7001e-06,  9.8032e-06, -2.2645e-05, -2.6448e-05,\n",
       "                      -2.6261e-05,  1.0807e-05,  1.0529e-05,  1.2598e-06, -2.3210e-05,\n",
       "                      -1.0075e-05,  2.1350e-05,  3.2488e-07,  1.1537e-05,  4.0996e-05,\n",
       "                      -1.4404e-05,  3.4469e-05, -2.4751e-05,  3.4033e-05,  9.5206e-07,\n",
       "                      -2.8565e-05, -8.5411e-06,  2.8874e-05,  2.5878e-05, -7.0027e-06,\n",
       "                       1.6861e-05,  2.9996e-05, -8.7277e-06, -1.9519e-05,  9.9292e-06,\n",
       "                      -2.9802e-05,  9.2801e-06,  2.9021e-05,  7.6878e-06,  3.6465e-05,\n",
       "                      -2.3759e-05,  1.7893e-05,  2.3316e-05,  5.8334e-06, -1.1728e-05,\n",
       "                      -5.2025e-07,  4.9771e-06,  1.7426e-05,  1.6842e-05,  3.5901e-05,\n",
       "                       8.7873e-06, -4.0516e-06,  3.4098e-05, -2.2415e-05, -1.5125e-05,\n",
       "                      -8.1865e-06, -1.6379e-05, -2.3339e-05, -3.7938e-05, -1.7359e-06,\n",
       "                       1.5998e-05, -1.3250e-05,  3.0115e-05,  1.5000e-08,  2.5526e-05,\n",
       "                      -1.2002e-05, -1.0470e-05,  1.6522e-05,  2.4301e-05, -8.7592e-06,\n",
       "                       7.2650e-06, -1.7554e-06,  1.6833e-05, -3.1818e-05,  1.1607e-05,\n",
       "                       5.1269e-06,  8.3411e-06,  2.9685e-05,  6.3310e-07,  2.0194e-05,\n",
       "                       2.6849e-05,  4.9527e-06,  4.5823e-06,  1.7965e-05,  6.4048e-08,\n",
       "                       1.8796e-05, -6.2739e-06,  9.2189e-06, -1.7924e-06, -3.2760e-06,\n",
       "                       3.5532e-05,  2.8542e-06,  3.0002e-06, -2.1351e-05,  2.7228e-06,\n",
       "                       2.0856e-05, -4.4865e-06, -1.5871e-05, -1.2225e-05,  2.4682e-06,\n",
       "                       2.0390e-05,  2.6879e-05, -7.3732e-06,  3.0236e-05, -2.5342e-05,\n",
       "                       2.3276e-06, -1.2996e-05, -1.5867e-05,  2.4153e-05, -1.5543e-05,\n",
       "                      -4.9561e-06, -3.5113e-05,  2.7491e-05,  1.5965e-05, -2.1344e-05,\n",
       "                       1.8548e-05,  5.1225e-06, -1.6444e-05,  5.7850e-06, -1.1872e-05,\n",
       "                      -3.5670e-06, -1.2509e-05, -5.3082e-05, -2.6372e-05,  9.1574e-06,\n",
       "                      -1.1352e-05,  6.7288e-06,  1.3977e-05, -2.0874e-05, -2.1436e-05,\n",
       "                      -3.6495e-06,  6.0960e-06, -4.7473e-06, -6.5239e-06,  1.9219e-05,\n",
       "                       3.4517e-05, -1.8189e-05, -6.4308e-06,  1.0599e-05,  1.0881e-05,\n",
       "                       1.3807e-05, -3.0880e-06,  1.1149e-05, -2.1470e-05,  3.2241e-05,\n",
       "                       2.1026e-06,  2.1317e-05, -6.7991e-06, -6.3864e-06,  1.1661e-05,\n",
       "                       1.6584e-05,  3.2481e-06, -7.0850e-06, -5.8154e-06, -1.6962e-06,\n",
       "                       9.0267e-06,  8.7907e-06,  1.0688e-05, -6.3721e-06,  1.6851e-06,\n",
       "                       8.5621e-06,  2.0328e-06,  3.0053e-06, -4.3057e-06, -1.1476e-06,\n",
       "                       5.0789e-06,  1.0789e-05,  1.2439e-06,  2.1969e-06, -1.1371e-06,\n",
       "                       2.1700e-07,  1.1706e-05,  7.9329e-06, -4.7321e-06, -3.4912e-07,\n",
       "                       4.5306e-06,  1.1237e-05,  7.6618e-07, -5.4868e-06, -1.2031e-05,\n",
       "                       1.2998e-05, -3.0944e-06, -1.8788e-06,  1.4276e-05, -6.0703e-07,\n",
       "                       9.2726e-07,  1.6793e-05,  1.8843e-06,  1.3697e-05,  1.8897e-06,\n",
       "                      -2.0896e-06, -1.1035e-05, -1.4035e-05,  3.0443e-06, -1.2417e-03,\n",
       "                       1.2986e-02,  1.7110e-02,  2.8946e-02, -2.5770e-02, -2.2517e-02,\n",
       "                      -1.6412e-02, -2.6122e-02,  6.4382e-03, -2.9509e-02,  1.3172e-02,\n",
       "                       5.9058e-03,  7.4972e-03,  8.5920e-03,  2.4156e-02,  5.1145e-03,\n",
       "                      -2.6836e-02, -3.2139e-02,  3.4703e-02, -2.0623e-02, -5.3632e-03,\n",
       "                      -4.5038e-03, -9.3564e-03, -2.0998e-02, -2.6330e-02, -2.6907e-02,\n",
       "                       5.0041e-02, -1.3542e-02,  3.9234e-03,  5.7549e-02,  1.7672e-02,\n",
       "                       4.5998e-03,  4.3968e-02, -2.1731e-02, -3.5134e-02,  1.5940e-02,\n",
       "                       4.1254e-02, -1.5624e-02, -1.4713e-03,  2.0806e-03, -2.4027e-02,\n",
       "                       1.0437e-02, -5.0316e-02,  3.3368e-02,  2.1649e-03,  3.8862e-03,\n",
       "                       2.1318e-02, -2.1336e-02,  1.6735e-02, -8.0728e-03,  1.4615e-02,\n",
       "                       6.2820e-03, -7.2301e-03, -1.8009e-02,  2.9891e-02, -1.8430e-02,\n",
       "                      -7.9581e-03, -1.0302e-02, -2.0487e-02,  2.0978e-02, -2.6380e-02,\n",
       "                      -2.4799e-02, -4.5737e-03, -4.4790e-03, -3.0404e-02, -8.8197e-03,\n",
       "                       4.8223e-03,  2.4362e-02,  1.9523e-02, -1.5462e-02, -2.1916e-02,\n",
       "                      -1.8568e-02,  4.0839e-03, -1.2365e-02, -3.6640e-03, -7.4302e-03,\n",
       "                       6.3905e-03,  2.0606e-03, -2.2020e-03,  1.6706e-02, -1.8979e-02,\n",
       "                       2.0243e-02, -2.4288e-02, -3.9204e-02,  4.0020e-03, -9.8654e-03,\n",
       "                       1.8450e-03,  2.9801e-02, -8.4133e-03,  1.3646e-02,  1.8222e-02,\n",
       "                      -1.3713e-02, -4.2595e-03, -2.2416e-04,  1.1639e-02, -1.4164e-02,\n",
       "                       2.1221e-02,  2.4912e-02,  8.2495e-03,  5.8912e-03,  1.7524e-02,\n",
       "                       2.2233e-02, -2.6181e-02, -2.2839e-03, -2.0001e-02, -8.3314e-03,\n",
       "                      -2.4315e-02,  2.6870e-02, -2.0131e-02, -4.3033e-02,  1.9417e-02,\n",
       "                      -9.2477e-03,  7.5161e-03,  1.1657e-02, -2.4600e-02, -1.6079e-03,\n",
       "                      -1.1613e-02,  2.3990e-03, -3.9418e-03,  1.0759e-02,  1.6646e-02,\n",
       "                       6.1001e-03, -2.8120e-04, -9.0739e-03, -8.7504e-03, -9.8231e-03,\n",
       "                       1.6593e-02,  3.1811e-03, -2.0796e-02, -4.3438e-03, -2.3748e-02,\n",
       "                      -2.9214e-03, -2.4150e-02,  1.1972e-02,  2.0657e-02,  2.0410e-02,\n",
       "                      -2.4166e-02, -1.1841e-02,  9.0982e-03, -1.6724e-02,  3.8315e-02,\n",
       "                       1.7728e-02,  1.4104e-03,  6.0435e-03,  5.3134e-03, -8.8090e-04,\n",
       "                       2.7553e-03,  3.0202e-02, -1.4383e-02,  1.6060e-02,  6.6492e-03,\n",
       "                      -3.5899e-02, -2.8970e-02, -2.1914e-02,  1.1662e-02, -5.6504e-02,\n",
       "                      -2.1874e-02,  1.5731e-02,  4.3625e-03, -3.3903e-02,  3.3354e-03,\n",
       "                       9.8275e-04,  6.8465e-04,  1.8499e-02,  3.2426e-02,  6.2430e-02,\n",
       "                       6.2513e-03, -3.3024e-03, -1.1179e-02, -2.5409e-03,  1.4897e-02,\n",
       "                      -1.6796e-02, -2.3393e-02, -1.0614e-02,  4.5039e-02, -1.4194e-02,\n",
       "                       2.8163e-02,  9.0386e-03, -4.2222e-03, -3.1192e-02,  7.6414e-03,\n",
       "                      -2.5173e-02, -2.4883e-02, -2.2236e-02,  4.4253e-02, -4.6075e-06,\n",
       "                      -2.7811e-02,  9.4191e-03, -3.3411e-02, -7.6351e-03,  1.5647e-03,\n",
       "                      -1.4231e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.out_proj.weight',\n",
       "              tensor([[-0.0059,  0.0194,  0.0176,  ..., -0.0292,  0.0565,  0.0259],\n",
       "                      [ 0.0185, -0.0124, -0.0953,  ...,  0.0345, -0.0260,  0.0659],\n",
       "                      [-0.0256, -0.0572,  0.0228,  ...,  0.0291,  0.0632,  0.0159],\n",
       "                      ...,\n",
       "                      [-0.0546,  0.0549, -0.0161,  ..., -0.0509, -0.0635,  0.0253],\n",
       "                      [ 0.0032, -0.0369,  0.0664,  ..., -0.0100, -0.0601,  0.0399],\n",
       "                      [ 0.0765,  0.0205, -0.0186,  ..., -0.0496, -0.0788, -0.0422]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.out_proj.bias',\n",
       "              tensor([-0.0046, -0.0390, -0.0213,  0.0041, -0.0133,  0.0255,  0.0131, -0.0110,\n",
       "                       0.0093,  0.0288,  0.0300,  0.0075,  0.0213, -0.0053,  0.0313, -0.0094,\n",
       "                       0.0030,  0.0099,  0.0037,  0.0432, -0.0034, -0.0020,  0.0028,  0.0200,\n",
       "                      -0.0218,  0.0318,  0.0109,  0.0560,  0.0434, -0.0144, -0.0268,  0.0173,\n",
       "                      -0.0095, -0.0119, -0.0198, -0.0083, -0.0297,  0.0154,  0.0116,  0.0057,\n",
       "                      -0.0145, -0.0016,  0.0119,  0.0030, -0.0191,  0.0091,  0.0134, -0.0010,\n",
       "                      -0.0080, -0.0055,  0.0062,  0.0026,  0.0146, -0.0415, -0.0024, -0.0013,\n",
       "                      -0.0172,  0.0127,  0.0254,  0.0166,  0.0322,  0.0038,  0.0069,  0.0182,\n",
       "                       0.0129,  0.0120, -0.0217, -0.0100, -0.0262,  0.0065,  0.0059,  0.0133,\n",
       "                       0.0148, -0.0301, -0.0139, -0.0144,  0.0209, -0.0129, -0.0274, -0.0055,\n",
       "                      -0.0176, -0.0116,  0.0064,  0.0098, -0.0010,  0.0266, -0.0059,  0.0448,\n",
       "                       0.0126, -0.0032, -0.0306,  0.0099, -0.0085, -0.0051,  0.0221, -0.0005,\n",
       "                      -0.0008, -0.0072,  0.0263, -0.0060, -0.0043, -0.0212, -0.0244, -0.0057,\n",
       "                      -0.0159,  0.0009,  0.0251, -0.0106, -0.0172, -0.0027,  0.0011, -0.0136,\n",
       "                       0.0402,  0.0243, -0.0023,  0.0054,  0.0274,  0.0048,  0.0297, -0.0070,\n",
       "                      -0.0200,  0.0033,  0.0073,  0.0115, -0.0380,  0.0022,  0.0298,  0.0092,\n",
       "                       0.0055,  0.0277, -0.0236, -0.0019,  0.0163, -0.0184,  0.0004, -0.0122,\n",
       "                       0.0005, -0.0268,  0.0013, -0.0336, -0.0122,  0.0113,  0.0137,  0.0034,\n",
       "                      -0.0182, -0.0154,  0.0276, -0.0253,  0.0123, -0.0533,  0.0128,  0.0073,\n",
       "                      -0.0157, -0.0139, -0.0295, -0.0181,  0.0296,  0.0030,  0.0008, -0.0124,\n",
       "                      -0.0151, -0.0158, -0.0128,  0.0025, -0.0088,  0.0237, -0.0107, -0.0217,\n",
       "                       0.0003, -0.0268, -0.0175, -0.0081, -0.0430, -0.0006,  0.0335, -0.0352,\n",
       "                      -0.0070, -0.0085, -0.0054,  0.0167,  0.0291, -0.0116,  0.0151, -0.0091,\n",
       "                       0.0039, -0.0374, -0.0186,  0.0028,  0.0069, -0.0265, -0.0110,  0.0177],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear1.weight',\n",
       "              tensor([[ 0.0315,  0.0020, -0.0214,  ...,  0.0625, -0.0140,  0.0430],\n",
       "                      [-0.0332, -0.0116, -0.0333,  ...,  0.0123,  0.0962,  0.0318],\n",
       "                      [ 0.0176,  0.0624,  0.0023,  ...,  0.0043, -0.0408, -0.0713],\n",
       "                      ...,\n",
       "                      [ 0.0034, -0.0222, -0.0172,  ...,  0.0616, -0.0484, -0.0138],\n",
       "                      [-0.0903,  0.1201,  0.0455,  ...,  0.0744,  0.0083, -0.0166],\n",
       "                      [ 0.0174, -0.0477,  0.0110,  ...,  0.0345,  0.0207, -0.0004]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear1.bias',\n",
       "              tensor([-0.0123, -0.0777, -0.1128,  ..., -0.0315, -0.0392, -0.1384],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear2.weight',\n",
       "              tensor([[-0.0004, -0.0038, -0.0331,  ...,  0.0354, -0.0150,  0.0024],\n",
       "                      [ 0.0365, -0.0252, -0.0177,  ...,  0.0002,  0.0386,  0.0061],\n",
       "                      [ 0.0007, -0.0517,  0.0137,  ..., -0.0052,  0.0227, -0.0482],\n",
       "                      ...,\n",
       "                      [ 0.0326,  0.0009, -0.0065,  ..., -0.0114,  0.0102,  0.0077],\n",
       "                      [ 0.0342, -0.0072,  0.0182,  ...,  0.0495,  0.0420, -0.0258],\n",
       "                      [ 0.0363,  0.0280,  0.0295,  ...,  0.0480, -0.0108,  0.0228]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear2.bias',\n",
       "              tensor([-0.0728,  0.0723, -0.0512,  0.0804, -0.0300,  0.0526,  0.0555,  0.0696,\n",
       "                      -0.0574, -0.0719,  0.0583,  0.0234, -0.0683,  0.1099, -0.0511,  0.0811,\n",
       "                       0.0261, -0.0471, -0.0725,  0.0384,  0.0786,  0.0769,  0.0104,  0.0503,\n",
       "                      -0.0355,  0.0548, -0.0192, -0.0366, -0.0683,  0.0580,  0.0499, -0.0842,\n",
       "                       0.0502,  0.0561,  0.0447,  0.0171,  0.0201,  0.0572,  0.0450, -0.0725,\n",
       "                       0.0780,  0.0468, -0.0439,  0.0454,  0.0638, -0.0927, -0.0427, -0.0281,\n",
       "                       0.0752,  0.0562, -0.0777,  0.0534,  0.0663, -0.0388,  0.0682, -0.0765,\n",
       "                       0.0948,  0.0716,  0.0091, -0.0602, -0.0377, -0.0689, -0.0661, -0.0538,\n",
       "                       0.0344,  0.0584,  0.0329, -0.0520, -0.0124,  0.0563, -0.0630, -0.0340,\n",
       "                       0.0377,  0.0391,  0.0627, -0.0854, -0.0138, -0.0651,  0.0372, -0.0558,\n",
       "                      -0.0178, -0.0322, -0.0804, -0.0608,  0.0079, -0.0209,  0.0522, -0.0765,\n",
       "                       0.0517,  0.0731,  0.0145,  0.0681, -0.0408, -0.0925, -0.0676, -0.0315,\n",
       "                      -0.0133, -0.1050, -0.0100, -0.0068,  0.0684,  0.0593,  0.0403,  0.0149,\n",
       "                       0.0581,  0.0197,  0.0100, -0.0056,  0.0545, -0.0304, -0.0657, -0.0251,\n",
       "                      -0.0581,  0.0793,  0.0424, -0.0865,  0.0749, -0.0933,  0.0927,  0.0431,\n",
       "                      -0.0673, -0.0661, -0.0136, -0.0408, -0.0432, -0.0688,  0.0893,  0.0784,\n",
       "                      -0.0007, -0.0659,  0.0664, -0.0348, -0.0613, -0.0126,  0.0096,  0.0386,\n",
       "                       0.0082, -0.0103, -0.0681, -0.0163, -0.0317, -0.0590,  0.0967, -0.0443,\n",
       "                       0.0330,  0.0531,  0.0273, -0.0614, -0.0460,  0.0621,  0.0620,  0.0021,\n",
       "                       0.0637, -0.0263,  0.0843,  0.0391, -0.0222, -0.0303, -0.0017, -0.0741,\n",
       "                       0.0401,  0.0648, -0.0611, -0.0372,  0.0425, -0.0816, -0.0172, -0.0705,\n",
       "                      -0.0371, -0.1074,  0.0532,  0.0011, -0.0363, -0.0571, -0.0407,  0.0491,\n",
       "                      -0.0022, -0.0471,  0.0585, -0.0725, -0.0345,  0.0369, -0.0409,  0.0142,\n",
       "                       0.0480, -0.0611, -0.0693,  0.0912,  0.0636, -0.0551,  0.0640,  0.0256],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm1.weight',\n",
       "              tensor([0.9731, 0.8455, 0.9837, 1.0036, 0.9621, 0.9957, 0.9784, 0.9806, 0.9593,\n",
       "                      0.9068, 0.9514, 0.9911, 0.9506, 1.0348, 0.9797, 0.9808, 0.9744, 0.9782,\n",
       "                      0.9860, 0.9780, 1.0024, 0.9764, 1.0013, 0.9711, 0.9924, 0.9625, 0.9387,\n",
       "                      0.9430, 0.8797, 0.9367, 1.0149, 0.9653, 0.9861, 1.0104, 0.9464, 1.0102,\n",
       "                      0.9693, 0.9710, 0.9649, 0.9702, 1.0018, 1.0131, 0.9428, 1.0015, 0.9554,\n",
       "                      1.0018, 0.9960, 0.9837, 0.9992, 1.0006, 0.9862, 0.9970, 0.9938, 0.9823,\n",
       "                      0.9613, 0.9825, 0.9944, 0.9515, 0.9984, 0.9970, 0.9892, 0.9772, 0.9622,\n",
       "                      0.9577, 0.8811, 0.9697, 0.9908, 0.9699, 0.9944, 0.9795, 1.0141, 1.0081,\n",
       "                      0.9742, 0.9797, 1.0149, 0.9584, 0.9850, 0.9971, 1.0124, 0.9546, 1.0109,\n",
       "                      0.9359, 0.9818, 0.9832, 0.9814, 1.0288, 0.9974, 0.9397, 1.0160, 0.9666,\n",
       "                      1.0069, 0.9276, 0.9554, 0.9330, 1.0347, 0.9899, 1.0282, 0.9848, 1.0288,\n",
       "                      0.9977, 1.0132, 0.9613, 0.9992, 0.9769, 0.9951, 0.9632, 1.0041, 0.9878,\n",
       "                      0.9869, 1.0040, 1.0105, 0.9984, 1.0036, 1.0026, 0.9865, 0.9458, 0.9694,\n",
       "                      0.9669, 0.9967, 0.9480, 0.9669, 1.0065, 0.9947, 0.9305, 1.0410, 0.9450,\n",
       "                      1.0363, 0.9947, 1.0298, 0.9041, 1.0149, 0.9766, 0.9643, 0.9549, 1.0312,\n",
       "                      0.9675, 1.0077, 0.9833, 1.0071, 0.9420, 1.0136, 0.9795, 0.9982, 1.0080,\n",
       "                      1.0197, 0.9631, 1.0128, 0.9857, 0.9721, 0.9482, 1.0020, 0.9332, 0.9949,\n",
       "                      0.9902, 0.9549, 0.9517, 0.9958, 0.9875, 1.0339, 0.9789, 1.0125, 0.9474,\n",
       "                      0.9837, 0.9026, 1.0183, 0.9507, 1.0527, 0.9604, 1.0299, 0.9629, 1.0224,\n",
       "                      0.9452, 0.9818, 0.9830, 1.0441, 0.9945, 0.9615, 0.9455, 1.0376, 0.9900,\n",
       "                      0.9857, 0.9615, 1.0278, 0.9556, 1.0060, 1.0015, 1.0358, 0.9474, 0.9050,\n",
       "                      0.9742, 1.0229, 0.9913], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm1.bias',\n",
       "              tensor([ 0.0198, -0.0869,  0.0126, -0.0674,  0.0581, -0.0429,  0.0935,  0.0003,\n",
       "                       0.0501,  0.1397, -0.0256, -0.0095,  0.1157, -0.0771,  0.1142, -0.0662,\n",
       "                      -0.0338,  0.0047,  0.0477,  0.1550, -0.0794, -0.0682, -0.0354,  0.0389,\n",
       "                      -0.0712,  0.0525,  0.0436,  0.0689,  0.0550, -0.0285, -0.1059,  0.1068,\n",
       "                      -0.0190, -0.1067, -0.0418, -0.0710, -0.1003, -0.0755, -0.0256,  0.0569,\n",
       "                      -0.1083, -0.0130,  0.0313, -0.0317, -0.0942,  0.0184,  0.0650,  0.0326,\n",
       "                      -0.0592, -0.0801,  0.0189, -0.0276, -0.0660, -0.0598, -0.0486,  0.0616,\n",
       "                      -0.0889, -0.1056,  0.0841,  0.0904,  0.1379, -0.0034,  0.0332,  0.0366,\n",
       "                       0.0367, -0.0464, -0.0651, -0.0215, -0.0330, -0.0781,  0.1470,  0.0598,\n",
       "                       0.0352, -0.0929, -0.1209,  0.0768,  0.0355, -0.0047, -0.0092, -0.0115,\n",
       "                      -0.0098, -0.0993,  0.1376,  0.0528, -0.0365,  0.0321, -0.0874,  0.1204,\n",
       "                      -0.0297, -0.0483, -0.0123, -0.1384,  0.0777,  0.0461,  0.0854, -0.0174,\n",
       "                       0.0564,  0.0787,  0.1205,  0.0074,  0.0752, -0.1571, -0.0133,  0.0455,\n",
       "                      -0.0957, -0.0833,  0.0182, -0.1271, -0.0036,  0.0162,  0.0601,  0.0190,\n",
       "                       0.1787, -0.0917,  0.0319, -0.0501, -0.0059,  0.1064,  0.0314, -0.1634,\n",
       "                       0.0655,  0.0594,  0.0747,  0.0355,  0.0278,  0.0098,  0.0036, -0.0641,\n",
       "                      -0.0152,  0.0107, -0.1165,  0.0419,  0.2074, -0.0610,  0.0572, -0.0853,\n",
       "                      -0.0377,  0.0434,  0.1225, -0.1124, -0.0291,  0.0578, -0.0687,  0.0232,\n",
       "                       0.0508, -0.0772, -0.0152, -0.0011,  0.0820, -0.0721, -0.0457, -0.1113,\n",
       "                      -0.0302,  0.0409, -0.0213, -0.1605,  0.0651,  0.0701,  0.0296,  0.0032,\n",
       "                      -0.0193,  0.0060,  0.1141, -0.0261, -0.0179,  0.0563,  0.0035, -0.0646,\n",
       "                      -0.0505,  0.0320, -0.0691, -0.0640,  0.0690,  0.0529,  0.1879, -0.1739,\n",
       "                       0.0594, -0.0182, -0.0813,  0.0973,  0.0430, -0.0603,  0.1456, -0.0096,\n",
       "                       0.0439,  0.0018,  0.0080, -0.0532, -0.0253, -0.0576, -0.0771, -0.0186],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm2.weight',\n",
       "              tensor([0.9742, 0.8801, 0.9925, 1.0076, 0.9853, 1.0096, 0.9951, 1.0002, 0.9659,\n",
       "                      0.9282, 0.9661, 0.9978, 0.9790, 1.0367, 0.9862, 0.9805, 0.9821, 0.9732,\n",
       "                      0.9930, 1.0025, 1.0099, 0.9891, 1.0105, 0.9630, 1.0084, 0.9679, 0.9538,\n",
       "                      0.9524, 0.9181, 0.9618, 1.0292, 0.9847, 1.0018, 1.0069, 0.9671, 1.0225,\n",
       "                      1.0126, 0.9757, 0.9812, 0.9737, 1.0053, 1.0297, 0.9820, 1.0080, 0.9823,\n",
       "                      1.0176, 0.9977, 0.9868, 1.0124, 1.0061, 1.0137, 1.0125, 1.0068, 1.0081,\n",
       "                      0.9690, 0.9846, 1.0079, 0.9991, 1.0257, 0.9994, 1.0046, 0.9850, 0.9766,\n",
       "                      0.9791, 0.8851, 0.9933, 1.0005, 0.9850, 1.0057, 1.0012, 1.0231, 1.0268,\n",
       "                      0.9809, 0.9930, 1.0223, 0.9670, 1.0029, 1.0076, 1.0276, 0.9635, 1.0022,\n",
       "                      0.9630, 1.0138, 0.9847, 0.9826, 1.0317, 1.0011, 0.9550, 1.0192, 0.9650,\n",
       "                      1.0355, 0.9717, 0.9788, 0.9537, 1.0243, 0.9922, 1.0266, 0.9929, 1.0278,\n",
       "                      1.0074, 1.0352, 0.9793, 0.9930, 1.0136, 1.0113, 0.9750, 0.9958, 0.9881,\n",
       "                      1.0054, 1.0002, 1.0151, 1.0088, 1.0201, 1.0294, 1.0005, 0.9633, 0.9834,\n",
       "                      0.9772, 1.0177, 0.9903, 0.9630, 1.0071, 0.9940, 0.9375, 1.0521, 0.9581,\n",
       "                      1.0328, 0.9951, 1.0322, 0.9090, 1.0275, 0.9719, 0.9926, 0.9622, 1.0347,\n",
       "                      0.9659, 1.0227, 0.9895, 1.0429, 0.9608, 1.0346, 0.9927, 1.0206, 1.0072,\n",
       "                      1.0072, 0.9722, 1.0197, 0.9781, 0.9958, 0.9757, 1.0086, 0.9489, 1.0016,\n",
       "                      1.0070, 0.9726, 1.0091, 1.0300, 0.9934, 1.0247, 0.9843, 0.9973, 0.9706,\n",
       "                      0.9963, 0.9191, 1.0301, 0.9525, 1.0398, 0.9668, 1.0269, 0.9723, 1.0349,\n",
       "                      0.9451, 1.0042, 0.9918, 1.0562, 1.0271, 0.9564, 0.9491, 1.0341, 1.0058,\n",
       "                      1.0063, 0.9541, 1.0300, 0.9608, 1.0119, 1.0126, 1.0391, 0.9559, 0.9391,\n",
       "                      0.9776, 1.0254, 0.9866], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm2.bias',\n",
       "              tensor([-6.8920e-03, -7.2111e-02,  7.9891e-03, -5.9260e-02,  5.5812e-02,\n",
       "                      -4.0608e-02,  1.0242e-01,  1.8335e-03,  1.9658e-02,  1.2593e-01,\n",
       "                      -3.3519e-02, -1.4055e-02,  1.0899e-01, -6.4207e-02,  1.0087e-01,\n",
       "                      -6.2346e-02, -2.5078e-02, -2.2093e-02,  2.8857e-02,  1.6391e-01,\n",
       "                      -6.0728e-02, -6.6126e-02, -3.3980e-02,  4.5222e-02, -8.5235e-02,\n",
       "                       5.1175e-02,  2.3125e-02,  4.2020e-02,  2.6068e-02, -2.8990e-02,\n",
       "                      -9.2827e-02,  8.8299e-02, -5.6933e-03, -9.7521e-02, -3.1562e-02,\n",
       "                      -4.4766e-02, -8.0784e-02, -8.1661e-02, -3.1638e-02,  5.7038e-02,\n",
       "                      -1.0289e-01, -1.0766e-02, -1.4374e-03, -3.1641e-02, -9.6235e-02,\n",
       "                       5.0753e-03,  4.7085e-02,  1.9778e-02, -6.0350e-02, -5.9486e-02,\n",
       "                       8.1317e-03, -3.0062e-02, -5.6837e-02, -6.1819e-02, -4.3450e-02,\n",
       "                       4.1574e-02, -7.2482e-02, -1.0855e-01,  8.8677e-02,  8.3320e-02,\n",
       "                       1.3007e-01, -2.1862e-02,  2.1758e-02,  1.5764e-02,  5.9907e-02,\n",
       "                      -4.0504e-02, -5.4790e-02, -2.3311e-02, -5.3295e-02, -7.9235e-02,\n",
       "                       1.4554e-01,  5.0846e-02,  3.3909e-02, -8.2725e-02, -1.1319e-01,\n",
       "                       5.7359e-02,  2.2162e-02, -1.8503e-02, -4.6059e-03, -3.1436e-02,\n",
       "                      -2.1263e-02, -1.2375e-01,  1.3234e-01,  3.2774e-02, -3.1062e-02,\n",
       "                       4.0217e-03, -8.6824e-02,  9.1485e-02, -2.1540e-02, -3.7683e-02,\n",
       "                      -1.2644e-02, -1.4852e-01,  7.8963e-02,  3.6596e-02,  5.6371e-02,\n",
       "                      -5.4107e-02,  4.6956e-02,  6.4316e-02,  1.1535e-01, -4.2919e-05,\n",
       "                       9.6756e-02, -1.5499e-01, -1.5210e-02,  2.8213e-02, -8.4908e-02,\n",
       "                      -9.3644e-02,  1.5095e-02, -1.4895e-01, -4.0220e-05, -8.2155e-03,\n",
       "                       4.6576e-02,  1.8349e-02,  1.4895e-01, -9.7923e-02,  4.1825e-02,\n",
       "                      -7.2580e-02, -1.1028e-02,  8.9832e-02,  4.7372e-02, -1.6943e-01,\n",
       "                       5.6088e-02,  5.8194e-02,  7.6173e-02,  2.4986e-02,  3.7966e-02,\n",
       "                       2.6056e-03,  9.8641e-04, -5.4875e-02, -1.0071e-02, -1.8660e-02,\n",
       "                      -9.9124e-02,  1.8528e-02,  1.9838e-01, -6.5790e-02,  3.8815e-02,\n",
       "                      -9.2702e-02, -3.3865e-02,  3.2837e-02,  1.1691e-01, -1.2156e-01,\n",
       "                      -3.4788e-02,  2.5079e-02, -7.2349e-02, -1.3093e-03,  6.1893e-02,\n",
       "                      -6.5288e-02, -2.6841e-02, -7.9301e-03,  7.3063e-02, -4.9616e-02,\n",
       "                      -2.6508e-02, -1.2164e-01, -1.6969e-02,  3.7896e-02, -2.6305e-03,\n",
       "                      -1.7341e-01,  3.5728e-02,  6.8970e-02,  2.7231e-02, -5.8719e-03,\n",
       "                       1.0030e-02,  3.1528e-02,  1.0657e-01, -4.8645e-02, -8.1379e-03,\n",
       "                       3.9293e-02, -1.1886e-02, -7.2036e-02, -6.1012e-02,  1.7504e-02,\n",
       "                      -5.3645e-02, -8.0437e-02,  7.9758e-02,  4.7421e-02,  1.8195e-01,\n",
       "                      -1.6304e-01,  5.7535e-02, -4.0829e-02, -7.4070e-02,  9.5699e-02,\n",
       "                       3.9215e-02, -4.3308e-02,  1.4764e-01, -1.1513e-02,  5.2592e-02,\n",
       "                      -1.6017e-02,  1.7335e-02, -4.3716e-02, -2.9863e-02, -7.7705e-02,\n",
       "                      -6.0049e-02, -3.3052e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm3.weight',\n",
       "              tensor([1.5975, 1.2724, 1.6548, 1.5620, 1.5888, 1.4758, 1.6184, 1.6951, 1.5243,\n",
       "                      1.4638, 1.5494, 1.4919, 1.4811, 1.4739, 1.4174, 1.4991, 1.6934, 1.6613,\n",
       "                      1.5637, 1.5082, 1.5144, 1.4759, 1.5891, 1.6599, 1.6046, 1.5935, 1.5738,\n",
       "                      1.5326, 1.4682, 1.4928, 1.5036, 1.5927, 1.5237, 1.5367, 1.5264, 1.6365,\n",
       "                      1.6331, 1.5854, 1.6481, 1.5102, 1.5754, 1.6723, 1.7262, 1.6386, 1.4230,\n",
       "                      1.6149, 1.6269, 1.5825, 1.5622, 1.4946, 1.6169, 1.5873, 1.5803, 1.6863,\n",
       "                      1.5078, 1.4214, 1.5883, 1.5988, 1.6939, 1.5567, 1.5356, 1.6329, 1.4972,\n",
       "                      1.5688, 1.4995, 1.5494, 1.5703, 1.6860, 1.6307, 1.5239, 1.4986, 1.3610,\n",
       "                      1.6621, 1.5923, 1.5038, 1.5266, 1.6668, 1.6143, 1.5333, 1.6409, 1.7163,\n",
       "                      1.5194, 1.6427, 1.5934, 1.6433, 1.5330, 1.3579, 1.1677, 1.4122, 1.5534,\n",
       "                      1.5612, 1.5729, 1.5860, 1.5081, 1.6167, 1.4766, 1.6344, 1.5414, 1.5861,\n",
       "                      1.6728, 1.6470, 1.5270, 1.6229, 1.6673, 1.5391, 1.6425, 1.5835, 1.4465,\n",
       "                      1.6218, 1.6223, 1.5890, 1.6183, 1.4834, 1.5697, 1.5915, 1.6561, 1.5420,\n",
       "                      1.4091, 1.6105, 1.5370, 1.5680, 1.5285, 1.4782, 1.3529, 1.6642, 1.5768,\n",
       "                      1.6011, 1.5639, 1.6438, 1.4897, 1.5292, 1.5429, 1.3970, 1.6128, 1.6716,\n",
       "                      1.5921, 1.6126, 1.6582, 1.5526, 1.4635, 1.4761, 1.6187, 1.4952, 1.6069,\n",
       "                      1.4046, 1.5375, 1.5449, 1.6226, 1.6520, 1.5129, 1.6531, 1.5954, 1.6067,\n",
       "                      1.6175, 1.5102, 1.3445, 1.6366, 1.4525, 1.6684, 1.5970, 1.6105, 1.5532,\n",
       "                      1.6115, 1.5977, 1.6835, 1.4844, 1.6495, 1.5761, 1.5711, 1.5903, 1.5764,\n",
       "                      1.5800, 1.6468, 1.4435, 1.4853, 1.5279, 1.5721, 1.6540, 1.4830, 1.4447,\n",
       "                      1.4530, 1.6237, 1.4736, 1.5924, 1.7227, 1.6058, 1.7411, 1.4939, 1.5363,\n",
       "                      1.4588, 1.6092, 1.6925], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm3.bias',\n",
       "              tensor([-2.1745e-02, -3.7432e-02,  9.1398e-02, -4.1320e-02,  3.1379e-02,\n",
       "                      -6.1644e-02,  9.6546e-02,  2.8034e-02, -3.1854e-02,  6.8596e-02,\n",
       "                      -1.2323e-01,  1.1661e-02,  1.6202e-02, -1.2381e-01,  8.6480e-02,\n",
       "                      -5.8939e-02,  2.9780e-02, -1.2212e-03,  6.2275e-02, -3.1589e-02,\n",
       "                      -8.3103e-02,  1.1854e-03,  1.2437e-02,  4.1205e-02,  4.1702e-02,\n",
       "                       9.3354e-02, -4.5256e-02,  4.3816e-03, -4.4604e-02,  5.3999e-02,\n",
       "                      -1.9950e-02,  1.2070e-01, -1.7267e-02, -1.6632e-01,  8.4606e-02,\n",
       "                       1.8302e-02, -1.2448e-02,  1.2394e-02,  1.3967e-02,  8.4074e-03,\n",
       "                      -6.2931e-02,  8.9536e-02, -8.0722e-02, -1.1229e-03, -2.6511e-02,\n",
       "                       1.9918e-02,  3.9635e-02,  1.3602e-02, -4.6308e-02, -4.1713e-02,\n",
       "                       7.2625e-02, -3.7655e-03,  5.8490e-02, -8.1118e-02,  1.7010e-02,\n",
       "                      -2.1432e-02, -6.9998e-02, -4.1613e-02,  5.8596e-02,  7.4762e-02,\n",
       "                       3.3998e-02, -1.8953e-02, -4.4246e-02, -2.5177e-02,  1.3385e-01,\n",
       "                      -3.5204e-02, -1.8826e-02,  4.2173e-02, -6.9824e-02, -5.1474e-02,\n",
       "                       8.0345e-02, -2.2259e-02,  7.4933e-02,  3.9226e-03, -8.5856e-02,\n",
       "                      -1.5467e-03, -5.7900e-02,  3.4713e-02, -6.3154e-02, -6.3245e-02,\n",
       "                      -1.8890e-02, -4.6423e-02,  1.0968e-01,  7.3472e-02, -2.3538e-03,\n",
       "                       3.4127e-02,  5.6415e-02, -4.6972e-02,  9.3600e-04, -3.3573e-02,\n",
       "                       2.3302e-02, -1.0016e-01,  8.3620e-02,  8.4229e-02,  2.8950e-02,\n",
       "                      -3.6067e-02, -3.6434e-03,  8.7206e-02,  8.3662e-02, -3.3972e-02,\n",
       "                       5.6259e-02, -3.2464e-02, -6.7635e-02, -9.7480e-02, -4.9164e-02,\n",
       "                      -1.0579e-01,  6.9177e-02, -4.9910e-02,  1.2666e-01, -6.0323e-02,\n",
       "                       6.7384e-03,  1.3177e-02,  1.0023e-01, -6.8097e-02,  4.8643e-02,\n",
       "                      -6.8356e-02,  3.6083e-02,  1.0359e-01,  4.7605e-02, -8.2346e-02,\n",
       "                       4.0556e-02,  7.5959e-02, -7.4442e-02, -6.0737e-02,  4.5956e-02,\n",
       "                       2.3323e-02, -3.7467e-02, -4.0692e-02, -1.7497e-02, -1.7762e-02,\n",
       "                      -5.7937e-02, -8.8918e-02,  9.5461e-02,  4.9966e-03,  3.5089e-02,\n",
       "                      -2.9846e-02,  7.0613e-03, -6.9217e-02,  9.9124e-02, -5.5895e-02,\n",
       "                       7.3908e-02,  4.2186e-03, -6.6830e-02,  2.2228e-03,  1.3826e-03,\n",
       "                      -5.0106e-02, -8.1044e-02,  8.6144e-02,  9.9316e-02,  5.8107e-02,\n",
       "                      -4.2341e-03, -1.2161e-01,  1.7558e-02, -2.0554e-02,  6.4554e-02,\n",
       "                       6.3170e-02, -5.9232e-02,  3.0071e-02, -9.1322e-02,  1.1285e-02,\n",
       "                       1.0183e-01,  9.0252e-02,  6.0811e-02, -5.7993e-02, -8.9038e-03,\n",
       "                       3.9626e-02, -3.0313e-02, -6.0946e-02, -6.2827e-02,  5.1603e-02,\n",
       "                      -4.9608e-02, -1.0293e-01,  9.8684e-02,  5.9090e-02,  8.2171e-02,\n",
       "                      -1.2210e-01,  2.2958e-02,  1.0011e-04,  1.1252e-02,  1.1200e-01,\n",
       "                       4.7166e-02, -3.9170e-02,  7.1433e-02,  5.6726e-02,  1.1172e-01,\n",
       "                       3.0972e-02,  1.0202e-01, -2.1346e-02, -1.0029e-03, -2.3210e-02,\n",
       "                       4.9386e-02,  1.7554e-02], device='cuda:0')),\n",
       "             ('word_emb.weight',\n",
       "              tensor([[-0.0231, -0.1089, -0.0314,  ..., -0.0823,  0.0072, -0.0278],\n",
       "                      [-0.0085, -0.1220,  0.0351,  ..., -0.0374,  0.0094, -0.0614],\n",
       "                      [-0.0476,  0.0218, -0.0224,  ...,  0.0235, -0.0009, -0.0247],\n",
       "                      ...,\n",
       "                      [-0.0081, -0.0108,  0.0223,  ...,  0.0252,  0.0296,  0.0094],\n",
       "                      [-0.0247, -0.0056, -0.0418,  ...,  0.0059, -0.0127, -0.0348],\n",
       "                      [ 0.0083, -0.0188,  0.0275,  ...,  0.0063,  0.0331,  0.0015]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.weight',\n",
       "              tensor([[ 0.1444,  0.0340,  0.0644,  ..., -0.0600,  0.0713,  0.0388],\n",
       "                      [-0.0251,  0.0054, -0.0187,  ..., -0.0408,  0.0636, -0.0873],\n",
       "                      [-0.0032,  0.0023, -0.0051,  ...,  0.0436, -0.0230,  0.0074],\n",
       "                      ...,\n",
       "                      [-0.1845,  0.0455,  0.0306,  ..., -0.0771,  0.1305, -0.0463],\n",
       "                      [ 0.0742,  0.0575,  0.0213,  ..., -0.0602, -0.1442,  0.0134],\n",
       "                      [-0.0883, -0.0248, -0.0477,  ..., -0.0651,  0.1710,  0.0396]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.bias',\n",
       "              tensor([ 0.0367,  0.0367,  0.0446,  0.0219,  0.0460,  0.0366,  0.0208,  0.0368,\n",
       "                       0.0274,  0.0283,  0.0334,  0.0452,  0.0585,  0.0373,  0.0305,  0.0137,\n",
       "                       0.0124,  0.0298,  0.0421,  0.0277,  0.0452,  0.0322,  0.0301,  0.0492,\n",
       "                       0.0437,  0.0297,  0.0410,  0.0243,  0.0189,  0.0304,  0.0339,  0.0521,\n",
       "                       0.0296,  0.0292,  0.0365,  0.0424,  0.0394,  0.0260,  0.0290, -0.1153,\n",
       "                       0.0482,  0.0323,  0.0422,  0.0447,  0.0325,  0.0543,  0.0319,  0.0278,\n",
       "                       0.0530,  0.0400,  0.0210,  0.0288,  0.0223,  0.0430,  0.0277,  0.0460,\n",
       "                       0.0547,  0.0531,  0.0318,  0.0242,  0.0095,  0.0335,  0.0366,  0.0305,\n",
       "                       0.0343,  0.0316, -0.1597, -0.0946,  0.0412,  0.0336,  0.0254,  0.0271,\n",
       "                       0.0375,  0.0436,  0.0252,  0.0342,  0.0261,  0.0067,  0.0355,  0.0286,\n",
       "                       0.0010,  0.0413,  0.0498,  0.0209,  0.0460,  0.0273,  0.0414,  0.0326,\n",
       "                       0.0336,  0.0391,  0.0352,  0.0262,  0.0508,  0.0134, -0.0046,  0.0165,\n",
       "                       0.0193, -0.0025,  0.0485,  0.0472,  0.0201,  0.0363,  0.0423,  0.0370,\n",
       "                       0.0229,  0.0158,  0.0182,  0.0356,  0.0272,  0.0355,  0.0479,  0.0462,\n",
       "                       0.0214,  0.0181,  0.0375,  0.0341,  0.0451,  0.0350,  0.0255,  0.0278,\n",
       "                       0.0413,  0.0445,  0.0490,  0.0332,  0.0314,  0.0382,  0.0394,  0.0175,\n",
       "                       0.0292,  0.0529,  0.0226,  0.0281,  0.0379,  0.0319,  0.0512,  0.0271,\n",
       "                      -0.0647,  0.0412,  0.0312,  0.0391,  0.0211,  0.0336,  0.0289,  0.0191,\n",
       "                       0.0337,  0.0268,  0.0303,  0.0473,  0.0328,  0.0516,  0.0380,  0.0246,\n",
       "                       0.0456,  0.0212,  0.0294,  0.0486,  0.0393,  0.0429,  0.0533,  0.0540,\n",
       "                       0.0356,  0.0228,  0.0508,  0.0241,  0.0382,  0.0146,  0.0449,  0.0329,\n",
       "                      -0.0008,  0.0428,  0.0238,  0.0272,  0.0252,  0.0412,  0.0356,  0.0387,\n",
       "                       0.0285,  0.0429,  0.0443,  0.0244,  0.0293,  0.0614,  0.0343,  0.0398,\n",
       "                       0.0358,  0.0491,  0.0581,  0.0435,  0.0199,  0.0336,  0.0417,  0.0509,\n",
       "                       0.0435,  0.0375, -0.1228,  0.0485,  0.0345,  0.0338,  0.0488,  0.0187,\n",
       "                       0.0395,  0.0460,  0.0413,  0.0592,  0.0222,  0.0452,  0.0471,  0.0249,\n",
       "                       0.0293,  0.0283,  0.0338,  0.0372,  0.0125,  0.0387,  0.0422,  0.0441,\n",
       "                       0.0643,  0.0339,  0.0435,  0.0504,  0.0268,  0.0346,  0.0377,  0.0376,\n",
       "                       0.0362,  0.0357,  0.0412,  0.0415,  0.0405,  0.0390,  0.0456,  0.0138,\n",
       "                       0.0539,  0.0319,  0.0322,  0.0483,  0.0394,  0.0345,  0.0548,  0.0461,\n",
       "                       0.0425,  0.0331,  0.0341,  0.0517,  0.0350,  0.0444,  0.0211,  0.0616,\n",
       "                       0.0328,  0.0437,  0.0298,  0.0275,  0.0497,  0.0511,  0.0505,  0.0459,\n",
       "                       0.0424,  0.0362,  0.0318,  0.0293,  0.0406,  0.0104, -0.0026,  0.0369,\n",
       "                       0.0401,  0.0542,  0.0514,  0.0374,  0.0310,  0.0505,  0.0122,  0.0537,\n",
       "                       0.0231,  0.0114,  0.0334,  0.0269,  0.0314,  0.0742,  0.0416,  0.0607,\n",
       "                       0.0224,  0.0553,  0.0150,  0.0325,  0.0202,  0.0368,  0.0151,  0.0342,\n",
       "                       0.0258,  0.0234,  0.0251,  0.0300,  0.0288,  0.0273,  0.0321,  0.0297,\n",
       "                       0.0494,  0.0158,  0.0285,  0.0372,  0.0474,  0.0394,  0.0414,  0.0234,\n",
       "                       0.0215,  0.0232,  0.0512,  0.0542,  0.0233,  0.0346,  0.0339,  0.0299,\n",
       "                       0.0217,  0.0494,  0.0446,  0.0281,  0.0337,  0.0264,  0.0284,  0.0275,\n",
       "                       0.0436,  0.0378,  0.0382,  0.0647,  0.0230,  0.0205,  0.0480,  0.0513,\n",
       "                       0.0315,  0.0357,  0.0339,  0.0303,  0.0326,  0.0506,  0.0328,  0.0204,\n",
       "                       0.0381,  0.0416,  0.0173,  0.0411,  0.0272,  0.0085,  0.0156,  0.0360,\n",
       "                       0.0204,  0.0305,  0.0407,  0.0119,  0.0505,  0.0621,  0.0526,  0.0305,\n",
       "                       0.0336,  0.0358,  0.0229,  0.0184,  0.0481,  0.0507,  0.0355,  0.0514,\n",
       "                       0.0353,  0.0256,  0.0560,  0.0376,  0.0208,  0.0431,  0.0445,  0.0349,\n",
       "                       0.0406,  0.0528,  0.0362,  0.0411,  0.0235,  0.0435,  0.0254,  0.0380,\n",
       "                       0.0340,  0.0437,  0.0214,  0.0261,  0.0569,  0.0366,  0.0340,  0.0397,\n",
       "                       0.0292,  0.0318,  0.0499,  0.0217,  0.0362,  0.0489,  0.0325,  0.0299,\n",
       "                       0.0347,  0.0140,  0.0401,  0.0337,  0.0293,  0.0319,  0.0401,  0.0166,\n",
       "                       0.0409,  0.0283,  0.0460,  0.0292, -0.0452,  0.0404,  0.0409,  0.0639,\n",
       "                       0.0544,  0.0192,  0.0343,  0.0396,  0.0338,  0.0390,  0.0247,  0.0402,\n",
       "                       0.0303,  0.0520,  0.0566,  0.0459,  0.0324,  0.0446,  0.0416,  0.0417,\n",
       "                       0.0429,  0.0408,  0.0326,  0.0238,  0.0261,  0.0343,  0.0249,  0.0375,\n",
       "                       0.0517,  0.0296,  0.0351,  0.0362,  0.0383,  0.0249,  0.0307,  0.0346,\n",
       "                       0.0210,  0.0310,  0.0382,  0.0436,  0.0326,  0.0161,  0.0220,  0.0578,\n",
       "                       0.0383,  0.0368,  0.0376,  0.0232,  0.0282,  0.0396,  0.0293,  0.0221,\n",
       "                       0.0396,  0.0393,  0.0216,  0.0416,  0.0284,  0.0104,  0.0295,  0.0528,\n",
       "                       0.0223,  0.0359,  0.0386,  0.0502,  0.0375,  0.0359,  0.0299,  0.0444,\n",
       "                       0.0233,  0.0225,  0.0430,  0.0231,  0.0368,  0.0465,  0.0291,  0.0449,\n",
       "                       0.0453, -0.0254,  0.0386,  0.0067,  0.0203,  0.0294,  0.0479,  0.0145,\n",
       "                       0.0424,  0.0439,  0.0434,  0.0364,  0.0114,  0.0381,  0.0510,  0.0276,\n",
       "                       0.0504,  0.0410,  0.0253,  0.0479,  0.0389,  0.0160,  0.0780,  0.0393,\n",
       "                       0.0206,  0.0410,  0.0437,  0.0506,  0.0463,  0.0419,  0.0185,  0.0493],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0307,  0.1376, -0.1259,  ...,  0.1168, -0.0896,  0.1418],\n",
       "                      [-0.0776,  0.0154,  0.0732,  ...,  0.1017,  0.0250,  0.1068],\n",
       "                      [ 0.1295,  0.0259,  0.0450,  ...,  0.0666, -0.1836,  0.0254],\n",
       "                      ...,\n",
       "                      [-0.0734,  0.1149, -0.0034,  ...,  0.0244,  0.0729,  0.0403],\n",
       "                      [ 0.0233, -0.0057, -0.1105,  ...,  0.0581,  0.0574,  0.0630],\n",
       "                      [ 0.0348, -0.0349, -0.0884,  ..., -0.0703,  0.0813, -0.0675]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.0504,  0.0212,  0.0022,  0.0093,  0.0279,  0.0439,  0.0426,  0.0800,\n",
       "                       0.0185,  0.0387,  0.0355, -0.0141,  0.0065,  0.0312,  0.0551,  0.0058,\n",
       "                       0.0553,  0.0417,  0.0232,  0.0351,  0.0283,  0.0414,  0.0464,  0.0411,\n",
       "                       0.0505,  0.0191,  0.0164, -0.0267,  0.0300,  0.0226,  0.0367,  0.0480,\n",
       "                       0.0487,  0.0170,  0.0403,  0.0387,  0.0288,  0.0126,  0.0152,  0.0068,\n",
       "                      -0.0252,  0.0085,  0.0476,  0.0299,  0.0429,  0.0683, -0.0072,  0.0150,\n",
       "                       0.0333,  0.0331,  0.0442,  0.0381,  0.0241,  0.0525,  0.0020,  0.0364,\n",
       "                       0.0290,  0.0310,  0.0431,  0.0215, -0.0232,  0.0296,  0.0324,  0.0382,\n",
       "                       0.0364,  0.0607,  0.0559,  0.0478,  0.0713,  0.0584,  0.0340,  0.0627,\n",
       "                       0.0277,  0.0508,  0.0381,  0.0389,  0.0223,  0.0102,  0.0263,  0.0363,\n",
       "                       0.0284,  0.0330,  0.0585,  0.0214,  0.0577,  0.0327,  0.0353,  0.0040,\n",
       "                       0.0646,  0.0359,  0.0555,  0.0409,  0.0464,  0.0225,  0.0331,  0.1127,\n",
       "                       0.0509,  0.0386,  0.0013,  0.0639,  0.0400,  0.0592,  0.0370,  0.0509,\n",
       "                       0.0241,  0.0281,  0.0544,  0.0423,  0.0530,  0.0372,  0.0399,  0.0856,\n",
       "                       0.0171, -0.0294,  0.0445,  0.0151,  0.0490,  0.0433,  0.0189,  0.0435,\n",
       "                       0.0258,  0.0083,  0.0336,  0.0276,  0.0512,  0.0406,  0.0370,  0.0197,\n",
       "                       0.0316,  0.0330,  0.0477,  0.0169,  0.0220,  0.0433,  0.0575,  0.0413,\n",
       "                       0.0679,  0.0384, -0.0251,  0.0254,  0.0546,  0.0362,  0.0482,  0.0326,\n",
       "                       0.0263, -0.0047, -0.0019,  0.0080, -0.0008,  0.0616, -0.0103,  0.0510,\n",
       "                       0.0318,  0.0506,  0.0032,  0.0481,  0.0234,  0.0524,  0.0317,  0.0267,\n",
       "                       0.0231,  0.0564, -0.0108,  0.0599,  0.0200,  0.0225,  0.0330,  0.0373,\n",
       "                       0.0364,  0.0255,  0.0035,  0.0215,  0.0492,  0.0392,  0.0290,  0.0336,\n",
       "                       0.0435,  0.0183,  0.0220,  0.0075,  0.0397,  0.0468,  0.0087,  0.0283,\n",
       "                       0.0179,  0.0056,  0.0041,  0.0308,  0.0331,  0.0268,  0.0514,  0.0010],\n",
       "                     device='cuda:0')),\n",
       "             ('dec_fc.weight',\n",
       "              tensor([[-0.0114,  0.0572, -0.0272,  ..., -0.0415,  0.0233,  0.0115],\n",
       "                      [-0.0003, -0.0729,  0.0486,  ...,  0.0926, -0.0621, -0.0563],\n",
       "                      [-0.0375, -0.0020, -0.0117,  ..., -0.0593,  0.0189,  0.0245],\n",
       "                      ...,\n",
       "                      [-0.0326,  0.0691, -0.0299,  ..., -0.0161,  0.0336,  0.0115],\n",
       "                      [-0.0013,  0.0943,  0.0008,  ..., -0.0436,  0.0268,  0.0173],\n",
       "                      [-0.0258,  0.0902, -0.0465,  ..., -0.0315,  0.0217,  0.0177]],\n",
       "                     device='cuda:0')),\n",
       "             ('dec_fc.bias',\n",
       "              tensor([-0.1765,  0.1406, -0.0783,  ..., -0.0784, -0.0632, -0.0761],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.bn0.weight',\n",
       "              tensor([1.2579, 1.2287, 1.1752, 1.1472, 1.1341, 1.1017, 1.0914, 1.0787, 1.0651,\n",
       "                      1.0756, 1.0683, 1.0589, 1.0478, 1.0323, 1.0432, 1.0094, 1.0038, 1.0202,\n",
       "                      1.0210, 1.0268, 1.0409, 1.0565, 1.0200, 1.0603, 1.0618, 1.0505, 1.0631,\n",
       "                      1.0512, 1.0770, 1.0790, 1.0833, 1.0788, 1.0826, 1.0741, 1.0893, 1.0994,\n",
       "                      1.1181, 1.1037, 1.1052, 1.1233, 1.1174, 1.1264, 1.1512, 1.1866, 1.2267,\n",
       "                      1.2610, 1.2632, 1.3015, 1.2884, 1.3413, 1.3513, 1.3659, 1.3383, 1.3445,\n",
       "                      1.3790, 1.3468, 1.3447, 1.3394, 1.2890, 1.2610, 1.2722, 1.2695, 1.2540,\n",
       "                      1.2942], device='cuda:0')),\n",
       "             ('encoder.base.bn0.bias',\n",
       "              tensor([ 0.1418,  0.1614,  0.2051,  0.2250,  0.2054,  0.2128,  0.2234,  0.2539,\n",
       "                       0.2251,  0.2122,  0.2185,  0.2002,  0.2017,  0.1822,  0.1683,  0.1444,\n",
       "                       0.1269,  0.1714,  0.1422,  0.1387,  0.1513,  0.1419,  0.1510,  0.1334,\n",
       "                       0.1520,  0.1332,  0.1163,  0.1276,  0.1073,  0.1257,  0.1314,  0.1131,\n",
       "                       0.1414,  0.1328,  0.1064,  0.1035,  0.0991,  0.1022,  0.1113,  0.1031,\n",
       "                       0.0918,  0.0667,  0.0340,  0.0058, -0.0343, -0.0510, -0.0735, -0.0952,\n",
       "                      -0.1210, -0.1620, -0.1719, -0.1713, -0.1978, -0.1898, -0.2296, -0.2104,\n",
       "                      -0.2010, -0.2143, -0.1837, -0.2698, -0.2991, -0.3428, -0.3216, -0.2706],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.bn0.running_mean',\n",
       "              tensor([-11.1140, -11.0367, -11.6734, -12.0733, -12.2690, -13.1829, -12.8244,\n",
       "                      -13.8654, -13.6266, -14.1256, -14.2417, -14.2807, -15.1179, -14.4914,\n",
       "                      -15.3485, -15.0152, -15.6214, -15.3768, -15.8950, -15.9210, -16.0077,\n",
       "                      -16.3230, -16.5533, -16.4185, -16.8656, -16.9338, -17.1143, -17.2644,\n",
       "                      -17.5348, -17.6393, -17.8601, -18.0469, -18.2951, -18.5422, -18.7396,\n",
       "                      -18.8787, -19.0903, -19.3984, -19.7062, -19.8755, -20.3276, -20.6704,\n",
       "                      -20.9696, -21.2577, -21.5934, -21.9502, -22.1573, -22.3885, -22.6773,\n",
       "                      -23.0146, -23.3851, -23.7347, -23.9969, -24.3780, -24.8172, -25.1915,\n",
       "                      -25.6874, -26.2066, -26.6295, -27.0645, -27.5256, -27.8966, -28.4427,\n",
       "                      -29.7023], device='cuda:0')),\n",
       "             ('encoder.base.bn0.running_var',\n",
       "              tensor([108.5400, 100.5474, 104.6310, 106.9863, 107.7479, 114.1496, 111.6755,\n",
       "                      120.0199, 117.8161, 121.8113, 122.4541, 121.5557, 126.3898, 121.3896,\n",
       "                      127.6692, 124.6137, 129.6735, 125.9474, 126.5959, 126.0733, 128.5122,\n",
       "                      131.1895, 132.9866, 131.1968, 136.2513, 136.4128, 137.8435, 138.7266,\n",
       "                      140.4252, 142.1982, 143.6312, 146.2618, 149.1181, 150.0039, 152.3840,\n",
       "                      154.4992, 157.6141, 161.5698, 165.2521, 167.2338, 169.0995, 172.5907,\n",
       "                      176.6368, 178.3062, 181.3046, 186.4619, 188.5393, 190.9229, 195.1447,\n",
       "                      199.3110, 203.5005, 207.1522, 209.5275, 213.5443, 217.1879, 221.1509,\n",
       "                      225.1093, 229.9661, 233.8673, 238.2281, 244.0726, 246.9852, 253.2982,\n",
       "                      270.9163], device='cuda:0')),\n",
       "             ('encoder.base.bn0.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.conv1.weight',\n",
       "              tensor([[[[-3.7039e-02, -4.2758e-01,  4.6078e-01],\n",
       "                        [-9.8838e-02, -4.7424e-01,  3.5086e-01],\n",
       "                        [ 5.4757e-02, -2.9605e-01,  4.8484e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3487e-01, -2.7748e-01, -2.2969e-01],\n",
       "                        [-2.5529e-03, -1.0134e-01, -9.9216e-02],\n",
       "                        [ 8.8498e-02,  4.3399e-01,  3.1902e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8117e-01,  2.1679e-01,  8.6598e-03],\n",
       "                        [-3.0433e-01,  4.2776e-01, -2.8384e-02],\n",
       "                        [-3.1323e-01,  3.7712e-01, -8.6349e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1328e-01, -4.7214e-01, -1.5421e-01],\n",
       "                        [-7.4739e-03,  1.5373e-01, -9.9434e-02],\n",
       "                        [ 5.1257e-01,  3.8470e-01,  2.0314e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2202e-01,  1.1475e-01,  1.7375e-01],\n",
       "                        [ 4.6711e-02, -2.4738e-01, -1.1763e-01],\n",
       "                        [-1.2941e-01, -1.4176e-01, -8.9102e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.6680e-01, -5.6923e-01, -3.8833e-01],\n",
       "                        [ 7.2493e-01, -2.7824e-01,  9.7279e-03],\n",
       "                        [ 2.4725e-01, -1.6016e-01,  9.7753e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4617e-01,  1.1877e-01,  9.5465e-02],\n",
       "                        [ 5.3723e-02,  1.6259e-02,  3.4303e-02],\n",
       "                        [-2.3713e-01, -1.7044e-01, -7.7720e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7280e-01,  5.4870e-01, -3.0124e-01],\n",
       "                        [-3.1358e-01,  4.4885e-01, -2.8404e-01],\n",
       "                        [-1.4353e-01,  5.0320e-01, -2.3500e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.4014e-04, -6.3007e-02, -2.5290e-01],\n",
       "                        [-1.3695e-02, -7.0924e-02, -1.0243e-01],\n",
       "                        [ 1.5860e-01,  2.4922e-01,  7.3565e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2324e-01, -2.8807e-01,  7.9693e-01],\n",
       "                        [-2.5401e-01, -1.1556e-01,  2.5972e-01],\n",
       "                        [-2.0476e-01, -4.7462e-01, -3.4198e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0406e-01,  5.1279e-02, -3.6834e-01],\n",
       "                        [-2.3591e-01,  2.6704e-01,  1.5689e-01],\n",
       "                        [-2.8982e-01, -2.9980e-02,  1.7038e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.3808e-02, -2.1475e-01,  2.4791e-01],\n",
       "                        [-1.5626e-01, -2.8334e-01,  9.1087e-02],\n",
       "                        [-8.4360e-02, -1.1746e-01,  1.6794e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2985e-01, -1.6245e-01, -3.5523e-01],\n",
       "                        [ 5.0251e-01, -1.0382e-01, -3.8975e-01],\n",
       "                        [ 2.4276e-01,  5.4808e-02, -2.7259e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4744e-01,  2.3009e-01,  8.3530e-01],\n",
       "                        [-1.4976e-01, -2.8275e-01,  2.4763e-01],\n",
       "                        [-1.9248e-01, -3.3660e-01, -1.4239e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.4622e-02, -5.6861e-02, -4.1197e-01],\n",
       "                        [ 5.7208e-01, -5.0864e-02, -4.3210e-01],\n",
       "                        [ 5.4853e-01,  5.0650e-02, -3.2082e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6556e-01, -5.3412e-01, -2.3066e-01],\n",
       "                        [-2.8875e-02,  2.4764e-02, -1.6386e-01],\n",
       "                        [-3.9200e-03,  5.5788e-01,  2.6252e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1720e-01, -4.7870e-01,  1.1784e-01],\n",
       "                        [-2.0684e-01,  6.2280e-02,  4.1311e-01],\n",
       "                        [ 5.6433e-02,  4.4781e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1200e-01,  2.7321e-01, -3.9600e-02],\n",
       "                        [-3.1901e-01,  3.1452e-01, -2.7479e-03],\n",
       "                        [-3.3993e-01,  3.6536e-01,  5.1426e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2003e-01,  1.8998e-01,  1.2129e-01],\n",
       "                        [-2.7666e-01,  9.2499e-02, -4.6375e-02],\n",
       "                        [-1.4448e-01,  6.8090e-02,  7.0098e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.7226e-02, -1.2127e-01,  2.3658e-01],\n",
       "                        [-2.4300e-01, -1.9383e-01,  1.1952e-01],\n",
       "                        [ 2.2897e-02, -8.7058e-02,  3.2172e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.3028e-02, -2.3576e-01,  4.1035e-02],\n",
       "                        [ 1.6508e-01, -1.1036e-01,  9.5125e-02],\n",
       "                        [-2.9840e-03,  1.8085e-01,  2.6306e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4316e-01,  1.1665e+00, -4.3412e-01],\n",
       "                        [ 6.2403e-02, -5.5574e-01,  1.2445e-01],\n",
       "                        [ 5.2582e-02, -3.2262e-01,  1.8072e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5395e-01,  6.7191e-01, -4.2608e-01],\n",
       "                        [ 1.4435e-01,  7.4019e-01, -1.7308e-01],\n",
       "                        [-2.6455e-01, -1.5263e-02, -2.0942e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5521e-01, -2.1611e-01,  7.1947e-02],\n",
       "                        [ 3.0966e-01, -3.0091e-01, -7.8164e-03],\n",
       "                        [ 3.0483e-01, -3.1466e-01,  1.5690e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9823e-01, -4.2168e-01,  6.0279e-02],\n",
       "                        [-3.2808e-01, -3.3818e-01,  3.4307e-01],\n",
       "                        [-9.1788e-02,  2.4978e-01,  6.2914e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0916e-01, -1.0632e-02,  4.5488e-01],\n",
       "                        [ 1.1837e-02, -5.0426e-01,  5.5825e-02],\n",
       "                        [ 1.8273e-01, -5.3850e-01,  8.3406e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.7359e-01, -1.8598e-01,  2.1945e-02],\n",
       "                        [ 2.8800e-01, -1.5747e-01, -1.0243e-01],\n",
       "                        [ 1.2883e-01, -3.4466e-01, -1.4244e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6872e-01, -1.4464e-01,  2.2020e-01],\n",
       "                        [-2.9175e-01,  2.2592e-01,  2.0379e-01],\n",
       "                        [-1.6604e-01,  2.6496e-01, -8.3792e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.5360e-02,  3.8966e-01,  1.4031e-01],\n",
       "                        [ 1.2257e-02,  2.1597e-02, -4.7005e-02],\n",
       "                        [ 9.1067e-02, -1.6526e-01, -1.9378e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0163e-01, -4.5580e-01,  3.1707e-01],\n",
       "                        [ 1.8935e-01, -4.5179e-01,  2.3650e-01],\n",
       "                        [ 2.7485e-01, -4.0986e-01,  2.1443e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7262e-01, -1.0266e-01, -4.1695e-01],\n",
       "                        [ 4.8492e-01, -2.3177e-03, -4.4562e-01],\n",
       "                        [ 3.3022e-01,  6.2551e-02, -3.2547e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2101e-01,  1.0126e-01, -3.6913e-02],\n",
       "                        [ 1.4700e-01,  6.9705e-02, -3.9404e-02],\n",
       "                        [-5.5072e-02, -1.1184e-01, -6.6921e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.8531e-01, -4.7569e-02, -2.3400e-01],\n",
       "                        [ 3.4791e-01, -7.7497e-02, -2.4477e-01],\n",
       "                        [ 3.7497e-01, -1.4277e-01, -3.4089e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1033e+00,  1.2753e-01, -6.2010e-03],\n",
       "                        [-7.2243e-01, -4.6420e-01, -5.2412e-03],\n",
       "                        [-3.7374e-01,  4.0990e-01, -7.4779e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1552e-01,  5.3512e-01,  8.1034e-02],\n",
       "                        [-1.1637e-01,  3.2702e-02,  9.7668e-03],\n",
       "                        [ 7.4868e-01, -5.4375e-01, -1.1775e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.5149e-01,  1.8367e-01,  5.9942e-01],\n",
       "                        [ 6.4945e-02, -3.3298e-01,  4.7456e-02],\n",
       "                        [-7.2457e-02, -6.4503e-01, -2.3545e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3996e-01, -4.6708e-01,  6.5029e-02],\n",
       "                        [ 4.1431e-01, -5.8810e-01, -1.2947e-01],\n",
       "                        [ 6.3620e-01, -4.6198e-01,  8.9512e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8400e-01,  6.0769e-01,  3.9696e-01],\n",
       "                        [-1.0041e-01, -5.5067e-02, -6.5041e-02],\n",
       "                        [-4.0160e-01, -5.5484e-01, -4.9943e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.7577e-01,  9.2406e-02,  9.8464e-02],\n",
       "                        [-2.4153e-01, -1.5672e-02,  1.2420e-01],\n",
       "                        [-6.3149e-01, -2.6339e-02,  4.9605e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.2362e-01, -4.3782e-01, -5.7199e-01],\n",
       "                        [ 5.7036e-02,  1.7327e-01,  5.8640e-02],\n",
       "                        [ 3.2428e-01,  2.6780e-01,  1.1553e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.2817e-02,  2.5345e-01, -2.3407e-01],\n",
       "                        [ 6.5310e-02,  1.0996e-01, -1.5513e-01],\n",
       "                        [-2.7904e-02,  2.7827e-01, -2.4337e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1770e-01,  3.1490e-01, -9.0855e-01],\n",
       "                        [-1.3766e-01,  3.3192e-03,  7.7066e-01],\n",
       "                        [-5.3093e-02, -3.6863e-01,  2.3213e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.5213e-02, -4.4828e-01,  6.2535e-02],\n",
       "                        [ 5.3619e-02, -4.0840e-01,  4.2392e-03],\n",
       "                        [ 2.0112e-01, -2.2866e-01,  3.0056e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9792e-01,  2.0081e-01,  1.9037e-01],\n",
       "                        [-2.4127e-01, -3.5608e-01, -2.4821e-01],\n",
       "                        [-3.8929e-02,  1.7353e-01, -4.8857e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0018e-01,  1.3077e-03, -2.7321e-01],\n",
       "                        [ 2.7165e-02,  3.3843e-02, -7.1168e-02],\n",
       "                        [ 5.3553e-02,  2.3183e-01, -4.2740e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8983e-01, -3.7882e-02,  7.5205e-01],\n",
       "                        [-4.3510e-01, -2.7665e-01,  5.3879e-01],\n",
       "                        [-3.7065e-01, -1.9793e-01,  3.8153e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0559e-01,  3.1273e-01,  1.5594e-01],\n",
       "                        [ 1.7393e-01, -6.1596e-02, -2.1482e-01],\n",
       "                        [ 1.0072e-01, -3.6248e-01, -2.6370e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0709e-01, -2.5422e-01,  5.1832e-02],\n",
       "                        [ 2.1006e-01, -1.3040e-01, -6.3120e-02],\n",
       "                        [ 6.7084e-02, -9.1186e-02,  8.9826e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0937e-01,  3.9595e-01,  2.2122e-01],\n",
       "                        [-1.6386e-01,  2.8206e-02, -1.7149e-01],\n",
       "                        [-4.2785e-01, -1.2610e-01, -1.6499e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4867e-01, -2.5180e-01, -3.5126e-01],\n",
       "                        [-1.1301e-01, -1.2536e-01, -8.0463e-02],\n",
       "                        [ 8.8822e-01,  3.9861e-01,  2.1695e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0753e-02,  4.4991e-02, -2.4421e-01],\n",
       "                        [ 9.5658e-03,  2.3654e-01, -2.5991e-01],\n",
       "                        [ 2.4366e-02,  3.8166e-01, -2.2451e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.7838e-01, -5.9983e-02,  1.4472e-01],\n",
       "                        [ 2.1890e-01, -8.2260e-02,  3.5236e-02],\n",
       "                        [-1.6305e-01, -5.5475e-01, -3.4149e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1640e-01,  7.8737e-02, -1.7762e-01],\n",
       "                        [-1.4516e-02,  1.3225e-01,  2.5413e-02],\n",
       "                        [-2.8115e-02,  1.8151e-01, -3.3639e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3240e-01, -3.6960e-01, -1.5010e-01],\n",
       "                        [ 6.2620e-02,  2.2893e-02,  1.1247e-01],\n",
       "                        [ 2.6827e-01,  3.7458e-01, -8.5182e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0860e-01,  1.1462e+00, -4.2346e-02],\n",
       "                        [-1.4127e-01,  3.0784e-01, -4.1399e-02],\n",
       "                        [-3.6094e-01, -1.9679e-01, -2.6113e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3481e-01, -2.5167e-01,  3.8530e-01],\n",
       "                        [-1.3977e-01, -3.6216e-01,  1.1309e-03],\n",
       "                        [ 2.0413e-01, -4.5980e-01,  2.9574e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.7680e-02,  2.6627e-01, -2.8784e-01],\n",
       "                        [-3.3592e-01,  2.4736e-01, -1.2399e-01],\n",
       "                        [-2.8255e-01,  8.0267e-01, -4.0267e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3659e-01, -5.6885e-01, -5.8263e-02],\n",
       "                        [ 2.3202e-01, -3.7275e-01,  4.3137e-02],\n",
       "                        [ 2.3751e-01, -1.1991e-01,  2.6967e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7833e-01,  6.2141e-01,  4.1701e-01],\n",
       "                        [-9.2735e-02, -3.6468e-02, -3.5021e-01],\n",
       "                        [-5.1336e-02,  1.1924e-01, -1.3558e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.9185e-01,  2.7757e-01,  1.5429e-01],\n",
       "                        [ 2.0638e-01, -9.3221e-02, -4.2492e-02],\n",
       "                        [-3.6869e-01, -2.5070e-01, -3.6196e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1912e-01, -3.4506e-01, -2.0505e-01],\n",
       "                        [-3.5524e-02,  5.3625e-02,  3.3577e-01],\n",
       "                        [ 1.5814e-01, -1.6911e-02,  5.5144e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1422e-01, -9.4341e-02,  4.3752e-02],\n",
       "                        [ 1.3863e+00, -7.7188e-02,  1.9691e-02],\n",
       "                        [-3.5302e-01, -1.1650e-01, -4.4031e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.5821e-01,  1.7370e-01,  3.0065e-01],\n",
       "                        [-4.7475e-01, -6.5231e-01, -4.0496e-01],\n",
       "                        [ 1.6438e-01,  4.0722e-01,  1.4705e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6765e-01, -3.5122e-01, -3.0718e-01],\n",
       "                        [-3.7997e-02, -1.8845e-01,  5.6407e-02],\n",
       "                        [ 2.3948e-01,  2.0316e-01,  6.8780e-01]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.conv2.weight',\n",
       "              tensor([[[[ 3.7716e-02,  3.8377e-01, -2.6829e-02],\n",
       "                        [ 1.4405e-02, -2.7071e-02, -1.1790e-01],\n",
       "                        [ 3.1483e-02, -1.2675e-01,  1.0402e-01]],\n",
       "              \n",
       "                       [[-1.3191e-01,  5.1577e-02,  9.3906e-02],\n",
       "                        [-1.0973e-01,  1.2606e-01,  6.9330e-02],\n",
       "                        [-7.9789e-02,  1.4824e-01, -2.2891e-01]],\n",
       "              \n",
       "                       [[ 8.4112e-02, -6.5050e-02,  2.2053e-02],\n",
       "                        [-1.6003e-02,  3.6255e-02, -1.0961e-01],\n",
       "                        [ 2.1383e-03,  1.7355e-01, -2.0730e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.2900e-01, -9.4333e-02, -4.8292e-01],\n",
       "                        [ 1.5381e-01, -8.5188e-03,  2.9697e-02],\n",
       "                        [ 1.7547e-01,  5.9568e-02,  4.1180e-01]],\n",
       "              \n",
       "                       [[-6.4412e-02,  2.3372e-02, -8.3541e-02],\n",
       "                        [-5.3537e-02, -8.9693e-02, -1.3112e-02],\n",
       "                        [-5.3418e-02, -4.0995e-02,  1.0250e-01]],\n",
       "              \n",
       "                       [[-2.1671e-01,  2.8036e-02, -1.3197e-04],\n",
       "                        [-3.4290e-02,  5.9299e-02, -1.8906e-02],\n",
       "                        [-5.3243e-02, -4.2178e-02,  2.6321e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0785e+00, -2.0748e-01,  7.5568e-02],\n",
       "                        [ 2.0621e-01, -5.9543e-02,  6.3722e-02],\n",
       "                        [-6.5188e-01, -1.2228e-02,  1.1816e-01]],\n",
       "              \n",
       "                       [[-1.2173e-01,  1.9149e-01,  8.3929e-02],\n",
       "                        [ 8.3358e-02, -2.0013e-01, -1.1041e-02],\n",
       "                        [ 2.7151e-01, -3.6403e-01, -4.3889e-02]],\n",
       "              \n",
       "                       [[-1.7432e-01,  1.5744e-01, -2.0128e-01],\n",
       "                        [ 2.6894e-02, -1.1746e-01, -5.5749e-03],\n",
       "                        [ 2.9326e-01, -4.2377e-01,  5.7002e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.5385e-01, -8.2642e-01,  3.3079e-01],\n",
       "                        [-4.6052e-02, -1.7915e-01,  1.1808e-01],\n",
       "                        [-5.4963e-01,  1.0333e+00, -2.4473e-01]],\n",
       "              \n",
       "                       [[-6.9922e-02,  1.3253e-01,  8.7043e-02],\n",
       "                        [ 1.5732e-01,  1.6859e-01, -2.4649e-02],\n",
       "                        [ 4.5574e-02, -1.4071e-01, -1.5539e-01]],\n",
       "              \n",
       "                       [[ 1.2706e-01,  3.1828e-02,  1.1200e-01],\n",
       "                        [ 9.8312e-02,  3.1909e-02,  8.6010e-02],\n",
       "                        [ 1.4542e-02, -3.4562e-04,  8.4735e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.7297e-02, -1.1035e-01, -1.1087e-01],\n",
       "                        [-7.3131e-02, -9.5376e-02, -9.5487e-02],\n",
       "                        [-8.0729e-02, -9.2381e-04,  2.4190e-02]],\n",
       "              \n",
       "                       [[-1.7203e-01, -4.6300e-01,  2.5281e-01],\n",
       "                        [-1.5188e-01, -4.7515e-01, -3.0280e-02],\n",
       "                        [ 6.9937e-02, -1.2466e-01,  4.5305e-01]],\n",
       "              \n",
       "                       [[ 8.2297e-02,  1.0682e-01,  2.8612e-02],\n",
       "                        [ 1.3627e-01,  4.2858e-02, -3.2870e-02],\n",
       "                        [-3.5023e-02, -7.2602e-02, -2.1970e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.8166e-02,  1.6987e-01,  2.3324e-01],\n",
       "                        [ 2.0293e-01, -1.0903e-02, -1.6093e-01],\n",
       "                        [ 1.5683e-01, -1.1523e-01, -3.9176e-01]],\n",
       "              \n",
       "                       [[ 2.7918e-02, -5.2651e-02, -3.0204e-02],\n",
       "                        [-6.0518e-02, -1.3612e-01, -2.5142e-01],\n",
       "                        [ 8.2353e-02, -6.1556e-02,  5.9971e-02]],\n",
       "              \n",
       "                       [[-7.5691e-02, -5.9457e-03, -4.2270e-02],\n",
       "                        [-4.8160e-02, -3.5608e-02, -2.8247e-02],\n",
       "                        [-1.7834e-02, -7.6805e-02,  2.5366e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-4.9454e-02, -5.7105e-03, -8.8107e-02],\n",
       "                        [-3.6103e-02,  2.0379e-01,  3.4189e-01],\n",
       "                        [-4.2215e-02, -2.1860e-01, -2.4045e-01]],\n",
       "              \n",
       "                       [[-3.0638e-01, -1.8374e-01, -3.8692e-01],\n",
       "                        [ 4.3731e-01,  6.7990e-01,  3.9994e-01],\n",
       "                        [-3.8064e-01, -3.3509e-01, -6.1751e-01]],\n",
       "              \n",
       "                       [[-1.5306e-02, -1.0777e-02, -4.1142e-02],\n",
       "                        [-8.7511e-02, -1.0601e-01, -1.5231e-01],\n",
       "                        [-1.8568e-02,  3.6170e-02, -7.9173e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.1569e-01,  2.8898e-01,  3.5592e-01],\n",
       "                        [-1.0991e+00, -7.5708e-01, -8.5644e-01],\n",
       "                        [ 6.9730e-01,  1.2808e-01,  4.9305e-01]],\n",
       "              \n",
       "                       [[-6.9309e-02, -2.3946e-02, -6.7120e-02],\n",
       "                        [ 7.7438e-02,  7.9852e-02, -2.2187e-02],\n",
       "                        [-5.7858e-02, -7.3175e-03, -4.6205e-02]],\n",
       "              \n",
       "                       [[ 2.4485e-01,  3.5203e-01,  1.8942e-01],\n",
       "                        [-2.1788e-01, -1.4184e-01, -1.8707e-01],\n",
       "                        [-1.7722e-01, -9.8066e-02, -2.2995e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2625e-02,  1.0379e-02, -8.0609e-02],\n",
       "                        [ 5.3149e-02, -9.3726e-02, -1.0543e-01],\n",
       "                        [ 4.8197e-02, -5.4563e-02, -4.1949e-02]],\n",
       "              \n",
       "                       [[ 1.4315e-02,  7.2706e-02, -6.4910e-02],\n",
       "                        [-3.9319e-02, -1.9981e-01, -9.3217e-02],\n",
       "                        [ 5.4948e-02,  7.2174e-02,  5.5379e-02]],\n",
       "              \n",
       "                       [[-2.6129e-02, -1.1373e-02, -1.9768e-02],\n",
       "                        [ 2.1967e-02,  6.3522e-02,  1.2756e-02],\n",
       "                        [ 9.7849e-02,  8.7106e-02,  4.9843e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5595e-02, -1.5106e-01,  2.8897e-01],\n",
       "                        [ 9.5800e-02, -1.1059e-01,  1.5325e-01],\n",
       "                        [ 2.9394e-02, -2.9501e-02,  1.2501e-01]],\n",
       "              \n",
       "                       [[ 1.2613e-01,  6.3016e-02,  2.7176e-02],\n",
       "                        [-5.3751e-02, -8.8469e-02, -2.4307e-02],\n",
       "                        [ 7.0750e-02,  2.2604e-02,  1.4919e-02]],\n",
       "              \n",
       "                       [[ 2.6332e-02, -2.9871e-02,  7.3902e-02],\n",
       "                        [ 5.8938e-02,  8.6006e-02,  3.4223e-02],\n",
       "                        [-2.8744e-02,  8.2594e-03,  1.7609e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7435e-01,  4.7874e-02,  7.0055e-02],\n",
       "                        [ 8.6948e-02,  3.3030e-01,  1.3110e-01],\n",
       "                        [ 1.5556e-01,  3.2963e-01,  1.5869e-01]],\n",
       "              \n",
       "                       [[-6.3539e-01, -6.0424e-01, -2.4252e-01],\n",
       "                        [-1.3502e-01, -1.3486e-01, -3.6140e-01],\n",
       "                        [-5.2280e-01, -4.7667e-01, -5.4187e-01]],\n",
       "              \n",
       "                       [[ 1.0034e-01, -3.9097e-01, -6.2816e-01],\n",
       "                        [-5.8587e-02, -3.5102e-01, -4.4382e-01],\n",
       "                        [-1.9356e-02, -2.9316e-01, -2.4458e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.3339e-01, -3.5807e-01, -7.3283e-03],\n",
       "                        [ 9.7241e-03, -1.2542e-01,  4.9291e-02],\n",
       "                        [ 2.5228e-01, -1.4051e-01, -8.6471e-02]],\n",
       "              \n",
       "                       [[-6.5190e-02, -1.7026e-01, -9.0556e-02],\n",
       "                        [ 1.3915e-01, -3.3030e-02, -7.1347e-02],\n",
       "                        [-2.2762e-05, -1.7184e-01, -1.6950e-02]],\n",
       "              \n",
       "                       [[ 7.2244e-02,  7.6516e-02, -2.7654e-03],\n",
       "                        [ 1.0507e-01, -4.3255e-04,  5.2007e-02],\n",
       "                        [ 2.0332e-02,  1.0466e-01,  5.0690e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.weight',\n",
       "              tensor([1.0147, 1.8317, 0.8301, 1.2968, 0.5953, 0.7233, 0.7475, 1.2259, 0.7721,\n",
       "                      1.0568, 1.3650, 0.3360, 0.4459, 0.6781, 0.6541, 0.3440, 0.5908, 1.0499,\n",
       "                      0.6292, 0.5092, 0.6707, 2.1327, 1.5605, 0.8525, 0.6335, 0.9048, 0.8897,\n",
       "                      0.6496, 1.0510, 1.3799, 0.9359, 0.6482, 0.5818, 1.7507, 2.3637, 0.6982,\n",
       "                      0.9968, 0.4719, 0.5994, 0.5357, 0.7040, 2.0022, 0.6293, 0.2890, 0.5688,\n",
       "                      0.9239, 0.6793, 0.5159, 0.4398, 0.5231, 0.6452, 0.8483, 0.5375, 1.9732,\n",
       "                      0.8341, 0.7305, 1.1377, 1.0964, 0.8403, 0.4709, 0.7815, 1.3541, 0.9502,\n",
       "                      1.0875], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.bias',\n",
       "              tensor([ 0.6754,  0.1345,  0.0220,  1.3368, -0.6749,  0.0839, -1.3812, -1.3433,\n",
       "                      -0.7652,  0.2082, -1.0769,  0.1627,  0.0673,  0.0511,  0.1200,  0.1681,\n",
       "                       0.0150,  0.0098, -0.7188, -0.5221, -0.8065,  0.4152,  0.2131, -1.1045,\n",
       "                       0.0147, -1.0571,  0.0904, -0.7248, -0.9289, -0.0724,  0.0621, -0.8089,\n",
       "                       0.0928,  0.1172,  0.0503,  0.1471,  0.6545,  0.1610, -0.4684,  0.0174,\n",
       "                      -0.8001,  0.3992, -0.6326,  0.1002, -0.7923,  0.0503, -0.4399, -0.1764,\n",
       "                      -1.0168,  0.0272, -0.1202,  0.1499, -0.9979,  0.2602, -0.7370,  0.1048,\n",
       "                       0.8390, -0.2476,  0.0871,  0.0680,  0.1174,  1.5486, -1.0039, -1.6553],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.running_mean',\n",
       "              tensor([-2.6442e-03, -1.0105e-03, -7.4347e-03, -5.6551e-04, -5.9022e-03,\n",
       "                       8.1001e-03, -7.3443e-04, -3.3866e-03, -3.5781e-06, -1.8388e-03,\n",
       "                       2.9289e-04, -1.3109e-02,  4.9675e-03, -5.5409e-03,  4.4445e-03,\n",
       "                      -1.7432e-02, -1.1836e-02, -6.5054e-03, -8.9932e-03, -4.7090e-03,\n",
       "                       1.2896e-02,  1.2038e-03,  1.9172e-04,  3.8127e-03, -9.4586e-03,\n",
       "                      -1.5608e-03,  3.7078e-03, -9.7344e-04,  6.8434e-03,  1.3096e-03,\n",
       "                       5.8198e-03, -7.2441e-03,  1.2007e-02,  3.0239e-04,  6.6009e-04,\n",
       "                       4.3699e-03,  6.0325e-03, -1.0725e-02, -4.3649e-02, -1.8055e-02,\n",
       "                       1.5195e-03, -1.7206e-03, -1.6533e-02, -7.0380e-03, -9.7681e-03,\n",
       "                      -5.4719e-03,  5.8173e-04,  8.5079e-04, -4.3638e-03,  1.9839e-02,\n",
       "                       7.8969e-04,  8.3074e-03, -7.5507e-03, -1.3189e-03,  2.5798e-02,\n",
       "                       5.1496e-03, -2.1499e-03,  2.5010e-03, -1.7609e-03,  1.6992e-02,\n",
       "                       4.3116e-03,  3.5006e-03,  6.6559e-04, -7.5510e-04], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.running_var',\n",
       "              tensor([0.0990, 0.0290, 0.0589, 0.0637, 0.0521, 0.1160, 0.0099, 0.0679, 0.0146,\n",
       "                      0.0908, 0.0122, 0.1292, 0.1407, 0.1051, 0.1647, 0.2356, 0.1505, 0.0526,\n",
       "                      0.0477, 0.0382, 0.1537, 0.0292, 0.0740, 0.0330, 0.1240, 0.0544, 0.0538,\n",
       "                      0.0369, 0.0421, 0.0523, 0.1617, 0.1542, 0.1353, 0.0649, 0.0190, 0.0816,\n",
       "                      0.1264, 0.2075, 1.1808, 0.3108, 0.0238, 0.0288, 0.2683, 0.0547, 0.0837,\n",
       "                      0.2347, 0.0352, 0.0102, 0.0502, 0.3289, 0.0327, 0.1034, 0.0380, 0.0303,\n",
       "                      0.6256, 0.0560, 0.0578, 0.0475, 0.0395, 0.2082, 0.0961, 0.0619, 0.0489,\n",
       "                      0.0635], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.weight',\n",
       "              tensor([1.4841, 1.2917, 1.0752, 0.9392, 1.3012, 0.5648, 0.7395, 1.2967, 0.3735,\n",
       "                      1.2988, 1.5531, 1.1796, 1.5098, 0.8108, 0.5671, 1.0800, 1.0263, 1.2715,\n",
       "                      1.3641, 1.3163, 1.5201, 0.6631, 1.1183, 1.1883, 1.2024, 0.8789, 1.3421,\n",
       "                      0.3771, 1.0490, 1.4551, 1.1245, 1.5359, 0.6782, 1.5352, 0.9282, 1.1248,\n",
       "                      1.3073, 0.9236, 1.2908, 1.3024, 0.4935, 1.0720, 0.8583, 1.5085, 1.4076,\n",
       "                      1.4440, 0.6413, 0.6526, 1.0588, 0.5574, 0.6595, 1.0363, 0.7635, 1.3950,\n",
       "                      1.3622, 1.1709, 0.8593, 0.5827, 0.9331, 1.3578, 1.2215, 0.9420, 0.5712,\n",
       "                      0.5443], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.bias',\n",
       "              tensor([-0.8234, -0.8081, -0.4838, -0.5944, -0.8566, -0.2404, -0.5236, -0.9160,\n",
       "                      -0.0529, -0.3748, -0.7467, -0.8183, -1.0355, -0.2404, -0.3608, -0.5537,\n",
       "                      -0.6094, -0.5815, -0.5941, -0.8944, -0.6258, -0.1631, -0.5619, -0.8486,\n",
       "                      -0.4367, -0.3251, -0.8718, -0.0486, -0.5740, -0.9323, -0.6806, -0.7423,\n",
       "                      -0.9645, -1.0283, -0.6479, -0.5786, -0.9397, -0.1561, -0.6581, -0.7995,\n",
       "                      -0.1054, -0.5006, -0.2690, -0.9833, -0.6177, -1.0039, -0.5419, -0.7335,\n",
       "                      -0.4527, -0.3228, -0.2103, -0.3911, -0.2588, -0.8303, -0.6102, -0.4021,\n",
       "                      -0.2842, -0.4564, -0.4216, -0.6266, -0.8774, -0.5110, -0.9052, -0.2076],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.running_mean',\n",
       "              tensor([ -7.5214,  -3.5263,  -7.6195,  -7.3292, -10.1689,  -3.5676,  -5.5123,\n",
       "                       -6.4482,   2.5568,  -7.0457,  -4.9308,  -4.0243,  -5.7459,  -3.0006,\n",
       "                       -0.4771,  -5.7695,  -6.4044,  -8.2480,  -9.8571,  -7.5985,  -7.1609,\n",
       "                      -10.7915,  -5.2936,  -5.5477,  -4.2093, -14.3836,  -9.0733,   0.5924,\n",
       "                       -5.9486,  -4.5786,  -9.5296, -18.9389,   7.1328,  -3.7252,  -4.3018,\n",
       "                       -4.3027,  -9.6727, -11.4089,  -8.2913,  -4.0851,  -8.5113, -13.2303,\n",
       "                       -5.4044,  -5.5494,  -6.0409,  -5.7176,  -0.3189,   2.1054, -11.1128,\n",
       "                        0.1121, -10.7496,  -4.8157,  -1.3577,  -5.7857,  -4.9932,  -8.8108,\n",
       "                       -5.8132,   0.7328,  -4.6833, -11.2964,  -6.6940,  -5.2393,   3.5756,\n",
       "                      -13.2411], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.running_var',\n",
       "              tensor([ 83.4874,  49.2280,  79.8500,  65.7017, 104.6649, 147.6423,  30.4582,\n",
       "                       79.2726,  38.4524, 135.0762,  43.4954,  34.0307,  43.2262,  56.8076,\n",
       "                       15.2798,  73.5737, 124.5944, 136.4150, 159.5756,  71.4369,  73.7142,\n",
       "                      121.5120,  84.3253,  40.6370,  41.4570, 250.3013, 146.4842,  39.3805,\n",
       "                      119.0096,  81.0722,  91.1335, 299.9778,  30.1207,  33.7678,  31.2618,\n",
       "                       38.2270,  95.4588, 211.1729, 157.5682,  25.0145,  58.4743, 142.2299,\n",
       "                       40.8495,  94.0520,  56.1689,  40.2752,  15.1789,  34.4148, 209.8351,\n",
       "                       20.2163,  81.0546,  39.9090,  31.7404,  59.5921,  76.8075, 138.7216,\n",
       "                      183.5796,  25.3117,  73.6397, 243.3807,  62.6100,  55.8699,  17.5195,\n",
       "                      227.4245], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.conv1.weight',\n",
       "              tensor([[[[-6.6612e-02, -5.9600e-02, -3.3646e-02],\n",
       "                        [-9.0082e-03, -3.4218e-02, -1.2638e-01],\n",
       "                        [-1.5268e-01, -5.2480e-02, -6.7372e-02]],\n",
       "              \n",
       "                       [[ 1.1773e-01,  1.3273e-01,  1.4331e-01],\n",
       "                        [ 1.5485e-02, -5.2641e-02,  6.5574e-02],\n",
       "                        [ 3.9865e-02,  6.6218e-02,  1.6867e-01]],\n",
       "              \n",
       "                       [[ 9.3612e-03, -3.2874e-03, -5.0931e-03],\n",
       "                        [ 1.0213e-02,  2.7881e-02,  5.9696e-02],\n",
       "                        [ 2.5336e-03,  5.3899e-02,  1.0334e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.3382e-02,  6.7181e-02,  6.3629e-02],\n",
       "                        [-8.2463e-03,  3.0971e-02,  3.6543e-02],\n",
       "                        [-3.2838e-02, -5.4525e-02, -1.0010e-01]],\n",
       "              \n",
       "                       [[ 5.8703e-03, -5.4488e-03, -7.4210e-03],\n",
       "                        [-8.8855e-03,  9.4491e-03, -2.4393e-02],\n",
       "                        [ 4.0046e-02,  2.7267e-02, -2.4605e-02]],\n",
       "              \n",
       "                       [[ 3.4274e-03, -1.7679e-02, -1.0506e-02],\n",
       "                        [-6.6787e-02, -2.9965e-02, -3.4468e-02],\n",
       "                        [-4.4432e-02, -1.3806e-02, -4.1295e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.9368e-02, -4.6169e-02, -3.1849e-02],\n",
       "                        [ 1.1523e-01,  1.7957e-01,  4.6607e-02],\n",
       "                        [ 5.8586e-03,  1.2307e-01,  1.4036e-02]],\n",
       "              \n",
       "                       [[-1.8446e-01, -2.0808e-01, -7.5956e-02],\n",
       "                        [-2.9685e-01, -2.9554e-01,  5.7040e-02],\n",
       "                        [-2.7504e-01,  6.5192e-02,  2.9643e-02]],\n",
       "              \n",
       "                       [[ 3.1143e-02,  5.7940e-02,  5.3295e-02],\n",
       "                        [-1.4687e-01, -2.6303e-01,  4.0375e-02],\n",
       "                        [ 8.0275e-02, -1.9773e-01,  7.4133e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.7884e-02, -6.6429e-02, -6.8187e-03],\n",
       "                        [-8.8455e-02, -2.1068e-01, -1.0393e-01],\n",
       "                        [ 4.0991e-02, -1.4381e-01, -1.1891e-01]],\n",
       "              \n",
       "                       [[ 3.8864e-02, -7.3408e-02, -1.0042e-01],\n",
       "                        [ 6.2543e-02, -1.5229e-02,  3.8400e-02],\n",
       "                        [-4.9299e-02, -1.4120e-01, -1.5871e-01]],\n",
       "              \n",
       "                       [[ 1.2304e-01,  1.6561e-01,  1.1603e-01],\n",
       "                        [-3.1976e-03,  1.5427e-01,  1.0683e-01],\n",
       "                        [ 1.0294e-01,  1.0579e-01,  1.8109e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3461e-01,  3.3709e-01, -1.2679e-01],\n",
       "                        [-1.1710e-01, -1.9431e-01, -2.6899e-01],\n",
       "                        [ 1.2496e-01, -2.3303e-01, -3.0178e-01]],\n",
       "              \n",
       "                       [[-7.5645e-01, -1.8989e-02, -1.4834e-01],\n",
       "                        [-1.5400e+00, -1.4846e+00, -2.8898e-01],\n",
       "                        [-1.9606e+00, -1.8870e+00, -6.1143e-01]],\n",
       "              \n",
       "                       [[ 7.4252e-02, -3.6760e-02,  2.5229e-01],\n",
       "                        [-5.4651e-03, -4.8606e-01,  6.3125e-02],\n",
       "                        [ 1.1650e-01, -6.2473e-01,  9.7307e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.3681e-02,  1.0975e-01, -1.4098e-01],\n",
       "                        [-1.3643e-02, -1.8806e-02, -1.1949e-01],\n",
       "                        [-1.5424e-01,  2.1139e-02, -1.2501e-01]],\n",
       "              \n",
       "                       [[-2.0506e-01, -3.0328e-01, -7.0644e-03],\n",
       "                        [ 6.5120e-02, -1.5298e-02,  8.4776e-02],\n",
       "                        [ 9.8368e-02,  2.2104e-01,  4.7331e-02]],\n",
       "              \n",
       "                       [[ 1.0543e-02, -3.8799e-02,  1.2879e-01],\n",
       "                        [-1.4161e-03, -1.6089e-01, -1.1688e-01],\n",
       "                        [ 1.8923e-01,  2.9672e-02, -8.9577e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5869e-01,  2.4997e-01,  1.0919e-01],\n",
       "                        [ 8.0202e-02, -7.0330e-02, -1.1587e-01],\n",
       "                        [-1.7754e-01, -9.0353e-02, -1.1497e-02]],\n",
       "              \n",
       "                       [[ 3.2115e-01,  2.9448e-01, -5.0417e-02],\n",
       "                        [ 1.6544e-01,  5.9469e-02,  1.6220e-02],\n",
       "                        [-3.3938e-02, -2.0441e-02,  2.2820e-01]],\n",
       "              \n",
       "                       [[-2.6324e-01, -2.1927e-01,  1.9276e-02],\n",
       "                        [-1.1829e-01, -9.9668e-02, -3.7246e-02],\n",
       "                        [-1.5414e-01, -3.0073e-01, -3.8076e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.8569e-01, -8.8609e-02, -2.7967e-01],\n",
       "                        [-1.7912e-01, -1.2283e-01, -1.4729e-01],\n",
       "                        [-1.1130e-01, -1.5198e-01, -4.9355e-02]],\n",
       "              \n",
       "                       [[-1.5297e-01, -6.4467e-02, -1.4488e-02],\n",
       "                        [ 8.3452e-02,  1.1420e-01,  1.4201e-01],\n",
       "                        [ 6.5947e-02,  7.5174e-02,  1.4104e-02]],\n",
       "              \n",
       "                       [[-3.9835e-01, -4.4832e-01,  4.2174e-02],\n",
       "                        [-4.3757e-02,  3.5249e-03,  1.9157e-01],\n",
       "                        [ 5.1002e-01,  2.7074e-01,  2.1804e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0083e-01, -2.0754e-01, -1.2930e-01],\n",
       "                        [-4.3015e-02,  7.0285e-02,  3.9884e-02],\n",
       "                        [ 4.1164e-03, -1.0237e-02, -2.3977e-01]],\n",
       "              \n",
       "                       [[-2.5900e-01, -4.4998e-01,  1.5604e-01],\n",
       "                        [-1.7697e-01, -4.5872e-01,  2.1617e-01],\n",
       "                        [ 3.7660e-02, -7.4408e-01,  6.8443e-02]],\n",
       "              \n",
       "                       [[-1.1396e-01, -5.3961e-02, -3.6279e-01],\n",
       "                        [ 1.1854e-01, -1.2681e-01, -2.1725e-01],\n",
       "                        [ 2.6696e-01, -3.6346e-01, -9.5176e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.7260e-04, -6.8171e-02,  8.3130e-02],\n",
       "                        [-6.1544e-02, -1.0541e-01,  1.3370e-01],\n",
       "                        [-1.3495e-02, -3.3459e-01, -3.7672e-01]],\n",
       "              \n",
       "                       [[ 4.4782e-02, -4.8111e-02, -3.0118e-01],\n",
       "                        [ 7.5534e-02,  1.4195e-02, -9.2084e-02],\n",
       "                        [ 5.9530e-02,  2.4830e-01, -1.9449e-02]],\n",
       "              \n",
       "                       [[-5.6514e-02, -4.7786e-01, -5.4551e-01],\n",
       "                        [ 6.7129e-02, -1.0447e-01, -3.5393e-01],\n",
       "                        [ 2.0524e-01,  1.4802e-01, -1.2159e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1755e-01,  1.8948e-01, -8.5609e-02],\n",
       "                        [ 1.8041e-03,  9.2940e-02,  4.3612e-03],\n",
       "                        [-2.8400e-02,  8.6866e-02,  5.8296e-02]],\n",
       "              \n",
       "                       [[ 1.5267e-01,  9.4688e-02,  1.0845e-01],\n",
       "                        [ 1.2109e-02,  1.7323e-02,  7.2662e-02],\n",
       "                        [ 1.5045e-01,  6.3335e-02,  1.3530e-01]],\n",
       "              \n",
       "                       [[-1.1404e-02, -6.6846e-05,  3.2670e-02],\n",
       "                        [ 1.3148e-02, -9.1374e-03,  7.4029e-02],\n",
       "                        [ 7.1019e-02, -1.2960e-02,  2.3726e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.7098e-02,  6.7599e-02,  1.4238e-02],\n",
       "                        [ 4.8238e-02,  1.3659e-02, -1.2117e-01],\n",
       "                        [ 1.4043e-02, -4.1660e-02, -1.5624e-01]],\n",
       "              \n",
       "                       [[ 7.8119e-02,  5.5463e-02, -4.3440e-02],\n",
       "                        [ 4.9839e-02,  1.5844e-02,  6.5254e-03],\n",
       "                        [-1.8330e-03,  3.8192e-02, -6.3780e-02]],\n",
       "              \n",
       "                       [[ 1.2015e-03, -5.0034e-02, -4.7408e-03],\n",
       "                        [-9.7093e-02, -1.0198e-01, -1.2352e-01],\n",
       "                        [-4.9896e-02, -4.3457e-02, -1.8967e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.conv2.weight',\n",
       "              tensor([[[[-1.2165e-01, -3.4758e-02, -3.1801e-02],\n",
       "                        [-2.2202e-01, -4.2053e-02, -8.9334e-03],\n",
       "                        [-2.1968e-01,  1.4105e-02, -7.2417e-02]],\n",
       "              \n",
       "                       [[-1.8230e-02,  4.9553e-02,  2.1746e-03],\n",
       "                        [-5.1542e-03,  1.5157e-01, -5.8213e-02],\n",
       "                        [-6.2584e-02,  8.8796e-02, -9.7473e-02]],\n",
       "              \n",
       "                       [[-7.6419e-02,  2.6815e-01, -4.1798e-01],\n",
       "                        [ 1.1087e-01,  1.8604e-01, -4.2441e-01],\n",
       "                        [ 6.6051e-01,  6.7546e-02, -2.2249e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.7164e-01,  6.9644e-02, -1.1054e-01],\n",
       "                        [-1.9934e-01,  1.2364e-01, -1.8217e-01],\n",
       "                        [ 1.9870e-01, -2.1927e-01, -4.7338e-01]],\n",
       "              \n",
       "                       [[ 6.0575e-01,  1.9189e-01, -3.9298e-01],\n",
       "                        [ 3.8937e-01, -5.2282e-01, -3.3441e-01],\n",
       "                        [ 5.0963e-02, -8.0754e-01,  2.1472e-01]],\n",
       "              \n",
       "                       [[-5.4394e-02, -4.4702e-02, -4.1633e-02],\n",
       "                        [-7.9942e-02,  2.0425e-02, -1.1764e-01],\n",
       "                        [-6.7712e-02, -4.8692e-02, -8.1700e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.8303e-02, -1.1456e-01, -6.3068e-02],\n",
       "                        [-3.1676e-02, -7.5469e-02, -8.8714e-02],\n",
       "                        [ 1.6190e-02, -1.3691e-01, -1.2982e-02]],\n",
       "              \n",
       "                       [[ 1.3800e-02,  4.3082e-02,  1.2921e-01],\n",
       "                        [-6.6615e-02,  3.9583e-02,  5.1345e-02],\n",
       "                        [-9.0941e-02, -3.3695e-02, -1.6292e-01]],\n",
       "              \n",
       "                       [[-2.9417e-01, -2.7346e-01, -2.8625e-01],\n",
       "                        [-4.8340e-01, -3.0853e-01, -2.9241e-01],\n",
       "                        [-4.6969e-01, -4.4771e-01, -2.2531e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3768e-01, -1.3367e-01,  6.3965e-02],\n",
       "                        [-1.8034e-01, -1.0056e-01,  4.9152e-02],\n",
       "                        [ 6.9681e-02,  4.4886e-02, -1.5970e-02]],\n",
       "              \n",
       "                       [[ 6.3910e-02,  5.0630e-02, -1.5643e-01],\n",
       "                        [-1.2564e-02,  8.7770e-02, -2.5424e-01],\n",
       "                        [-1.5242e-01,  3.2650e-02, -3.4847e-01]],\n",
       "              \n",
       "                       [[-1.0796e-02, -6.4269e-02, -5.0478e-03],\n",
       "                        [-9.9691e-02, -6.7211e-02, -5.9294e-02],\n",
       "                        [-5.5320e-02, -4.8565e-02, -8.5714e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3092e-01,  9.5969e-02,  1.5641e-01],\n",
       "                        [ 1.9266e-01,  1.9806e-01,  3.0072e-01],\n",
       "                        [ 1.0866e-01,  6.0311e-02,  1.0739e-01]],\n",
       "              \n",
       "                       [[-4.7209e-02, -7.3073e-02, -1.1407e-01],\n",
       "                        [ 3.4073e-02, -6.4070e-02,  7.7815e-02],\n",
       "                        [ 2.4749e-02, -6.8775e-02,  7.9206e-02]],\n",
       "              \n",
       "                       [[-2.8662e-02, -6.8921e-03, -1.5398e-01],\n",
       "                        [ 1.1468e-01,  1.0031e-01, -2.7129e-02],\n",
       "                        [ 1.9977e-01,  1.8576e-01,  5.5038e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.7789e-01, -1.6586e-01, -5.8020e-02],\n",
       "                        [-1.0732e-01, -1.4870e-01, -1.8783e-01],\n",
       "                        [ 1.1411e-01,  1.8217e-03,  6.5047e-03]],\n",
       "              \n",
       "                       [[ 5.4595e-02,  7.4122e-02, -2.3456e-01],\n",
       "                        [-1.3140e-01, -1.0850e-02, -2.9233e-01],\n",
       "                        [-3.5969e-02,  2.3044e-01, -1.8797e-01]],\n",
       "              \n",
       "                       [[ 1.4259e-01,  7.6576e-02,  9.8668e-02],\n",
       "                        [ 2.4371e-01,  1.9889e-01,  1.1936e-01],\n",
       "                        [ 1.4846e-01,  1.9596e-01,  1.3475e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.1735e-02, -1.3602e-03, -6.8345e-03],\n",
       "                        [-3.9126e-02, -2.0053e-02, -6.9146e-02],\n",
       "                        [-4.7897e-02, -3.2232e-02, -3.0127e-02]],\n",
       "              \n",
       "                       [[-1.1223e-01, -2.3186e-03,  1.0385e-01],\n",
       "                        [-1.8395e-02, -9.9355e-03,  2.3772e-02],\n",
       "                        [ 9.9456e-03,  3.8746e-02,  3.2703e-02]],\n",
       "              \n",
       "                       [[ 5.2624e-01,  3.0441e-01, -2.7560e-02],\n",
       "                        [ 3.8298e-01,  3.3152e-01,  3.2366e-01],\n",
       "                        [-1.7045e-01, -1.2247e-01, -6.2685e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.2901e-01,  1.6458e-01, -5.7356e-02],\n",
       "                        [ 1.9583e-01,  1.6779e-01,  2.3444e-02],\n",
       "                        [-1.3751e-01, -1.7650e-01, -3.1298e-01]],\n",
       "              \n",
       "                       [[ 1.4263e-01, -1.8176e-01, -1.3101e-01],\n",
       "                        [-3.3003e-01, -1.7546e-01, -1.4912e-01],\n",
       "                        [-4.1653e-01, -2.7350e-01, -2.3506e-01]],\n",
       "              \n",
       "                       [[-3.4305e-03, -1.1950e-02, -2.6996e-02],\n",
       "                        [-3.5794e-02, -1.4185e-02, -2.9764e-02],\n",
       "                        [ 2.7390e-02, -6.2543e-02, -3.8219e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0635e-02, -2.6808e-03, -9.0777e-02],\n",
       "                        [-3.8485e-02,  3.2833e-02, -1.6659e-02],\n",
       "                        [-1.8095e-02,  8.3388e-03,  1.3049e-02]],\n",
       "              \n",
       "                       [[-4.0688e-02, -2.1189e-01, -1.4189e-01],\n",
       "                        [-4.1159e-02, -1.1777e-01, -3.9503e-02],\n",
       "                        [ 4.0488e-02,  6.5073e-02, -1.2451e-01]],\n",
       "              \n",
       "                       [[-1.9807e-01, -1.4593e-01, -3.1981e-01],\n",
       "                        [-2.6858e-01, -9.8892e-02, -2.4597e-01],\n",
       "                        [-3.9285e-01, -2.7522e-02, -2.4347e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2200e-01, -2.3795e-01, -4.5053e-01],\n",
       "                        [-4.3874e-01, -2.1310e-02, -6.6127e-02],\n",
       "                        [ 1.4589e-01,  1.8029e-01, -2.1881e-01]],\n",
       "              \n",
       "                       [[ 1.2308e-02,  3.8618e-01,  4.7723e-02],\n",
       "                        [ 1.1494e-02,  2.0954e-01,  1.6211e-02],\n",
       "                        [-1.2337e-01, -1.7129e-01, -2.3508e-01]],\n",
       "              \n",
       "                       [[-2.2188e-03, -2.6811e-02, -4.6226e-03],\n",
       "                        [-7.3100e-02, -4.6282e-02, -5.9734e-02],\n",
       "                        [ 1.5354e-02, -7.1094e-02, -4.0344e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9619e-02, -1.3767e-02, -6.4492e-02],\n",
       "                        [ 7.0084e-02,  2.1040e-02, -1.6778e-02],\n",
       "                        [ 2.5448e-02, -2.0526e-02, -1.5553e-02]],\n",
       "              \n",
       "                       [[ 6.7199e-02,  5.4012e-02, -5.1086e-02],\n",
       "                        [-1.6294e-02,  2.6211e-03, -5.9751e-02],\n",
       "                        [ 1.1546e-01,  7.7307e-02, -3.1984e-02]],\n",
       "              \n",
       "                       [[-1.3045e-01,  4.2094e-01,  3.6570e-01],\n",
       "                        [ 5.6246e-02,  7.0460e-01,  5.7300e-01],\n",
       "                        [-8.8699e-02,  4.3950e-01,  6.2013e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.6621e-01, -1.4640e-01,  1.2067e-01],\n",
       "                        [ 3.1655e-02,  3.4726e-01,  4.2844e-01],\n",
       "                        [-4.9609e-02,  3.7723e-01,  2.6148e-01]],\n",
       "              \n",
       "                       [[ 1.0608e-02,  5.0214e-01,  1.0745e-01],\n",
       "                        [-1.9865e-01,  2.3390e-01,  7.7547e-03],\n",
       "                        [-1.2779e-01,  2.3408e-01, -2.2846e-02]],\n",
       "              \n",
       "                       [[ 2.3396e-02, -2.1005e-02, -6.9662e-03],\n",
       "                        [-2.6809e-02, -3.2222e-02, -9.1260e-03],\n",
       "                        [-5.6296e-04, -2.4745e-03, -5.7847e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.weight',\n",
       "              tensor([0.7172, 1.1233, 1.1306, 1.0778, 1.2900, 1.3358, 1.0254, 0.9637, 1.0924,\n",
       "                      1.9560, 1.1531, 1.0244, 0.9168, 0.9906, 1.3675, 1.0856, 1.0364, 1.4014,\n",
       "                      0.6489, 1.1420, 1.0177, 1.0153, 0.4829, 1.3125, 1.0182, 1.2070, 0.8518,\n",
       "                      1.1346, 1.0194, 1.0389, 0.6530, 1.6765, 1.3377, 1.0420, 1.1963, 1.4562,\n",
       "                      1.2257, 0.8529, 1.2123, 1.0886, 1.2572, 0.9541, 1.2606, 1.1860, 0.7690,\n",
       "                      1.0909, 0.8198, 1.6815, 1.5043, 0.9400, 0.9319, 1.2516, 1.2181, 0.7739,\n",
       "                      1.5223, 1.2250, 0.5551, 0.8316, 1.1723, 0.6180, 1.2489, 1.3083, 1.2504,\n",
       "                      1.1648, 0.9319, 0.8519, 1.1785, 1.1199, 1.0065, 1.0437, 0.8517, 0.9715,\n",
       "                      1.1117, 0.8660, 1.2616, 0.6270, 1.4886, 0.8508, 1.6452, 0.9375, 0.9837,\n",
       "                      0.9614, 0.9463, 0.9444, 1.3023, 0.9668, 0.9989, 0.8529, 1.2239, 1.2258,\n",
       "                      0.8677, 1.0991, 1.2224, 1.3239, 1.0160, 0.8423, 0.7899, 1.0761, 0.9532,\n",
       "                      1.1130, 1.0155, 1.4508, 0.9422, 0.4902, 1.3575, 1.2227, 0.6806, 1.0196,\n",
       "                      1.1379, 1.3348, 0.8498, 1.1620, 1.0342, 1.0171, 0.7932, 1.2207, 1.0058,\n",
       "                      1.1235, 0.9424, 0.7260, 1.1394, 1.4980, 0.9080, 1.0551, 0.7560, 1.6658,\n",
       "                      1.0238, 0.7015], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.bias',\n",
       "              tensor([-1.3539, -0.9176, -0.3358, -0.6793, -0.2511, -0.5147,  0.1780,  0.0788,\n",
       "                      -0.9521, -3.2531, -0.3384, -0.2269, -0.1342, -0.4940, -0.5501, -0.7990,\n",
       "                      -0.2480, -0.7214, -1.2223, -0.8328,  0.1423, -0.7698, -0.0695, -0.9567,\n",
       "                      -0.6748, -0.8609, -1.0909, -0.6635, -0.5919, -0.3254, -0.5232, -1.0573,\n",
       "                      -0.5956,  0.2500, -1.2381, -0.9972, -1.1012, -0.7308, -0.9487, -0.4341,\n",
       "                      -0.7429, -0.7259, -0.9874, -0.2327, -1.4147, -0.8253, -0.5465, -2.2435,\n",
       "                      -0.7619, -0.4607, -1.0012, -0.7680,  0.0576, -0.1711, -0.9545, -0.4789,\n",
       "                      -0.2734, -0.1463, -0.9236, -0.4300, -1.3015, -0.8899, -1.5931, -0.5611,\n",
       "                      -0.2354,  0.1681, -0.6901, -0.1235, -0.6812, -0.5706, -0.0539, -0.2259,\n",
       "                      -0.7704, -0.1603, -0.9158, -1.2511, -1.1759, -0.4254, -1.5772,  0.0548,\n",
       "                      -0.3023, -0.2560, -0.9098,  0.1258, -0.8445,  0.2932, -0.5789, -1.4806,\n",
       "                      -0.7398, -0.6939, -0.2297, -0.3205, -1.0558, -0.5916, -0.7359, -0.6250,\n",
       "                       0.0800, -0.9542, -0.1950, -0.3094, -0.5269, -0.8853, -0.4104, -0.0767,\n",
       "                      -0.9139, -0.6508, -0.2267, -0.5620, -0.0352, -0.6384,  0.3548, -0.7505,\n",
       "                      -0.5176, -0.8099, -0.5966, -0.7521, -1.1145, -0.2763, -0.7157, -0.2710,\n",
       "                      -0.5462, -0.9088, -0.2783, -0.7310,  0.0219, -0.8976, -0.0224, -1.1168],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.running_mean',\n",
       "              tensor([-2.3564e+00, -7.8623e-01, -4.6387e+00, -1.5049e+00, -2.2726e+00,\n",
       "                      -2.7921e+00, -7.8990e-01, -2.8141e+00, -5.9426e-01, -2.2119e-01,\n",
       "                      -2.2360e+00, -1.1295e+00, -4.6336e-01, -6.6574e-02, -3.6455e+00,\n",
       "                      -8.3942e-01, -2.1146e+00, -3.3238e+00, -1.4186e-01, -3.0691e+00,\n",
       "                      -2.2668e+00, -1.1178e+00, -8.3395e-01, -2.8017e+00, -1.6393e+00,\n",
       "                      -3.2161e+00,  2.2586e+00, -2.7256e+00, -1.5868e+00, -2.5973e+00,\n",
       "                       5.9631e-01, -2.0146e+00, -3.9246e+00, -4.6789e-01, -1.3337e+00,\n",
       "                      -2.9259e+00, -3.4471e+00,  4.0029e-01, -2.7329e+00, -1.4647e+00,\n",
       "                      -2.7654e+00, -7.8124e-01, -2.8880e+00, -2.2220e+00, -3.1499e+00,\n",
       "                      -2.0553e+00, -1.3198e+00, -1.3732e+00, -1.1723e+00, -3.7504e+00,\n",
       "                      -2.9886e+00, -2.1853e+00, -1.5485e+00, -3.1541e+00, -2.1112e+00,\n",
       "                      -1.7010e+00, -7.4233e-01, -1.2257e+00, -1.9303e+00, -1.8361e+00,\n",
       "                      -8.7065e-01, -1.9204e+00, -7.5239e-01, -1.1576e+00, -1.1160e+00,\n",
       "                      -2.2270e+00, -9.1154e-01, -2.0062e+00, -2.4841e+00, -2.2993e+00,\n",
       "                      -1.4874e+00, -1.1571e+00, -2.4260e+00, -3.6369e-01, -3.3601e+00,\n",
       "                      -1.9821e+00, -7.2913e-01, -1.6621e+00, -1.3400e+00, -1.2716e+00,\n",
       "                      -1.3281e+00, -2.1497e-01, -1.1626e+00, -2.3756e+00, -2.5502e+00,\n",
       "                      -1.1670e+00, -6.4745e-01,  5.7326e-01, -1.6173e+00, -2.3845e+00,\n",
       "                       4.2936e-03, -2.3031e+00, -2.2605e+00, -1.4771e+00, -1.5212e+00,\n",
       "                       6.9390e-01, -9.1834e-01,  2.9509e-01, -2.1181e+00, -1.3780e+00,\n",
       "                      -2.6048e-02, -1.7809e+00, -2.0320e+00,  1.7299e+00, -3.1834e+00,\n",
       "                      -8.1315e-01,  3.8306e-01, -1.1156e+00, -1.8082e+00, -1.4379e+00,\n",
       "                      -2.8346e+00, -1.0881e+00, -1.2295e+00, -1.1997e+00,  1.3506e+00,\n",
       "                      -1.8708e+00, -7.6548e-01, -3.8635e+00, -9.9921e-01, -2.0282e+00,\n",
       "                      -4.2747e+00, -3.8394e+00, -3.5665e+00, -2.8408e+00, -2.4622e-01,\n",
       "                      -1.8582e+00, -2.5839e+00, -1.9727e+00], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.running_var',\n",
       "              tensor([ 1.1628,  2.2944,  8.6532,  2.7921,  6.7483,  3.9477,  6.2737, 11.0114,\n",
       "                       1.1497,  2.9575,  6.1196,  4.8618,  2.6658,  1.2191,  9.8697,  1.8588,\n",
       "                       7.7485,  3.2064,  0.7007,  2.6209,  7.0998,  0.9956,  8.4282,  4.6423,\n",
       "                       1.8855,  3.9211,  2.0303,  6.6025,  3.2229,  4.9314,  4.0883,  8.9942,\n",
       "                       5.5522,  2.3270,  1.9216,  5.1352,  2.6981,  1.1372,  2.9688,  3.6854,\n",
       "                       7.6050,  7.3443,  2.6095,  2.1476,  2.4595,  3.0240,  4.5101,  2.0808,\n",
       "                       4.8284,  6.4665,  2.4399,  2.4437,  3.4446,  6.3414,  8.9221,  3.9288,\n",
       "                       4.5559,  4.1219,  1.5601,  7.2267,  1.0878,  2.0362,  1.5766,  6.8748,\n",
       "                       3.5607,  6.7264,  1.2537, 15.1972,  3.8910,  5.8348,  4.1857,  3.3512,\n",
       "                       2.7344,  3.2213,  4.6379,  1.4182,  1.2774, 10.6226,  1.4496,  3.8304,\n",
       "                       5.4729,  2.5310,  1.2216,  3.1023,  3.2071,  2.9372,  5.2183,  0.7089,\n",
       "                       1.9102,  3.0293,  1.9638,  2.7152,  1.6664,  4.4831,  2.3184,  1.3854,\n",
       "                       5.7960,  0.8607,  3.7067,  3.5862,  3.1024,  1.7274,  6.0427,  8.3279,\n",
       "                       4.1307,  2.4674,  2.2121,  4.5371,  2.9238,  2.9484, 12.1494,  0.9848,\n",
       "                       4.5319,  2.2995,  8.1437,  6.4259,  2.4978,  5.0054,  1.7669,  6.3232,\n",
       "                       9.9577,  8.3383,  5.7918,  5.6132,  5.2834,  7.8332,  4.3388,  1.1185],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.weight',\n",
       "              tensor([1.3141, 0.9743, 0.9400, 0.9704, 1.1382, 1.0515, 0.7056, 0.8917, 1.2728,\n",
       "                      0.8739, 0.8869, 1.0483, 0.6003, 0.7180, 0.9838, 0.9419, 1.2941, 1.2745,\n",
       "                      1.1587, 1.3949, 0.7573, 0.7964, 1.2028, 1.1286, 0.5101, 1.5309, 1.7043,\n",
       "                      1.0253, 1.2643, 1.5136, 0.9687, 1.1254, 0.9008, 1.0613, 1.2545, 1.9371,\n",
       "                      1.0074, 1.1867, 0.6400, 0.8690, 1.2913, 1.1891, 1.5210, 1.2264, 1.1337,\n",
       "                      1.5098, 0.7860, 1.1929, 0.9391, 1.0299, 0.8509, 1.0739, 1.1180, 1.0300,\n",
       "                      1.1998, 0.9821, 0.9817, 1.3478, 0.9603, 0.9633, 0.6857, 0.6026, 0.7475,\n",
       "                      0.7358, 0.7933, 0.9335, 0.9808, 1.0397, 0.8151, 0.7391, 0.6320, 1.2441,\n",
       "                      1.0984, 1.2876, 0.8579, 1.6905, 0.7509, 0.7957, 0.7060, 1.0145, 0.9281,\n",
       "                      0.8951, 1.7811, 1.0739, 1.3654, 1.0729, 0.7540, 0.7065, 1.2138, 1.0745,\n",
       "                      0.9565, 0.9216, 1.0931, 0.6989, 1.1158, 0.9414, 0.7919, 1.2018, 1.0087,\n",
       "                      1.4503, 0.6382, 0.8017, 0.9373, 1.1921, 1.0555, 1.2000, 1.3124, 1.1891,\n",
       "                      0.8393, 1.0704, 0.7054, 1.2592, 0.7358, 0.9641, 1.1372, 0.8094, 1.0117,\n",
       "                      1.2514, 1.1951, 1.0004, 0.8262, 0.7046, 0.8043, 1.1598, 0.6865, 1.4700,\n",
       "                      0.8981, 0.9085], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.bias',\n",
       "              tensor([-1.3503, -0.4413, -0.6789, -0.9455, -1.0849, -0.4448, -0.5752, -0.7186,\n",
       "                      -0.8108, -0.2051, -0.4654, -0.7822, -0.4704, -0.3479, -0.7247, -0.6463,\n",
       "                      -1.1507, -0.8867, -0.7556, -0.8274, -0.4405, -0.4568, -0.9801, -0.6102,\n",
       "                      -1.2241, -1.2244, -1.5618, -0.8782, -0.5003, -0.9520, -0.5820, -1.1252,\n",
       "                      -0.9082, -0.9316, -1.0885, -1.7258, -0.9305, -0.9675, -0.2319, -0.6314,\n",
       "                      -0.8341, -1.1461, -0.9772, -0.9146, -0.7383, -1.1380, -0.6114, -0.9168,\n",
       "                      -1.1098, -0.8108, -0.2102, -0.8518, -0.5361, -0.4911, -0.9719, -0.7816,\n",
       "                      -0.7263, -1.1259, -0.3177, -0.4689, -0.2683, -0.5677, -0.5023, -0.3059,\n",
       "                      -0.5004, -0.7979, -0.7226, -0.8363, -0.3814, -0.5096, -2.4209, -1.0990,\n",
       "                      -0.7452, -1.0950, -0.4069, -1.6483, -0.4548, -0.4833, -0.4344, -0.7627,\n",
       "                      -0.5733, -0.4171, -1.7487, -1.0344, -0.9407, -0.8883, -0.0773, -0.2880,\n",
       "                      -1.0581, -0.7470, -0.6575, -0.5272, -0.7539, -0.3000, -0.6706, -0.6163,\n",
       "                      -0.3594, -0.7435, -2.1373, -1.4771, -0.2047, -0.3021, -0.4441, -0.8505,\n",
       "                      -0.7633, -1.0400, -0.6749, -0.8543, -0.2337, -0.7890, -0.1617, -0.7715,\n",
       "                      -0.4618, -0.8388, -0.8737, -0.8112, -0.6466, -0.8895, -0.7215, -0.9477,\n",
       "                      -0.6900, -0.5412, -0.4516, -1.3314, -0.2638, -1.1401, -0.6788, -0.7952],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.running_mean',\n",
       "              tensor([-6.9297, -4.3337, -5.7589, -0.8863, -2.2412, -1.4413, -3.4932, -6.0370,\n",
       "                      -5.2845, -2.1129, -5.9746, -2.2982, -0.1805, -1.9609, -3.9859, -2.5096,\n",
       "                      -9.8723, -4.8601, -5.3042, -2.1145, -3.4193, -3.2424, -4.6652, -1.9158,\n",
       "                       0.2138, -3.6972, -1.9212, -3.2995, -3.1840, -8.4560, -7.4588, -8.7266,\n",
       "                      -1.2513, -1.9974, -5.5300, -4.2195, -3.7250, -2.1256, -3.6457, -6.0307,\n",
       "                      -2.3493, -1.5394, -5.7551, -4.4863, -5.5497, -4.5754, -3.0556, -5.5282,\n",
       "                       4.0172, -6.1605, -3.4883, -3.7118, -7.3187, -8.2365, -3.5258, -1.8673,\n",
       "                      -0.7454, -1.8293, -3.3306, -6.0135, -0.3439, -1.7986, -4.1060, -8.0788,\n",
       "                      -6.2054, -4.6057, -8.8555, -5.2569, -3.6296, -6.3634, -4.6917, -5.0731,\n",
       "                      -3.5708, -3.3057, -4.4096, -5.6592, -7.4107, -2.9892, -6.6684, -3.7112,\n",
       "                      -0.1329, -7.2910, -5.4560, -7.7363, -6.1466, -4.1547, -5.3513, -9.7286,\n",
       "                      -4.6962, -7.7151, -8.1191, -3.9913, -1.1417, -2.8012, -5.0069, -5.7323,\n",
       "                      -2.7388, -4.5593, -8.8022, -4.6429, -1.6462, -6.3479, -3.9436, -3.4581,\n",
       "                      -3.9018, -2.6764, -4.2597, -3.6427, -5.7447, -4.2069, -2.9528, -6.0274,\n",
       "                      -2.2515, -7.0223, -2.5649, -0.8349, -6.6115, -3.0227, -5.8236, -5.4464,\n",
       "                      -4.9398,  0.5112, -5.7200, -2.4090, -1.9134, -1.6693, -8.4573, -7.5632],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.running_var',\n",
       "              tensor([30.6659, 44.3200, 18.3157, 20.5948, 15.7070, 15.0497,  6.2826, 38.1174,\n",
       "                      17.1388, 41.9682, 27.3024, 12.1402, 22.9494, 13.0412, 24.8706, 15.3759,\n",
       "                      34.4519, 18.4692, 20.1711, 17.2156, 29.4188, 23.2388, 16.7092, 22.9201,\n",
       "                       2.3241, 25.2681, 19.5696, 18.9731, 31.4712, 37.6598, 30.9196, 35.2994,\n",
       "                      12.7409, 12.1795, 10.5677, 24.4400, 32.0738, 23.1013, 22.0267, 24.0519,\n",
       "                      30.1795, 28.6623, 35.2770, 17.5137, 14.4632, 34.9817, 13.1082, 22.4076,\n",
       "                      12.2356, 27.6757, 42.7241, 11.3820, 23.2812, 39.8190, 16.6850, 16.6628,\n",
       "                      11.7425, 13.5440, 14.1517, 16.3527, 17.1861, 17.4135, 15.5357, 22.4912,\n",
       "                      20.4443, 15.9669, 16.4832, 17.2318,  7.1193, 20.2935,  6.8821, 24.5627,\n",
       "                      20.3342, 14.7529, 22.7395, 34.7625, 61.4325, 17.0555, 45.7971, 19.0875,\n",
       "                      13.7665, 27.6330, 16.5559, 25.3476, 20.9822, 23.3057, 16.2179, 45.1180,\n",
       "                      34.5436, 18.5065, 19.3175, 20.1623, 11.7982, 19.0447, 22.6937, 27.3784,\n",
       "                      17.4375, 14.3894, 23.7390, 21.1173, 32.1722, 13.5240, 26.1376, 13.4418,\n",
       "                      26.0792, 11.1197, 22.5386, 34.6845, 43.4385, 20.0209, 30.8511, 14.8955,\n",
       "                      25.5031, 25.1505, 13.1208, 45.8165, 26.7770, 35.5371, 17.3669, 15.0885,\n",
       "                      11.7473, 12.7117, 25.2792, 11.6972, 56.6025, 13.2156, 36.0186, 25.4881],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.conv1.weight',\n",
       "              tensor([[[[ 0.1918,  0.2914,  0.2449],\n",
       "                        [ 0.1409,  0.4522,  0.5067],\n",
       "                        [-0.0884,  0.0737,  0.0301]],\n",
       "              \n",
       "                       [[ 0.1019,  0.0240,  0.1687],\n",
       "                        [ 0.1553,  0.1560,  0.1272],\n",
       "                        [ 0.3152,  0.1944,  0.5959]],\n",
       "              \n",
       "                       [[-0.0959,  0.0195, -0.0181],\n",
       "                        [ 0.1306,  0.3360,  0.2106],\n",
       "                        [ 0.0172,  0.2755,  0.1774]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0589, -0.0836, -0.0707],\n",
       "                        [-0.0466, -0.0364, -0.0165],\n",
       "                        [-0.1360, -0.1182, -0.2067]],\n",
       "              \n",
       "                       [[ 0.1215, -0.0398,  0.0103],\n",
       "                        [ 0.2076,  0.1056,  0.0358],\n",
       "                        [ 0.2488,  0.1140,  0.0059]],\n",
       "              \n",
       "                       [[-0.1999,  0.1547, -0.0563],\n",
       "                        [ 0.0262,  0.1187,  0.0150],\n",
       "                        [-0.0092,  0.0139, -0.0758]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2419,  0.0038,  0.0491],\n",
       "                        [ 0.1142,  0.1323,  0.0855],\n",
       "                        [ 0.0182,  0.1687,  0.1369]],\n",
       "              \n",
       "                       [[ 0.0632, -0.0132, -0.2317],\n",
       "                        [-0.0641,  0.1044, -0.1256],\n",
       "                        [-0.2285, -0.0290, -0.1301]],\n",
       "              \n",
       "                       [[ 0.1610,  0.1163, -0.5981],\n",
       "                        [-0.1550,  0.0303, -0.5493],\n",
       "                        [-0.0474,  0.0092, -0.9042]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0083,  0.0083,  0.0075],\n",
       "                        [ 0.0145,  0.0950,  0.0511],\n",
       "                        [ 0.0830,  0.1164,  0.0494]],\n",
       "              \n",
       "                       [[ 0.2263,  0.1090,  0.0101],\n",
       "                        [ 0.1972,  0.0947,  0.0223],\n",
       "                        [ 0.2290,  0.0657,  0.0559]],\n",
       "              \n",
       "                       [[ 0.0564,  0.0782, -0.1155],\n",
       "                        [-0.0289,  0.0121, -0.1669],\n",
       "                        [-0.1572, -0.0734, -0.2753]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1550,  0.0760, -0.0711],\n",
       "                        [ 0.0081,  0.0031,  0.2342],\n",
       "                        [-0.0559, -0.0469,  0.0951]],\n",
       "              \n",
       "                       [[-0.2200, -0.1018,  0.0902],\n",
       "                        [-0.0272, -0.0195, -0.0870],\n",
       "                        [-0.0746,  0.0177, -0.0156]],\n",
       "              \n",
       "                       [[ 0.1937,  0.1846, -0.1088],\n",
       "                        [-0.0464, -0.0803, -0.1807],\n",
       "                        [-0.2460, -0.4201, -0.2906]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2961,  0.0428,  0.0576],\n",
       "                        [-0.0060, -0.0896, -0.0119],\n",
       "                        [-0.0070, -0.1107, -0.0374]],\n",
       "              \n",
       "                       [[ 0.0958, -0.1339, -0.5265],\n",
       "                        [ 0.2807, -0.0662, -0.3240],\n",
       "                        [ 0.1958, -0.0395,  0.0079]],\n",
       "              \n",
       "                       [[-0.1234, -0.1167,  0.0425],\n",
       "                        [-0.1760, -0.0356,  0.1057],\n",
       "                        [ 0.0918,  0.0630,  0.0935]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1052,  0.0447, -0.0383],\n",
       "                        [ 0.3132, -0.0677,  0.2181],\n",
       "                        [ 0.3347,  0.1222,  0.1651]],\n",
       "              \n",
       "                       [[-0.1390, -0.1263, -0.2003],\n",
       "                        [ 0.0697,  0.2888,  0.1418],\n",
       "                        [-0.1250,  0.1076, -0.2513]],\n",
       "              \n",
       "                       [[ 0.1868,  0.4712, -0.2973],\n",
       "                        [ 0.4597,  0.3130,  0.0224],\n",
       "                        [ 0.6202,  0.3876,  0.2023]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1832, -0.2164, -0.1429],\n",
       "                        [-1.0208, -0.7868, -0.6915],\n",
       "                        [ 0.0429, -0.0640,  0.0734]],\n",
       "              \n",
       "                       [[ 0.3000, -0.1256, -0.1552],\n",
       "                        [ 0.3883,  0.0413, -0.0672],\n",
       "                        [-0.0734, -0.2630, -0.1852]],\n",
       "              \n",
       "                       [[-0.0130, -0.1501, -0.0803],\n",
       "                        [-0.0735, -0.1439, -0.1835],\n",
       "                        [-0.0352, -0.1001, -0.0571]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1292, -0.0475, -0.2751],\n",
       "                        [-0.0806, -0.0832, -0.1058],\n",
       "                        [-0.2897, -0.2348, -0.2851]],\n",
       "              \n",
       "                       [[ 0.3081, -0.0171,  0.0433],\n",
       "                        [ 0.3938, -0.0264,  0.0846],\n",
       "                        [-0.0721, -0.1088,  0.0143]],\n",
       "              \n",
       "                       [[-0.2201, -0.1279,  0.0128],\n",
       "                        [-0.0203, -0.0936,  0.2572],\n",
       "                        [-0.0513,  0.0027,  0.2839]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1582,  0.0710, -0.0582],\n",
       "                        [-0.1213,  0.0654,  0.0037],\n",
       "                        [-0.0399,  0.0586, -0.0409]],\n",
       "              \n",
       "                       [[ 0.1604, -0.0942, -0.0826],\n",
       "                        [ 0.0975,  0.0810,  0.0280],\n",
       "                        [ 0.1393,  0.1117,  0.0537]],\n",
       "              \n",
       "                       [[-0.0604, -0.2456, -0.2025],\n",
       "                        [ 0.0392, -0.1012, -0.0784],\n",
       "                        [-0.0073, -0.2827, -0.0562]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0430,  0.2113,  0.5149],\n",
       "                        [-0.0677,  0.0607,  0.4389],\n",
       "                        [-0.2325, -0.0065,  0.1742]],\n",
       "              \n",
       "                       [[-0.3542, -0.1437,  0.3854],\n",
       "                        [-0.2052, -0.2274,  0.2500],\n",
       "                        [-0.4057, -0.3395, -0.0143]],\n",
       "              \n",
       "                       [[-0.1930, -0.0256, -0.0375],\n",
       "                        [ 0.0103, -0.0207, -0.0794],\n",
       "                        [ 0.3867,  0.2394,  0.1966]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1049,  0.0724, -0.0165],\n",
       "                        [ 0.0512,  0.0242, -0.0029],\n",
       "                        [ 0.0762,  0.0376,  0.0533]],\n",
       "              \n",
       "                       [[-0.0143,  0.0353,  0.0516],\n",
       "                        [-0.0515,  0.0574,  0.0636],\n",
       "                        [ 0.1108,  0.1316,  0.1324]],\n",
       "              \n",
       "                       [[ 0.2118, -0.2252,  0.0978],\n",
       "                        [ 0.4146, -0.1564,  0.0487],\n",
       "                        [ 0.1328, -0.3897, -0.1263]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.conv2.weight',\n",
       "              tensor([[[[ 1.3757e-01,  4.3896e-02,  7.7711e-02],\n",
       "                        [ 3.9155e-02, -1.6810e-02, -5.3194e-03],\n",
       "                        [-7.1487e-02, -8.9337e-02, -9.6639e-02]],\n",
       "              \n",
       "                       [[ 1.0051e-01,  5.4529e-02,  2.5286e-01],\n",
       "                        [ 2.2643e-01,  1.0918e-01,  2.1707e-01],\n",
       "                        [ 2.2286e-01,  1.7694e-01,  1.8261e-01]],\n",
       "              \n",
       "                       [[ 1.0463e-01,  4.7260e-02,  1.4341e-01],\n",
       "                        [ 6.8646e-03,  3.5136e-02, -1.8568e-01],\n",
       "                        [ 1.4691e-02,  2.7523e-02, -8.4363e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.6073e-02, -1.0391e-01, -5.4284e-01],\n",
       "                        [-1.1898e-01, -1.1015e-01, -2.7668e-01],\n",
       "                        [-1.6836e-01, -1.7446e-01, -4.8569e-01]],\n",
       "              \n",
       "                       [[-2.9016e-01, -1.0900e-01, -5.3641e-02],\n",
       "                        [-2.6679e-01, -1.2469e-01, -1.4308e-01],\n",
       "                        [-1.3673e-01, -1.5387e-02,  1.9499e-02]],\n",
       "              \n",
       "                       [[-3.0667e-02, -2.2987e-01, -2.8192e-01],\n",
       "                        [-1.4152e-01, -1.1759e-01, -1.8855e-01],\n",
       "                        [-1.6718e-01, -2.3168e-01, -2.6251e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8786e-01,  1.6873e-01,  1.3946e-01],\n",
       "                        [-1.7823e-01,  5.2950e-02,  1.0508e-01],\n",
       "                        [ 3.9748e-02,  1.1322e-01,  9.1565e-02]],\n",
       "              \n",
       "                       [[ 1.6513e-01,  7.0866e-02,  2.9959e-02],\n",
       "                        [ 1.8623e-01,  8.5402e-02,  1.0393e-01],\n",
       "                        [ 1.6429e-01,  6.0174e-02,  9.9975e-02]],\n",
       "              \n",
       "                       [[-2.9346e-02,  2.7225e-01,  4.5111e-03],\n",
       "                        [-1.6765e-01,  8.2408e-02, -6.9969e-02],\n",
       "                        [-3.3864e-01, -3.1999e-01, -4.8076e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.7067e-02,  3.7755e-02,  1.4875e-01],\n",
       "                        [ 1.3623e-01,  5.7685e-02,  1.2049e-01],\n",
       "                        [-4.3463e-02,  8.5667e-02,  2.6807e-01]],\n",
       "              \n",
       "                       [[ 3.3094e-02, -3.1364e-02, -9.8045e-02],\n",
       "                        [ 5.5394e-02,  1.4516e-01,  4.4614e-02],\n",
       "                        [ 1.2437e-01,  6.7197e-02,  2.6299e-01]],\n",
       "              \n",
       "                       [[ 1.3716e-02,  2.9617e-02, -8.5375e-03],\n",
       "                        [-5.4299e-02, -9.0567e-03, -3.2639e-02],\n",
       "                        [-3.9753e-02, -3.7975e-02,  1.0959e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2729e-02,  1.2983e-02, -1.1082e-03],\n",
       "                        [-1.0104e-02, -2.4775e-03, -1.8996e-03],\n",
       "                        [-6.1798e-02, -5.7441e-02, -7.8250e-02]],\n",
       "              \n",
       "                       [[-1.8100e-02, -8.1336e-02,  8.5607e-03],\n",
       "                        [ 2.4292e-02,  3.0190e-03,  6.1094e-03],\n",
       "                        [ 5.0470e-02, -2.3951e-03,  3.9983e-02]],\n",
       "              \n",
       "                       [[-1.2726e-02, -9.6699e-02, -1.3851e-01],\n",
       "                        [-2.9790e-02, -8.6112e-02, -1.5020e-01],\n",
       "                        [-7.4393e-02, -9.5068e-02, -1.3827e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.0869e-02, -7.1531e-02, -3.1412e-03],\n",
       "                        [-2.2586e-02, -4.4022e-03, -1.1555e-02],\n",
       "                        [-3.3323e-02, -7.2141e-02, -3.3744e-02]],\n",
       "              \n",
       "                       [[ 3.9286e-02,  2.1935e-02, -1.1812e-02],\n",
       "                        [ 8.7210e-02,  4.9117e-02,  3.8273e-02],\n",
       "                        [ 7.9813e-03,  2.1938e-02, -2.2139e-02]],\n",
       "              \n",
       "                       [[-1.0034e-01, -6.9140e-02, -9.8685e-02],\n",
       "                        [ 7.6026e-03,  5.4144e-04, -2.7368e-02],\n",
       "                        [ 2.0734e-02,  2.5915e-02, -4.8275e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.3179e-03, -1.0582e-01, -7.0599e-02],\n",
       "                        [ 3.1258e-02,  2.8049e-02,  2.0656e-03],\n",
       "                        [ 1.3279e-01,  4.2829e-02,  9.6902e-02]],\n",
       "              \n",
       "                       [[-2.8050e-01, -2.3010e-01, -2.8824e-01],\n",
       "                        [-3.2654e-02,  7.5081e-02, -1.0713e-01],\n",
       "                        [ 2.2023e-01,  1.2251e-01, -3.1004e-02]],\n",
       "              \n",
       "                       [[-2.2567e-02, -1.0412e-01, -2.9561e-01],\n",
       "                        [-6.5547e-02, -1.8374e-01, -2.1960e-01],\n",
       "                        [ 4.5878e-02, -5.6491e-02, -1.8567e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2591e-01, -2.1784e-02, -4.0365e-02],\n",
       "                        [-5.7017e-02,  8.3478e-02, -3.8980e-02],\n",
       "                        [ 7.2135e-02,  1.7239e-01,  1.7608e-01]],\n",
       "              \n",
       "                       [[-3.4503e-01, -3.1989e-01, -3.2226e-01],\n",
       "                        [-1.6589e-01, -1.6011e-01, -1.2297e-01],\n",
       "                        [-7.5813e-02, -5.2137e-02, -5.5259e-02]],\n",
       "              \n",
       "                       [[-1.4890e-01,  1.2244e-02,  3.4804e-03],\n",
       "                        [ 9.9097e-02,  1.0039e-01,  1.1039e-01],\n",
       "                        [ 2.7918e-01,  2.4813e-01,  2.0999e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2763e-02,  3.3710e-02,  9.8060e-02],\n",
       "                        [ 4.1523e-02,  1.0447e-01,  1.1888e-01],\n",
       "                        [ 9.0085e-02,  1.0030e-01,  1.2675e-01]],\n",
       "              \n",
       "                       [[-2.0796e-02,  1.4305e-01, -8.5851e-02],\n",
       "                        [ 9.9763e-02,  1.7328e-01,  1.0501e-01],\n",
       "                        [ 9.9091e-02,  1.1628e-01,  5.7350e-02]],\n",
       "              \n",
       "                       [[-1.8043e-01, -6.2085e-02, -4.5798e-02],\n",
       "                        [-8.4020e-02,  1.2727e-01,  9.6284e-02],\n",
       "                        [ 1.7993e-01,  1.3537e-01,  1.8061e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.6259e-02, -5.4515e-02,  1.0738e-01],\n",
       "                        [-1.6335e-01, -1.6188e-01, -4.7400e-02],\n",
       "                        [-4.4075e-01, -2.0570e-01, -2.3790e-01]],\n",
       "              \n",
       "                       [[ 6.3876e-02,  5.0798e-02,  3.0333e-02],\n",
       "                        [ 1.7889e-02,  1.8676e-02,  2.0114e-02],\n",
       "                        [ 3.7309e-03,  6.1642e-02,  1.0740e-01]],\n",
       "              \n",
       "                       [[ 7.5402e-02,  6.8505e-02,  1.2329e-02],\n",
       "                        [ 9.4484e-02,  1.3652e-01,  7.6856e-02],\n",
       "                        [ 2.4983e-01,  2.6860e-01,  1.3195e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5039e-02,  3.9122e-02, -4.0369e-03],\n",
       "                        [-1.2478e-01, -5.6188e-02, -2.4111e-02],\n",
       "                        [-6.4421e-02, -1.1154e-02,  3.1546e-02]],\n",
       "              \n",
       "                       [[ 6.7863e-02, -1.7155e-02,  8.1381e-02],\n",
       "                        [-3.2866e-02, -1.4610e-01, -7.5981e-03],\n",
       "                        [-9.6189e-02, -1.5031e-01, -2.5742e-02]],\n",
       "              \n",
       "                       [[-6.0012e-02,  7.6986e-02,  5.3144e-01],\n",
       "                        [ 1.6253e-01,  2.6311e-02,  2.9028e-01],\n",
       "                        [ 2.8924e-01,  4.3638e-01,  9.5001e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.4443e-02,  8.4047e-02,  9.4683e-02],\n",
       "                        [ 7.5064e-02,  8.1519e-03,  9.3771e-02],\n",
       "                        [ 4.4937e-02,  1.1582e-02,  3.0661e-02]],\n",
       "              \n",
       "                       [[-4.2403e-02,  5.5279e-02,  7.3614e-02],\n",
       "                        [-1.4714e-01, -1.1489e-01, -1.1970e-01],\n",
       "                        [-2.2739e-01, -2.6858e-01, -2.7262e-01]],\n",
       "              \n",
       "                       [[ 5.3812e-02,  1.3348e-01,  9.6792e-02],\n",
       "                        [ 1.7793e-02,  9.1173e-02,  1.9585e-02],\n",
       "                        [ 7.9299e-03,  8.6664e-02,  1.0111e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.weight',\n",
       "              tensor([1.0210, 1.0682, 1.3787, 1.2665, 1.1524, 1.2183, 0.7760, 0.9235, 1.3536,\n",
       "                      1.1974, 1.3259, 1.0340, 0.7915, 1.4988, 1.3355, 1.0443, 1.5879, 1.0444,\n",
       "                      1.4216, 1.0978, 0.9139, 1.1532, 1.1720, 1.4551, 0.9114, 1.1548, 0.2007,\n",
       "                      0.9233, 0.9801, 1.4392, 1.2658, 1.2461, 1.2587, 0.9034, 1.2150, 0.9803,\n",
       "                      0.9793, 1.0596, 1.2942, 1.0567, 0.9321, 1.1342, 1.5601, 1.0315, 1.2391,\n",
       "                      1.0022, 0.9950, 1.2044, 1.0443, 1.0558, 1.0039, 1.3602, 1.1981, 1.2316,\n",
       "                      1.3122, 1.0064, 0.7829, 1.3809, 1.1030, 1.4282, 0.9289, 1.1313, 1.3792,\n",
       "                      0.9184, 1.0905, 1.0623, 1.2476, 1.4465, 1.1163, 1.2293, 1.0798, 1.3139,\n",
       "                      1.7250, 0.8172, 1.5012, 1.3231, 1.0144, 1.1767, 0.8729, 1.1869, 0.9012,\n",
       "                      1.0563, 0.7078, 1.3326, 1.0936, 1.0224, 1.3593, 0.9392, 1.0068, 0.9863,\n",
       "                      1.1849, 0.9958, 1.2248, 0.9927, 0.3141, 1.3952, 1.0526, 0.9720, 1.1495,\n",
       "                      1.1253, 0.9783, 1.0597, 1.0248, 1.4366, 1.3393, 1.2572, 0.9937, 1.1931,\n",
       "                      1.1437, 0.8957, 1.2098, 0.2566, 1.0649, 1.3017, 1.0800, 0.5224, 1.0450,\n",
       "                      1.1513, 1.1263, 0.8780, 1.3537, 1.1516, 1.5164, 1.1235, 0.9574, 0.9924,\n",
       "                      1.1335, 1.0409, 0.9817, 0.9195, 0.9063, 0.7173, 1.1560, 1.2215, 1.1700,\n",
       "                      1.4139, 1.2205, 0.9432, 1.0820, 1.4721, 1.3174, 1.0905, 1.2970, 0.8261,\n",
       "                      0.9812, 1.0475, 1.2826, 1.2452, 0.8185, 1.0462, 1.0750, 1.5156, 1.1132,\n",
       "                      1.3410, 1.1077, 1.1155, 1.2860, 0.9671, 0.5262, 1.1721, 0.9906, 1.1165,\n",
       "                      1.2943, 0.9292, 1.0349, 1.1765, 1.1188, 1.1820, 0.9491, 0.9734, 1.3175,\n",
       "                      1.2034, 1.2084, 0.9865, 1.2615, 0.8739, 0.7807, 1.1073, 0.7385, 0.9734,\n",
       "                      1.4519, 0.9854, 1.0787, 1.0790, 1.0758, 1.1872, 1.0594, 0.9354, 0.5785,\n",
       "                      1.2671, 0.6805, 1.1030, 1.2096, 1.1690, 0.8356, 0.8897, 1.0657, 1.2187,\n",
       "                      0.9070, 0.7119, 0.9653, 0.9849, 1.0520, 0.2849, 0.9442, 1.1167, 1.2524,\n",
       "                      1.0367, 1.4768, 1.2307, 1.2085, 0.8254, 1.2146, 1.1639, 0.2181, 1.2649,\n",
       "                      1.1123, 1.2077, 1.2347, 1.0788, 1.5626, 1.0067, 1.1525, 1.1592, 1.1814,\n",
       "                      1.2216, 1.1346, 0.6273, 1.3089, 1.5136, 1.1486, 0.7495, 1.3114, 0.9355,\n",
       "                      1.1059, 1.4022, 1.3204, 1.5235, 1.3346, 1.1735, 1.1633, 1.0751, 1.3056,\n",
       "                      1.0540, 1.0776, 0.9134, 0.7332, 1.1821, 0.9479, 0.8942, 1.1816, 1.1299,\n",
       "                      0.9147, 1.0555, 0.8702, 1.0005], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.bias',\n",
       "              tensor([-0.8982, -0.5593, -0.8299, -0.8870, -0.6938, -0.3829, -1.0505, -0.7719,\n",
       "                      -0.6779, -0.5489, -0.8549, -0.9675, -0.3858, -1.1915, -0.7939, -0.5287,\n",
       "                      -1.0818, -0.6826, -1.1990, -0.5504, -0.6985, -0.5265, -0.7031, -0.7221,\n",
       "                      -0.6240, -0.7923, -0.7477, -0.6211, -0.4847, -0.9305, -0.8672, -0.9640,\n",
       "                      -0.5970, -0.7963, -1.0095, -0.7041, -0.6201, -0.8272, -0.8642, -0.7149,\n",
       "                      -0.1486, -0.8913, -1.5533, -0.5700, -0.7954, -0.9663, -0.5202, -1.0395,\n",
       "                      -1.0383, -0.8046, -0.7002, -1.1470, -0.5868, -0.7367, -0.7754, -0.4929,\n",
       "                      -0.6644, -0.7077, -0.7026, -0.8174, -0.6611, -0.5234, -0.6234, -0.5961,\n",
       "                      -0.5143, -0.7454, -0.6751, -0.6286, -1.0052, -1.2545, -0.4291, -1.1618,\n",
       "                      -0.8726, -0.8077, -1.0296, -0.9257, -1.2397, -0.9032, -1.1586, -0.6834,\n",
       "                      -0.3203, -0.7832,  0.3590, -0.7680, -0.7617, -0.9250, -0.9485, -0.8702,\n",
       "                      -0.5869, -0.2732, -1.1147, -0.6329, -0.7087, -0.5849, -1.2142, -0.8736,\n",
       "                      -1.2073, -0.4033, -0.6485, -0.9067, -0.1779, -0.7485, -1.5761, -0.8470,\n",
       "                      -0.5936, -1.3240, -0.8528, -0.7504, -0.8944, -0.4018, -0.9139, -0.2481,\n",
       "                      -1.2777, -0.6512, -0.5649,  0.1888, -0.9627, -0.8056, -0.6371, -0.6132,\n",
       "                      -1.0691, -0.5870, -1.7209, -0.3129, -0.5256, -1.5523, -0.5553, -0.8495,\n",
       "                      -0.0422, -0.3014, -0.5068, -0.6025, -0.5146, -1.0281, -0.7575, -1.0009,\n",
       "                      -0.9620, -0.3392, -0.7340, -0.9131, -1.0636, -0.7621, -0.8121, -0.3924,\n",
       "                      -1.2843, -0.4223, -0.8621, -0.7582, -0.4664, -0.6746, -0.9525, -0.7069,\n",
       "                      -0.6494, -1.2329, -0.9510, -0.5987, -0.8122, -0.2585, -2.3511, -0.4336,\n",
       "                      -0.4982, -1.0574, -0.6793, -0.3944, -0.4837, -0.6630, -1.0718, -0.7356,\n",
       "                      -0.3307, -0.7226, -0.8178, -0.3179, -0.6890, -0.4605, -1.2686, -0.4719,\n",
       "                      -0.4427, -0.6833, -0.3259, -0.6951, -1.1053, -0.9664, -0.7898, -0.8774,\n",
       "                      -0.1740, -0.9885, -0.3770, -0.7380, -1.2202, -1.1224, -0.1347, -0.7182,\n",
       "                      -0.7212, -0.3407, -0.2000, -0.8056, -0.8408, -0.6210, -1.0593, -3.0333,\n",
       "                      -0.3586, -1.0164, -0.5091, -0.7474, -0.7502, -0.5594, -0.7063, -0.6198,\n",
       "                      -1.2757, -0.9516, -0.7334, -0.6935, -0.7772, -0.7707, -0.4082, -1.0337,\n",
       "                      -0.6719, -0.8486, -0.8674, -0.7073, -0.8083, -0.7788, -0.8789, -0.3953,\n",
       "                      -1.1115, -0.7206, -0.9332,  0.0890, -0.8098, -0.9703, -1.0459, -0.3908,\n",
       "                      -0.4484, -0.9225, -0.8505, -0.7879, -0.9284, -1.4579, -1.1448, -0.5124,\n",
       "                      -0.8017, -0.4046, -0.8617, -0.6982, -0.5067, -0.4861, -0.2880, -0.7619,\n",
       "                      -0.6610, -0.4801, -0.9662, -0.7079, -0.0607, -0.8820, -0.4338, -0.8083],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.running_mean',\n",
       "              tensor([-3.6716, -4.4998, -3.3928, -4.3136, -4.6425, -6.1826,  2.4349, -2.4528,\n",
       "                      -5.3190, -4.4415, -5.0642, -4.3423, -0.9123, -1.6092, -3.6615, -4.2036,\n",
       "                      -5.0053, -5.8946, -1.9175, -2.6510, -2.0259, -3.2013, -2.9067, -3.4250,\n",
       "                      -3.6012, -2.8132,  0.2122, -1.4167, -2.3176, -4.8757, -1.5723, -3.1555,\n",
       "                      -3.8470, -3.5484, -4.6692, -1.2059, -5.4423, -6.5821, -2.9674, -3.6584,\n",
       "                      -5.3014, -2.0395, -3.5407, -3.4778, -3.0371,  0.2025, -0.0142, -0.6985,\n",
       "                      -3.6262, -5.2778, -1.2839, -0.6250, -3.5389, -1.7519, -7.4743, -1.9592,\n",
       "                      -5.1269, -5.5833, -3.8974, -5.2696, -4.9513, -2.1108, -5.9900, -2.8826,\n",
       "                       0.3543, -2.9952, -4.6341, -2.8891, -3.0032, -5.8718, -3.6505, -2.1396,\n",
       "                      -3.3803,  0.5207, -1.3521, -3.7571, -0.0504, -3.8170,  2.6244, -3.5578,\n",
       "                      -5.7465, -5.9931, -2.0362, -7.6235, -3.8140, -1.5547, -4.4511, -4.1878,\n",
       "                      -3.8005, -3.5834,  1.3269, -3.9786, -1.9909, -3.7507,  0.1906, -6.9346,\n",
       "                       1.3870, -2.8135, -3.8540, -1.1593, -4.5123, -2.3343,  0.0959, -1.7825,\n",
       "                      -3.6221, -1.7327, -0.6540, -6.8581, -0.6884, -6.3777, -2.5159, -0.2136,\n",
       "                      -0.7809, -4.1160, -2.5850, -3.2121, -4.0634, -1.8600, -3.4295,  1.6156,\n",
       "                      -3.2638, -5.7367, -4.3896, -3.4009, -1.5803,  5.5251, -3.7837, -1.5342,\n",
       "                      -1.6288, -2.4254, -4.1731, -1.9629, -4.0375, -4.3813, -1.0746, -1.9116,\n",
       "                      -3.3286, -1.3124, -3.1905, -2.5201, -4.8249, -2.8369, -2.2420, -8.3987,\n",
       "                       5.3649, -3.0550, -4.4956, -3.3828, -1.4829, -3.6053, -4.1002, -4.3864,\n",
       "                      -3.4545, -1.2725, -1.7832, -3.7080, -3.4804, -4.7292,  0.0678, -5.4915,\n",
       "                      -2.0888, -2.6093, -2.9651, -3.9596, -3.0122, -6.6763, -3.8709, -2.6090,\n",
       "                      -0.7712, -2.2966, -2.8729, -2.7528, -2.3835, -3.5038, -8.4375, -5.2468,\n",
       "                      -1.0841, -4.8295, -5.4690, -5.4507, -4.4401,  0.3135, -4.0276, -3.3131,\n",
       "                      -2.2113, -4.1910, -6.2188, -0.8436,  0.2293,  1.4562, -6.2594, -3.6078,\n",
       "                      -1.6662, -3.9950, -2.1669, -4.7181, -0.4500, -3.1043, -0.6794, -1.1833,\n",
       "                      -4.7434,  0.2188, -2.0610,  0.3194, -0.1356, -4.5057, -3.3635, -1.3687,\n",
       "                      -4.0310, -2.8598, -3.1592, -0.2566, -2.2996, -4.2440,  0.4073, -4.5379,\n",
       "                      -4.2696, -3.6634, -3.5430, -2.7403, -3.3694,  1.1686, -2.6047, -2.3251,\n",
       "                      -3.5192, -2.8872, -1.9932, -2.2582, -3.1104, -7.5036, -1.8841, -0.2710,\n",
       "                      -2.5072,  2.6645, -1.1727, -3.0118, -4.0894, -5.0187, -3.1375, -3.0995,\n",
       "                      -4.8769, -0.5808, -2.1449, -0.8675, -2.4263, -5.6197, -5.6222, -1.7829,\n",
       "                      -3.5098, -1.2072, -3.4861, -3.3749, -3.2012, -3.6895, -4.1671, -1.3001],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.running_var',\n",
       "              tensor([5.7976e+00, 1.0303e+01, 1.8532e+01, 8.1071e+00, 1.4653e+01, 3.4577e+01,\n",
       "                      6.6280e+00, 1.8159e+01, 1.8759e+01, 9.0697e+00, 1.4710e+01, 7.8978e+00,\n",
       "                      1.3225e+01, 5.6688e+00, 1.2380e+01, 5.3476e+00, 1.6595e+01, 1.1957e+01,\n",
       "                      4.3686e+00, 5.3855e+00, 7.4871e+00, 1.5339e+01, 1.3848e+01, 1.3873e+01,\n",
       "                      7.8771e+00, 2.1859e+01, 3.1837e-01, 9.6762e+00, 2.1956e+01, 1.9514e+01,\n",
       "                      5.6002e+00, 8.6276e+00, 1.2053e+01, 1.1066e+01, 1.0630e+01, 1.0872e+01,\n",
       "                      1.0524e+01, 1.3720e+01, 1.5714e+01, 1.2064e+01, 1.4017e+01, 1.1442e+01,\n",
       "                      8.7009e+00, 7.3242e+00, 1.1817e+01, 1.1544e+01, 1.1481e+01, 7.0910e+00,\n",
       "                      7.4718e+00, 6.3352e+00, 3.4908e+00, 7.1058e+00, 1.2840e+01, 4.7154e+00,\n",
       "                      1.7992e+01, 4.9718e+00, 1.1630e+01, 1.3115e+01, 1.5667e+01, 1.6031e+01,\n",
       "                      9.7328e+00, 1.1478e+01, 1.5452e+01, 1.1953e+01, 1.5424e+01, 1.4640e+01,\n",
       "                      1.1706e+01, 1.8597e+01, 6.2712e+00, 1.6643e+01, 9.9804e+00, 5.3885e+00,\n",
       "                      2.4392e+01, 3.0136e+00, 9.2681e+00, 1.4552e+01, 3.7358e+00, 1.0519e+01,\n",
       "                      5.7727e+00, 8.1866e+00, 1.3902e+01, 9.1539e+00, 1.3845e+01, 1.7084e+01,\n",
       "                      5.6192e+00, 3.4896e+00, 8.8599e+00, 6.4242e+00, 1.5906e+01, 1.4505e+01,\n",
       "                      4.7681e+00, 5.7155e+00, 1.1734e+01, 6.9707e+00, 5.5136e-01, 1.6104e+01,\n",
       "                      2.5965e+00, 1.0944e+01, 8.1110e+00, 1.0195e+01, 1.6952e+01, 1.3493e+01,\n",
       "                      6.0901e+00, 8.9571e+00, 8.6324e+00, 6.5912e+00, 3.7050e+00, 1.6901e+01,\n",
       "                      4.3927e+00, 1.3979e+01, 1.5108e+01, 2.7228e-01, 5.8820e+00, 7.7603e+00,\n",
       "                      9.9676e+00, 1.1688e+01, 5.9136e+00, 7.2226e+00, 9.1692e+00, 1.8006e+01,\n",
       "                      1.0924e+01, 1.6213e+01, 9.1611e+00, 1.4584e+01, 8.2220e+00, 1.5949e+01,\n",
       "                      8.6650e+00, 5.9576e+00, 1.2013e+01, 6.9288e+00, 1.4488e+01, 7.2608e+00,\n",
       "                      1.0110e+01, 1.5923e+01, 1.0383e+01, 8.5505e+00, 6.5930e+00, 1.4222e+01,\n",
       "                      8.4192e+00, 9.4597e+00, 2.0852e+01, 9.6252e+00, 6.1861e+00, 1.9565e+01,\n",
       "                      6.1862e+00, 1.0905e+01, 2.3752e+01, 1.0633e+01, 8.1979e+00, 1.2115e+01,\n",
       "                      5.8161e+00, 2.5614e+01, 1.5373e+01, 6.8529e+00, 4.8582e+00, 7.2487e+00,\n",
       "                      2.3886e+01, 1.2444e+01, 9.5726e-03, 2.1607e+01, 1.3386e+01, 8.6087e+00,\n",
       "                      1.9674e+01, 1.5994e+01, 1.9218e+01, 1.3990e+01, 5.4658e+00, 1.3306e+01,\n",
       "                      1.0966e+01, 7.3778e+00, 4.8761e+00, 7.2859e+00, 5.9489e+00, 7.2654e+00,\n",
       "                      1.2752e+01, 9.5316e+00, 3.8809e+00, 1.2131e+01, 1.4180e+01, 7.5931e+00,\n",
       "                      1.1456e+01, 5.7739e+00, 1.1338e+01, 1.2067e+01, 1.4043e+01, 7.3046e+00,\n",
       "                      1.2074e+01, 9.8756e+00, 4.7968e-01, 6.9488e+00, 9.4756e+00, 4.8433e+00,\n",
       "                      1.2606e+01, 1.4359e+01, 1.3846e+01, 1.1663e+01, 6.2291e+00, 7.9061e+00,\n",
       "                      2.4580e+00, 2.8053e+00, 8.1402e+00, 3.1479e+00, 6.6411e+00, 3.8595e-01,\n",
       "                      8.5913e+00, 1.4635e+01, 1.4451e+01, 1.1988e+01, 8.3239e+00, 1.5531e+01,\n",
       "                      6.2787e+00, 1.2057e+01, 8.8100e+00, 1.2882e+01, 3.0027e-01, 1.1884e+01,\n",
       "                      7.3730e+00, 1.1336e+01, 9.5796e+00, 6.9708e+00, 2.2095e+01, 5.0976e+00,\n",
       "                      8.6211e+00, 1.3601e+01, 1.0556e+01, 6.3089e+00, 7.0896e+00, 1.6363e+01,\n",
       "                      1.1323e+01, 1.5216e+01, 9.0809e+00, 1.5924e+01, 1.8947e+01, 6.5797e+00,\n",
       "                      1.5773e+01, 1.1652e+01, 1.3167e+01, 1.4312e+01, 8.1882e+00, 7.4336e+00,\n",
       "                      1.5864e+01, 9.0699e+00, 4.2691e+00, 9.8060e+00, 4.7070e+00, 1.8503e+01,\n",
       "                      1.4675e+01, 6.3952e+00, 1.0764e+01, 1.0295e+01, 1.0047e+01, 1.5425e+01,\n",
       "                      1.5972e+01, 1.4392e+01, 1.6011e+01, 8.0134e+00], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.weight',\n",
       "              tensor([0.9051, 0.9394, 0.3467, 1.0366, 1.0479, 1.1572, 1.6049, 1.1137, 0.9935,\n",
       "                      1.1752, 0.8874, 1.0937, 0.6876, 1.1102, 1.4864, 1.3248, 0.9897, 1.4706,\n",
       "                      1.4177, 0.2613, 1.1516, 0.9729, 1.2617, 0.2820, 1.0827, 0.2616, 1.4487,\n",
       "                      1.0664, 1.4253, 1.3209, 1.0332, 1.2626, 0.9325, 1.1220, 0.8981, 1.0424,\n",
       "                      0.9619, 1.2507, 1.3945, 1.1734, 0.9084, 0.8654, 1.2673, 1.0337, 1.0987,\n",
       "                      1.3766, 1.6624, 0.8357, 1.0707, 0.9537, 0.2633, 0.9885, 0.9755, 1.3231,\n",
       "                      1.2518, 1.4758, 1.3703, 1.1539, 1.1889, 1.1905, 1.4671, 1.0795, 0.8962,\n",
       "                      0.8735, 1.1473, 1.0061, 0.9262, 0.9056, 0.9279, 1.1607, 1.1400, 1.3418,\n",
       "                      0.2692, 1.0091, 1.3077, 0.5176, 0.9112, 0.9307, 1.0229, 0.8897, 1.0297,\n",
       "                      0.9391, 1.0971, 0.4626, 0.9116, 1.4098, 1.0808, 1.0182, 1.5772, 1.0186,\n",
       "                      1.0702, 0.9926, 1.3717, 0.9138, 1.1040, 1.0963, 0.8279, 1.0532, 1.3980,\n",
       "                      1.2943, 1.0913, 0.8435, 1.0859, 0.9802, 1.0216, 0.2935, 1.1645, 0.9617,\n",
       "                      1.4009, 1.1233, 0.9578, 0.6571, 1.0725, 0.7002, 1.0372, 1.1292, 1.2509,\n",
       "                      0.9716, 1.5299, 1.2976, 1.0172, 1.2507, 1.0353, 1.0831, 0.9625, 0.9419,\n",
       "                      1.1977, 1.0909, 1.2755, 0.8902, 1.2145, 1.3266, 0.8319, 0.9505, 0.9411,\n",
       "                      1.1432, 0.9254, 1.1651, 1.1642, 0.2505, 1.2972, 1.1613, 0.9954, 1.1288,\n",
       "                      1.1554, 1.1024, 1.4579, 0.8870, 1.1077, 1.3331, 1.1827, 1.0637, 0.9267,\n",
       "                      1.1762, 1.0574, 1.2458, 1.3292, 0.9216, 1.0776, 1.2446, 1.3153, 1.2265,\n",
       "                      1.1726, 1.0782, 0.2623, 0.8875, 0.2963, 1.2376, 1.4084, 1.0460, 1.2456,\n",
       "                      1.2219, 1.0095, 1.0642, 0.9782, 1.2341, 1.0097, 1.0705, 0.8490, 0.9098,\n",
       "                      1.0768, 1.0270, 1.1807, 1.2606, 1.3560, 1.4065, 1.1395, 1.1043, 1.0956,\n",
       "                      0.9400, 0.9232, 0.9482, 1.0033, 0.7078, 1.1307, 1.1774, 0.9191, 1.1546,\n",
       "                      0.9854, 0.8554, 1.0341, 0.8977, 0.8860, 0.9033, 1.0850, 1.0711, 1.1451,\n",
       "                      0.9898, 1.1208, 1.0563, 1.3754, 0.8993, 1.0484, 0.8753, 0.9922, 1.2163,\n",
       "                      1.0892, 1.1947, 0.7565, 0.9142, 1.3299, 0.9942, 1.0805, 1.3669, 0.8534,\n",
       "                      1.3016, 1.4345, 1.2004, 1.1323, 0.7956, 0.9888, 1.0292, 1.1574, 1.1866,\n",
       "                      1.1543, 1.0344, 1.4174, 0.3030, 1.4229, 1.2801, 0.2937, 0.9351, 0.9618,\n",
       "                      1.1582, 1.2652, 0.9315, 1.1234, 1.0876, 1.0357, 1.2522, 0.9250, 1.1716,\n",
       "                      1.2080, 1.2942, 1.3198, 1.2777], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.bias',\n",
       "              tensor([-0.6634, -0.5544, -0.0422, -0.6581, -0.8572, -0.9712, -1.6261, -0.5950,\n",
       "                      -0.7201, -1.2496, -0.5318, -0.7978, -0.1393, -0.6118, -1.3631, -1.3863,\n",
       "                      -0.6188, -1.2326, -1.6330, -0.1872, -0.8443, -0.7549, -1.2820, -0.0505,\n",
       "                      -1.1499, -0.0781, -1.2581, -1.0880, -1.3273, -1.2754, -0.6035, -0.7674,\n",
       "                      -0.4481, -1.0971, -0.9998, -0.6411, -0.5971, -1.3235, -1.3134, -0.8110,\n",
       "                      -0.5895, -0.6744, -0.8855, -1.1614, -1.0477, -1.3588, -1.3315, -0.6502,\n",
       "                      -1.0932, -0.7254, -0.3861, -0.5992, -1.0614, -1.1524, -1.2114, -1.0342,\n",
       "                      -1.3392, -0.7853, -0.7540, -0.9350, -1.7840, -0.9019, -0.7942, -0.5565,\n",
       "                      -1.1643, -0.6610, -0.6357, -0.4942, -0.7252, -1.0780, -0.9504, -1.2680,\n",
       "                      -0.0283, -0.9093, -1.0604,  0.0534, -0.5707, -0.8475, -0.7689, -0.7964,\n",
       "                      -1.0437, -0.7244, -0.6308, -0.0799, -0.6952, -1.1794, -0.9914, -0.9248,\n",
       "                      -1.2379, -0.8964, -1.0408, -0.6191, -1.2270, -0.5548, -0.9034, -1.1669,\n",
       "                      -0.6484, -0.8183, -1.1430, -1.5660, -0.9298, -0.2687, -0.6611, -0.5908,\n",
       "                      -0.7479, -0.0536, -1.2109, -0.8190, -1.3240, -0.9726, -0.5736, -0.2446,\n",
       "                      -0.9323, -0.2670, -0.8135, -0.9782, -1.0693, -0.8946, -1.2197, -1.2017,\n",
       "                      -0.8493, -1.0271, -0.7801, -0.9973, -0.5407, -0.5843, -0.8183, -0.9339,\n",
       "                      -1.1637, -0.6353, -0.8803, -1.1417, -0.6053, -0.5750, -0.9905, -1.1236,\n",
       "                      -0.7335, -0.7768, -1.1079, -0.0484, -1.5820, -1.2682, -0.9510, -0.8856,\n",
       "                      -1.1036, -1.2498, -1.1422, -0.8046, -0.9191, -1.1010, -0.9548, -0.9208,\n",
       "                      -0.7223, -0.7993, -0.9130, -0.6914, -1.4146, -0.8214, -0.7783, -0.7009,\n",
       "                      -1.1782, -0.8517, -0.7981, -1.0004, -0.0658, -0.6777,  0.1841, -0.9849,\n",
       "                      -1.3402, -0.8736, -0.5267, -0.7914, -0.9291, -1.1181, -0.5579, -0.9340,\n",
       "                      -1.1616, -1.0515, -0.6710, -0.8138, -0.8020, -0.6899, -1.1364, -1.0139,\n",
       "                      -0.7805, -1.3099, -0.3936, -0.8767, -0.4665, -0.8453, -0.6968, -0.5989,\n",
       "                      -0.8351, -0.6806, -0.9338, -1.0715, -0.7662, -1.4438, -0.6182, -0.7659,\n",
       "                      -1.0537, -0.5319, -0.5135, -0.9045, -0.5828, -0.8373, -0.9134, -0.7420,\n",
       "                      -1.1932, -0.9939, -0.7015, -0.5463, -1.0515, -0.5218, -0.5948, -0.8505,\n",
       "                      -1.0803, -0.9453, -0.5138, -0.3713, -1.3711, -0.6823, -0.7744, -1.3687,\n",
       "                      -0.5889, -0.9297, -1.4539, -0.9427, -0.8768, -0.5206, -1.0093, -0.6510,\n",
       "                      -0.8140, -1.1389, -1.1334, -0.8144, -1.4738,  0.0231, -1.1460, -1.0632,\n",
       "                      -0.0401, -0.7883, -0.5025, -0.6524, -1.0350, -0.7857, -0.7549, -0.8493,\n",
       "                      -0.7969, -0.8876, -0.9356, -0.6092, -1.0583, -1.3752, -1.4297, -1.2696],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.running_mean',\n",
       "              tensor([-3.7632e+00, -9.0942e+00, -5.2324e+00, -1.6265e+01, -5.5120e+00,\n",
       "                      -8.4833e+00, -9.1915e+00, -6.0935e+00, -8.4992e+00, -8.5229e+00,\n",
       "                      -2.8742e+00, -7.1312e+00, -3.9346e+00, -8.3223e+00, -6.6446e+00,\n",
       "                      -1.4633e+01, -1.2050e+01, -7.4102e+00, -4.1665e+00, -3.8852e+00,\n",
       "                      -1.1782e+01,  2.0337e+00, -8.9674e+00, -3.5421e-02, -5.4318e+00,\n",
       "                      -6.3430e-02, -6.1789e+00, -6.2252e-01, -1.2175e+01, -5.7403e+00,\n",
       "                      -1.2922e+01, -5.8772e+00, -2.4498e+00, -1.0857e+01, -5.8939e+00,\n",
       "                      -9.4072e+00, -1.1868e+01, -3.9199e+00, -5.9831e+00, -2.7893e+00,\n",
       "                       3.7596e+00, -3.8224e+00, -3.7453e+00, -4.5187e+00, -5.4211e+00,\n",
       "                      -1.2399e+01, -4.2647e+00, -4.7974e+00, -8.3507e+00, -6.2286e+00,\n",
       "                      -8.4950e-04, -8.1919e+00, -4.1917e+00, -6.9957e+00, -7.5349e+00,\n",
       "                      -6.9743e+00, -9.6604e+00, -1.1177e+01, -7.9157e+00, -1.6553e+01,\n",
       "                      -9.1609e+00, -3.0231e+00, -2.9965e+00, -5.3564e+00, -9.3424e-01,\n",
       "                      -9.2723e+00, -1.2275e+00, -7.0908e+00, -4.9050e+00, -1.0858e+01,\n",
       "                      -7.0457e+00, -9.2624e+00, -1.0445e-01, -7.1027e+00, -8.7540e+00,\n",
       "                      -1.2387e+00, -9.5546e+00, -1.3784e+01, -9.9896e+00, -3.3787e+00,\n",
       "                      -3.7355e+00, -5.9943e+00, -7.1598e+00, -7.0738e+00, -7.9076e+00,\n",
       "                      -1.8110e+00, -4.4033e+00, -1.7395e+00, -8.2204e+00, -6.1652e+00,\n",
       "                      -4.9114e+00, -5.9712e+00, -7.1176e+00, -8.5425e+00, -1.4877e+01,\n",
       "                      -8.2049e+00,  5.1621e+00, -1.2247e+01, -5.9140e+00, -1.8665e+00,\n",
       "                      -1.9099e+00, -3.5394e+00, -5.9519e+00, -1.1243e+01, -1.0292e+01,\n",
       "                       1.1542e-02, -6.1347e+00, -6.6159e+00, -9.0597e+00, -8.9896e+00,\n",
       "                      -1.0409e+01, -7.9867e+00, -8.1136e+00, -3.0078e+00, -3.3415e+00,\n",
       "                      -5.1625e+00, -1.3732e+01, -1.0659e+01, -5.9755e+00, -1.0130e+01,\n",
       "                      -5.5045e+00, -2.5274e+00, -3.5657e+00, -9.2018e+00, -7.4413e+00,\n",
       "                      -7.7006e+00, -7.7164e+00, -9.6146e+00, -6.2727e+00, -1.0488e+01,\n",
       "                      -8.7456e+00, -2.5740e+00, -8.4706e+00, -4.7237e+00, -1.0442e+01,\n",
       "                      -9.2775e+00, -1.2671e+01, -6.6309e+00, -4.2030e+00, -7.1187e-02,\n",
       "                      -6.0836e+00, -1.0300e+01, -8.1018e+00, -2.2341e+00, -1.0689e+01,\n",
       "                      -3.6317e+00, -6.1755e+00, -1.0596e+01, -7.7081e+00, -8.6579e+00,\n",
       "                      -8.9929e+00, -1.1972e+01, -7.4886e+00, -7.2483e+00, -3.7808e+00,\n",
       "                      -6.2587e+00, -9.2261e+00, -1.3240e+00, -5.2833e+00, -9.6430e-01,\n",
       "                      -4.5933e+00, -1.0360e+01, -9.6514e+00, -5.7713e+00,  2.4909e-03,\n",
       "                      -2.9826e+00, -1.4669e+00, -3.6351e+00, -8.7625e+00, -9.2196e+00,\n",
       "                      -7.2660e+00, -6.4894e+00, -1.0512e+01, -4.7800e+00, -4.0744e+00,\n",
       "                      -6.5161e+00, -6.5730e+00, -6.1712e+00, -5.0224e+00, -4.8053e+00,\n",
       "                      -9.2358e+00, -1.0091e+01, -6.6775e+00, -5.6374e+00, -1.1505e+01,\n",
       "                      -6.4864e+00, -4.7991e+00, -1.3428e+01, -4.4413e+00, -1.2248e+01,\n",
       "                      -6.2546e+00, -6.6766e+00, -8.0788e+00,  3.5028e-01, -1.3248e+01,\n",
       "                      -3.1043e+00, -6.8361e+00,  4.3378e-01, -6.2018e+00, -6.6109e+00,\n",
       "                      -8.8146e+00, -5.1341e+00, -3.5145e+00, -5.8523e+00, -1.0397e+01,\n",
       "                      -6.2023e+00, -1.1400e+01, -3.9769e+00,  3.1227e+00, -6.3729e+00,\n",
       "                      -9.1428e+00, -8.1317e+00, -8.6478e+00, -1.1008e+01, -5.5727e+00,\n",
       "                      -9.6256e+00,  2.6206e+00, -8.8840e+00, -3.4394e+00, -1.0024e+01,\n",
       "                       2.8129e+00, -1.0264e+01, -7.9636e+00, -1.0159e+01, -7.5524e+00,\n",
       "                      -7.6272e+00, -5.8084e+00, -7.2452e+00, -1.0212e+01, -2.0675e+00,\n",
       "                      -6.7425e+00, -4.5466e+00, -1.0737e+01, -6.6364e+00, -3.5613e+00,\n",
       "                      -1.0022e+01, -1.0441e+01,  2.3489e+00, -5.4235e+00, -5.9015e+00,\n",
       "                      -5.0889e-02, -1.1071e+01, -1.1174e+01, -1.0034e+01, -6.0598e+00,\n",
       "                      -7.0747e+00, -2.3704e+00, -1.0295e+01, -1.0242e+00, -4.4956e+00,\n",
       "                      -8.1543e+00, -6.5005e+00, -5.4108e+00, -9.8053e+00, -6.2623e+00,\n",
       "                      -9.3068e+00], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.running_var',\n",
       "              tensor([ 40.5723,  65.7030,  11.8584,  67.4836,  26.6316,  50.4351,  54.1779,\n",
       "                       30.1589,  42.8167,  49.9692,  28.4224,  31.3713,  32.0274,  46.6070,\n",
       "                       48.1286,  58.4122,  31.7544,  44.7766,  27.0445,   4.2099,  77.1243,\n",
       "                       30.4201,  58.8890,   0.4141,  20.1350,   0.2635,  45.1380,  20.2287,\n",
       "                       68.0608,  23.5049,  37.5302,  53.7064,  54.6602,  58.0534,  29.1404,\n",
       "                       47.6535,  51.5917,  63.7634,  55.1338,  25.2223,  41.3617,  52.7705,\n",
       "                       34.5100,  53.7506,  58.5715,  46.6809,  34.5419,  36.1039,  36.5626,\n",
       "                       25.8292,   0.2981,  28.9679,  40.5153,  60.2064,  33.9075,  30.9585,\n",
       "                       36.4447,  51.0632,  52.7367,  81.1930,  42.4597,  43.4219,  22.2235,\n",
       "                       40.2748,  34.3417,  72.5276,  45.0313,  53.1840,  34.8067,  42.1514,\n",
       "                       47.2410,  58.1298,   0.4201,  56.7860,  30.6251,  20.6250,  42.2545,\n",
       "                       76.7949,  25.8407,  49.3553,  76.2543,  51.0976,  22.5277,  15.0258,\n",
       "                       38.6420,  30.9443,  61.9598,  59.8144,  44.0024,  55.4643,  46.6360,\n",
       "                       43.7867,  43.8053,  51.5570,  97.5555,  23.4702,  22.3750,  35.2476,\n",
       "                       50.9145,  19.7545,  36.8942,  21.6182,  36.6579,  56.8219,  43.5087,\n",
       "                        0.3208,  36.8081,  42.6586,  53.6447,  42.7517,  53.7115,  24.3025,\n",
       "                       44.2902,  32.6030,  67.9141,  46.2343,  49.2114,  41.4842,  31.3825,\n",
       "                       52.1681,  76.2221,  33.6903,  59.1630,  35.9490,  39.6129,  37.6400,\n",
       "                       32.5703,  65.5450,  30.8750,  45.4082,  45.8819,  26.3946,  47.4205,\n",
       "                       49.1348,  43.3766,  27.2011,  75.8063,  63.7155,  46.3493,   0.3979,\n",
       "                       26.5054,  45.8701,  69.3298,  56.8755,  59.8682,  42.5232,  41.1253,\n",
       "                       43.6935,  53.3741,  32.5585,  35.8902,  43.9328,  45.5414,  31.5621,\n",
       "                       48.7838,  47.2220,  29.6616,  15.5673,  22.2395,  28.9994,  24.2479,\n",
       "                      102.9704,  39.9512,  32.3244,   0.2558,  24.3601,   5.2302,  29.5106,\n",
       "                       41.3319,  75.3155,  37.3672,  22.4993,  59.5364,  46.9117,  39.3268,\n",
       "                       40.9311,  52.5730,  72.9468,  33.1480,  19.0017,  71.2979,  35.3832,\n",
       "                       37.9487,  45.4771,  41.7069,  36.8463,  41.5128,  85.9343,  30.5077,\n",
       "                       42.6010,  37.2925,  42.0592,  56.6934,  15.7602,  47.6612,  30.0385,\n",
       "                       47.0208,  33.2221,  44.7548,  24.5391,  45.9706,  31.9674,  36.1938,\n",
       "                       60.4913,  29.1829,  31.4370,  53.4403,  28.3113,  34.7869,  70.9355,\n",
       "                       68.1365,  40.4803,  36.3636,  47.1711,  22.1173,  38.4825,  39.3975,\n",
       "                       43.7432,  29.4210,  34.8596,  30.4687,  68.7060,  67.3378,  26.3805,\n",
       "                       41.5847,  35.6842,  35.0291,  37.1290,  36.2059,  46.2787,  39.5105,\n",
       "                       37.2341,  50.8404,  27.8260,  38.5722,  46.0524,  38.2611,  10.2442,\n",
       "                       46.6448,  30.8053,   0.3152,  29.1311,  45.0049,  35.8925,  31.2280,\n",
       "                       37.7955,  27.8912,  45.8276,  33.1744,  29.8663,  32.7236,  57.9544,\n",
       "                       47.7023,  37.2118,  48.3244,  38.3405], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.conv1.weight',\n",
       "              tensor([[[[-2.8117e-01, -1.9448e-01, -3.2072e-01],\n",
       "                        [ 1.6667e-01,  7.5469e-03, -1.2761e-01],\n",
       "                        [ 1.5804e-01,  1.4452e-01,  5.4735e-03]],\n",
       "              \n",
       "                       [[ 5.7425e-03, -1.6190e-02, -4.9775e-01],\n",
       "                        [ 6.9577e-02,  3.7016e-02, -2.2179e-01],\n",
       "                        [-2.1399e-01, -1.8292e-01, -2.7259e-01]],\n",
       "              \n",
       "                       [[-3.2275e-02,  6.3697e-02,  3.6232e-02],\n",
       "                        [-1.0834e-02,  2.3389e-01, -1.6246e-02],\n",
       "                        [ 1.3494e-01,  1.3342e-01, -1.4910e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0493e-01,  6.6150e-03,  9.4810e-02],\n",
       "                        [ 7.5323e-02, -8.4515e-02, -2.6031e-01],\n",
       "                        [-4.4923e-02,  1.3767e-01, -1.3903e-02]],\n",
       "              \n",
       "                       [[ 5.8768e-02,  3.0249e-03,  1.2129e-01],\n",
       "                        [-1.4058e-02, -1.4894e-02,  1.1285e-01],\n",
       "                        [ 7.8302e-02, -5.2702e-03,  1.2461e-01]],\n",
       "              \n",
       "                       [[-2.8437e-02, -1.5080e-01, -1.7280e-02],\n",
       "                        [ 2.3192e-01, -1.1718e-02, -4.4942e-02],\n",
       "                        [ 6.1271e-01,  2.4129e-01,  1.4843e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8397e-01,  1.0231e-01, -3.6553e-04],\n",
       "                        [ 3.4619e-01,  2.6139e-01,  2.4499e-01],\n",
       "                        [ 3.5390e-01,  2.8168e-01,  3.8342e-01]],\n",
       "              \n",
       "                       [[ 8.4976e-02,  2.6384e-01,  9.5468e-02],\n",
       "                        [-2.7714e-02, -2.2332e-02, -4.8102e-02],\n",
       "                        [-1.7257e-01,  6.8492e-02,  1.0205e-01]],\n",
       "              \n",
       "                       [[-2.5342e-02, -1.5528e-02, -6.1688e-02],\n",
       "                        [-2.7608e-02, -2.5081e-02, -6.0266e-02],\n",
       "                        [ 6.7514e-04, -1.2479e-03, -4.8764e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2393e-01, -9.4306e-02, -1.9476e-01],\n",
       "                        [ 5.8398e-03, -7.9925e-02, -4.1517e-01],\n",
       "                        [-5.0327e-02, -1.9655e-01, -1.1735e-01]],\n",
       "              \n",
       "                       [[ 2.7297e-01, -4.6044e-02,  2.8592e-02],\n",
       "                        [ 7.4112e-01, -5.0212e-02, -1.0976e-01],\n",
       "                        [ 6.0514e-01, -6.1636e-02,  1.5829e-01]],\n",
       "              \n",
       "                       [[-8.9858e-02, -1.4299e-01, -8.8171e-02],\n",
       "                        [-2.7729e-02, -5.3546e-02,  1.1596e-03],\n",
       "                        [ 1.9970e-01,  5.9318e-02,  1.9625e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5145e-02, -7.8992e-02, -2.5136e-02],\n",
       "                        [-4.0007e-02, -3.4993e-02, -4.9632e-02],\n",
       "                        [ 2.2835e-02, -8.2773e-02, -1.4480e-01]],\n",
       "              \n",
       "                       [[ 8.8546e-02, -1.3631e-03,  7.4954e-05],\n",
       "                        [ 2.7300e-02, -2.4629e-02, -6.8863e-02],\n",
       "                        [ 9.9173e-02,  2.9239e-02, -1.0297e-02]],\n",
       "              \n",
       "                       [[ 1.6983e-02,  3.6542e-03, -6.4787e-02],\n",
       "                        [ 9.0322e-02,  2.4170e-02, -5.2050e-02],\n",
       "                        [ 6.6579e-02,  4.9823e-02, -2.5309e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.4695e-02,  4.1721e-02, -5.1636e-02],\n",
       "                        [-6.5091e-02, -4.3530e-02, -1.4238e-01],\n",
       "                        [-5.6960e-02, -3.9052e-02, -1.4414e-01]],\n",
       "              \n",
       "                       [[ 1.1531e-02,  5.8840e-02,  4.7447e-02],\n",
       "                        [ 6.2048e-02,  1.1637e-01,  5.8397e-02],\n",
       "                        [ 5.2231e-03, -4.5418e-03, -3.0628e-02]],\n",
       "              \n",
       "                       [[ 5.5873e-03,  3.9302e-02, -1.9303e-02],\n",
       "                        [-8.0556e-02,  4.2154e-03, -8.2461e-02],\n",
       "                        [-1.3790e-01, -1.9746e-02, -1.8784e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.5198e-01, -3.6075e-02, -1.4837e-01],\n",
       "                        [-2.3885e-01, -2.8460e-02, -1.0875e-01],\n",
       "                        [-1.4545e-01, -7.0426e-02, -6.8133e-02]],\n",
       "              \n",
       "                       [[-5.5952e-02, -4.0911e-02, -3.3310e-02],\n",
       "                        [-1.7451e-01, -8.7108e-02,  1.2693e-02],\n",
       "                        [-7.0759e-02, -4.8385e-02, -3.3718e-03]],\n",
       "              \n",
       "                       [[ 2.9875e-02,  6.5026e-03, -1.0522e-01],\n",
       "                        [ 9.7180e-02,  5.2470e-02, -5.8483e-02],\n",
       "                        [ 1.0137e-02,  2.4127e-02, -2.8789e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.7989e-02,  1.1075e-01,  9.5427e-02],\n",
       "                        [ 2.2058e-02,  4.7560e-02,  4.7533e-02],\n",
       "                        [-1.4979e-02, -4.1187e-02, -8.4268e-03]],\n",
       "              \n",
       "                       [[-5.8950e-03, -4.3256e-02, -1.0115e-01],\n",
       "                        [-4.2977e-02,  7.3435e-04, -1.7013e-02],\n",
       "                        [-1.0561e-01, -1.1956e-01, -4.2652e-02]],\n",
       "              \n",
       "                       [[-3.0934e-02, -1.9715e-02, -4.4373e-02],\n",
       "                        [ 1.9279e-01,  1.6256e-01,  1.3915e-01],\n",
       "                        [ 4.7260e-02,  1.3291e-01, -8.4166e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3602e-02,  2.0539e-02,  1.2633e-01],\n",
       "                        [-2.9732e-02,  6.9290e-02,  1.5418e-01],\n",
       "                        [ 7.1638e-02,  9.3394e-02,  1.5287e-01]],\n",
       "              \n",
       "                       [[-1.8831e-02,  1.6386e-02, -3.7939e-02],\n",
       "                        [-5.5418e-02,  3.2672e-03, -3.0469e-02],\n",
       "                        [ 1.9739e-03,  4.9307e-02, -2.8697e-02]],\n",
       "              \n",
       "                       [[ 1.1110e-02, -9.3922e-03, -1.0620e-01],\n",
       "                        [ 5.1250e-02,  4.8479e-02, -1.5916e-01],\n",
       "                        [ 2.6691e-02,  6.9313e-02, -1.7979e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.3847e-02, -1.4713e-02, -1.0052e-01],\n",
       "                        [ 1.9321e-02,  8.7875e-03, -5.4893e-02],\n",
       "                        [ 3.4401e-02,  1.7562e-02,  1.9163e-02]],\n",
       "              \n",
       "                       [[-1.8030e-04,  7.7708e-02,  1.5777e-01],\n",
       "                        [ 1.7430e-02,  5.9972e-02,  1.0575e-01],\n",
       "                        [-6.3385e-03,  6.1964e-02,  2.0596e-01]],\n",
       "              \n",
       "                       [[ 4.0382e-02,  1.6917e-01,  1.4179e-01],\n",
       "                        [ 6.5023e-02,  7.9723e-02,  1.8729e-01],\n",
       "                        [ 4.7586e-02,  1.4556e-01,  8.0061e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9561e-02,  1.6063e-02,  4.5139e-02],\n",
       "                        [-1.0781e-01, -1.5374e-02,  8.8728e-05],\n",
       "                        [-4.4376e-02,  5.6114e-03,  6.6437e-02]],\n",
       "              \n",
       "                       [[-2.1091e-02,  1.9502e-03, -5.8937e-02],\n",
       "                        [-4.3717e-02, -4.9178e-03, -1.5190e-01],\n",
       "                        [ 6.7578e-02,  5.1915e-02,  2.1604e-02]],\n",
       "              \n",
       "                       [[ 2.7038e-03, -4.4696e-02, -8.6027e-02],\n",
       "                        [ 8.1351e-02,  3.4863e-02, -1.7840e-01],\n",
       "                        [ 3.4614e-02,  3.6288e-02, -1.2641e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.3675e-03,  1.8449e-02, -4.5892e-02],\n",
       "                        [ 3.9285e-02,  1.1169e-02, -4.6597e-02],\n",
       "                        [ 1.1016e-02, -1.7599e-02, -4.0958e-02]],\n",
       "              \n",
       "                       [[ 1.7124e-02,  4.0852e-02,  7.1878e-02],\n",
       "                        [ 1.9256e-02,  2.0039e-02,  6.9166e-02],\n",
       "                        [ 8.0109e-02,  1.0178e-01,  1.2642e-01]],\n",
       "              \n",
       "                       [[-1.3671e-02,  2.6154e-02, -1.1227e-03],\n",
       "                        [-5.0951e-02,  1.0144e-02, -8.1067e-02],\n",
       "                        [-4.0022e-02, -1.2864e-02, -1.0272e-01]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.conv2.weight',\n",
       "              tensor([[[[-1.3141e-01, -1.7014e-01, -3.1536e-01],\n",
       "                        [ 1.4788e-04, -1.2086e-01, -3.0856e-01],\n",
       "                        [-5.1835e-02, -1.7605e-01, -3.0941e-01]],\n",
       "              \n",
       "                       [[-1.5246e-01, -1.2831e-01, -4.4812e-02],\n",
       "                        [-1.6314e-01, -1.2917e-01, -7.5320e-02],\n",
       "                        [-1.5122e-01, -1.1717e-01, -1.5710e-01]],\n",
       "              \n",
       "                       [[-5.3818e-02, -5.1342e-02, -1.5757e-01],\n",
       "                        [-7.5635e-02, -9.9171e-02, -2.1828e-01],\n",
       "                        [-1.0729e-03, -1.0431e-01, -2.2602e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4321e-02, -2.2552e-02, -8.8848e-02],\n",
       "                        [-2.5956e-02, -3.5327e-02, -1.3773e-01],\n",
       "                        [ 8.9133e-03,  3.0740e-03, -1.0050e-01]],\n",
       "              \n",
       "                       [[ 6.3828e-02,  1.4987e-05, -3.2330e-02],\n",
       "                        [ 1.6951e-03, -2.7668e-02, -1.7322e-01],\n",
       "                        [-6.9142e-03, -5.0586e-02, -1.9127e-01]],\n",
       "              \n",
       "                       [[-3.0931e-02, -6.4165e-02, -1.4262e-01],\n",
       "                        [-5.3583e-02, -1.3207e-01, -2.6642e-01],\n",
       "                        [-4.2838e-02, -6.4026e-02, -2.8391e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.9623e-02, -6.3867e-02,  2.5452e-02],\n",
       "                        [ 1.1098e-01, -3.8810e-02,  1.3309e-01],\n",
       "                        [ 1.2145e-01, -2.1395e-02,  1.1927e-01]],\n",
       "              \n",
       "                       [[ 2.8668e-01,  1.7305e-02,  8.8408e-02],\n",
       "                        [ 2.5384e-01, -1.9117e-01, -2.0238e-01],\n",
       "                        [ 2.4004e-01, -2.0833e-01, -1.6091e-01]],\n",
       "              \n",
       "                       [[-2.6671e-02, -1.1001e-01,  3.0393e-02],\n",
       "                        [ 4.0007e-04, -1.1037e-01,  4.0861e-03],\n",
       "                        [-1.8974e-02, -1.4899e-01,  2.3437e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.5335e-02, -6.9298e-02, -4.2384e-03],\n",
       "                        [-3.2748e-02, -7.9837e-02, -3.2012e-02],\n",
       "                        [-9.6534e-02, -1.6497e-01, -8.8456e-02]],\n",
       "              \n",
       "                       [[-1.4191e-02, -5.7730e-02,  7.7663e-02],\n",
       "                        [-1.6944e-02, -1.2329e-01,  6.6457e-02],\n",
       "                        [-3.9793e-02, -5.5077e-02,  1.8633e-02]],\n",
       "              \n",
       "                       [[-4.3596e-02, -1.3971e-01,  1.0534e-02],\n",
       "                        [-4.4777e-02, -1.0370e-01,  2.5256e-02],\n",
       "                        [-2.9126e-02, -1.2420e-01,  1.6884e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2084e-01, -6.4760e-02,  1.3030e-01],\n",
       "                        [-1.3044e-01, -2.5075e-02,  1.6151e-02],\n",
       "                        [-8.7644e-02,  1.5531e-03,  1.7084e-02]],\n",
       "              \n",
       "                       [[ 1.0630e-01,  6.8825e-02,  1.0841e-01],\n",
       "                        [ 6.3294e-02,  5.6313e-02,  9.1738e-02],\n",
       "                        [-8.5978e-02,  4.0142e-03,  4.2442e-02]],\n",
       "              \n",
       "                       [[-7.9506e-02, -5.3952e-01, -4.3850e-02],\n",
       "                        [-1.0070e-01, -6.0278e-01, -6.0825e-02],\n",
       "                        [-4.1294e-02, -4.5038e-01, -5.5793e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.0779e-02, -9.0226e-03,  3.3375e-03],\n",
       "                        [ 8.1960e-04, -7.6463e-02, -3.6247e-02],\n",
       "                        [ 1.9942e-02, -4.3963e-02, -3.7640e-02]],\n",
       "              \n",
       "                       [[-4.5117e-02, -9.3657e-02, -1.9836e-03],\n",
       "                        [-5.8529e-02, -8.0018e-02, -3.1515e-02],\n",
       "                        [-1.2475e-02, -7.1371e-02, -4.3010e-03]],\n",
       "              \n",
       "                       [[-5.3049e-02, -1.5731e-01, -2.5275e-02],\n",
       "                        [-5.1301e-02, -2.0356e-01, -2.3456e-02],\n",
       "                        [-2.6011e-02, -1.6314e-01, -5.0286e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3632e-03, -1.2925e-02,  6.8488e-04],\n",
       "                        [-9.8775e-02, -8.1714e-02, -3.4547e-02],\n",
       "                        [-1.1710e-02, -7.6958e-02, -6.0914e-02]],\n",
       "              \n",
       "                       [[-1.0509e-01, -1.0036e-01, -3.5899e-02],\n",
       "                        [-1.3978e-01, -1.4804e-01, -3.0534e-02],\n",
       "                        [-1.9116e-01, -1.2482e-01, -7.7175e-02]],\n",
       "              \n",
       "                       [[ 1.0296e-02, -6.9565e-02,  7.9738e-02],\n",
       "                        [ 2.8699e-02, -1.6072e-01,  6.3567e-02],\n",
       "                        [ 1.6107e-02, -1.5727e-01,  4.8203e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.1035e-02, -1.2945e-01,  1.2868e-02],\n",
       "                        [-1.6226e-01, -2.2084e-01, -4.9709e-03],\n",
       "                        [-2.6686e-02, -8.8472e-02,  4.4570e-02]],\n",
       "              \n",
       "                       [[-5.2616e-03, -5.7111e-02,  5.4005e-02],\n",
       "                        [-2.7419e-02, -9.5018e-02,  4.9039e-02],\n",
       "                        [-2.7858e-04, -2.4506e-02,  3.1993e-02]],\n",
       "              \n",
       "                       [[-3.8276e-02, -7.3607e-02, -9.0714e-03],\n",
       "                        [-5.5761e-02, -1.2196e-01,  4.7025e-03],\n",
       "                        [-1.7847e-02, -1.2619e-01,  4.5440e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.4819e-02, -1.4828e-01, -1.0668e-01],\n",
       "                        [ 4.5886e-02,  2.8900e-02,  4.0922e-02],\n",
       "                        [ 1.8913e-03,  2.3505e-02,  1.6824e-01]],\n",
       "              \n",
       "                       [[ 1.5831e-01,  1.1025e-01,  3.2725e-01],\n",
       "                        [ 3.3227e-01,  2.0414e-01,  3.9934e-01],\n",
       "                        [ 3.2118e-01,  2.7469e-01,  3.1816e-01]],\n",
       "              \n",
       "                       [[ 4.3839e-03, -1.8127e-01,  3.0586e-02],\n",
       "                        [-5.1334e-02, -2.2614e-01,  6.0986e-02],\n",
       "                        [-9.7718e-03, -2.2800e-01,  7.6102e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.9273e-02, -9.4798e-02, -1.8765e-02],\n",
       "                        [ 2.7452e-02, -1.2884e-01, -6.5547e-03],\n",
       "                        [-1.1060e-01, -2.2181e-01, -8.4998e-02]],\n",
       "              \n",
       "                       [[-1.2539e-02, -9.0758e-02,  3.2262e-02],\n",
       "                        [-2.7983e-02, -1.2655e-01,  1.7510e-03],\n",
       "                        [-7.8804e-03, -1.0630e-01,  3.6500e-02]],\n",
       "              \n",
       "                       [[-4.5780e-02, -1.7082e-01,  3.4723e-02],\n",
       "                        [-4.5897e-02, -2.2459e-01, -1.2138e-02],\n",
       "                        [-5.9276e-02, -1.9904e-01, -7.6359e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.4527e-02,  2.3626e-03,  3.5323e-02],\n",
       "                        [ 5.2964e-02,  8.6002e-03,  9.5076e-02],\n",
       "                        [ 2.5534e-01,  2.2776e-01,  6.3691e-01]],\n",
       "              \n",
       "                       [[-3.1473e-01, -1.5584e-01, -2.4066e-01],\n",
       "                        [-5.6614e-01, -2.5919e-01, -4.8721e-01],\n",
       "                        [-4.7625e-01, -4.3592e-01, -5.6699e-01]],\n",
       "              \n",
       "                       [[-8.0138e-02, -2.7227e-01, -3.8287e-03],\n",
       "                        [-8.9857e-02, -3.3922e-01, -7.3446e-03],\n",
       "                        [-8.2277e-02, -2.2914e-01, -2.5482e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.4436e-02, -1.6535e-01, -6.6169e-02],\n",
       "                        [-1.0076e-01, -1.9541e-01, -2.1543e-02],\n",
       "                        [-4.8573e-02, -2.3831e-01, -7.6474e-02]],\n",
       "              \n",
       "                       [[-6.5030e-02, -1.0340e-01, -1.7654e-02],\n",
       "                        [-4.2388e-02, -9.1843e-02, -4.4946e-02],\n",
       "                        [-5.0771e-02, -9.4325e-02, -3.5689e-02]],\n",
       "              \n",
       "                       [[-1.0607e-01, -1.3761e-01, -1.6891e-01],\n",
       "                        [-7.1688e-02, -1.0667e-01, -9.9844e-02],\n",
       "                        [-6.6565e-02, -1.0376e-01, -2.3241e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.weight',\n",
       "              tensor([1.0171, 0.5798, 0.5005, 0.9467, 0.4131, 0.9769, 0.4462, 1.0130, 0.9361,\n",
       "                      1.1435, 1.0755, 0.8172, 1.2160, 1.1708, 0.8326, 1.0605, 1.3565, 1.1408,\n",
       "                      0.9933, 1.1301, 1.0148, 1.1272, 0.9770, 0.5058, 0.8135, 0.6770, 1.1596,\n",
       "                      1.0459, 1.0975, 1.0943, 1.0097, 0.8133, 1.1153, 0.8899, 1.0428, 1.2536,\n",
       "                      0.9832, 0.6203, 0.9139, 0.8731, 0.6918, 1.1260, 0.2733, 1.0130, 1.0926,\n",
       "                      1.0720, 1.1631, 1.1839, 0.5973, 1.1405, 1.1763, 0.9800, 1.0225, 1.0436,\n",
       "                      0.8502, 1.1530, 0.9835, 1.3239, 0.6362, 0.9547, 0.8648, 0.7036, 0.9891,\n",
       "                      0.8956, 0.6684, 1.0972, 0.9076, 0.6384, 0.8603, 1.0418, 0.8226, 0.9889,\n",
       "                      0.4692, 0.4991, 0.8975, 0.8536, 1.2099, 0.9635, 1.1211, 1.0741, 1.1748,\n",
       "                      1.0328, 0.9639, 0.8464, 0.9222, 0.8646, 0.9812, 1.0259, 0.9026, 1.0985,\n",
       "                      1.3200, 1.3520, 0.8091, 0.8493, 1.0194, 0.5287, 0.9658, 0.9977, 0.9788,\n",
       "                      1.3655, 0.4898, 0.7785, 0.9938, 0.4714, 0.3356, 0.9735, 0.8762, 0.8690,\n",
       "                      1.3053, 0.7439, 0.7643, 0.6878, 1.0019, 1.0641, 1.0696, 1.1539, 1.1049,\n",
       "                      0.8718, 1.3012, 0.9538, 0.9531, 0.5643, 1.0746, 0.9723, 0.8656, 1.3475,\n",
       "                      0.9380, 0.8953, 1.3727, 0.4535, 1.1457, 0.6542, 1.0409, 1.0981, 0.9023,\n",
       "                      1.1144, 1.0815, 1.2134, 0.8978, 0.9925, 0.8624, 1.0421, 1.3380, 1.1504,\n",
       "                      0.9870, 0.4670, 1.0330, 1.1302, 1.1419, 1.2744, 1.2785, 1.2513, 1.0941,\n",
       "                      1.1802, 1.2290, 1.3752, 0.9396, 0.9662, 0.9707, 1.0778, 0.3860, 0.9183,\n",
       "                      1.1586, 0.8619, 0.6188, 1.1147, 1.3675, 1.0019, 1.1476, 1.0775, 1.0792,\n",
       "                      1.1930, 0.9706, 0.9071, 0.9174, 0.9868, 0.7037, 0.7321, 0.8768, 1.0496,\n",
       "                      0.9915, 1.0660, 0.8966, 0.9964, 0.8852, 1.2159, 1.1580, 0.7111, 0.4730,\n",
       "                      1.0353, 1.0192, 0.8928, 1.2706, 1.4263, 0.9980, 0.3532, 0.4918, 0.9829,\n",
       "                      0.7474, 1.0839, 0.5446, 1.0956, 1.0380, 1.0943, 1.0517, 0.7094, 1.0557,\n",
       "                      0.6625, 1.1248, 1.0023, 1.5281, 1.3572, 1.0759, 0.7746, 1.2011, 1.1546,\n",
       "                      0.5964, 0.9852, 0.8495, 0.9046, 0.9232, 1.2807, 0.5028, 0.9053, 1.1093,\n",
       "                      1.2315, 1.0267, 1.0194, 1.2623, 0.9689, 1.0482, 1.0786, 0.8586, 0.4864,\n",
       "                      1.2161, 1.0685, 1.0953, 0.9853, 0.8778, 1.0397, 1.2730, 0.9377, 1.2230,\n",
       "                      0.9753, 1.0981, 0.5209, 0.9376, 0.6086, 0.4151, 0.7702, 0.9797, 1.2388,\n",
       "                      1.0349, 0.9509, 0.8632, 1.2876, 1.6126, 1.1258, 0.4149, 1.0089, 1.0519,\n",
       "                      0.8221, 1.2245, 1.0256, 1.0461, 0.9651, 0.8645, 1.0192, 1.0774, 1.0158,\n",
       "                      1.1035, 0.9729, 1.2657, 1.1162, 1.0492, 0.8497, 1.1300, 1.0705, 0.9149,\n",
       "                      0.5904, 0.9442, 1.1462, 0.9009, 1.3760, 0.4095, 1.0837, 1.2117, 0.5813,\n",
       "                      1.1220, 1.3137, 0.5588, 1.1104, 0.7647, 0.8270, 1.7138, 1.0442, 0.9528,\n",
       "                      1.1511, 0.8160, 1.0942, 1.2062, 1.0723, 0.9839, 1.4398, 1.0917, 1.1048,\n",
       "                      1.0294, 1.0739, 1.1939, 1.0529, 1.0129, 1.0052, 1.4338, 1.0208, 0.9004,\n",
       "                      1.1145, 0.8237, 1.2433, 0.9026, 1.0068, 1.1364, 0.9539, 0.7693, 1.0401,\n",
       "                      1.3652, 0.4287, 1.0163, 0.9942, 1.1042, 0.4577, 0.9942, 0.9551, 0.9146,\n",
       "                      1.0011, 1.1516, 0.9862, 0.7260, 1.1630, 1.0532, 0.9281, 0.9433, 0.6011,\n",
       "                      0.6257, 1.1354, 0.9504, 0.9805, 0.9760, 0.9792, 0.4477, 0.7953, 0.9629,\n",
       "                      0.8023, 1.1022, 1.1797, 0.8836, 1.0323, 0.5699, 1.0605, 1.1273, 1.0621,\n",
       "                      0.7290, 0.9571, 0.8671, 0.6478, 0.3853, 0.9439, 0.8821, 0.8617, 0.4659,\n",
       "                      1.0389, 0.3590, 1.1582, 0.9726, 1.0988, 1.0964, 0.8692, 1.2900, 0.8554,\n",
       "                      1.1174, 0.9015, 0.9937, 1.2691, 0.9923, 0.9630, 1.0504, 0.7922, 0.5388,\n",
       "                      1.0412, 1.0914, 0.9493, 1.1033, 0.9571, 0.9168, 0.9361, 1.1429, 0.4560,\n",
       "                      1.0962, 1.0570, 0.6944, 1.0913, 1.0084, 0.9310, 0.8042, 0.9676, 1.1645,\n",
       "                      1.0108, 0.9704, 0.8509, 0.8505, 0.9832, 0.9930, 1.0751, 0.9806, 1.0307,\n",
       "                      1.1843, 1.0450, 0.8979, 0.8262, 0.7724, 0.8858, 0.9827, 1.0757, 1.1863,\n",
       "                      0.9124, 0.8604, 1.0140, 1.1726, 0.8133, 0.9450, 0.7757, 0.9359, 0.8902,\n",
       "                      0.4347, 0.8054, 0.9967, 0.8918, 1.1201, 0.8330, 1.3714, 0.6347, 0.6996,\n",
       "                      0.9285, 0.9511, 1.2236, 1.0164, 0.8717, 1.0107, 1.2076, 0.9399, 1.1091,\n",
       "                      0.9706, 1.1365, 1.0346, 1.1798, 1.2603, 1.0090, 0.9313, 0.8644, 1.0968,\n",
       "                      0.7437, 1.1048, 1.1171, 0.9892, 0.9939, 1.4142, 1.0721, 1.1209, 1.0621,\n",
       "                      1.1425, 0.8798, 1.1274, 0.9831, 1.0430, 0.9428, 0.3956, 0.9816, 1.0278,\n",
       "                      0.9393, 0.9891, 1.3775, 1.0050, 0.8539, 0.9556, 1.1961, 1.1283, 1.0901,\n",
       "                      0.9547, 1.0527, 1.6421, 1.0322, 1.0283, 0.7542, 0.9550, 1.1278, 0.9013,\n",
       "                      1.0847, 1.1320, 0.8843, 1.1033, 1.0025, 1.0018, 1.0766, 0.2731, 1.0976,\n",
       "                      1.3175, 1.2517, 1.0063, 1.2144, 1.1150, 0.8921, 0.4834, 0.4870],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.bias',\n",
       "              tensor([-0.9268, -0.6266, -0.5309, -0.6357, -0.5046, -1.1536, -0.5173, -1.4939,\n",
       "                      -0.7832, -1.5075, -0.6342, -0.5730, -1.1893, -1.1652, -0.7942, -1.0887,\n",
       "                      -1.3104, -1.3070, -0.8438, -1.5253, -0.9678, -1.0071, -0.9260, -0.5962,\n",
       "                      -1.2304, -0.2258, -0.6201, -0.8741, -0.9973, -0.2882, -1.0181, -0.0473,\n",
       "                      -1.2342, -0.8188, -0.9273, -1.0032, -1.1131, -0.5810, -0.9244, -0.8191,\n",
       "                      -0.4738, -0.7664, -0.1053, -1.1785, -1.2238, -1.2519, -1.0774, -1.7462,\n",
       "                      -1.2521, -1.0098, -1.3732, -1.0013, -0.9384, -0.9089, -0.7262, -1.2270,\n",
       "                      -1.0483, -1.5191, -0.4390, -1.0361, -0.8670, -0.8597, -1.4813, -0.6777,\n",
       "                      -0.4823, -1.1131, -0.8683, -0.1681, -0.6160, -1.1000, -0.6691, -0.6610,\n",
       "                       0.1074, -0.4299, -0.8592, -0.8151, -1.7040, -1.0895, -0.9872, -1.5288,\n",
       "                      -1.1496, -0.6807, -0.8016, -0.7891, -0.9479, -0.6210, -1.0759, -1.1950,\n",
       "                      -0.9956, -1.2665, -1.5158, -1.7583, -0.7382, -0.5999, -0.9451, -0.5500,\n",
       "                      -1.0278, -0.6882, -1.0760, -1.4877, -0.7106, -0.9699, -1.1468, -0.5725,\n",
       "                      -0.2269, -1.4250, -0.7481, -0.9016, -1.3545, -0.4090, -0.5920, -0.7844,\n",
       "                      -1.2422, -1.0947, -1.3283, -1.2184, -1.1426, -0.8193, -1.3204, -0.8605,\n",
       "                      -0.7378, -0.5170, -1.3469, -1.0916, -0.9371, -1.4747, -1.0785, -1.3800,\n",
       "                      -1.3396, -0.4237, -1.3274, -0.8327, -0.8605, -1.2755, -0.9883, -1.0643,\n",
       "                      -1.1332, -1.2407, -1.0683, -0.9353, -0.8443, -1.0549, -1.1899, -1.0002,\n",
       "                      -1.4368, -0.4605, -0.8931, -1.3795, -1.1537, -1.2295, -1.5573, -1.3294,\n",
       "                      -1.2111, -1.4382, -1.0037, -1.4445, -0.7545, -1.1937, -1.0555, -0.8604,\n",
       "                      -0.3483, -0.8547, -1.4832, -0.9992, -0.6245, -1.1271, -1.8393, -0.8570,\n",
       "                      -1.1873, -0.9002, -1.1650, -1.4616, -1.0966, -1.0338, -0.8798, -1.0539,\n",
       "                      -0.5295, -0.5991, -0.5281, -1.1401, -1.3800, -1.1607, -1.0025, -0.7102,\n",
       "                      -0.9779, -1.1512, -1.1975, -0.7246, -0.4748, -0.9941, -0.7571, -0.8653,\n",
       "                      -1.4647, -1.8294, -0.6385, -0.2421, -0.4240, -0.7561, -0.7323, -1.0429,\n",
       "                      -0.5567, -0.7589, -0.8982, -1.1422, -1.3670, -0.8966, -0.7570, -0.8501,\n",
       "                      -1.4752, -1.3566, -1.5417, -1.3120, -1.4789, -0.8098, -1.1903, -1.1919,\n",
       "                      -0.5641, -1.0068, -0.6368, -1.1082, -0.6602, -1.2209, -0.5706, -0.8450,\n",
       "                      -1.4457, -1.1181, -0.5517, -1.0157, -1.0188, -1.3320, -1.1227, -0.8480,\n",
       "                      -0.9637, -0.3996, -1.1952, -1.4615, -1.0471, -0.8518, -1.3566, -1.1436,\n",
       "                      -1.2017, -0.7486, -1.5245, -0.9609, -1.2642, -0.4812, -1.1266, -0.8732,\n",
       "                      -0.4258, -0.7096, -0.8881, -1.1568, -1.1495, -1.0584, -0.5065, -2.0450,\n",
       "                      -1.8439, -1.0001, -0.4478, -1.3064, -1.2587, -0.7340, -0.7342, -0.9460,\n",
       "                      -1.0269, -0.9412, -0.7271, -0.9116, -0.7955, -1.3599, -1.3335, -1.3596,\n",
       "                      -2.0832, -1.4160, -0.9864, -0.7417, -0.7941, -1.4409, -0.8184, -0.5528,\n",
       "                      -0.7167, -1.1789, -0.8158, -1.4325, -0.2628, -1.1581, -1.9050, -0.4080,\n",
       "                      -1.2944, -1.1235, -0.6202, -1.1652, -0.9671, -1.1774, -1.8213, -0.8847,\n",
       "                      -0.6611, -1.5906, -0.7409, -1.0386, -1.0712, -1.1633, -1.0001, -1.3512,\n",
       "                      -0.9485, -1.2225, -1.0768, -1.1959, -1.0779, -1.0752, -1.1522, -0.9081,\n",
       "                      -1.0947, -0.8541, -0.9721, -1.3169, -0.8332, -1.1959, -0.8614, -1.2096,\n",
       "                      -1.2910, -1.3517, -0.7324, -0.7874, -1.2204, -0.3987, -1.2808, -1.0477,\n",
       "                      -1.0734, -0.4106, -0.8290, -0.8418, -1.1694, -1.0074, -1.2381, -1.2645,\n",
       "                      -0.4686, -0.9527, -0.7772, -0.9946, -0.5623, -0.7630, -0.8910, -1.0892,\n",
       "                      -0.8300, -0.9807, -0.9775, -1.3635, -0.4377, -0.6563, -1.3178, -0.7624,\n",
       "                      -1.1922, -1.3888, -1.3011, -0.8241, -0.6315, -1.0948, -1.0740, -1.1862,\n",
       "                      -1.2401, -0.8922, -0.8188, -0.4529, -0.3196, -0.9116, -0.5977, -0.7753,\n",
       "                      -0.3463, -0.9359, -0.2351, -1.1351, -0.8505, -1.2622, -0.8808, -0.8275,\n",
       "                      -1.4604, -0.6374, -0.9875, -0.5543, -0.9385, -1.4324, -1.0252, -0.7666,\n",
       "                      -1.3167, -0.6675, -0.3785, -0.6188, -1.1109, -0.7665, -0.6459, -1.3750,\n",
       "                      -0.9565, -0.8162, -1.1617, -0.2942, -1.1032, -0.9313, -0.6704, -0.9382,\n",
       "                      -1.4996, -0.6677, -0.9241, -0.9116, -1.5874, -1.2366, -0.9990, -0.7313,\n",
       "                      -0.6550, -0.9268, -0.9094, -1.2075, -0.7507, -1.5805, -1.3963, -1.1001,\n",
       "                      -0.8197, -0.6291, -0.5572, -0.6652, -1.0816, -1.0449, -1.2613, -0.6382,\n",
       "                      -0.4380, -1.4386, -1.2137, -0.5551, -1.0229, -0.9086, -0.8036, -0.8823,\n",
       "                      -0.4433, -0.5666, -1.3386, -0.8249, -1.0241, -0.9359, -1.3669, -0.1792,\n",
       "                      -0.4910, -0.6613, -0.6006, -1.2904, -1.2362, -0.9800, -0.7748, -0.8731,\n",
       "                      -0.9160, -1.3455, -0.6145, -1.3676, -0.9559, -0.8511, -1.0169, -1.0877,\n",
       "                      -0.6715, -0.8468, -0.9053, -0.6382, -0.7508, -1.1323, -1.2330, -1.0002,\n",
       "                      -1.0657, -1.0172, -1.3319, -1.0393, -1.2256, -0.7244, -1.3001, -1.1020,\n",
       "                      -1.2895, -0.6108, -0.4768, -1.4196, -1.3897, -0.7835, -1.0923, -1.2570,\n",
       "                      -0.9177, -0.8924, -0.9494, -0.8150, -1.1034, -1.1010, -0.7710, -1.2923,\n",
       "                      -1.7607, -0.8246, -1.0299, -0.7357, -0.8449, -1.3700, -0.9031, -1.1970,\n",
       "                      -1.0119, -0.7387, -1.1051, -1.0061, -1.1059, -0.8715, -0.2503, -0.7411,\n",
       "                      -1.5400, -1.4532, -0.8578, -1.6902, -1.4873, -0.8968, -0.5279, -0.5539],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.running_mean',\n",
       "              tensor([-10.2793,  -5.1050,   0.5770, -12.2499,   1.1114,  -5.0149,   2.6296,\n",
       "                       -5.7523,  -4.7333,  -9.0336,  -4.5115,  -7.6067,  -9.8591,  -4.0122,\n",
       "                      -10.7823,  -5.9085,  -7.6807,  -4.9074,  -5.2075,  -5.1058,  -6.3960,\n",
       "                       -8.2817,  -5.2456,   0.0449,  -2.5947,  -5.1229,   3.0265,  -9.0198,\n",
       "                       -7.9768,  -2.0162, -16.2726,  -3.1200,  -5.7590,  -3.1134,  -8.1856,\n",
       "                       -5.2627,  -6.8978,   1.6054,  -2.5897,  -2.4606,  -6.4149,  -0.0205,\n",
       "                        1.8035, -11.9931,  -7.4352,  -4.6106,  -6.3099,  -1.2977,  -1.6846,\n",
       "                       -9.3642,  -5.2194,  -6.9079,  -4.9136,  -2.1780,  -5.5695,  -6.6912,\n",
       "                       -4.2017,  -7.7757,  -3.1779,  -4.0478,  -8.0861,  -3.7367,  -5.8779,\n",
       "                       -3.1723,  -1.7294,  -6.1344,  -4.8933,   0.0762,  -8.5907,  -5.8002,\n",
       "                       -9.0861,  -1.2178,  -0.4124,   2.0606,  -2.1005,  -7.2921,  -5.3342,\n",
       "                       -3.6185,  -6.3721,  -6.5325,  -6.0726,  -7.7600,  -3.4875,  -4.4815,\n",
       "                       -6.0967,  -1.5140,  -6.1712,  -3.2782,  -4.4434,  -9.1119,  -5.0394,\n",
       "                       -4.1701,  -8.7567,  -8.5084,  -7.7246,  -1.0465,  -1.7473,  -5.7842,\n",
       "                       -1.8228,  -6.2296,   2.0070,  -3.7328,  -7.6452,   0.0470,   1.9210,\n",
       "                       -8.1234,  -7.0801,  -3.7098, -13.6400,  -1.5657,  -6.4982,  -0.9597,\n",
       "                       -7.3450,  -5.1298, -13.1911,  -8.3593,  -6.5813,  -9.8701,  -8.2120,\n",
       "                      -10.2244,  -1.7166,   0.3624,  -6.1199,  -5.2311,  -2.4564,  -6.3264,\n",
       "                       -7.9257,  -7.9577,  -3.4013,   1.5921,  -5.8668,  -0.8193,  -2.5089,\n",
       "                       -5.0900,  -8.0176,  -6.4210,  -1.1759,  -6.7921,  -0.3481,  -9.2427,\n",
       "                       -9.9008,  -8.3225,  -9.3032,  -8.9493,  -5.2085,   1.5023,  -5.2136,\n",
       "                       -6.0105,  -6.2447,  -6.5079,  -4.2751,  -9.7660,  -6.1132,  -1.8229,\n",
       "                       -5.8968,  -8.7571,  -9.2568,  -0.3043,  -5.9986,  -0.7422,   2.8028,\n",
       "                       -3.2696,  -5.3210,  -3.5418,  -1.2045,  -5.7917, -10.0467, -10.2704,\n",
       "                       -6.2779,  -7.2943,  -5.7070,  -6.7291, -11.9753,  -4.7874, -12.9624,\n",
       "                       -8.8783,  -2.5503,  -0.9713, -10.5295, -12.2764,  -5.5694,  -6.0106,\n",
       "                       -4.0255,  -7.1279,  -8.2322,  -3.4059,  -1.6601,  -5.5689,   0.5852,\n",
       "                       -3.9591,  -4.6329,  -3.0914,  -7.8443,  -6.0076,  -6.4779,   1.6296,\n",
       "                        0.1636,  -6.4931,  -1.9335,  -6.2480,   0.8268,  -5.4800,  -9.3580,\n",
       "                       -3.8273,  -6.9180,  -3.8009,  -5.3921,  -1.0332,  -7.8456,  -4.3468,\n",
       "                       -3.9134,  -2.0628,  -0.8970,  -3.7377,  -5.2491,  -3.9716,   1.7836,\n",
       "                       -4.8697,  -9.8217, -12.0063,  -5.8720,  -6.0146,   1.1641,  -4.2303,\n",
       "                       -6.2902,  -7.7341,  -6.0825,  -7.5879,  -5.5148,  -6.5780,   0.0881,\n",
       "                       -7.2020,  -5.0114,  -4.3173,  -2.5251,  -4.9577,  -6.3364,  -7.3803,\n",
       "                       -2.9454,  -6.4389,  -5.0101,  -6.6061,  -6.5512,  -5.1629,  -4.6097,\n",
       "                       -1.5746,  -2.8374,  -0.5122,   0.7712,  -4.4144,  -5.8370,  -3.9464,\n",
       "                      -12.3806,  -4.7935,  -3.9609,  -3.2923,  -7.0694,  -6.3033,   2.0305,\n",
       "                       -6.3570,  -5.0539,  -5.1913,  -3.5339,  -2.1619,  -6.7763,  -6.3931,\n",
       "                      -11.1211,  -9.3622, -11.0594,  -5.0233,  -4.9589,  -6.3624,  -7.0158,\n",
       "                      -12.1250, -11.4559,  -5.3347,  -3.3384,  -1.9951,  -4.3446,  -1.8381,\n",
       "                       -6.8602,  -6.8828,  -1.9819,  -3.8376,   0.9528,  -7.9761,  -8.2387,\n",
       "                       -0.2785,  -7.7605,  -5.6871,   0.1998, -10.1335,  -5.3290,   1.1781,\n",
       "                      -10.0592,  -6.3349,  -0.9074,  -2.5916,  -8.9815,  -5.5814,  -7.6576,\n",
       "                       -7.7590,  -5.6901,  -5.7995,  -6.4633,  -7.0798,  -9.2863,  -3.3237,\n",
       "                       -0.7928,  -8.3835,  -3.3632,  -5.5329,  -5.8154,  -7.5749,  -5.4600,\n",
       "                       -3.2018,  -3.7958,  -1.2822,  -7.5610,  -8.0757,  -6.4004,   0.0784,\n",
       "                      -12.9392,  -7.0685,  -6.5679,   0.6536,  -9.9785,  -4.6147,  -8.3518,\n",
       "                        0.6975,  -7.0733,  -6.0345,  -6.5054, -11.3228, -10.2335,  -3.2918,\n",
       "                       -3.5762,   1.4748,  -5.7224,  -8.3526,  -4.4862,   0.8099,   0.4632,\n",
       "                       -3.3076,  -4.9378,  -7.3780,  -6.9124,  -4.9742,   0.9185,  -8.1968,\n",
       "                       -4.2707,  -8.3432,  -7.4695,  -2.3438,  -6.6042,  -7.4780,   1.3620,\n",
       "                       -7.4275,  -4.6859,  -9.7884,   0.5683,  -6.4116,  -4.6786,  -6.0446,\n",
       "                        2.2747,  -4.5395,  -7.1189,  -1.0410,  -0.2631,  -7.2017,   2.1779,\n",
       "                      -10.9636,  -6.8035,  -6.5435,  -6.0287,  -0.9497, -10.6271,  -5.2722,\n",
       "                       -6.2655,  -3.8363,  -7.2287,  -2.5849,  -2.7195,  -2.5114,  -2.4181,\n",
       "                       -3.6162,   1.2660,  -4.8813,  -7.8794,  -2.1826,  -5.0133,  -5.9276,\n",
       "                       -1.0022,  -5.2859,  -6.3448,  -0.0995,  -7.2606,  -4.8345,  -3.4389,\n",
       "                       -7.7076,  -6.0039,  -7.0864,  -1.5581, -11.9516,  -6.6842,  -4.7997,\n",
       "                       -7.9832,  -1.8929,  -3.8697,  -7.2771, -11.0676,  -8.2769,  -0.1662,\n",
       "                       -5.9941,  -5.0723, -12.7834,  -7.3765,  -8.0371,  -8.8059,  -7.5946,\n",
       "                       -6.9716,  -8.1132, -10.4097,   0.7244,  -8.5828,  -6.2128,  -9.7671,\n",
       "                       -6.6599,  -5.2965,  -0.7537,  -3.7555,  -4.3002,   2.1005,  -6.0888,\n",
       "                       -8.4214,  -6.9165,  -5.9569,  -4.5327,  -6.1004,  -2.8920,  -6.0032,\n",
       "                       -2.2724,  -3.9450,  -5.6058, -10.2554,  -9.5931,  -6.6777,  -7.4380,\n",
       "                       -8.7531, -11.3134,  -4.8196,  -5.7835,  -6.5160,   0.3841,  -8.8216,\n",
       "                       -3.3551,  -4.4611,  -9.0977,  -4.4484,   1.4702,  -2.2733,  -4.6829,\n",
       "                       -3.5563,  -7.8723,  -5.1950,  -4.8242,  -7.0583,  -8.7942,  -5.7782,\n",
       "                       -4.5458,  -8.1177,  -7.6210,  -3.1566,  -7.1672,   0.6632,  -4.1542,\n",
       "                       -4.2291,  -6.6208,  -7.1946,  -5.2934,  -9.6849,  -5.4624,  -3.5769,\n",
       "                       -3.4177,  -5.3127,  -6.7569,  -4.6155,  -6.7661,  -6.3095,  -3.6367,\n",
       "                       -4.8903,   2.3502,  -0.6025,  -9.1916,   2.1711,  -7.7282,  -5.9922,\n",
       "                       -8.2701,  -4.6847,  -5.7975,  -5.2849,  -7.1303,   1.8561,  -6.2341,\n",
       "                       -4.0587,  -4.0731,  -8.7921,  -6.9323,  -5.1966,  -2.1089,   1.8824,\n",
       "                        1.2020], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.running_var',\n",
       "              tensor([25.9477, 16.5733,  4.9564, 28.6898,  7.1413, 17.8488,  3.8144, 14.5970,\n",
       "                      17.3948, 38.2940, 13.0234, 29.2071, 31.1680,  8.8923, 30.8701, 12.7928,\n",
       "                      19.2679, 14.7399, 21.9500, 15.5500, 10.6833, 21.7241, 11.5524,  4.0457,\n",
       "                       7.9603, 16.8295, 15.5251, 32.9095, 23.1123, 14.0936, 37.5358, 12.4848,\n",
       "                      21.5845, 15.5798, 19.2634, 15.0854, 18.4694,  5.2985,  7.7973, 27.5669,\n",
       "                      15.9851,  9.6565,  3.9385, 20.3290, 28.3304, 12.5070, 14.7064, 26.1982,\n",
       "                       3.9066, 18.9662, 13.9175, 19.6702, 24.5714, 13.0022, 53.1503, 14.5090,\n",
       "                      14.9587, 12.9142,  4.3092, 14.5339, 24.8722, 10.7357, 28.5289,  8.0343,\n",
       "                       8.1199, 39.9542, 19.8778, 10.3461, 30.5962, 19.5617, 20.5699,  7.4316,\n",
       "                       7.8675,  7.7964,  7.1674, 33.1144, 13.7808, 20.8220, 15.3775, 13.9209,\n",
       "                      11.9177, 22.2030,  7.4819, 18.6825, 16.9285,  9.8723, 10.3241, 28.9917,\n",
       "                      16.9282, 27.4749, 34.3637,  8.9852, 22.4466, 38.7172, 34.9716, 11.5602,\n",
       "                      13.5902, 13.6143,  9.9763, 12.4859,  4.4295,  8.3284, 37.5300,  4.3734,\n",
       "                       3.0895, 41.6860, 34.0726, 10.5124, 36.2825,  8.2954, 29.2960,  6.3537,\n",
       "                      20.5536,  9.4501, 36.9986, 20.8720, 12.8368, 37.7083, 24.7643, 23.0841,\n",
       "                      12.6122,  4.0673, 14.8067, 38.4710, 14.2712, 13.7243, 10.6322, 19.8489,\n",
       "                      12.2712,  4.8436, 19.0219,  6.3717,  7.0603, 12.1327, 20.4187, 20.3443,\n",
       "                      13.9391, 32.7323, 13.4792, 28.6418, 26.6187, 31.5201, 23.0340, 22.5258,\n",
       "                      15.2911,  4.4022, 17.8964, 18.6309, 11.5805, 17.1843, 10.7487, 27.3265,\n",
       "                      11.7636, 27.5499, 13.4789, 26.4110, 48.1084, 10.9896, 19.1405, 11.0402,\n",
       "                       6.7606,  9.4307, 20.0629, 32.8033,  6.7211, 14.6987, 30.0069, 18.2410,\n",
       "                      14.6452, 26.7315, 14.6979, 28.7509, 37.2557, 21.9850, 32.0598, 26.7120,\n",
       "                       7.0789, 10.0965, 44.3797, 33.8998, 24.1027, 13.7562, 10.4648, 25.6448,\n",
       "                      23.1698, 24.1747, 13.5981, 19.5093,  4.4610, 11.9872, 11.1300,  4.4206,\n",
       "                      22.5331, 23.6396, 15.7599,  6.3538,  3.2810, 14.8751, 16.0796, 10.9207,\n",
       "                       5.1066, 16.0795, 31.8497, 20.7898, 13.5729, 17.2899, 15.2702,  7.9741,\n",
       "                      16.0184, 16.0046, 15.0117, 11.9559, 17.4703,  8.5567, 16.5416,  8.6536,\n",
       "                       3.1471, 13.3657, 36.9750, 29.1694, 13.3317, 11.3734,  4.7904, 11.2839,\n",
       "                      12.1372, 31.8972, 11.1363, 15.1774, 16.3388, 19.4651,  8.1487, 21.0309,\n",
       "                       9.1159, 11.8341, 15.9305, 18.3443, 19.2887, 23.6510, 19.0304, 25.6219,\n",
       "                      13.7310, 11.1023, 28.5880,  8.2523, 11.3362,  3.9850, 11.8526,  5.8452,\n",
       "                       4.6486, 13.1018, 18.2617, 25.5351, 26.5429, 22.0399, 14.0497, 18.8683,\n",
       "                      15.0423, 19.3316,  4.9169, 17.1923, 11.2731, 20.3997, 17.1153, 14.7711,\n",
       "                      13.1216, 14.6626, 18.7908, 33.7767, 31.1224, 16.8063, 19.4649, 26.5509,\n",
       "                      10.4670, 40.6961, 56.8420, 13.9113, 19.8506, 15.9927, 13.1833,  5.3747,\n",
       "                      12.9164, 19.6825, 11.7234, 10.5552,  3.2164, 19.0529, 18.6243,  3.8479,\n",
       "                      17.3073, 17.8297,  6.0869, 19.2629,  9.5786,  7.3701, 27.4588, 17.7705,\n",
       "                      17.8569, 10.5123, 23.3862, 21.5240, 13.3133, 22.4450, 18.8869, 15.9933,\n",
       "                      20.2897, 15.5485, 30.0565, 23.1910, 13.0794, 21.1492,  7.7913, 14.5334,\n",
       "                      17.4401, 11.9952, 13.4288, 12.8075,  7.4606, 21.0727, 18.0289, 19.0485,\n",
       "                      16.3264,  8.6855, 34.4725, 16.3944, 38.3138,  4.3363, 39.7006, 13.5680,\n",
       "                      25.1719,  2.3369, 14.6388, 22.5186, 15.4152, 31.3699, 20.9004, 18.2541,\n",
       "                       8.4245, 14.0153, 10.9995, 29.2076,  7.6909,  3.7396,  8.4154, 10.0600,\n",
       "                      16.5012, 19.1621, 21.0240, 20.0611,  5.7387, 18.8005,  6.1813, 12.2710,\n",
       "                      22.5044, 15.4921, 21.4759, 13.4136,  6.9473, 17.1352, 13.0289, 22.4990,\n",
       "                       6.0225, 10.6556, 16.2021, 32.8283,  4.7706, 14.8738, 11.1560,  5.3743,\n",
       "                       5.7921, 13.3604,  2.7482, 21.5029, 18.7508, 10.4992, 11.8807, 12.2436,\n",
       "                      20.7739, 19.8033, 14.8469, 29.4510, 16.5537, 11.8768, 14.7347,  8.0578,\n",
       "                      19.0071,  7.7629,  5.1596, 14.3560, 22.3317, 13.3205, 19.7466, 24.0590,\n",
       "                       6.4785, 15.4873, 12.4923,  3.4095, 13.0653, 28.5847, 11.8347, 21.4392,\n",
       "                       9.8598, 21.0303,  6.1335, 41.6386, 38.8693, 13.3092, 37.4739, 24.0293,\n",
       "                      29.3321, 20.2335, 25.1091, 15.4169, 20.7976, 11.3012, 18.0666, 31.7064,\n",
       "                      29.0671, 22.3197, 24.9146, 26.9031, 16.6671, 10.1967, 28.5814,  4.7615,\n",
       "                      12.0240, 24.9222, 47.2419, 14.4547, 15.7475,  8.2459, 14.8922, 18.0402,\n",
       "                       4.3960, 17.3405, 18.5886, 20.8925, 20.4716, 24.4640, 12.8354, 22.0989,\n",
       "                      11.8033,  8.9580, 29.3541, 14.4815, 44.2939, 45.6635, 12.4235, 14.7183,\n",
       "                      30.9570, 20.2884, 17.1768, 23.2277, 23.9515, 10.5962, 23.8915, 13.6565,\n",
       "                       5.5642, 14.8275, 18.0266,  6.5589,  6.7854, 11.0593, 15.2008, 14.4204,\n",
       "                      15.2472, 15.3347, 23.7237, 35.7539, 16.3468, 10.1289, 19.9992, 24.8273,\n",
       "                      20.1210, 10.2618,  2.7819, 10.3906,  9.9954, 16.3208, 10.1581, 13.0410,\n",
       "                      44.9760, 20.8118, 20.8414, 10.9393, 19.6904, 12.4679, 10.3500, 15.2428,\n",
       "                      15.8127, 14.6952, 11.2404,  6.7499,  7.6787, 20.9956, 15.3474, 27.1440,\n",
       "                      43.7911, 31.7482, 11.0519, 18.2463, 19.6826, 21.1500,  5.7881, 14.8946,\n",
       "                      20.2056, 12.6739, 27.8798, 16.1588, 19.6985,  6.2127,  5.5244,  3.4680],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.weight',\n",
       "              tensor([0.8692, 1.0196, 0.9362, 0.9131, 1.0375, 1.0444, 1.0132, 1.0092, 1.0608,\n",
       "                      1.0743, 1.0304, 1.1891, 1.0405, 1.0412, 1.0269, 0.9653, 1.0626, 1.0576,\n",
       "                      1.0416, 1.0394, 1.0032, 0.9530, 1.0887, 1.1196, 1.2284, 1.1845, 1.2006,\n",
       "                      1.0038, 0.9120, 0.9737, 1.0074, 1.0234, 0.9587, 0.9566, 1.1203, 1.0380,\n",
       "                      1.2199, 1.0974, 1.0536, 0.7612, 0.9293, 1.2127, 1.0957, 1.0487, 1.0060,\n",
       "                      0.9303, 1.1301, 0.9962, 0.9253, 0.9390, 1.0552, 1.0215, 0.6022, 1.1631,\n",
       "                      1.0075, 0.9166, 1.1436, 1.1242, 0.9639, 0.8867, 0.8757, 1.0242, 1.0773,\n",
       "                      1.0337, 1.0872, 0.9788, 0.9669, 0.9332, 0.7769, 1.0834, 1.1052, 1.0670,\n",
       "                      1.2093, 1.0479, 0.8535, 1.0409, 1.0113, 0.8261, 0.9043, 1.0220, 1.0291,\n",
       "                      1.0649, 0.9358, 1.2345, 0.9310, 0.9950, 1.1893, 1.0115, 0.7559, 1.0712,\n",
       "                      1.0209, 0.9954, 0.8501, 1.0186, 1.1557, 0.9994, 0.9954, 1.0819, 1.0597,\n",
       "                      1.0474, 1.0162, 0.9761, 0.9244, 0.9922, 0.9519, 1.1067, 0.9372, 0.9337,\n",
       "                      1.1715, 1.0161, 1.0217, 1.0195, 1.1220, 1.0149, 1.1270, 1.1602, 0.9379,\n",
       "                      1.0706, 1.1358, 1.0445, 0.9419, 1.0347, 0.9873, 1.0045, 0.9723, 1.0441,\n",
       "                      0.8574, 1.0103, 1.0524, 0.9981, 0.9770, 1.0063, 1.0351, 1.0704, 1.0712,\n",
       "                      1.1775, 1.0923, 1.0152, 1.0871, 1.0963, 0.9691, 1.0647, 0.6194, 1.0080,\n",
       "                      1.0311, 1.1069, 0.9379, 1.0183, 1.0397, 0.9723, 1.0926, 0.9570, 1.1201,\n",
       "                      0.6124, 1.0335, 1.0131, 1.0401, 1.0126, 0.9381, 1.0591, 1.0451, 0.6448,\n",
       "                      1.2713, 0.8568, 1.0401, 0.9968, 0.9266, 0.9932, 1.0042, 1.0146, 0.9523,\n",
       "                      1.0785, 1.0504, 1.0440, 0.8292, 1.0258, 0.8946, 1.0836, 0.9695, 1.1255,\n",
       "                      1.0539, 1.0798, 1.0433, 0.9571, 1.0015, 1.0899, 0.9283, 1.0606, 0.9519,\n",
       "                      0.7614, 0.7617, 0.9541, 1.1838, 0.9471, 1.0733, 1.1440, 1.0788, 1.0504,\n",
       "                      0.9725, 0.7654, 1.0277, 0.7071, 0.9312, 1.0306, 1.0887, 1.1121, 0.9629,\n",
       "                      1.0552, 1.0747, 1.1719, 0.8791, 1.0809, 1.0920, 0.8258, 1.0560, 0.9856,\n",
       "                      1.0623, 0.8904, 0.9770, 0.9496, 1.1909, 0.8231, 0.9825, 0.9999, 1.0781,\n",
       "                      1.0322, 0.9479, 0.6987, 1.0529, 0.9777, 1.0731, 1.0085, 1.0309, 0.9760,\n",
       "                      1.1300, 1.0308, 0.9500, 0.8970, 1.0981, 0.9828, 1.0356, 1.0897, 1.0457,\n",
       "                      1.1373, 1.0823, 1.0683, 1.1204, 1.0674, 1.1082, 1.0366, 1.0477, 0.7976,\n",
       "                      1.0946, 1.0202, 0.9869, 0.9141, 0.9358, 1.0071, 1.0090, 0.9882, 1.2007,\n",
       "                      0.9805, 0.9280, 0.9648, 1.1031, 1.0952, 1.0682, 0.9051, 0.9703, 0.9847,\n",
       "                      1.0507, 1.0302, 1.0373, 1.0126, 1.1133, 0.9373, 1.0751, 1.0259, 0.8999,\n",
       "                      0.9758, 1.0634, 0.9822, 0.9974, 1.1841, 1.0385, 0.9460, 1.0757, 1.0571,\n",
       "                      0.8684, 0.7430, 1.0869, 1.0043, 0.8735, 0.9567, 1.0572, 1.0317, 1.0294,\n",
       "                      1.0523, 1.0352, 1.0453, 1.1801, 1.1518, 1.0357, 1.0031, 1.0059, 1.0505,\n",
       "                      0.8497, 0.8277, 0.7445, 1.0762, 1.0021, 1.1202, 1.0641, 0.9924, 1.1110,\n",
       "                      1.0767, 0.9756, 1.0253, 1.1018, 0.9259, 0.9461, 1.0254, 1.0322, 0.9632,\n",
       "                      1.0843, 0.8916, 0.8301, 1.1465, 0.9954, 0.9512, 0.9322, 0.9779, 0.9065,\n",
       "                      0.9694, 0.5169, 1.1076, 1.0327, 0.9517, 1.1000, 0.9666, 0.9286, 0.9862,\n",
       "                      1.1279, 0.9118, 0.9248, 0.8618, 0.8209, 0.7729, 0.9371, 0.8842, 0.9992,\n",
       "                      1.0429, 1.0914, 0.8012, 1.0192, 1.0117, 1.0623, 1.0231, 1.0377, 1.1539,\n",
       "                      0.8518, 0.6366, 1.0854, 0.9593, 0.9821, 0.8839, 1.2614, 0.9315, 0.8245,\n",
       "                      0.9191, 1.0720, 0.9815, 0.7630, 1.0368, 1.0000, 1.0597, 0.9025, 1.0035,\n",
       "                      1.1145, 0.9382, 1.0012, 0.9382, 0.9492, 1.0129, 0.7285, 1.0805, 0.9569,\n",
       "                      1.0730, 1.0464, 0.8662, 0.5841, 0.9371, 0.7384, 0.9628, 1.1045, 0.9737,\n",
       "                      1.0557, 1.1154, 1.1908, 0.9917, 0.9906, 0.7624, 1.0398, 0.9751, 1.0418,\n",
       "                      1.0149, 0.8918, 0.9710, 0.9319, 0.9814, 0.9381, 0.9196, 1.1777, 1.0211,\n",
       "                      1.0665, 0.9604, 1.0621, 1.0200, 0.8991, 0.9888, 0.8206, 1.0428, 1.0212,\n",
       "                      1.0214, 1.0759, 1.0050, 0.9450, 0.9638, 1.0861, 1.0789, 0.9607, 0.7226,\n",
       "                      0.8935, 1.0180, 0.9566, 1.1027, 0.9531, 0.9753, 1.1532, 1.0002, 0.9920,\n",
       "                      1.0342, 0.9385, 0.8641, 0.9388, 0.9327, 1.0506, 1.0106, 1.0389, 0.9956,\n",
       "                      1.0707, 1.0160, 1.1350, 1.1605, 0.9819, 0.9502, 1.0184, 1.0517, 1.0610,\n",
       "                      1.0803, 0.9218, 0.9971, 1.0046, 1.0675, 0.9909, 1.1060, 0.7715, 1.0106,\n",
       "                      0.9804, 1.0199, 1.0249, 1.0042, 1.0969, 0.8566, 1.0517, 0.6326, 1.0388,\n",
       "                      1.0691, 1.0669, 0.9527, 1.0403, 1.0416, 0.7403, 1.1037, 1.0038, 1.0177,\n",
       "                      0.5930, 0.9599, 1.0896, 0.9358, 0.9490, 0.9979, 1.0591, 0.9622, 0.9875,\n",
       "                      0.9553, 1.0062, 1.0119, 1.1283, 1.0414, 1.0745, 1.0687, 0.8101, 1.0115,\n",
       "                      1.1221, 1.0903, 0.9864, 1.1624, 1.0129, 1.0907, 0.9775, 0.7475],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.bias',\n",
       "              tensor([-0.6357, -0.8527, -0.7240, -0.7183, -0.9574, -0.9813, -0.7130, -0.8558,\n",
       "                      -0.8158, -0.8945, -0.7349, -0.9749, -1.0785, -0.7781, -0.8201, -0.7343,\n",
       "                      -1.2163, -0.9349, -0.9170, -0.7448, -0.8741, -0.8969, -1.0082, -0.9573,\n",
       "                      -1.1156, -1.2825, -1.2379, -0.9295, -0.6968, -1.0297, -0.9719, -0.8778,\n",
       "                      -0.6440, -0.7050, -1.0121, -1.0072, -1.1827, -0.8992, -0.8494, -0.6630,\n",
       "                      -0.6907, -1.1151, -0.9045, -1.0034, -0.8512, -0.8988, -1.0106, -0.6670,\n",
       "                      -0.6949, -0.8435, -1.0474, -0.8233, -0.4661, -1.0223, -0.9171, -0.9080,\n",
       "                      -1.1544, -1.0028, -1.1745, -0.8494, -0.5735, -1.0519, -0.8442, -0.8575,\n",
       "                      -1.1057, -0.8953, -0.8886, -0.8457, -0.5678, -1.0093, -0.9063, -0.9730,\n",
       "                      -1.3149, -0.9343, -0.6227, -0.9176, -0.9047, -0.6808, -0.7603, -0.9709,\n",
       "                      -0.9282, -1.0250, -0.7901, -1.1732, -0.9183, -0.8938, -1.0894, -0.7654,\n",
       "                      -0.7095, -1.1964, -0.8708, -0.8142, -0.8661, -0.9949, -1.1258, -0.9737,\n",
       "                      -0.7671, -0.9461, -0.8957, -0.9559, -0.8173, -0.8774, -0.8777, -0.9807,\n",
       "                      -0.6896, -0.9080, -0.7666, -0.7901, -0.9920, -1.0560, -0.9186, -0.8876,\n",
       "                      -0.9487, -0.8476, -0.9140, -1.0839, -0.7586, -1.0032, -1.0627, -0.9870,\n",
       "                      -0.6890, -0.7998, -0.8275, -0.7153, -0.7468, -0.9308, -0.5439, -0.7082,\n",
       "                      -0.9491, -0.8077, -0.7686, -0.8005, -1.1216, -1.0302, -0.8449, -1.2532,\n",
       "                      -1.0404, -0.8978, -0.8028, -1.0356, -0.8640, -0.9739, -0.3478, -0.7908,\n",
       "                      -1.0078, -1.0894, -0.6264, -0.9284, -0.8441, -0.6705, -0.9099, -0.6895,\n",
       "                      -1.0781, -0.4041, -0.9598, -0.9002, -0.8591, -0.8593, -0.9035, -0.9717,\n",
       "                      -0.8061, -0.4209, -1.1186, -0.6594, -0.9079, -0.8793, -0.6905, -0.7890,\n",
       "                      -0.7763, -0.8181, -0.7768, -0.9247, -1.1757, -0.9052, -0.6392, -0.9119,\n",
       "                      -0.8816, -1.1514, -0.6032, -1.1121, -1.0446, -0.9701, -0.9160, -0.7903,\n",
       "                      -0.9031, -0.9186, -0.8806, -0.9007, -0.8075, -0.5293, -0.7690, -0.7966,\n",
       "                      -1.0551, -0.7402, -0.9771, -1.1216, -1.0144, -0.7270, -0.8152, -0.4969,\n",
       "                      -0.9188, -0.5080, -0.6954, -0.8943, -0.9111, -0.9846, -0.7691, -0.7996,\n",
       "                      -0.9310, -0.9318, -0.7881, -1.0120, -1.1179, -0.6427, -0.8588, -0.8852,\n",
       "                      -0.9369, -0.6432, -0.8372, -0.7708, -1.0399, -0.5446, -0.8622, -1.0342,\n",
       "                      -1.0385, -0.9053, -0.7958, -0.5640, -1.0736, -0.7351, -0.9306, -0.7655,\n",
       "                      -0.9475, -0.9423, -1.0223, -0.8780, -0.8575, -0.8953, -1.0348, -0.9474,\n",
       "                      -1.0599, -0.8597, -0.9905, -0.8517, -0.8602, -1.0753, -0.9481, -1.0397,\n",
       "                      -0.9873, -0.9807, -0.9107, -0.8368, -0.9407, -0.9491, -0.9919, -0.6827,\n",
       "                      -1.0033, -0.8495, -0.9439, -0.7659, -0.9812, -0.7008, -0.6716, -0.7872,\n",
       "                      -0.7998, -0.9925, -0.7968, -0.6551, -0.9045, -0.9280, -1.0423, -0.9507,\n",
       "                      -0.8546, -0.7400, -1.2037, -0.9359, -0.8926, -0.8114, -0.8905, -0.9073,\n",
       "                      -0.9369, -0.8521, -0.9964, -0.9729, -0.9072, -0.6744, -0.9125, -0.8992,\n",
       "                      -0.6318, -0.5347, -0.9464, -1.0394, -0.8523, -0.7701, -0.8907, -0.9499,\n",
       "                      -1.0483, -0.9705, -0.9066, -0.9237, -1.2272, -1.3275, -0.8460, -0.7763,\n",
       "                      -0.6645, -0.9437, -0.4811, -0.6286, -0.5974, -0.9572, -0.8808, -0.9409,\n",
       "                      -0.9350, -0.8788, -0.9325, -0.9302, -0.9094, -0.8218, -1.0726, -0.7214,\n",
       "                      -0.9896, -0.8111, -1.0361, -0.7955, -0.7910, -0.7099, -0.6057, -0.9668,\n",
       "                      -0.8110, -0.9454, -0.8162, -0.7066, -0.6406, -0.9381, -0.2838, -1.2096,\n",
       "                      -0.8564, -0.9551, -1.0171, -0.8412, -0.7527, -0.7537, -0.9505, -0.7497,\n",
       "                      -0.8901, -0.6481, -0.7140, -0.4668, -0.8714, -0.9210, -1.0737, -0.9736,\n",
       "                      -0.9253, -0.8462, -0.9520, -0.7971, -1.1652, -0.9690, -0.9288, -0.8844,\n",
       "                      -0.7713, -0.4085, -0.9273, -0.7709, -0.9965, -0.7296, -1.0591, -0.8909,\n",
       "                      -0.6816, -0.7582, -0.8895, -1.0022, -0.4112, -0.9052, -0.8330, -0.7699,\n",
       "                      -0.6271, -0.7419, -0.9814, -0.8401, -0.8756, -0.7851, -0.8853, -0.9722,\n",
       "                      -0.4361, -1.0040, -0.8905, -0.9258, -0.8468, -0.6977, -0.3273, -0.7692,\n",
       "                      -0.5724, -0.7710, -0.9961, -0.9429, -1.0810, -1.0256, -1.0846, -0.8732,\n",
       "                      -0.8395, -0.6623, -0.7299, -0.7672, -1.0518, -0.8442, -0.7411, -1.0576,\n",
       "                      -1.0265, -0.9971, -0.9094, -0.6428, -1.1716, -0.7394, -0.8364, -0.8228,\n",
       "                      -0.9271, -0.7503, -0.7941, -0.9165, -0.6003, -0.7904, -0.8405, -1.0136,\n",
       "                      -0.8585, -0.9383, -0.6179, -0.9837, -1.0112, -0.8642, -0.8000, -0.4619,\n",
       "                      -0.7208, -0.9207, -0.8988, -0.8371, -0.9391, -0.8320, -0.9519, -0.8000,\n",
       "                      -0.8909, -0.9169, -0.8799, -0.7483, -0.7430, -0.9219, -0.8550, -0.8171,\n",
       "                      -0.7724, -0.8056, -0.8571, -0.8749, -1.1316, -1.0753, -1.0479, -0.9392,\n",
       "                      -0.8136, -0.8701, -0.9236, -0.9709, -0.8798, -0.6883, -0.9078, -0.9579,\n",
       "                      -0.9275, -1.1071, -0.5766, -0.9774, -0.8089, -0.9832, -1.1391, -0.9514,\n",
       "                      -0.9571, -0.8613, -0.9184, -0.5020, -1.0454, -0.9861, -0.8187, -0.9366,\n",
       "                      -0.9146, -0.9690, -0.4672, -1.0258, -0.9856, -0.9362, -0.3431, -0.7617,\n",
       "                      -0.8894, -0.7865, -0.8302, -0.9095, -0.8643, -0.8991, -0.9230, -0.7429,\n",
       "                      -0.7601, -0.8827, -1.0443, -0.8199, -0.9924, -0.9508, -0.6007, -0.8046,\n",
       "                      -0.9269, -0.9579, -0.7895, -0.9726, -0.8318, -1.0327, -0.9359, -0.5078],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.running_mean',\n",
       "              tensor([ -7.2217,  -9.4223,  -7.8555, -11.1171, -10.0695, -10.1816,  -9.7072,\n",
       "                      -11.7213, -11.2590, -11.6571, -11.2408, -12.6502,  -9.2718, -11.3189,\n",
       "                       -9.7495,  -9.7426, -10.5952,  -9.2792, -12.3860, -12.8628,  -9.4238,\n",
       "                       -9.1996, -11.4070, -10.2552, -14.0790,  -8.0529, -12.4514, -13.6325,\n",
       "                       -6.2170,  -6.2160, -13.5863, -14.3095,  -7.6623,  -8.5154, -15.6250,\n",
       "                      -12.8607, -12.8907, -10.0198, -11.2232,  -8.9098,  -8.9619, -11.4442,\n",
       "                      -13.6419, -12.4959, -10.6334, -10.8593,  -9.7524,  -9.5926, -10.5570,\n",
       "                       -9.5048,  -9.8907, -11.6446,  -5.3319, -11.6572,  -8.4265,  -9.6813,\n",
       "                      -13.1681, -13.0823, -11.3458,  -8.7367,  -7.2302, -12.3392,  -9.5577,\n",
       "                      -10.3921,  -8.5522,  -8.0391,  -7.5973,  -9.0618,  -6.4561, -13.9282,\n",
       "                      -11.7446,  -8.7068, -11.7447,  -9.6265, -10.5582, -11.7715,  -6.6955,\n",
       "                       -6.5593,  -7.6174, -14.4919,  -9.2879,  -9.6648,  -8.8314, -14.4307,\n",
       "                       -9.2314,  -9.1620, -13.7911,  -8.6315,  -7.4932, -12.4490, -13.6174,\n",
       "                      -12.8365,  -8.1795, -11.0466, -14.5331, -11.1737, -10.7006, -13.7215,\n",
       "                      -10.2419, -10.5857, -11.3194,  -8.6429, -14.4091, -11.8756, -10.0178,\n",
       "                      -15.7342, -12.2482, -10.7726,  -9.0064,  -7.0679,  -8.7856,  -9.3819,\n",
       "                       -8.7810,  -8.2171, -11.0313, -12.0236, -10.7850,  -8.3264, -12.4882,\n",
       "                      -12.3049, -12.1004, -11.7934,  -8.6513,  -9.9407, -12.6059,  -6.4946,\n",
       "                      -11.3678, -10.3008, -15.7178,  -9.4577, -12.9797, -11.8957,  -9.2470,\n",
       "                      -11.4784,  -8.8219, -12.2327, -11.2816,  -7.2670,  -9.0750, -10.4724,\n",
       "                       -7.4391, -11.9796,  -9.0265,  -9.7816, -10.7094,  -7.7733,  -6.4624,\n",
       "                       -9.9683,  -8.1779,  -9.5215, -12.2368,  -7.7565, -11.2028,  -4.9102,\n",
       "                       -7.1140, -10.6850, -12.9298,  -7.5132, -10.5257, -10.9926, -10.7832,\n",
       "                       -8.8580, -18.0062,  -9.4415, -10.2365, -11.5155,  -8.0074,  -6.9057,\n",
       "                      -11.1964,  -8.3443,  -6.8587, -11.6304,  -9.6873,  -8.6372,  -9.6715,\n",
       "                       -8.7017, -11.9263,  -9.1683,  -8.5967, -12.6367,  -9.3720,  -7.4918,\n",
       "                      -13.1590, -10.0388,  -9.7203, -10.3351,  -7.9317, -10.7264,  -9.6274,\n",
       "                       -8.1217,  -9.2193, -12.2071, -13.4013, -10.6536, -10.3623, -10.3160,\n",
       "                      -10.0965,  -8.1060,  -8.5414,  -9.2067, -11.1811,  -6.1787,  -9.7677,\n",
       "                       -7.1946,  -8.3545,  -9.4483, -11.4419, -13.4036, -10.8391, -12.5806,\n",
       "                       -7.6436, -14.4315, -10.3716, -10.1163, -10.5008,  -9.3274, -15.0703,\n",
       "                      -12.0637,  -9.0438, -10.4931, -11.8402, -10.3053,  -9.4609,  -7.6577,\n",
       "                      -10.5881, -12.5979,  -8.0026,  -6.9366, -11.1863, -10.6480, -12.0001,\n",
       "                      -11.1000, -12.4991, -10.0910,  -8.9072, -12.4983, -12.2681, -10.1324,\n",
       "                      -11.1406, -10.9403, -12.6944, -11.3389, -10.4013, -11.9818, -11.3081,\n",
       "                       -9.9142, -13.1472,  -9.2163, -13.2241, -11.7402, -11.6737,  -9.6230,\n",
       "                      -13.4140, -12.1015, -11.5829,  -8.9552,  -9.0485,  -9.6531,  -9.9278,\n",
       "                      -11.3367,  -9.3939, -10.8233,  -9.8794,  -8.1579, -14.4697, -11.9489,\n",
       "                       -8.7169,  -6.3876, -12.5473,  -7.8143,  -9.4044,  -9.3503,  -7.3239,\n",
       "                      -15.4242, -13.2306,  -8.0393, -10.4300, -11.2145,  -9.9549,  -9.5331,\n",
       "                      -13.3521, -11.4589, -10.0917, -10.9457,  -6.9367,  -8.9972,  -9.4621,\n",
       "                      -12.0825, -12.3788,  -9.2887,  -8.7469, -12.6476,  -8.6055,  -9.1447,\n",
       "                      -10.5725,  -8.6255,  -8.3522, -12.0912,  -7.6991, -12.8994, -11.6844,\n",
       "                      -10.7394,  -9.3927, -11.6476,  -7.7208, -11.9528,  -8.8031,  -9.6025,\n",
       "                       -8.3256,  -9.1556, -11.2885,  -7.9890, -10.5148, -10.8330, -14.7228,\n",
       "                      -12.7514, -12.7055, -11.4063, -11.3698,  -9.0356,  -8.7748, -10.5433,\n",
       "                      -11.1318,  -7.7884, -10.5276, -12.0900,  -9.2404, -13.7438, -10.4205,\n",
       "                      -12.8268, -12.3967,  -8.6786, -10.9816, -10.9238,  -5.9067, -11.4906,\n",
       "                      -10.0465, -12.1413,  -7.2672, -11.3725,  -4.9285, -11.6286, -10.8008,\n",
       "                      -10.3324, -12.3026,  -9.6679, -10.3923,  -9.8403,  -8.6109, -12.4986,\n",
       "                       -8.9889, -16.8392, -13.0485, -11.0315, -10.8717,  -8.3067, -10.5114,\n",
       "                      -14.8787, -12.6069, -10.4141,  -7.3667,  -9.0827,  -8.5039, -13.4819,\n",
       "                       -6.4613,  -5.1190,  -9.6952, -11.0072, -10.8268, -12.5833,  -7.9105,\n",
       "                      -12.5562,  -6.2074, -10.0806, -11.3504,  -9.3440,  -7.1545, -10.8582,\n",
       "                       -8.7306,  -9.0149,  -8.8829, -10.9102, -11.2524,  -8.9335,  -8.7774,\n",
       "                      -10.2540, -13.7164, -11.3447, -11.1530,  -8.0848,  -5.1182,  -7.2847,\n",
       "                       -9.5097,  -6.8421, -11.2962, -11.4274, -11.5100,  -9.4415,  -9.5615,\n",
       "                       -8.6290, -10.4914,  -5.1203, -14.6960, -12.8453, -11.7213,  -9.3324,\n",
       "                      -13.3476,  -9.4075, -11.5146,  -7.7887,  -9.4822,  -9.4678,  -9.3904,\n",
       "                      -11.4133, -12.7036, -11.6822,  -9.2775,  -8.9780, -11.1748,  -9.4884,\n",
       "                       -8.8757,  -6.3992, -11.8633,  -9.8954, -12.3142, -10.4113,  -8.0166,\n",
       "                       -8.0830, -16.9970,  -8.0023, -11.6493,  -6.2276, -11.0222, -14.8319,\n",
       "                       -8.3396,  -9.7679,  -7.3102,  -9.2206, -10.8120, -11.0586, -10.9502,\n",
       "                       -8.7739, -11.9664, -12.3467,  -9.1712,  -8.8585, -11.9318, -13.1968,\n",
       "                      -10.9864,  -7.0135, -11.3529, -10.9490, -10.8191, -14.6997,  -9.9752,\n",
       "                       -9.8470, -10.3471,  -9.8631, -16.0614, -11.2940,  -6.3747, -10.9368,\n",
       "                       -8.2019,  -9.1173,  -9.5453, -11.2364, -11.6317, -10.6414, -10.2458,\n",
       "                      -15.1182,  -8.8647, -10.5941, -11.7257,  -8.2518,  -7.7674,  -6.1582,\n",
       "                      -12.5324, -10.5480, -15.6717,  -9.8634,  -8.9418,  -9.5094,  -5.1978,\n",
       "                       -9.5818, -12.6270, -11.0348,  -6.8526,  -8.4254,  -9.6214,  -8.7497,\n",
       "                       -6.8091, -11.9404, -12.8351,  -9.0511,  -7.4129, -10.5719,  -8.1175,\n",
       "                       -9.1278, -15.8671, -10.2872, -13.2889,  -9.5792, -12.3235,  -9.9624,\n",
       "                      -11.6903, -10.9088,  -5.9552, -10.1533, -11.9592, -10.2975, -15.1941,\n",
       "                       -8.0593], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.running_var',\n",
       "              tensor([110.1013,  96.6726,  98.5284, 169.1435, 125.3366, 131.8992, 157.7085,\n",
       "                      141.3341, 149.2600, 217.5996, 176.2289, 182.7384,  80.2694, 209.9898,\n",
       "                      125.8025, 135.3296,  91.9456,  91.7280, 142.9655, 209.0277,  88.5425,\n",
       "                       82.1984, 148.4225, 135.6134, 160.7234,  63.7350,  93.9494, 200.4517,\n",
       "                       66.7372,  31.2505, 165.5277, 217.5831, 150.6635, 124.6320, 186.7790,\n",
       "                      148.4877, 144.1012, 131.7364, 189.5228,  83.9388, 107.3515, 102.9139,\n",
       "                      165.2373, 128.3841, 136.5176,  88.6900,  97.4081, 174.6878, 156.0142,\n",
       "                       84.7350,  80.9815, 166.5275,  87.9052, 121.1472,  66.6285,  81.6391,\n",
       "                      121.2194, 158.9013,  67.9545, 115.1811, 103.4202,  78.5062,  92.2965,\n",
       "                      158.7301,  49.4481, 102.7154,  47.7885, 108.4013,  73.1864, 152.3747,\n",
       "                      143.2400,  86.5247,  96.5657,  98.6674, 143.7276, 166.4690,  50.6137,\n",
       "                       93.5723,  74.5582, 185.1402, 110.8337,  94.8524, 114.5059, 142.2812,\n",
       "                       58.9620, 148.6631, 143.0482, 116.4142,  57.8174, 119.7907, 159.5803,\n",
       "                      235.4661,  87.1023, 116.2071, 124.5230,  72.2186, 168.6625, 220.6602,\n",
       "                      132.6162, 140.5872, 119.5533,  67.9487, 179.9690, 114.5721, 200.1702,\n",
       "                      190.9090, 133.7323, 166.5645,  90.8927,  44.1526,  89.1107,  81.5050,\n",
       "                       69.9309,  75.3521, 121.8020, 143.3390, 136.8282,  81.7913, 119.4934,\n",
       "                      128.8568, 183.8851, 135.8139,  92.1185, 190.1746, 202.9908,  66.4810,\n",
       "                      116.3261, 147.3400, 223.4248, 160.3358, 151.2916, 169.2514,  71.6559,\n",
       "                       90.9859,  96.6361,  92.7306,  98.1640,  50.6953,  97.8228, 109.0772,\n",
       "                       62.8536, 121.9632, 177.8334,  76.8715,  74.1420,  80.4216,  97.8073,\n",
       "                       87.0813,  86.5070, 211.5015, 168.8579, 103.6034, 111.8142,  81.8090,\n",
       "                       55.8474, 122.8912, 149.1518,  70.3364,  86.0826,  82.7988, 155.4536,\n",
       "                      120.4539, 239.7780, 127.3867, 146.4868, 139.6124, 100.1240,  84.6870,\n",
       "                      161.9178,  84.3400,  68.0607, 111.1455,  90.4961, 120.1926, 146.9254,\n",
       "                       78.8875, 108.2526,  83.5099, 170.5288, 114.0824,  57.6681,  83.1408,\n",
       "                      154.8800, 130.4887,  69.8103, 114.7006,  58.8390, 130.3068, 112.9413,\n",
       "                       95.5596,  76.9168, 107.3800, 221.2277, 131.5453, 101.0562,  74.8707,\n",
       "                       79.0981, 148.5423,  78.7560, 143.8539, 160.5497,  91.7535, 114.0328,\n",
       "                       56.7479,  86.7435, 140.3108, 175.3329, 207.8251, 169.8280, 132.7879,\n",
       "                       90.0089, 162.7866,  90.4319, 104.3550,  93.4183,  70.2525, 193.8038,\n",
       "                      145.8176, 119.6230, 180.1873, 130.2723, 249.5124,  95.7630,  43.2008,\n",
       "                       71.8060, 133.5331,  85.6062, 107.4483,  81.1492, 157.1075, 161.8346,\n",
       "                      184.4619, 162.2600,  74.3426,  70.5584, 120.7091, 144.7428,  68.3063,\n",
       "                      110.9502,  85.8114, 105.6033, 189.9105,  94.4094, 185.3419, 158.1815,\n",
       "                       69.1600, 161.4762,  65.7762, 166.5166, 111.9396, 163.1152,  72.1205,\n",
       "                      174.4374, 158.1032, 122.6268, 183.1980,  79.2362, 124.0882,  86.4705,\n",
       "                      127.4449, 113.9221, 213.7068, 273.2770,  84.5255, 223.4370, 151.7839,\n",
       "                      122.4230,  91.7628, 118.4312,  93.5417, 118.1462,  78.5812,  77.4551,\n",
       "                      310.5958, 106.2299,  46.5142,  96.5988, 170.8459,  72.7737, 110.2889,\n",
       "                      172.8573, 141.7009, 100.1371, 166.6598,  70.4011, 120.2401, 110.3596,\n",
       "                      257.4808, 206.7974, 128.4669, 112.8255,  94.8757,  70.4902, 117.4317,\n",
       "                      125.2519,  91.7481,  72.0719, 127.7492,  94.7460, 144.4422,  89.8823,\n",
       "                       58.0244, 112.2464, 141.9746,  97.7469, 148.0883, 158.9829, 114.1908,\n",
       "                      112.5693,  86.8755,  95.8040,  68.1667, 123.8803, 132.8888, 183.8204,\n",
       "                      157.2871, 108.9738, 145.1028, 126.2896, 152.6040,  58.9737, 114.8399,\n",
       "                      129.9149, 101.2524, 155.0703, 228.5103, 187.0171, 184.6077, 150.3114,\n",
       "                      120.3314, 138.5758, 114.6693, 275.3282, 111.4841, 144.9713,  72.2476,\n",
       "                      107.7681,  89.2029,  57.9141, 130.5548,  62.9172, 157.2776, 138.3540,\n",
       "                      166.7440, 131.0383, 137.9407,  83.9371, 153.9592,  73.4197, 127.9162,\n",
       "                       62.7614, 201.9830, 171.1706,  96.5811, 105.9448, 120.7381,  82.2109,\n",
       "                      212.9325, 152.6997, 132.3338,  69.9235, 111.8345,  73.2308, 292.5711,\n",
       "                       42.3482,  77.1124, 108.5411,  97.8758, 128.8943, 150.3757, 124.9101,\n",
       "                       85.6510, 147.2085, 125.9798, 157.2897, 128.7485, 117.7546, 164.0232,\n",
       "                       71.6350,  81.0349,  73.1138, 102.3292, 124.0345,  71.3246,  81.5554,\n",
       "                      107.3662, 149.7952, 125.9802, 175.7148,  76.6589, 213.6187,  90.5383,\n",
       "                      160.0675,  57.0136, 129.2416,  95.9125, 100.5742, 105.0315,  90.8378,\n",
       "                       72.2433, 139.2287,  81.7090, 282.4514, 147.1225, 111.8001,  84.1852,\n",
       "                      181.8748,  85.6247,  83.1833,  51.0131,  80.0823, 158.6868,  68.2417,\n",
       "                      183.6794, 146.5224, 187.7189, 100.0812, 130.7287, 105.3006,  70.1932,\n",
       "                       97.1133,  77.9340, 190.2665,  79.4642, 160.6101, 118.4879, 130.7286,\n",
       "                       47.0878, 217.4846,  89.7300, 177.2421, 109.4929, 201.4668, 246.0836,\n",
       "                      119.2581, 115.1693,  52.8004,  97.3680, 120.0003, 194.6324, 124.6765,\n",
       "                       80.3927,  91.8537, 184.7792, 106.4194,  64.6763, 165.3777, 196.0274,\n",
       "                      167.1150,  70.6278,  97.2015, 161.7706, 103.0451, 142.7020,  95.7354,\n",
       "                       90.0979, 134.3394, 120.6295, 206.8418, 165.7470,  48.3387, 189.5372,\n",
       "                       85.3331,  85.3150,  73.5294,  92.7901, 220.5452,  99.2099, 196.0856,\n",
       "                      202.2265,  51.3303,  86.5851, 114.2133,  68.9200,  75.2077,  66.1028,\n",
       "                      122.0823, 117.7750, 245.7526,  66.1286, 123.7523,  65.8125,  87.0287,\n",
       "                      104.8593, 113.6976,  81.1487, 157.0695, 153.1468, 102.4417, 109.2315,\n",
       "                       72.9572, 148.5748, 182.4391,  71.6832,  72.7795, 162.9872, 106.4467,\n",
       "                       93.8314, 162.9913, 129.5555, 196.3907, 164.7498, 165.6248, 114.9831,\n",
       "                      168.4438, 115.9995, 101.6505, 129.2027, 130.0742,  97.4615, 142.0679,\n",
       "                      144.2227], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('pos_encoder.pe',\n",
       "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                         0.0000e+00,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 8.4147e-01,  5.4030e-01,  7.8859e-01,  ...,  1.0000e+00,\n",
       "                         1.1007e-04,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 9.0930e-01, -4.1615e-01,  9.6984e-01,  ...,  1.0000e+00,\n",
       "                         2.2014e-04,  1.0000e+00]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 3.7961e-01, -9.2515e-01,  1.6091e-01,  ...,  9.9993e-01,\n",
       "                         1.0677e-02,  9.9994e-01]],\n",
       "              \n",
       "                      [[-5.7338e-01, -8.1929e-01,  8.7726e-01,  ...,  9.9993e-01,\n",
       "                         1.0787e-02,  9.9994e-01]],\n",
       "              \n",
       "                      [[-9.9921e-01,  3.9821e-02,  9.1797e-01,  ...,  9.9993e-01,\n",
       "                         1.0897e-02,  9.9994e-01]]], device='cuda:0'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"/home/hj20/dcase_2020_T6/models/cnn10_best_48.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc0d519d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TransformerModel:\n\tMissing key(s) in state_dict: \"encoder.bn0.weight\", \"encoder.bn0.bias\", \"encoder.bn0.running_mean\", \"encoder.bn0.running_var\", \"encoder.conv_block1.conv1.weight\", \"encoder.conv_block1.conv2.weight\", \"encoder.conv_block1.bn1.weight\", \"encoder.conv_block1.bn1.bias\", \"encoder.conv_block1.bn1.running_mean\", \"encoder.conv_block1.bn1.running_var\", \"encoder.conv_block1.bn2.weight\", \"encoder.conv_block1.bn2.bias\", \"encoder.conv_block1.bn2.running_mean\", \"encoder.conv_block1.bn2.running_var\", \"encoder.conv_block2.conv1.weight\", \"encoder.conv_block2.conv2.weight\", \"encoder.conv_block2.bn1.weight\", \"encoder.conv_block2.bn1.bias\", \"encoder.conv_block2.bn1.running_mean\", \"encoder.conv_block2.bn1.running_var\", \"encoder.conv_block2.bn2.weight\", \"encoder.conv_block2.bn2.bias\", \"encoder.conv_block2.bn2.running_mean\", \"encoder.conv_block2.bn2.running_var\", \"encoder.conv_block3.conv1.weight\", \"encoder.conv_block3.conv2.weight\", \"encoder.conv_block3.bn1.weight\", \"encoder.conv_block3.bn1.bias\", \"encoder.conv_block3.bn1.running_mean\", \"encoder.conv_block3.bn1.running_var\", \"encoder.conv_block3.bn2.weight\", \"encoder.conv_block3.bn2.bias\", \"encoder.conv_block3.bn2.running_mean\", \"encoder.conv_block3.bn2.running_var\", \"encoder.conv_block4.conv1.weight\", \"encoder.conv_block4.conv2.weight\", \"encoder.conv_block4.bn1.weight\", \"encoder.conv_block4.bn1.bias\", \"encoder.conv_block4.bn1.running_mean\", \"encoder.conv_block4.bn1.running_var\", \"encoder.conv_block4.bn2.weight\", \"encoder.conv_block4.bn2.bias\", \"encoder.conv_block4.bn2.running_mean\", \"encoder.conv_block4.bn2.running_var\". \n\tUnexpected key(s) in state_dict: \"encoder.base.bn0.weight\", \"encoder.base.bn0.bias\", \"encoder.base.bn0.running_mean\", \"encoder.base.bn0.running_var\", \"encoder.base.bn0.num_batches_tracked\", \"encoder.base.conv_block1.conv1.weight\", \"encoder.base.conv_block1.conv2.weight\", \"encoder.base.conv_block1.bn1.weight\", \"encoder.base.conv_block1.bn1.bias\", \"encoder.base.conv_block1.bn1.running_mean\", \"encoder.base.conv_block1.bn1.running_var\", \"encoder.base.conv_block1.bn1.num_batches_tracked\", \"encoder.base.conv_block1.bn2.weight\", \"encoder.base.conv_block1.bn2.bias\", \"encoder.base.conv_block1.bn2.running_mean\", \"encoder.base.conv_block1.bn2.running_var\", \"encoder.base.conv_block1.bn2.num_batches_tracked\", \"encoder.base.conv_block2.conv1.weight\", \"encoder.base.conv_block2.conv2.weight\", \"encoder.base.conv_block2.bn1.weight\", \"encoder.base.conv_block2.bn1.bias\", \"encoder.base.conv_block2.bn1.running_mean\", \"encoder.base.conv_block2.bn1.running_var\", \"encoder.base.conv_block2.bn1.num_batches_tracked\", \"encoder.base.conv_block2.bn2.weight\", \"encoder.base.conv_block2.bn2.bias\", \"encoder.base.conv_block2.bn2.running_mean\", \"encoder.base.conv_block2.bn2.running_var\", \"encoder.base.conv_block2.bn2.num_batches_tracked\", \"encoder.base.conv_block3.conv1.weight\", \"encoder.base.conv_block3.conv2.weight\", \"encoder.base.conv_block3.bn1.weight\", \"encoder.base.conv_block3.bn1.bias\", \"encoder.base.conv_block3.bn1.running_mean\", \"encoder.base.conv_block3.bn1.running_var\", \"encoder.base.conv_block3.bn1.num_batches_tracked\", \"encoder.base.conv_block3.bn2.weight\", \"encoder.base.conv_block3.bn2.bias\", \"encoder.base.conv_block3.bn2.running_mean\", \"encoder.base.conv_block3.bn2.running_var\", \"encoder.base.conv_block3.bn2.num_batches_tracked\", \"encoder.base.conv_block4.conv1.weight\", \"encoder.base.conv_block4.conv2.weight\", \"encoder.base.conv_block4.bn1.weight\", \"encoder.base.conv_block4.bn1.bias\", \"encoder.base.conv_block4.bn1.running_mean\", \"encoder.base.conv_block4.bn1.running_var\", \"encoder.base.conv_block4.bn1.num_batches_tracked\", \"encoder.base.conv_block4.bn2.weight\", \"encoder.base.conv_block4.bn2.bias\", \"encoder.base.conv_block4.bn2.running_mean\", \"encoder.base.conv_block4.bn2.running_var\", \"encoder.base.conv_block4.bn2.num_batches_tracked\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-afece93dfcf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/hj20/dcase_2020_T6/models/cnn10_best_48.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1407\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TransformerModel:\n\tMissing key(s) in state_dict: \"encoder.bn0.weight\", \"encoder.bn0.bias\", \"encoder.bn0.running_mean\", \"encoder.bn0.running_var\", \"encoder.conv_block1.conv1.weight\", \"encoder.conv_block1.conv2.weight\", \"encoder.conv_block1.bn1.weight\", \"encoder.conv_block1.bn1.bias\", \"encoder.conv_block1.bn1.running_mean\", \"encoder.conv_block1.bn1.running_var\", \"encoder.conv_block1.bn2.weight\", \"encoder.conv_block1.bn2.bias\", \"encoder.conv_block1.bn2.running_mean\", \"encoder.conv_block1.bn2.running_var\", \"encoder.conv_block2.conv1.weight\", \"encoder.conv_block2.conv2.weight\", \"encoder.conv_block2.bn1.weight\", \"encoder.conv_block2.bn1.bias\", \"encoder.conv_block2.bn1.running_mean\", \"encoder.conv_block2.bn1.running_var\", \"encoder.conv_block2.bn2.weight\", \"encoder.conv_block2.bn2.bias\", \"encoder.conv_block2.bn2.running_mean\", \"encoder.conv_block2.bn2.running_var\", \"encoder.conv_block3.conv1.weight\", \"encoder.conv_block3.conv2.weight\", \"encoder.conv_block3.bn1.weight\", \"encoder.conv_block3.bn1.bias\", \"encoder.conv_block3.bn1.running_mean\", \"encoder.conv_block3.bn1.running_var\", \"encoder.conv_block3.bn2.weight\", \"encoder.conv_block3.bn2.bias\", \"encoder.conv_block3.bn2.running_mean\", \"encoder.conv_block3.bn2.running_var\", \"encoder.conv_block4.conv1.weight\", \"encoder.conv_block4.conv2.weight\", \"encoder.conv_block4.bn1.weight\", \"encoder.conv_block4.bn1.bias\", \"encoder.conv_block4.bn1.running_mean\", \"encoder.conv_block4.bn1.running_var\", \"encoder.conv_block4.bn2.weight\", \"encoder.conv_block4.bn2.bias\", \"encoder.conv_block4.bn2.running_mean\", \"encoder.conv_block4.bn2.running_var\". \n\tUnexpected key(s) in state_dict: \"encoder.base.bn0.weight\", \"encoder.base.bn0.bias\", \"encoder.base.bn0.running_mean\", \"encoder.base.bn0.running_var\", \"encoder.base.bn0.num_batches_tracked\", \"encoder.base.conv_block1.conv1.weight\", \"encoder.base.conv_block1.conv2.weight\", \"encoder.base.conv_block1.bn1.weight\", \"encoder.base.conv_block1.bn1.bias\", \"encoder.base.conv_block1.bn1.running_mean\", \"encoder.base.conv_block1.bn1.running_var\", \"encoder.base.conv_block1.bn1.num_batches_tracked\", \"encoder.base.conv_block1.bn2.weight\", \"encoder.base.conv_block1.bn2.bias\", \"encoder.base.conv_block1.bn2.running_mean\", \"encoder.base.conv_block1.bn2.running_var\", \"encoder.base.conv_block1.bn2.num_batches_tracked\", \"encoder.base.conv_block2.conv1.weight\", \"encoder.base.conv_block2.conv2.weight\", \"encoder.base.conv_block2.bn1.weight\", \"encoder.base.conv_block2.bn1.bias\", \"encoder.base.conv_block2.bn1.running_mean\", \"encoder.base.conv_block2.bn1.running_var\", \"encoder.base.conv_block2.bn1.num_batches_tracked\", \"encoder.base.conv_block2.bn2.weight\", \"encoder.base.conv_block2.bn2.bias\", \"encoder.base.conv_block2.bn2.running_mean\", \"encoder.base.conv_block2.bn2.running_var\", \"encoder.base.conv_block2.bn2.num_batches_tracked\", \"encoder.base.conv_block3.conv1.weight\", \"encoder.base.conv_block3.conv2.weight\", \"encoder.base.conv_block3.bn1.weight\", \"encoder.base.conv_block3.bn1.bias\", \"encoder.base.conv_block3.bn1.running_mean\", \"encoder.base.conv_block3.bn1.running_var\", \"encoder.base.conv_block3.bn1.num_batches_tracked\", \"encoder.base.conv_block3.bn2.weight\", \"encoder.base.conv_block3.bn2.bias\", \"encoder.base.conv_block3.bn2.running_mean\", \"encoder.base.conv_block3.bn2.running_var\", \"encoder.base.conv_block3.bn2.num_batches_tracked\", \"encoder.base.conv_block4.conv1.weight\", \"encoder.base.conv_block4.conv2.weight\", \"encoder.base.conv_block4.bn1.weight\", \"encoder.base.conv_block4.bn1.bias\", \"encoder.base.conv_block4.bn1.running_mean\", \"encoder.base.conv_block4.bn1.running_var\", \"encoder.base.conv_block4.bn1.num_batches_tracked\", \"encoder.base.conv_block4.bn2.weight\", \"encoder.base.conv_block4.bn2.bias\", \"encoder.base.conv_block4.bn2.running_mean\", \"encoder.base.conv_block4.bn2.running_var\", \"encoder.base.conv_block4.bn2.num_batches_tracked\". "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/home/hj20/dcase_2020_T6/models/cnn10_best_48.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d99add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3e6cadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_emb): Embedding(4371, 192)\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=512, out_features=192, bias=True)\n",
       "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
       "  (encoder): Transfer_Cnn10(\n",
       "    (base): Cnn10(\n",
       "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_block1): ConvBlock(\n",
       "        (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block2): ConvBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block3): ConvBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block4): ConvBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (generator): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a269e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best=torch.load(\"/home/hj20/dcase_2020_T6/models/cnn10_best_48.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8804a638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('transformer_decoder.layers.0.self_attn.in_proj_weight',\n",
       "              tensor([[-0.1121,  0.1543, -0.0988,  ..., -0.0251, -0.0537, -0.0022],\n",
       "                      [ 0.0296,  0.0604, -0.1261,  ..., -0.0366, -0.0391, -0.0789],\n",
       "                      [-0.0670,  0.0440, -0.0538,  ..., -0.0826, -0.0667, -0.0441],\n",
       "                      ...,\n",
       "                      [ 0.0519,  0.0259,  0.0380,  ..., -0.0424,  0.0839, -0.0298],\n",
       "                      [-0.1306,  0.0024,  0.0710,  ...,  0.0484, -0.0190, -0.0325],\n",
       "                      [-0.0671, -0.0377,  0.0468,  ..., -0.0534, -0.0323, -0.0415]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.self_attn.in_proj_bias',\n",
       "              tensor([-4.8882e-02,  1.4886e-02, -1.3403e-02, -3.1634e-02,  2.4075e-02,\n",
       "                       6.1872e-02,  3.3191e-02,  4.9238e-03, -2.4707e-02, -2.9865e-02,\n",
       "                      -8.4079e-02,  6.5329e-04,  2.5111e-02, -7.4482e-02, -5.5098e-02,\n",
       "                       3.9614e-02,  3.6864e-02,  5.8129e-03, -8.2433e-03, -4.9785e-02,\n",
       "                       4.7040e-02,  3.5419e-02, -7.7811e-02, -2.3538e-02, -3.2797e-02,\n",
       "                       5.0955e-02,  1.2973e-02,  8.2237e-02, -6.7934e-02, -4.8609e-03,\n",
       "                       5.2928e-03, -1.4551e-02, -4.8945e-02, -2.8405e-03,  1.1080e-01,\n",
       "                      -1.1835e-02, -7.7633e-02, -3.2229e-02, -3.3883e-02,  1.1286e-02,\n",
       "                       9.5591e-02,  7.0906e-02, -5.2854e-02, -8.2858e-02,  1.4638e-02,\n",
       "                       1.1863e-02,  5.4218e-02,  3.7832e-03,  2.1142e-02,  4.5759e-02,\n",
       "                      -1.3421e-03, -5.1448e-02,  2.7143e-02, -1.3486e-02, -1.7756e-02,\n",
       "                      -2.6771e-03,  1.0478e-02, -3.1756e-02,  4.3664e-02,  5.6513e-02,\n",
       "                      -2.2516e-02,  2.3603e-02, -2.7578e-02, -1.8583e-02, -1.6563e-03,\n",
       "                       2.1780e-02, -2.1138e-02,  2.5185e-02, -3.9830e-02,  5.6972e-02,\n",
       "                      -1.8557e-02,  5.4048e-02,  3.6929e-02, -4.3725e-02, -3.5584e-02,\n",
       "                       5.2630e-02,  1.8012e-02,  2.9198e-02, -2.1126e-02, -3.6502e-02,\n",
       "                       1.4218e-02,  2.3038e-02, -4.4794e-02, -1.9552e-02,  6.1013e-02,\n",
       "                      -7.8966e-03,  8.0278e-03, -1.1486e-02, -2.0190e-02, -1.6710e-02,\n",
       "                       2.8131e-02,  3.0692e-02,  3.6090e-02, -4.1345e-02,  4.4258e-02,\n",
       "                       7.3780e-03,  3.4233e-02, -1.8111e-02, -1.3227e-02,  7.3515e-02,\n",
       "                       1.1337e-02,  9.9177e-03, -8.6224e-02,  2.2670e-02,  1.3303e-02,\n",
       "                       5.5076e-02,  6.2373e-02, -3.1701e-02,  7.1008e-02, -2.3537e-02,\n",
       "                       3.1060e-02,  2.6192e-02, -3.2962e-02, -4.7220e-02,  4.7160e-02,\n",
       "                       2.0929e-02,  6.2649e-02,  6.2644e-02,  5.8579e-02,  6.6606e-02,\n",
       "                      -4.8528e-02,  1.0226e-02, -3.0267e-02, -3.7159e-02, -1.1162e-02,\n",
       "                       3.7877e-04,  2.0019e-02, -1.9767e-02, -4.1481e-02, -7.0210e-02,\n",
       "                       2.8430e-02,  6.9786e-02,  2.0005e-02,  9.6821e-04, -8.2378e-03,\n",
       "                       8.2414e-03,  2.7708e-02, -4.9569e-02, -2.1599e-02, -8.0262e-02,\n",
       "                      -1.6523e-02, -4.0349e-02,  4.2360e-04, -9.3588e-02, -3.0103e-02,\n",
       "                       4.3306e-02,  2.5295e-02,  1.0102e-02,  1.3036e-02, -7.6830e-02,\n",
       "                       4.2402e-02, -2.7280e-02, -2.2149e-02, -6.9022e-03,  6.0508e-02,\n",
       "                      -9.8263e-06, -1.4295e-03,  5.8245e-02, -7.0920e-03, -2.0126e-02,\n",
       "                      -2.1960e-02, -3.1308e-03,  1.7412e-02, -1.4055e-02,  5.1541e-02,\n",
       "                      -6.4362e-02,  1.2900e-02,  6.3986e-02, -2.5059e-02, -1.2995e-02,\n",
       "                       5.8593e-02, -3.5203e-02, -5.3229e-02,  5.3457e-02,  3.4618e-02,\n",
       "                       5.5110e-02, -6.3361e-02,  1.6490e-03,  8.1990e-02,  1.7448e-02,\n",
       "                      -5.6289e-02, -1.2129e-02, -9.0056e-02, -5.8310e-02,  1.1758e-03,\n",
       "                       2.8986e-02, -5.3037e-03,  1.7086e-03, -3.7347e-02, -5.2185e-02,\n",
       "                       1.0463e-02, -3.6608e-02,  1.8068e-05,  5.9495e-07,  5.7673e-06,\n",
       "                      -2.7862e-07, -4.4372e-06, -8.0239e-07, -1.1467e-05,  7.6796e-06,\n",
       "                      -1.3956e-06,  5.1741e-06,  2.1183e-06,  7.7048e-06, -9.7893e-06,\n",
       "                      -1.4522e-05,  3.4087e-07,  1.8796e-05, -2.6494e-06,  1.4365e-05,\n",
       "                      -8.7614e-06, -1.1120e-05, -1.8833e-05,  2.8068e-05, -3.8711e-06,\n",
       "                      -8.2170e-06,  1.2640e-07,  6.2034e-06,  2.6308e-05,  4.4106e-06,\n",
       "                       3.0250e-06, -1.1356e-05,  1.1416e-07,  4.0462e-07,  2.8889e-06,\n",
       "                      -6.8269e-07,  3.5595e-06, -3.1678e-06, -6.0499e-06,  1.2191e-05,\n",
       "                       3.8592e-06,  1.4879e-05,  7.7183e-06,  2.5749e-06,  1.5579e-05,\n",
       "                       1.2576e-05,  1.7262e-05, -8.3990e-06,  1.9338e-05, -2.4847e-06,\n",
       "                       1.4755e-05,  1.7367e-05,  3.9021e-06, -2.3688e-05, -4.8710e-06,\n",
       "                      -1.4862e-06, -1.0407e-05,  7.0105e-06,  8.7756e-06, -1.0468e-06,\n",
       "                       1.9916e-05, -6.6776e-07, -1.2132e-05,  2.0989e-06, -2.8841e-05,\n",
       "                      -6.4898e-06,  5.5858e-06,  3.1141e-06, -4.8956e-06, -7.8123e-06,\n",
       "                       1.3019e-06,  1.0751e-05, -1.9872e-05,  1.4185e-05,  1.9184e-05,\n",
       "                      -2.1530e-05,  1.4479e-05,  2.1295e-05, -1.0091e-05, -1.2123e-05,\n",
       "                      -4.9186e-06,  2.5457e-06, -5.5626e-06,  2.2077e-07, -1.5818e-05,\n",
       "                      -9.4985e-06,  1.2390e-05, -6.5742e-06, -4.6334e-06, -2.0278e-06,\n",
       "                      -3.0525e-06, -4.4899e-06, -6.5110e-06,  1.5640e-05,  9.6016e-06,\n",
       "                      -3.8675e-06,  9.9518e-06,  9.3398e-06,  7.4123e-06, -1.1731e-05,\n",
       "                      -8.2104e-06, -9.5115e-06, -3.3973e-06, -4.0556e-06, -1.0658e-05,\n",
       "                      -1.4509e-05,  2.2110e-05,  8.0925e-07,  1.4756e-05,  9.0053e-06,\n",
       "                      -3.4359e-06, -4.4677e-06, -1.7822e-06, -1.3005e-05, -1.3517e-05,\n",
       "                       1.6259e-05, -4.7014e-06, -8.7356e-06, -6.7677e-07,  1.5488e-05,\n",
       "                      -5.6666e-06, -4.0197e-06,  8.7348e-06, -6.6217e-06,  2.0163e-06,\n",
       "                       3.4504e-06, -7.3133e-06, -8.6196e-06,  6.1361e-06,  1.1035e-05,\n",
       "                       1.3948e-05,  9.1823e-06,  1.0121e-05,  4.3631e-06, -1.1018e-05,\n",
       "                      -8.7860e-06,  1.1358e-05,  1.4105e-05,  1.6605e-05, -1.7249e-05,\n",
       "                      -1.9136e-07,  5.9873e-06,  8.4071e-06, -8.9901e-06, -5.5589e-06,\n",
       "                       4.9634e-06, -7.8524e-06, -5.3248e-06,  1.9807e-05, -1.6503e-05,\n",
       "                       9.4166e-06,  6.9066e-06, -8.5433e-06,  2.9994e-06, -2.8097e-06,\n",
       "                      -2.7189e-05,  6.4151e-06, -1.2244e-05,  5.6847e-06, -5.6364e-06,\n",
       "                      -1.6330e-06, -1.2545e-06,  1.0316e-05,  1.4496e-05,  1.2129e-05,\n",
       "                       1.1116e-05,  4.1328e-06, -1.1332e-05,  3.8587e-06, -1.0591e-05,\n",
       "                      -1.4575e-06, -2.7460e-06,  9.7502e-09,  4.0198e-06,  2.8573e-06,\n",
       "                      -1.0807e-05, -1.0168e-05,  6.9058e-06,  8.4973e-06,  1.2796e-05,\n",
       "                      -6.8630e-06, -3.0286e-06,  1.3395e-05,  5.7577e-06, -6.8268e-07,\n",
       "                       5.6857e-06, -1.6506e-05, -1.4703e-06,  4.1138e-06, -8.2722e-06,\n",
       "                       8.3598e-06, -3.7493e-06,  7.0791e-06, -9.0113e-07,  1.6303e-03,\n",
       "                      -9.6012e-03, -5.4251e-04, -7.9567e-03,  2.0648e-02,  1.8485e-02,\n",
       "                      -2.5845e-04, -1.6929e-02, -1.5671e-02, -1.0191e-02,  6.3123e-03,\n",
       "                      -1.3405e-03,  3.1166e-02, -1.8430e-02, -3.2544e-03, -4.0480e-03,\n",
       "                       4.0280e-04,  3.3984e-04,  1.6234e-02, -2.1567e-03, -1.4890e-02,\n",
       "                      -7.9630e-03,  1.6148e-03, -1.0456e-02, -1.6454e-02, -1.2794e-02,\n",
       "                       7.7591e-03,  1.2401e-02, -7.8674e-03,  4.8117e-03, -2.7521e-02,\n",
       "                       5.3664e-03,  6.1583e-03,  1.0492e-02, -3.7021e-03, -1.1865e-02,\n",
       "                       1.2562e-02,  1.3275e-02,  1.1872e-02,  5.1559e-03, -1.3351e-02,\n",
       "                      -5.9799e-03, -1.3111e-02,  9.7624e-04, -2.5651e-02, -4.5339e-04,\n",
       "                       5.2899e-03, -1.0601e-02, -3.6222e-03, -1.1123e-02, -1.9616e-02,\n",
       "                      -4.8156e-03,  6.0370e-03,  8.0743e-03, -6.2176e-03,  4.4354e-05,\n",
       "                       6.1760e-03,  2.0883e-02, -1.8602e-02, -1.0920e-02, -1.0792e-02,\n",
       "                       6.0563e-03, -1.0085e-02,  9.5700e-03,  9.4747e-03,  1.1323e-02,\n",
       "                      -1.1852e-02,  3.3083e-03,  5.6840e-03, -1.0192e-02,  2.0097e-02,\n",
       "                      -1.3658e-02, -2.3602e-02, -9.2293e-03, -1.5105e-03, -1.1637e-03,\n",
       "                       5.3992e-03, -9.3063e-03,  2.1969e-03, -9.6324e-03,  8.6117e-03,\n",
       "                      -1.1540e-02,  5.4705e-03,  4.4957e-03, -1.6253e-02, -3.9632e-03,\n",
       "                       2.3247e-04, -2.7323e-03, -8.9022e-03,  9.7149e-03, -4.3621e-03,\n",
       "                      -8.9750e-03,  1.9970e-02,  1.7519e-04, -6.3800e-03,  5.2539e-03,\n",
       "                       4.1380e-03, -1.6113e-02, -2.4926e-02, -1.8221e-02,  3.0167e-03,\n",
       "                      -1.4001e-03, -5.5736e-03, -2.0499e-04, -4.2547e-03, -1.6165e-02,\n",
       "                       4.1057e-03,  3.8345e-03, -6.1370e-03, -1.2611e-02, -3.7280e-04,\n",
       "                      -1.2744e-03, -3.8480e-03,  1.6761e-02, -5.9505e-03,  3.1695e-03,\n",
       "                       1.7846e-02, -5.1126e-03, -1.4647e-02,  2.6612e-03, -4.3751e-03,\n",
       "                       8.5199e-03,  1.3615e-02, -3.1236e-03, -1.5956e-03,  3.4538e-02,\n",
       "                       1.0163e-02,  9.5487e-03, -9.4259e-03,  3.0504e-03, -9.4489e-03,\n",
       "                      -1.9994e-02, -4.1760e-03,  1.6245e-02,  5.4962e-03,  1.3091e-02,\n",
       "                       2.1879e-02, -3.4830e-02,  6.2942e-03, -1.6166e-02, -1.9049e-02,\n",
       "                      -8.9314e-03,  8.2999e-03,  3.4078e-03,  3.1725e-03, -4.0692e-03,\n",
       "                       6.8395e-03, -7.1589e-03, -3.0603e-03,  1.1652e-02,  1.1986e-02,\n",
       "                       1.2687e-02,  2.9401e-03,  1.8258e-02,  2.0876e-02,  1.5723e-02,\n",
       "                      -6.3720e-03, -1.2507e-02, -3.5083e-04,  1.3760e-04,  2.1818e-02,\n",
       "                       3.8723e-03, -1.0731e-02,  1.2925e-02,  6.9276e-03,  7.0941e-03,\n",
       "                       1.6803e-02,  8.9527e-03,  2.8582e-03,  1.6302e-03,  1.8747e-02,\n",
       "                      -2.5962e-02,  1.1765e-02,  2.2601e-02, -2.0326e-04,  4.0143e-03,\n",
       "                      -1.9114e-02, -2.4557e-02,  2.4854e-02, -2.4203e-02,  8.3314e-03,\n",
       "                       1.6553e-02,  9.2608e-04, -8.0551e-03,  1.6081e-02, -6.5435e-03,\n",
       "                      -1.4003e-03,  5.9490e-03, -3.6475e-03, -6.4959e-04, -2.2006e-02,\n",
       "                       1.8325e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.self_attn.out_proj.weight',\n",
       "              tensor([[ 0.0071, -0.0170,  0.0544,  ...,  0.0417, -0.0457,  0.0115],\n",
       "                      [ 0.0116, -0.0627,  0.0536,  ..., -0.0290,  0.0505, -0.0429],\n",
       "                      [ 0.0030, -0.0363,  0.0468,  ...,  0.0435,  0.0419,  0.0496],\n",
       "                      ...,\n",
       "                      [-0.0251, -0.0649,  0.0008,  ...,  0.0273, -0.0087, -0.0659],\n",
       "                      [-0.0135,  0.0043, -0.0222,  ...,  0.0163, -0.0711,  0.0409],\n",
       "                      [ 0.0986, -0.0893, -0.0425,  ..., -0.0275, -0.0433,  0.0447]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.self_attn.out_proj.bias',\n",
       "              tensor([ 4.5005e-02, -5.7770e-02,  2.2619e-02, -4.7946e-02,  1.2709e-02,\n",
       "                       4.0395e-03,  5.0262e-03,  1.8686e-02,  6.1701e-02,  1.5990e-02,\n",
       "                      -1.6832e-02,  1.3102e-02,  3.2107e-03,  8.3510e-03, -1.6098e-02,\n",
       "                      -5.0668e-03, -3.2309e-02,  1.7314e-02, -1.1023e-02,  5.4407e-02,\n",
       "                      -8.1607e-03, -2.3525e-02, -4.5785e-02, -1.1861e-02, -3.2681e-02,\n",
       "                       1.9470e-02, -3.5496e-02,  3.7925e-03,  3.4880e-02, -3.2732e-02,\n",
       "                      -3.4458e-02, -3.0290e-02, -5.9235e-03, -1.0048e-02, -4.7402e-02,\n",
       "                      -1.7985e-02, -1.9088e-02, -1.5136e-02, -8.5931e-03,  2.7678e-02,\n",
       "                      -3.9901e-02, -5.3573e-03, -1.4800e-02, -1.8086e-02, -1.7363e-02,\n",
       "                      -1.7534e-02,  2.3187e-02, -4.8089e-03,  2.2995e-02, -3.2562e-02,\n",
       "                       2.6960e-02, -9.6114e-03, -2.0635e-02,  1.2320e-02, -1.9474e-03,\n",
       "                       2.8542e-02,  6.2370e-03, -2.5571e-03, -4.9565e-03, -1.7610e-02,\n",
       "                      -1.1158e-02,  2.6874e-02, -4.2357e-02,  9.5133e-03, -8.9433e-02,\n",
       "                      -3.2635e-02,  8.6950e-03, -1.3292e-02,  1.1847e-02,  3.7086e-03,\n",
       "                       3.1326e-02,  2.4883e-02,  1.1376e-03, -1.1957e-02, -6.7654e-03,\n",
       "                       1.4580e-03, -1.1571e-03, -8.3807e-03,  1.4737e-02,  2.9075e-03,\n",
       "                       2.2689e-02,  1.8249e-02, -1.9737e-02,  4.0774e-02, -3.3194e-03,\n",
       "                      -3.7961e-03, -1.9316e-02,  8.0790e-02, -3.0340e-02, -4.2859e-03,\n",
       "                       4.0717e-02,  2.8951e-02, -1.7661e-02,  3.8694e-02,  3.1667e-02,\n",
       "                       3.5434e-02,  4.6041e-03,  7.7567e-04,  6.1045e-03, -3.5738e-02,\n",
       "                      -6.2822e-03, -1.1982e-02,  1.1408e-02,  4.7743e-03, -1.3419e-02,\n",
       "                       1.7808e-02, -7.2443e-03,  2.5336e-02, -1.9320e-02,  1.8701e-02,\n",
       "                       2.4112e-02, -1.0928e-02, -1.5588e-02, -3.1790e-02, -4.0040e-02,\n",
       "                       9.0055e-03,  1.4874e-02,  3.3433e-02, -8.2995e-03,  4.8370e-03,\n",
       "                       2.1514e-02, -1.2159e-03,  3.6464e-02,  2.1912e-02,  7.6836e-03,\n",
       "                       5.5695e-02,  8.7656e-03,  1.7148e-02, -2.9240e-02,  3.0324e-02,\n",
       "                       1.0201e-02,  4.1016e-02, -1.1358e-02,  3.1722e-03,  3.3864e-03,\n",
       "                       1.0282e-02, -9.5728e-03,  2.3971e-02,  1.2634e-02, -3.6492e-02,\n",
       "                       5.9735e-03,  3.5276e-02, -1.4573e-02, -3.4076e-03, -1.4085e-02,\n",
       "                      -1.4274e-02,  1.5589e-02, -8.6285e-04,  2.8017e-02, -2.8156e-03,\n",
       "                      -6.9918e-03,  3.4997e-02, -6.6776e-03, -2.0914e-02, -1.9886e-02,\n",
       "                      -1.6349e-03,  1.2484e-02,  1.2373e-02, -9.2129e-03,  2.1557e-02,\n",
       "                      -1.4658e-03, -3.2431e-02,  2.1798e-02,  5.5920e-02,  1.0223e-02,\n",
       "                      -1.2436e-03, -1.9993e-02,  3.5559e-02,  1.0937e-03,  1.6642e-02,\n",
       "                       2.2836e-02, -2.3831e-02,  1.2063e-02,  1.3795e-02,  1.5220e-02,\n",
       "                      -2.7483e-03,  1.0863e-02,  3.8898e-02, -2.4596e-02,  6.0935e-03,\n",
       "                      -2.9736e-02, -1.3506e-03,  2.2078e-02, -4.0607e-02,  1.0178e-02,\n",
       "                       1.5563e-02,  3.4041e-02, -3.2595e-02, -2.3743e-02,  3.5603e-02,\n",
       "                       4.0861e-05,  1.2753e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.in_proj_weight',\n",
       "              tensor([[-0.0510,  0.0235,  0.0390,  ...,  0.0022, -0.0389,  0.0308],\n",
       "                      [-0.0576,  0.1312,  0.0614,  ..., -0.0323, -0.0187,  0.0050],\n",
       "                      [ 0.0004,  0.0592, -0.0743,  ..., -0.0778, -0.0405,  0.0197],\n",
       "                      ...,\n",
       "                      [ 0.0793, -0.0213, -0.0250,  ..., -0.0374,  0.0299, -0.0058],\n",
       "                      [ 0.0236,  0.0140, -0.1080,  ..., -0.0605,  0.1349, -0.0244],\n",
       "                      [ 0.0547, -0.0423, -0.0525,  ...,  0.0670, -0.0364,  0.1099]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.in_proj_bias',\n",
       "              tensor([ 1.5719e-02, -6.5023e-02, -7.4259e-02, -3.2016e-02, -1.2725e-02,\n",
       "                      -1.6205e-02,  2.7985e-02,  4.2385e-02,  8.4327e-02, -4.9016e-02,\n",
       "                      -6.6608e-03, -1.7063e-03,  1.2185e-01,  1.1178e-01,  2.0014e-02,\n",
       "                       4.9659e-02,  1.0708e-01,  1.8618e-01,  1.7622e-01,  5.4289e-02,\n",
       "                       8.4650e-02,  1.2694e-03, -6.8204e-03, -1.7957e-01,  4.0825e-02,\n",
       "                      -5.8345e-02,  2.0193e-02, -1.4281e-01,  9.9162e-02,  1.6082e-02,\n",
       "                       3.8716e-03,  9.5413e-02,  2.1360e-02,  8.1995e-02, -3.2427e-03,\n",
       "                      -6.2873e-02,  5.1095e-02, -4.6009e-02,  4.1415e-02,  1.3450e-01,\n",
       "                       5.7405e-02, -1.6322e-01,  1.6365e-01, -1.0268e-01, -1.6924e-01,\n",
       "                       4.0478e-04,  1.1233e-01,  5.2837e-02, -4.8728e-02, -9.0370e-02,\n",
       "                       1.9675e-01,  1.4328e-01, -1.2257e-01,  1.1671e-01, -2.0108e-01,\n",
       "                      -5.3182e-02, -8.8471e-02,  9.9866e-02, -1.1494e-01,  1.8033e-01,\n",
       "                      -2.4498e-02,  1.4649e-01,  1.2888e-01, -1.3570e-01, -5.3837e-02,\n",
       "                       1.4408e-01,  1.2218e-01, -1.6364e-01,  1.6133e-01,  8.3091e-02,\n",
       "                      -1.6595e-01, -1.8332e-01,  1.5886e-02,  1.6835e-01, -9.5366e-02,\n",
       "                       2.0251e-01, -3.4824e-02,  1.7640e-01,  1.4353e-01,  1.4627e-01,\n",
       "                       8.7901e-02,  1.5454e-01, -5.5306e-02,  8.3272e-02, -1.8956e-01,\n",
       "                      -5.8504e-02,  6.4809e-02, -1.0490e-01,  1.4487e-01, -1.4120e-01,\n",
       "                       1.9036e-01, -1.5010e-01, -1.6259e-01, -1.1575e-02,  5.8022e-02,\n",
       "                       1.0943e-01,  1.2804e-01,  9.0255e-02,  6.8738e-02, -4.1632e-02,\n",
       "                       7.5363e-02,  5.9557e-02,  5.6483e-03,  8.4279e-02, -6.2927e-02,\n",
       "                      -9.7351e-02,  2.4894e-02, -3.0917e-02,  6.0600e-02, -1.3552e-01,\n",
       "                       2.6484e-02,  7.5328e-02,  3.3857e-02,  1.6079e-02,  6.9198e-02,\n",
       "                      -5.9800e-02,  1.2569e-01, -3.3195e-03,  7.0211e-02, -2.0361e-02,\n",
       "                      -2.3659e-02, -6.8085e-02, -8.2717e-03, -9.2561e-02,  6.4189e-02,\n",
       "                       5.4724e-02, -2.5061e-02, -6.9251e-02, -1.1177e-03, -1.5826e-02,\n",
       "                      -1.5914e-02, -1.4413e-02,  1.2587e-01,  1.4106e-01, -3.5848e-02,\n",
       "                       3.1298e-04,  4.9775e-02, -1.9188e-02,  5.2998e-03,  5.6199e-02,\n",
       "                      -3.0183e-02, -4.1522e-02,  5.5708e-02,  9.6429e-02,  1.0489e-01,\n",
       "                       1.8989e-01,  2.3053e-01,  5.4516e-03, -1.4345e-02,  6.4166e-02,\n",
       "                       8.1795e-02,  3.2163e-02, -1.9433e-01, -1.7814e-01,  1.5610e-01,\n",
       "                       4.6796e-02,  1.6577e-01, -1.7953e-01,  1.9409e-01, -3.2803e-02,\n",
       "                      -9.1183e-03, -1.3341e-01, -8.4511e-02,  1.3134e-01, -1.7424e-01,\n",
       "                      -7.4281e-02, -2.2600e-01,  1.0690e-01,  1.5900e-01,  1.0985e-01,\n",
       "                      -1.8252e-01,  6.8460e-02,  9.5344e-02, -7.9874e-02, -5.5933e-02,\n",
       "                      -1.1369e-02, -6.6311e-02, -1.5390e-01, -1.0869e-01,  2.5441e-02,\n",
       "                      -2.2509e-01,  1.0533e-01,  2.0403e-02, -1.1195e-01, -2.2535e-01,\n",
       "                       2.9697e-03,  3.1386e-02, -2.9968e-03,  3.7162e-02,  5.4720e-02,\n",
       "                      -1.1231e-01,  1.4205e-01, -6.5057e-06, -7.0764e-06,  3.7421e-06,\n",
       "                      -2.0166e-06, -1.2356e-05, -2.5593e-06, -3.1904e-06,  4.6997e-06,\n",
       "                      -7.7547e-06, -1.9689e-06, -1.0125e-05, -1.1658e-05, -1.0043e-05,\n",
       "                       1.4630e-05, -4.9768e-06,  7.2710e-07, -4.1527e-07, -5.7933e-06,\n",
       "                      -8.6928e-06,  7.2949e-06, -1.4098e-05, -7.5106e-06,  9.2135e-06,\n",
       "                       5.1398e-06, -1.5048e-06, -6.7764e-06,  7.6130e-07,  5.3331e-06,\n",
       "                      -1.3136e-06, -7.1179e-06, -7.4296e-06, -7.5033e-06, -5.0354e-06,\n",
       "                       2.3946e-06, -7.1851e-06, -3.7053e-06,  2.8297e-06, -2.2827e-06,\n",
       "                      -5.3683e-06,  3.3629e-06, -1.3121e-06, -7.6834e-06,  4.8597e-07,\n",
       "                      -5.3724e-06,  5.7536e-06, -7.2392e-06, -1.0158e-05, -5.1635e-07,\n",
       "                      -1.5685e-06,  8.0575e-06, -8.6190e-06, -4.0266e-06,  2.1771e-06,\n",
       "                       6.1807e-06, -1.0185e-05,  1.4256e-06, -6.6482e-06, -9.3988e-07,\n",
       "                       1.0484e-05,  6.2684e-06, -2.4461e-06,  1.2868e-06,  3.3807e-06,\n",
       "                      -9.6079e-06, -1.0451e-06,  5.6985e-06,  3.8938e-06,  1.5543e-06,\n",
       "                      -6.1950e-06,  4.7622e-06,  4.9368e-06,  5.3637e-06, -1.9757e-06,\n",
       "                       7.1534e-06,  9.4358e-06, -1.5044e-06, -7.6798e-06,  3.1864e-06,\n",
       "                      -3.3255e-06,  8.5677e-06,  1.8699e-06,  9.3920e-06,  4.2862e-06,\n",
       "                       3.6217e-06,  2.0951e-05,  5.9336e-06, -4.4011e-06, -1.2528e-05,\n",
       "                       1.5726e-05,  4.2865e-06, -8.0846e-06,  1.6137e-06, -5.2794e-06,\n",
       "                       3.8477e-06, -3.0863e-06,  1.4422e-06, -1.8195e-06, -2.7978e-06,\n",
       "                      -3.4908e-06,  3.9427e-06,  1.0204e-05, -4.6609e-07, -1.4795e-06,\n",
       "                       3.4507e-06, -1.5536e-06, -1.5025e-06, -3.8499e-06,  5.5031e-07,\n",
       "                      -2.5372e-06, -6.6340e-06, -6.9294e-06, -1.9167e-07, -1.9270e-06,\n",
       "                      -1.1534e-06,  2.3052e-06,  5.4208e-06,  8.7959e-07,  6.5298e-07,\n",
       "                       7.5313e-08,  2.5505e-06,  2.3096e-06,  8.8688e-06,  4.4825e-06,\n",
       "                       1.7142e-06, -5.5938e-06,  8.1063e-07, -1.6574e-07,  4.8960e-06,\n",
       "                       5.1882e-06, -7.9997e-06, -5.0402e-06, -8.2934e-06,  6.3917e-06,\n",
       "                       4.9754e-06,  6.7534e-06,  5.0178e-06, -1.7724e-06,  7.4930e-07,\n",
       "                      -6.2737e-06, -1.3607e-06,  6.1511e-07,  3.1505e-07,  5.0712e-07,\n",
       "                      -8.6979e-07,  3.1747e-07,  8.9290e-06, -3.5459e-07, -1.0801e-05,\n",
       "                      -1.1407e-05,  9.3820e-06, -5.8160e-07, -3.8076e-06, -9.3735e-06,\n",
       "                       4.5460e-06,  8.2010e-06,  2.8333e-06,  1.5056e-08, -1.2404e-05,\n",
       "                      -3.8821e-06, -3.2701e-07, -1.8181e-06, -6.9650e-06, -6.7588e-06,\n",
       "                      -1.7403e-06,  2.1445e-06,  3.8730e-06, -1.3280e-06,  3.7354e-06,\n",
       "                       1.1475e-05,  5.1851e-06, -2.6614e-06, -2.1292e-07,  5.7815e-07,\n",
       "                      -7.2227e-06,  4.9871e-06, -9.2567e-07, -4.4973e-06, -2.3517e-06,\n",
       "                      -1.2250e-06,  5.6164e-06,  5.9067e-06,  5.9379e-06,  4.6954e-06,\n",
       "                       6.9731e-07, -4.3795e-07, -2.2880e-06,  7.7874e-06, -5.1595e-06,\n",
       "                      -1.7105e-06, -5.5070e-06,  5.7244e-06,  5.4474e-06,  3.0089e-02,\n",
       "                       1.1338e-02,  3.9437e-02,  1.7516e-02,  1.7094e-03, -1.8524e-02,\n",
       "                       2.3037e-02, -4.1646e-02, -2.9902e-02,  1.4140e-02, -1.8229e-02,\n",
       "                       2.9954e-02, -6.1651e-03, -1.0826e-02,  3.9289e-02, -1.8914e-02,\n",
       "                      -4.3496e-02, -2.1388e-02,  2.5527e-02, -1.4475e-03, -3.5708e-02,\n",
       "                      -1.0787e-02,  2.8714e-02, -3.8172e-02, -1.9748e-02, -5.1771e-02,\n",
       "                       4.1120e-02, -5.5818e-02,  4.0496e-02,  5.4719e-02,  1.7898e-02,\n",
       "                      -1.6385e-02,  3.8480e-02, -6.0435e-02, -4.2043e-02,  1.4359e-02,\n",
       "                       3.5543e-02, -9.7380e-03, -6.5012e-03, -8.0451e-03, -4.4921e-03,\n",
       "                       1.0385e-02, -3.3786e-03,  7.0143e-02, -1.2088e-02,  9.3490e-03,\n",
       "                       6.8397e-03, -3.3300e-02,  4.8289e-02, -1.2607e-02,  4.5281e-02,\n",
       "                       4.0373e-02, -4.3526e-02, -8.5757e-03,  1.6170e-02, -4.7732e-02,\n",
       "                       5.9965e-03, -2.2384e-02,  2.7536e-02,  3.4251e-02, -4.3974e-02,\n",
       "                      -2.2144e-02,  5.8228e-03,  1.9570e-02, -4.9301e-02,  2.2661e-02,\n",
       "                       2.4072e-02, -3.3470e-02,  2.3383e-02, -2.6210e-02,  4.9462e-03,\n",
       "                       1.4282e-02, -1.5927e-02, -2.7038e-02,  1.0392e-02, -1.4839e-02,\n",
       "                      -1.1217e-02, -1.5057e-02,  2.9870e-02,  4.1216e-02, -3.2408e-02,\n",
       "                      -1.4546e-02, -5.5052e-02, -2.4855e-02,  4.1109e-02,  2.6727e-02,\n",
       "                       3.1205e-02, -2.5827e-02,  6.7742e-03, -1.2371e-02,  4.5097e-02,\n",
       "                       1.4142e-02,  2.5086e-02,  3.9702e-03, -2.9593e-02, -1.8877e-02,\n",
       "                       2.9677e-02,  2.1262e-02,  1.2180e-02,  4.0362e-02,  5.3087e-02,\n",
       "                       1.4109e-02, -2.5317e-02,  5.1055e-02, -2.2661e-02, -4.1945e-02,\n",
       "                      -5.4231e-02, -1.4030e-02, -1.9288e-02, -6.7270e-03,  4.3133e-03,\n",
       "                      -5.0349e-02,  5.0856e-02,  3.8530e-02,  2.0852e-02,  4.9339e-02,\n",
       "                      -1.9208e-02,  3.5886e-02,  1.1789e-02, -2.3316e-02,  2.9358e-02,\n",
       "                      -3.0367e-02,  2.1460e-02, -2.9498e-02, -1.1441e-02,  3.7770e-02,\n",
       "                       4.0026e-02, -3.9712e-02, -1.1151e-02, -4.9935e-02, -2.9651e-02,\n",
       "                      -1.1969e-02, -1.0445e-02,  1.9312e-02,  5.9869e-02,  4.3904e-02,\n",
       "                      -1.9319e-02, -4.9591e-02,  1.4821e-02, -2.2988e-02, -2.5593e-03,\n",
       "                       2.1945e-02,  1.1452e-02,  2.5535e-02,  2.5589e-03, -4.1116e-02,\n",
       "                      -4.6135e-03,  2.0691e-02, -6.2429e-03,  8.9878e-03,  5.2409e-03,\n",
       "                      -3.8400e-02, -7.2674e-03,  5.8039e-04,  1.3122e-02, -3.9467e-02,\n",
       "                      -2.0036e-02,  3.9264e-02, -2.0630e-02, -1.7365e-02, -2.7057e-03,\n",
       "                       9.6599e-03, -2.2532e-03,  1.6172e-02, -2.0917e-02,  2.0165e-02,\n",
       "                      -3.7379e-02,  1.0594e-02, -5.3276e-03,  1.7460e-02,  1.4661e-02,\n",
       "                      -1.3612e-03, -1.3143e-02, -3.8006e-03,  4.4998e-02,  2.1867e-02,\n",
       "                       3.3483e-02, -3.4989e-03,  1.8276e-02,  9.6856e-03,  1.0981e-02,\n",
       "                      -2.9643e-02,  4.7454e-03, -4.4657e-02,  2.6200e-02, -2.2193e-02,\n",
       "                      -1.6045e-02, -1.1433e-02, -1.4035e-02,  1.4923e-02, -3.3914e-03,\n",
       "                      -8.7830e-03], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.out_proj.weight',\n",
       "              tensor([[-0.0264, -0.0084,  0.0109,  ..., -0.0427,  0.1266,  0.0344],\n",
       "                      [-0.0119,  0.0977, -0.0310,  ..., -0.0671, -0.0113,  0.0943],\n",
       "                      [-0.0424, -0.1197,  0.0708,  ...,  0.0140,  0.0529,  0.0096],\n",
       "                      ...,\n",
       "                      [-0.0667,  0.0559, -0.0101,  ..., -0.0844, -0.0235,  0.0197],\n",
       "                      [ 0.0158,  0.0050,  0.0737,  ..., -0.0350, -0.0613, -0.0410],\n",
       "                      [ 0.0093,  0.0534, -0.0330,  ..., -0.0644, -0.0587, -0.0672]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.multihead_attn.out_proj.bias',\n",
       "              tensor([ 2.0904e-02, -3.6296e-02, -7.8835e-03, -5.1018e-03, -2.2020e-02,\n",
       "                       1.8243e-02,  2.0913e-03, -3.3842e-02,  2.6335e-02,  9.0636e-03,\n",
       "                      -1.5588e-03,  3.0777e-03, -5.7296e-03, -1.8244e-02,  1.6449e-02,\n",
       "                      -3.7050e-03, -2.6354e-03, -3.5835e-03,  9.1720e-03,  2.6901e-02,\n",
       "                      -2.1391e-02,  1.7155e-03,  8.0978e-03,  5.0808e-03, -8.1524e-03,\n",
       "                      -5.3720e-03, -9.1375e-04,  2.8753e-02,  2.8714e-02,  7.4894e-03,\n",
       "                      -2.3505e-02,  2.6058e-03, -2.7097e-02, -1.7899e-02, -4.0675e-02,\n",
       "                      -1.7815e-02, -9.6137e-04,  9.1175e-03, -1.8800e-03,  1.7129e-02,\n",
       "                      -1.7099e-02, -4.9817e-03, -2.2179e-02, -2.5716e-03, -4.6505e-02,\n",
       "                      -1.4379e-03, -1.8797e-02,  7.4819e-03, -1.9169e-02,  3.2904e-03,\n",
       "                      -7.3656e-03,  3.7000e-03,  2.4859e-03, -6.6691e-05, -5.6468e-03,\n",
       "                       4.1991e-02, -3.5084e-02,  1.1769e-03,  2.1795e-02,  2.1057e-02,\n",
       "                       2.5820e-02,  1.8087e-02,  1.5780e-02,  3.4255e-02, -4.2019e-02,\n",
       "                      -2.0092e-03, -3.3550e-02, -7.3025e-05, -1.6785e-02, -3.0603e-04,\n",
       "                       8.4711e-03,  3.7302e-02, -1.1655e-02, -1.6676e-02, -1.0991e-02,\n",
       "                       2.4692e-02,  1.2275e-03,  5.0395e-03, -8.7636e-03,  1.6138e-02,\n",
       "                       1.4094e-02,  5.4869e-03, -2.3130e-02,  3.3993e-02, -4.6707e-03,\n",
       "                       3.9233e-02, -1.9759e-02,  8.0727e-02, -2.6531e-02, -2.6402e-02,\n",
       "                      -4.5838e-03,  1.3373e-02, -2.8444e-03,  1.9404e-02,  1.1335e-02,\n",
       "                       3.7114e-02,  3.7549e-03,  1.2272e-02,  5.1075e-03,  6.8545e-03,\n",
       "                      -6.1033e-03,  2.2125e-03, -9.9100e-03,  1.5353e-02, -4.2213e-02,\n",
       "                       2.4608e-02,  2.4468e-02,  2.6330e-02, -2.0711e-02,  2.1468e-02,\n",
       "                       2.0510e-02, -7.7880e-03,  1.6115e-02, -1.7265e-03, -3.0733e-02,\n",
       "                       2.7025e-02,  4.3766e-03,  2.2566e-02, -4.3188e-03, -6.6172e-03,\n",
       "                       5.5764e-03, -2.6051e-03,  1.9897e-02,  3.6237e-02, -1.8636e-02,\n",
       "                       2.6804e-02, -4.2881e-03,  1.0497e-02,  9.7343e-03,  4.3110e-02,\n",
       "                      -2.0788e-04,  2.7730e-02,  3.3249e-04,  4.4489e-03,  3.2401e-03,\n",
       "                       1.5728e-02, -1.3369e-02, -5.4831e-03, -4.5281e-03, -1.8961e-03,\n",
       "                      -2.5931e-02,  3.2226e-02, -2.3925e-02,  8.3698e-03, -2.1098e-02,\n",
       "                      -9.1900e-04,  4.9404e-03,  1.7156e-02,  1.2565e-02, -2.6390e-02,\n",
       "                      -2.3665e-02,  3.1074e-02, -1.7944e-02, -1.3680e-02, -4.7381e-02,\n",
       "                      -9.9717e-03,  1.9179e-02,  2.7189e-02, -2.1728e-03,  1.9534e-02,\n",
       "                      -3.2275e-02, -3.0420e-02, -4.7778e-03,  2.3953e-02, -1.6428e-02,\n",
       "                       2.1846e-02,  1.9485e-02,  3.5273e-02,  4.5470e-04,  1.6808e-02,\n",
       "                      -2.8650e-02,  8.0416e-03, -2.3454e-02,  4.0284e-02,  9.8438e-03,\n",
       "                      -2.9774e-02, -1.6604e-02,  4.0165e-02, -8.4055e-03, -4.4613e-03,\n",
       "                       8.2839e-03, -3.1439e-02,  5.1451e-03, -5.2206e-03,  5.6546e-03,\n",
       "                      -2.2619e-03, -1.6286e-02, -1.0356e-02, -3.1248e-02,  1.7470e-02,\n",
       "                      -2.0780e-02, -5.5476e-03], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear1.weight',\n",
       "              tensor([[ 0.0504,  0.0055, -0.0186,  ...,  0.0315, -0.0197,  0.0049],\n",
       "                      [-0.0415, -0.0060, -0.0021,  ...,  0.0308, -0.0030,  0.0122],\n",
       "                      [ 0.0020,  0.0323,  0.0387,  ..., -0.0270, -0.0628, -0.0952],\n",
       "                      ...,\n",
       "                      [-0.0364, -0.0565, -0.0524,  ...,  0.0619, -0.0237, -0.0261],\n",
       "                      [-0.0203,  0.0205,  0.0206,  ...,  0.0488,  0.0131, -0.0311],\n",
       "                      [-0.0199, -0.0565,  0.0026,  ...,  0.0409, -0.0237,  0.0592]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear1.bias',\n",
       "              tensor([-0.0242, -0.0738, -0.0703,  ..., -0.0637, -0.0254, -0.1045],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear2.weight',\n",
       "              tensor([[ 0.0407, -0.0163, -0.0402,  ...,  0.0033, -0.0159, -0.0044],\n",
       "                      [ 0.0535, -0.0424,  0.0337,  ..., -0.0392,  0.0355,  0.0015],\n",
       "                      [ 0.0340, -0.0130,  0.0208,  ..., -0.0171,  0.0216, -0.0292],\n",
       "                      ...,\n",
       "                      [ 0.0120,  0.0138, -0.0165,  ...,  0.0191, -0.0421, -0.0044],\n",
       "                      [ 0.0430, -0.0357,  0.0194,  ...,  0.0337, -0.0402,  0.0631],\n",
       "                      [ 0.0117,  0.0087,  0.0234,  ...,  0.0453, -0.0381, -0.0415]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.linear2.bias',\n",
       "              tensor([-0.0593,  0.0648,  0.0023,  0.0535,  0.0226,  0.0122,  0.0188,  0.0426,\n",
       "                      -0.0361, -0.0361,  0.0128,  0.0045, -0.0443,  0.0586, -0.0031,  0.0337,\n",
       "                       0.0360,  0.0098, -0.0133, -0.0164,  0.0541,  0.0435,  0.0094,  0.0255,\n",
       "                       0.0196,  0.0554, -0.0191, -0.0200, -0.0528,  0.0335,  0.0294, -0.0343,\n",
       "                      -0.0021,  0.0031,  0.0313,  0.0388, -0.0150,  0.0062,  0.0072, -0.0646,\n",
       "                       0.0396,  0.0384, -0.0321,  0.0113,  0.0357, -0.0401,  0.0092,  0.0107,\n",
       "                       0.0265, -0.0070, -0.0185,  0.0216,  0.0243, -0.0265,  0.0465, -0.0569,\n",
       "                       0.0457,  0.0141, -0.0238, -0.0367, -0.0237, -0.0651, -0.0339, -0.0417,\n",
       "                       0.0720,  0.0034,  0.0097, -0.0270, -0.0034, -0.0080, -0.0257, -0.0237,\n",
       "                       0.0390,  0.0051,  0.0313, -0.0394,  0.0031, -0.0124,  0.0261, -0.0414,\n",
       "                       0.0210, -0.0075, -0.0165, -0.0097,  0.0019, -0.0256,  0.0557, -0.0994,\n",
       "                       0.0632,  0.0436,  0.0091,  0.0008,  0.0108, -0.0382, -0.0076, -0.0345,\n",
       "                      -0.0041, -0.0655, -0.0157,  0.0029,  0.0295,  0.0089, -0.0063, -0.0376,\n",
       "                       0.0347, -0.0009,  0.0025, -0.0151,  0.0502, -0.0274, -0.0101, -0.0190,\n",
       "                      -0.0305,  0.0292,  0.0388, -0.0833,  0.0431, -0.0566,  0.0625, -0.0125,\n",
       "                      -0.0343, -0.0196, -0.0432, -0.0851,  0.0098, -0.0447,  0.0360, -0.0172,\n",
       "                       0.0253, -0.0719,  0.0321, -0.0618,  0.0097, -0.0004,  0.0162,  0.0122,\n",
       "                      -0.0092, -0.0200, -0.0183, -0.0253,  0.0440, -0.0472,  0.0652, -0.0365,\n",
       "                       0.0265, -0.0083, -0.0130, -0.0326, -0.0118,  0.0450,  0.0297, -0.0418,\n",
       "                       0.0632, -0.0308,  0.0790,  0.0477,  0.0165, -0.0370,  0.0019, -0.0569,\n",
       "                       0.0397,  0.0545, -0.0142, -0.0424,  0.0241, -0.0529,  0.0214, -0.0698,\n",
       "                      -0.0014, -0.0665,  0.0320, -0.0298,  0.0085, -0.0479, -0.0221,  0.0115,\n",
       "                       0.0378, -0.0738,  0.0567, -0.0145,  0.0060, -0.0011, -0.0271,  0.0269,\n",
       "                       0.0256, -0.0158, -0.0002,  0.0308,  0.0350, -0.0646,  0.0467,  0.0217],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm1.weight',\n",
       "              tensor([1.0122, 1.0732, 1.0125, 1.0210, 1.0419, 1.0138, 0.9997, 0.9772, 0.9951,\n",
       "                      1.0300, 0.9524, 1.0194, 0.9656, 1.0051, 0.9797, 1.0167, 1.0122, 0.9929,\n",
       "                      0.9762, 0.9869, 1.0062, 1.0185, 1.0091, 1.0150, 0.9800, 1.0136, 0.9989,\n",
       "                      0.9809, 1.0030, 0.9640, 0.9693, 0.9960, 0.9668, 1.0201, 0.9832, 0.9945,\n",
       "                      0.9349, 0.9979, 0.9513, 1.0317, 0.9487, 1.0099, 0.9532, 1.0094, 0.9604,\n",
       "                      0.9876, 0.9999, 0.9870, 0.9991, 0.9716, 0.9971, 0.9631, 1.0068, 0.9360,\n",
       "                      1.0292, 0.9317, 1.0063, 0.9248, 1.0179, 0.9477, 1.0142, 0.9318, 1.0214,\n",
       "                      0.9137, 1.0768, 0.9036, 1.0288, 0.8940, 1.0545, 0.8833, 1.0464, 0.9185,\n",
       "                      1.0753, 0.9014, 1.0653, 0.9105, 1.0339, 0.9169, 1.0686, 0.9421, 1.0594,\n",
       "                      0.9258, 0.9851, 0.9194, 1.0410, 0.9125, 1.0941, 0.9806, 1.0655, 0.8837,\n",
       "                      1.0784, 0.9110, 1.0630, 0.9186, 1.0332, 0.9188, 1.0714, 0.8587, 1.0477,\n",
       "                      0.8790, 1.0546, 0.9161, 1.0712, 0.8889, 1.0803, 0.9000, 1.0678, 0.9159,\n",
       "                      1.0430, 0.8937, 1.0413, 0.9287, 1.0302, 0.8803, 1.0467, 0.9223, 1.0748,\n",
       "                      0.9033, 1.0590, 0.9242, 1.0510, 0.9030, 1.1041, 0.9772, 1.0555, 0.9036,\n",
       "                      1.0430, 0.9185, 1.0606, 0.9328, 1.0745, 0.8873, 1.0444, 0.9406, 1.0735,\n",
       "                      0.9098, 1.0662, 0.9133, 1.0484, 0.9219, 1.0408, 0.9180, 1.0523, 0.9104,\n",
       "                      1.0890, 0.9043, 1.0655, 0.9031, 1.0411, 0.8859, 1.0664, 0.9345, 1.0536,\n",
       "                      0.9042, 1.0687, 0.9107, 1.0676, 0.9206, 1.0770, 0.9249, 1.0646, 0.9140,\n",
       "                      1.0554, 0.9444, 1.0579, 0.8974, 1.0733, 0.9318, 1.0696, 0.9192, 1.0699,\n",
       "                      0.9183, 1.0461, 0.8980, 1.0579, 0.9057, 1.0620, 0.9138, 1.0648, 0.9078,\n",
       "                      1.0314, 0.8800, 1.0751, 0.8980, 1.0852, 0.9375, 1.0621, 0.9114, 1.0517,\n",
       "                      0.9108, 1.0575, 0.8997], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm1.bias',\n",
       "              tensor([ 0.1107, -0.1105,  0.0496, -0.0711, -0.0341, -0.0068, -0.0040, -0.0071,\n",
       "                       0.1108,  0.0745, -0.0282,  0.0257, -0.0214, -0.0482,  0.0447, -0.0122,\n",
       "                      -0.0516,  0.0527,  0.0271,  0.1116, -0.0979, -0.0502, -0.0666, -0.0212,\n",
       "                      -0.0298,  0.0120,  0.0105, -0.0026,  0.1012, -0.0616, -0.0766, -0.0177,\n",
       "                      -0.0647, -0.0232, -0.1045, -0.1019, -0.0128, -0.0210,  0.0015,  0.0742,\n",
       "                      -0.1152, -0.0361, -0.0178, -0.0401, -0.1391,  0.0491,  0.0402,  0.0449,\n",
       "                      -0.0142, -0.0738,  0.0123, -0.0344, -0.0853,  0.0185, -0.0318,  0.1416,\n",
       "                      -0.0769,  0.0086,  0.0450,  0.0627,  0.0608,  0.0846,  0.0451,  0.0763,\n",
       "                      -0.1909, -0.0391, -0.0807,  0.0162, -0.0203, -0.0602,  0.0529,  0.0860,\n",
       "                      -0.0598, -0.0744, -0.0359,  0.0775, -0.0142,  0.0135, -0.0017,  0.0920,\n",
       "                       0.0179, -0.0025,  0.0311,  0.1181, -0.0474,  0.0281, -0.1158,  0.2363,\n",
       "                      -0.1158, -0.0379, -0.0127,  0.0199,  0.0235,  0.1015,  0.1062,  0.1071,\n",
       "                       0.0157,  0.0700,  0.0134, -0.0070, -0.0442, -0.0338, -0.0091,  0.0182,\n",
       "                      -0.1253,  0.0119,  0.0025,  0.0746, -0.0627,  0.0907,  0.0853,  0.0460,\n",
       "                       0.0127, -0.0586, -0.0785,  0.0717, -0.0135,  0.1364, -0.0514, -0.0420,\n",
       "                       0.0746,  0.0532,  0.0724,  0.0705,  0.0064,  0.0954, -0.0350, -0.0228,\n",
       "                      -0.0019,  0.1074, -0.0501,  0.1210, -0.0309, -0.0090,  0.0117,  0.0397,\n",
       "                      -0.0191,  0.0781,  0.0157, -0.0224, -0.0531,  0.1213, -0.0753,  0.0318,\n",
       "                      -0.0489, -0.0286, -0.0240,  0.0443,  0.0576, -0.0560, -0.0525,  0.0670,\n",
       "                      -0.0253,  0.0133, -0.1166, -0.0552,  0.0496,  0.0752,  0.0044,  0.0562,\n",
       "                      -0.0612, -0.0961,  0.0582,  0.1190, -0.0170,  0.0406, -0.0037,  0.0483,\n",
       "                      -0.0307,  0.0424, -0.0927,  0.0434, -0.0154,  0.0824,  0.0781, -0.0372,\n",
       "                      -0.0501,  0.0865, -0.0628,  0.0427, -0.0351, -0.0664,  0.0587, -0.0522,\n",
       "                      -0.0056,  0.0581,  0.0198, -0.0723, -0.1109,  0.0646, -0.0722,  0.0223],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm2.weight',\n",
       "              tensor([1.0179, 1.0780, 1.0126, 1.0245, 1.0368, 1.0148, 1.0004, 0.9973, 0.9954,\n",
       "                      1.0242, 0.9610, 1.0176, 0.9661, 1.0038, 0.9771, 1.0069, 1.0138, 0.9862,\n",
       "                      0.9822, 0.9989, 1.0134, 1.0158, 1.0164, 1.0063, 0.9849, 1.0131, 0.9946,\n",
       "                      0.9769, 1.0073, 0.9663, 0.9743, 1.0026, 0.9754, 1.0182, 1.0050, 1.0075,\n",
       "                      0.9494, 0.9891, 0.9623, 1.0261, 0.9676, 1.0208, 0.9640, 1.0114, 0.9900,\n",
       "                      0.9900, 1.0026, 0.9848, 0.9980, 0.9749, 1.0175, 0.9707, 1.0124, 0.9466,\n",
       "                      1.0244, 0.9471, 1.0200, 0.9237, 1.0246, 0.9495, 1.0107, 0.9368, 1.0245,\n",
       "                      0.9377, 1.0849, 0.9113, 1.0276, 0.9026, 1.0566, 0.9028, 1.0459, 0.9296,\n",
       "                      1.0689, 0.9119, 1.0572, 0.9257, 1.0365, 0.9196, 1.0682, 0.9518, 1.0529,\n",
       "                      0.9270, 0.9998, 0.9432, 1.0373, 0.9161, 1.0907, 1.0134, 1.0677, 0.8848,\n",
       "                      1.0799, 0.8987, 1.0636, 0.9392, 1.0497, 0.9317, 1.0644, 0.9099, 1.0361,\n",
       "                      0.9083, 1.0636, 0.9178, 1.0551, 0.9057, 1.0758, 0.9163, 1.0595, 0.9243,\n",
       "                      1.0533, 0.9081, 1.0497, 0.9409, 1.0353, 0.9191, 1.0395, 0.9340, 1.0625,\n",
       "                      0.9380, 1.0580, 0.9292, 1.0476, 0.9215, 1.0977, 0.9766, 1.0637, 0.9124,\n",
       "                      1.0480, 0.9320, 1.0593, 0.9379, 1.0677, 0.9058, 1.0523, 0.9471, 1.0738,\n",
       "                      0.9203, 1.0599, 0.9117, 1.0487, 0.9261, 1.0460, 0.9576, 1.0513, 0.9157,\n",
       "                      1.0760, 0.9118, 1.0646, 0.9294, 1.0426, 0.9058, 1.0636, 0.9399, 1.0513,\n",
       "                      0.9161, 1.0795, 0.9241, 1.0698, 0.9350, 1.0667, 0.9393, 1.0637, 0.9291,\n",
       "                      1.0588, 0.9559, 1.0590, 0.9056, 1.0649, 0.9282, 1.0616, 0.9335, 1.0678,\n",
       "                      0.9228, 1.0520, 0.9031, 1.0559, 0.9199, 1.0595, 0.9272, 1.0650, 0.9128,\n",
       "                      1.0262, 0.9000, 1.0648, 0.8981, 1.0777, 0.9428, 1.0665, 0.9076, 1.0513,\n",
       "                      0.9087, 1.0690, 0.9085], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm2.bias',\n",
       "              tensor([ 0.1014, -0.1061,  0.0455, -0.0666, -0.0225, -0.0088, -0.0059, -0.0009,\n",
       "                       0.0996,  0.0780, -0.0276,  0.0248, -0.0255, -0.0378,  0.0368, -0.0152,\n",
       "                      -0.0538,  0.0463,  0.0192,  0.1225, -0.0884, -0.0507, -0.0788, -0.0237,\n",
       "                      -0.0378,  0.0237,  0.0039, -0.0089,  0.0932, -0.0682, -0.0835, -0.0252,\n",
       "                      -0.0596, -0.0267, -0.1022, -0.1000, -0.0265, -0.0375, -0.0025,  0.0681,\n",
       "                      -0.1205, -0.0338, -0.0247, -0.0453, -0.1385,  0.0407,  0.0401,  0.0434,\n",
       "                      -0.0108, -0.0830,  0.0135, -0.0395, -0.0824,  0.0023, -0.0366,  0.1196,\n",
       "                      -0.0691,  0.0036,  0.0386,  0.0525,  0.0614,  0.0708,  0.0419,  0.0557,\n",
       "                      -0.1815, -0.0453, -0.0672,  0.0109, -0.0235, -0.0705,  0.0541,  0.0686,\n",
       "                      -0.0597, -0.0829, -0.0309,  0.0649, -0.0150,  0.0047,  0.0010,  0.0715,\n",
       "                       0.0136, -0.0232,  0.0495,  0.1002, -0.0482,  0.0010, -0.1133,  0.2212,\n",
       "                      -0.1045, -0.0366, -0.0113, -0.0070,  0.0272,  0.0853,  0.1088,  0.0785,\n",
       "                       0.0104,  0.0586,  0.0203, -0.0089, -0.0409, -0.0498, -0.0135,  0.0030,\n",
       "                      -0.1149, -0.0031, -0.0124,  0.0541, -0.0558,  0.0746,  0.0801,  0.0359,\n",
       "                       0.0117, -0.0725, -0.0714,  0.0500, -0.0162,  0.1242, -0.0445, -0.0558,\n",
       "                       0.0707,  0.0431,  0.0680,  0.0546,  0.0152,  0.0749, -0.0323, -0.0346,\n",
       "                      -0.0044,  0.0859, -0.0531,  0.1042, -0.0277, -0.0171,  0.0126,  0.0321,\n",
       "                      -0.0116,  0.0734,  0.0210, -0.0457, -0.0493,  0.0997, -0.0695,  0.0197,\n",
       "                      -0.0376, -0.0389, -0.0258,  0.0323,  0.0549, -0.0537, -0.0480,  0.0431,\n",
       "                      -0.0185,  0.0071, -0.1089, -0.0722,  0.0471,  0.0525,  0.0004,  0.0380,\n",
       "                      -0.0500, -0.0884,  0.0599,  0.1011, -0.0150,  0.0241, -0.0125,  0.0295,\n",
       "                      -0.0248,  0.0204, -0.0919,  0.0168, -0.0124,  0.0682,  0.0804, -0.0443,\n",
       "                      -0.0452,  0.0596, -0.0648,  0.0405, -0.0365, -0.0617,  0.0548, -0.0661,\n",
       "                      -0.0099,  0.0466,  0.0256, -0.0793, -0.1022,  0.0429, -0.0657,  0.0170],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm3.weight',\n",
       "              tensor([0.9704, 0.9299, 0.9906, 0.9871, 0.9566, 1.0009, 0.9909, 0.9906, 0.9556,\n",
       "                      0.9729, 0.9873, 0.9965, 0.9713, 1.0177, 0.9836, 1.0138, 0.9997, 1.0266,\n",
       "                      0.9871, 0.9951, 1.0052, 0.9767, 1.0150, 1.0148, 0.9912, 0.9958, 0.9466,\n",
       "                      0.9665, 0.9432, 0.9599, 1.0083, 0.9962, 0.9882, 1.0278, 0.9524, 1.0219,\n",
       "                      0.9347, 1.0097, 1.0020, 1.0014, 1.0170, 1.0301, 0.9876, 1.0356, 0.9579,\n",
       "                      1.0341, 1.0085, 0.9933, 1.0325, 0.9722, 0.9999, 1.0307, 1.0152, 0.9656,\n",
       "                      1.0010, 0.9552, 1.0033, 0.9582, 1.0234, 0.9963, 0.9959, 0.9948, 1.0433,\n",
       "                      0.9546, 0.9508, 0.9521, 1.0146, 0.9707, 1.0278, 0.9685, 1.0417, 0.9564,\n",
       "                      1.0150, 1.0045, 1.0417, 0.9766, 1.0236, 1.0021, 1.0576, 0.9780, 1.0302,\n",
       "                      0.9388, 0.9841, 0.9510, 1.0077, 1.0176, 1.0340, 0.8882, 0.9906, 0.9648,\n",
       "                      1.0379, 0.9292, 1.0169, 0.9412, 1.0340, 0.9455, 1.0523, 0.9684, 1.0751,\n",
       "                      0.9692, 1.0397, 0.9625, 1.0200, 0.9849, 1.0261, 0.9567, 1.0339, 0.9725,\n",
       "                      0.9883, 0.9726, 1.0254, 0.9565, 0.9767, 0.9881, 0.9972, 0.9585, 1.0063,\n",
       "                      0.9301, 1.0600, 0.9656, 1.0346, 0.9806, 1.0373, 0.9476, 1.0638, 0.9389,\n",
       "                      1.0426, 0.9996, 1.0355, 0.9510, 1.0236, 0.9602, 0.9650, 1.0166, 1.0684,\n",
       "                      0.9755, 1.0366, 0.9692, 1.0366, 0.9113, 0.9994, 0.9517, 1.0284, 0.9968,\n",
       "                      1.0168, 0.9740, 1.0417, 0.9682, 1.0064, 0.9483, 1.0214, 0.8978, 1.0285,\n",
       "                      1.0042, 0.9877, 0.9764, 1.0640, 0.9491, 1.0285, 0.9888, 1.0234, 0.9234,\n",
       "                      1.0143, 0.9336, 1.0299, 0.9573, 1.0374, 0.9343, 1.0366, 0.9737, 1.0612,\n",
       "                      0.9878, 1.0303, 0.9684, 1.0386, 0.9614, 1.0201, 0.9445, 1.0575, 0.9753,\n",
       "                      0.9903, 0.9470, 1.0381, 0.9586, 1.0582, 1.0133, 1.0631, 0.9656, 0.9376,\n",
       "                      0.9516, 1.0466, 0.9843], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.0.norm3.bias',\n",
       "              tensor([ 0.0529, -0.0911,  0.0329, -0.0132,  0.0664, -0.0029,  0.0616,  0.0147,\n",
       "                       0.0431,  0.1139,  0.0084,  0.0243,  0.1082, -0.0237,  0.0654, -0.0247,\n",
       "                      -0.0440,  0.0400,  0.0214,  0.0937, -0.0573, -0.0013, -0.0126,  0.0333,\n",
       "                      -0.0606,  0.0376,  0.0162,  0.0690,  0.0361, -0.0089, -0.0672,  0.0823,\n",
       "                      -0.0204, -0.0596, -0.0441, -0.0544, -0.0791, -0.0370, -0.0289,  0.0339,\n",
       "                      -0.0481, -0.0240,  0.0173, -0.0358, -0.0630,  0.0040,  0.0222, -0.0208,\n",
       "                      -0.0569, -0.0605,  0.0126, -0.0439, -0.0294, -0.0367, -0.0366,  0.0320,\n",
       "                      -0.0375, -0.0785,  0.0285,  0.0224,  0.0989, -0.0199,  0.0328,  0.0051,\n",
       "                      -0.0123, -0.0303, -0.0282, -0.0178,  0.0178, -0.0466,  0.0882,  0.0036,\n",
       "                       0.0284, -0.0623, -0.0882, -0.0007,  0.0608, -0.0239,  0.0135, -0.0408,\n",
       "                       0.0091, -0.0628,  0.0785,  0.0049, -0.0107, -0.0059, -0.0565,  0.0932,\n",
       "                      -0.0017, -0.0661, -0.0071, -0.0885,  0.0305,  0.0094,  0.0466, -0.0492,\n",
       "                       0.0611,  0.0378,  0.0952, -0.0158,  0.0466, -0.0963,  0.0065,  0.0155,\n",
       "                      -0.0525, -0.0753,  0.0405, -0.0970,  0.0085, -0.0202,  0.0352, -0.0183,\n",
       "                       0.1410, -0.0673,  0.0349, -0.0435,  0.0050,  0.0497,  0.0345, -0.0938,\n",
       "                       0.0698,  0.0010,  0.1195,  0.0386,  0.0402, -0.0186,  0.0223, -0.0609,\n",
       "                       0.0132,  0.0059, -0.0640,  0.0218,  0.1428, -0.0804,  0.0660, -0.0976,\n",
       "                      -0.0011, -0.0046,  0.1008, -0.1065,  0.0060, -0.0158, -0.0553, -0.0149,\n",
       "                       0.0440, -0.0690,  0.0309, -0.0206,  0.0804, -0.0607, -0.0064, -0.0962,\n",
       "                      -0.0244,  0.0118, -0.0059, -0.1390,  0.0514,  0.0225,  0.0490,  0.0075,\n",
       "                       0.0084, -0.0225,  0.0754, -0.0261, -0.0165,  0.0044,  0.0245, -0.0490,\n",
       "                      -0.0124,  0.0130, -0.0293, -0.0210,  0.0605, -0.0185,  0.1439, -0.1134,\n",
       "                       0.0602, -0.0202, -0.0148,  0.0211,  0.0202, -0.0560,  0.0824, -0.0446,\n",
       "                       0.0396, -0.0311,  0.0298, -0.0469, -0.0192, -0.0154, -0.0183, -0.0422],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.in_proj_weight',\n",
       "              tensor([[-0.1119,  0.0588,  0.0002,  ...,  0.0133, -0.0133,  0.0116],\n",
       "                      [ 0.0301, -0.0270, -0.1334,  ..., -0.0421,  0.0298, -0.0486],\n",
       "                      [-0.0188,  0.0825, -0.0291,  ..., -0.1244, -0.0764, -0.0075],\n",
       "                      ...,\n",
       "                      [ 0.0014,  0.0188,  0.0348,  ..., -0.0706,  0.0439,  0.0133],\n",
       "                      [-0.0917,  0.0005,  0.0726,  ...,  0.0730,  0.0314,  0.0048],\n",
       "                      [-0.1028, -0.0489,  0.1067,  ..., -0.0096, -0.0822,  0.0110]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.in_proj_bias',\n",
       "              tensor([-4.6883e-02, -1.7689e-02, -3.5032e-02,  1.9831e-02, -4.0250e-03,\n",
       "                       6.4847e-02,  4.4583e-02, -1.7099e-03, -1.2833e-02,  1.2622e-03,\n",
       "                      -2.2965e-02, -1.9850e-02,  2.0853e-03, -2.4800e-02, -6.0025e-02,\n",
       "                      -4.0198e-03,  6.5970e-02, -1.9065e-03, -5.2621e-02, -5.6490e-02,\n",
       "                       9.1652e-02,  3.0203e-02, -5.5018e-03,  3.0497e-02, -6.4178e-02,\n",
       "                       8.2146e-02,  3.5095e-02,  3.9055e-03,  3.0006e-02, -5.3455e-02,\n",
       "                       7.8429e-02,  2.2789e-02, -3.7786e-03, -6.5885e-02,  6.2286e-02,\n",
       "                       5.3171e-02, -3.7818e-02,  3.8454e-02, -1.0112e-01, -2.0054e-02,\n",
       "                       4.3922e-02,  4.9698e-03, -6.7393e-03, -3.9034e-02, -1.1273e-03,\n",
       "                       7.6299e-02, -3.0213e-02, -4.7463e-03, -2.6794e-02,  2.8705e-02,\n",
       "                       6.7507e-02, -3.5129e-02, -3.1392e-02, -1.6337e-02, -2.5238e-02,\n",
       "                       1.0285e-01, -1.3067e-02, -9.6286e-03,  1.6271e-02,  5.8257e-02,\n",
       "                      -1.0560e-02,  9.2034e-02, -2.2250e-02, -9.0629e-02, -3.8578e-02,\n",
       "                      -1.4965e-02,  2.8649e-02,  6.5088e-02, -5.0830e-02,  9.4831e-02,\n",
       "                      -5.7366e-02,  4.7760e-02, -7.0443e-02, -8.0418e-02,  2.1831e-07,\n",
       "                      -1.0751e-02,  1.0435e-01,  4.5741e-02, -8.8505e-02, -2.7445e-02,\n",
       "                       2.2839e-02, -1.5149e-02, -2.7207e-02,  3.4977e-03,  4.9749e-02,\n",
       "                      -4.2513e-02, -1.1560e-02,  3.0572e-02, -4.0768e-03, -8.4038e-02,\n",
       "                       1.8262e-02,  6.3885e-02, -5.3466e-02,  7.1422e-04,  9.0777e-02,\n",
       "                       9.3107e-02,  3.4152e-02,  4.4870e-03, -5.1810e-02,  1.2621e-01,\n",
       "                      -3.2467e-02, -3.7477e-02, -6.9751e-02,  4.9383e-02, -5.6180e-02,\n",
       "                       5.6727e-02,  1.1718e-02, -2.7198e-03,  2.1034e-02, -6.5690e-02,\n",
       "                       1.6238e-03,  7.2895e-02, -1.3576e-02,  2.0290e-02,  4.0003e-02,\n",
       "                      -1.6992e-02,  3.6560e-02,  6.2649e-02,  5.2250e-02, -8.7838e-02,\n",
       "                      -2.9428e-02, -3.6050e-02, -3.2043e-02, -5.7541e-02, -3.6915e-03,\n",
       "                       1.8416e-02, -4.0111e-02, -3.0585e-03,  8.1765e-02, -6.9614e-03,\n",
       "                       3.0550e-02,  7.6814e-02, -2.5128e-03,  3.5678e-03, -7.4245e-03,\n",
       "                       4.9970e-02,  2.0363e-02,  7.4293e-02, -3.9016e-02, -6.8782e-02,\n",
       "                      -1.9240e-02, -4.9059e-02,  2.3087e-02, -7.5147e-02, -9.5646e-03,\n",
       "                      -6.2987e-02, -4.3627e-02,  1.5153e-02, -6.0074e-02, -8.8119e-02,\n",
       "                       4.4028e-02, -3.2256e-02,  2.4366e-02,  4.6890e-03, -1.5686e-02,\n",
       "                       7.6131e-02, -7.9720e-02,  6.8249e-02, -5.9612e-02, -5.6961e-02,\n",
       "                       4.0447e-02, -5.4531e-02,  1.1257e-02, -6.4836e-02,  3.2665e-02,\n",
       "                      -1.1279e-02, -6.8678e-02,  8.1423e-02,  6.4479e-03,  8.7029e-02,\n",
       "                       6.6353e-03, -4.0897e-02, -4.7400e-02, -2.1320e-02, -9.2970e-03,\n",
       "                       1.2130e-02, -4.1210e-02,  5.4055e-02,  1.6114e-02,  4.8390e-02,\n",
       "                       6.8868e-02,  7.2520e-02, -7.9469e-02,  8.9908e-02, -2.6710e-02,\n",
       "                      -2.5450e-02, -4.7421e-02,  9.1955e-02,  4.6766e-02, -5.6362e-02,\n",
       "                      -5.1963e-02, -9.0686e-02,  6.7066e-07, -6.8542e-06, -1.0412e-05,\n",
       "                       1.8717e-05,  4.9458e-06,  1.5089e-05,  3.6870e-06, -7.0318e-06,\n",
       "                       8.5687e-06, -1.4225e-05, -2.8814e-06, -8.9961e-07, -1.9802e-05,\n",
       "                      -2.2285e-06, -9.2259e-06,  1.2833e-05, -4.3311e-07, -4.9876e-06,\n",
       "                       1.2974e-05, -1.2378e-05,  4.4406e-06,  8.1023e-06, -1.6453e-05,\n",
       "                       8.8154e-06, -2.1751e-06,  1.6634e-06,  5.0101e-07,  1.4763e-05,\n",
       "                      -8.9392e-06, -1.1927e-05,  7.3410e-07, -1.8079e-06, -1.0112e-06,\n",
       "                       2.1312e-06, -1.3294e-06,  6.4454e-06,  1.5292e-05, -2.2782e-06,\n",
       "                       1.4620e-05,  2.3917e-06,  3.5869e-06,  5.1180e-06,  1.4277e-05,\n",
       "                       1.6190e-06,  9.3059e-06,  3.4910e-06,  1.3219e-05, -8.7786e-06,\n",
       "                      -8.9638e-06,  3.2758e-05, -5.6812e-06,  1.2096e-05, -1.8322e-06,\n",
       "                       1.1415e-05, -5.2610e-06, -9.1960e-06,  2.4595e-06,  5.8087e-06,\n",
       "                      -1.4308e-05, -7.9415e-06, -8.2228e-06, -3.2715e-05, -1.0647e-05,\n",
       "                       8.8445e-07, -4.0231e-06,  2.3951e-06, -4.1686e-06,  2.3579e-05,\n",
       "                      -1.4601e-06, -2.3998e-05, -1.1285e-05, -6.9366e-06,  2.5404e-06,\n",
       "                      -1.5187e-05,  5.0074e-07,  7.5442e-06, -2.2652e-06, -2.2262e-05,\n",
       "                       6.0181e-07,  1.2068e-05,  2.6521e-06, -6.1183e-06,  1.9119e-05,\n",
       "                       4.4352e-06, -1.0421e-05,  2.3038e-06, -5.9336e-06,  6.2893e-06,\n",
       "                      -5.2309e-06,  9.0303e-06,  4.5187e-06,  8.7036e-06, -1.2103e-06,\n",
       "                      -7.0735e-06, -1.0518e-05,  1.6272e-05, -1.2516e-05,  4.7558e-06,\n",
       "                       1.0142e-05,  6.8331e-06, -1.1170e-05,  7.9071e-06,  8.7836e-06,\n",
       "                      -4.0817e-06,  9.5960e-06, -1.0453e-05,  1.0371e-05,  5.9365e-07,\n",
       "                      -8.8530e-06, -8.3707e-06,  2.0282e-07,  1.5774e-05, -1.5736e-06,\n",
       "                      -5.3639e-06,  1.4631e-05, -9.6260e-07, -1.7075e-05, -5.5270e-06,\n",
       "                      -1.3181e-05,  4.0289e-06,  8.6837e-06,  1.2179e-05,  9.3846e-06,\n",
       "                       6.7348e-06,  1.5191e-05, -3.7660e-06,  7.4114e-06, -1.4243e-06,\n",
       "                      -1.2655e-05, -4.4605e-06, -3.9999e-06, -1.1263e-05,  8.2569e-07,\n",
       "                       2.6240e-06,  1.5060e-05, -4.3887e-06, -5.5399e-06, -1.1687e-05,\n",
       "                       2.3589e-06,  8.1158e-06,  6.9327e-07, -1.2371e-06,  6.4682e-06,\n",
       "                      -1.8930e-06, -2.3744e-06, -5.3860e-06, -7.1082e-06, -7.0457e-06,\n",
       "                      -1.2718e-05,  1.5667e-06,  1.3732e-05,  5.2376e-07,  2.6724e-06,\n",
       "                       2.7801e-06, -1.3938e-05, -6.9093e-06,  6.9195e-06,  1.4301e-05,\n",
       "                       3.2901e-06,  1.3307e-05, -1.8844e-06, -6.1952e-06, -4.8320e-06,\n",
       "                      -5.0136e-06,  6.3665e-06,  5.6536e-06,  2.8044e-05, -6.4470e-06,\n",
       "                       6.2553e-06,  3.4509e-06,  7.7146e-06,  6.3251e-06, -1.6008e-05,\n",
       "                      -2.3275e-05, -8.8323e-07, -1.6839e-05,  1.0590e-05,  7.6439e-06,\n",
       "                      -1.8164e-06, -1.0996e-05, -3.3013e-06, -6.5375e-09,  1.1906e-05,\n",
       "                       7.7347e-06,  7.0320e-06,  1.2623e-06,  4.8321e-06,  7.8364e-06,\n",
       "                      -1.3552e-05, -1.5539e-05, -1.9772e-06, -1.4583e-05, -1.4083e-02,\n",
       "                       1.1176e-02,  9.7251e-03,  1.5138e-02, -6.0981e-03,  7.6033e-03,\n",
       "                      -2.9974e-02, -1.1989e-02,  8.4238e-03,  1.7924e-02, -1.1342e-02,\n",
       "                       1.7498e-02,  1.7233e-02,  2.4611e-02, -3.2326e-03, -6.2816e-03,\n",
       "                      -2.0022e-02, -7.6461e-03,  1.8008e-02,  5.6165e-03,  1.1291e-02,\n",
       "                       4.6782e-03,  1.9247e-02,  3.8092e-03,  1.0551e-02,  3.8759e-03,\n",
       "                       6.4586e-04,  3.2884e-03, -5.4096e-04, -1.0096e-02,  1.2916e-02,\n",
       "                      -6.5504e-03,  4.5368e-03, -4.4401e-03,  7.0199e-03,  4.4013e-03,\n",
       "                      -1.4619e-02,  1.2791e-02,  1.3249e-02, -2.4694e-02, -4.8855e-03,\n",
       "                      -5.3836e-03, -5.8164e-03,  1.1458e-02,  2.7668e-02, -1.4218e-02,\n",
       "                       1.2458e-02, -1.6016e-02,  8.8222e-03,  7.5653e-04, -8.6830e-04,\n",
       "                       1.1913e-02, -9.5163e-03, -1.2947e-02,  6.9819e-03, -1.8076e-02,\n",
       "                       7.1307e-03, -2.3290e-02,  1.6420e-02, -5.2034e-03,  1.6884e-02,\n",
       "                       1.4874e-02, -1.1817e-02, -4.6706e-03,  3.9306e-02,  1.0370e-02,\n",
       "                      -1.2274e-02,  7.6153e-03,  7.2630e-03, -9.8423e-03,  1.7785e-02,\n",
       "                       2.0041e-03, -1.4072e-02,  1.3066e-02,  1.2530e-02, -1.0354e-02,\n",
       "                       1.3929e-02, -1.8552e-02,  3.0378e-02, -7.1660e-03, -1.0186e-03,\n",
       "                       1.0420e-02,  9.9631e-03, -6.0956e-03, -1.2155e-02, -6.5960e-03,\n",
       "                       1.4070e-02, -1.5161e-02,  1.6140e-02,  1.2424e-02, -6.8124e-05,\n",
       "                       2.1549e-02,  5.4264e-03,  1.8213e-02,  7.1934e-03, -1.9516e-02,\n",
       "                       9.9552e-03,  5.3198e-04, -1.3909e-03, -2.4340e-02, -1.0219e-02,\n",
       "                       6.9933e-03,  1.3917e-03, -8.6553e-03,  2.0894e-02, -2.3368e-02,\n",
       "                      -2.0220e-03, -1.5113e-02, -7.0708e-03, -7.0731e-03, -5.6691e-03,\n",
       "                       5.3663e-03,  2.8587e-02, -1.3280e-02,  1.3504e-02, -1.3050e-02,\n",
       "                      -5.1631e-03,  1.9800e-03, -8.1878e-03,  1.4707e-02, -1.1270e-02,\n",
       "                      -3.1284e-02,  1.2387e-02,  3.2550e-03,  2.0075e-02, -2.2253e-04,\n",
       "                       2.4929e-02,  2.5022e-02,  7.6679e-03,  2.1497e-02, -3.5650e-03,\n",
       "                      -1.7133e-02, -2.4663e-03,  5.8851e-03,  2.0289e-02,  9.5215e-04,\n",
       "                       1.9021e-02,  5.2186e-03,  7.6804e-03,  1.2181e-02, -9.6251e-03,\n",
       "                       4.2442e-02,  3.4983e-02,  7.6254e-03,  1.2292e-02, -1.0654e-02,\n",
       "                      -2.3302e-02, -5.5196e-03,  6.6391e-03, -6.3755e-03,  2.7376e-02,\n",
       "                       1.0261e-02, -1.0865e-02,  6.1418e-03,  1.3693e-02,  7.0305e-03,\n",
       "                      -6.9481e-03, -1.5277e-02,  8.0434e-03, -1.8173e-02,  1.3320e-02,\n",
       "                       6.0668e-03,  7.3001e-03,  1.1019e-02,  3.6146e-03,  1.2082e-02,\n",
       "                      -1.6947e-02, -3.7481e-03, -1.0476e-02,  5.9758e-03, -1.7444e-03,\n",
       "                      -2.5558e-02, -1.3555e-02,  1.0794e-02, -5.6015e-03,  2.1191e-02,\n",
       "                      -1.1795e-02,  1.5423e-02,  2.2444e-02, -2.8323e-03,  9.9287e-03,\n",
       "                       2.6240e-02,  1.9329e-03, -3.3978e-03,  1.5984e-02,  1.4085e-02,\n",
       "                      -8.8675e-03, -1.9650e-02,  1.1788e-02, -2.9695e-03, -7.8964e-03,\n",
       "                      -5.3159e-04], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.out_proj.weight',\n",
       "              tensor([[-0.0008, -0.0805,  0.0672,  ...,  0.1154, -0.0272,  0.0385],\n",
       "                      [ 0.0514, -0.0521,  0.0722,  ..., -0.0322, -0.0197, -0.0190],\n",
       "                      [ 0.0093,  0.0065,  0.0328,  ...,  0.0313,  0.0241,  0.0342],\n",
       "                      ...,\n",
       "                      [-0.0304, -0.0854,  0.0255,  ...,  0.0012,  0.0079, -0.0530],\n",
       "                      [ 0.0110,  0.0005, -0.0343,  ...,  0.0320, -0.0869,  0.0306],\n",
       "                      [ 0.0671, -0.0503, -0.0378,  ..., -0.0256, -0.0091,  0.0425]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.self_attn.out_proj.bias',\n",
       "              tensor([ 0.0330, -0.0086,  0.0069, -0.0247,  0.0413,  0.0059,  0.0425,  0.0049,\n",
       "                       0.0296,  0.0073, -0.0126,  0.0047,  0.0249, -0.0200,  0.0255, -0.0344,\n",
       "                      -0.0136,  0.0036, -0.0006,  0.0256, -0.0090, -0.0240, -0.0387,  0.0024,\n",
       "                      -0.0373, -0.0038,  0.0210,  0.0173, -0.0134,  0.0180, -0.0298,  0.0486,\n",
       "                       0.0087,  0.0013, -0.0209, -0.0106, -0.0313, -0.0179, -0.0076,  0.0152,\n",
       "                      -0.0087, -0.0066,  0.0159, -0.0239,  0.0308, -0.0124,  0.0285, -0.0031,\n",
       "                       0.0013,  0.0120,  0.0249, -0.0023,  0.0029,  0.0230, -0.0436,  0.0203,\n",
       "                       0.0069, -0.0399, -0.0151, -0.0027,  0.0145,  0.0027, -0.0326,  0.0138,\n",
       "                      -0.0405,  0.0280,  0.0150, -0.0249,  0.0024, -0.0131,  0.0456,  0.0098,\n",
       "                       0.0092,  0.0217, -0.0280,  0.0013,  0.0143, -0.0158, -0.0063, -0.0307,\n",
       "                      -0.0246, -0.0197, -0.0005,  0.0065, -0.0031, -0.0207, -0.0020,  0.0236,\n",
       "                       0.0240, -0.0029,  0.0201, -0.0196, -0.0036, -0.0084, -0.0172, -0.0191,\n",
       "                       0.0059,  0.0231,  0.0641,  0.0007,  0.0243, -0.0290, -0.0008,  0.0530,\n",
       "                      -0.0144,  0.0193, -0.0001, -0.0353, -0.0212,  0.0075, -0.0112, -0.0287,\n",
       "                       0.0294, -0.0274,  0.0054, -0.0298,  0.0206,  0.0265,  0.0230, -0.0034,\n",
       "                      -0.0035, -0.0109,  0.0283,  0.0058, -0.0089,  0.0193,  0.0105, -0.0088,\n",
       "                      -0.0238, -0.0008, -0.0313, -0.0031,  0.0528, -0.0233,  0.0214, -0.0085,\n",
       "                      -0.0221,  0.0255,  0.0156, -0.0317, -0.0063,  0.0044, -0.0143, -0.0028,\n",
       "                       0.0225, -0.0331, -0.0011, -0.0173,  0.0334, -0.0445, -0.0180, -0.0330,\n",
       "                      -0.0080,  0.0131,  0.0252, -0.0228, -0.0057,  0.0147,  0.0099, -0.0004,\n",
       "                      -0.0257,  0.0080,  0.0321, -0.0160, -0.0098,  0.0135, -0.0089,  0.0008,\n",
       "                      -0.0195,  0.0014,  0.0252, -0.0274, -0.0098,  0.0190,  0.0490, -0.0125,\n",
       "                       0.0228,  0.0243,  0.0114,  0.0238, -0.0131,  0.0032,  0.0416,  0.0151,\n",
       "                       0.0042, -0.0165, -0.0025,  0.0041, -0.0142,  0.0024, -0.0105, -0.0061],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.in_proj_weight',\n",
       "              tensor([[ 0.0400, -0.0830,  0.1026,  ...,  0.0482, -0.0199, -0.0458],\n",
       "                      [-0.1486,  0.0807, -0.0066,  ..., -0.0112, -0.0836,  0.0269],\n",
       "                      [-0.0611,  0.0616, -0.1253,  ..., -0.0843, -0.0113,  0.1073],\n",
       "                      ...,\n",
       "                      [ 0.0686,  0.0005, -0.0231,  ..., -0.0429, -0.0058, -0.0189],\n",
       "                      [ 0.0458, -0.0076, -0.0780,  ..., -0.0622,  0.1324, -0.0213],\n",
       "                      [ 0.1321, -0.0259,  0.0002,  ...,  0.1245, -0.0017,  0.1072]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.in_proj_bias',\n",
       "              tensor([ 1.5504e-01, -5.6370e-02, -1.1369e-01, -1.3652e-01,  4.3207e-03,\n",
       "                       1.6370e-01,  6.3209e-02,  1.5051e-01,  1.3203e-01,  1.8422e-01,\n",
       "                      -2.0319e-02, -6.3878e-02,  1.6497e-01,  1.8327e-01, -1.1724e-01,\n",
       "                       1.9724e-02, -5.9973e-02, -1.4914e-01,  1.6350e-01, -1.2836e-01,\n",
       "                       1.8582e-01, -1.9367e-01, -3.6031e-02,  1.1585e-01,  9.7958e-02,\n",
       "                      -1.6164e-01, -8.6266e-02,  9.3083e-02,  2.2463e-02, -1.1063e-01,\n",
       "                       4.3902e-03,  1.9732e-01, -5.2724e-02,  1.7754e-01, -8.7357e-03,\n",
       "                      -1.6333e-01,  1.6326e-01, -2.0917e-01,  1.5877e-01, -7.8540e-02,\n",
       "                      -9.2886e-02, -2.0304e-02, -1.7338e-02, -7.0090e-02, -6.6697e-02,\n",
       "                      -9.4168e-02,  6.0382e-02, -1.6986e-01,  1.9997e-02,  7.6481e-02,\n",
       "                       4.0379e-02,  2.1728e-02, -1.7251e-01, -6.7962e-02, -9.3912e-02,\n",
       "                      -2.2624e-01, -2.0715e-02, -4.2494e-03,  5.2871e-02,  9.5855e-02,\n",
       "                       1.2396e-01,  4.4612e-02,  1.3755e-01, -6.1753e-03, -4.1619e-02,\n",
       "                      -3.4560e-02,  1.6320e-01, -5.0872e-02,  2.9179e-02, -6.7443e-03,\n",
       "                      -5.3601e-02, -1.5044e-01,  2.1788e-02, -2.2430e-02,  9.0122e-02,\n",
       "                       1.5626e-02,  7.9398e-02,  6.5898e-02,  1.3770e-01,  1.6014e-02,\n",
       "                      -4.9615e-02,  1.0683e-02, -1.2002e-01,  4.0162e-02, -2.5270e-02,\n",
       "                      -1.0023e-01,  1.1434e-01,  7.4981e-02,  8.7075e-03,  5.3735e-02,\n",
       "                      -5.9318e-02,  4.3582e-02, -1.2041e-01, -5.0116e-02,  9.8981e-02,\n",
       "                      -1.0764e-01,  5.4857e-02,  1.7231e-02, -2.5794e-02,  2.0714e-01,\n",
       "                       1.1127e-01, -2.2029e-02, -1.4357e-02,  1.6007e-01,  9.1329e-02,\n",
       "                      -2.4932e-01, -2.6011e-02,  4.3957e-02,  1.1908e-01,  2.3245e-02,\n",
       "                      -1.0138e-01, -2.6802e-02,  1.9162e-02, -4.7787e-02,  1.7835e-01,\n",
       "                      -2.5350e-02,  1.3947e-01,  4.5914e-02,  1.6342e-01,  1.1585e-02,\n",
       "                      -2.7268e-02, -7.0741e-02, -7.3770e-02, -1.6192e-02,  1.1991e-01,\n",
       "                      -9.3042e-02,  7.6398e-02,  9.6625e-04,  1.1429e-01, -5.5349e-02,\n",
       "                      -6.4933e-02, -2.1002e-01,  4.3806e-03,  7.9301e-03,  4.4888e-03,\n",
       "                       1.1197e-01, -1.0898e-01,  1.6126e-01, -5.6258e-02,  6.8537e-02,\n",
       "                      -5.4987e-02,  2.0874e-02,  1.6675e-02, -2.8978e-02,  2.0904e-01,\n",
       "                       1.1457e-01,  1.1815e-01,  7.5224e-02,  2.9395e-03,  1.5691e-02,\n",
       "                       9.7557e-02, -1.8913e-02,  1.2209e-01, -8.4427e-02, -1.1219e-01,\n",
       "                       2.4342e-02,  1.1368e-01, -3.0334e-03,  1.8703e-01,  1.0674e-01,\n",
       "                       3.5884e-02,  3.6150e-02, -4.2148e-02,  7.0939e-02, -5.2510e-02,\n",
       "                      -1.0394e-01, -6.2265e-02,  2.4612e-02, -1.1659e-01,  9.9583e-02,\n",
       "                      -1.2409e-01,  1.2987e-01, -1.0682e-01,  1.2009e-01, -7.3495e-02,\n",
       "                       5.7528e-02,  2.3724e-02, -2.0681e-01, -1.9926e-02,  2.1003e-02,\n",
       "                      -2.0856e-01, -1.0600e-01,  7.1733e-02,  9.6997e-03, -1.8087e-01,\n",
       "                       8.5025e-02, -2.5274e-02,  9.8903e-03, -3.2104e-02,  2.0084e-01,\n",
       "                       1.4788e-02, -3.2493e-02, -4.1117e-05,  2.7223e-05,  2.3324e-05,\n",
       "                       3.2174e-05,  5.7001e-06,  9.8032e-06, -2.2645e-05, -2.6448e-05,\n",
       "                      -2.6261e-05,  1.0807e-05,  1.0529e-05,  1.2598e-06, -2.3210e-05,\n",
       "                      -1.0075e-05,  2.1350e-05,  3.2488e-07,  1.1537e-05,  4.0996e-05,\n",
       "                      -1.4404e-05,  3.4469e-05, -2.4751e-05,  3.4033e-05,  9.5206e-07,\n",
       "                      -2.8565e-05, -8.5411e-06,  2.8874e-05,  2.5878e-05, -7.0027e-06,\n",
       "                       1.6861e-05,  2.9996e-05, -8.7277e-06, -1.9519e-05,  9.9292e-06,\n",
       "                      -2.9802e-05,  9.2801e-06,  2.9021e-05,  7.6878e-06,  3.6465e-05,\n",
       "                      -2.3759e-05,  1.7893e-05,  2.3316e-05,  5.8334e-06, -1.1728e-05,\n",
       "                      -5.2025e-07,  4.9771e-06,  1.7426e-05,  1.6842e-05,  3.5901e-05,\n",
       "                       8.7873e-06, -4.0516e-06,  3.4098e-05, -2.2415e-05, -1.5125e-05,\n",
       "                      -8.1865e-06, -1.6379e-05, -2.3339e-05, -3.7938e-05, -1.7359e-06,\n",
       "                       1.5998e-05, -1.3250e-05,  3.0115e-05,  1.5000e-08,  2.5526e-05,\n",
       "                      -1.2002e-05, -1.0470e-05,  1.6522e-05,  2.4301e-05, -8.7592e-06,\n",
       "                       7.2650e-06, -1.7554e-06,  1.6833e-05, -3.1818e-05,  1.1607e-05,\n",
       "                       5.1269e-06,  8.3411e-06,  2.9685e-05,  6.3310e-07,  2.0194e-05,\n",
       "                       2.6849e-05,  4.9527e-06,  4.5823e-06,  1.7965e-05,  6.4048e-08,\n",
       "                       1.8796e-05, -6.2739e-06,  9.2189e-06, -1.7924e-06, -3.2760e-06,\n",
       "                       3.5532e-05,  2.8542e-06,  3.0002e-06, -2.1351e-05,  2.7228e-06,\n",
       "                       2.0856e-05, -4.4865e-06, -1.5871e-05, -1.2225e-05,  2.4682e-06,\n",
       "                       2.0390e-05,  2.6879e-05, -7.3732e-06,  3.0236e-05, -2.5342e-05,\n",
       "                       2.3276e-06, -1.2996e-05, -1.5867e-05,  2.4153e-05, -1.5543e-05,\n",
       "                      -4.9561e-06, -3.5113e-05,  2.7491e-05,  1.5965e-05, -2.1344e-05,\n",
       "                       1.8548e-05,  5.1225e-06, -1.6444e-05,  5.7850e-06, -1.1872e-05,\n",
       "                      -3.5670e-06, -1.2509e-05, -5.3082e-05, -2.6372e-05,  9.1574e-06,\n",
       "                      -1.1352e-05,  6.7288e-06,  1.3977e-05, -2.0874e-05, -2.1436e-05,\n",
       "                      -3.6495e-06,  6.0960e-06, -4.7473e-06, -6.5239e-06,  1.9219e-05,\n",
       "                       3.4517e-05, -1.8189e-05, -6.4308e-06,  1.0599e-05,  1.0881e-05,\n",
       "                       1.3807e-05, -3.0880e-06,  1.1149e-05, -2.1470e-05,  3.2241e-05,\n",
       "                       2.1026e-06,  2.1317e-05, -6.7991e-06, -6.3864e-06,  1.1661e-05,\n",
       "                       1.6584e-05,  3.2481e-06, -7.0850e-06, -5.8154e-06, -1.6962e-06,\n",
       "                       9.0267e-06,  8.7907e-06,  1.0688e-05, -6.3721e-06,  1.6851e-06,\n",
       "                       8.5621e-06,  2.0328e-06,  3.0053e-06, -4.3057e-06, -1.1476e-06,\n",
       "                       5.0789e-06,  1.0789e-05,  1.2439e-06,  2.1969e-06, -1.1371e-06,\n",
       "                       2.1700e-07,  1.1706e-05,  7.9329e-06, -4.7321e-06, -3.4912e-07,\n",
       "                       4.5306e-06,  1.1237e-05,  7.6618e-07, -5.4868e-06, -1.2031e-05,\n",
       "                       1.2998e-05, -3.0944e-06, -1.8788e-06,  1.4276e-05, -6.0703e-07,\n",
       "                       9.2726e-07,  1.6793e-05,  1.8843e-06,  1.3697e-05,  1.8897e-06,\n",
       "                      -2.0896e-06, -1.1035e-05, -1.4035e-05,  3.0443e-06, -1.2417e-03,\n",
       "                       1.2986e-02,  1.7110e-02,  2.8946e-02, -2.5770e-02, -2.2517e-02,\n",
       "                      -1.6412e-02, -2.6122e-02,  6.4382e-03, -2.9509e-02,  1.3172e-02,\n",
       "                       5.9058e-03,  7.4972e-03,  8.5920e-03,  2.4156e-02,  5.1145e-03,\n",
       "                      -2.6836e-02, -3.2139e-02,  3.4703e-02, -2.0623e-02, -5.3632e-03,\n",
       "                      -4.5038e-03, -9.3564e-03, -2.0998e-02, -2.6330e-02, -2.6907e-02,\n",
       "                       5.0041e-02, -1.3542e-02,  3.9234e-03,  5.7549e-02,  1.7672e-02,\n",
       "                       4.5998e-03,  4.3968e-02, -2.1731e-02, -3.5134e-02,  1.5940e-02,\n",
       "                       4.1254e-02, -1.5624e-02, -1.4713e-03,  2.0806e-03, -2.4027e-02,\n",
       "                       1.0437e-02, -5.0316e-02,  3.3368e-02,  2.1649e-03,  3.8862e-03,\n",
       "                       2.1318e-02, -2.1336e-02,  1.6735e-02, -8.0728e-03,  1.4615e-02,\n",
       "                       6.2820e-03, -7.2301e-03, -1.8009e-02,  2.9891e-02, -1.8430e-02,\n",
       "                      -7.9581e-03, -1.0302e-02, -2.0487e-02,  2.0978e-02, -2.6380e-02,\n",
       "                      -2.4799e-02, -4.5737e-03, -4.4790e-03, -3.0404e-02, -8.8197e-03,\n",
       "                       4.8223e-03,  2.4362e-02,  1.9523e-02, -1.5462e-02, -2.1916e-02,\n",
       "                      -1.8568e-02,  4.0839e-03, -1.2365e-02, -3.6640e-03, -7.4302e-03,\n",
       "                       6.3905e-03,  2.0606e-03, -2.2020e-03,  1.6706e-02, -1.8979e-02,\n",
       "                       2.0243e-02, -2.4288e-02, -3.9204e-02,  4.0020e-03, -9.8654e-03,\n",
       "                       1.8450e-03,  2.9801e-02, -8.4133e-03,  1.3646e-02,  1.8222e-02,\n",
       "                      -1.3713e-02, -4.2595e-03, -2.2416e-04,  1.1639e-02, -1.4164e-02,\n",
       "                       2.1221e-02,  2.4912e-02,  8.2495e-03,  5.8912e-03,  1.7524e-02,\n",
       "                       2.2233e-02, -2.6181e-02, -2.2839e-03, -2.0001e-02, -8.3314e-03,\n",
       "                      -2.4315e-02,  2.6870e-02, -2.0131e-02, -4.3033e-02,  1.9417e-02,\n",
       "                      -9.2477e-03,  7.5161e-03,  1.1657e-02, -2.4600e-02, -1.6079e-03,\n",
       "                      -1.1613e-02,  2.3990e-03, -3.9418e-03,  1.0759e-02,  1.6646e-02,\n",
       "                       6.1001e-03, -2.8120e-04, -9.0739e-03, -8.7504e-03, -9.8231e-03,\n",
       "                       1.6593e-02,  3.1811e-03, -2.0796e-02, -4.3438e-03, -2.3748e-02,\n",
       "                      -2.9214e-03, -2.4150e-02,  1.1972e-02,  2.0657e-02,  2.0410e-02,\n",
       "                      -2.4166e-02, -1.1841e-02,  9.0982e-03, -1.6724e-02,  3.8315e-02,\n",
       "                       1.7728e-02,  1.4104e-03,  6.0435e-03,  5.3134e-03, -8.8090e-04,\n",
       "                       2.7553e-03,  3.0202e-02, -1.4383e-02,  1.6060e-02,  6.6492e-03,\n",
       "                      -3.5899e-02, -2.8970e-02, -2.1914e-02,  1.1662e-02, -5.6504e-02,\n",
       "                      -2.1874e-02,  1.5731e-02,  4.3625e-03, -3.3903e-02,  3.3354e-03,\n",
       "                       9.8275e-04,  6.8465e-04,  1.8499e-02,  3.2426e-02,  6.2430e-02,\n",
       "                       6.2513e-03, -3.3024e-03, -1.1179e-02, -2.5409e-03,  1.4897e-02,\n",
       "                      -1.6796e-02, -2.3393e-02, -1.0614e-02,  4.5039e-02, -1.4194e-02,\n",
       "                       2.8163e-02,  9.0386e-03, -4.2222e-03, -3.1192e-02,  7.6414e-03,\n",
       "                      -2.5173e-02, -2.4883e-02, -2.2236e-02,  4.4253e-02, -4.6075e-06,\n",
       "                      -2.7811e-02,  9.4191e-03, -3.3411e-02, -7.6351e-03,  1.5647e-03,\n",
       "                      -1.4231e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.out_proj.weight',\n",
       "              tensor([[-0.0059,  0.0194,  0.0176,  ..., -0.0292,  0.0565,  0.0259],\n",
       "                      [ 0.0185, -0.0124, -0.0953,  ...,  0.0345, -0.0260,  0.0659],\n",
       "                      [-0.0256, -0.0572,  0.0228,  ...,  0.0291,  0.0632,  0.0159],\n",
       "                      ...,\n",
       "                      [-0.0546,  0.0549, -0.0161,  ..., -0.0509, -0.0635,  0.0253],\n",
       "                      [ 0.0032, -0.0369,  0.0664,  ..., -0.0100, -0.0601,  0.0399],\n",
       "                      [ 0.0765,  0.0205, -0.0186,  ..., -0.0496, -0.0788, -0.0422]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.multihead_attn.out_proj.bias',\n",
       "              tensor([-0.0046, -0.0390, -0.0213,  0.0041, -0.0133,  0.0255,  0.0131, -0.0110,\n",
       "                       0.0093,  0.0288,  0.0300,  0.0075,  0.0213, -0.0053,  0.0313, -0.0094,\n",
       "                       0.0030,  0.0099,  0.0037,  0.0432, -0.0034, -0.0020,  0.0028,  0.0200,\n",
       "                      -0.0218,  0.0318,  0.0109,  0.0560,  0.0434, -0.0144, -0.0268,  0.0173,\n",
       "                      -0.0095, -0.0119, -0.0198, -0.0083, -0.0297,  0.0154,  0.0116,  0.0057,\n",
       "                      -0.0145, -0.0016,  0.0119,  0.0030, -0.0191,  0.0091,  0.0134, -0.0010,\n",
       "                      -0.0080, -0.0055,  0.0062,  0.0026,  0.0146, -0.0415, -0.0024, -0.0013,\n",
       "                      -0.0172,  0.0127,  0.0254,  0.0166,  0.0322,  0.0038,  0.0069,  0.0182,\n",
       "                       0.0129,  0.0120, -0.0217, -0.0100, -0.0262,  0.0065,  0.0059,  0.0133,\n",
       "                       0.0148, -0.0301, -0.0139, -0.0144,  0.0209, -0.0129, -0.0274, -0.0055,\n",
       "                      -0.0176, -0.0116,  0.0064,  0.0098, -0.0010,  0.0266, -0.0059,  0.0448,\n",
       "                       0.0126, -0.0032, -0.0306,  0.0099, -0.0085, -0.0051,  0.0221, -0.0005,\n",
       "                      -0.0008, -0.0072,  0.0263, -0.0060, -0.0043, -0.0212, -0.0244, -0.0057,\n",
       "                      -0.0159,  0.0009,  0.0251, -0.0106, -0.0172, -0.0027,  0.0011, -0.0136,\n",
       "                       0.0402,  0.0243, -0.0023,  0.0054,  0.0274,  0.0048,  0.0297, -0.0070,\n",
       "                      -0.0200,  0.0033,  0.0073,  0.0115, -0.0380,  0.0022,  0.0298,  0.0092,\n",
       "                       0.0055,  0.0277, -0.0236, -0.0019,  0.0163, -0.0184,  0.0004, -0.0122,\n",
       "                       0.0005, -0.0268,  0.0013, -0.0336, -0.0122,  0.0113,  0.0137,  0.0034,\n",
       "                      -0.0182, -0.0154,  0.0276, -0.0253,  0.0123, -0.0533,  0.0128,  0.0073,\n",
       "                      -0.0157, -0.0139, -0.0295, -0.0181,  0.0296,  0.0030,  0.0008, -0.0124,\n",
       "                      -0.0151, -0.0158, -0.0128,  0.0025, -0.0088,  0.0237, -0.0107, -0.0217,\n",
       "                       0.0003, -0.0268, -0.0175, -0.0081, -0.0430, -0.0006,  0.0335, -0.0352,\n",
       "                      -0.0070, -0.0085, -0.0054,  0.0167,  0.0291, -0.0116,  0.0151, -0.0091,\n",
       "                       0.0039, -0.0374, -0.0186,  0.0028,  0.0069, -0.0265, -0.0110,  0.0177],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear1.weight',\n",
       "              tensor([[ 0.0315,  0.0020, -0.0214,  ...,  0.0625, -0.0140,  0.0430],\n",
       "                      [-0.0332, -0.0116, -0.0333,  ...,  0.0123,  0.0962,  0.0318],\n",
       "                      [ 0.0176,  0.0624,  0.0023,  ...,  0.0043, -0.0408, -0.0713],\n",
       "                      ...,\n",
       "                      [ 0.0034, -0.0222, -0.0172,  ...,  0.0616, -0.0484, -0.0138],\n",
       "                      [-0.0903,  0.1201,  0.0455,  ...,  0.0744,  0.0083, -0.0166],\n",
       "                      [ 0.0174, -0.0477,  0.0110,  ...,  0.0345,  0.0207, -0.0004]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear1.bias',\n",
       "              tensor([-0.0123, -0.0777, -0.1128,  ..., -0.0315, -0.0392, -0.1384],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear2.weight',\n",
       "              tensor([[-0.0004, -0.0038, -0.0331,  ...,  0.0354, -0.0150,  0.0024],\n",
       "                      [ 0.0365, -0.0252, -0.0177,  ...,  0.0002,  0.0386,  0.0061],\n",
       "                      [ 0.0007, -0.0517,  0.0137,  ..., -0.0052,  0.0227, -0.0482],\n",
       "                      ...,\n",
       "                      [ 0.0326,  0.0009, -0.0065,  ..., -0.0114,  0.0102,  0.0077],\n",
       "                      [ 0.0342, -0.0072,  0.0182,  ...,  0.0495,  0.0420, -0.0258],\n",
       "                      [ 0.0363,  0.0280,  0.0295,  ...,  0.0480, -0.0108,  0.0228]],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.linear2.bias',\n",
       "              tensor([-0.0728,  0.0723, -0.0512,  0.0804, -0.0300,  0.0526,  0.0555,  0.0696,\n",
       "                      -0.0574, -0.0719,  0.0583,  0.0234, -0.0683,  0.1099, -0.0511,  0.0811,\n",
       "                       0.0261, -0.0471, -0.0725,  0.0384,  0.0786,  0.0769,  0.0104,  0.0503,\n",
       "                      -0.0355,  0.0548, -0.0192, -0.0366, -0.0683,  0.0580,  0.0499, -0.0842,\n",
       "                       0.0502,  0.0561,  0.0447,  0.0171,  0.0201,  0.0572,  0.0450, -0.0725,\n",
       "                       0.0780,  0.0468, -0.0439,  0.0454,  0.0638, -0.0927, -0.0427, -0.0281,\n",
       "                       0.0752,  0.0562, -0.0777,  0.0534,  0.0663, -0.0388,  0.0682, -0.0765,\n",
       "                       0.0948,  0.0716,  0.0091, -0.0602, -0.0377, -0.0689, -0.0661, -0.0538,\n",
       "                       0.0344,  0.0584,  0.0329, -0.0520, -0.0124,  0.0563, -0.0630, -0.0340,\n",
       "                       0.0377,  0.0391,  0.0627, -0.0854, -0.0138, -0.0651,  0.0372, -0.0558,\n",
       "                      -0.0178, -0.0322, -0.0804, -0.0608,  0.0079, -0.0209,  0.0522, -0.0765,\n",
       "                       0.0517,  0.0731,  0.0145,  0.0681, -0.0408, -0.0925, -0.0676, -0.0315,\n",
       "                      -0.0133, -0.1050, -0.0100, -0.0068,  0.0684,  0.0593,  0.0403,  0.0149,\n",
       "                       0.0581,  0.0197,  0.0100, -0.0056,  0.0545, -0.0304, -0.0657, -0.0251,\n",
       "                      -0.0581,  0.0793,  0.0424, -0.0865,  0.0749, -0.0933,  0.0927,  0.0431,\n",
       "                      -0.0673, -0.0661, -0.0136, -0.0408, -0.0432, -0.0688,  0.0893,  0.0784,\n",
       "                      -0.0007, -0.0659,  0.0664, -0.0348, -0.0613, -0.0126,  0.0096,  0.0386,\n",
       "                       0.0082, -0.0103, -0.0681, -0.0163, -0.0317, -0.0590,  0.0967, -0.0443,\n",
       "                       0.0330,  0.0531,  0.0273, -0.0614, -0.0460,  0.0621,  0.0620,  0.0021,\n",
       "                       0.0637, -0.0263,  0.0843,  0.0391, -0.0222, -0.0303, -0.0017, -0.0741,\n",
       "                       0.0401,  0.0648, -0.0611, -0.0372,  0.0425, -0.0816, -0.0172, -0.0705,\n",
       "                      -0.0371, -0.1074,  0.0532,  0.0011, -0.0363, -0.0571, -0.0407,  0.0491,\n",
       "                      -0.0022, -0.0471,  0.0585, -0.0725, -0.0345,  0.0369, -0.0409,  0.0142,\n",
       "                       0.0480, -0.0611, -0.0693,  0.0912,  0.0636, -0.0551,  0.0640,  0.0256],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm1.weight',\n",
       "              tensor([0.9731, 0.8455, 0.9837, 1.0036, 0.9621, 0.9957, 0.9784, 0.9806, 0.9593,\n",
       "                      0.9068, 0.9514, 0.9911, 0.9506, 1.0348, 0.9797, 0.9808, 0.9744, 0.9782,\n",
       "                      0.9860, 0.9780, 1.0024, 0.9764, 1.0013, 0.9711, 0.9924, 0.9625, 0.9387,\n",
       "                      0.9430, 0.8797, 0.9367, 1.0149, 0.9653, 0.9861, 1.0104, 0.9464, 1.0102,\n",
       "                      0.9693, 0.9710, 0.9649, 0.9702, 1.0018, 1.0131, 0.9428, 1.0015, 0.9554,\n",
       "                      1.0018, 0.9960, 0.9837, 0.9992, 1.0006, 0.9862, 0.9970, 0.9938, 0.9823,\n",
       "                      0.9613, 0.9825, 0.9944, 0.9515, 0.9984, 0.9970, 0.9892, 0.9772, 0.9622,\n",
       "                      0.9577, 0.8811, 0.9697, 0.9908, 0.9699, 0.9944, 0.9795, 1.0141, 1.0081,\n",
       "                      0.9742, 0.9797, 1.0149, 0.9584, 0.9850, 0.9971, 1.0124, 0.9546, 1.0109,\n",
       "                      0.9359, 0.9818, 0.9832, 0.9814, 1.0288, 0.9974, 0.9397, 1.0160, 0.9666,\n",
       "                      1.0069, 0.9276, 0.9554, 0.9330, 1.0347, 0.9899, 1.0282, 0.9848, 1.0288,\n",
       "                      0.9977, 1.0132, 0.9613, 0.9992, 0.9769, 0.9951, 0.9632, 1.0041, 0.9878,\n",
       "                      0.9869, 1.0040, 1.0105, 0.9984, 1.0036, 1.0026, 0.9865, 0.9458, 0.9694,\n",
       "                      0.9669, 0.9967, 0.9480, 0.9669, 1.0065, 0.9947, 0.9305, 1.0410, 0.9450,\n",
       "                      1.0363, 0.9947, 1.0298, 0.9041, 1.0149, 0.9766, 0.9643, 0.9549, 1.0312,\n",
       "                      0.9675, 1.0077, 0.9833, 1.0071, 0.9420, 1.0136, 0.9795, 0.9982, 1.0080,\n",
       "                      1.0197, 0.9631, 1.0128, 0.9857, 0.9721, 0.9482, 1.0020, 0.9332, 0.9949,\n",
       "                      0.9902, 0.9549, 0.9517, 0.9958, 0.9875, 1.0339, 0.9789, 1.0125, 0.9474,\n",
       "                      0.9837, 0.9026, 1.0183, 0.9507, 1.0527, 0.9604, 1.0299, 0.9629, 1.0224,\n",
       "                      0.9452, 0.9818, 0.9830, 1.0441, 0.9945, 0.9615, 0.9455, 1.0376, 0.9900,\n",
       "                      0.9857, 0.9615, 1.0278, 0.9556, 1.0060, 1.0015, 1.0358, 0.9474, 0.9050,\n",
       "                      0.9742, 1.0229, 0.9913], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm1.bias',\n",
       "              tensor([ 0.0198, -0.0869,  0.0126, -0.0674,  0.0581, -0.0429,  0.0935,  0.0003,\n",
       "                       0.0501,  0.1397, -0.0256, -0.0095,  0.1157, -0.0771,  0.1142, -0.0662,\n",
       "                      -0.0338,  0.0047,  0.0477,  0.1550, -0.0794, -0.0682, -0.0354,  0.0389,\n",
       "                      -0.0712,  0.0525,  0.0436,  0.0689,  0.0550, -0.0285, -0.1059,  0.1068,\n",
       "                      -0.0190, -0.1067, -0.0418, -0.0710, -0.1003, -0.0755, -0.0256,  0.0569,\n",
       "                      -0.1083, -0.0130,  0.0313, -0.0317, -0.0942,  0.0184,  0.0650,  0.0326,\n",
       "                      -0.0592, -0.0801,  0.0189, -0.0276, -0.0660, -0.0598, -0.0486,  0.0616,\n",
       "                      -0.0889, -0.1056,  0.0841,  0.0904,  0.1379, -0.0034,  0.0332,  0.0366,\n",
       "                       0.0367, -0.0464, -0.0651, -0.0215, -0.0330, -0.0781,  0.1470,  0.0598,\n",
       "                       0.0352, -0.0929, -0.1209,  0.0768,  0.0355, -0.0047, -0.0092, -0.0115,\n",
       "                      -0.0098, -0.0993,  0.1376,  0.0528, -0.0365,  0.0321, -0.0874,  0.1204,\n",
       "                      -0.0297, -0.0483, -0.0123, -0.1384,  0.0777,  0.0461,  0.0854, -0.0174,\n",
       "                       0.0564,  0.0787,  0.1205,  0.0074,  0.0752, -0.1571, -0.0133,  0.0455,\n",
       "                      -0.0957, -0.0833,  0.0182, -0.1271, -0.0036,  0.0162,  0.0601,  0.0190,\n",
       "                       0.1787, -0.0917,  0.0319, -0.0501, -0.0059,  0.1064,  0.0314, -0.1634,\n",
       "                       0.0655,  0.0594,  0.0747,  0.0355,  0.0278,  0.0098,  0.0036, -0.0641,\n",
       "                      -0.0152,  0.0107, -0.1165,  0.0419,  0.2074, -0.0610,  0.0572, -0.0853,\n",
       "                      -0.0377,  0.0434,  0.1225, -0.1124, -0.0291,  0.0578, -0.0687,  0.0232,\n",
       "                       0.0508, -0.0772, -0.0152, -0.0011,  0.0820, -0.0721, -0.0457, -0.1113,\n",
       "                      -0.0302,  0.0409, -0.0213, -0.1605,  0.0651,  0.0701,  0.0296,  0.0032,\n",
       "                      -0.0193,  0.0060,  0.1141, -0.0261, -0.0179,  0.0563,  0.0035, -0.0646,\n",
       "                      -0.0505,  0.0320, -0.0691, -0.0640,  0.0690,  0.0529,  0.1879, -0.1739,\n",
       "                       0.0594, -0.0182, -0.0813,  0.0973,  0.0430, -0.0603,  0.1456, -0.0096,\n",
       "                       0.0439,  0.0018,  0.0080, -0.0532, -0.0253, -0.0576, -0.0771, -0.0186],\n",
       "                     device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm2.weight',\n",
       "              tensor([0.9742, 0.8801, 0.9925, 1.0076, 0.9853, 1.0096, 0.9951, 1.0002, 0.9659,\n",
       "                      0.9282, 0.9661, 0.9978, 0.9790, 1.0367, 0.9862, 0.9805, 0.9821, 0.9732,\n",
       "                      0.9930, 1.0025, 1.0099, 0.9891, 1.0105, 0.9630, 1.0084, 0.9679, 0.9538,\n",
       "                      0.9524, 0.9181, 0.9618, 1.0292, 0.9847, 1.0018, 1.0069, 0.9671, 1.0225,\n",
       "                      1.0126, 0.9757, 0.9812, 0.9737, 1.0053, 1.0297, 0.9820, 1.0080, 0.9823,\n",
       "                      1.0176, 0.9977, 0.9868, 1.0124, 1.0061, 1.0137, 1.0125, 1.0068, 1.0081,\n",
       "                      0.9690, 0.9846, 1.0079, 0.9991, 1.0257, 0.9994, 1.0046, 0.9850, 0.9766,\n",
       "                      0.9791, 0.8851, 0.9933, 1.0005, 0.9850, 1.0057, 1.0012, 1.0231, 1.0268,\n",
       "                      0.9809, 0.9930, 1.0223, 0.9670, 1.0029, 1.0076, 1.0276, 0.9635, 1.0022,\n",
       "                      0.9630, 1.0138, 0.9847, 0.9826, 1.0317, 1.0011, 0.9550, 1.0192, 0.9650,\n",
       "                      1.0355, 0.9717, 0.9788, 0.9537, 1.0243, 0.9922, 1.0266, 0.9929, 1.0278,\n",
       "                      1.0074, 1.0352, 0.9793, 0.9930, 1.0136, 1.0113, 0.9750, 0.9958, 0.9881,\n",
       "                      1.0054, 1.0002, 1.0151, 1.0088, 1.0201, 1.0294, 1.0005, 0.9633, 0.9834,\n",
       "                      0.9772, 1.0177, 0.9903, 0.9630, 1.0071, 0.9940, 0.9375, 1.0521, 0.9581,\n",
       "                      1.0328, 0.9951, 1.0322, 0.9090, 1.0275, 0.9719, 0.9926, 0.9622, 1.0347,\n",
       "                      0.9659, 1.0227, 0.9895, 1.0429, 0.9608, 1.0346, 0.9927, 1.0206, 1.0072,\n",
       "                      1.0072, 0.9722, 1.0197, 0.9781, 0.9958, 0.9757, 1.0086, 0.9489, 1.0016,\n",
       "                      1.0070, 0.9726, 1.0091, 1.0300, 0.9934, 1.0247, 0.9843, 0.9973, 0.9706,\n",
       "                      0.9963, 0.9191, 1.0301, 0.9525, 1.0398, 0.9668, 1.0269, 0.9723, 1.0349,\n",
       "                      0.9451, 1.0042, 0.9918, 1.0562, 1.0271, 0.9564, 0.9491, 1.0341, 1.0058,\n",
       "                      1.0063, 0.9541, 1.0300, 0.9608, 1.0119, 1.0126, 1.0391, 0.9559, 0.9391,\n",
       "                      0.9776, 1.0254, 0.9866], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm2.bias',\n",
       "              tensor([-6.8920e-03, -7.2111e-02,  7.9891e-03, -5.9260e-02,  5.5812e-02,\n",
       "                      -4.0608e-02,  1.0242e-01,  1.8335e-03,  1.9658e-02,  1.2593e-01,\n",
       "                      -3.3519e-02, -1.4055e-02,  1.0899e-01, -6.4207e-02,  1.0087e-01,\n",
       "                      -6.2346e-02, -2.5078e-02, -2.2093e-02,  2.8857e-02,  1.6391e-01,\n",
       "                      -6.0728e-02, -6.6126e-02, -3.3980e-02,  4.5222e-02, -8.5235e-02,\n",
       "                       5.1175e-02,  2.3125e-02,  4.2020e-02,  2.6068e-02, -2.8990e-02,\n",
       "                      -9.2827e-02,  8.8299e-02, -5.6933e-03, -9.7521e-02, -3.1562e-02,\n",
       "                      -4.4766e-02, -8.0784e-02, -8.1661e-02, -3.1638e-02,  5.7038e-02,\n",
       "                      -1.0289e-01, -1.0766e-02, -1.4374e-03, -3.1641e-02, -9.6235e-02,\n",
       "                       5.0753e-03,  4.7085e-02,  1.9778e-02, -6.0350e-02, -5.9486e-02,\n",
       "                       8.1317e-03, -3.0062e-02, -5.6837e-02, -6.1819e-02, -4.3450e-02,\n",
       "                       4.1574e-02, -7.2482e-02, -1.0855e-01,  8.8677e-02,  8.3320e-02,\n",
       "                       1.3007e-01, -2.1862e-02,  2.1758e-02,  1.5764e-02,  5.9907e-02,\n",
       "                      -4.0504e-02, -5.4790e-02, -2.3311e-02, -5.3295e-02, -7.9235e-02,\n",
       "                       1.4554e-01,  5.0846e-02,  3.3909e-02, -8.2725e-02, -1.1319e-01,\n",
       "                       5.7359e-02,  2.2162e-02, -1.8503e-02, -4.6059e-03, -3.1436e-02,\n",
       "                      -2.1263e-02, -1.2375e-01,  1.3234e-01,  3.2774e-02, -3.1062e-02,\n",
       "                       4.0217e-03, -8.6824e-02,  9.1485e-02, -2.1540e-02, -3.7683e-02,\n",
       "                      -1.2644e-02, -1.4852e-01,  7.8963e-02,  3.6596e-02,  5.6371e-02,\n",
       "                      -5.4107e-02,  4.6956e-02,  6.4316e-02,  1.1535e-01, -4.2919e-05,\n",
       "                       9.6756e-02, -1.5499e-01, -1.5210e-02,  2.8213e-02, -8.4908e-02,\n",
       "                      -9.3644e-02,  1.5095e-02, -1.4895e-01, -4.0220e-05, -8.2155e-03,\n",
       "                       4.6576e-02,  1.8349e-02,  1.4895e-01, -9.7923e-02,  4.1825e-02,\n",
       "                      -7.2580e-02, -1.1028e-02,  8.9832e-02,  4.7372e-02, -1.6943e-01,\n",
       "                       5.6088e-02,  5.8194e-02,  7.6173e-02,  2.4986e-02,  3.7966e-02,\n",
       "                       2.6056e-03,  9.8641e-04, -5.4875e-02, -1.0071e-02, -1.8660e-02,\n",
       "                      -9.9124e-02,  1.8528e-02,  1.9838e-01, -6.5790e-02,  3.8815e-02,\n",
       "                      -9.2702e-02, -3.3865e-02,  3.2837e-02,  1.1691e-01, -1.2156e-01,\n",
       "                      -3.4788e-02,  2.5079e-02, -7.2349e-02, -1.3093e-03,  6.1893e-02,\n",
       "                      -6.5288e-02, -2.6841e-02, -7.9301e-03,  7.3063e-02, -4.9616e-02,\n",
       "                      -2.6508e-02, -1.2164e-01, -1.6969e-02,  3.7896e-02, -2.6305e-03,\n",
       "                      -1.7341e-01,  3.5728e-02,  6.8970e-02,  2.7231e-02, -5.8719e-03,\n",
       "                       1.0030e-02,  3.1528e-02,  1.0657e-01, -4.8645e-02, -8.1379e-03,\n",
       "                       3.9293e-02, -1.1886e-02, -7.2036e-02, -6.1012e-02,  1.7504e-02,\n",
       "                      -5.3645e-02, -8.0437e-02,  7.9758e-02,  4.7421e-02,  1.8195e-01,\n",
       "                      -1.6304e-01,  5.7535e-02, -4.0829e-02, -7.4070e-02,  9.5699e-02,\n",
       "                       3.9215e-02, -4.3308e-02,  1.4764e-01, -1.1513e-02,  5.2592e-02,\n",
       "                      -1.6017e-02,  1.7335e-02, -4.3716e-02, -2.9863e-02, -7.7705e-02,\n",
       "                      -6.0049e-02, -3.3052e-02], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm3.weight',\n",
       "              tensor([1.5975, 1.2724, 1.6548, 1.5620, 1.5888, 1.4758, 1.6184, 1.6951, 1.5243,\n",
       "                      1.4638, 1.5494, 1.4919, 1.4811, 1.4739, 1.4174, 1.4991, 1.6934, 1.6613,\n",
       "                      1.5637, 1.5082, 1.5144, 1.4759, 1.5891, 1.6599, 1.6046, 1.5935, 1.5738,\n",
       "                      1.5326, 1.4682, 1.4928, 1.5036, 1.5927, 1.5237, 1.5367, 1.5264, 1.6365,\n",
       "                      1.6331, 1.5854, 1.6481, 1.5102, 1.5754, 1.6723, 1.7262, 1.6386, 1.4230,\n",
       "                      1.6149, 1.6269, 1.5825, 1.5622, 1.4946, 1.6169, 1.5873, 1.5803, 1.6863,\n",
       "                      1.5078, 1.4214, 1.5883, 1.5988, 1.6939, 1.5567, 1.5356, 1.6329, 1.4972,\n",
       "                      1.5688, 1.4995, 1.5494, 1.5703, 1.6860, 1.6307, 1.5239, 1.4986, 1.3610,\n",
       "                      1.6621, 1.5923, 1.5038, 1.5266, 1.6668, 1.6143, 1.5333, 1.6409, 1.7163,\n",
       "                      1.5194, 1.6427, 1.5934, 1.6433, 1.5330, 1.3579, 1.1677, 1.4122, 1.5534,\n",
       "                      1.5612, 1.5729, 1.5860, 1.5081, 1.6167, 1.4766, 1.6344, 1.5414, 1.5861,\n",
       "                      1.6728, 1.6470, 1.5270, 1.6229, 1.6673, 1.5391, 1.6425, 1.5835, 1.4465,\n",
       "                      1.6218, 1.6223, 1.5890, 1.6183, 1.4834, 1.5697, 1.5915, 1.6561, 1.5420,\n",
       "                      1.4091, 1.6105, 1.5370, 1.5680, 1.5285, 1.4782, 1.3529, 1.6642, 1.5768,\n",
       "                      1.6011, 1.5639, 1.6438, 1.4897, 1.5292, 1.5429, 1.3970, 1.6128, 1.6716,\n",
       "                      1.5921, 1.6126, 1.6582, 1.5526, 1.4635, 1.4761, 1.6187, 1.4952, 1.6069,\n",
       "                      1.4046, 1.5375, 1.5449, 1.6226, 1.6520, 1.5129, 1.6531, 1.5954, 1.6067,\n",
       "                      1.6175, 1.5102, 1.3445, 1.6366, 1.4525, 1.6684, 1.5970, 1.6105, 1.5532,\n",
       "                      1.6115, 1.5977, 1.6835, 1.4844, 1.6495, 1.5761, 1.5711, 1.5903, 1.5764,\n",
       "                      1.5800, 1.6468, 1.4435, 1.4853, 1.5279, 1.5721, 1.6540, 1.4830, 1.4447,\n",
       "                      1.4530, 1.6237, 1.4736, 1.5924, 1.7227, 1.6058, 1.7411, 1.4939, 1.5363,\n",
       "                      1.4588, 1.6092, 1.6925], device='cuda:0')),\n",
       "             ('transformer_decoder.layers.1.norm3.bias',\n",
       "              tensor([-2.1745e-02, -3.7432e-02,  9.1398e-02, -4.1320e-02,  3.1379e-02,\n",
       "                      -6.1644e-02,  9.6546e-02,  2.8034e-02, -3.1854e-02,  6.8596e-02,\n",
       "                      -1.2323e-01,  1.1661e-02,  1.6202e-02, -1.2381e-01,  8.6480e-02,\n",
       "                      -5.8939e-02,  2.9780e-02, -1.2212e-03,  6.2275e-02, -3.1589e-02,\n",
       "                      -8.3103e-02,  1.1854e-03,  1.2437e-02,  4.1205e-02,  4.1702e-02,\n",
       "                       9.3354e-02, -4.5256e-02,  4.3816e-03, -4.4604e-02,  5.3999e-02,\n",
       "                      -1.9950e-02,  1.2070e-01, -1.7267e-02, -1.6632e-01,  8.4606e-02,\n",
       "                       1.8302e-02, -1.2448e-02,  1.2394e-02,  1.3967e-02,  8.4074e-03,\n",
       "                      -6.2931e-02,  8.9536e-02, -8.0722e-02, -1.1229e-03, -2.6511e-02,\n",
       "                       1.9918e-02,  3.9635e-02,  1.3602e-02, -4.6308e-02, -4.1713e-02,\n",
       "                       7.2625e-02, -3.7655e-03,  5.8490e-02, -8.1118e-02,  1.7010e-02,\n",
       "                      -2.1432e-02, -6.9998e-02, -4.1613e-02,  5.8596e-02,  7.4762e-02,\n",
       "                       3.3998e-02, -1.8953e-02, -4.4246e-02, -2.5177e-02,  1.3385e-01,\n",
       "                      -3.5204e-02, -1.8826e-02,  4.2173e-02, -6.9824e-02, -5.1474e-02,\n",
       "                       8.0345e-02, -2.2259e-02,  7.4933e-02,  3.9226e-03, -8.5856e-02,\n",
       "                      -1.5467e-03, -5.7900e-02,  3.4713e-02, -6.3154e-02, -6.3245e-02,\n",
       "                      -1.8890e-02, -4.6423e-02,  1.0968e-01,  7.3472e-02, -2.3538e-03,\n",
       "                       3.4127e-02,  5.6415e-02, -4.6972e-02,  9.3600e-04, -3.3573e-02,\n",
       "                       2.3302e-02, -1.0016e-01,  8.3620e-02,  8.4229e-02,  2.8950e-02,\n",
       "                      -3.6067e-02, -3.6434e-03,  8.7206e-02,  8.3662e-02, -3.3972e-02,\n",
       "                       5.6259e-02, -3.2464e-02, -6.7635e-02, -9.7480e-02, -4.9164e-02,\n",
       "                      -1.0579e-01,  6.9177e-02, -4.9910e-02,  1.2666e-01, -6.0323e-02,\n",
       "                       6.7384e-03,  1.3177e-02,  1.0023e-01, -6.8097e-02,  4.8643e-02,\n",
       "                      -6.8356e-02,  3.6083e-02,  1.0359e-01,  4.7605e-02, -8.2346e-02,\n",
       "                       4.0556e-02,  7.5959e-02, -7.4442e-02, -6.0737e-02,  4.5956e-02,\n",
       "                       2.3323e-02, -3.7467e-02, -4.0692e-02, -1.7497e-02, -1.7762e-02,\n",
       "                      -5.7937e-02, -8.8918e-02,  9.5461e-02,  4.9966e-03,  3.5089e-02,\n",
       "                      -2.9846e-02,  7.0613e-03, -6.9217e-02,  9.9124e-02, -5.5895e-02,\n",
       "                       7.3908e-02,  4.2186e-03, -6.6830e-02,  2.2228e-03,  1.3826e-03,\n",
       "                      -5.0106e-02, -8.1044e-02,  8.6144e-02,  9.9316e-02,  5.8107e-02,\n",
       "                      -4.2341e-03, -1.2161e-01,  1.7558e-02, -2.0554e-02,  6.4554e-02,\n",
       "                       6.3170e-02, -5.9232e-02,  3.0071e-02, -9.1322e-02,  1.1285e-02,\n",
       "                       1.0183e-01,  9.0252e-02,  6.0811e-02, -5.7993e-02, -8.9038e-03,\n",
       "                       3.9626e-02, -3.0313e-02, -6.0946e-02, -6.2827e-02,  5.1603e-02,\n",
       "                      -4.9608e-02, -1.0293e-01,  9.8684e-02,  5.9090e-02,  8.2171e-02,\n",
       "                      -1.2210e-01,  2.2958e-02,  1.0011e-04,  1.1252e-02,  1.1200e-01,\n",
       "                       4.7166e-02, -3.9170e-02,  7.1433e-02,  5.6726e-02,  1.1172e-01,\n",
       "                       3.0972e-02,  1.0202e-01, -2.1346e-02, -1.0029e-03, -2.3210e-02,\n",
       "                       4.9386e-02,  1.7554e-02], device='cuda:0')),\n",
       "             ('word_emb.weight',\n",
       "              tensor([[-0.0231, -0.1089, -0.0314,  ..., -0.0823,  0.0072, -0.0278],\n",
       "                      [-0.0085, -0.1220,  0.0351,  ..., -0.0374,  0.0094, -0.0614],\n",
       "                      [-0.0476,  0.0218, -0.0224,  ...,  0.0235, -0.0009, -0.0247],\n",
       "                      ...,\n",
       "                      [-0.0081, -0.0108,  0.0223,  ...,  0.0252,  0.0296,  0.0094],\n",
       "                      [-0.0247, -0.0056, -0.0418,  ...,  0.0059, -0.0127, -0.0348],\n",
       "                      [ 0.0083, -0.0188,  0.0275,  ...,  0.0063,  0.0331,  0.0015]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.weight',\n",
       "              tensor([[ 0.1444,  0.0340,  0.0644,  ..., -0.0600,  0.0713,  0.0388],\n",
       "                      [-0.0251,  0.0054, -0.0187,  ..., -0.0408,  0.0636, -0.0873],\n",
       "                      [-0.0032,  0.0023, -0.0051,  ...,  0.0436, -0.0230,  0.0074],\n",
       "                      ...,\n",
       "                      [-0.1845,  0.0455,  0.0306,  ..., -0.0771,  0.1305, -0.0463],\n",
       "                      [ 0.0742,  0.0575,  0.0213,  ..., -0.0602, -0.1442,  0.0134],\n",
       "                      [-0.0883, -0.0248, -0.0477,  ..., -0.0651,  0.1710,  0.0396]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.bias',\n",
       "              tensor([ 0.0367,  0.0367,  0.0446,  0.0219,  0.0460,  0.0366,  0.0208,  0.0368,\n",
       "                       0.0274,  0.0283,  0.0334,  0.0452,  0.0585,  0.0373,  0.0305,  0.0137,\n",
       "                       0.0124,  0.0298,  0.0421,  0.0277,  0.0452,  0.0322,  0.0301,  0.0492,\n",
       "                       0.0437,  0.0297,  0.0410,  0.0243,  0.0189,  0.0304,  0.0339,  0.0521,\n",
       "                       0.0296,  0.0292,  0.0365,  0.0424,  0.0394,  0.0260,  0.0290, -0.1153,\n",
       "                       0.0482,  0.0323,  0.0422,  0.0447,  0.0325,  0.0543,  0.0319,  0.0278,\n",
       "                       0.0530,  0.0400,  0.0210,  0.0288,  0.0223,  0.0430,  0.0277,  0.0460,\n",
       "                       0.0547,  0.0531,  0.0318,  0.0242,  0.0095,  0.0335,  0.0366,  0.0305,\n",
       "                       0.0343,  0.0316, -0.1597, -0.0946,  0.0412,  0.0336,  0.0254,  0.0271,\n",
       "                       0.0375,  0.0436,  0.0252,  0.0342,  0.0261,  0.0067,  0.0355,  0.0286,\n",
       "                       0.0010,  0.0413,  0.0498,  0.0209,  0.0460,  0.0273,  0.0414,  0.0326,\n",
       "                       0.0336,  0.0391,  0.0352,  0.0262,  0.0508,  0.0134, -0.0046,  0.0165,\n",
       "                       0.0193, -0.0025,  0.0485,  0.0472,  0.0201,  0.0363,  0.0423,  0.0370,\n",
       "                       0.0229,  0.0158,  0.0182,  0.0356,  0.0272,  0.0355,  0.0479,  0.0462,\n",
       "                       0.0214,  0.0181,  0.0375,  0.0341,  0.0451,  0.0350,  0.0255,  0.0278,\n",
       "                       0.0413,  0.0445,  0.0490,  0.0332,  0.0314,  0.0382,  0.0394,  0.0175,\n",
       "                       0.0292,  0.0529,  0.0226,  0.0281,  0.0379,  0.0319,  0.0512,  0.0271,\n",
       "                      -0.0647,  0.0412,  0.0312,  0.0391,  0.0211,  0.0336,  0.0289,  0.0191,\n",
       "                       0.0337,  0.0268,  0.0303,  0.0473,  0.0328,  0.0516,  0.0380,  0.0246,\n",
       "                       0.0456,  0.0212,  0.0294,  0.0486,  0.0393,  0.0429,  0.0533,  0.0540,\n",
       "                       0.0356,  0.0228,  0.0508,  0.0241,  0.0382,  0.0146,  0.0449,  0.0329,\n",
       "                      -0.0008,  0.0428,  0.0238,  0.0272,  0.0252,  0.0412,  0.0356,  0.0387,\n",
       "                       0.0285,  0.0429,  0.0443,  0.0244,  0.0293,  0.0614,  0.0343,  0.0398,\n",
       "                       0.0358,  0.0491,  0.0581,  0.0435,  0.0199,  0.0336,  0.0417,  0.0509,\n",
       "                       0.0435,  0.0375, -0.1228,  0.0485,  0.0345,  0.0338,  0.0488,  0.0187,\n",
       "                       0.0395,  0.0460,  0.0413,  0.0592,  0.0222,  0.0452,  0.0471,  0.0249,\n",
       "                       0.0293,  0.0283,  0.0338,  0.0372,  0.0125,  0.0387,  0.0422,  0.0441,\n",
       "                       0.0643,  0.0339,  0.0435,  0.0504,  0.0268,  0.0346,  0.0377,  0.0376,\n",
       "                       0.0362,  0.0357,  0.0412,  0.0415,  0.0405,  0.0390,  0.0456,  0.0138,\n",
       "                       0.0539,  0.0319,  0.0322,  0.0483,  0.0394,  0.0345,  0.0548,  0.0461,\n",
       "                       0.0425,  0.0331,  0.0341,  0.0517,  0.0350,  0.0444,  0.0211,  0.0616,\n",
       "                       0.0328,  0.0437,  0.0298,  0.0275,  0.0497,  0.0511,  0.0505,  0.0459,\n",
       "                       0.0424,  0.0362,  0.0318,  0.0293,  0.0406,  0.0104, -0.0026,  0.0369,\n",
       "                       0.0401,  0.0542,  0.0514,  0.0374,  0.0310,  0.0505,  0.0122,  0.0537,\n",
       "                       0.0231,  0.0114,  0.0334,  0.0269,  0.0314,  0.0742,  0.0416,  0.0607,\n",
       "                       0.0224,  0.0553,  0.0150,  0.0325,  0.0202,  0.0368,  0.0151,  0.0342,\n",
       "                       0.0258,  0.0234,  0.0251,  0.0300,  0.0288,  0.0273,  0.0321,  0.0297,\n",
       "                       0.0494,  0.0158,  0.0285,  0.0372,  0.0474,  0.0394,  0.0414,  0.0234,\n",
       "                       0.0215,  0.0232,  0.0512,  0.0542,  0.0233,  0.0346,  0.0339,  0.0299,\n",
       "                       0.0217,  0.0494,  0.0446,  0.0281,  0.0337,  0.0264,  0.0284,  0.0275,\n",
       "                       0.0436,  0.0378,  0.0382,  0.0647,  0.0230,  0.0205,  0.0480,  0.0513,\n",
       "                       0.0315,  0.0357,  0.0339,  0.0303,  0.0326,  0.0506,  0.0328,  0.0204,\n",
       "                       0.0381,  0.0416,  0.0173,  0.0411,  0.0272,  0.0085,  0.0156,  0.0360,\n",
       "                       0.0204,  0.0305,  0.0407,  0.0119,  0.0505,  0.0621,  0.0526,  0.0305,\n",
       "                       0.0336,  0.0358,  0.0229,  0.0184,  0.0481,  0.0507,  0.0355,  0.0514,\n",
       "                       0.0353,  0.0256,  0.0560,  0.0376,  0.0208,  0.0431,  0.0445,  0.0349,\n",
       "                       0.0406,  0.0528,  0.0362,  0.0411,  0.0235,  0.0435,  0.0254,  0.0380,\n",
       "                       0.0340,  0.0437,  0.0214,  0.0261,  0.0569,  0.0366,  0.0340,  0.0397,\n",
       "                       0.0292,  0.0318,  0.0499,  0.0217,  0.0362,  0.0489,  0.0325,  0.0299,\n",
       "                       0.0347,  0.0140,  0.0401,  0.0337,  0.0293,  0.0319,  0.0401,  0.0166,\n",
       "                       0.0409,  0.0283,  0.0460,  0.0292, -0.0452,  0.0404,  0.0409,  0.0639,\n",
       "                       0.0544,  0.0192,  0.0343,  0.0396,  0.0338,  0.0390,  0.0247,  0.0402,\n",
       "                       0.0303,  0.0520,  0.0566,  0.0459,  0.0324,  0.0446,  0.0416,  0.0417,\n",
       "                       0.0429,  0.0408,  0.0326,  0.0238,  0.0261,  0.0343,  0.0249,  0.0375,\n",
       "                       0.0517,  0.0296,  0.0351,  0.0362,  0.0383,  0.0249,  0.0307,  0.0346,\n",
       "                       0.0210,  0.0310,  0.0382,  0.0436,  0.0326,  0.0161,  0.0220,  0.0578,\n",
       "                       0.0383,  0.0368,  0.0376,  0.0232,  0.0282,  0.0396,  0.0293,  0.0221,\n",
       "                       0.0396,  0.0393,  0.0216,  0.0416,  0.0284,  0.0104,  0.0295,  0.0528,\n",
       "                       0.0223,  0.0359,  0.0386,  0.0502,  0.0375,  0.0359,  0.0299,  0.0444,\n",
       "                       0.0233,  0.0225,  0.0430,  0.0231,  0.0368,  0.0465,  0.0291,  0.0449,\n",
       "                       0.0453, -0.0254,  0.0386,  0.0067,  0.0203,  0.0294,  0.0479,  0.0145,\n",
       "                       0.0424,  0.0439,  0.0434,  0.0364,  0.0114,  0.0381,  0.0510,  0.0276,\n",
       "                       0.0504,  0.0410,  0.0253,  0.0479,  0.0389,  0.0160,  0.0780,  0.0393,\n",
       "                       0.0206,  0.0410,  0.0437,  0.0506,  0.0463,  0.0419,  0.0185,  0.0493],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0307,  0.1376, -0.1259,  ...,  0.1168, -0.0896,  0.1418],\n",
       "                      [-0.0776,  0.0154,  0.0732,  ...,  0.1017,  0.0250,  0.1068],\n",
       "                      [ 0.1295,  0.0259,  0.0450,  ...,  0.0666, -0.1836,  0.0254],\n",
       "                      ...,\n",
       "                      [-0.0734,  0.1149, -0.0034,  ...,  0.0244,  0.0729,  0.0403],\n",
       "                      [ 0.0233, -0.0057, -0.1105,  ...,  0.0581,  0.0574,  0.0630],\n",
       "                      [ 0.0348, -0.0349, -0.0884,  ..., -0.0703,  0.0813, -0.0675]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.0504,  0.0212,  0.0022,  0.0093,  0.0279,  0.0439,  0.0426,  0.0800,\n",
       "                       0.0185,  0.0387,  0.0355, -0.0141,  0.0065,  0.0312,  0.0551,  0.0058,\n",
       "                       0.0553,  0.0417,  0.0232,  0.0351,  0.0283,  0.0414,  0.0464,  0.0411,\n",
       "                       0.0505,  0.0191,  0.0164, -0.0267,  0.0300,  0.0226,  0.0367,  0.0480,\n",
       "                       0.0487,  0.0170,  0.0403,  0.0387,  0.0288,  0.0126,  0.0152,  0.0068,\n",
       "                      -0.0252,  0.0085,  0.0476,  0.0299,  0.0429,  0.0683, -0.0072,  0.0150,\n",
       "                       0.0333,  0.0331,  0.0442,  0.0381,  0.0241,  0.0525,  0.0020,  0.0364,\n",
       "                       0.0290,  0.0310,  0.0431,  0.0215, -0.0232,  0.0296,  0.0324,  0.0382,\n",
       "                       0.0364,  0.0607,  0.0559,  0.0478,  0.0713,  0.0584,  0.0340,  0.0627,\n",
       "                       0.0277,  0.0508,  0.0381,  0.0389,  0.0223,  0.0102,  0.0263,  0.0363,\n",
       "                       0.0284,  0.0330,  0.0585,  0.0214,  0.0577,  0.0327,  0.0353,  0.0040,\n",
       "                       0.0646,  0.0359,  0.0555,  0.0409,  0.0464,  0.0225,  0.0331,  0.1127,\n",
       "                       0.0509,  0.0386,  0.0013,  0.0639,  0.0400,  0.0592,  0.0370,  0.0509,\n",
       "                       0.0241,  0.0281,  0.0544,  0.0423,  0.0530,  0.0372,  0.0399,  0.0856,\n",
       "                       0.0171, -0.0294,  0.0445,  0.0151,  0.0490,  0.0433,  0.0189,  0.0435,\n",
       "                       0.0258,  0.0083,  0.0336,  0.0276,  0.0512,  0.0406,  0.0370,  0.0197,\n",
       "                       0.0316,  0.0330,  0.0477,  0.0169,  0.0220,  0.0433,  0.0575,  0.0413,\n",
       "                       0.0679,  0.0384, -0.0251,  0.0254,  0.0546,  0.0362,  0.0482,  0.0326,\n",
       "                       0.0263, -0.0047, -0.0019,  0.0080, -0.0008,  0.0616, -0.0103,  0.0510,\n",
       "                       0.0318,  0.0506,  0.0032,  0.0481,  0.0234,  0.0524,  0.0317,  0.0267,\n",
       "                       0.0231,  0.0564, -0.0108,  0.0599,  0.0200,  0.0225,  0.0330,  0.0373,\n",
       "                       0.0364,  0.0255,  0.0035,  0.0215,  0.0492,  0.0392,  0.0290,  0.0336,\n",
       "                       0.0435,  0.0183,  0.0220,  0.0075,  0.0397,  0.0468,  0.0087,  0.0283,\n",
       "                       0.0179,  0.0056,  0.0041,  0.0308,  0.0331,  0.0268,  0.0514,  0.0010],\n",
       "                     device='cuda:0')),\n",
       "             ('dec_fc.weight',\n",
       "              tensor([[-0.0114,  0.0572, -0.0272,  ..., -0.0415,  0.0233,  0.0115],\n",
       "                      [-0.0003, -0.0729,  0.0486,  ...,  0.0926, -0.0621, -0.0563],\n",
       "                      [-0.0375, -0.0020, -0.0117,  ..., -0.0593,  0.0189,  0.0245],\n",
       "                      ...,\n",
       "                      [-0.0326,  0.0691, -0.0299,  ..., -0.0161,  0.0336,  0.0115],\n",
       "                      [-0.0013,  0.0943,  0.0008,  ..., -0.0436,  0.0268,  0.0173],\n",
       "                      [-0.0258,  0.0902, -0.0465,  ..., -0.0315,  0.0217,  0.0177]],\n",
       "                     device='cuda:0')),\n",
       "             ('dec_fc.bias',\n",
       "              tensor([-0.1765,  0.1406, -0.0783,  ..., -0.0784, -0.0632, -0.0761],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.bn0.weight',\n",
       "              tensor([1.2579, 1.2287, 1.1752, 1.1472, 1.1341, 1.1017, 1.0914, 1.0787, 1.0651,\n",
       "                      1.0756, 1.0683, 1.0589, 1.0478, 1.0323, 1.0432, 1.0094, 1.0038, 1.0202,\n",
       "                      1.0210, 1.0268, 1.0409, 1.0565, 1.0200, 1.0603, 1.0618, 1.0505, 1.0631,\n",
       "                      1.0512, 1.0770, 1.0790, 1.0833, 1.0788, 1.0826, 1.0741, 1.0893, 1.0994,\n",
       "                      1.1181, 1.1037, 1.1052, 1.1233, 1.1174, 1.1264, 1.1512, 1.1866, 1.2267,\n",
       "                      1.2610, 1.2632, 1.3015, 1.2884, 1.3413, 1.3513, 1.3659, 1.3383, 1.3445,\n",
       "                      1.3790, 1.3468, 1.3447, 1.3394, 1.2890, 1.2610, 1.2722, 1.2695, 1.2540,\n",
       "                      1.2942], device='cuda:0')),\n",
       "             ('encoder.base.bn0.bias',\n",
       "              tensor([ 0.1418,  0.1614,  0.2051,  0.2250,  0.2054,  0.2128,  0.2234,  0.2539,\n",
       "                       0.2251,  0.2122,  0.2185,  0.2002,  0.2017,  0.1822,  0.1683,  0.1444,\n",
       "                       0.1269,  0.1714,  0.1422,  0.1387,  0.1513,  0.1419,  0.1510,  0.1334,\n",
       "                       0.1520,  0.1332,  0.1163,  0.1276,  0.1073,  0.1257,  0.1314,  0.1131,\n",
       "                       0.1414,  0.1328,  0.1064,  0.1035,  0.0991,  0.1022,  0.1113,  0.1031,\n",
       "                       0.0918,  0.0667,  0.0340,  0.0058, -0.0343, -0.0510, -0.0735, -0.0952,\n",
       "                      -0.1210, -0.1620, -0.1719, -0.1713, -0.1978, -0.1898, -0.2296, -0.2104,\n",
       "                      -0.2010, -0.2143, -0.1837, -0.2698, -0.2991, -0.3428, -0.3216, -0.2706],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.bn0.running_mean',\n",
       "              tensor([-11.1140, -11.0367, -11.6734, -12.0733, -12.2690, -13.1829, -12.8244,\n",
       "                      -13.8654, -13.6266, -14.1256, -14.2417, -14.2807, -15.1179, -14.4914,\n",
       "                      -15.3485, -15.0152, -15.6214, -15.3768, -15.8950, -15.9210, -16.0077,\n",
       "                      -16.3230, -16.5533, -16.4185, -16.8656, -16.9338, -17.1143, -17.2644,\n",
       "                      -17.5348, -17.6393, -17.8601, -18.0469, -18.2951, -18.5422, -18.7396,\n",
       "                      -18.8787, -19.0903, -19.3984, -19.7062, -19.8755, -20.3276, -20.6704,\n",
       "                      -20.9696, -21.2577, -21.5934, -21.9502, -22.1573, -22.3885, -22.6773,\n",
       "                      -23.0146, -23.3851, -23.7347, -23.9969, -24.3780, -24.8172, -25.1915,\n",
       "                      -25.6874, -26.2066, -26.6295, -27.0645, -27.5256, -27.8966, -28.4427,\n",
       "                      -29.7023], device='cuda:0')),\n",
       "             ('encoder.base.bn0.running_var',\n",
       "              tensor([108.5400, 100.5474, 104.6310, 106.9863, 107.7479, 114.1496, 111.6755,\n",
       "                      120.0199, 117.8161, 121.8113, 122.4541, 121.5557, 126.3898, 121.3896,\n",
       "                      127.6692, 124.6137, 129.6735, 125.9474, 126.5959, 126.0733, 128.5122,\n",
       "                      131.1895, 132.9866, 131.1968, 136.2513, 136.4128, 137.8435, 138.7266,\n",
       "                      140.4252, 142.1982, 143.6312, 146.2618, 149.1181, 150.0039, 152.3840,\n",
       "                      154.4992, 157.6141, 161.5698, 165.2521, 167.2338, 169.0995, 172.5907,\n",
       "                      176.6368, 178.3062, 181.3046, 186.4619, 188.5393, 190.9229, 195.1447,\n",
       "                      199.3110, 203.5005, 207.1522, 209.5275, 213.5443, 217.1879, 221.1509,\n",
       "                      225.1093, 229.9661, 233.8673, 238.2281, 244.0726, 246.9852, 253.2982,\n",
       "                      270.9163], device='cuda:0')),\n",
       "             ('encoder.base.bn0.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.conv1.weight',\n",
       "              tensor([[[[-3.7039e-02, -4.2758e-01,  4.6078e-01],\n",
       "                        [-9.8838e-02, -4.7424e-01,  3.5086e-01],\n",
       "                        [ 5.4757e-02, -2.9605e-01,  4.8484e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3487e-01, -2.7748e-01, -2.2969e-01],\n",
       "                        [-2.5529e-03, -1.0134e-01, -9.9216e-02],\n",
       "                        [ 8.8498e-02,  4.3399e-01,  3.1902e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8117e-01,  2.1679e-01,  8.6598e-03],\n",
       "                        [-3.0433e-01,  4.2776e-01, -2.8384e-02],\n",
       "                        [-3.1323e-01,  3.7712e-01, -8.6349e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1328e-01, -4.7214e-01, -1.5421e-01],\n",
       "                        [-7.4739e-03,  1.5373e-01, -9.9434e-02],\n",
       "                        [ 5.1257e-01,  3.8470e-01,  2.0314e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2202e-01,  1.1475e-01,  1.7375e-01],\n",
       "                        [ 4.6711e-02, -2.4738e-01, -1.1763e-01],\n",
       "                        [-1.2941e-01, -1.4176e-01, -8.9102e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.6680e-01, -5.6923e-01, -3.8833e-01],\n",
       "                        [ 7.2493e-01, -2.7824e-01,  9.7279e-03],\n",
       "                        [ 2.4725e-01, -1.6016e-01,  9.7753e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4617e-01,  1.1877e-01,  9.5465e-02],\n",
       "                        [ 5.3723e-02,  1.6259e-02,  3.4303e-02],\n",
       "                        [-2.3713e-01, -1.7044e-01, -7.7720e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7280e-01,  5.4870e-01, -3.0124e-01],\n",
       "                        [-3.1358e-01,  4.4885e-01, -2.8404e-01],\n",
       "                        [-1.4353e-01,  5.0320e-01, -2.3500e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.4014e-04, -6.3007e-02, -2.5290e-01],\n",
       "                        [-1.3695e-02, -7.0924e-02, -1.0243e-01],\n",
       "                        [ 1.5860e-01,  2.4922e-01,  7.3565e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2324e-01, -2.8807e-01,  7.9693e-01],\n",
       "                        [-2.5401e-01, -1.1556e-01,  2.5972e-01],\n",
       "                        [-2.0476e-01, -4.7462e-01, -3.4198e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0406e-01,  5.1279e-02, -3.6834e-01],\n",
       "                        [-2.3591e-01,  2.6704e-01,  1.5689e-01],\n",
       "                        [-2.8982e-01, -2.9980e-02,  1.7038e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.3808e-02, -2.1475e-01,  2.4791e-01],\n",
       "                        [-1.5626e-01, -2.8334e-01,  9.1087e-02],\n",
       "                        [-8.4360e-02, -1.1746e-01,  1.6794e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2985e-01, -1.6245e-01, -3.5523e-01],\n",
       "                        [ 5.0251e-01, -1.0382e-01, -3.8975e-01],\n",
       "                        [ 2.4276e-01,  5.4808e-02, -2.7259e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4744e-01,  2.3009e-01,  8.3530e-01],\n",
       "                        [-1.4976e-01, -2.8275e-01,  2.4763e-01],\n",
       "                        [-1.9248e-01, -3.3660e-01, -1.4239e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.4622e-02, -5.6861e-02, -4.1197e-01],\n",
       "                        [ 5.7208e-01, -5.0864e-02, -4.3210e-01],\n",
       "                        [ 5.4853e-01,  5.0650e-02, -3.2082e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6556e-01, -5.3412e-01, -2.3066e-01],\n",
       "                        [-2.8875e-02,  2.4764e-02, -1.6386e-01],\n",
       "                        [-3.9200e-03,  5.5788e-01,  2.6252e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1720e-01, -4.7870e-01,  1.1784e-01],\n",
       "                        [-2.0684e-01,  6.2280e-02,  4.1311e-01],\n",
       "                        [ 5.6433e-02,  4.4781e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1200e-01,  2.7321e-01, -3.9600e-02],\n",
       "                        [-3.1901e-01,  3.1452e-01, -2.7479e-03],\n",
       "                        [-3.3993e-01,  3.6536e-01,  5.1426e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.2003e-01,  1.8998e-01,  1.2129e-01],\n",
       "                        [-2.7666e-01,  9.2499e-02, -4.6375e-02],\n",
       "                        [-1.4448e-01,  6.8090e-02,  7.0098e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.7226e-02, -1.2127e-01,  2.3658e-01],\n",
       "                        [-2.4300e-01, -1.9383e-01,  1.1952e-01],\n",
       "                        [ 2.2897e-02, -8.7058e-02,  3.2172e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.3028e-02, -2.3576e-01,  4.1035e-02],\n",
       "                        [ 1.6508e-01, -1.1036e-01,  9.5125e-02],\n",
       "                        [-2.9840e-03,  1.8085e-01,  2.6306e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4316e-01,  1.1665e+00, -4.3412e-01],\n",
       "                        [ 6.2403e-02, -5.5574e-01,  1.2445e-01],\n",
       "                        [ 5.2582e-02, -3.2262e-01,  1.8072e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5395e-01,  6.7191e-01, -4.2608e-01],\n",
       "                        [ 1.4435e-01,  7.4019e-01, -1.7308e-01],\n",
       "                        [-2.6455e-01, -1.5263e-02, -2.0942e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5521e-01, -2.1611e-01,  7.1947e-02],\n",
       "                        [ 3.0966e-01, -3.0091e-01, -7.8164e-03],\n",
       "                        [ 3.0483e-01, -3.1466e-01,  1.5690e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9823e-01, -4.2168e-01,  6.0279e-02],\n",
       "                        [-3.2808e-01, -3.3818e-01,  3.4307e-01],\n",
       "                        [-9.1788e-02,  2.4978e-01,  6.2914e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0916e-01, -1.0632e-02,  4.5488e-01],\n",
       "                        [ 1.1837e-02, -5.0426e-01,  5.5825e-02],\n",
       "                        [ 1.8273e-01, -5.3850e-01,  8.3406e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.7359e-01, -1.8598e-01,  2.1945e-02],\n",
       "                        [ 2.8800e-01, -1.5747e-01, -1.0243e-01],\n",
       "                        [ 1.2883e-01, -3.4466e-01, -1.4244e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6872e-01, -1.4464e-01,  2.2020e-01],\n",
       "                        [-2.9175e-01,  2.2592e-01,  2.0379e-01],\n",
       "                        [-1.6604e-01,  2.6496e-01, -8.3792e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.5360e-02,  3.8966e-01,  1.4031e-01],\n",
       "                        [ 1.2257e-02,  2.1597e-02, -4.7005e-02],\n",
       "                        [ 9.1067e-02, -1.6526e-01, -1.9378e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0163e-01, -4.5580e-01,  3.1707e-01],\n",
       "                        [ 1.8935e-01, -4.5179e-01,  2.3650e-01],\n",
       "                        [ 2.7485e-01, -4.0986e-01,  2.1443e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7262e-01, -1.0266e-01, -4.1695e-01],\n",
       "                        [ 4.8492e-01, -2.3177e-03, -4.4562e-01],\n",
       "                        [ 3.3022e-01,  6.2551e-02, -3.2547e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2101e-01,  1.0126e-01, -3.6913e-02],\n",
       "                        [ 1.4700e-01,  6.9705e-02, -3.9404e-02],\n",
       "                        [-5.5072e-02, -1.1184e-01, -6.6921e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.8531e-01, -4.7569e-02, -2.3400e-01],\n",
       "                        [ 3.4791e-01, -7.7497e-02, -2.4477e-01],\n",
       "                        [ 3.7497e-01, -1.4277e-01, -3.4089e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1033e+00,  1.2753e-01, -6.2010e-03],\n",
       "                        [-7.2243e-01, -4.6420e-01, -5.2412e-03],\n",
       "                        [-3.7374e-01,  4.0990e-01, -7.4779e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.1552e-01,  5.3512e-01,  8.1034e-02],\n",
       "                        [-1.1637e-01,  3.2702e-02,  9.7668e-03],\n",
       "                        [ 7.4868e-01, -5.4375e-01, -1.1775e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.5149e-01,  1.8367e-01,  5.9942e-01],\n",
       "                        [ 6.4945e-02, -3.3298e-01,  4.7456e-02],\n",
       "                        [-7.2457e-02, -6.4503e-01, -2.3545e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3996e-01, -4.6708e-01,  6.5029e-02],\n",
       "                        [ 4.1431e-01, -5.8810e-01, -1.2947e-01],\n",
       "                        [ 6.3620e-01, -4.6198e-01,  8.9512e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8400e-01,  6.0769e-01,  3.9696e-01],\n",
       "                        [-1.0041e-01, -5.5067e-02, -6.5041e-02],\n",
       "                        [-4.0160e-01, -5.5484e-01, -4.9943e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.7577e-01,  9.2406e-02,  9.8464e-02],\n",
       "                        [-2.4153e-01, -1.5672e-02,  1.2420e-01],\n",
       "                        [-6.3149e-01, -2.6339e-02,  4.9605e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.2362e-01, -4.3782e-01, -5.7199e-01],\n",
       "                        [ 5.7036e-02,  1.7327e-01,  5.8640e-02],\n",
       "                        [ 3.2428e-01,  2.6780e-01,  1.1553e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.2817e-02,  2.5345e-01, -2.3407e-01],\n",
       "                        [ 6.5310e-02,  1.0996e-01, -1.5513e-01],\n",
       "                        [-2.7904e-02,  2.7827e-01, -2.4337e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1770e-01,  3.1490e-01, -9.0855e-01],\n",
       "                        [-1.3766e-01,  3.3192e-03,  7.7066e-01],\n",
       "                        [-5.3093e-02, -3.6863e-01,  2.3213e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.5213e-02, -4.4828e-01,  6.2535e-02],\n",
       "                        [ 5.3619e-02, -4.0840e-01,  4.2392e-03],\n",
       "                        [ 2.0112e-01, -2.2866e-01,  3.0056e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9792e-01,  2.0081e-01,  1.9037e-01],\n",
       "                        [-2.4127e-01, -3.5608e-01, -2.4821e-01],\n",
       "                        [-3.8929e-02,  1.7353e-01, -4.8857e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0018e-01,  1.3077e-03, -2.7321e-01],\n",
       "                        [ 2.7165e-02,  3.3843e-02, -7.1168e-02],\n",
       "                        [ 5.3553e-02,  2.3183e-01, -4.2740e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8983e-01, -3.7882e-02,  7.5205e-01],\n",
       "                        [-4.3510e-01, -2.7665e-01,  5.3879e-01],\n",
       "                        [-3.7065e-01, -1.9793e-01,  3.8153e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0559e-01,  3.1273e-01,  1.5594e-01],\n",
       "                        [ 1.7393e-01, -6.1596e-02, -2.1482e-01],\n",
       "                        [ 1.0072e-01, -3.6248e-01, -2.6370e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0709e-01, -2.5422e-01,  5.1832e-02],\n",
       "                        [ 2.1006e-01, -1.3040e-01, -6.3120e-02],\n",
       "                        [ 6.7084e-02, -9.1186e-02,  8.9826e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0937e-01,  3.9595e-01,  2.2122e-01],\n",
       "                        [-1.6386e-01,  2.8206e-02, -1.7149e-01],\n",
       "                        [-4.2785e-01, -1.2610e-01, -1.6499e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4867e-01, -2.5180e-01, -3.5126e-01],\n",
       "                        [-1.1301e-01, -1.2536e-01, -8.0463e-02],\n",
       "                        [ 8.8822e-01,  3.9861e-01,  2.1695e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0753e-02,  4.4991e-02, -2.4421e-01],\n",
       "                        [ 9.5658e-03,  2.3654e-01, -2.5991e-01],\n",
       "                        [ 2.4366e-02,  3.8166e-01, -2.2451e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.7838e-01, -5.9983e-02,  1.4472e-01],\n",
       "                        [ 2.1890e-01, -8.2260e-02,  3.5236e-02],\n",
       "                        [-1.6305e-01, -5.5475e-01, -3.4149e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1640e-01,  7.8737e-02, -1.7762e-01],\n",
       "                        [-1.4516e-02,  1.3225e-01,  2.5413e-02],\n",
       "                        [-2.8115e-02,  1.8151e-01, -3.3639e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3240e-01, -3.6960e-01, -1.5010e-01],\n",
       "                        [ 6.2620e-02,  2.2893e-02,  1.1247e-01],\n",
       "                        [ 2.6827e-01,  3.7458e-01, -8.5182e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0860e-01,  1.1462e+00, -4.2346e-02],\n",
       "                        [-1.4127e-01,  3.0784e-01, -4.1399e-02],\n",
       "                        [-3.6094e-01, -1.9679e-01, -2.6113e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3481e-01, -2.5167e-01,  3.8530e-01],\n",
       "                        [-1.3977e-01, -3.6216e-01,  1.1309e-03],\n",
       "                        [ 2.0413e-01, -4.5980e-01,  2.9574e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.7680e-02,  2.6627e-01, -2.8784e-01],\n",
       "                        [-3.3592e-01,  2.4736e-01, -1.2399e-01],\n",
       "                        [-2.8255e-01,  8.0267e-01, -4.0267e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3659e-01, -5.6885e-01, -5.8263e-02],\n",
       "                        [ 2.3202e-01, -3.7275e-01,  4.3137e-02],\n",
       "                        [ 2.3751e-01, -1.1991e-01,  2.6967e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7833e-01,  6.2141e-01,  4.1701e-01],\n",
       "                        [-9.2735e-02, -3.6468e-02, -3.5021e-01],\n",
       "                        [-5.1336e-02,  1.1924e-01, -1.3558e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.9185e-01,  2.7757e-01,  1.5429e-01],\n",
       "                        [ 2.0638e-01, -9.3221e-02, -4.2492e-02],\n",
       "                        [-3.6869e-01, -2.5070e-01, -3.6196e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.1912e-01, -3.4506e-01, -2.0505e-01],\n",
       "                        [-3.5524e-02,  5.3625e-02,  3.3577e-01],\n",
       "                        [ 1.5814e-01, -1.6911e-02,  5.5144e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1422e-01, -9.4341e-02,  4.3752e-02],\n",
       "                        [ 1.3863e+00, -7.7188e-02,  1.9691e-02],\n",
       "                        [-3.5302e-01, -1.1650e-01, -4.4031e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.5821e-01,  1.7370e-01,  3.0065e-01],\n",
       "                        [-4.7475e-01, -6.5231e-01, -4.0496e-01],\n",
       "                        [ 1.6438e-01,  4.0722e-01,  1.4705e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6765e-01, -3.5122e-01, -3.0718e-01],\n",
       "                        [-3.7997e-02, -1.8845e-01,  5.6407e-02],\n",
       "                        [ 2.3948e-01,  2.0316e-01,  6.8780e-01]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.conv2.weight',\n",
       "              tensor([[[[ 3.7716e-02,  3.8377e-01, -2.6829e-02],\n",
       "                        [ 1.4405e-02, -2.7071e-02, -1.1790e-01],\n",
       "                        [ 3.1483e-02, -1.2675e-01,  1.0402e-01]],\n",
       "              \n",
       "                       [[-1.3191e-01,  5.1577e-02,  9.3906e-02],\n",
       "                        [-1.0973e-01,  1.2606e-01,  6.9330e-02],\n",
       "                        [-7.9789e-02,  1.4824e-01, -2.2891e-01]],\n",
       "              \n",
       "                       [[ 8.4112e-02, -6.5050e-02,  2.2053e-02],\n",
       "                        [-1.6003e-02,  3.6255e-02, -1.0961e-01],\n",
       "                        [ 2.1383e-03,  1.7355e-01, -2.0730e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.2900e-01, -9.4333e-02, -4.8292e-01],\n",
       "                        [ 1.5381e-01, -8.5188e-03,  2.9697e-02],\n",
       "                        [ 1.7547e-01,  5.9568e-02,  4.1180e-01]],\n",
       "              \n",
       "                       [[-6.4412e-02,  2.3372e-02, -8.3541e-02],\n",
       "                        [-5.3537e-02, -8.9693e-02, -1.3112e-02],\n",
       "                        [-5.3418e-02, -4.0995e-02,  1.0250e-01]],\n",
       "              \n",
       "                       [[-2.1671e-01,  2.8036e-02, -1.3197e-04],\n",
       "                        [-3.4290e-02,  5.9299e-02, -1.8906e-02],\n",
       "                        [-5.3243e-02, -4.2178e-02,  2.6321e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0785e+00, -2.0748e-01,  7.5568e-02],\n",
       "                        [ 2.0621e-01, -5.9543e-02,  6.3722e-02],\n",
       "                        [-6.5188e-01, -1.2228e-02,  1.1816e-01]],\n",
       "              \n",
       "                       [[-1.2173e-01,  1.9149e-01,  8.3929e-02],\n",
       "                        [ 8.3358e-02, -2.0013e-01, -1.1041e-02],\n",
       "                        [ 2.7151e-01, -3.6403e-01, -4.3889e-02]],\n",
       "              \n",
       "                       [[-1.7432e-01,  1.5744e-01, -2.0128e-01],\n",
       "                        [ 2.6894e-02, -1.1746e-01, -5.5749e-03],\n",
       "                        [ 2.9326e-01, -4.2377e-01,  5.7002e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.5385e-01, -8.2642e-01,  3.3079e-01],\n",
       "                        [-4.6052e-02, -1.7915e-01,  1.1808e-01],\n",
       "                        [-5.4963e-01,  1.0333e+00, -2.4473e-01]],\n",
       "              \n",
       "                       [[-6.9922e-02,  1.3253e-01,  8.7043e-02],\n",
       "                        [ 1.5732e-01,  1.6859e-01, -2.4649e-02],\n",
       "                        [ 4.5574e-02, -1.4071e-01, -1.5539e-01]],\n",
       "              \n",
       "                       [[ 1.2706e-01,  3.1828e-02,  1.1200e-01],\n",
       "                        [ 9.8312e-02,  3.1909e-02,  8.6010e-02],\n",
       "                        [ 1.4542e-02, -3.4562e-04,  8.4735e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.7297e-02, -1.1035e-01, -1.1087e-01],\n",
       "                        [-7.3131e-02, -9.5376e-02, -9.5487e-02],\n",
       "                        [-8.0729e-02, -9.2381e-04,  2.4190e-02]],\n",
       "              \n",
       "                       [[-1.7203e-01, -4.6300e-01,  2.5281e-01],\n",
       "                        [-1.5188e-01, -4.7515e-01, -3.0280e-02],\n",
       "                        [ 6.9937e-02, -1.2466e-01,  4.5305e-01]],\n",
       "              \n",
       "                       [[ 8.2297e-02,  1.0682e-01,  2.8612e-02],\n",
       "                        [ 1.3627e-01,  4.2858e-02, -3.2870e-02],\n",
       "                        [-3.5023e-02, -7.2602e-02, -2.1970e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.8166e-02,  1.6987e-01,  2.3324e-01],\n",
       "                        [ 2.0293e-01, -1.0903e-02, -1.6093e-01],\n",
       "                        [ 1.5683e-01, -1.1523e-01, -3.9176e-01]],\n",
       "              \n",
       "                       [[ 2.7918e-02, -5.2651e-02, -3.0204e-02],\n",
       "                        [-6.0518e-02, -1.3612e-01, -2.5142e-01],\n",
       "                        [ 8.2353e-02, -6.1556e-02,  5.9971e-02]],\n",
       "              \n",
       "                       [[-7.5691e-02, -5.9457e-03, -4.2270e-02],\n",
       "                        [-4.8160e-02, -3.5608e-02, -2.8247e-02],\n",
       "                        [-1.7834e-02, -7.6805e-02,  2.5366e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-4.9454e-02, -5.7105e-03, -8.8107e-02],\n",
       "                        [-3.6103e-02,  2.0379e-01,  3.4189e-01],\n",
       "                        [-4.2215e-02, -2.1860e-01, -2.4045e-01]],\n",
       "              \n",
       "                       [[-3.0638e-01, -1.8374e-01, -3.8692e-01],\n",
       "                        [ 4.3731e-01,  6.7990e-01,  3.9994e-01],\n",
       "                        [-3.8064e-01, -3.3509e-01, -6.1751e-01]],\n",
       "              \n",
       "                       [[-1.5306e-02, -1.0777e-02, -4.1142e-02],\n",
       "                        [-8.7511e-02, -1.0601e-01, -1.5231e-01],\n",
       "                        [-1.8568e-02,  3.6170e-02, -7.9173e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.1569e-01,  2.8898e-01,  3.5592e-01],\n",
       "                        [-1.0991e+00, -7.5708e-01, -8.5644e-01],\n",
       "                        [ 6.9730e-01,  1.2808e-01,  4.9305e-01]],\n",
       "              \n",
       "                       [[-6.9309e-02, -2.3946e-02, -6.7120e-02],\n",
       "                        [ 7.7438e-02,  7.9852e-02, -2.2187e-02],\n",
       "                        [-5.7858e-02, -7.3175e-03, -4.6205e-02]],\n",
       "              \n",
       "                       [[ 2.4485e-01,  3.5203e-01,  1.8942e-01],\n",
       "                        [-2.1788e-01, -1.4184e-01, -1.8707e-01],\n",
       "                        [-1.7722e-01, -9.8066e-02, -2.2995e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2625e-02,  1.0379e-02, -8.0609e-02],\n",
       "                        [ 5.3149e-02, -9.3726e-02, -1.0543e-01],\n",
       "                        [ 4.8197e-02, -5.4563e-02, -4.1949e-02]],\n",
       "              \n",
       "                       [[ 1.4315e-02,  7.2706e-02, -6.4910e-02],\n",
       "                        [-3.9319e-02, -1.9981e-01, -9.3217e-02],\n",
       "                        [ 5.4948e-02,  7.2174e-02,  5.5379e-02]],\n",
       "              \n",
       "                       [[-2.6129e-02, -1.1373e-02, -1.9768e-02],\n",
       "                        [ 2.1967e-02,  6.3522e-02,  1.2756e-02],\n",
       "                        [ 9.7849e-02,  8.7106e-02,  4.9843e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5595e-02, -1.5106e-01,  2.8897e-01],\n",
       "                        [ 9.5800e-02, -1.1059e-01,  1.5325e-01],\n",
       "                        [ 2.9394e-02, -2.9501e-02,  1.2501e-01]],\n",
       "              \n",
       "                       [[ 1.2613e-01,  6.3016e-02,  2.7176e-02],\n",
       "                        [-5.3751e-02, -8.8469e-02, -2.4307e-02],\n",
       "                        [ 7.0750e-02,  2.2604e-02,  1.4919e-02]],\n",
       "              \n",
       "                       [[ 2.6332e-02, -2.9871e-02,  7.3902e-02],\n",
       "                        [ 5.8938e-02,  8.6006e-02,  3.4223e-02],\n",
       "                        [-2.8744e-02,  8.2594e-03,  1.7609e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7435e-01,  4.7874e-02,  7.0055e-02],\n",
       "                        [ 8.6948e-02,  3.3030e-01,  1.3110e-01],\n",
       "                        [ 1.5556e-01,  3.2963e-01,  1.5869e-01]],\n",
       "              \n",
       "                       [[-6.3539e-01, -6.0424e-01, -2.4252e-01],\n",
       "                        [-1.3502e-01, -1.3486e-01, -3.6140e-01],\n",
       "                        [-5.2280e-01, -4.7667e-01, -5.4187e-01]],\n",
       "              \n",
       "                       [[ 1.0034e-01, -3.9097e-01, -6.2816e-01],\n",
       "                        [-5.8587e-02, -3.5102e-01, -4.4382e-01],\n",
       "                        [-1.9356e-02, -2.9316e-01, -2.4458e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.3339e-01, -3.5807e-01, -7.3283e-03],\n",
       "                        [ 9.7241e-03, -1.2542e-01,  4.9291e-02],\n",
       "                        [ 2.5228e-01, -1.4051e-01, -8.6471e-02]],\n",
       "              \n",
       "                       [[-6.5190e-02, -1.7026e-01, -9.0556e-02],\n",
       "                        [ 1.3915e-01, -3.3030e-02, -7.1347e-02],\n",
       "                        [-2.2762e-05, -1.7184e-01, -1.6950e-02]],\n",
       "              \n",
       "                       [[ 7.2244e-02,  7.6516e-02, -2.7654e-03],\n",
       "                        [ 1.0507e-01, -4.3255e-04,  5.2007e-02],\n",
       "                        [ 2.0332e-02,  1.0466e-01,  5.0690e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.weight',\n",
       "              tensor([1.0147, 1.8317, 0.8301, 1.2968, 0.5953, 0.7233, 0.7475, 1.2259, 0.7721,\n",
       "                      1.0568, 1.3650, 0.3360, 0.4459, 0.6781, 0.6541, 0.3440, 0.5908, 1.0499,\n",
       "                      0.6292, 0.5092, 0.6707, 2.1327, 1.5605, 0.8525, 0.6335, 0.9048, 0.8897,\n",
       "                      0.6496, 1.0510, 1.3799, 0.9359, 0.6482, 0.5818, 1.7507, 2.3637, 0.6982,\n",
       "                      0.9968, 0.4719, 0.5994, 0.5357, 0.7040, 2.0022, 0.6293, 0.2890, 0.5688,\n",
       "                      0.9239, 0.6793, 0.5159, 0.4398, 0.5231, 0.6452, 0.8483, 0.5375, 1.9732,\n",
       "                      0.8341, 0.7305, 1.1377, 1.0964, 0.8403, 0.4709, 0.7815, 1.3541, 0.9502,\n",
       "                      1.0875], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.bias',\n",
       "              tensor([ 0.6754,  0.1345,  0.0220,  1.3368, -0.6749,  0.0839, -1.3812, -1.3433,\n",
       "                      -0.7652,  0.2082, -1.0769,  0.1627,  0.0673,  0.0511,  0.1200,  0.1681,\n",
       "                       0.0150,  0.0098, -0.7188, -0.5221, -0.8065,  0.4152,  0.2131, -1.1045,\n",
       "                       0.0147, -1.0571,  0.0904, -0.7248, -0.9289, -0.0724,  0.0621, -0.8089,\n",
       "                       0.0928,  0.1172,  0.0503,  0.1471,  0.6545,  0.1610, -0.4684,  0.0174,\n",
       "                      -0.8001,  0.3992, -0.6326,  0.1002, -0.7923,  0.0503, -0.4399, -0.1764,\n",
       "                      -1.0168,  0.0272, -0.1202,  0.1499, -0.9979,  0.2602, -0.7370,  0.1048,\n",
       "                       0.8390, -0.2476,  0.0871,  0.0680,  0.1174,  1.5486, -1.0039, -1.6553],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.running_mean',\n",
       "              tensor([-2.6442e-03, -1.0105e-03, -7.4347e-03, -5.6551e-04, -5.9022e-03,\n",
       "                       8.1001e-03, -7.3443e-04, -3.3866e-03, -3.5781e-06, -1.8388e-03,\n",
       "                       2.9289e-04, -1.3109e-02,  4.9675e-03, -5.5409e-03,  4.4445e-03,\n",
       "                      -1.7432e-02, -1.1836e-02, -6.5054e-03, -8.9932e-03, -4.7090e-03,\n",
       "                       1.2896e-02,  1.2038e-03,  1.9172e-04,  3.8127e-03, -9.4586e-03,\n",
       "                      -1.5608e-03,  3.7078e-03, -9.7344e-04,  6.8434e-03,  1.3096e-03,\n",
       "                       5.8198e-03, -7.2441e-03,  1.2007e-02,  3.0239e-04,  6.6009e-04,\n",
       "                       4.3699e-03,  6.0325e-03, -1.0725e-02, -4.3649e-02, -1.8055e-02,\n",
       "                       1.5195e-03, -1.7206e-03, -1.6533e-02, -7.0380e-03, -9.7681e-03,\n",
       "                      -5.4719e-03,  5.8173e-04,  8.5079e-04, -4.3638e-03,  1.9839e-02,\n",
       "                       7.8969e-04,  8.3074e-03, -7.5507e-03, -1.3189e-03,  2.5798e-02,\n",
       "                       5.1496e-03, -2.1499e-03,  2.5010e-03, -1.7609e-03,  1.6992e-02,\n",
       "                       4.3116e-03,  3.5006e-03,  6.6559e-04, -7.5510e-04], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.running_var',\n",
       "              tensor([0.0990, 0.0290, 0.0589, 0.0637, 0.0521, 0.1160, 0.0099, 0.0679, 0.0146,\n",
       "                      0.0908, 0.0122, 0.1292, 0.1407, 0.1051, 0.1647, 0.2356, 0.1505, 0.0526,\n",
       "                      0.0477, 0.0382, 0.1537, 0.0292, 0.0740, 0.0330, 0.1240, 0.0544, 0.0538,\n",
       "                      0.0369, 0.0421, 0.0523, 0.1617, 0.1542, 0.1353, 0.0649, 0.0190, 0.0816,\n",
       "                      0.1264, 0.2075, 1.1808, 0.3108, 0.0238, 0.0288, 0.2683, 0.0547, 0.0837,\n",
       "                      0.2347, 0.0352, 0.0102, 0.0502, 0.3289, 0.0327, 0.1034, 0.0380, 0.0303,\n",
       "                      0.6256, 0.0560, 0.0578, 0.0475, 0.0395, 0.2082, 0.0961, 0.0619, 0.0489,\n",
       "                      0.0635], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.weight',\n",
       "              tensor([1.4841, 1.2917, 1.0752, 0.9392, 1.3012, 0.5648, 0.7395, 1.2967, 0.3735,\n",
       "                      1.2988, 1.5531, 1.1796, 1.5098, 0.8108, 0.5671, 1.0800, 1.0263, 1.2715,\n",
       "                      1.3641, 1.3163, 1.5201, 0.6631, 1.1183, 1.1883, 1.2024, 0.8789, 1.3421,\n",
       "                      0.3771, 1.0490, 1.4551, 1.1245, 1.5359, 0.6782, 1.5352, 0.9282, 1.1248,\n",
       "                      1.3073, 0.9236, 1.2908, 1.3024, 0.4935, 1.0720, 0.8583, 1.5085, 1.4076,\n",
       "                      1.4440, 0.6413, 0.6526, 1.0588, 0.5574, 0.6595, 1.0363, 0.7635, 1.3950,\n",
       "                      1.3622, 1.1709, 0.8593, 0.5827, 0.9331, 1.3578, 1.2215, 0.9420, 0.5712,\n",
       "                      0.5443], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.bias',\n",
       "              tensor([-0.8234, -0.8081, -0.4838, -0.5944, -0.8566, -0.2404, -0.5236, -0.9160,\n",
       "                      -0.0529, -0.3748, -0.7467, -0.8183, -1.0355, -0.2404, -0.3608, -0.5537,\n",
       "                      -0.6094, -0.5815, -0.5941, -0.8944, -0.6258, -0.1631, -0.5619, -0.8486,\n",
       "                      -0.4367, -0.3251, -0.8718, -0.0486, -0.5740, -0.9323, -0.6806, -0.7423,\n",
       "                      -0.9645, -1.0283, -0.6479, -0.5786, -0.9397, -0.1561, -0.6581, -0.7995,\n",
       "                      -0.1054, -0.5006, -0.2690, -0.9833, -0.6177, -1.0039, -0.5419, -0.7335,\n",
       "                      -0.4527, -0.3228, -0.2103, -0.3911, -0.2588, -0.8303, -0.6102, -0.4021,\n",
       "                      -0.2842, -0.4564, -0.4216, -0.6266, -0.8774, -0.5110, -0.9052, -0.2076],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.running_mean',\n",
       "              tensor([ -7.5214,  -3.5263,  -7.6195,  -7.3292, -10.1689,  -3.5676,  -5.5123,\n",
       "                       -6.4482,   2.5568,  -7.0457,  -4.9308,  -4.0243,  -5.7459,  -3.0006,\n",
       "                       -0.4771,  -5.7695,  -6.4044,  -8.2480,  -9.8571,  -7.5985,  -7.1609,\n",
       "                      -10.7915,  -5.2936,  -5.5477,  -4.2093, -14.3836,  -9.0733,   0.5924,\n",
       "                       -5.9486,  -4.5786,  -9.5296, -18.9389,   7.1328,  -3.7252,  -4.3018,\n",
       "                       -4.3027,  -9.6727, -11.4089,  -8.2913,  -4.0851,  -8.5113, -13.2303,\n",
       "                       -5.4044,  -5.5494,  -6.0409,  -5.7176,  -0.3189,   2.1054, -11.1128,\n",
       "                        0.1121, -10.7496,  -4.8157,  -1.3577,  -5.7857,  -4.9932,  -8.8108,\n",
       "                       -5.8132,   0.7328,  -4.6833, -11.2964,  -6.6940,  -5.2393,   3.5756,\n",
       "                      -13.2411], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.running_var',\n",
       "              tensor([ 83.4874,  49.2280,  79.8500,  65.7017, 104.6649, 147.6423,  30.4582,\n",
       "                       79.2726,  38.4524, 135.0762,  43.4954,  34.0307,  43.2262,  56.8076,\n",
       "                       15.2798,  73.5737, 124.5944, 136.4150, 159.5756,  71.4369,  73.7142,\n",
       "                      121.5120,  84.3253,  40.6370,  41.4570, 250.3013, 146.4842,  39.3805,\n",
       "                      119.0096,  81.0722,  91.1335, 299.9778,  30.1207,  33.7678,  31.2618,\n",
       "                       38.2270,  95.4588, 211.1729, 157.5682,  25.0145,  58.4743, 142.2299,\n",
       "                       40.8495,  94.0520,  56.1689,  40.2752,  15.1789,  34.4148, 209.8351,\n",
       "                       20.2163,  81.0546,  39.9090,  31.7404,  59.5921,  76.8075, 138.7216,\n",
       "                      183.5796,  25.3117,  73.6397, 243.3807,  62.6100,  55.8699,  17.5195,\n",
       "                      227.4245], device='cuda:0')),\n",
       "             ('encoder.base.conv_block1.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.conv1.weight',\n",
       "              tensor([[[[-6.6612e-02, -5.9600e-02, -3.3646e-02],\n",
       "                        [-9.0082e-03, -3.4218e-02, -1.2638e-01],\n",
       "                        [-1.5268e-01, -5.2480e-02, -6.7372e-02]],\n",
       "              \n",
       "                       [[ 1.1773e-01,  1.3273e-01,  1.4331e-01],\n",
       "                        [ 1.5485e-02, -5.2641e-02,  6.5574e-02],\n",
       "                        [ 3.9865e-02,  6.6218e-02,  1.6867e-01]],\n",
       "              \n",
       "                       [[ 9.3612e-03, -3.2874e-03, -5.0931e-03],\n",
       "                        [ 1.0213e-02,  2.7881e-02,  5.9696e-02],\n",
       "                        [ 2.5336e-03,  5.3899e-02,  1.0334e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.3382e-02,  6.7181e-02,  6.3629e-02],\n",
       "                        [-8.2463e-03,  3.0971e-02,  3.6543e-02],\n",
       "                        [-3.2838e-02, -5.4525e-02, -1.0010e-01]],\n",
       "              \n",
       "                       [[ 5.8703e-03, -5.4488e-03, -7.4210e-03],\n",
       "                        [-8.8855e-03,  9.4491e-03, -2.4393e-02],\n",
       "                        [ 4.0046e-02,  2.7267e-02, -2.4605e-02]],\n",
       "              \n",
       "                       [[ 3.4274e-03, -1.7679e-02, -1.0506e-02],\n",
       "                        [-6.6787e-02, -2.9965e-02, -3.4468e-02],\n",
       "                        [-4.4432e-02, -1.3806e-02, -4.1295e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.9368e-02, -4.6169e-02, -3.1849e-02],\n",
       "                        [ 1.1523e-01,  1.7957e-01,  4.6607e-02],\n",
       "                        [ 5.8586e-03,  1.2307e-01,  1.4036e-02]],\n",
       "              \n",
       "                       [[-1.8446e-01, -2.0808e-01, -7.5956e-02],\n",
       "                        [-2.9685e-01, -2.9554e-01,  5.7040e-02],\n",
       "                        [-2.7504e-01,  6.5192e-02,  2.9643e-02]],\n",
       "              \n",
       "                       [[ 3.1143e-02,  5.7940e-02,  5.3295e-02],\n",
       "                        [-1.4687e-01, -2.6303e-01,  4.0375e-02],\n",
       "                        [ 8.0275e-02, -1.9773e-01,  7.4133e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.7884e-02, -6.6429e-02, -6.8187e-03],\n",
       "                        [-8.8455e-02, -2.1068e-01, -1.0393e-01],\n",
       "                        [ 4.0991e-02, -1.4381e-01, -1.1891e-01]],\n",
       "              \n",
       "                       [[ 3.8864e-02, -7.3408e-02, -1.0042e-01],\n",
       "                        [ 6.2543e-02, -1.5229e-02,  3.8400e-02],\n",
       "                        [-4.9299e-02, -1.4120e-01, -1.5871e-01]],\n",
       "              \n",
       "                       [[ 1.2304e-01,  1.6561e-01,  1.1603e-01],\n",
       "                        [-3.1976e-03,  1.5427e-01,  1.0683e-01],\n",
       "                        [ 1.0294e-01,  1.0579e-01,  1.8109e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3461e-01,  3.3709e-01, -1.2679e-01],\n",
       "                        [-1.1710e-01, -1.9431e-01, -2.6899e-01],\n",
       "                        [ 1.2496e-01, -2.3303e-01, -3.0178e-01]],\n",
       "              \n",
       "                       [[-7.5645e-01, -1.8989e-02, -1.4834e-01],\n",
       "                        [-1.5400e+00, -1.4846e+00, -2.8898e-01],\n",
       "                        [-1.9606e+00, -1.8870e+00, -6.1143e-01]],\n",
       "              \n",
       "                       [[ 7.4252e-02, -3.6760e-02,  2.5229e-01],\n",
       "                        [-5.4651e-03, -4.8606e-01,  6.3125e-02],\n",
       "                        [ 1.1650e-01, -6.2473e-01,  9.7307e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.3681e-02,  1.0975e-01, -1.4098e-01],\n",
       "                        [-1.3643e-02, -1.8806e-02, -1.1949e-01],\n",
       "                        [-1.5424e-01,  2.1139e-02, -1.2501e-01]],\n",
       "              \n",
       "                       [[-2.0506e-01, -3.0328e-01, -7.0644e-03],\n",
       "                        [ 6.5120e-02, -1.5298e-02,  8.4776e-02],\n",
       "                        [ 9.8368e-02,  2.2104e-01,  4.7331e-02]],\n",
       "              \n",
       "                       [[ 1.0543e-02, -3.8799e-02,  1.2879e-01],\n",
       "                        [-1.4161e-03, -1.6089e-01, -1.1688e-01],\n",
       "                        [ 1.8923e-01,  2.9672e-02, -8.9577e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5869e-01,  2.4997e-01,  1.0919e-01],\n",
       "                        [ 8.0202e-02, -7.0330e-02, -1.1587e-01],\n",
       "                        [-1.7754e-01, -9.0353e-02, -1.1497e-02]],\n",
       "              \n",
       "                       [[ 3.2115e-01,  2.9448e-01, -5.0417e-02],\n",
       "                        [ 1.6544e-01,  5.9469e-02,  1.6220e-02],\n",
       "                        [-3.3938e-02, -2.0441e-02,  2.2820e-01]],\n",
       "              \n",
       "                       [[-2.6324e-01, -2.1927e-01,  1.9276e-02],\n",
       "                        [-1.1829e-01, -9.9668e-02, -3.7246e-02],\n",
       "                        [-1.5414e-01, -3.0073e-01, -3.8076e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.8569e-01, -8.8609e-02, -2.7967e-01],\n",
       "                        [-1.7912e-01, -1.2283e-01, -1.4729e-01],\n",
       "                        [-1.1130e-01, -1.5198e-01, -4.9355e-02]],\n",
       "              \n",
       "                       [[-1.5297e-01, -6.4467e-02, -1.4488e-02],\n",
       "                        [ 8.3452e-02,  1.1420e-01,  1.4201e-01],\n",
       "                        [ 6.5947e-02,  7.5174e-02,  1.4104e-02]],\n",
       "              \n",
       "                       [[-3.9835e-01, -4.4832e-01,  4.2174e-02],\n",
       "                        [-4.3757e-02,  3.5249e-03,  1.9157e-01],\n",
       "                        [ 5.1002e-01,  2.7074e-01,  2.1804e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0083e-01, -2.0754e-01, -1.2930e-01],\n",
       "                        [-4.3015e-02,  7.0285e-02,  3.9884e-02],\n",
       "                        [ 4.1164e-03, -1.0237e-02, -2.3977e-01]],\n",
       "              \n",
       "                       [[-2.5900e-01, -4.4998e-01,  1.5604e-01],\n",
       "                        [-1.7697e-01, -4.5872e-01,  2.1617e-01],\n",
       "                        [ 3.7660e-02, -7.4408e-01,  6.8443e-02]],\n",
       "              \n",
       "                       [[-1.1396e-01, -5.3961e-02, -3.6279e-01],\n",
       "                        [ 1.1854e-01, -1.2681e-01, -2.1725e-01],\n",
       "                        [ 2.6696e-01, -3.6346e-01, -9.5176e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.7260e-04, -6.8171e-02,  8.3130e-02],\n",
       "                        [-6.1544e-02, -1.0541e-01,  1.3370e-01],\n",
       "                        [-1.3495e-02, -3.3459e-01, -3.7672e-01]],\n",
       "              \n",
       "                       [[ 4.4782e-02, -4.8111e-02, -3.0118e-01],\n",
       "                        [ 7.5534e-02,  1.4195e-02, -9.2084e-02],\n",
       "                        [ 5.9530e-02,  2.4830e-01, -1.9449e-02]],\n",
       "              \n",
       "                       [[-5.6514e-02, -4.7786e-01, -5.4551e-01],\n",
       "                        [ 6.7129e-02, -1.0447e-01, -3.5393e-01],\n",
       "                        [ 2.0524e-01,  1.4802e-01, -1.2159e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1755e-01,  1.8948e-01, -8.5609e-02],\n",
       "                        [ 1.8041e-03,  9.2940e-02,  4.3612e-03],\n",
       "                        [-2.8400e-02,  8.6866e-02,  5.8296e-02]],\n",
       "              \n",
       "                       [[ 1.5267e-01,  9.4688e-02,  1.0845e-01],\n",
       "                        [ 1.2109e-02,  1.7323e-02,  7.2662e-02],\n",
       "                        [ 1.5045e-01,  6.3335e-02,  1.3530e-01]],\n",
       "              \n",
       "                       [[-1.1404e-02, -6.6846e-05,  3.2670e-02],\n",
       "                        [ 1.3148e-02, -9.1374e-03,  7.4029e-02],\n",
       "                        [ 7.1019e-02, -1.2960e-02,  2.3726e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.7098e-02,  6.7599e-02,  1.4238e-02],\n",
       "                        [ 4.8238e-02,  1.3659e-02, -1.2117e-01],\n",
       "                        [ 1.4043e-02, -4.1660e-02, -1.5624e-01]],\n",
       "              \n",
       "                       [[ 7.8119e-02,  5.5463e-02, -4.3440e-02],\n",
       "                        [ 4.9839e-02,  1.5844e-02,  6.5254e-03],\n",
       "                        [-1.8330e-03,  3.8192e-02, -6.3780e-02]],\n",
       "              \n",
       "                       [[ 1.2015e-03, -5.0034e-02, -4.7408e-03],\n",
       "                        [-9.7093e-02, -1.0198e-01, -1.2352e-01],\n",
       "                        [-4.9896e-02, -4.3457e-02, -1.8967e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.conv2.weight',\n",
       "              tensor([[[[-1.2165e-01, -3.4758e-02, -3.1801e-02],\n",
       "                        [-2.2202e-01, -4.2053e-02, -8.9334e-03],\n",
       "                        [-2.1968e-01,  1.4105e-02, -7.2417e-02]],\n",
       "              \n",
       "                       [[-1.8230e-02,  4.9553e-02,  2.1746e-03],\n",
       "                        [-5.1542e-03,  1.5157e-01, -5.8213e-02],\n",
       "                        [-6.2584e-02,  8.8796e-02, -9.7473e-02]],\n",
       "              \n",
       "                       [[-7.6419e-02,  2.6815e-01, -4.1798e-01],\n",
       "                        [ 1.1087e-01,  1.8604e-01, -4.2441e-01],\n",
       "                        [ 6.6051e-01,  6.7546e-02, -2.2249e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.7164e-01,  6.9644e-02, -1.1054e-01],\n",
       "                        [-1.9934e-01,  1.2364e-01, -1.8217e-01],\n",
       "                        [ 1.9870e-01, -2.1927e-01, -4.7338e-01]],\n",
       "              \n",
       "                       [[ 6.0575e-01,  1.9189e-01, -3.9298e-01],\n",
       "                        [ 3.8937e-01, -5.2282e-01, -3.3441e-01],\n",
       "                        [ 5.0963e-02, -8.0754e-01,  2.1472e-01]],\n",
       "              \n",
       "                       [[-5.4394e-02, -4.4702e-02, -4.1633e-02],\n",
       "                        [-7.9942e-02,  2.0425e-02, -1.1764e-01],\n",
       "                        [-6.7712e-02, -4.8692e-02, -8.1700e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.8303e-02, -1.1456e-01, -6.3068e-02],\n",
       "                        [-3.1676e-02, -7.5469e-02, -8.8714e-02],\n",
       "                        [ 1.6190e-02, -1.3691e-01, -1.2982e-02]],\n",
       "              \n",
       "                       [[ 1.3800e-02,  4.3082e-02,  1.2921e-01],\n",
       "                        [-6.6615e-02,  3.9583e-02,  5.1345e-02],\n",
       "                        [-9.0941e-02, -3.3695e-02, -1.6292e-01]],\n",
       "              \n",
       "                       [[-2.9417e-01, -2.7346e-01, -2.8625e-01],\n",
       "                        [-4.8340e-01, -3.0853e-01, -2.9241e-01],\n",
       "                        [-4.6969e-01, -4.4771e-01, -2.2531e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3768e-01, -1.3367e-01,  6.3965e-02],\n",
       "                        [-1.8034e-01, -1.0056e-01,  4.9152e-02],\n",
       "                        [ 6.9681e-02,  4.4886e-02, -1.5970e-02]],\n",
       "              \n",
       "                       [[ 6.3910e-02,  5.0630e-02, -1.5643e-01],\n",
       "                        [-1.2564e-02,  8.7770e-02, -2.5424e-01],\n",
       "                        [-1.5242e-01,  3.2650e-02, -3.4847e-01]],\n",
       "              \n",
       "                       [[-1.0796e-02, -6.4269e-02, -5.0478e-03],\n",
       "                        [-9.9691e-02, -6.7211e-02, -5.9294e-02],\n",
       "                        [-5.5320e-02, -4.8565e-02, -8.5714e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3092e-01,  9.5969e-02,  1.5641e-01],\n",
       "                        [ 1.9266e-01,  1.9806e-01,  3.0072e-01],\n",
       "                        [ 1.0866e-01,  6.0311e-02,  1.0739e-01]],\n",
       "              \n",
       "                       [[-4.7209e-02, -7.3073e-02, -1.1407e-01],\n",
       "                        [ 3.4073e-02, -6.4070e-02,  7.7815e-02],\n",
       "                        [ 2.4749e-02, -6.8775e-02,  7.9206e-02]],\n",
       "              \n",
       "                       [[-2.8662e-02, -6.8921e-03, -1.5398e-01],\n",
       "                        [ 1.1468e-01,  1.0031e-01, -2.7129e-02],\n",
       "                        [ 1.9977e-01,  1.8576e-01,  5.5038e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.7789e-01, -1.6586e-01, -5.8020e-02],\n",
       "                        [-1.0732e-01, -1.4870e-01, -1.8783e-01],\n",
       "                        [ 1.1411e-01,  1.8217e-03,  6.5047e-03]],\n",
       "              \n",
       "                       [[ 5.4595e-02,  7.4122e-02, -2.3456e-01],\n",
       "                        [-1.3140e-01, -1.0850e-02, -2.9233e-01],\n",
       "                        [-3.5969e-02,  2.3044e-01, -1.8797e-01]],\n",
       "              \n",
       "                       [[ 1.4259e-01,  7.6576e-02,  9.8668e-02],\n",
       "                        [ 2.4371e-01,  1.9889e-01,  1.1936e-01],\n",
       "                        [ 1.4846e-01,  1.9596e-01,  1.3475e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.1735e-02, -1.3602e-03, -6.8345e-03],\n",
       "                        [-3.9126e-02, -2.0053e-02, -6.9146e-02],\n",
       "                        [-4.7897e-02, -3.2232e-02, -3.0127e-02]],\n",
       "              \n",
       "                       [[-1.1223e-01, -2.3186e-03,  1.0385e-01],\n",
       "                        [-1.8395e-02, -9.9355e-03,  2.3772e-02],\n",
       "                        [ 9.9456e-03,  3.8746e-02,  3.2703e-02]],\n",
       "              \n",
       "                       [[ 5.2624e-01,  3.0441e-01, -2.7560e-02],\n",
       "                        [ 3.8298e-01,  3.3152e-01,  3.2366e-01],\n",
       "                        [-1.7045e-01, -1.2247e-01, -6.2685e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.2901e-01,  1.6458e-01, -5.7356e-02],\n",
       "                        [ 1.9583e-01,  1.6779e-01,  2.3444e-02],\n",
       "                        [-1.3751e-01, -1.7650e-01, -3.1298e-01]],\n",
       "              \n",
       "                       [[ 1.4263e-01, -1.8176e-01, -1.3101e-01],\n",
       "                        [-3.3003e-01, -1.7546e-01, -1.4912e-01],\n",
       "                        [-4.1653e-01, -2.7350e-01, -2.3506e-01]],\n",
       "              \n",
       "                       [[-3.4305e-03, -1.1950e-02, -2.6996e-02],\n",
       "                        [-3.5794e-02, -1.4185e-02, -2.9764e-02],\n",
       "                        [ 2.7390e-02, -6.2543e-02, -3.8219e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0635e-02, -2.6808e-03, -9.0777e-02],\n",
       "                        [-3.8485e-02,  3.2833e-02, -1.6659e-02],\n",
       "                        [-1.8095e-02,  8.3388e-03,  1.3049e-02]],\n",
       "              \n",
       "                       [[-4.0688e-02, -2.1189e-01, -1.4189e-01],\n",
       "                        [-4.1159e-02, -1.1777e-01, -3.9503e-02],\n",
       "                        [ 4.0488e-02,  6.5073e-02, -1.2451e-01]],\n",
       "              \n",
       "                       [[-1.9807e-01, -1.4593e-01, -3.1981e-01],\n",
       "                        [-2.6858e-01, -9.8892e-02, -2.4597e-01],\n",
       "                        [-3.9285e-01, -2.7522e-02, -2.4347e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2200e-01, -2.3795e-01, -4.5053e-01],\n",
       "                        [-4.3874e-01, -2.1310e-02, -6.6127e-02],\n",
       "                        [ 1.4589e-01,  1.8029e-01, -2.1881e-01]],\n",
       "              \n",
       "                       [[ 1.2308e-02,  3.8618e-01,  4.7723e-02],\n",
       "                        [ 1.1494e-02,  2.0954e-01,  1.6211e-02],\n",
       "                        [-1.2337e-01, -1.7129e-01, -2.3508e-01]],\n",
       "              \n",
       "                       [[-2.2188e-03, -2.6811e-02, -4.6226e-03],\n",
       "                        [-7.3100e-02, -4.6282e-02, -5.9734e-02],\n",
       "                        [ 1.5354e-02, -7.1094e-02, -4.0344e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9619e-02, -1.3767e-02, -6.4492e-02],\n",
       "                        [ 7.0084e-02,  2.1040e-02, -1.6778e-02],\n",
       "                        [ 2.5448e-02, -2.0526e-02, -1.5553e-02]],\n",
       "              \n",
       "                       [[ 6.7199e-02,  5.4012e-02, -5.1086e-02],\n",
       "                        [-1.6294e-02,  2.6211e-03, -5.9751e-02],\n",
       "                        [ 1.1546e-01,  7.7307e-02, -3.1984e-02]],\n",
       "              \n",
       "                       [[-1.3045e-01,  4.2094e-01,  3.6570e-01],\n",
       "                        [ 5.6246e-02,  7.0460e-01,  5.7300e-01],\n",
       "                        [-8.8699e-02,  4.3950e-01,  6.2013e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.6621e-01, -1.4640e-01,  1.2067e-01],\n",
       "                        [ 3.1655e-02,  3.4726e-01,  4.2844e-01],\n",
       "                        [-4.9609e-02,  3.7723e-01,  2.6148e-01]],\n",
       "              \n",
       "                       [[ 1.0608e-02,  5.0214e-01,  1.0745e-01],\n",
       "                        [-1.9865e-01,  2.3390e-01,  7.7547e-03],\n",
       "                        [-1.2779e-01,  2.3408e-01, -2.2846e-02]],\n",
       "              \n",
       "                       [[ 2.3396e-02, -2.1005e-02, -6.9662e-03],\n",
       "                        [-2.6809e-02, -3.2222e-02, -9.1260e-03],\n",
       "                        [-5.6296e-04, -2.4745e-03, -5.7847e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.weight',\n",
       "              tensor([0.7172, 1.1233, 1.1306, 1.0778, 1.2900, 1.3358, 1.0254, 0.9637, 1.0924,\n",
       "                      1.9560, 1.1531, 1.0244, 0.9168, 0.9906, 1.3675, 1.0856, 1.0364, 1.4014,\n",
       "                      0.6489, 1.1420, 1.0177, 1.0153, 0.4829, 1.3125, 1.0182, 1.2070, 0.8518,\n",
       "                      1.1346, 1.0194, 1.0389, 0.6530, 1.6765, 1.3377, 1.0420, 1.1963, 1.4562,\n",
       "                      1.2257, 0.8529, 1.2123, 1.0886, 1.2572, 0.9541, 1.2606, 1.1860, 0.7690,\n",
       "                      1.0909, 0.8198, 1.6815, 1.5043, 0.9400, 0.9319, 1.2516, 1.2181, 0.7739,\n",
       "                      1.5223, 1.2250, 0.5551, 0.8316, 1.1723, 0.6180, 1.2489, 1.3083, 1.2504,\n",
       "                      1.1648, 0.9319, 0.8519, 1.1785, 1.1199, 1.0065, 1.0437, 0.8517, 0.9715,\n",
       "                      1.1117, 0.8660, 1.2616, 0.6270, 1.4886, 0.8508, 1.6452, 0.9375, 0.9837,\n",
       "                      0.9614, 0.9463, 0.9444, 1.3023, 0.9668, 0.9989, 0.8529, 1.2239, 1.2258,\n",
       "                      0.8677, 1.0991, 1.2224, 1.3239, 1.0160, 0.8423, 0.7899, 1.0761, 0.9532,\n",
       "                      1.1130, 1.0155, 1.4508, 0.9422, 0.4902, 1.3575, 1.2227, 0.6806, 1.0196,\n",
       "                      1.1379, 1.3348, 0.8498, 1.1620, 1.0342, 1.0171, 0.7932, 1.2207, 1.0058,\n",
       "                      1.1235, 0.9424, 0.7260, 1.1394, 1.4980, 0.9080, 1.0551, 0.7560, 1.6658,\n",
       "                      1.0238, 0.7015], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.bias',\n",
       "              tensor([-1.3539, -0.9176, -0.3358, -0.6793, -0.2511, -0.5147,  0.1780,  0.0788,\n",
       "                      -0.9521, -3.2531, -0.3384, -0.2269, -0.1342, -0.4940, -0.5501, -0.7990,\n",
       "                      -0.2480, -0.7214, -1.2223, -0.8328,  0.1423, -0.7698, -0.0695, -0.9567,\n",
       "                      -0.6748, -0.8609, -1.0909, -0.6635, -0.5919, -0.3254, -0.5232, -1.0573,\n",
       "                      -0.5956,  0.2500, -1.2381, -0.9972, -1.1012, -0.7308, -0.9487, -0.4341,\n",
       "                      -0.7429, -0.7259, -0.9874, -0.2327, -1.4147, -0.8253, -0.5465, -2.2435,\n",
       "                      -0.7619, -0.4607, -1.0012, -0.7680,  0.0576, -0.1711, -0.9545, -0.4789,\n",
       "                      -0.2734, -0.1463, -0.9236, -0.4300, -1.3015, -0.8899, -1.5931, -0.5611,\n",
       "                      -0.2354,  0.1681, -0.6901, -0.1235, -0.6812, -0.5706, -0.0539, -0.2259,\n",
       "                      -0.7704, -0.1603, -0.9158, -1.2511, -1.1759, -0.4254, -1.5772,  0.0548,\n",
       "                      -0.3023, -0.2560, -0.9098,  0.1258, -0.8445,  0.2932, -0.5789, -1.4806,\n",
       "                      -0.7398, -0.6939, -0.2297, -0.3205, -1.0558, -0.5916, -0.7359, -0.6250,\n",
       "                       0.0800, -0.9542, -0.1950, -0.3094, -0.5269, -0.8853, -0.4104, -0.0767,\n",
       "                      -0.9139, -0.6508, -0.2267, -0.5620, -0.0352, -0.6384,  0.3548, -0.7505,\n",
       "                      -0.5176, -0.8099, -0.5966, -0.7521, -1.1145, -0.2763, -0.7157, -0.2710,\n",
       "                      -0.5462, -0.9088, -0.2783, -0.7310,  0.0219, -0.8976, -0.0224, -1.1168],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.running_mean',\n",
       "              tensor([-2.3564e+00, -7.8623e-01, -4.6387e+00, -1.5049e+00, -2.2726e+00,\n",
       "                      -2.7921e+00, -7.8990e-01, -2.8141e+00, -5.9426e-01, -2.2119e-01,\n",
       "                      -2.2360e+00, -1.1295e+00, -4.6336e-01, -6.6574e-02, -3.6455e+00,\n",
       "                      -8.3942e-01, -2.1146e+00, -3.3238e+00, -1.4186e-01, -3.0691e+00,\n",
       "                      -2.2668e+00, -1.1178e+00, -8.3395e-01, -2.8017e+00, -1.6393e+00,\n",
       "                      -3.2161e+00,  2.2586e+00, -2.7256e+00, -1.5868e+00, -2.5973e+00,\n",
       "                       5.9631e-01, -2.0146e+00, -3.9246e+00, -4.6789e-01, -1.3337e+00,\n",
       "                      -2.9259e+00, -3.4471e+00,  4.0029e-01, -2.7329e+00, -1.4647e+00,\n",
       "                      -2.7654e+00, -7.8124e-01, -2.8880e+00, -2.2220e+00, -3.1499e+00,\n",
       "                      -2.0553e+00, -1.3198e+00, -1.3732e+00, -1.1723e+00, -3.7504e+00,\n",
       "                      -2.9886e+00, -2.1853e+00, -1.5485e+00, -3.1541e+00, -2.1112e+00,\n",
       "                      -1.7010e+00, -7.4233e-01, -1.2257e+00, -1.9303e+00, -1.8361e+00,\n",
       "                      -8.7065e-01, -1.9204e+00, -7.5239e-01, -1.1576e+00, -1.1160e+00,\n",
       "                      -2.2270e+00, -9.1154e-01, -2.0062e+00, -2.4841e+00, -2.2993e+00,\n",
       "                      -1.4874e+00, -1.1571e+00, -2.4260e+00, -3.6369e-01, -3.3601e+00,\n",
       "                      -1.9821e+00, -7.2913e-01, -1.6621e+00, -1.3400e+00, -1.2716e+00,\n",
       "                      -1.3281e+00, -2.1497e-01, -1.1626e+00, -2.3756e+00, -2.5502e+00,\n",
       "                      -1.1670e+00, -6.4745e-01,  5.7326e-01, -1.6173e+00, -2.3845e+00,\n",
       "                       4.2936e-03, -2.3031e+00, -2.2605e+00, -1.4771e+00, -1.5212e+00,\n",
       "                       6.9390e-01, -9.1834e-01,  2.9509e-01, -2.1181e+00, -1.3780e+00,\n",
       "                      -2.6048e-02, -1.7809e+00, -2.0320e+00,  1.7299e+00, -3.1834e+00,\n",
       "                      -8.1315e-01,  3.8306e-01, -1.1156e+00, -1.8082e+00, -1.4379e+00,\n",
       "                      -2.8346e+00, -1.0881e+00, -1.2295e+00, -1.1997e+00,  1.3506e+00,\n",
       "                      -1.8708e+00, -7.6548e-01, -3.8635e+00, -9.9921e-01, -2.0282e+00,\n",
       "                      -4.2747e+00, -3.8394e+00, -3.5665e+00, -2.8408e+00, -2.4622e-01,\n",
       "                      -1.8582e+00, -2.5839e+00, -1.9727e+00], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.running_var',\n",
       "              tensor([ 1.1628,  2.2944,  8.6532,  2.7921,  6.7483,  3.9477,  6.2737, 11.0114,\n",
       "                       1.1497,  2.9575,  6.1196,  4.8618,  2.6658,  1.2191,  9.8697,  1.8588,\n",
       "                       7.7485,  3.2064,  0.7007,  2.6209,  7.0998,  0.9956,  8.4282,  4.6423,\n",
       "                       1.8855,  3.9211,  2.0303,  6.6025,  3.2229,  4.9314,  4.0883,  8.9942,\n",
       "                       5.5522,  2.3270,  1.9216,  5.1352,  2.6981,  1.1372,  2.9688,  3.6854,\n",
       "                       7.6050,  7.3443,  2.6095,  2.1476,  2.4595,  3.0240,  4.5101,  2.0808,\n",
       "                       4.8284,  6.4665,  2.4399,  2.4437,  3.4446,  6.3414,  8.9221,  3.9288,\n",
       "                       4.5559,  4.1219,  1.5601,  7.2267,  1.0878,  2.0362,  1.5766,  6.8748,\n",
       "                       3.5607,  6.7264,  1.2537, 15.1972,  3.8910,  5.8348,  4.1857,  3.3512,\n",
       "                       2.7344,  3.2213,  4.6379,  1.4182,  1.2774, 10.6226,  1.4496,  3.8304,\n",
       "                       5.4729,  2.5310,  1.2216,  3.1023,  3.2071,  2.9372,  5.2183,  0.7089,\n",
       "                       1.9102,  3.0293,  1.9638,  2.7152,  1.6664,  4.4831,  2.3184,  1.3854,\n",
       "                       5.7960,  0.8607,  3.7067,  3.5862,  3.1024,  1.7274,  6.0427,  8.3279,\n",
       "                       4.1307,  2.4674,  2.2121,  4.5371,  2.9238,  2.9484, 12.1494,  0.9848,\n",
       "                       4.5319,  2.2995,  8.1437,  6.4259,  2.4978,  5.0054,  1.7669,  6.3232,\n",
       "                       9.9577,  8.3383,  5.7918,  5.6132,  5.2834,  7.8332,  4.3388,  1.1185],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.weight',\n",
       "              tensor([1.3141, 0.9743, 0.9400, 0.9704, 1.1382, 1.0515, 0.7056, 0.8917, 1.2728,\n",
       "                      0.8739, 0.8869, 1.0483, 0.6003, 0.7180, 0.9838, 0.9419, 1.2941, 1.2745,\n",
       "                      1.1587, 1.3949, 0.7573, 0.7964, 1.2028, 1.1286, 0.5101, 1.5309, 1.7043,\n",
       "                      1.0253, 1.2643, 1.5136, 0.9687, 1.1254, 0.9008, 1.0613, 1.2545, 1.9371,\n",
       "                      1.0074, 1.1867, 0.6400, 0.8690, 1.2913, 1.1891, 1.5210, 1.2264, 1.1337,\n",
       "                      1.5098, 0.7860, 1.1929, 0.9391, 1.0299, 0.8509, 1.0739, 1.1180, 1.0300,\n",
       "                      1.1998, 0.9821, 0.9817, 1.3478, 0.9603, 0.9633, 0.6857, 0.6026, 0.7475,\n",
       "                      0.7358, 0.7933, 0.9335, 0.9808, 1.0397, 0.8151, 0.7391, 0.6320, 1.2441,\n",
       "                      1.0984, 1.2876, 0.8579, 1.6905, 0.7509, 0.7957, 0.7060, 1.0145, 0.9281,\n",
       "                      0.8951, 1.7811, 1.0739, 1.3654, 1.0729, 0.7540, 0.7065, 1.2138, 1.0745,\n",
       "                      0.9565, 0.9216, 1.0931, 0.6989, 1.1158, 0.9414, 0.7919, 1.2018, 1.0087,\n",
       "                      1.4503, 0.6382, 0.8017, 0.9373, 1.1921, 1.0555, 1.2000, 1.3124, 1.1891,\n",
       "                      0.8393, 1.0704, 0.7054, 1.2592, 0.7358, 0.9641, 1.1372, 0.8094, 1.0117,\n",
       "                      1.2514, 1.1951, 1.0004, 0.8262, 0.7046, 0.8043, 1.1598, 0.6865, 1.4700,\n",
       "                      0.8981, 0.9085], device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.bias',\n",
       "              tensor([-1.3503, -0.4413, -0.6789, -0.9455, -1.0849, -0.4448, -0.5752, -0.7186,\n",
       "                      -0.8108, -0.2051, -0.4654, -0.7822, -0.4704, -0.3479, -0.7247, -0.6463,\n",
       "                      -1.1507, -0.8867, -0.7556, -0.8274, -0.4405, -0.4568, -0.9801, -0.6102,\n",
       "                      -1.2241, -1.2244, -1.5618, -0.8782, -0.5003, -0.9520, -0.5820, -1.1252,\n",
       "                      -0.9082, -0.9316, -1.0885, -1.7258, -0.9305, -0.9675, -0.2319, -0.6314,\n",
       "                      -0.8341, -1.1461, -0.9772, -0.9146, -0.7383, -1.1380, -0.6114, -0.9168,\n",
       "                      -1.1098, -0.8108, -0.2102, -0.8518, -0.5361, -0.4911, -0.9719, -0.7816,\n",
       "                      -0.7263, -1.1259, -0.3177, -0.4689, -0.2683, -0.5677, -0.5023, -0.3059,\n",
       "                      -0.5004, -0.7979, -0.7226, -0.8363, -0.3814, -0.5096, -2.4209, -1.0990,\n",
       "                      -0.7452, -1.0950, -0.4069, -1.6483, -0.4548, -0.4833, -0.4344, -0.7627,\n",
       "                      -0.5733, -0.4171, -1.7487, -1.0344, -0.9407, -0.8883, -0.0773, -0.2880,\n",
       "                      -1.0581, -0.7470, -0.6575, -0.5272, -0.7539, -0.3000, -0.6706, -0.6163,\n",
       "                      -0.3594, -0.7435, -2.1373, -1.4771, -0.2047, -0.3021, -0.4441, -0.8505,\n",
       "                      -0.7633, -1.0400, -0.6749, -0.8543, -0.2337, -0.7890, -0.1617, -0.7715,\n",
       "                      -0.4618, -0.8388, -0.8737, -0.8112, -0.6466, -0.8895, -0.7215, -0.9477,\n",
       "                      -0.6900, -0.5412, -0.4516, -1.3314, -0.2638, -1.1401, -0.6788, -0.7952],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.running_mean',\n",
       "              tensor([-6.9297, -4.3337, -5.7589, -0.8863, -2.2412, -1.4413, -3.4932, -6.0370,\n",
       "                      -5.2845, -2.1129, -5.9746, -2.2982, -0.1805, -1.9609, -3.9859, -2.5096,\n",
       "                      -9.8723, -4.8601, -5.3042, -2.1145, -3.4193, -3.2424, -4.6652, -1.9158,\n",
       "                       0.2138, -3.6972, -1.9212, -3.2995, -3.1840, -8.4560, -7.4588, -8.7266,\n",
       "                      -1.2513, -1.9974, -5.5300, -4.2195, -3.7250, -2.1256, -3.6457, -6.0307,\n",
       "                      -2.3493, -1.5394, -5.7551, -4.4863, -5.5497, -4.5754, -3.0556, -5.5282,\n",
       "                       4.0172, -6.1605, -3.4883, -3.7118, -7.3187, -8.2365, -3.5258, -1.8673,\n",
       "                      -0.7454, -1.8293, -3.3306, -6.0135, -0.3439, -1.7986, -4.1060, -8.0788,\n",
       "                      -6.2054, -4.6057, -8.8555, -5.2569, -3.6296, -6.3634, -4.6917, -5.0731,\n",
       "                      -3.5708, -3.3057, -4.4096, -5.6592, -7.4107, -2.9892, -6.6684, -3.7112,\n",
       "                      -0.1329, -7.2910, -5.4560, -7.7363, -6.1466, -4.1547, -5.3513, -9.7286,\n",
       "                      -4.6962, -7.7151, -8.1191, -3.9913, -1.1417, -2.8012, -5.0069, -5.7323,\n",
       "                      -2.7388, -4.5593, -8.8022, -4.6429, -1.6462, -6.3479, -3.9436, -3.4581,\n",
       "                      -3.9018, -2.6764, -4.2597, -3.6427, -5.7447, -4.2069, -2.9528, -6.0274,\n",
       "                      -2.2515, -7.0223, -2.5649, -0.8349, -6.6115, -3.0227, -5.8236, -5.4464,\n",
       "                      -4.9398,  0.5112, -5.7200, -2.4090, -1.9134, -1.6693, -8.4573, -7.5632],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.running_var',\n",
       "              tensor([30.6659, 44.3200, 18.3157, 20.5948, 15.7070, 15.0497,  6.2826, 38.1174,\n",
       "                      17.1388, 41.9682, 27.3024, 12.1402, 22.9494, 13.0412, 24.8706, 15.3759,\n",
       "                      34.4519, 18.4692, 20.1711, 17.2156, 29.4188, 23.2388, 16.7092, 22.9201,\n",
       "                       2.3241, 25.2681, 19.5696, 18.9731, 31.4712, 37.6598, 30.9196, 35.2994,\n",
       "                      12.7409, 12.1795, 10.5677, 24.4400, 32.0738, 23.1013, 22.0267, 24.0519,\n",
       "                      30.1795, 28.6623, 35.2770, 17.5137, 14.4632, 34.9817, 13.1082, 22.4076,\n",
       "                      12.2356, 27.6757, 42.7241, 11.3820, 23.2812, 39.8190, 16.6850, 16.6628,\n",
       "                      11.7425, 13.5440, 14.1517, 16.3527, 17.1861, 17.4135, 15.5357, 22.4912,\n",
       "                      20.4443, 15.9669, 16.4832, 17.2318,  7.1193, 20.2935,  6.8821, 24.5627,\n",
       "                      20.3342, 14.7529, 22.7395, 34.7625, 61.4325, 17.0555, 45.7971, 19.0875,\n",
       "                      13.7665, 27.6330, 16.5559, 25.3476, 20.9822, 23.3057, 16.2179, 45.1180,\n",
       "                      34.5436, 18.5065, 19.3175, 20.1623, 11.7982, 19.0447, 22.6937, 27.3784,\n",
       "                      17.4375, 14.3894, 23.7390, 21.1173, 32.1722, 13.5240, 26.1376, 13.4418,\n",
       "                      26.0792, 11.1197, 22.5386, 34.6845, 43.4385, 20.0209, 30.8511, 14.8955,\n",
       "                      25.5031, 25.1505, 13.1208, 45.8165, 26.7770, 35.5371, 17.3669, 15.0885,\n",
       "                      11.7473, 12.7117, 25.2792, 11.6972, 56.6025, 13.2156, 36.0186, 25.4881],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block2.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.conv1.weight',\n",
       "              tensor([[[[ 0.1918,  0.2914,  0.2449],\n",
       "                        [ 0.1409,  0.4522,  0.5067],\n",
       "                        [-0.0884,  0.0737,  0.0301]],\n",
       "              \n",
       "                       [[ 0.1019,  0.0240,  0.1687],\n",
       "                        [ 0.1553,  0.1560,  0.1272],\n",
       "                        [ 0.3152,  0.1944,  0.5959]],\n",
       "              \n",
       "                       [[-0.0959,  0.0195, -0.0181],\n",
       "                        [ 0.1306,  0.3360,  0.2106],\n",
       "                        [ 0.0172,  0.2755,  0.1774]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0589, -0.0836, -0.0707],\n",
       "                        [-0.0466, -0.0364, -0.0165],\n",
       "                        [-0.1360, -0.1182, -0.2067]],\n",
       "              \n",
       "                       [[ 0.1215, -0.0398,  0.0103],\n",
       "                        [ 0.2076,  0.1056,  0.0358],\n",
       "                        [ 0.2488,  0.1140,  0.0059]],\n",
       "              \n",
       "                       [[-0.1999,  0.1547, -0.0563],\n",
       "                        [ 0.0262,  0.1187,  0.0150],\n",
       "                        [-0.0092,  0.0139, -0.0758]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2419,  0.0038,  0.0491],\n",
       "                        [ 0.1142,  0.1323,  0.0855],\n",
       "                        [ 0.0182,  0.1687,  0.1369]],\n",
       "              \n",
       "                       [[ 0.0632, -0.0132, -0.2317],\n",
       "                        [-0.0641,  0.1044, -0.1256],\n",
       "                        [-0.2285, -0.0290, -0.1301]],\n",
       "              \n",
       "                       [[ 0.1610,  0.1163, -0.5981],\n",
       "                        [-0.1550,  0.0303, -0.5493],\n",
       "                        [-0.0474,  0.0092, -0.9042]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0083,  0.0083,  0.0075],\n",
       "                        [ 0.0145,  0.0950,  0.0511],\n",
       "                        [ 0.0830,  0.1164,  0.0494]],\n",
       "              \n",
       "                       [[ 0.2263,  0.1090,  0.0101],\n",
       "                        [ 0.1972,  0.0947,  0.0223],\n",
       "                        [ 0.2290,  0.0657,  0.0559]],\n",
       "              \n",
       "                       [[ 0.0564,  0.0782, -0.1155],\n",
       "                        [-0.0289,  0.0121, -0.1669],\n",
       "                        [-0.1572, -0.0734, -0.2753]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1550,  0.0760, -0.0711],\n",
       "                        [ 0.0081,  0.0031,  0.2342],\n",
       "                        [-0.0559, -0.0469,  0.0951]],\n",
       "              \n",
       "                       [[-0.2200, -0.1018,  0.0902],\n",
       "                        [-0.0272, -0.0195, -0.0870],\n",
       "                        [-0.0746,  0.0177, -0.0156]],\n",
       "              \n",
       "                       [[ 0.1937,  0.1846, -0.1088],\n",
       "                        [-0.0464, -0.0803, -0.1807],\n",
       "                        [-0.2460, -0.4201, -0.2906]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2961,  0.0428,  0.0576],\n",
       "                        [-0.0060, -0.0896, -0.0119],\n",
       "                        [-0.0070, -0.1107, -0.0374]],\n",
       "              \n",
       "                       [[ 0.0958, -0.1339, -0.5265],\n",
       "                        [ 0.2807, -0.0662, -0.3240],\n",
       "                        [ 0.1958, -0.0395,  0.0079]],\n",
       "              \n",
       "                       [[-0.1234, -0.1167,  0.0425],\n",
       "                        [-0.1760, -0.0356,  0.1057],\n",
       "                        [ 0.0918,  0.0630,  0.0935]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1052,  0.0447, -0.0383],\n",
       "                        [ 0.3132, -0.0677,  0.2181],\n",
       "                        [ 0.3347,  0.1222,  0.1651]],\n",
       "              \n",
       "                       [[-0.1390, -0.1263, -0.2003],\n",
       "                        [ 0.0697,  0.2888,  0.1418],\n",
       "                        [-0.1250,  0.1076, -0.2513]],\n",
       "              \n",
       "                       [[ 0.1868,  0.4712, -0.2973],\n",
       "                        [ 0.4597,  0.3130,  0.0224],\n",
       "                        [ 0.6202,  0.3876,  0.2023]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1832, -0.2164, -0.1429],\n",
       "                        [-1.0208, -0.7868, -0.6915],\n",
       "                        [ 0.0429, -0.0640,  0.0734]],\n",
       "              \n",
       "                       [[ 0.3000, -0.1256, -0.1552],\n",
       "                        [ 0.3883,  0.0413, -0.0672],\n",
       "                        [-0.0734, -0.2630, -0.1852]],\n",
       "              \n",
       "                       [[-0.0130, -0.1501, -0.0803],\n",
       "                        [-0.0735, -0.1439, -0.1835],\n",
       "                        [-0.0352, -0.1001, -0.0571]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1292, -0.0475, -0.2751],\n",
       "                        [-0.0806, -0.0832, -0.1058],\n",
       "                        [-0.2897, -0.2348, -0.2851]],\n",
       "              \n",
       "                       [[ 0.3081, -0.0171,  0.0433],\n",
       "                        [ 0.3938, -0.0264,  0.0846],\n",
       "                        [-0.0721, -0.1088,  0.0143]],\n",
       "              \n",
       "                       [[-0.2201, -0.1279,  0.0128],\n",
       "                        [-0.0203, -0.0936,  0.2572],\n",
       "                        [-0.0513,  0.0027,  0.2839]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1582,  0.0710, -0.0582],\n",
       "                        [-0.1213,  0.0654,  0.0037],\n",
       "                        [-0.0399,  0.0586, -0.0409]],\n",
       "              \n",
       "                       [[ 0.1604, -0.0942, -0.0826],\n",
       "                        [ 0.0975,  0.0810,  0.0280],\n",
       "                        [ 0.1393,  0.1117,  0.0537]],\n",
       "              \n",
       "                       [[-0.0604, -0.2456, -0.2025],\n",
       "                        [ 0.0392, -0.1012, -0.0784],\n",
       "                        [-0.0073, -0.2827, -0.0562]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0430,  0.2113,  0.5149],\n",
       "                        [-0.0677,  0.0607,  0.4389],\n",
       "                        [-0.2325, -0.0065,  0.1742]],\n",
       "              \n",
       "                       [[-0.3542, -0.1437,  0.3854],\n",
       "                        [-0.2052, -0.2274,  0.2500],\n",
       "                        [-0.4057, -0.3395, -0.0143]],\n",
       "              \n",
       "                       [[-0.1930, -0.0256, -0.0375],\n",
       "                        [ 0.0103, -0.0207, -0.0794],\n",
       "                        [ 0.3867,  0.2394,  0.1966]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1049,  0.0724, -0.0165],\n",
       "                        [ 0.0512,  0.0242, -0.0029],\n",
       "                        [ 0.0762,  0.0376,  0.0533]],\n",
       "              \n",
       "                       [[-0.0143,  0.0353,  0.0516],\n",
       "                        [-0.0515,  0.0574,  0.0636],\n",
       "                        [ 0.1108,  0.1316,  0.1324]],\n",
       "              \n",
       "                       [[ 0.2118, -0.2252,  0.0978],\n",
       "                        [ 0.4146, -0.1564,  0.0487],\n",
       "                        [ 0.1328, -0.3897, -0.1263]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.conv2.weight',\n",
       "              tensor([[[[ 1.3757e-01,  4.3896e-02,  7.7711e-02],\n",
       "                        [ 3.9155e-02, -1.6810e-02, -5.3194e-03],\n",
       "                        [-7.1487e-02, -8.9337e-02, -9.6639e-02]],\n",
       "              \n",
       "                       [[ 1.0051e-01,  5.4529e-02,  2.5286e-01],\n",
       "                        [ 2.2643e-01,  1.0918e-01,  2.1707e-01],\n",
       "                        [ 2.2286e-01,  1.7694e-01,  1.8261e-01]],\n",
       "              \n",
       "                       [[ 1.0463e-01,  4.7260e-02,  1.4341e-01],\n",
       "                        [ 6.8646e-03,  3.5136e-02, -1.8568e-01],\n",
       "                        [ 1.4691e-02,  2.7523e-02, -8.4363e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.6073e-02, -1.0391e-01, -5.4284e-01],\n",
       "                        [-1.1898e-01, -1.1015e-01, -2.7668e-01],\n",
       "                        [-1.6836e-01, -1.7446e-01, -4.8569e-01]],\n",
       "              \n",
       "                       [[-2.9016e-01, -1.0900e-01, -5.3641e-02],\n",
       "                        [-2.6679e-01, -1.2469e-01, -1.4308e-01],\n",
       "                        [-1.3673e-01, -1.5387e-02,  1.9499e-02]],\n",
       "              \n",
       "                       [[-3.0667e-02, -2.2987e-01, -2.8192e-01],\n",
       "                        [-1.4152e-01, -1.1759e-01, -1.8855e-01],\n",
       "                        [-1.6718e-01, -2.3168e-01, -2.6251e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8786e-01,  1.6873e-01,  1.3946e-01],\n",
       "                        [-1.7823e-01,  5.2950e-02,  1.0508e-01],\n",
       "                        [ 3.9748e-02,  1.1322e-01,  9.1565e-02]],\n",
       "              \n",
       "                       [[ 1.6513e-01,  7.0866e-02,  2.9959e-02],\n",
       "                        [ 1.8623e-01,  8.5402e-02,  1.0393e-01],\n",
       "                        [ 1.6429e-01,  6.0174e-02,  9.9975e-02]],\n",
       "              \n",
       "                       [[-2.9346e-02,  2.7225e-01,  4.5111e-03],\n",
       "                        [-1.6765e-01,  8.2408e-02, -6.9969e-02],\n",
       "                        [-3.3864e-01, -3.1999e-01, -4.8076e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.7067e-02,  3.7755e-02,  1.4875e-01],\n",
       "                        [ 1.3623e-01,  5.7685e-02,  1.2049e-01],\n",
       "                        [-4.3463e-02,  8.5667e-02,  2.6807e-01]],\n",
       "              \n",
       "                       [[ 3.3094e-02, -3.1364e-02, -9.8045e-02],\n",
       "                        [ 5.5394e-02,  1.4516e-01,  4.4614e-02],\n",
       "                        [ 1.2437e-01,  6.7197e-02,  2.6299e-01]],\n",
       "              \n",
       "                       [[ 1.3716e-02,  2.9617e-02, -8.5375e-03],\n",
       "                        [-5.4299e-02, -9.0567e-03, -3.2639e-02],\n",
       "                        [-3.9753e-02, -3.7975e-02,  1.0959e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2729e-02,  1.2983e-02, -1.1082e-03],\n",
       "                        [-1.0104e-02, -2.4775e-03, -1.8996e-03],\n",
       "                        [-6.1798e-02, -5.7441e-02, -7.8250e-02]],\n",
       "              \n",
       "                       [[-1.8100e-02, -8.1336e-02,  8.5607e-03],\n",
       "                        [ 2.4292e-02,  3.0190e-03,  6.1094e-03],\n",
       "                        [ 5.0470e-02, -2.3951e-03,  3.9983e-02]],\n",
       "              \n",
       "                       [[-1.2726e-02, -9.6699e-02, -1.3851e-01],\n",
       "                        [-2.9790e-02, -8.6112e-02, -1.5020e-01],\n",
       "                        [-7.4393e-02, -9.5068e-02, -1.3827e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.0869e-02, -7.1531e-02, -3.1412e-03],\n",
       "                        [-2.2586e-02, -4.4022e-03, -1.1555e-02],\n",
       "                        [-3.3323e-02, -7.2141e-02, -3.3744e-02]],\n",
       "              \n",
       "                       [[ 3.9286e-02,  2.1935e-02, -1.1812e-02],\n",
       "                        [ 8.7210e-02,  4.9117e-02,  3.8273e-02],\n",
       "                        [ 7.9813e-03,  2.1938e-02, -2.2139e-02]],\n",
       "              \n",
       "                       [[-1.0034e-01, -6.9140e-02, -9.8685e-02],\n",
       "                        [ 7.6026e-03,  5.4144e-04, -2.7368e-02],\n",
       "                        [ 2.0734e-02,  2.5915e-02, -4.8275e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.3179e-03, -1.0582e-01, -7.0599e-02],\n",
       "                        [ 3.1258e-02,  2.8049e-02,  2.0656e-03],\n",
       "                        [ 1.3279e-01,  4.2829e-02,  9.6902e-02]],\n",
       "              \n",
       "                       [[-2.8050e-01, -2.3010e-01, -2.8824e-01],\n",
       "                        [-3.2654e-02,  7.5081e-02, -1.0713e-01],\n",
       "                        [ 2.2023e-01,  1.2251e-01, -3.1004e-02]],\n",
       "              \n",
       "                       [[-2.2567e-02, -1.0412e-01, -2.9561e-01],\n",
       "                        [-6.5547e-02, -1.8374e-01, -2.1960e-01],\n",
       "                        [ 4.5878e-02, -5.6491e-02, -1.8567e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2591e-01, -2.1784e-02, -4.0365e-02],\n",
       "                        [-5.7017e-02,  8.3478e-02, -3.8980e-02],\n",
       "                        [ 7.2135e-02,  1.7239e-01,  1.7608e-01]],\n",
       "              \n",
       "                       [[-3.4503e-01, -3.1989e-01, -3.2226e-01],\n",
       "                        [-1.6589e-01, -1.6011e-01, -1.2297e-01],\n",
       "                        [-7.5813e-02, -5.2137e-02, -5.5259e-02]],\n",
       "              \n",
       "                       [[-1.4890e-01,  1.2244e-02,  3.4804e-03],\n",
       "                        [ 9.9097e-02,  1.0039e-01,  1.1039e-01],\n",
       "                        [ 2.7918e-01,  2.4813e-01,  2.0999e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2763e-02,  3.3710e-02,  9.8060e-02],\n",
       "                        [ 4.1523e-02,  1.0447e-01,  1.1888e-01],\n",
       "                        [ 9.0085e-02,  1.0030e-01,  1.2675e-01]],\n",
       "              \n",
       "                       [[-2.0796e-02,  1.4305e-01, -8.5851e-02],\n",
       "                        [ 9.9763e-02,  1.7328e-01,  1.0501e-01],\n",
       "                        [ 9.9091e-02,  1.1628e-01,  5.7350e-02]],\n",
       "              \n",
       "                       [[-1.8043e-01, -6.2085e-02, -4.5798e-02],\n",
       "                        [-8.4020e-02,  1.2727e-01,  9.6284e-02],\n",
       "                        [ 1.7993e-01,  1.3537e-01,  1.8061e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.6259e-02, -5.4515e-02,  1.0738e-01],\n",
       "                        [-1.6335e-01, -1.6188e-01, -4.7400e-02],\n",
       "                        [-4.4075e-01, -2.0570e-01, -2.3790e-01]],\n",
       "              \n",
       "                       [[ 6.3876e-02,  5.0798e-02,  3.0333e-02],\n",
       "                        [ 1.7889e-02,  1.8676e-02,  2.0114e-02],\n",
       "                        [ 3.7309e-03,  6.1642e-02,  1.0740e-01]],\n",
       "              \n",
       "                       [[ 7.5402e-02,  6.8505e-02,  1.2329e-02],\n",
       "                        [ 9.4484e-02,  1.3652e-01,  7.6856e-02],\n",
       "                        [ 2.4983e-01,  2.6860e-01,  1.3195e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5039e-02,  3.9122e-02, -4.0369e-03],\n",
       "                        [-1.2478e-01, -5.6188e-02, -2.4111e-02],\n",
       "                        [-6.4421e-02, -1.1154e-02,  3.1546e-02]],\n",
       "              \n",
       "                       [[ 6.7863e-02, -1.7155e-02,  8.1381e-02],\n",
       "                        [-3.2866e-02, -1.4610e-01, -7.5981e-03],\n",
       "                        [-9.6189e-02, -1.5031e-01, -2.5742e-02]],\n",
       "              \n",
       "                       [[-6.0012e-02,  7.6986e-02,  5.3144e-01],\n",
       "                        [ 1.6253e-01,  2.6311e-02,  2.9028e-01],\n",
       "                        [ 2.8924e-01,  4.3638e-01,  9.5001e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.4443e-02,  8.4047e-02,  9.4683e-02],\n",
       "                        [ 7.5064e-02,  8.1519e-03,  9.3771e-02],\n",
       "                        [ 4.4937e-02,  1.1582e-02,  3.0661e-02]],\n",
       "              \n",
       "                       [[-4.2403e-02,  5.5279e-02,  7.3614e-02],\n",
       "                        [-1.4714e-01, -1.1489e-01, -1.1970e-01],\n",
       "                        [-2.2739e-01, -2.6858e-01, -2.7262e-01]],\n",
       "              \n",
       "                       [[ 5.3812e-02,  1.3348e-01,  9.6792e-02],\n",
       "                        [ 1.7793e-02,  9.1173e-02,  1.9585e-02],\n",
       "                        [ 7.9299e-03,  8.6664e-02,  1.0111e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.weight',\n",
       "              tensor([1.0210, 1.0682, 1.3787, 1.2665, 1.1524, 1.2183, 0.7760, 0.9235, 1.3536,\n",
       "                      1.1974, 1.3259, 1.0340, 0.7915, 1.4988, 1.3355, 1.0443, 1.5879, 1.0444,\n",
       "                      1.4216, 1.0978, 0.9139, 1.1532, 1.1720, 1.4551, 0.9114, 1.1548, 0.2007,\n",
       "                      0.9233, 0.9801, 1.4392, 1.2658, 1.2461, 1.2587, 0.9034, 1.2150, 0.9803,\n",
       "                      0.9793, 1.0596, 1.2942, 1.0567, 0.9321, 1.1342, 1.5601, 1.0315, 1.2391,\n",
       "                      1.0022, 0.9950, 1.2044, 1.0443, 1.0558, 1.0039, 1.3602, 1.1981, 1.2316,\n",
       "                      1.3122, 1.0064, 0.7829, 1.3809, 1.1030, 1.4282, 0.9289, 1.1313, 1.3792,\n",
       "                      0.9184, 1.0905, 1.0623, 1.2476, 1.4465, 1.1163, 1.2293, 1.0798, 1.3139,\n",
       "                      1.7250, 0.8172, 1.5012, 1.3231, 1.0144, 1.1767, 0.8729, 1.1869, 0.9012,\n",
       "                      1.0563, 0.7078, 1.3326, 1.0936, 1.0224, 1.3593, 0.9392, 1.0068, 0.9863,\n",
       "                      1.1849, 0.9958, 1.2248, 0.9927, 0.3141, 1.3952, 1.0526, 0.9720, 1.1495,\n",
       "                      1.1253, 0.9783, 1.0597, 1.0248, 1.4366, 1.3393, 1.2572, 0.9937, 1.1931,\n",
       "                      1.1437, 0.8957, 1.2098, 0.2566, 1.0649, 1.3017, 1.0800, 0.5224, 1.0450,\n",
       "                      1.1513, 1.1263, 0.8780, 1.3537, 1.1516, 1.5164, 1.1235, 0.9574, 0.9924,\n",
       "                      1.1335, 1.0409, 0.9817, 0.9195, 0.9063, 0.7173, 1.1560, 1.2215, 1.1700,\n",
       "                      1.4139, 1.2205, 0.9432, 1.0820, 1.4721, 1.3174, 1.0905, 1.2970, 0.8261,\n",
       "                      0.9812, 1.0475, 1.2826, 1.2452, 0.8185, 1.0462, 1.0750, 1.5156, 1.1132,\n",
       "                      1.3410, 1.1077, 1.1155, 1.2860, 0.9671, 0.5262, 1.1721, 0.9906, 1.1165,\n",
       "                      1.2943, 0.9292, 1.0349, 1.1765, 1.1188, 1.1820, 0.9491, 0.9734, 1.3175,\n",
       "                      1.2034, 1.2084, 0.9865, 1.2615, 0.8739, 0.7807, 1.1073, 0.7385, 0.9734,\n",
       "                      1.4519, 0.9854, 1.0787, 1.0790, 1.0758, 1.1872, 1.0594, 0.9354, 0.5785,\n",
       "                      1.2671, 0.6805, 1.1030, 1.2096, 1.1690, 0.8356, 0.8897, 1.0657, 1.2187,\n",
       "                      0.9070, 0.7119, 0.9653, 0.9849, 1.0520, 0.2849, 0.9442, 1.1167, 1.2524,\n",
       "                      1.0367, 1.4768, 1.2307, 1.2085, 0.8254, 1.2146, 1.1639, 0.2181, 1.2649,\n",
       "                      1.1123, 1.2077, 1.2347, 1.0788, 1.5626, 1.0067, 1.1525, 1.1592, 1.1814,\n",
       "                      1.2216, 1.1346, 0.6273, 1.3089, 1.5136, 1.1486, 0.7495, 1.3114, 0.9355,\n",
       "                      1.1059, 1.4022, 1.3204, 1.5235, 1.3346, 1.1735, 1.1633, 1.0751, 1.3056,\n",
       "                      1.0540, 1.0776, 0.9134, 0.7332, 1.1821, 0.9479, 0.8942, 1.1816, 1.1299,\n",
       "                      0.9147, 1.0555, 0.8702, 1.0005], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.bias',\n",
       "              tensor([-0.8982, -0.5593, -0.8299, -0.8870, -0.6938, -0.3829, -1.0505, -0.7719,\n",
       "                      -0.6779, -0.5489, -0.8549, -0.9675, -0.3858, -1.1915, -0.7939, -0.5287,\n",
       "                      -1.0818, -0.6826, -1.1990, -0.5504, -0.6985, -0.5265, -0.7031, -0.7221,\n",
       "                      -0.6240, -0.7923, -0.7477, -0.6211, -0.4847, -0.9305, -0.8672, -0.9640,\n",
       "                      -0.5970, -0.7963, -1.0095, -0.7041, -0.6201, -0.8272, -0.8642, -0.7149,\n",
       "                      -0.1486, -0.8913, -1.5533, -0.5700, -0.7954, -0.9663, -0.5202, -1.0395,\n",
       "                      -1.0383, -0.8046, -0.7002, -1.1470, -0.5868, -0.7367, -0.7754, -0.4929,\n",
       "                      -0.6644, -0.7077, -0.7026, -0.8174, -0.6611, -0.5234, -0.6234, -0.5961,\n",
       "                      -0.5143, -0.7454, -0.6751, -0.6286, -1.0052, -1.2545, -0.4291, -1.1618,\n",
       "                      -0.8726, -0.8077, -1.0296, -0.9257, -1.2397, -0.9032, -1.1586, -0.6834,\n",
       "                      -0.3203, -0.7832,  0.3590, -0.7680, -0.7617, -0.9250, -0.9485, -0.8702,\n",
       "                      -0.5869, -0.2732, -1.1147, -0.6329, -0.7087, -0.5849, -1.2142, -0.8736,\n",
       "                      -1.2073, -0.4033, -0.6485, -0.9067, -0.1779, -0.7485, -1.5761, -0.8470,\n",
       "                      -0.5936, -1.3240, -0.8528, -0.7504, -0.8944, -0.4018, -0.9139, -0.2481,\n",
       "                      -1.2777, -0.6512, -0.5649,  0.1888, -0.9627, -0.8056, -0.6371, -0.6132,\n",
       "                      -1.0691, -0.5870, -1.7209, -0.3129, -0.5256, -1.5523, -0.5553, -0.8495,\n",
       "                      -0.0422, -0.3014, -0.5068, -0.6025, -0.5146, -1.0281, -0.7575, -1.0009,\n",
       "                      -0.9620, -0.3392, -0.7340, -0.9131, -1.0636, -0.7621, -0.8121, -0.3924,\n",
       "                      -1.2843, -0.4223, -0.8621, -0.7582, -0.4664, -0.6746, -0.9525, -0.7069,\n",
       "                      -0.6494, -1.2329, -0.9510, -0.5987, -0.8122, -0.2585, -2.3511, -0.4336,\n",
       "                      -0.4982, -1.0574, -0.6793, -0.3944, -0.4837, -0.6630, -1.0718, -0.7356,\n",
       "                      -0.3307, -0.7226, -0.8178, -0.3179, -0.6890, -0.4605, -1.2686, -0.4719,\n",
       "                      -0.4427, -0.6833, -0.3259, -0.6951, -1.1053, -0.9664, -0.7898, -0.8774,\n",
       "                      -0.1740, -0.9885, -0.3770, -0.7380, -1.2202, -1.1224, -0.1347, -0.7182,\n",
       "                      -0.7212, -0.3407, -0.2000, -0.8056, -0.8408, -0.6210, -1.0593, -3.0333,\n",
       "                      -0.3586, -1.0164, -0.5091, -0.7474, -0.7502, -0.5594, -0.7063, -0.6198,\n",
       "                      -1.2757, -0.9516, -0.7334, -0.6935, -0.7772, -0.7707, -0.4082, -1.0337,\n",
       "                      -0.6719, -0.8486, -0.8674, -0.7073, -0.8083, -0.7788, -0.8789, -0.3953,\n",
       "                      -1.1115, -0.7206, -0.9332,  0.0890, -0.8098, -0.9703, -1.0459, -0.3908,\n",
       "                      -0.4484, -0.9225, -0.8505, -0.7879, -0.9284, -1.4579, -1.1448, -0.5124,\n",
       "                      -0.8017, -0.4046, -0.8617, -0.6982, -0.5067, -0.4861, -0.2880, -0.7619,\n",
       "                      -0.6610, -0.4801, -0.9662, -0.7079, -0.0607, -0.8820, -0.4338, -0.8083],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.running_mean',\n",
       "              tensor([-3.6716, -4.4998, -3.3928, -4.3136, -4.6425, -6.1826,  2.4349, -2.4528,\n",
       "                      -5.3190, -4.4415, -5.0642, -4.3423, -0.9123, -1.6092, -3.6615, -4.2036,\n",
       "                      -5.0053, -5.8946, -1.9175, -2.6510, -2.0259, -3.2013, -2.9067, -3.4250,\n",
       "                      -3.6012, -2.8132,  0.2122, -1.4167, -2.3176, -4.8757, -1.5723, -3.1555,\n",
       "                      -3.8470, -3.5484, -4.6692, -1.2059, -5.4423, -6.5821, -2.9674, -3.6584,\n",
       "                      -5.3014, -2.0395, -3.5407, -3.4778, -3.0371,  0.2025, -0.0142, -0.6985,\n",
       "                      -3.6262, -5.2778, -1.2839, -0.6250, -3.5389, -1.7519, -7.4743, -1.9592,\n",
       "                      -5.1269, -5.5833, -3.8974, -5.2696, -4.9513, -2.1108, -5.9900, -2.8826,\n",
       "                       0.3543, -2.9952, -4.6341, -2.8891, -3.0032, -5.8718, -3.6505, -2.1396,\n",
       "                      -3.3803,  0.5207, -1.3521, -3.7571, -0.0504, -3.8170,  2.6244, -3.5578,\n",
       "                      -5.7465, -5.9931, -2.0362, -7.6235, -3.8140, -1.5547, -4.4511, -4.1878,\n",
       "                      -3.8005, -3.5834,  1.3269, -3.9786, -1.9909, -3.7507,  0.1906, -6.9346,\n",
       "                       1.3870, -2.8135, -3.8540, -1.1593, -4.5123, -2.3343,  0.0959, -1.7825,\n",
       "                      -3.6221, -1.7327, -0.6540, -6.8581, -0.6884, -6.3777, -2.5159, -0.2136,\n",
       "                      -0.7809, -4.1160, -2.5850, -3.2121, -4.0634, -1.8600, -3.4295,  1.6156,\n",
       "                      -3.2638, -5.7367, -4.3896, -3.4009, -1.5803,  5.5251, -3.7837, -1.5342,\n",
       "                      -1.6288, -2.4254, -4.1731, -1.9629, -4.0375, -4.3813, -1.0746, -1.9116,\n",
       "                      -3.3286, -1.3124, -3.1905, -2.5201, -4.8249, -2.8369, -2.2420, -8.3987,\n",
       "                       5.3649, -3.0550, -4.4956, -3.3828, -1.4829, -3.6053, -4.1002, -4.3864,\n",
       "                      -3.4545, -1.2725, -1.7832, -3.7080, -3.4804, -4.7292,  0.0678, -5.4915,\n",
       "                      -2.0888, -2.6093, -2.9651, -3.9596, -3.0122, -6.6763, -3.8709, -2.6090,\n",
       "                      -0.7712, -2.2966, -2.8729, -2.7528, -2.3835, -3.5038, -8.4375, -5.2468,\n",
       "                      -1.0841, -4.8295, -5.4690, -5.4507, -4.4401,  0.3135, -4.0276, -3.3131,\n",
       "                      -2.2113, -4.1910, -6.2188, -0.8436,  0.2293,  1.4562, -6.2594, -3.6078,\n",
       "                      -1.6662, -3.9950, -2.1669, -4.7181, -0.4500, -3.1043, -0.6794, -1.1833,\n",
       "                      -4.7434,  0.2188, -2.0610,  0.3194, -0.1356, -4.5057, -3.3635, -1.3687,\n",
       "                      -4.0310, -2.8598, -3.1592, -0.2566, -2.2996, -4.2440,  0.4073, -4.5379,\n",
       "                      -4.2696, -3.6634, -3.5430, -2.7403, -3.3694,  1.1686, -2.6047, -2.3251,\n",
       "                      -3.5192, -2.8872, -1.9932, -2.2582, -3.1104, -7.5036, -1.8841, -0.2710,\n",
       "                      -2.5072,  2.6645, -1.1727, -3.0118, -4.0894, -5.0187, -3.1375, -3.0995,\n",
       "                      -4.8769, -0.5808, -2.1449, -0.8675, -2.4263, -5.6197, -5.6222, -1.7829,\n",
       "                      -3.5098, -1.2072, -3.4861, -3.3749, -3.2012, -3.6895, -4.1671, -1.3001],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.running_var',\n",
       "              tensor([5.7976e+00, 1.0303e+01, 1.8532e+01, 8.1071e+00, 1.4653e+01, 3.4577e+01,\n",
       "                      6.6280e+00, 1.8159e+01, 1.8759e+01, 9.0697e+00, 1.4710e+01, 7.8978e+00,\n",
       "                      1.3225e+01, 5.6688e+00, 1.2380e+01, 5.3476e+00, 1.6595e+01, 1.1957e+01,\n",
       "                      4.3686e+00, 5.3855e+00, 7.4871e+00, 1.5339e+01, 1.3848e+01, 1.3873e+01,\n",
       "                      7.8771e+00, 2.1859e+01, 3.1837e-01, 9.6762e+00, 2.1956e+01, 1.9514e+01,\n",
       "                      5.6002e+00, 8.6276e+00, 1.2053e+01, 1.1066e+01, 1.0630e+01, 1.0872e+01,\n",
       "                      1.0524e+01, 1.3720e+01, 1.5714e+01, 1.2064e+01, 1.4017e+01, 1.1442e+01,\n",
       "                      8.7009e+00, 7.3242e+00, 1.1817e+01, 1.1544e+01, 1.1481e+01, 7.0910e+00,\n",
       "                      7.4718e+00, 6.3352e+00, 3.4908e+00, 7.1058e+00, 1.2840e+01, 4.7154e+00,\n",
       "                      1.7992e+01, 4.9718e+00, 1.1630e+01, 1.3115e+01, 1.5667e+01, 1.6031e+01,\n",
       "                      9.7328e+00, 1.1478e+01, 1.5452e+01, 1.1953e+01, 1.5424e+01, 1.4640e+01,\n",
       "                      1.1706e+01, 1.8597e+01, 6.2712e+00, 1.6643e+01, 9.9804e+00, 5.3885e+00,\n",
       "                      2.4392e+01, 3.0136e+00, 9.2681e+00, 1.4552e+01, 3.7358e+00, 1.0519e+01,\n",
       "                      5.7727e+00, 8.1866e+00, 1.3902e+01, 9.1539e+00, 1.3845e+01, 1.7084e+01,\n",
       "                      5.6192e+00, 3.4896e+00, 8.8599e+00, 6.4242e+00, 1.5906e+01, 1.4505e+01,\n",
       "                      4.7681e+00, 5.7155e+00, 1.1734e+01, 6.9707e+00, 5.5136e-01, 1.6104e+01,\n",
       "                      2.5965e+00, 1.0944e+01, 8.1110e+00, 1.0195e+01, 1.6952e+01, 1.3493e+01,\n",
       "                      6.0901e+00, 8.9571e+00, 8.6324e+00, 6.5912e+00, 3.7050e+00, 1.6901e+01,\n",
       "                      4.3927e+00, 1.3979e+01, 1.5108e+01, 2.7228e-01, 5.8820e+00, 7.7603e+00,\n",
       "                      9.9676e+00, 1.1688e+01, 5.9136e+00, 7.2226e+00, 9.1692e+00, 1.8006e+01,\n",
       "                      1.0924e+01, 1.6213e+01, 9.1611e+00, 1.4584e+01, 8.2220e+00, 1.5949e+01,\n",
       "                      8.6650e+00, 5.9576e+00, 1.2013e+01, 6.9288e+00, 1.4488e+01, 7.2608e+00,\n",
       "                      1.0110e+01, 1.5923e+01, 1.0383e+01, 8.5505e+00, 6.5930e+00, 1.4222e+01,\n",
       "                      8.4192e+00, 9.4597e+00, 2.0852e+01, 9.6252e+00, 6.1861e+00, 1.9565e+01,\n",
       "                      6.1862e+00, 1.0905e+01, 2.3752e+01, 1.0633e+01, 8.1979e+00, 1.2115e+01,\n",
       "                      5.8161e+00, 2.5614e+01, 1.5373e+01, 6.8529e+00, 4.8582e+00, 7.2487e+00,\n",
       "                      2.3886e+01, 1.2444e+01, 9.5726e-03, 2.1607e+01, 1.3386e+01, 8.6087e+00,\n",
       "                      1.9674e+01, 1.5994e+01, 1.9218e+01, 1.3990e+01, 5.4658e+00, 1.3306e+01,\n",
       "                      1.0966e+01, 7.3778e+00, 4.8761e+00, 7.2859e+00, 5.9489e+00, 7.2654e+00,\n",
       "                      1.2752e+01, 9.5316e+00, 3.8809e+00, 1.2131e+01, 1.4180e+01, 7.5931e+00,\n",
       "                      1.1456e+01, 5.7739e+00, 1.1338e+01, 1.2067e+01, 1.4043e+01, 7.3046e+00,\n",
       "                      1.2074e+01, 9.8756e+00, 4.7968e-01, 6.9488e+00, 9.4756e+00, 4.8433e+00,\n",
       "                      1.2606e+01, 1.4359e+01, 1.3846e+01, 1.1663e+01, 6.2291e+00, 7.9061e+00,\n",
       "                      2.4580e+00, 2.8053e+00, 8.1402e+00, 3.1479e+00, 6.6411e+00, 3.8595e-01,\n",
       "                      8.5913e+00, 1.4635e+01, 1.4451e+01, 1.1988e+01, 8.3239e+00, 1.5531e+01,\n",
       "                      6.2787e+00, 1.2057e+01, 8.8100e+00, 1.2882e+01, 3.0027e-01, 1.1884e+01,\n",
       "                      7.3730e+00, 1.1336e+01, 9.5796e+00, 6.9708e+00, 2.2095e+01, 5.0976e+00,\n",
       "                      8.6211e+00, 1.3601e+01, 1.0556e+01, 6.3089e+00, 7.0896e+00, 1.6363e+01,\n",
       "                      1.1323e+01, 1.5216e+01, 9.0809e+00, 1.5924e+01, 1.8947e+01, 6.5797e+00,\n",
       "                      1.5773e+01, 1.1652e+01, 1.3167e+01, 1.4312e+01, 8.1882e+00, 7.4336e+00,\n",
       "                      1.5864e+01, 9.0699e+00, 4.2691e+00, 9.8060e+00, 4.7070e+00, 1.8503e+01,\n",
       "                      1.4675e+01, 6.3952e+00, 1.0764e+01, 1.0295e+01, 1.0047e+01, 1.5425e+01,\n",
       "                      1.5972e+01, 1.4392e+01, 1.6011e+01, 8.0134e+00], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.weight',\n",
       "              tensor([0.9051, 0.9394, 0.3467, 1.0366, 1.0479, 1.1572, 1.6049, 1.1137, 0.9935,\n",
       "                      1.1752, 0.8874, 1.0937, 0.6876, 1.1102, 1.4864, 1.3248, 0.9897, 1.4706,\n",
       "                      1.4177, 0.2613, 1.1516, 0.9729, 1.2617, 0.2820, 1.0827, 0.2616, 1.4487,\n",
       "                      1.0664, 1.4253, 1.3209, 1.0332, 1.2626, 0.9325, 1.1220, 0.8981, 1.0424,\n",
       "                      0.9619, 1.2507, 1.3945, 1.1734, 0.9084, 0.8654, 1.2673, 1.0337, 1.0987,\n",
       "                      1.3766, 1.6624, 0.8357, 1.0707, 0.9537, 0.2633, 0.9885, 0.9755, 1.3231,\n",
       "                      1.2518, 1.4758, 1.3703, 1.1539, 1.1889, 1.1905, 1.4671, 1.0795, 0.8962,\n",
       "                      0.8735, 1.1473, 1.0061, 0.9262, 0.9056, 0.9279, 1.1607, 1.1400, 1.3418,\n",
       "                      0.2692, 1.0091, 1.3077, 0.5176, 0.9112, 0.9307, 1.0229, 0.8897, 1.0297,\n",
       "                      0.9391, 1.0971, 0.4626, 0.9116, 1.4098, 1.0808, 1.0182, 1.5772, 1.0186,\n",
       "                      1.0702, 0.9926, 1.3717, 0.9138, 1.1040, 1.0963, 0.8279, 1.0532, 1.3980,\n",
       "                      1.2943, 1.0913, 0.8435, 1.0859, 0.9802, 1.0216, 0.2935, 1.1645, 0.9617,\n",
       "                      1.4009, 1.1233, 0.9578, 0.6571, 1.0725, 0.7002, 1.0372, 1.1292, 1.2509,\n",
       "                      0.9716, 1.5299, 1.2976, 1.0172, 1.2507, 1.0353, 1.0831, 0.9625, 0.9419,\n",
       "                      1.1977, 1.0909, 1.2755, 0.8902, 1.2145, 1.3266, 0.8319, 0.9505, 0.9411,\n",
       "                      1.1432, 0.9254, 1.1651, 1.1642, 0.2505, 1.2972, 1.1613, 0.9954, 1.1288,\n",
       "                      1.1554, 1.1024, 1.4579, 0.8870, 1.1077, 1.3331, 1.1827, 1.0637, 0.9267,\n",
       "                      1.1762, 1.0574, 1.2458, 1.3292, 0.9216, 1.0776, 1.2446, 1.3153, 1.2265,\n",
       "                      1.1726, 1.0782, 0.2623, 0.8875, 0.2963, 1.2376, 1.4084, 1.0460, 1.2456,\n",
       "                      1.2219, 1.0095, 1.0642, 0.9782, 1.2341, 1.0097, 1.0705, 0.8490, 0.9098,\n",
       "                      1.0768, 1.0270, 1.1807, 1.2606, 1.3560, 1.4065, 1.1395, 1.1043, 1.0956,\n",
       "                      0.9400, 0.9232, 0.9482, 1.0033, 0.7078, 1.1307, 1.1774, 0.9191, 1.1546,\n",
       "                      0.9854, 0.8554, 1.0341, 0.8977, 0.8860, 0.9033, 1.0850, 1.0711, 1.1451,\n",
       "                      0.9898, 1.1208, 1.0563, 1.3754, 0.8993, 1.0484, 0.8753, 0.9922, 1.2163,\n",
       "                      1.0892, 1.1947, 0.7565, 0.9142, 1.3299, 0.9942, 1.0805, 1.3669, 0.8534,\n",
       "                      1.3016, 1.4345, 1.2004, 1.1323, 0.7956, 0.9888, 1.0292, 1.1574, 1.1866,\n",
       "                      1.1543, 1.0344, 1.4174, 0.3030, 1.4229, 1.2801, 0.2937, 0.9351, 0.9618,\n",
       "                      1.1582, 1.2652, 0.9315, 1.1234, 1.0876, 1.0357, 1.2522, 0.9250, 1.1716,\n",
       "                      1.2080, 1.2942, 1.3198, 1.2777], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.bias',\n",
       "              tensor([-0.6634, -0.5544, -0.0422, -0.6581, -0.8572, -0.9712, -1.6261, -0.5950,\n",
       "                      -0.7201, -1.2496, -0.5318, -0.7978, -0.1393, -0.6118, -1.3631, -1.3863,\n",
       "                      -0.6188, -1.2326, -1.6330, -0.1872, -0.8443, -0.7549, -1.2820, -0.0505,\n",
       "                      -1.1499, -0.0781, -1.2581, -1.0880, -1.3273, -1.2754, -0.6035, -0.7674,\n",
       "                      -0.4481, -1.0971, -0.9998, -0.6411, -0.5971, -1.3235, -1.3134, -0.8110,\n",
       "                      -0.5895, -0.6744, -0.8855, -1.1614, -1.0477, -1.3588, -1.3315, -0.6502,\n",
       "                      -1.0932, -0.7254, -0.3861, -0.5992, -1.0614, -1.1524, -1.2114, -1.0342,\n",
       "                      -1.3392, -0.7853, -0.7540, -0.9350, -1.7840, -0.9019, -0.7942, -0.5565,\n",
       "                      -1.1643, -0.6610, -0.6357, -0.4942, -0.7252, -1.0780, -0.9504, -1.2680,\n",
       "                      -0.0283, -0.9093, -1.0604,  0.0534, -0.5707, -0.8475, -0.7689, -0.7964,\n",
       "                      -1.0437, -0.7244, -0.6308, -0.0799, -0.6952, -1.1794, -0.9914, -0.9248,\n",
       "                      -1.2379, -0.8964, -1.0408, -0.6191, -1.2270, -0.5548, -0.9034, -1.1669,\n",
       "                      -0.6484, -0.8183, -1.1430, -1.5660, -0.9298, -0.2687, -0.6611, -0.5908,\n",
       "                      -0.7479, -0.0536, -1.2109, -0.8190, -1.3240, -0.9726, -0.5736, -0.2446,\n",
       "                      -0.9323, -0.2670, -0.8135, -0.9782, -1.0693, -0.8946, -1.2197, -1.2017,\n",
       "                      -0.8493, -1.0271, -0.7801, -0.9973, -0.5407, -0.5843, -0.8183, -0.9339,\n",
       "                      -1.1637, -0.6353, -0.8803, -1.1417, -0.6053, -0.5750, -0.9905, -1.1236,\n",
       "                      -0.7335, -0.7768, -1.1079, -0.0484, -1.5820, -1.2682, -0.9510, -0.8856,\n",
       "                      -1.1036, -1.2498, -1.1422, -0.8046, -0.9191, -1.1010, -0.9548, -0.9208,\n",
       "                      -0.7223, -0.7993, -0.9130, -0.6914, -1.4146, -0.8214, -0.7783, -0.7009,\n",
       "                      -1.1782, -0.8517, -0.7981, -1.0004, -0.0658, -0.6777,  0.1841, -0.9849,\n",
       "                      -1.3402, -0.8736, -0.5267, -0.7914, -0.9291, -1.1181, -0.5579, -0.9340,\n",
       "                      -1.1616, -1.0515, -0.6710, -0.8138, -0.8020, -0.6899, -1.1364, -1.0139,\n",
       "                      -0.7805, -1.3099, -0.3936, -0.8767, -0.4665, -0.8453, -0.6968, -0.5989,\n",
       "                      -0.8351, -0.6806, -0.9338, -1.0715, -0.7662, -1.4438, -0.6182, -0.7659,\n",
       "                      -1.0537, -0.5319, -0.5135, -0.9045, -0.5828, -0.8373, -0.9134, -0.7420,\n",
       "                      -1.1932, -0.9939, -0.7015, -0.5463, -1.0515, -0.5218, -0.5948, -0.8505,\n",
       "                      -1.0803, -0.9453, -0.5138, -0.3713, -1.3711, -0.6823, -0.7744, -1.3687,\n",
       "                      -0.5889, -0.9297, -1.4539, -0.9427, -0.8768, -0.5206, -1.0093, -0.6510,\n",
       "                      -0.8140, -1.1389, -1.1334, -0.8144, -1.4738,  0.0231, -1.1460, -1.0632,\n",
       "                      -0.0401, -0.7883, -0.5025, -0.6524, -1.0350, -0.7857, -0.7549, -0.8493,\n",
       "                      -0.7969, -0.8876, -0.9356, -0.6092, -1.0583, -1.3752, -1.4297, -1.2696],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.running_mean',\n",
       "              tensor([-3.7632e+00, -9.0942e+00, -5.2324e+00, -1.6265e+01, -5.5120e+00,\n",
       "                      -8.4833e+00, -9.1915e+00, -6.0935e+00, -8.4992e+00, -8.5229e+00,\n",
       "                      -2.8742e+00, -7.1312e+00, -3.9346e+00, -8.3223e+00, -6.6446e+00,\n",
       "                      -1.4633e+01, -1.2050e+01, -7.4102e+00, -4.1665e+00, -3.8852e+00,\n",
       "                      -1.1782e+01,  2.0337e+00, -8.9674e+00, -3.5421e-02, -5.4318e+00,\n",
       "                      -6.3430e-02, -6.1789e+00, -6.2252e-01, -1.2175e+01, -5.7403e+00,\n",
       "                      -1.2922e+01, -5.8772e+00, -2.4498e+00, -1.0857e+01, -5.8939e+00,\n",
       "                      -9.4072e+00, -1.1868e+01, -3.9199e+00, -5.9831e+00, -2.7893e+00,\n",
       "                       3.7596e+00, -3.8224e+00, -3.7453e+00, -4.5187e+00, -5.4211e+00,\n",
       "                      -1.2399e+01, -4.2647e+00, -4.7974e+00, -8.3507e+00, -6.2286e+00,\n",
       "                      -8.4950e-04, -8.1919e+00, -4.1917e+00, -6.9957e+00, -7.5349e+00,\n",
       "                      -6.9743e+00, -9.6604e+00, -1.1177e+01, -7.9157e+00, -1.6553e+01,\n",
       "                      -9.1609e+00, -3.0231e+00, -2.9965e+00, -5.3564e+00, -9.3424e-01,\n",
       "                      -9.2723e+00, -1.2275e+00, -7.0908e+00, -4.9050e+00, -1.0858e+01,\n",
       "                      -7.0457e+00, -9.2624e+00, -1.0445e-01, -7.1027e+00, -8.7540e+00,\n",
       "                      -1.2387e+00, -9.5546e+00, -1.3784e+01, -9.9896e+00, -3.3787e+00,\n",
       "                      -3.7355e+00, -5.9943e+00, -7.1598e+00, -7.0738e+00, -7.9076e+00,\n",
       "                      -1.8110e+00, -4.4033e+00, -1.7395e+00, -8.2204e+00, -6.1652e+00,\n",
       "                      -4.9114e+00, -5.9712e+00, -7.1176e+00, -8.5425e+00, -1.4877e+01,\n",
       "                      -8.2049e+00,  5.1621e+00, -1.2247e+01, -5.9140e+00, -1.8665e+00,\n",
       "                      -1.9099e+00, -3.5394e+00, -5.9519e+00, -1.1243e+01, -1.0292e+01,\n",
       "                       1.1542e-02, -6.1347e+00, -6.6159e+00, -9.0597e+00, -8.9896e+00,\n",
       "                      -1.0409e+01, -7.9867e+00, -8.1136e+00, -3.0078e+00, -3.3415e+00,\n",
       "                      -5.1625e+00, -1.3732e+01, -1.0659e+01, -5.9755e+00, -1.0130e+01,\n",
       "                      -5.5045e+00, -2.5274e+00, -3.5657e+00, -9.2018e+00, -7.4413e+00,\n",
       "                      -7.7006e+00, -7.7164e+00, -9.6146e+00, -6.2727e+00, -1.0488e+01,\n",
       "                      -8.7456e+00, -2.5740e+00, -8.4706e+00, -4.7237e+00, -1.0442e+01,\n",
       "                      -9.2775e+00, -1.2671e+01, -6.6309e+00, -4.2030e+00, -7.1187e-02,\n",
       "                      -6.0836e+00, -1.0300e+01, -8.1018e+00, -2.2341e+00, -1.0689e+01,\n",
       "                      -3.6317e+00, -6.1755e+00, -1.0596e+01, -7.7081e+00, -8.6579e+00,\n",
       "                      -8.9929e+00, -1.1972e+01, -7.4886e+00, -7.2483e+00, -3.7808e+00,\n",
       "                      -6.2587e+00, -9.2261e+00, -1.3240e+00, -5.2833e+00, -9.6430e-01,\n",
       "                      -4.5933e+00, -1.0360e+01, -9.6514e+00, -5.7713e+00,  2.4909e-03,\n",
       "                      -2.9826e+00, -1.4669e+00, -3.6351e+00, -8.7625e+00, -9.2196e+00,\n",
       "                      -7.2660e+00, -6.4894e+00, -1.0512e+01, -4.7800e+00, -4.0744e+00,\n",
       "                      -6.5161e+00, -6.5730e+00, -6.1712e+00, -5.0224e+00, -4.8053e+00,\n",
       "                      -9.2358e+00, -1.0091e+01, -6.6775e+00, -5.6374e+00, -1.1505e+01,\n",
       "                      -6.4864e+00, -4.7991e+00, -1.3428e+01, -4.4413e+00, -1.2248e+01,\n",
       "                      -6.2546e+00, -6.6766e+00, -8.0788e+00,  3.5028e-01, -1.3248e+01,\n",
       "                      -3.1043e+00, -6.8361e+00,  4.3378e-01, -6.2018e+00, -6.6109e+00,\n",
       "                      -8.8146e+00, -5.1341e+00, -3.5145e+00, -5.8523e+00, -1.0397e+01,\n",
       "                      -6.2023e+00, -1.1400e+01, -3.9769e+00,  3.1227e+00, -6.3729e+00,\n",
       "                      -9.1428e+00, -8.1317e+00, -8.6478e+00, -1.1008e+01, -5.5727e+00,\n",
       "                      -9.6256e+00,  2.6206e+00, -8.8840e+00, -3.4394e+00, -1.0024e+01,\n",
       "                       2.8129e+00, -1.0264e+01, -7.9636e+00, -1.0159e+01, -7.5524e+00,\n",
       "                      -7.6272e+00, -5.8084e+00, -7.2452e+00, -1.0212e+01, -2.0675e+00,\n",
       "                      -6.7425e+00, -4.5466e+00, -1.0737e+01, -6.6364e+00, -3.5613e+00,\n",
       "                      -1.0022e+01, -1.0441e+01,  2.3489e+00, -5.4235e+00, -5.9015e+00,\n",
       "                      -5.0889e-02, -1.1071e+01, -1.1174e+01, -1.0034e+01, -6.0598e+00,\n",
       "                      -7.0747e+00, -2.3704e+00, -1.0295e+01, -1.0242e+00, -4.4956e+00,\n",
       "                      -8.1543e+00, -6.5005e+00, -5.4108e+00, -9.8053e+00, -6.2623e+00,\n",
       "                      -9.3068e+00], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.running_var',\n",
       "              tensor([ 40.5723,  65.7030,  11.8584,  67.4836,  26.6316,  50.4351,  54.1779,\n",
       "                       30.1589,  42.8167,  49.9692,  28.4224,  31.3713,  32.0274,  46.6070,\n",
       "                       48.1286,  58.4122,  31.7544,  44.7766,  27.0445,   4.2099,  77.1243,\n",
       "                       30.4201,  58.8890,   0.4141,  20.1350,   0.2635,  45.1380,  20.2287,\n",
       "                       68.0608,  23.5049,  37.5302,  53.7064,  54.6602,  58.0534,  29.1404,\n",
       "                       47.6535,  51.5917,  63.7634,  55.1338,  25.2223,  41.3617,  52.7705,\n",
       "                       34.5100,  53.7506,  58.5715,  46.6809,  34.5419,  36.1039,  36.5626,\n",
       "                       25.8292,   0.2981,  28.9679,  40.5153,  60.2064,  33.9075,  30.9585,\n",
       "                       36.4447,  51.0632,  52.7367,  81.1930,  42.4597,  43.4219,  22.2235,\n",
       "                       40.2748,  34.3417,  72.5276,  45.0313,  53.1840,  34.8067,  42.1514,\n",
       "                       47.2410,  58.1298,   0.4201,  56.7860,  30.6251,  20.6250,  42.2545,\n",
       "                       76.7949,  25.8407,  49.3553,  76.2543,  51.0976,  22.5277,  15.0258,\n",
       "                       38.6420,  30.9443,  61.9598,  59.8144,  44.0024,  55.4643,  46.6360,\n",
       "                       43.7867,  43.8053,  51.5570,  97.5555,  23.4702,  22.3750,  35.2476,\n",
       "                       50.9145,  19.7545,  36.8942,  21.6182,  36.6579,  56.8219,  43.5087,\n",
       "                        0.3208,  36.8081,  42.6586,  53.6447,  42.7517,  53.7115,  24.3025,\n",
       "                       44.2902,  32.6030,  67.9141,  46.2343,  49.2114,  41.4842,  31.3825,\n",
       "                       52.1681,  76.2221,  33.6903,  59.1630,  35.9490,  39.6129,  37.6400,\n",
       "                       32.5703,  65.5450,  30.8750,  45.4082,  45.8819,  26.3946,  47.4205,\n",
       "                       49.1348,  43.3766,  27.2011,  75.8063,  63.7155,  46.3493,   0.3979,\n",
       "                       26.5054,  45.8701,  69.3298,  56.8755,  59.8682,  42.5232,  41.1253,\n",
       "                       43.6935,  53.3741,  32.5585,  35.8902,  43.9328,  45.5414,  31.5621,\n",
       "                       48.7838,  47.2220,  29.6616,  15.5673,  22.2395,  28.9994,  24.2479,\n",
       "                      102.9704,  39.9512,  32.3244,   0.2558,  24.3601,   5.2302,  29.5106,\n",
       "                       41.3319,  75.3155,  37.3672,  22.4993,  59.5364,  46.9117,  39.3268,\n",
       "                       40.9311,  52.5730,  72.9468,  33.1480,  19.0017,  71.2979,  35.3832,\n",
       "                       37.9487,  45.4771,  41.7069,  36.8463,  41.5128,  85.9343,  30.5077,\n",
       "                       42.6010,  37.2925,  42.0592,  56.6934,  15.7602,  47.6612,  30.0385,\n",
       "                       47.0208,  33.2221,  44.7548,  24.5391,  45.9706,  31.9674,  36.1938,\n",
       "                       60.4913,  29.1829,  31.4370,  53.4403,  28.3113,  34.7869,  70.9355,\n",
       "                       68.1365,  40.4803,  36.3636,  47.1711,  22.1173,  38.4825,  39.3975,\n",
       "                       43.7432,  29.4210,  34.8596,  30.4687,  68.7060,  67.3378,  26.3805,\n",
       "                       41.5847,  35.6842,  35.0291,  37.1290,  36.2059,  46.2787,  39.5105,\n",
       "                       37.2341,  50.8404,  27.8260,  38.5722,  46.0524,  38.2611,  10.2442,\n",
       "                       46.6448,  30.8053,   0.3152,  29.1311,  45.0049,  35.8925,  31.2280,\n",
       "                       37.7955,  27.8912,  45.8276,  33.1744,  29.8663,  32.7236,  57.9544,\n",
       "                       47.7023,  37.2118,  48.3244,  38.3405], device='cuda:0')),\n",
       "             ('encoder.base.conv_block3.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.conv1.weight',\n",
       "              tensor([[[[-2.8117e-01, -1.9448e-01, -3.2072e-01],\n",
       "                        [ 1.6667e-01,  7.5469e-03, -1.2761e-01],\n",
       "                        [ 1.5804e-01,  1.4452e-01,  5.4735e-03]],\n",
       "              \n",
       "                       [[ 5.7425e-03, -1.6190e-02, -4.9775e-01],\n",
       "                        [ 6.9577e-02,  3.7016e-02, -2.2179e-01],\n",
       "                        [-2.1399e-01, -1.8292e-01, -2.7259e-01]],\n",
       "              \n",
       "                       [[-3.2275e-02,  6.3697e-02,  3.6232e-02],\n",
       "                        [-1.0834e-02,  2.3389e-01, -1.6246e-02],\n",
       "                        [ 1.3494e-01,  1.3342e-01, -1.4910e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0493e-01,  6.6150e-03,  9.4810e-02],\n",
       "                        [ 7.5323e-02, -8.4515e-02, -2.6031e-01],\n",
       "                        [-4.4923e-02,  1.3767e-01, -1.3903e-02]],\n",
       "              \n",
       "                       [[ 5.8768e-02,  3.0249e-03,  1.2129e-01],\n",
       "                        [-1.4058e-02, -1.4894e-02,  1.1285e-01],\n",
       "                        [ 7.8302e-02, -5.2702e-03,  1.2461e-01]],\n",
       "              \n",
       "                       [[-2.8437e-02, -1.5080e-01, -1.7280e-02],\n",
       "                        [ 2.3192e-01, -1.1718e-02, -4.4942e-02],\n",
       "                        [ 6.1271e-01,  2.4129e-01,  1.4843e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8397e-01,  1.0231e-01, -3.6553e-04],\n",
       "                        [ 3.4619e-01,  2.6139e-01,  2.4499e-01],\n",
       "                        [ 3.5390e-01,  2.8168e-01,  3.8342e-01]],\n",
       "              \n",
       "                       [[ 8.4976e-02,  2.6384e-01,  9.5468e-02],\n",
       "                        [-2.7714e-02, -2.2332e-02, -4.8102e-02],\n",
       "                        [-1.7257e-01,  6.8492e-02,  1.0205e-01]],\n",
       "              \n",
       "                       [[-2.5342e-02, -1.5528e-02, -6.1688e-02],\n",
       "                        [-2.7608e-02, -2.5081e-02, -6.0266e-02],\n",
       "                        [ 6.7514e-04, -1.2479e-03, -4.8764e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2393e-01, -9.4306e-02, -1.9476e-01],\n",
       "                        [ 5.8398e-03, -7.9925e-02, -4.1517e-01],\n",
       "                        [-5.0327e-02, -1.9655e-01, -1.1735e-01]],\n",
       "              \n",
       "                       [[ 2.7297e-01, -4.6044e-02,  2.8592e-02],\n",
       "                        [ 7.4112e-01, -5.0212e-02, -1.0976e-01],\n",
       "                        [ 6.0514e-01, -6.1636e-02,  1.5829e-01]],\n",
       "              \n",
       "                       [[-8.9858e-02, -1.4299e-01, -8.8171e-02],\n",
       "                        [-2.7729e-02, -5.3546e-02,  1.1596e-03],\n",
       "                        [ 1.9970e-01,  5.9318e-02,  1.9625e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5145e-02, -7.8992e-02, -2.5136e-02],\n",
       "                        [-4.0007e-02, -3.4993e-02, -4.9632e-02],\n",
       "                        [ 2.2835e-02, -8.2773e-02, -1.4480e-01]],\n",
       "              \n",
       "                       [[ 8.8546e-02, -1.3631e-03,  7.4954e-05],\n",
       "                        [ 2.7300e-02, -2.4629e-02, -6.8863e-02],\n",
       "                        [ 9.9173e-02,  2.9239e-02, -1.0297e-02]],\n",
       "              \n",
       "                       [[ 1.6983e-02,  3.6542e-03, -6.4787e-02],\n",
       "                        [ 9.0322e-02,  2.4170e-02, -5.2050e-02],\n",
       "                        [ 6.6579e-02,  4.9823e-02, -2.5309e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.4695e-02,  4.1721e-02, -5.1636e-02],\n",
       "                        [-6.5091e-02, -4.3530e-02, -1.4238e-01],\n",
       "                        [-5.6960e-02, -3.9052e-02, -1.4414e-01]],\n",
       "              \n",
       "                       [[ 1.1531e-02,  5.8840e-02,  4.7447e-02],\n",
       "                        [ 6.2048e-02,  1.1637e-01,  5.8397e-02],\n",
       "                        [ 5.2231e-03, -4.5418e-03, -3.0628e-02]],\n",
       "              \n",
       "                       [[ 5.5873e-03,  3.9302e-02, -1.9303e-02],\n",
       "                        [-8.0556e-02,  4.2154e-03, -8.2461e-02],\n",
       "                        [-1.3790e-01, -1.9746e-02, -1.8784e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.5198e-01, -3.6075e-02, -1.4837e-01],\n",
       "                        [-2.3885e-01, -2.8460e-02, -1.0875e-01],\n",
       "                        [-1.4545e-01, -7.0426e-02, -6.8133e-02]],\n",
       "              \n",
       "                       [[-5.5952e-02, -4.0911e-02, -3.3310e-02],\n",
       "                        [-1.7451e-01, -8.7108e-02,  1.2693e-02],\n",
       "                        [-7.0759e-02, -4.8385e-02, -3.3718e-03]],\n",
       "              \n",
       "                       [[ 2.9875e-02,  6.5026e-03, -1.0522e-01],\n",
       "                        [ 9.7180e-02,  5.2470e-02, -5.8483e-02],\n",
       "                        [ 1.0137e-02,  2.4127e-02, -2.8789e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.7989e-02,  1.1075e-01,  9.5427e-02],\n",
       "                        [ 2.2058e-02,  4.7560e-02,  4.7533e-02],\n",
       "                        [-1.4979e-02, -4.1187e-02, -8.4268e-03]],\n",
       "              \n",
       "                       [[-5.8950e-03, -4.3256e-02, -1.0115e-01],\n",
       "                        [-4.2977e-02,  7.3435e-04, -1.7013e-02],\n",
       "                        [-1.0561e-01, -1.1956e-01, -4.2652e-02]],\n",
       "              \n",
       "                       [[-3.0934e-02, -1.9715e-02, -4.4373e-02],\n",
       "                        [ 1.9279e-01,  1.6256e-01,  1.3915e-01],\n",
       "                        [ 4.7260e-02,  1.3291e-01, -8.4166e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3602e-02,  2.0539e-02,  1.2633e-01],\n",
       "                        [-2.9732e-02,  6.9290e-02,  1.5418e-01],\n",
       "                        [ 7.1638e-02,  9.3394e-02,  1.5287e-01]],\n",
       "              \n",
       "                       [[-1.8831e-02,  1.6386e-02, -3.7939e-02],\n",
       "                        [-5.5418e-02,  3.2672e-03, -3.0469e-02],\n",
       "                        [ 1.9739e-03,  4.9307e-02, -2.8697e-02]],\n",
       "              \n",
       "                       [[ 1.1110e-02, -9.3922e-03, -1.0620e-01],\n",
       "                        [ 5.1250e-02,  4.8479e-02, -1.5916e-01],\n",
       "                        [ 2.6691e-02,  6.9313e-02, -1.7979e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.3847e-02, -1.4713e-02, -1.0052e-01],\n",
       "                        [ 1.9321e-02,  8.7875e-03, -5.4893e-02],\n",
       "                        [ 3.4401e-02,  1.7562e-02,  1.9163e-02]],\n",
       "              \n",
       "                       [[-1.8030e-04,  7.7708e-02,  1.5777e-01],\n",
       "                        [ 1.7430e-02,  5.9972e-02,  1.0575e-01],\n",
       "                        [-6.3385e-03,  6.1964e-02,  2.0596e-01]],\n",
       "              \n",
       "                       [[ 4.0382e-02,  1.6917e-01,  1.4179e-01],\n",
       "                        [ 6.5023e-02,  7.9723e-02,  1.8729e-01],\n",
       "                        [ 4.7586e-02,  1.4556e-01,  8.0061e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9561e-02,  1.6063e-02,  4.5139e-02],\n",
       "                        [-1.0781e-01, -1.5374e-02,  8.8728e-05],\n",
       "                        [-4.4376e-02,  5.6114e-03,  6.6437e-02]],\n",
       "              \n",
       "                       [[-2.1091e-02,  1.9502e-03, -5.8937e-02],\n",
       "                        [-4.3717e-02, -4.9178e-03, -1.5190e-01],\n",
       "                        [ 6.7578e-02,  5.1915e-02,  2.1604e-02]],\n",
       "              \n",
       "                       [[ 2.7038e-03, -4.4696e-02, -8.6027e-02],\n",
       "                        [ 8.1351e-02,  3.4863e-02, -1.7840e-01],\n",
       "                        [ 3.4614e-02,  3.6288e-02, -1.2641e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.3675e-03,  1.8449e-02, -4.5892e-02],\n",
       "                        [ 3.9285e-02,  1.1169e-02, -4.6597e-02],\n",
       "                        [ 1.1016e-02, -1.7599e-02, -4.0958e-02]],\n",
       "              \n",
       "                       [[ 1.7124e-02,  4.0852e-02,  7.1878e-02],\n",
       "                        [ 1.9256e-02,  2.0039e-02,  6.9166e-02],\n",
       "                        [ 8.0109e-02,  1.0178e-01,  1.2642e-01]],\n",
       "              \n",
       "                       [[-1.3671e-02,  2.6154e-02, -1.1227e-03],\n",
       "                        [-5.0951e-02,  1.0144e-02, -8.1067e-02],\n",
       "                        [-4.0022e-02, -1.2864e-02, -1.0272e-01]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.conv2.weight',\n",
       "              tensor([[[[-1.3141e-01, -1.7014e-01, -3.1536e-01],\n",
       "                        [ 1.4788e-04, -1.2086e-01, -3.0856e-01],\n",
       "                        [-5.1835e-02, -1.7605e-01, -3.0941e-01]],\n",
       "              \n",
       "                       [[-1.5246e-01, -1.2831e-01, -4.4812e-02],\n",
       "                        [-1.6314e-01, -1.2917e-01, -7.5320e-02],\n",
       "                        [-1.5122e-01, -1.1717e-01, -1.5710e-01]],\n",
       "              \n",
       "                       [[-5.3818e-02, -5.1342e-02, -1.5757e-01],\n",
       "                        [-7.5635e-02, -9.9171e-02, -2.1828e-01],\n",
       "                        [-1.0729e-03, -1.0431e-01, -2.2602e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4321e-02, -2.2552e-02, -8.8848e-02],\n",
       "                        [-2.5956e-02, -3.5327e-02, -1.3773e-01],\n",
       "                        [ 8.9133e-03,  3.0740e-03, -1.0050e-01]],\n",
       "              \n",
       "                       [[ 6.3828e-02,  1.4987e-05, -3.2330e-02],\n",
       "                        [ 1.6951e-03, -2.7668e-02, -1.7322e-01],\n",
       "                        [-6.9142e-03, -5.0586e-02, -1.9127e-01]],\n",
       "              \n",
       "                       [[-3.0931e-02, -6.4165e-02, -1.4262e-01],\n",
       "                        [-5.3583e-02, -1.3207e-01, -2.6642e-01],\n",
       "                        [-4.2838e-02, -6.4026e-02, -2.8391e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.9623e-02, -6.3867e-02,  2.5452e-02],\n",
       "                        [ 1.1098e-01, -3.8810e-02,  1.3309e-01],\n",
       "                        [ 1.2145e-01, -2.1395e-02,  1.1927e-01]],\n",
       "              \n",
       "                       [[ 2.8668e-01,  1.7305e-02,  8.8408e-02],\n",
       "                        [ 2.5384e-01, -1.9117e-01, -2.0238e-01],\n",
       "                        [ 2.4004e-01, -2.0833e-01, -1.6091e-01]],\n",
       "              \n",
       "                       [[-2.6671e-02, -1.1001e-01,  3.0393e-02],\n",
       "                        [ 4.0007e-04, -1.1037e-01,  4.0861e-03],\n",
       "                        [-1.8974e-02, -1.4899e-01,  2.3437e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.5335e-02, -6.9298e-02, -4.2384e-03],\n",
       "                        [-3.2748e-02, -7.9837e-02, -3.2012e-02],\n",
       "                        [-9.6534e-02, -1.6497e-01, -8.8456e-02]],\n",
       "              \n",
       "                       [[-1.4191e-02, -5.7730e-02,  7.7663e-02],\n",
       "                        [-1.6944e-02, -1.2329e-01,  6.6457e-02],\n",
       "                        [-3.9793e-02, -5.5077e-02,  1.8633e-02]],\n",
       "              \n",
       "                       [[-4.3596e-02, -1.3971e-01,  1.0534e-02],\n",
       "                        [-4.4777e-02, -1.0370e-01,  2.5256e-02],\n",
       "                        [-2.9126e-02, -1.2420e-01,  1.6884e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2084e-01, -6.4760e-02,  1.3030e-01],\n",
       "                        [-1.3044e-01, -2.5075e-02,  1.6151e-02],\n",
       "                        [-8.7644e-02,  1.5531e-03,  1.7084e-02]],\n",
       "              \n",
       "                       [[ 1.0630e-01,  6.8825e-02,  1.0841e-01],\n",
       "                        [ 6.3294e-02,  5.6313e-02,  9.1738e-02],\n",
       "                        [-8.5978e-02,  4.0142e-03,  4.2442e-02]],\n",
       "              \n",
       "                       [[-7.9506e-02, -5.3952e-01, -4.3850e-02],\n",
       "                        [-1.0070e-01, -6.0278e-01, -6.0825e-02],\n",
       "                        [-4.1294e-02, -4.5038e-01, -5.5793e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.0779e-02, -9.0226e-03,  3.3375e-03],\n",
       "                        [ 8.1960e-04, -7.6463e-02, -3.6247e-02],\n",
       "                        [ 1.9942e-02, -4.3963e-02, -3.7640e-02]],\n",
       "              \n",
       "                       [[-4.5117e-02, -9.3657e-02, -1.9836e-03],\n",
       "                        [-5.8529e-02, -8.0018e-02, -3.1515e-02],\n",
       "                        [-1.2475e-02, -7.1371e-02, -4.3010e-03]],\n",
       "              \n",
       "                       [[-5.3049e-02, -1.5731e-01, -2.5275e-02],\n",
       "                        [-5.1301e-02, -2.0356e-01, -2.3456e-02],\n",
       "                        [-2.6011e-02, -1.6314e-01, -5.0286e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.3632e-03, -1.2925e-02,  6.8488e-04],\n",
       "                        [-9.8775e-02, -8.1714e-02, -3.4547e-02],\n",
       "                        [-1.1710e-02, -7.6958e-02, -6.0914e-02]],\n",
       "              \n",
       "                       [[-1.0509e-01, -1.0036e-01, -3.5899e-02],\n",
       "                        [-1.3978e-01, -1.4804e-01, -3.0534e-02],\n",
       "                        [-1.9116e-01, -1.2482e-01, -7.7175e-02]],\n",
       "              \n",
       "                       [[ 1.0296e-02, -6.9565e-02,  7.9738e-02],\n",
       "                        [ 2.8699e-02, -1.6072e-01,  6.3567e-02],\n",
       "                        [ 1.6107e-02, -1.5727e-01,  4.8203e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.1035e-02, -1.2945e-01,  1.2868e-02],\n",
       "                        [-1.6226e-01, -2.2084e-01, -4.9709e-03],\n",
       "                        [-2.6686e-02, -8.8472e-02,  4.4570e-02]],\n",
       "              \n",
       "                       [[-5.2616e-03, -5.7111e-02,  5.4005e-02],\n",
       "                        [-2.7419e-02, -9.5018e-02,  4.9039e-02],\n",
       "                        [-2.7858e-04, -2.4506e-02,  3.1993e-02]],\n",
       "              \n",
       "                       [[-3.8276e-02, -7.3607e-02, -9.0714e-03],\n",
       "                        [-5.5761e-02, -1.2196e-01,  4.7025e-03],\n",
       "                        [-1.7847e-02, -1.2619e-01,  4.5440e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.4819e-02, -1.4828e-01, -1.0668e-01],\n",
       "                        [ 4.5886e-02,  2.8900e-02,  4.0922e-02],\n",
       "                        [ 1.8913e-03,  2.3505e-02,  1.6824e-01]],\n",
       "              \n",
       "                       [[ 1.5831e-01,  1.1025e-01,  3.2725e-01],\n",
       "                        [ 3.3227e-01,  2.0414e-01,  3.9934e-01],\n",
       "                        [ 3.2118e-01,  2.7469e-01,  3.1816e-01]],\n",
       "              \n",
       "                       [[ 4.3839e-03, -1.8127e-01,  3.0586e-02],\n",
       "                        [-5.1334e-02, -2.2614e-01,  6.0986e-02],\n",
       "                        [-9.7718e-03, -2.2800e-01,  7.6102e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.9273e-02, -9.4798e-02, -1.8765e-02],\n",
       "                        [ 2.7452e-02, -1.2884e-01, -6.5547e-03],\n",
       "                        [-1.1060e-01, -2.2181e-01, -8.4998e-02]],\n",
       "              \n",
       "                       [[-1.2539e-02, -9.0758e-02,  3.2262e-02],\n",
       "                        [-2.7983e-02, -1.2655e-01,  1.7510e-03],\n",
       "                        [-7.8804e-03, -1.0630e-01,  3.6500e-02]],\n",
       "              \n",
       "                       [[-4.5780e-02, -1.7082e-01,  3.4723e-02],\n",
       "                        [-4.5897e-02, -2.2459e-01, -1.2138e-02],\n",
       "                        [-5.9276e-02, -1.9904e-01, -7.6359e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.4527e-02,  2.3626e-03,  3.5323e-02],\n",
       "                        [ 5.2964e-02,  8.6002e-03,  9.5076e-02],\n",
       "                        [ 2.5534e-01,  2.2776e-01,  6.3691e-01]],\n",
       "              \n",
       "                       [[-3.1473e-01, -1.5584e-01, -2.4066e-01],\n",
       "                        [-5.6614e-01, -2.5919e-01, -4.8721e-01],\n",
       "                        [-4.7625e-01, -4.3592e-01, -5.6699e-01]],\n",
       "              \n",
       "                       [[-8.0138e-02, -2.7227e-01, -3.8287e-03],\n",
       "                        [-8.9857e-02, -3.3922e-01, -7.3446e-03],\n",
       "                        [-8.2277e-02, -2.2914e-01, -2.5482e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.4436e-02, -1.6535e-01, -6.6169e-02],\n",
       "                        [-1.0076e-01, -1.9541e-01, -2.1543e-02],\n",
       "                        [-4.8573e-02, -2.3831e-01, -7.6474e-02]],\n",
       "              \n",
       "                       [[-6.5030e-02, -1.0340e-01, -1.7654e-02],\n",
       "                        [-4.2388e-02, -9.1843e-02, -4.4946e-02],\n",
       "                        [-5.0771e-02, -9.4325e-02, -3.5689e-02]],\n",
       "              \n",
       "                       [[-1.0607e-01, -1.3761e-01, -1.6891e-01],\n",
       "                        [-7.1688e-02, -1.0667e-01, -9.9844e-02],\n",
       "                        [-6.6565e-02, -1.0376e-01, -2.3241e-02]]]], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.weight',\n",
       "              tensor([1.0171, 0.5798, 0.5005, 0.9467, 0.4131, 0.9769, 0.4462, 1.0130, 0.9361,\n",
       "                      1.1435, 1.0755, 0.8172, 1.2160, 1.1708, 0.8326, 1.0605, 1.3565, 1.1408,\n",
       "                      0.9933, 1.1301, 1.0148, 1.1272, 0.9770, 0.5058, 0.8135, 0.6770, 1.1596,\n",
       "                      1.0459, 1.0975, 1.0943, 1.0097, 0.8133, 1.1153, 0.8899, 1.0428, 1.2536,\n",
       "                      0.9832, 0.6203, 0.9139, 0.8731, 0.6918, 1.1260, 0.2733, 1.0130, 1.0926,\n",
       "                      1.0720, 1.1631, 1.1839, 0.5973, 1.1405, 1.1763, 0.9800, 1.0225, 1.0436,\n",
       "                      0.8502, 1.1530, 0.9835, 1.3239, 0.6362, 0.9547, 0.8648, 0.7036, 0.9891,\n",
       "                      0.8956, 0.6684, 1.0972, 0.9076, 0.6384, 0.8603, 1.0418, 0.8226, 0.9889,\n",
       "                      0.4692, 0.4991, 0.8975, 0.8536, 1.2099, 0.9635, 1.1211, 1.0741, 1.1748,\n",
       "                      1.0328, 0.9639, 0.8464, 0.9222, 0.8646, 0.9812, 1.0259, 0.9026, 1.0985,\n",
       "                      1.3200, 1.3520, 0.8091, 0.8493, 1.0194, 0.5287, 0.9658, 0.9977, 0.9788,\n",
       "                      1.3655, 0.4898, 0.7785, 0.9938, 0.4714, 0.3356, 0.9735, 0.8762, 0.8690,\n",
       "                      1.3053, 0.7439, 0.7643, 0.6878, 1.0019, 1.0641, 1.0696, 1.1539, 1.1049,\n",
       "                      0.8718, 1.3012, 0.9538, 0.9531, 0.5643, 1.0746, 0.9723, 0.8656, 1.3475,\n",
       "                      0.9380, 0.8953, 1.3727, 0.4535, 1.1457, 0.6542, 1.0409, 1.0981, 0.9023,\n",
       "                      1.1144, 1.0815, 1.2134, 0.8978, 0.9925, 0.8624, 1.0421, 1.3380, 1.1504,\n",
       "                      0.9870, 0.4670, 1.0330, 1.1302, 1.1419, 1.2744, 1.2785, 1.2513, 1.0941,\n",
       "                      1.1802, 1.2290, 1.3752, 0.9396, 0.9662, 0.9707, 1.0778, 0.3860, 0.9183,\n",
       "                      1.1586, 0.8619, 0.6188, 1.1147, 1.3675, 1.0019, 1.1476, 1.0775, 1.0792,\n",
       "                      1.1930, 0.9706, 0.9071, 0.9174, 0.9868, 0.7037, 0.7321, 0.8768, 1.0496,\n",
       "                      0.9915, 1.0660, 0.8966, 0.9964, 0.8852, 1.2159, 1.1580, 0.7111, 0.4730,\n",
       "                      1.0353, 1.0192, 0.8928, 1.2706, 1.4263, 0.9980, 0.3532, 0.4918, 0.9829,\n",
       "                      0.7474, 1.0839, 0.5446, 1.0956, 1.0380, 1.0943, 1.0517, 0.7094, 1.0557,\n",
       "                      0.6625, 1.1248, 1.0023, 1.5281, 1.3572, 1.0759, 0.7746, 1.2011, 1.1546,\n",
       "                      0.5964, 0.9852, 0.8495, 0.9046, 0.9232, 1.2807, 0.5028, 0.9053, 1.1093,\n",
       "                      1.2315, 1.0267, 1.0194, 1.2623, 0.9689, 1.0482, 1.0786, 0.8586, 0.4864,\n",
       "                      1.2161, 1.0685, 1.0953, 0.9853, 0.8778, 1.0397, 1.2730, 0.9377, 1.2230,\n",
       "                      0.9753, 1.0981, 0.5209, 0.9376, 0.6086, 0.4151, 0.7702, 0.9797, 1.2388,\n",
       "                      1.0349, 0.9509, 0.8632, 1.2876, 1.6126, 1.1258, 0.4149, 1.0089, 1.0519,\n",
       "                      0.8221, 1.2245, 1.0256, 1.0461, 0.9651, 0.8645, 1.0192, 1.0774, 1.0158,\n",
       "                      1.1035, 0.9729, 1.2657, 1.1162, 1.0492, 0.8497, 1.1300, 1.0705, 0.9149,\n",
       "                      0.5904, 0.9442, 1.1462, 0.9009, 1.3760, 0.4095, 1.0837, 1.2117, 0.5813,\n",
       "                      1.1220, 1.3137, 0.5588, 1.1104, 0.7647, 0.8270, 1.7138, 1.0442, 0.9528,\n",
       "                      1.1511, 0.8160, 1.0942, 1.2062, 1.0723, 0.9839, 1.4398, 1.0917, 1.1048,\n",
       "                      1.0294, 1.0739, 1.1939, 1.0529, 1.0129, 1.0052, 1.4338, 1.0208, 0.9004,\n",
       "                      1.1145, 0.8237, 1.2433, 0.9026, 1.0068, 1.1364, 0.9539, 0.7693, 1.0401,\n",
       "                      1.3652, 0.4287, 1.0163, 0.9942, 1.1042, 0.4577, 0.9942, 0.9551, 0.9146,\n",
       "                      1.0011, 1.1516, 0.9862, 0.7260, 1.1630, 1.0532, 0.9281, 0.9433, 0.6011,\n",
       "                      0.6257, 1.1354, 0.9504, 0.9805, 0.9760, 0.9792, 0.4477, 0.7953, 0.9629,\n",
       "                      0.8023, 1.1022, 1.1797, 0.8836, 1.0323, 0.5699, 1.0605, 1.1273, 1.0621,\n",
       "                      0.7290, 0.9571, 0.8671, 0.6478, 0.3853, 0.9439, 0.8821, 0.8617, 0.4659,\n",
       "                      1.0389, 0.3590, 1.1582, 0.9726, 1.0988, 1.0964, 0.8692, 1.2900, 0.8554,\n",
       "                      1.1174, 0.9015, 0.9937, 1.2691, 0.9923, 0.9630, 1.0504, 0.7922, 0.5388,\n",
       "                      1.0412, 1.0914, 0.9493, 1.1033, 0.9571, 0.9168, 0.9361, 1.1429, 0.4560,\n",
       "                      1.0962, 1.0570, 0.6944, 1.0913, 1.0084, 0.9310, 0.8042, 0.9676, 1.1645,\n",
       "                      1.0108, 0.9704, 0.8509, 0.8505, 0.9832, 0.9930, 1.0751, 0.9806, 1.0307,\n",
       "                      1.1843, 1.0450, 0.8979, 0.8262, 0.7724, 0.8858, 0.9827, 1.0757, 1.1863,\n",
       "                      0.9124, 0.8604, 1.0140, 1.1726, 0.8133, 0.9450, 0.7757, 0.9359, 0.8902,\n",
       "                      0.4347, 0.8054, 0.9967, 0.8918, 1.1201, 0.8330, 1.3714, 0.6347, 0.6996,\n",
       "                      0.9285, 0.9511, 1.2236, 1.0164, 0.8717, 1.0107, 1.2076, 0.9399, 1.1091,\n",
       "                      0.9706, 1.1365, 1.0346, 1.1798, 1.2603, 1.0090, 0.9313, 0.8644, 1.0968,\n",
       "                      0.7437, 1.1048, 1.1171, 0.9892, 0.9939, 1.4142, 1.0721, 1.1209, 1.0621,\n",
       "                      1.1425, 0.8798, 1.1274, 0.9831, 1.0430, 0.9428, 0.3956, 0.9816, 1.0278,\n",
       "                      0.9393, 0.9891, 1.3775, 1.0050, 0.8539, 0.9556, 1.1961, 1.1283, 1.0901,\n",
       "                      0.9547, 1.0527, 1.6421, 1.0322, 1.0283, 0.7542, 0.9550, 1.1278, 0.9013,\n",
       "                      1.0847, 1.1320, 0.8843, 1.1033, 1.0025, 1.0018, 1.0766, 0.2731, 1.0976,\n",
       "                      1.3175, 1.2517, 1.0063, 1.2144, 1.1150, 0.8921, 0.4834, 0.4870],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.bias',\n",
       "              tensor([-0.9268, -0.6266, -0.5309, -0.6357, -0.5046, -1.1536, -0.5173, -1.4939,\n",
       "                      -0.7832, -1.5075, -0.6342, -0.5730, -1.1893, -1.1652, -0.7942, -1.0887,\n",
       "                      -1.3104, -1.3070, -0.8438, -1.5253, -0.9678, -1.0071, -0.9260, -0.5962,\n",
       "                      -1.2304, -0.2258, -0.6201, -0.8741, -0.9973, -0.2882, -1.0181, -0.0473,\n",
       "                      -1.2342, -0.8188, -0.9273, -1.0032, -1.1131, -0.5810, -0.9244, -0.8191,\n",
       "                      -0.4738, -0.7664, -0.1053, -1.1785, -1.2238, -1.2519, -1.0774, -1.7462,\n",
       "                      -1.2521, -1.0098, -1.3732, -1.0013, -0.9384, -0.9089, -0.7262, -1.2270,\n",
       "                      -1.0483, -1.5191, -0.4390, -1.0361, -0.8670, -0.8597, -1.4813, -0.6777,\n",
       "                      -0.4823, -1.1131, -0.8683, -0.1681, -0.6160, -1.1000, -0.6691, -0.6610,\n",
       "                       0.1074, -0.4299, -0.8592, -0.8151, -1.7040, -1.0895, -0.9872, -1.5288,\n",
       "                      -1.1496, -0.6807, -0.8016, -0.7891, -0.9479, -0.6210, -1.0759, -1.1950,\n",
       "                      -0.9956, -1.2665, -1.5158, -1.7583, -0.7382, -0.5999, -0.9451, -0.5500,\n",
       "                      -1.0278, -0.6882, -1.0760, -1.4877, -0.7106, -0.9699, -1.1468, -0.5725,\n",
       "                      -0.2269, -1.4250, -0.7481, -0.9016, -1.3545, -0.4090, -0.5920, -0.7844,\n",
       "                      -1.2422, -1.0947, -1.3283, -1.2184, -1.1426, -0.8193, -1.3204, -0.8605,\n",
       "                      -0.7378, -0.5170, -1.3469, -1.0916, -0.9371, -1.4747, -1.0785, -1.3800,\n",
       "                      -1.3396, -0.4237, -1.3274, -0.8327, -0.8605, -1.2755, -0.9883, -1.0643,\n",
       "                      -1.1332, -1.2407, -1.0683, -0.9353, -0.8443, -1.0549, -1.1899, -1.0002,\n",
       "                      -1.4368, -0.4605, -0.8931, -1.3795, -1.1537, -1.2295, -1.5573, -1.3294,\n",
       "                      -1.2111, -1.4382, -1.0037, -1.4445, -0.7545, -1.1937, -1.0555, -0.8604,\n",
       "                      -0.3483, -0.8547, -1.4832, -0.9992, -0.6245, -1.1271, -1.8393, -0.8570,\n",
       "                      -1.1873, -0.9002, -1.1650, -1.4616, -1.0966, -1.0338, -0.8798, -1.0539,\n",
       "                      -0.5295, -0.5991, -0.5281, -1.1401, -1.3800, -1.1607, -1.0025, -0.7102,\n",
       "                      -0.9779, -1.1512, -1.1975, -0.7246, -0.4748, -0.9941, -0.7571, -0.8653,\n",
       "                      -1.4647, -1.8294, -0.6385, -0.2421, -0.4240, -0.7561, -0.7323, -1.0429,\n",
       "                      -0.5567, -0.7589, -0.8982, -1.1422, -1.3670, -0.8966, -0.7570, -0.8501,\n",
       "                      -1.4752, -1.3566, -1.5417, -1.3120, -1.4789, -0.8098, -1.1903, -1.1919,\n",
       "                      -0.5641, -1.0068, -0.6368, -1.1082, -0.6602, -1.2209, -0.5706, -0.8450,\n",
       "                      -1.4457, -1.1181, -0.5517, -1.0157, -1.0188, -1.3320, -1.1227, -0.8480,\n",
       "                      -0.9637, -0.3996, -1.1952, -1.4615, -1.0471, -0.8518, -1.3566, -1.1436,\n",
       "                      -1.2017, -0.7486, -1.5245, -0.9609, -1.2642, -0.4812, -1.1266, -0.8732,\n",
       "                      -0.4258, -0.7096, -0.8881, -1.1568, -1.1495, -1.0584, -0.5065, -2.0450,\n",
       "                      -1.8439, -1.0001, -0.4478, -1.3064, -1.2587, -0.7340, -0.7342, -0.9460,\n",
       "                      -1.0269, -0.9412, -0.7271, -0.9116, -0.7955, -1.3599, -1.3335, -1.3596,\n",
       "                      -2.0832, -1.4160, -0.9864, -0.7417, -0.7941, -1.4409, -0.8184, -0.5528,\n",
       "                      -0.7167, -1.1789, -0.8158, -1.4325, -0.2628, -1.1581, -1.9050, -0.4080,\n",
       "                      -1.2944, -1.1235, -0.6202, -1.1652, -0.9671, -1.1774, -1.8213, -0.8847,\n",
       "                      -0.6611, -1.5906, -0.7409, -1.0386, -1.0712, -1.1633, -1.0001, -1.3512,\n",
       "                      -0.9485, -1.2225, -1.0768, -1.1959, -1.0779, -1.0752, -1.1522, -0.9081,\n",
       "                      -1.0947, -0.8541, -0.9721, -1.3169, -0.8332, -1.1959, -0.8614, -1.2096,\n",
       "                      -1.2910, -1.3517, -0.7324, -0.7874, -1.2204, -0.3987, -1.2808, -1.0477,\n",
       "                      -1.0734, -0.4106, -0.8290, -0.8418, -1.1694, -1.0074, -1.2381, -1.2645,\n",
       "                      -0.4686, -0.9527, -0.7772, -0.9946, -0.5623, -0.7630, -0.8910, -1.0892,\n",
       "                      -0.8300, -0.9807, -0.9775, -1.3635, -0.4377, -0.6563, -1.3178, -0.7624,\n",
       "                      -1.1922, -1.3888, -1.3011, -0.8241, -0.6315, -1.0948, -1.0740, -1.1862,\n",
       "                      -1.2401, -0.8922, -0.8188, -0.4529, -0.3196, -0.9116, -0.5977, -0.7753,\n",
       "                      -0.3463, -0.9359, -0.2351, -1.1351, -0.8505, -1.2622, -0.8808, -0.8275,\n",
       "                      -1.4604, -0.6374, -0.9875, -0.5543, -0.9385, -1.4324, -1.0252, -0.7666,\n",
       "                      -1.3167, -0.6675, -0.3785, -0.6188, -1.1109, -0.7665, -0.6459, -1.3750,\n",
       "                      -0.9565, -0.8162, -1.1617, -0.2942, -1.1032, -0.9313, -0.6704, -0.9382,\n",
       "                      -1.4996, -0.6677, -0.9241, -0.9116, -1.5874, -1.2366, -0.9990, -0.7313,\n",
       "                      -0.6550, -0.9268, -0.9094, -1.2075, -0.7507, -1.5805, -1.3963, -1.1001,\n",
       "                      -0.8197, -0.6291, -0.5572, -0.6652, -1.0816, -1.0449, -1.2613, -0.6382,\n",
       "                      -0.4380, -1.4386, -1.2137, -0.5551, -1.0229, -0.9086, -0.8036, -0.8823,\n",
       "                      -0.4433, -0.5666, -1.3386, -0.8249, -1.0241, -0.9359, -1.3669, -0.1792,\n",
       "                      -0.4910, -0.6613, -0.6006, -1.2904, -1.2362, -0.9800, -0.7748, -0.8731,\n",
       "                      -0.9160, -1.3455, -0.6145, -1.3676, -0.9559, -0.8511, -1.0169, -1.0877,\n",
       "                      -0.6715, -0.8468, -0.9053, -0.6382, -0.7508, -1.1323, -1.2330, -1.0002,\n",
       "                      -1.0657, -1.0172, -1.3319, -1.0393, -1.2256, -0.7244, -1.3001, -1.1020,\n",
       "                      -1.2895, -0.6108, -0.4768, -1.4196, -1.3897, -0.7835, -1.0923, -1.2570,\n",
       "                      -0.9177, -0.8924, -0.9494, -0.8150, -1.1034, -1.1010, -0.7710, -1.2923,\n",
       "                      -1.7607, -0.8246, -1.0299, -0.7357, -0.8449, -1.3700, -0.9031, -1.1970,\n",
       "                      -1.0119, -0.7387, -1.1051, -1.0061, -1.1059, -0.8715, -0.2503, -0.7411,\n",
       "                      -1.5400, -1.4532, -0.8578, -1.6902, -1.4873, -0.8968, -0.5279, -0.5539],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.running_mean',\n",
       "              tensor([-10.2793,  -5.1050,   0.5770, -12.2499,   1.1114,  -5.0149,   2.6296,\n",
       "                       -5.7523,  -4.7333,  -9.0336,  -4.5115,  -7.6067,  -9.8591,  -4.0122,\n",
       "                      -10.7823,  -5.9085,  -7.6807,  -4.9074,  -5.2075,  -5.1058,  -6.3960,\n",
       "                       -8.2817,  -5.2456,   0.0449,  -2.5947,  -5.1229,   3.0265,  -9.0198,\n",
       "                       -7.9768,  -2.0162, -16.2726,  -3.1200,  -5.7590,  -3.1134,  -8.1856,\n",
       "                       -5.2627,  -6.8978,   1.6054,  -2.5897,  -2.4606,  -6.4149,  -0.0205,\n",
       "                        1.8035, -11.9931,  -7.4352,  -4.6106,  -6.3099,  -1.2977,  -1.6846,\n",
       "                       -9.3642,  -5.2194,  -6.9079,  -4.9136,  -2.1780,  -5.5695,  -6.6912,\n",
       "                       -4.2017,  -7.7757,  -3.1779,  -4.0478,  -8.0861,  -3.7367,  -5.8779,\n",
       "                       -3.1723,  -1.7294,  -6.1344,  -4.8933,   0.0762,  -8.5907,  -5.8002,\n",
       "                       -9.0861,  -1.2178,  -0.4124,   2.0606,  -2.1005,  -7.2921,  -5.3342,\n",
       "                       -3.6185,  -6.3721,  -6.5325,  -6.0726,  -7.7600,  -3.4875,  -4.4815,\n",
       "                       -6.0967,  -1.5140,  -6.1712,  -3.2782,  -4.4434,  -9.1119,  -5.0394,\n",
       "                       -4.1701,  -8.7567,  -8.5084,  -7.7246,  -1.0465,  -1.7473,  -5.7842,\n",
       "                       -1.8228,  -6.2296,   2.0070,  -3.7328,  -7.6452,   0.0470,   1.9210,\n",
       "                       -8.1234,  -7.0801,  -3.7098, -13.6400,  -1.5657,  -6.4982,  -0.9597,\n",
       "                       -7.3450,  -5.1298, -13.1911,  -8.3593,  -6.5813,  -9.8701,  -8.2120,\n",
       "                      -10.2244,  -1.7166,   0.3624,  -6.1199,  -5.2311,  -2.4564,  -6.3264,\n",
       "                       -7.9257,  -7.9577,  -3.4013,   1.5921,  -5.8668,  -0.8193,  -2.5089,\n",
       "                       -5.0900,  -8.0176,  -6.4210,  -1.1759,  -6.7921,  -0.3481,  -9.2427,\n",
       "                       -9.9008,  -8.3225,  -9.3032,  -8.9493,  -5.2085,   1.5023,  -5.2136,\n",
       "                       -6.0105,  -6.2447,  -6.5079,  -4.2751,  -9.7660,  -6.1132,  -1.8229,\n",
       "                       -5.8968,  -8.7571,  -9.2568,  -0.3043,  -5.9986,  -0.7422,   2.8028,\n",
       "                       -3.2696,  -5.3210,  -3.5418,  -1.2045,  -5.7917, -10.0467, -10.2704,\n",
       "                       -6.2779,  -7.2943,  -5.7070,  -6.7291, -11.9753,  -4.7874, -12.9624,\n",
       "                       -8.8783,  -2.5503,  -0.9713, -10.5295, -12.2764,  -5.5694,  -6.0106,\n",
       "                       -4.0255,  -7.1279,  -8.2322,  -3.4059,  -1.6601,  -5.5689,   0.5852,\n",
       "                       -3.9591,  -4.6329,  -3.0914,  -7.8443,  -6.0076,  -6.4779,   1.6296,\n",
       "                        0.1636,  -6.4931,  -1.9335,  -6.2480,   0.8268,  -5.4800,  -9.3580,\n",
       "                       -3.8273,  -6.9180,  -3.8009,  -5.3921,  -1.0332,  -7.8456,  -4.3468,\n",
       "                       -3.9134,  -2.0628,  -0.8970,  -3.7377,  -5.2491,  -3.9716,   1.7836,\n",
       "                       -4.8697,  -9.8217, -12.0063,  -5.8720,  -6.0146,   1.1641,  -4.2303,\n",
       "                       -6.2902,  -7.7341,  -6.0825,  -7.5879,  -5.5148,  -6.5780,   0.0881,\n",
       "                       -7.2020,  -5.0114,  -4.3173,  -2.5251,  -4.9577,  -6.3364,  -7.3803,\n",
       "                       -2.9454,  -6.4389,  -5.0101,  -6.6061,  -6.5512,  -5.1629,  -4.6097,\n",
       "                       -1.5746,  -2.8374,  -0.5122,   0.7712,  -4.4144,  -5.8370,  -3.9464,\n",
       "                      -12.3806,  -4.7935,  -3.9609,  -3.2923,  -7.0694,  -6.3033,   2.0305,\n",
       "                       -6.3570,  -5.0539,  -5.1913,  -3.5339,  -2.1619,  -6.7763,  -6.3931,\n",
       "                      -11.1211,  -9.3622, -11.0594,  -5.0233,  -4.9589,  -6.3624,  -7.0158,\n",
       "                      -12.1250, -11.4559,  -5.3347,  -3.3384,  -1.9951,  -4.3446,  -1.8381,\n",
       "                       -6.8602,  -6.8828,  -1.9819,  -3.8376,   0.9528,  -7.9761,  -8.2387,\n",
       "                       -0.2785,  -7.7605,  -5.6871,   0.1998, -10.1335,  -5.3290,   1.1781,\n",
       "                      -10.0592,  -6.3349,  -0.9074,  -2.5916,  -8.9815,  -5.5814,  -7.6576,\n",
       "                       -7.7590,  -5.6901,  -5.7995,  -6.4633,  -7.0798,  -9.2863,  -3.3237,\n",
       "                       -0.7928,  -8.3835,  -3.3632,  -5.5329,  -5.8154,  -7.5749,  -5.4600,\n",
       "                       -3.2018,  -3.7958,  -1.2822,  -7.5610,  -8.0757,  -6.4004,   0.0784,\n",
       "                      -12.9392,  -7.0685,  -6.5679,   0.6536,  -9.9785,  -4.6147,  -8.3518,\n",
       "                        0.6975,  -7.0733,  -6.0345,  -6.5054, -11.3228, -10.2335,  -3.2918,\n",
       "                       -3.5762,   1.4748,  -5.7224,  -8.3526,  -4.4862,   0.8099,   0.4632,\n",
       "                       -3.3076,  -4.9378,  -7.3780,  -6.9124,  -4.9742,   0.9185,  -8.1968,\n",
       "                       -4.2707,  -8.3432,  -7.4695,  -2.3438,  -6.6042,  -7.4780,   1.3620,\n",
       "                       -7.4275,  -4.6859,  -9.7884,   0.5683,  -6.4116,  -4.6786,  -6.0446,\n",
       "                        2.2747,  -4.5395,  -7.1189,  -1.0410,  -0.2631,  -7.2017,   2.1779,\n",
       "                      -10.9636,  -6.8035,  -6.5435,  -6.0287,  -0.9497, -10.6271,  -5.2722,\n",
       "                       -6.2655,  -3.8363,  -7.2287,  -2.5849,  -2.7195,  -2.5114,  -2.4181,\n",
       "                       -3.6162,   1.2660,  -4.8813,  -7.8794,  -2.1826,  -5.0133,  -5.9276,\n",
       "                       -1.0022,  -5.2859,  -6.3448,  -0.0995,  -7.2606,  -4.8345,  -3.4389,\n",
       "                       -7.7076,  -6.0039,  -7.0864,  -1.5581, -11.9516,  -6.6842,  -4.7997,\n",
       "                       -7.9832,  -1.8929,  -3.8697,  -7.2771, -11.0676,  -8.2769,  -0.1662,\n",
       "                       -5.9941,  -5.0723, -12.7834,  -7.3765,  -8.0371,  -8.8059,  -7.5946,\n",
       "                       -6.9716,  -8.1132, -10.4097,   0.7244,  -8.5828,  -6.2128,  -9.7671,\n",
       "                       -6.6599,  -5.2965,  -0.7537,  -3.7555,  -4.3002,   2.1005,  -6.0888,\n",
       "                       -8.4214,  -6.9165,  -5.9569,  -4.5327,  -6.1004,  -2.8920,  -6.0032,\n",
       "                       -2.2724,  -3.9450,  -5.6058, -10.2554,  -9.5931,  -6.6777,  -7.4380,\n",
       "                       -8.7531, -11.3134,  -4.8196,  -5.7835,  -6.5160,   0.3841,  -8.8216,\n",
       "                       -3.3551,  -4.4611,  -9.0977,  -4.4484,   1.4702,  -2.2733,  -4.6829,\n",
       "                       -3.5563,  -7.8723,  -5.1950,  -4.8242,  -7.0583,  -8.7942,  -5.7782,\n",
       "                       -4.5458,  -8.1177,  -7.6210,  -3.1566,  -7.1672,   0.6632,  -4.1542,\n",
       "                       -4.2291,  -6.6208,  -7.1946,  -5.2934,  -9.6849,  -5.4624,  -3.5769,\n",
       "                       -3.4177,  -5.3127,  -6.7569,  -4.6155,  -6.7661,  -6.3095,  -3.6367,\n",
       "                       -4.8903,   2.3502,  -0.6025,  -9.1916,   2.1711,  -7.7282,  -5.9922,\n",
       "                       -8.2701,  -4.6847,  -5.7975,  -5.2849,  -7.1303,   1.8561,  -6.2341,\n",
       "                       -4.0587,  -4.0731,  -8.7921,  -6.9323,  -5.1966,  -2.1089,   1.8824,\n",
       "                        1.2020], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.running_var',\n",
       "              tensor([25.9477, 16.5733,  4.9564, 28.6898,  7.1413, 17.8488,  3.8144, 14.5970,\n",
       "                      17.3948, 38.2940, 13.0234, 29.2071, 31.1680,  8.8923, 30.8701, 12.7928,\n",
       "                      19.2679, 14.7399, 21.9500, 15.5500, 10.6833, 21.7241, 11.5524,  4.0457,\n",
       "                       7.9603, 16.8295, 15.5251, 32.9095, 23.1123, 14.0936, 37.5358, 12.4848,\n",
       "                      21.5845, 15.5798, 19.2634, 15.0854, 18.4694,  5.2985,  7.7973, 27.5669,\n",
       "                      15.9851,  9.6565,  3.9385, 20.3290, 28.3304, 12.5070, 14.7064, 26.1982,\n",
       "                       3.9066, 18.9662, 13.9175, 19.6702, 24.5714, 13.0022, 53.1503, 14.5090,\n",
       "                      14.9587, 12.9142,  4.3092, 14.5339, 24.8722, 10.7357, 28.5289,  8.0343,\n",
       "                       8.1199, 39.9542, 19.8778, 10.3461, 30.5962, 19.5617, 20.5699,  7.4316,\n",
       "                       7.8675,  7.7964,  7.1674, 33.1144, 13.7808, 20.8220, 15.3775, 13.9209,\n",
       "                      11.9177, 22.2030,  7.4819, 18.6825, 16.9285,  9.8723, 10.3241, 28.9917,\n",
       "                      16.9282, 27.4749, 34.3637,  8.9852, 22.4466, 38.7172, 34.9716, 11.5602,\n",
       "                      13.5902, 13.6143,  9.9763, 12.4859,  4.4295,  8.3284, 37.5300,  4.3734,\n",
       "                       3.0895, 41.6860, 34.0726, 10.5124, 36.2825,  8.2954, 29.2960,  6.3537,\n",
       "                      20.5536,  9.4501, 36.9986, 20.8720, 12.8368, 37.7083, 24.7643, 23.0841,\n",
       "                      12.6122,  4.0673, 14.8067, 38.4710, 14.2712, 13.7243, 10.6322, 19.8489,\n",
       "                      12.2712,  4.8436, 19.0219,  6.3717,  7.0603, 12.1327, 20.4187, 20.3443,\n",
       "                      13.9391, 32.7323, 13.4792, 28.6418, 26.6187, 31.5201, 23.0340, 22.5258,\n",
       "                      15.2911,  4.4022, 17.8964, 18.6309, 11.5805, 17.1843, 10.7487, 27.3265,\n",
       "                      11.7636, 27.5499, 13.4789, 26.4110, 48.1084, 10.9896, 19.1405, 11.0402,\n",
       "                       6.7606,  9.4307, 20.0629, 32.8033,  6.7211, 14.6987, 30.0069, 18.2410,\n",
       "                      14.6452, 26.7315, 14.6979, 28.7509, 37.2557, 21.9850, 32.0598, 26.7120,\n",
       "                       7.0789, 10.0965, 44.3797, 33.8998, 24.1027, 13.7562, 10.4648, 25.6448,\n",
       "                      23.1698, 24.1747, 13.5981, 19.5093,  4.4610, 11.9872, 11.1300,  4.4206,\n",
       "                      22.5331, 23.6396, 15.7599,  6.3538,  3.2810, 14.8751, 16.0796, 10.9207,\n",
       "                       5.1066, 16.0795, 31.8497, 20.7898, 13.5729, 17.2899, 15.2702,  7.9741,\n",
       "                      16.0184, 16.0046, 15.0117, 11.9559, 17.4703,  8.5567, 16.5416,  8.6536,\n",
       "                       3.1471, 13.3657, 36.9750, 29.1694, 13.3317, 11.3734,  4.7904, 11.2839,\n",
       "                      12.1372, 31.8972, 11.1363, 15.1774, 16.3388, 19.4651,  8.1487, 21.0309,\n",
       "                       9.1159, 11.8341, 15.9305, 18.3443, 19.2887, 23.6510, 19.0304, 25.6219,\n",
       "                      13.7310, 11.1023, 28.5880,  8.2523, 11.3362,  3.9850, 11.8526,  5.8452,\n",
       "                       4.6486, 13.1018, 18.2617, 25.5351, 26.5429, 22.0399, 14.0497, 18.8683,\n",
       "                      15.0423, 19.3316,  4.9169, 17.1923, 11.2731, 20.3997, 17.1153, 14.7711,\n",
       "                      13.1216, 14.6626, 18.7908, 33.7767, 31.1224, 16.8063, 19.4649, 26.5509,\n",
       "                      10.4670, 40.6961, 56.8420, 13.9113, 19.8506, 15.9927, 13.1833,  5.3747,\n",
       "                      12.9164, 19.6825, 11.7234, 10.5552,  3.2164, 19.0529, 18.6243,  3.8479,\n",
       "                      17.3073, 17.8297,  6.0869, 19.2629,  9.5786,  7.3701, 27.4588, 17.7705,\n",
       "                      17.8569, 10.5123, 23.3862, 21.5240, 13.3133, 22.4450, 18.8869, 15.9933,\n",
       "                      20.2897, 15.5485, 30.0565, 23.1910, 13.0794, 21.1492,  7.7913, 14.5334,\n",
       "                      17.4401, 11.9952, 13.4288, 12.8075,  7.4606, 21.0727, 18.0289, 19.0485,\n",
       "                      16.3264,  8.6855, 34.4725, 16.3944, 38.3138,  4.3363, 39.7006, 13.5680,\n",
       "                      25.1719,  2.3369, 14.6388, 22.5186, 15.4152, 31.3699, 20.9004, 18.2541,\n",
       "                       8.4245, 14.0153, 10.9995, 29.2076,  7.6909,  3.7396,  8.4154, 10.0600,\n",
       "                      16.5012, 19.1621, 21.0240, 20.0611,  5.7387, 18.8005,  6.1813, 12.2710,\n",
       "                      22.5044, 15.4921, 21.4759, 13.4136,  6.9473, 17.1352, 13.0289, 22.4990,\n",
       "                       6.0225, 10.6556, 16.2021, 32.8283,  4.7706, 14.8738, 11.1560,  5.3743,\n",
       "                       5.7921, 13.3604,  2.7482, 21.5029, 18.7508, 10.4992, 11.8807, 12.2436,\n",
       "                      20.7739, 19.8033, 14.8469, 29.4510, 16.5537, 11.8768, 14.7347,  8.0578,\n",
       "                      19.0071,  7.7629,  5.1596, 14.3560, 22.3317, 13.3205, 19.7466, 24.0590,\n",
       "                       6.4785, 15.4873, 12.4923,  3.4095, 13.0653, 28.5847, 11.8347, 21.4392,\n",
       "                       9.8598, 21.0303,  6.1335, 41.6386, 38.8693, 13.3092, 37.4739, 24.0293,\n",
       "                      29.3321, 20.2335, 25.1091, 15.4169, 20.7976, 11.3012, 18.0666, 31.7064,\n",
       "                      29.0671, 22.3197, 24.9146, 26.9031, 16.6671, 10.1967, 28.5814,  4.7615,\n",
       "                      12.0240, 24.9222, 47.2419, 14.4547, 15.7475,  8.2459, 14.8922, 18.0402,\n",
       "                       4.3960, 17.3405, 18.5886, 20.8925, 20.4716, 24.4640, 12.8354, 22.0989,\n",
       "                      11.8033,  8.9580, 29.3541, 14.4815, 44.2939, 45.6635, 12.4235, 14.7183,\n",
       "                      30.9570, 20.2884, 17.1768, 23.2277, 23.9515, 10.5962, 23.8915, 13.6565,\n",
       "                       5.5642, 14.8275, 18.0266,  6.5589,  6.7854, 11.0593, 15.2008, 14.4204,\n",
       "                      15.2472, 15.3347, 23.7237, 35.7539, 16.3468, 10.1289, 19.9992, 24.8273,\n",
       "                      20.1210, 10.2618,  2.7819, 10.3906,  9.9954, 16.3208, 10.1581, 13.0410,\n",
       "                      44.9760, 20.8118, 20.8414, 10.9393, 19.6904, 12.4679, 10.3500, 15.2428,\n",
       "                      15.8127, 14.6952, 11.2404,  6.7499,  7.6787, 20.9956, 15.3474, 27.1440,\n",
       "                      43.7911, 31.7482, 11.0519, 18.2463, 19.6826, 21.1500,  5.7881, 14.8946,\n",
       "                      20.2056, 12.6739, 27.8798, 16.1588, 19.6985,  6.2127,  5.5244,  3.4680],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn1.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.weight',\n",
       "              tensor([0.8692, 1.0196, 0.9362, 0.9131, 1.0375, 1.0444, 1.0132, 1.0092, 1.0608,\n",
       "                      1.0743, 1.0304, 1.1891, 1.0405, 1.0412, 1.0269, 0.9653, 1.0626, 1.0576,\n",
       "                      1.0416, 1.0394, 1.0032, 0.9530, 1.0887, 1.1196, 1.2284, 1.1845, 1.2006,\n",
       "                      1.0038, 0.9120, 0.9737, 1.0074, 1.0234, 0.9587, 0.9566, 1.1203, 1.0380,\n",
       "                      1.2199, 1.0974, 1.0536, 0.7612, 0.9293, 1.2127, 1.0957, 1.0487, 1.0060,\n",
       "                      0.9303, 1.1301, 0.9962, 0.9253, 0.9390, 1.0552, 1.0215, 0.6022, 1.1631,\n",
       "                      1.0075, 0.9166, 1.1436, 1.1242, 0.9639, 0.8867, 0.8757, 1.0242, 1.0773,\n",
       "                      1.0337, 1.0872, 0.9788, 0.9669, 0.9332, 0.7769, 1.0834, 1.1052, 1.0670,\n",
       "                      1.2093, 1.0479, 0.8535, 1.0409, 1.0113, 0.8261, 0.9043, 1.0220, 1.0291,\n",
       "                      1.0649, 0.9358, 1.2345, 0.9310, 0.9950, 1.1893, 1.0115, 0.7559, 1.0712,\n",
       "                      1.0209, 0.9954, 0.8501, 1.0186, 1.1557, 0.9994, 0.9954, 1.0819, 1.0597,\n",
       "                      1.0474, 1.0162, 0.9761, 0.9244, 0.9922, 0.9519, 1.1067, 0.9372, 0.9337,\n",
       "                      1.1715, 1.0161, 1.0217, 1.0195, 1.1220, 1.0149, 1.1270, 1.1602, 0.9379,\n",
       "                      1.0706, 1.1358, 1.0445, 0.9419, 1.0347, 0.9873, 1.0045, 0.9723, 1.0441,\n",
       "                      0.8574, 1.0103, 1.0524, 0.9981, 0.9770, 1.0063, 1.0351, 1.0704, 1.0712,\n",
       "                      1.1775, 1.0923, 1.0152, 1.0871, 1.0963, 0.9691, 1.0647, 0.6194, 1.0080,\n",
       "                      1.0311, 1.1069, 0.9379, 1.0183, 1.0397, 0.9723, 1.0926, 0.9570, 1.1201,\n",
       "                      0.6124, 1.0335, 1.0131, 1.0401, 1.0126, 0.9381, 1.0591, 1.0451, 0.6448,\n",
       "                      1.2713, 0.8568, 1.0401, 0.9968, 0.9266, 0.9932, 1.0042, 1.0146, 0.9523,\n",
       "                      1.0785, 1.0504, 1.0440, 0.8292, 1.0258, 0.8946, 1.0836, 0.9695, 1.1255,\n",
       "                      1.0539, 1.0798, 1.0433, 0.9571, 1.0015, 1.0899, 0.9283, 1.0606, 0.9519,\n",
       "                      0.7614, 0.7617, 0.9541, 1.1838, 0.9471, 1.0733, 1.1440, 1.0788, 1.0504,\n",
       "                      0.9725, 0.7654, 1.0277, 0.7071, 0.9312, 1.0306, 1.0887, 1.1121, 0.9629,\n",
       "                      1.0552, 1.0747, 1.1719, 0.8791, 1.0809, 1.0920, 0.8258, 1.0560, 0.9856,\n",
       "                      1.0623, 0.8904, 0.9770, 0.9496, 1.1909, 0.8231, 0.9825, 0.9999, 1.0781,\n",
       "                      1.0322, 0.9479, 0.6987, 1.0529, 0.9777, 1.0731, 1.0085, 1.0309, 0.9760,\n",
       "                      1.1300, 1.0308, 0.9500, 0.8970, 1.0981, 0.9828, 1.0356, 1.0897, 1.0457,\n",
       "                      1.1373, 1.0823, 1.0683, 1.1204, 1.0674, 1.1082, 1.0366, 1.0477, 0.7976,\n",
       "                      1.0946, 1.0202, 0.9869, 0.9141, 0.9358, 1.0071, 1.0090, 0.9882, 1.2007,\n",
       "                      0.9805, 0.9280, 0.9648, 1.1031, 1.0952, 1.0682, 0.9051, 0.9703, 0.9847,\n",
       "                      1.0507, 1.0302, 1.0373, 1.0126, 1.1133, 0.9373, 1.0751, 1.0259, 0.8999,\n",
       "                      0.9758, 1.0634, 0.9822, 0.9974, 1.1841, 1.0385, 0.9460, 1.0757, 1.0571,\n",
       "                      0.8684, 0.7430, 1.0869, 1.0043, 0.8735, 0.9567, 1.0572, 1.0317, 1.0294,\n",
       "                      1.0523, 1.0352, 1.0453, 1.1801, 1.1518, 1.0357, 1.0031, 1.0059, 1.0505,\n",
       "                      0.8497, 0.8277, 0.7445, 1.0762, 1.0021, 1.1202, 1.0641, 0.9924, 1.1110,\n",
       "                      1.0767, 0.9756, 1.0253, 1.1018, 0.9259, 0.9461, 1.0254, 1.0322, 0.9632,\n",
       "                      1.0843, 0.8916, 0.8301, 1.1465, 0.9954, 0.9512, 0.9322, 0.9779, 0.9065,\n",
       "                      0.9694, 0.5169, 1.1076, 1.0327, 0.9517, 1.1000, 0.9666, 0.9286, 0.9862,\n",
       "                      1.1279, 0.9118, 0.9248, 0.8618, 0.8209, 0.7729, 0.9371, 0.8842, 0.9992,\n",
       "                      1.0429, 1.0914, 0.8012, 1.0192, 1.0117, 1.0623, 1.0231, 1.0377, 1.1539,\n",
       "                      0.8518, 0.6366, 1.0854, 0.9593, 0.9821, 0.8839, 1.2614, 0.9315, 0.8245,\n",
       "                      0.9191, 1.0720, 0.9815, 0.7630, 1.0368, 1.0000, 1.0597, 0.9025, 1.0035,\n",
       "                      1.1145, 0.9382, 1.0012, 0.9382, 0.9492, 1.0129, 0.7285, 1.0805, 0.9569,\n",
       "                      1.0730, 1.0464, 0.8662, 0.5841, 0.9371, 0.7384, 0.9628, 1.1045, 0.9737,\n",
       "                      1.0557, 1.1154, 1.1908, 0.9917, 0.9906, 0.7624, 1.0398, 0.9751, 1.0418,\n",
       "                      1.0149, 0.8918, 0.9710, 0.9319, 0.9814, 0.9381, 0.9196, 1.1777, 1.0211,\n",
       "                      1.0665, 0.9604, 1.0621, 1.0200, 0.8991, 0.9888, 0.8206, 1.0428, 1.0212,\n",
       "                      1.0214, 1.0759, 1.0050, 0.9450, 0.9638, 1.0861, 1.0789, 0.9607, 0.7226,\n",
       "                      0.8935, 1.0180, 0.9566, 1.1027, 0.9531, 0.9753, 1.1532, 1.0002, 0.9920,\n",
       "                      1.0342, 0.9385, 0.8641, 0.9388, 0.9327, 1.0506, 1.0106, 1.0389, 0.9956,\n",
       "                      1.0707, 1.0160, 1.1350, 1.1605, 0.9819, 0.9502, 1.0184, 1.0517, 1.0610,\n",
       "                      1.0803, 0.9218, 0.9971, 1.0046, 1.0675, 0.9909, 1.1060, 0.7715, 1.0106,\n",
       "                      0.9804, 1.0199, 1.0249, 1.0042, 1.0969, 0.8566, 1.0517, 0.6326, 1.0388,\n",
       "                      1.0691, 1.0669, 0.9527, 1.0403, 1.0416, 0.7403, 1.1037, 1.0038, 1.0177,\n",
       "                      0.5930, 0.9599, 1.0896, 0.9358, 0.9490, 0.9979, 1.0591, 0.9622, 0.9875,\n",
       "                      0.9553, 1.0062, 1.0119, 1.1283, 1.0414, 1.0745, 1.0687, 0.8101, 1.0115,\n",
       "                      1.1221, 1.0903, 0.9864, 1.1624, 1.0129, 1.0907, 0.9775, 0.7475],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.bias',\n",
       "              tensor([-0.6357, -0.8527, -0.7240, -0.7183, -0.9574, -0.9813, -0.7130, -0.8558,\n",
       "                      -0.8158, -0.8945, -0.7349, -0.9749, -1.0785, -0.7781, -0.8201, -0.7343,\n",
       "                      -1.2163, -0.9349, -0.9170, -0.7448, -0.8741, -0.8969, -1.0082, -0.9573,\n",
       "                      -1.1156, -1.2825, -1.2379, -0.9295, -0.6968, -1.0297, -0.9719, -0.8778,\n",
       "                      -0.6440, -0.7050, -1.0121, -1.0072, -1.1827, -0.8992, -0.8494, -0.6630,\n",
       "                      -0.6907, -1.1151, -0.9045, -1.0034, -0.8512, -0.8988, -1.0106, -0.6670,\n",
       "                      -0.6949, -0.8435, -1.0474, -0.8233, -0.4661, -1.0223, -0.9171, -0.9080,\n",
       "                      -1.1544, -1.0028, -1.1745, -0.8494, -0.5735, -1.0519, -0.8442, -0.8575,\n",
       "                      -1.1057, -0.8953, -0.8886, -0.8457, -0.5678, -1.0093, -0.9063, -0.9730,\n",
       "                      -1.3149, -0.9343, -0.6227, -0.9176, -0.9047, -0.6808, -0.7603, -0.9709,\n",
       "                      -0.9282, -1.0250, -0.7901, -1.1732, -0.9183, -0.8938, -1.0894, -0.7654,\n",
       "                      -0.7095, -1.1964, -0.8708, -0.8142, -0.8661, -0.9949, -1.1258, -0.9737,\n",
       "                      -0.7671, -0.9461, -0.8957, -0.9559, -0.8173, -0.8774, -0.8777, -0.9807,\n",
       "                      -0.6896, -0.9080, -0.7666, -0.7901, -0.9920, -1.0560, -0.9186, -0.8876,\n",
       "                      -0.9487, -0.8476, -0.9140, -1.0839, -0.7586, -1.0032, -1.0627, -0.9870,\n",
       "                      -0.6890, -0.7998, -0.8275, -0.7153, -0.7468, -0.9308, -0.5439, -0.7082,\n",
       "                      -0.9491, -0.8077, -0.7686, -0.8005, -1.1216, -1.0302, -0.8449, -1.2532,\n",
       "                      -1.0404, -0.8978, -0.8028, -1.0356, -0.8640, -0.9739, -0.3478, -0.7908,\n",
       "                      -1.0078, -1.0894, -0.6264, -0.9284, -0.8441, -0.6705, -0.9099, -0.6895,\n",
       "                      -1.0781, -0.4041, -0.9598, -0.9002, -0.8591, -0.8593, -0.9035, -0.9717,\n",
       "                      -0.8061, -0.4209, -1.1186, -0.6594, -0.9079, -0.8793, -0.6905, -0.7890,\n",
       "                      -0.7763, -0.8181, -0.7768, -0.9247, -1.1757, -0.9052, -0.6392, -0.9119,\n",
       "                      -0.8816, -1.1514, -0.6032, -1.1121, -1.0446, -0.9701, -0.9160, -0.7903,\n",
       "                      -0.9031, -0.9186, -0.8806, -0.9007, -0.8075, -0.5293, -0.7690, -0.7966,\n",
       "                      -1.0551, -0.7402, -0.9771, -1.1216, -1.0144, -0.7270, -0.8152, -0.4969,\n",
       "                      -0.9188, -0.5080, -0.6954, -0.8943, -0.9111, -0.9846, -0.7691, -0.7996,\n",
       "                      -0.9310, -0.9318, -0.7881, -1.0120, -1.1179, -0.6427, -0.8588, -0.8852,\n",
       "                      -0.9369, -0.6432, -0.8372, -0.7708, -1.0399, -0.5446, -0.8622, -1.0342,\n",
       "                      -1.0385, -0.9053, -0.7958, -0.5640, -1.0736, -0.7351, -0.9306, -0.7655,\n",
       "                      -0.9475, -0.9423, -1.0223, -0.8780, -0.8575, -0.8953, -1.0348, -0.9474,\n",
       "                      -1.0599, -0.8597, -0.9905, -0.8517, -0.8602, -1.0753, -0.9481, -1.0397,\n",
       "                      -0.9873, -0.9807, -0.9107, -0.8368, -0.9407, -0.9491, -0.9919, -0.6827,\n",
       "                      -1.0033, -0.8495, -0.9439, -0.7659, -0.9812, -0.7008, -0.6716, -0.7872,\n",
       "                      -0.7998, -0.9925, -0.7968, -0.6551, -0.9045, -0.9280, -1.0423, -0.9507,\n",
       "                      -0.8546, -0.7400, -1.2037, -0.9359, -0.8926, -0.8114, -0.8905, -0.9073,\n",
       "                      -0.9369, -0.8521, -0.9964, -0.9729, -0.9072, -0.6744, -0.9125, -0.8992,\n",
       "                      -0.6318, -0.5347, -0.9464, -1.0394, -0.8523, -0.7701, -0.8907, -0.9499,\n",
       "                      -1.0483, -0.9705, -0.9066, -0.9237, -1.2272, -1.3275, -0.8460, -0.7763,\n",
       "                      -0.6645, -0.9437, -0.4811, -0.6286, -0.5974, -0.9572, -0.8808, -0.9409,\n",
       "                      -0.9350, -0.8788, -0.9325, -0.9302, -0.9094, -0.8218, -1.0726, -0.7214,\n",
       "                      -0.9896, -0.8111, -1.0361, -0.7955, -0.7910, -0.7099, -0.6057, -0.9668,\n",
       "                      -0.8110, -0.9454, -0.8162, -0.7066, -0.6406, -0.9381, -0.2838, -1.2096,\n",
       "                      -0.8564, -0.9551, -1.0171, -0.8412, -0.7527, -0.7537, -0.9505, -0.7497,\n",
       "                      -0.8901, -0.6481, -0.7140, -0.4668, -0.8714, -0.9210, -1.0737, -0.9736,\n",
       "                      -0.9253, -0.8462, -0.9520, -0.7971, -1.1652, -0.9690, -0.9288, -0.8844,\n",
       "                      -0.7713, -0.4085, -0.9273, -0.7709, -0.9965, -0.7296, -1.0591, -0.8909,\n",
       "                      -0.6816, -0.7582, -0.8895, -1.0022, -0.4112, -0.9052, -0.8330, -0.7699,\n",
       "                      -0.6271, -0.7419, -0.9814, -0.8401, -0.8756, -0.7851, -0.8853, -0.9722,\n",
       "                      -0.4361, -1.0040, -0.8905, -0.9258, -0.8468, -0.6977, -0.3273, -0.7692,\n",
       "                      -0.5724, -0.7710, -0.9961, -0.9429, -1.0810, -1.0256, -1.0846, -0.8732,\n",
       "                      -0.8395, -0.6623, -0.7299, -0.7672, -1.0518, -0.8442, -0.7411, -1.0576,\n",
       "                      -1.0265, -0.9971, -0.9094, -0.6428, -1.1716, -0.7394, -0.8364, -0.8228,\n",
       "                      -0.9271, -0.7503, -0.7941, -0.9165, -0.6003, -0.7904, -0.8405, -1.0136,\n",
       "                      -0.8585, -0.9383, -0.6179, -0.9837, -1.0112, -0.8642, -0.8000, -0.4619,\n",
       "                      -0.7208, -0.9207, -0.8988, -0.8371, -0.9391, -0.8320, -0.9519, -0.8000,\n",
       "                      -0.8909, -0.9169, -0.8799, -0.7483, -0.7430, -0.9219, -0.8550, -0.8171,\n",
       "                      -0.7724, -0.8056, -0.8571, -0.8749, -1.1316, -1.0753, -1.0479, -0.9392,\n",
       "                      -0.8136, -0.8701, -0.9236, -0.9709, -0.8798, -0.6883, -0.9078, -0.9579,\n",
       "                      -0.9275, -1.1071, -0.5766, -0.9774, -0.8089, -0.9832, -1.1391, -0.9514,\n",
       "                      -0.9571, -0.8613, -0.9184, -0.5020, -1.0454, -0.9861, -0.8187, -0.9366,\n",
       "                      -0.9146, -0.9690, -0.4672, -1.0258, -0.9856, -0.9362, -0.3431, -0.7617,\n",
       "                      -0.8894, -0.7865, -0.8302, -0.9095, -0.8643, -0.8991, -0.9230, -0.7429,\n",
       "                      -0.7601, -0.8827, -1.0443, -0.8199, -0.9924, -0.9508, -0.6007, -0.8046,\n",
       "                      -0.9269, -0.9579, -0.7895, -0.9726, -0.8318, -1.0327, -0.9359, -0.5078],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.running_mean',\n",
       "              tensor([ -7.2217,  -9.4223,  -7.8555, -11.1171, -10.0695, -10.1816,  -9.7072,\n",
       "                      -11.7213, -11.2590, -11.6571, -11.2408, -12.6502,  -9.2718, -11.3189,\n",
       "                       -9.7495,  -9.7426, -10.5952,  -9.2792, -12.3860, -12.8628,  -9.4238,\n",
       "                       -9.1996, -11.4070, -10.2552, -14.0790,  -8.0529, -12.4514, -13.6325,\n",
       "                       -6.2170,  -6.2160, -13.5863, -14.3095,  -7.6623,  -8.5154, -15.6250,\n",
       "                      -12.8607, -12.8907, -10.0198, -11.2232,  -8.9098,  -8.9619, -11.4442,\n",
       "                      -13.6419, -12.4959, -10.6334, -10.8593,  -9.7524,  -9.5926, -10.5570,\n",
       "                       -9.5048,  -9.8907, -11.6446,  -5.3319, -11.6572,  -8.4265,  -9.6813,\n",
       "                      -13.1681, -13.0823, -11.3458,  -8.7367,  -7.2302, -12.3392,  -9.5577,\n",
       "                      -10.3921,  -8.5522,  -8.0391,  -7.5973,  -9.0618,  -6.4561, -13.9282,\n",
       "                      -11.7446,  -8.7068, -11.7447,  -9.6265, -10.5582, -11.7715,  -6.6955,\n",
       "                       -6.5593,  -7.6174, -14.4919,  -9.2879,  -9.6648,  -8.8314, -14.4307,\n",
       "                       -9.2314,  -9.1620, -13.7911,  -8.6315,  -7.4932, -12.4490, -13.6174,\n",
       "                      -12.8365,  -8.1795, -11.0466, -14.5331, -11.1737, -10.7006, -13.7215,\n",
       "                      -10.2419, -10.5857, -11.3194,  -8.6429, -14.4091, -11.8756, -10.0178,\n",
       "                      -15.7342, -12.2482, -10.7726,  -9.0064,  -7.0679,  -8.7856,  -9.3819,\n",
       "                       -8.7810,  -8.2171, -11.0313, -12.0236, -10.7850,  -8.3264, -12.4882,\n",
       "                      -12.3049, -12.1004, -11.7934,  -8.6513,  -9.9407, -12.6059,  -6.4946,\n",
       "                      -11.3678, -10.3008, -15.7178,  -9.4577, -12.9797, -11.8957,  -9.2470,\n",
       "                      -11.4784,  -8.8219, -12.2327, -11.2816,  -7.2670,  -9.0750, -10.4724,\n",
       "                       -7.4391, -11.9796,  -9.0265,  -9.7816, -10.7094,  -7.7733,  -6.4624,\n",
       "                       -9.9683,  -8.1779,  -9.5215, -12.2368,  -7.7565, -11.2028,  -4.9102,\n",
       "                       -7.1140, -10.6850, -12.9298,  -7.5132, -10.5257, -10.9926, -10.7832,\n",
       "                       -8.8580, -18.0062,  -9.4415, -10.2365, -11.5155,  -8.0074,  -6.9057,\n",
       "                      -11.1964,  -8.3443,  -6.8587, -11.6304,  -9.6873,  -8.6372,  -9.6715,\n",
       "                       -8.7017, -11.9263,  -9.1683,  -8.5967, -12.6367,  -9.3720,  -7.4918,\n",
       "                      -13.1590, -10.0388,  -9.7203, -10.3351,  -7.9317, -10.7264,  -9.6274,\n",
       "                       -8.1217,  -9.2193, -12.2071, -13.4013, -10.6536, -10.3623, -10.3160,\n",
       "                      -10.0965,  -8.1060,  -8.5414,  -9.2067, -11.1811,  -6.1787,  -9.7677,\n",
       "                       -7.1946,  -8.3545,  -9.4483, -11.4419, -13.4036, -10.8391, -12.5806,\n",
       "                       -7.6436, -14.4315, -10.3716, -10.1163, -10.5008,  -9.3274, -15.0703,\n",
       "                      -12.0637,  -9.0438, -10.4931, -11.8402, -10.3053,  -9.4609,  -7.6577,\n",
       "                      -10.5881, -12.5979,  -8.0026,  -6.9366, -11.1863, -10.6480, -12.0001,\n",
       "                      -11.1000, -12.4991, -10.0910,  -8.9072, -12.4983, -12.2681, -10.1324,\n",
       "                      -11.1406, -10.9403, -12.6944, -11.3389, -10.4013, -11.9818, -11.3081,\n",
       "                       -9.9142, -13.1472,  -9.2163, -13.2241, -11.7402, -11.6737,  -9.6230,\n",
       "                      -13.4140, -12.1015, -11.5829,  -8.9552,  -9.0485,  -9.6531,  -9.9278,\n",
       "                      -11.3367,  -9.3939, -10.8233,  -9.8794,  -8.1579, -14.4697, -11.9489,\n",
       "                       -8.7169,  -6.3876, -12.5473,  -7.8143,  -9.4044,  -9.3503,  -7.3239,\n",
       "                      -15.4242, -13.2306,  -8.0393, -10.4300, -11.2145,  -9.9549,  -9.5331,\n",
       "                      -13.3521, -11.4589, -10.0917, -10.9457,  -6.9367,  -8.9972,  -9.4621,\n",
       "                      -12.0825, -12.3788,  -9.2887,  -8.7469, -12.6476,  -8.6055,  -9.1447,\n",
       "                      -10.5725,  -8.6255,  -8.3522, -12.0912,  -7.6991, -12.8994, -11.6844,\n",
       "                      -10.7394,  -9.3927, -11.6476,  -7.7208, -11.9528,  -8.8031,  -9.6025,\n",
       "                       -8.3256,  -9.1556, -11.2885,  -7.9890, -10.5148, -10.8330, -14.7228,\n",
       "                      -12.7514, -12.7055, -11.4063, -11.3698,  -9.0356,  -8.7748, -10.5433,\n",
       "                      -11.1318,  -7.7884, -10.5276, -12.0900,  -9.2404, -13.7438, -10.4205,\n",
       "                      -12.8268, -12.3967,  -8.6786, -10.9816, -10.9238,  -5.9067, -11.4906,\n",
       "                      -10.0465, -12.1413,  -7.2672, -11.3725,  -4.9285, -11.6286, -10.8008,\n",
       "                      -10.3324, -12.3026,  -9.6679, -10.3923,  -9.8403,  -8.6109, -12.4986,\n",
       "                       -8.9889, -16.8392, -13.0485, -11.0315, -10.8717,  -8.3067, -10.5114,\n",
       "                      -14.8787, -12.6069, -10.4141,  -7.3667,  -9.0827,  -8.5039, -13.4819,\n",
       "                       -6.4613,  -5.1190,  -9.6952, -11.0072, -10.8268, -12.5833,  -7.9105,\n",
       "                      -12.5562,  -6.2074, -10.0806, -11.3504,  -9.3440,  -7.1545, -10.8582,\n",
       "                       -8.7306,  -9.0149,  -8.8829, -10.9102, -11.2524,  -8.9335,  -8.7774,\n",
       "                      -10.2540, -13.7164, -11.3447, -11.1530,  -8.0848,  -5.1182,  -7.2847,\n",
       "                       -9.5097,  -6.8421, -11.2962, -11.4274, -11.5100,  -9.4415,  -9.5615,\n",
       "                       -8.6290, -10.4914,  -5.1203, -14.6960, -12.8453, -11.7213,  -9.3324,\n",
       "                      -13.3476,  -9.4075, -11.5146,  -7.7887,  -9.4822,  -9.4678,  -9.3904,\n",
       "                      -11.4133, -12.7036, -11.6822,  -9.2775,  -8.9780, -11.1748,  -9.4884,\n",
       "                       -8.8757,  -6.3992, -11.8633,  -9.8954, -12.3142, -10.4113,  -8.0166,\n",
       "                       -8.0830, -16.9970,  -8.0023, -11.6493,  -6.2276, -11.0222, -14.8319,\n",
       "                       -8.3396,  -9.7679,  -7.3102,  -9.2206, -10.8120, -11.0586, -10.9502,\n",
       "                       -8.7739, -11.9664, -12.3467,  -9.1712,  -8.8585, -11.9318, -13.1968,\n",
       "                      -10.9864,  -7.0135, -11.3529, -10.9490, -10.8191, -14.6997,  -9.9752,\n",
       "                       -9.8470, -10.3471,  -9.8631, -16.0614, -11.2940,  -6.3747, -10.9368,\n",
       "                       -8.2019,  -9.1173,  -9.5453, -11.2364, -11.6317, -10.6414, -10.2458,\n",
       "                      -15.1182,  -8.8647, -10.5941, -11.7257,  -8.2518,  -7.7674,  -6.1582,\n",
       "                      -12.5324, -10.5480, -15.6717,  -9.8634,  -8.9418,  -9.5094,  -5.1978,\n",
       "                       -9.5818, -12.6270, -11.0348,  -6.8526,  -8.4254,  -9.6214,  -8.7497,\n",
       "                       -6.8091, -11.9404, -12.8351,  -9.0511,  -7.4129, -10.5719,  -8.1175,\n",
       "                       -9.1278, -15.8671, -10.2872, -13.2889,  -9.5792, -12.3235,  -9.9624,\n",
       "                      -11.6903, -10.9088,  -5.9552, -10.1533, -11.9592, -10.2975, -15.1941,\n",
       "                       -8.0593], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.running_var',\n",
       "              tensor([110.1013,  96.6726,  98.5284, 169.1435, 125.3366, 131.8992, 157.7085,\n",
       "                      141.3341, 149.2600, 217.5996, 176.2289, 182.7384,  80.2694, 209.9898,\n",
       "                      125.8025, 135.3296,  91.9456,  91.7280, 142.9655, 209.0277,  88.5425,\n",
       "                       82.1984, 148.4225, 135.6134, 160.7234,  63.7350,  93.9494, 200.4517,\n",
       "                       66.7372,  31.2505, 165.5277, 217.5831, 150.6635, 124.6320, 186.7790,\n",
       "                      148.4877, 144.1012, 131.7364, 189.5228,  83.9388, 107.3515, 102.9139,\n",
       "                      165.2373, 128.3841, 136.5176,  88.6900,  97.4081, 174.6878, 156.0142,\n",
       "                       84.7350,  80.9815, 166.5275,  87.9052, 121.1472,  66.6285,  81.6391,\n",
       "                      121.2194, 158.9013,  67.9545, 115.1811, 103.4202,  78.5062,  92.2965,\n",
       "                      158.7301,  49.4481, 102.7154,  47.7885, 108.4013,  73.1864, 152.3747,\n",
       "                      143.2400,  86.5247,  96.5657,  98.6674, 143.7276, 166.4690,  50.6137,\n",
       "                       93.5723,  74.5582, 185.1402, 110.8337,  94.8524, 114.5059, 142.2812,\n",
       "                       58.9620, 148.6631, 143.0482, 116.4142,  57.8174, 119.7907, 159.5803,\n",
       "                      235.4661,  87.1023, 116.2071, 124.5230,  72.2186, 168.6625, 220.6602,\n",
       "                      132.6162, 140.5872, 119.5533,  67.9487, 179.9690, 114.5721, 200.1702,\n",
       "                      190.9090, 133.7323, 166.5645,  90.8927,  44.1526,  89.1107,  81.5050,\n",
       "                       69.9309,  75.3521, 121.8020, 143.3390, 136.8282,  81.7913, 119.4934,\n",
       "                      128.8568, 183.8851, 135.8139,  92.1185, 190.1746, 202.9908,  66.4810,\n",
       "                      116.3261, 147.3400, 223.4248, 160.3358, 151.2916, 169.2514,  71.6559,\n",
       "                       90.9859,  96.6361,  92.7306,  98.1640,  50.6953,  97.8228, 109.0772,\n",
       "                       62.8536, 121.9632, 177.8334,  76.8715,  74.1420,  80.4216,  97.8073,\n",
       "                       87.0813,  86.5070, 211.5015, 168.8579, 103.6034, 111.8142,  81.8090,\n",
       "                       55.8474, 122.8912, 149.1518,  70.3364,  86.0826,  82.7988, 155.4536,\n",
       "                      120.4539, 239.7780, 127.3867, 146.4868, 139.6124, 100.1240,  84.6870,\n",
       "                      161.9178,  84.3400,  68.0607, 111.1455,  90.4961, 120.1926, 146.9254,\n",
       "                       78.8875, 108.2526,  83.5099, 170.5288, 114.0824,  57.6681,  83.1408,\n",
       "                      154.8800, 130.4887,  69.8103, 114.7006,  58.8390, 130.3068, 112.9413,\n",
       "                       95.5596,  76.9168, 107.3800, 221.2277, 131.5453, 101.0562,  74.8707,\n",
       "                       79.0981, 148.5423,  78.7560, 143.8539, 160.5497,  91.7535, 114.0328,\n",
       "                       56.7479,  86.7435, 140.3108, 175.3329, 207.8251, 169.8280, 132.7879,\n",
       "                       90.0089, 162.7866,  90.4319, 104.3550,  93.4183,  70.2525, 193.8038,\n",
       "                      145.8176, 119.6230, 180.1873, 130.2723, 249.5124,  95.7630,  43.2008,\n",
       "                       71.8060, 133.5331,  85.6062, 107.4483,  81.1492, 157.1075, 161.8346,\n",
       "                      184.4619, 162.2600,  74.3426,  70.5584, 120.7091, 144.7428,  68.3063,\n",
       "                      110.9502,  85.8114, 105.6033, 189.9105,  94.4094, 185.3419, 158.1815,\n",
       "                       69.1600, 161.4762,  65.7762, 166.5166, 111.9396, 163.1152,  72.1205,\n",
       "                      174.4374, 158.1032, 122.6268, 183.1980,  79.2362, 124.0882,  86.4705,\n",
       "                      127.4449, 113.9221, 213.7068, 273.2770,  84.5255, 223.4370, 151.7839,\n",
       "                      122.4230,  91.7628, 118.4312,  93.5417, 118.1462,  78.5812,  77.4551,\n",
       "                      310.5958, 106.2299,  46.5142,  96.5988, 170.8459,  72.7737, 110.2889,\n",
       "                      172.8573, 141.7009, 100.1371, 166.6598,  70.4011, 120.2401, 110.3596,\n",
       "                      257.4808, 206.7974, 128.4669, 112.8255,  94.8757,  70.4902, 117.4317,\n",
       "                      125.2519,  91.7481,  72.0719, 127.7492,  94.7460, 144.4422,  89.8823,\n",
       "                       58.0244, 112.2464, 141.9746,  97.7469, 148.0883, 158.9829, 114.1908,\n",
       "                      112.5693,  86.8755,  95.8040,  68.1667, 123.8803, 132.8888, 183.8204,\n",
       "                      157.2871, 108.9738, 145.1028, 126.2896, 152.6040,  58.9737, 114.8399,\n",
       "                      129.9149, 101.2524, 155.0703, 228.5103, 187.0171, 184.6077, 150.3114,\n",
       "                      120.3314, 138.5758, 114.6693, 275.3282, 111.4841, 144.9713,  72.2476,\n",
       "                      107.7681,  89.2029,  57.9141, 130.5548,  62.9172, 157.2776, 138.3540,\n",
       "                      166.7440, 131.0383, 137.9407,  83.9371, 153.9592,  73.4197, 127.9162,\n",
       "                       62.7614, 201.9830, 171.1706,  96.5811, 105.9448, 120.7381,  82.2109,\n",
       "                      212.9325, 152.6997, 132.3338,  69.9235, 111.8345,  73.2308, 292.5711,\n",
       "                       42.3482,  77.1124, 108.5411,  97.8758, 128.8943, 150.3757, 124.9101,\n",
       "                       85.6510, 147.2085, 125.9798, 157.2897, 128.7485, 117.7546, 164.0232,\n",
       "                       71.6350,  81.0349,  73.1138, 102.3292, 124.0345,  71.3246,  81.5554,\n",
       "                      107.3662, 149.7952, 125.9802, 175.7148,  76.6589, 213.6187,  90.5383,\n",
       "                      160.0675,  57.0136, 129.2416,  95.9125, 100.5742, 105.0315,  90.8378,\n",
       "                       72.2433, 139.2287,  81.7090, 282.4514, 147.1225, 111.8001,  84.1852,\n",
       "                      181.8748,  85.6247,  83.1833,  51.0131,  80.0823, 158.6868,  68.2417,\n",
       "                      183.6794, 146.5224, 187.7189, 100.0812, 130.7287, 105.3006,  70.1932,\n",
       "                       97.1133,  77.9340, 190.2665,  79.4642, 160.6101, 118.4879, 130.7286,\n",
       "                       47.0878, 217.4846,  89.7300, 177.2421, 109.4929, 201.4668, 246.0836,\n",
       "                      119.2581, 115.1693,  52.8004,  97.3680, 120.0003, 194.6324, 124.6765,\n",
       "                       80.3927,  91.8537, 184.7792, 106.4194,  64.6763, 165.3777, 196.0274,\n",
       "                      167.1150,  70.6278,  97.2015, 161.7706, 103.0451, 142.7020,  95.7354,\n",
       "                       90.0979, 134.3394, 120.6295, 206.8418, 165.7470,  48.3387, 189.5372,\n",
       "                       85.3331,  85.3150,  73.5294,  92.7901, 220.5452,  99.2099, 196.0856,\n",
       "                      202.2265,  51.3303,  86.5851, 114.2133,  68.9200,  75.2077,  66.1028,\n",
       "                      122.0823, 117.7750, 245.7526,  66.1286, 123.7523,  65.8125,  87.0287,\n",
       "                      104.8593, 113.6976,  81.1487, 157.0695, 153.1468, 102.4417, 109.2315,\n",
       "                       72.9572, 148.5748, 182.4391,  71.6832,  72.7795, 162.9872, 106.4467,\n",
       "                       93.8314, 162.9913, 129.5555, 196.3907, 164.7498, 165.6248, 114.9831,\n",
       "                      168.4438, 115.9995, 101.6505, 129.2027, 130.0742,  97.4615, 142.0679,\n",
       "                      144.2227], device='cuda:0')),\n",
       "             ('encoder.base.conv_block4.bn2.num_batches_tracked',\n",
       "              tensor(586728, device='cuda:0')),\n",
       "             ('pos_encoder.pe',\n",
       "              tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "                         0.0000e+00,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 8.4147e-01,  5.4030e-01,  7.8859e-01,  ...,  1.0000e+00,\n",
       "                         1.1007e-04,  1.0000e+00]],\n",
       "              \n",
       "                      [[ 9.0930e-01, -4.1615e-01,  9.6984e-01,  ...,  1.0000e+00,\n",
       "                         2.2014e-04,  1.0000e+00]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 3.7961e-01, -9.2515e-01,  1.6091e-01,  ...,  9.9993e-01,\n",
       "                         1.0677e-02,  9.9994e-01]],\n",
       "              \n",
       "                      [[-5.7338e-01, -8.1929e-01,  8.7726e-01,  ...,  9.9993e-01,\n",
       "                         1.0787e-02,  9.9994e-01]],\n",
       "              \n",
       "                      [[-9.9921e-01,  3.9821e-02,  9.1797e-01,  ...,  9.9993e-01,\n",
       "                         1.0897e-02,  9.9994e-01]]], device='cuda:0'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "786e703d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_emb): Embedding(4371, 192)\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=512, out_features=192, bias=True)\n",
       "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
       "  (encoder): Cnn10(\n",
       "    (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_block1): ConvBlock(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block2): ConvBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block3): ConvBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block4): ConvBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (generator): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15e50c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터 이름 맞추기\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith('encoder'):\n",
    "        s=name\n",
    "        name=s.replace('encoder','base')\n",
    "        name=name\n",
    "    else:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best=torch.load(\"/home/hj20/dcase_2020_T6/models/cnn10_best_48.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a849727a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('transformer_decoder.layers.0.self_attn.in_proj_weight', tensor([[-0.1121,  0.1543, -0.0988,  ..., -0.0251, -0.0537, -0.0022],\n",
       "        [ 0.0296,  0.0604, -0.1261,  ..., -0.0366, -0.0391, -0.0789],\n",
       "        [-0.0670,  0.0440, -0.0538,  ..., -0.0826, -0.0667, -0.0441],\n",
       "        ...,\n",
       "        [ 0.0519,  0.0259,  0.0380,  ..., -0.0424,  0.0839, -0.0298],\n",
       "        [-0.1306,  0.0024,  0.0710,  ...,  0.0484, -0.0190, -0.0325],\n",
       "        [-0.0671, -0.0377,  0.0468,  ..., -0.0534, -0.0323, -0.0415]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.0.self_attn.in_proj_bias', tensor([-4.8882e-02,  1.4886e-02, -1.3403e-02, -3.1634e-02,  2.4075e-02,\n",
       "         6.1872e-02,  3.3191e-02,  4.9238e-03, -2.4707e-02, -2.9865e-02,\n",
       "        -8.4079e-02,  6.5329e-04,  2.5111e-02, -7.4482e-02, -5.5098e-02,\n",
       "         3.9614e-02,  3.6864e-02,  5.8129e-03, -8.2433e-03, -4.9785e-02,\n",
       "         4.7040e-02,  3.5419e-02, -7.7811e-02, -2.3538e-02, -3.2797e-02,\n",
       "         5.0955e-02,  1.2973e-02,  8.2237e-02, -6.7934e-02, -4.8609e-03,\n",
       "         5.2928e-03, -1.4551e-02, -4.8945e-02, -2.8405e-03,  1.1080e-01,\n",
       "        -1.1835e-02, -7.7633e-02, -3.2229e-02, -3.3883e-02,  1.1286e-02,\n",
       "         9.5591e-02,  7.0906e-02, -5.2854e-02, -8.2858e-02,  1.4638e-02,\n",
       "         1.1863e-02,  5.4218e-02,  3.7832e-03,  2.1142e-02,  4.5759e-02,\n",
       "        -1.3421e-03, -5.1448e-02,  2.7143e-02, -1.3486e-02, -1.7756e-02,\n",
       "        -2.6771e-03,  1.0478e-02, -3.1756e-02,  4.3664e-02,  5.6513e-02,\n",
       "        -2.2516e-02,  2.3603e-02, -2.7578e-02, -1.8583e-02, -1.6563e-03,\n",
       "         2.1780e-02, -2.1138e-02,  2.5185e-02, -3.9830e-02,  5.6972e-02,\n",
       "        -1.8557e-02,  5.4048e-02,  3.6929e-02, -4.3725e-02, -3.5584e-02,\n",
       "         5.2630e-02,  1.8012e-02,  2.9198e-02, -2.1126e-02, -3.6502e-02,\n",
       "         1.4218e-02,  2.3038e-02, -4.4794e-02, -1.9552e-02,  6.1013e-02,\n",
       "        -7.8966e-03,  8.0278e-03, -1.1486e-02, -2.0190e-02, -1.6710e-02,\n",
       "         2.8131e-02,  3.0692e-02,  3.6090e-02, -4.1345e-02,  4.4258e-02,\n",
       "         7.3780e-03,  3.4233e-02, -1.8111e-02, -1.3227e-02,  7.3515e-02,\n",
       "         1.1337e-02,  9.9177e-03, -8.6224e-02,  2.2670e-02,  1.3303e-02,\n",
       "         5.5076e-02,  6.2373e-02, -3.1701e-02,  7.1008e-02, -2.3537e-02,\n",
       "         3.1060e-02,  2.6192e-02, -3.2962e-02, -4.7220e-02,  4.7160e-02,\n",
       "         2.0929e-02,  6.2649e-02,  6.2644e-02,  5.8579e-02,  6.6606e-02,\n",
       "        -4.8528e-02,  1.0226e-02, -3.0267e-02, -3.7159e-02, -1.1162e-02,\n",
       "         3.7877e-04,  2.0019e-02, -1.9767e-02, -4.1481e-02, -7.0210e-02,\n",
       "         2.8430e-02,  6.9786e-02,  2.0005e-02,  9.6821e-04, -8.2378e-03,\n",
       "         8.2414e-03,  2.7708e-02, -4.9569e-02, -2.1599e-02, -8.0262e-02,\n",
       "        -1.6523e-02, -4.0349e-02,  4.2360e-04, -9.3588e-02, -3.0103e-02,\n",
       "         4.3306e-02,  2.5295e-02,  1.0102e-02,  1.3036e-02, -7.6830e-02,\n",
       "         4.2402e-02, -2.7280e-02, -2.2149e-02, -6.9022e-03,  6.0508e-02,\n",
       "        -9.8263e-06, -1.4295e-03,  5.8245e-02, -7.0920e-03, -2.0126e-02,\n",
       "        -2.1960e-02, -3.1308e-03,  1.7412e-02, -1.4055e-02,  5.1541e-02,\n",
       "        -6.4362e-02,  1.2900e-02,  6.3986e-02, -2.5059e-02, -1.2995e-02,\n",
       "         5.8593e-02, -3.5203e-02, -5.3229e-02,  5.3457e-02,  3.4618e-02,\n",
       "         5.5110e-02, -6.3361e-02,  1.6490e-03,  8.1990e-02,  1.7448e-02,\n",
       "        -5.6289e-02, -1.2129e-02, -9.0056e-02, -5.8310e-02,  1.1758e-03,\n",
       "         2.8986e-02, -5.3037e-03,  1.7086e-03, -3.7347e-02, -5.2185e-02,\n",
       "         1.0463e-02, -3.6608e-02,  1.8068e-05,  5.9495e-07,  5.7673e-06,\n",
       "        -2.7862e-07, -4.4372e-06, -8.0239e-07, -1.1467e-05,  7.6796e-06,\n",
       "        -1.3956e-06,  5.1741e-06,  2.1183e-06,  7.7048e-06, -9.7893e-06,\n",
       "        -1.4522e-05,  3.4087e-07,  1.8796e-05, -2.6494e-06,  1.4365e-05,\n",
       "        -8.7614e-06, -1.1120e-05, -1.8833e-05,  2.8068e-05, -3.8711e-06,\n",
       "        -8.2170e-06,  1.2640e-07,  6.2034e-06,  2.6308e-05,  4.4106e-06,\n",
       "         3.0250e-06, -1.1356e-05,  1.1416e-07,  4.0462e-07,  2.8889e-06,\n",
       "        -6.8269e-07,  3.5595e-06, -3.1678e-06, -6.0499e-06,  1.2191e-05,\n",
       "         3.8592e-06,  1.4879e-05,  7.7183e-06,  2.5749e-06,  1.5579e-05,\n",
       "         1.2576e-05,  1.7262e-05, -8.3990e-06,  1.9338e-05, -2.4847e-06,\n",
       "         1.4755e-05,  1.7367e-05,  3.9021e-06, -2.3688e-05, -4.8710e-06,\n",
       "        -1.4862e-06, -1.0407e-05,  7.0105e-06,  8.7756e-06, -1.0468e-06,\n",
       "         1.9916e-05, -6.6776e-07, -1.2132e-05,  2.0989e-06, -2.8841e-05,\n",
       "        -6.4898e-06,  5.5858e-06,  3.1141e-06, -4.8956e-06, -7.8123e-06,\n",
       "         1.3019e-06,  1.0751e-05, -1.9872e-05,  1.4185e-05,  1.9184e-05,\n",
       "        -2.1530e-05,  1.4479e-05,  2.1295e-05, -1.0091e-05, -1.2123e-05,\n",
       "        -4.9186e-06,  2.5457e-06, -5.5626e-06,  2.2077e-07, -1.5818e-05,\n",
       "        -9.4985e-06,  1.2390e-05, -6.5742e-06, -4.6334e-06, -2.0278e-06,\n",
       "        -3.0525e-06, -4.4899e-06, -6.5110e-06,  1.5640e-05,  9.6016e-06,\n",
       "        -3.8675e-06,  9.9518e-06,  9.3398e-06,  7.4123e-06, -1.1731e-05,\n",
       "        -8.2104e-06, -9.5115e-06, -3.3973e-06, -4.0556e-06, -1.0658e-05,\n",
       "        -1.4509e-05,  2.2110e-05,  8.0925e-07,  1.4756e-05,  9.0053e-06,\n",
       "        -3.4359e-06, -4.4677e-06, -1.7822e-06, -1.3005e-05, -1.3517e-05,\n",
       "         1.6259e-05, -4.7014e-06, -8.7356e-06, -6.7677e-07,  1.5488e-05,\n",
       "        -5.6666e-06, -4.0197e-06,  8.7348e-06, -6.6217e-06,  2.0163e-06,\n",
       "         3.4504e-06, -7.3133e-06, -8.6196e-06,  6.1361e-06,  1.1035e-05,\n",
       "         1.3948e-05,  9.1823e-06,  1.0121e-05,  4.3631e-06, -1.1018e-05,\n",
       "        -8.7860e-06,  1.1358e-05,  1.4105e-05,  1.6605e-05, -1.7249e-05,\n",
       "        -1.9136e-07,  5.9873e-06,  8.4071e-06, -8.9901e-06, -5.5589e-06,\n",
       "         4.9634e-06, -7.8524e-06, -5.3248e-06,  1.9807e-05, -1.6503e-05,\n",
       "         9.4166e-06,  6.9066e-06, -8.5433e-06,  2.9994e-06, -2.8097e-06,\n",
       "        -2.7189e-05,  6.4151e-06, -1.2244e-05,  5.6847e-06, -5.6364e-06,\n",
       "        -1.6330e-06, -1.2545e-06,  1.0316e-05,  1.4496e-05,  1.2129e-05,\n",
       "         1.1116e-05,  4.1328e-06, -1.1332e-05,  3.8587e-06, -1.0591e-05,\n",
       "        -1.4575e-06, -2.7460e-06,  9.7502e-09,  4.0198e-06,  2.8573e-06,\n",
       "        -1.0807e-05, -1.0168e-05,  6.9058e-06,  8.4973e-06,  1.2796e-05,\n",
       "        -6.8630e-06, -3.0286e-06,  1.3395e-05,  5.7577e-06, -6.8268e-07,\n",
       "         5.6857e-06, -1.6506e-05, -1.4703e-06,  4.1138e-06, -8.2722e-06,\n",
       "         8.3598e-06, -3.7493e-06,  7.0791e-06, -9.0113e-07,  1.6303e-03,\n",
       "        -9.6012e-03, -5.4251e-04, -7.9567e-03,  2.0648e-02,  1.8485e-02,\n",
       "        -2.5845e-04, -1.6929e-02, -1.5671e-02, -1.0191e-02,  6.3123e-03,\n",
       "        -1.3405e-03,  3.1166e-02, -1.8430e-02, -3.2544e-03, -4.0480e-03,\n",
       "         4.0280e-04,  3.3984e-04,  1.6234e-02, -2.1567e-03, -1.4890e-02,\n",
       "        -7.9630e-03,  1.6148e-03, -1.0456e-02, -1.6454e-02, -1.2794e-02,\n",
       "         7.7591e-03,  1.2401e-02, -7.8674e-03,  4.8117e-03, -2.7521e-02,\n",
       "         5.3664e-03,  6.1583e-03,  1.0492e-02, -3.7021e-03, -1.1865e-02,\n",
       "         1.2562e-02,  1.3275e-02,  1.1872e-02,  5.1559e-03, -1.3351e-02,\n",
       "        -5.9799e-03, -1.3111e-02,  9.7624e-04, -2.5651e-02, -4.5339e-04,\n",
       "         5.2899e-03, -1.0601e-02, -3.6222e-03, -1.1123e-02, -1.9616e-02,\n",
       "        -4.8156e-03,  6.0370e-03,  8.0743e-03, -6.2176e-03,  4.4354e-05,\n",
       "         6.1760e-03,  2.0883e-02, -1.8602e-02, -1.0920e-02, -1.0792e-02,\n",
       "         6.0563e-03, -1.0085e-02,  9.5700e-03,  9.4747e-03,  1.1323e-02,\n",
       "        -1.1852e-02,  3.3083e-03,  5.6840e-03, -1.0192e-02,  2.0097e-02,\n",
       "        -1.3658e-02, -2.3602e-02, -9.2293e-03, -1.5105e-03, -1.1637e-03,\n",
       "         5.3992e-03, -9.3063e-03,  2.1969e-03, -9.6324e-03,  8.6117e-03,\n",
       "        -1.1540e-02,  5.4705e-03,  4.4957e-03, -1.6253e-02, -3.9632e-03,\n",
       "         2.3247e-04, -2.7323e-03, -8.9022e-03,  9.7149e-03, -4.3621e-03,\n",
       "        -8.9750e-03,  1.9970e-02,  1.7519e-04, -6.3800e-03,  5.2539e-03,\n",
       "         4.1380e-03, -1.6113e-02, -2.4926e-02, -1.8221e-02,  3.0167e-03,\n",
       "        -1.4001e-03, -5.5736e-03, -2.0499e-04, -4.2547e-03, -1.6165e-02,\n",
       "         4.1057e-03,  3.8345e-03, -6.1370e-03, -1.2611e-02, -3.7280e-04,\n",
       "        -1.2744e-03, -3.8480e-03,  1.6761e-02, -5.9505e-03,  3.1695e-03,\n",
       "         1.7846e-02, -5.1126e-03, -1.4647e-02,  2.6612e-03, -4.3751e-03,\n",
       "         8.5199e-03,  1.3615e-02, -3.1236e-03, -1.5956e-03,  3.4538e-02,\n",
       "         1.0163e-02,  9.5487e-03, -9.4259e-03,  3.0504e-03, -9.4489e-03,\n",
       "        -1.9994e-02, -4.1760e-03,  1.6245e-02,  5.4962e-03,  1.3091e-02,\n",
       "         2.1879e-02, -3.4830e-02,  6.2942e-03, -1.6166e-02, -1.9049e-02,\n",
       "        -8.9314e-03,  8.2999e-03,  3.4078e-03,  3.1725e-03, -4.0692e-03,\n",
       "         6.8395e-03, -7.1589e-03, -3.0603e-03,  1.1652e-02,  1.1986e-02,\n",
       "         1.2687e-02,  2.9401e-03,  1.8258e-02,  2.0876e-02,  1.5723e-02,\n",
       "        -6.3720e-03, -1.2507e-02, -3.5083e-04,  1.3760e-04,  2.1818e-02,\n",
       "         3.8723e-03, -1.0731e-02,  1.2925e-02,  6.9276e-03,  7.0941e-03,\n",
       "         1.6803e-02,  8.9527e-03,  2.8582e-03,  1.6302e-03,  1.8747e-02,\n",
       "        -2.5962e-02,  1.1765e-02,  2.2601e-02, -2.0326e-04,  4.0143e-03,\n",
       "        -1.9114e-02, -2.4557e-02,  2.4854e-02, -2.4203e-02,  8.3314e-03,\n",
       "         1.6553e-02,  9.2608e-04, -8.0551e-03,  1.6081e-02, -6.5435e-03,\n",
       "        -1.4003e-03,  5.9490e-03, -3.6475e-03, -6.4959e-04, -2.2006e-02,\n",
       "         1.8325e-02], device='cuda:0')), ('transformer_decoder.layers.0.self_attn.out_proj.weight', tensor([[ 0.0071, -0.0170,  0.0544,  ...,  0.0417, -0.0457,  0.0115],\n",
       "        [ 0.0116, -0.0627,  0.0536,  ..., -0.0290,  0.0505, -0.0429],\n",
       "        [ 0.0030, -0.0363,  0.0468,  ...,  0.0435,  0.0419,  0.0496],\n",
       "        ...,\n",
       "        [-0.0251, -0.0649,  0.0008,  ...,  0.0273, -0.0087, -0.0659],\n",
       "        [-0.0135,  0.0043, -0.0222,  ...,  0.0163, -0.0711,  0.0409],\n",
       "        [ 0.0986, -0.0893, -0.0425,  ..., -0.0275, -0.0433,  0.0447]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.0.self_attn.out_proj.bias', tensor([ 4.5005e-02, -5.7770e-02,  2.2619e-02, -4.7946e-02,  1.2709e-02,\n",
       "         4.0395e-03,  5.0262e-03,  1.8686e-02,  6.1701e-02,  1.5990e-02,\n",
       "        -1.6832e-02,  1.3102e-02,  3.2107e-03,  8.3510e-03, -1.6098e-02,\n",
       "        -5.0668e-03, -3.2309e-02,  1.7314e-02, -1.1023e-02,  5.4407e-02,\n",
       "        -8.1607e-03, -2.3525e-02, -4.5785e-02, -1.1861e-02, -3.2681e-02,\n",
       "         1.9470e-02, -3.5496e-02,  3.7925e-03,  3.4880e-02, -3.2732e-02,\n",
       "        -3.4458e-02, -3.0290e-02, -5.9235e-03, -1.0048e-02, -4.7402e-02,\n",
       "        -1.7985e-02, -1.9088e-02, -1.5136e-02, -8.5931e-03,  2.7678e-02,\n",
       "        -3.9901e-02, -5.3573e-03, -1.4800e-02, -1.8086e-02, -1.7363e-02,\n",
       "        -1.7534e-02,  2.3187e-02, -4.8089e-03,  2.2995e-02, -3.2562e-02,\n",
       "         2.6960e-02, -9.6114e-03, -2.0635e-02,  1.2320e-02, -1.9474e-03,\n",
       "         2.8542e-02,  6.2370e-03, -2.5571e-03, -4.9565e-03, -1.7610e-02,\n",
       "        -1.1158e-02,  2.6874e-02, -4.2357e-02,  9.5133e-03, -8.9433e-02,\n",
       "        -3.2635e-02,  8.6950e-03, -1.3292e-02,  1.1847e-02,  3.7086e-03,\n",
       "         3.1326e-02,  2.4883e-02,  1.1376e-03, -1.1957e-02, -6.7654e-03,\n",
       "         1.4580e-03, -1.1571e-03, -8.3807e-03,  1.4737e-02,  2.9075e-03,\n",
       "         2.2689e-02,  1.8249e-02, -1.9737e-02,  4.0774e-02, -3.3194e-03,\n",
       "        -3.7961e-03, -1.9316e-02,  8.0790e-02, -3.0340e-02, -4.2859e-03,\n",
       "         4.0717e-02,  2.8951e-02, -1.7661e-02,  3.8694e-02,  3.1667e-02,\n",
       "         3.5434e-02,  4.6041e-03,  7.7567e-04,  6.1045e-03, -3.5738e-02,\n",
       "        -6.2822e-03, -1.1982e-02,  1.1408e-02,  4.7743e-03, -1.3419e-02,\n",
       "         1.7808e-02, -7.2443e-03,  2.5336e-02, -1.9320e-02,  1.8701e-02,\n",
       "         2.4112e-02, -1.0928e-02, -1.5588e-02, -3.1790e-02, -4.0040e-02,\n",
       "         9.0055e-03,  1.4874e-02,  3.3433e-02, -8.2995e-03,  4.8370e-03,\n",
       "         2.1514e-02, -1.2159e-03,  3.6464e-02,  2.1912e-02,  7.6836e-03,\n",
       "         5.5695e-02,  8.7656e-03,  1.7148e-02, -2.9240e-02,  3.0324e-02,\n",
       "         1.0201e-02,  4.1016e-02, -1.1358e-02,  3.1722e-03,  3.3864e-03,\n",
       "         1.0282e-02, -9.5728e-03,  2.3971e-02,  1.2634e-02, -3.6492e-02,\n",
       "         5.9735e-03,  3.5276e-02, -1.4573e-02, -3.4076e-03, -1.4085e-02,\n",
       "        -1.4274e-02,  1.5589e-02, -8.6285e-04,  2.8017e-02, -2.8156e-03,\n",
       "        -6.9918e-03,  3.4997e-02, -6.6776e-03, -2.0914e-02, -1.9886e-02,\n",
       "        -1.6349e-03,  1.2484e-02,  1.2373e-02, -9.2129e-03,  2.1557e-02,\n",
       "        -1.4658e-03, -3.2431e-02,  2.1798e-02,  5.5920e-02,  1.0223e-02,\n",
       "        -1.2436e-03, -1.9993e-02,  3.5559e-02,  1.0937e-03,  1.6642e-02,\n",
       "         2.2836e-02, -2.3831e-02,  1.2063e-02,  1.3795e-02,  1.5220e-02,\n",
       "        -2.7483e-03,  1.0863e-02,  3.8898e-02, -2.4596e-02,  6.0935e-03,\n",
       "        -2.9736e-02, -1.3506e-03,  2.2078e-02, -4.0607e-02,  1.0178e-02,\n",
       "         1.5563e-02,  3.4041e-02, -3.2595e-02, -2.3743e-02,  3.5603e-02,\n",
       "         4.0861e-05,  1.2753e-02], device='cuda:0')), ('transformer_decoder.layers.0.multihead_attn.in_proj_weight', tensor([[-0.0510,  0.0235,  0.0390,  ...,  0.0022, -0.0389,  0.0308],\n",
       "        [-0.0576,  0.1312,  0.0614,  ..., -0.0323, -0.0187,  0.0050],\n",
       "        [ 0.0004,  0.0592, -0.0743,  ..., -0.0778, -0.0405,  0.0197],\n",
       "        ...,\n",
       "        [ 0.0793, -0.0213, -0.0250,  ..., -0.0374,  0.0299, -0.0058],\n",
       "        [ 0.0236,  0.0140, -0.1080,  ..., -0.0605,  0.1349, -0.0244],\n",
       "        [ 0.0547, -0.0423, -0.0525,  ...,  0.0670, -0.0364,  0.1099]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.0.multihead_attn.in_proj_bias', tensor([ 1.5719e-02, -6.5023e-02, -7.4259e-02, -3.2016e-02, -1.2725e-02,\n",
       "        -1.6205e-02,  2.7985e-02,  4.2385e-02,  8.4327e-02, -4.9016e-02,\n",
       "        -6.6608e-03, -1.7063e-03,  1.2185e-01,  1.1178e-01,  2.0014e-02,\n",
       "         4.9659e-02,  1.0708e-01,  1.8618e-01,  1.7622e-01,  5.4289e-02,\n",
       "         8.4650e-02,  1.2694e-03, -6.8204e-03, -1.7957e-01,  4.0825e-02,\n",
       "        -5.8345e-02,  2.0193e-02, -1.4281e-01,  9.9162e-02,  1.6082e-02,\n",
       "         3.8716e-03,  9.5413e-02,  2.1360e-02,  8.1995e-02, -3.2427e-03,\n",
       "        -6.2873e-02,  5.1095e-02, -4.6009e-02,  4.1415e-02,  1.3450e-01,\n",
       "         5.7405e-02, -1.6322e-01,  1.6365e-01, -1.0268e-01, -1.6924e-01,\n",
       "         4.0478e-04,  1.1233e-01,  5.2837e-02, -4.8728e-02, -9.0370e-02,\n",
       "         1.9675e-01,  1.4328e-01, -1.2257e-01,  1.1671e-01, -2.0108e-01,\n",
       "        -5.3182e-02, -8.8471e-02,  9.9866e-02, -1.1494e-01,  1.8033e-01,\n",
       "        -2.4498e-02,  1.4649e-01,  1.2888e-01, -1.3570e-01, -5.3837e-02,\n",
       "         1.4408e-01,  1.2218e-01, -1.6364e-01,  1.6133e-01,  8.3091e-02,\n",
       "        -1.6595e-01, -1.8332e-01,  1.5886e-02,  1.6835e-01, -9.5366e-02,\n",
       "         2.0251e-01, -3.4824e-02,  1.7640e-01,  1.4353e-01,  1.4627e-01,\n",
       "         8.7901e-02,  1.5454e-01, -5.5306e-02,  8.3272e-02, -1.8956e-01,\n",
       "        -5.8504e-02,  6.4809e-02, -1.0490e-01,  1.4487e-01, -1.4120e-01,\n",
       "         1.9036e-01, -1.5010e-01, -1.6259e-01, -1.1575e-02,  5.8022e-02,\n",
       "         1.0943e-01,  1.2804e-01,  9.0255e-02,  6.8738e-02, -4.1632e-02,\n",
       "         7.5363e-02,  5.9557e-02,  5.6483e-03,  8.4279e-02, -6.2927e-02,\n",
       "        -9.7351e-02,  2.4894e-02, -3.0917e-02,  6.0600e-02, -1.3552e-01,\n",
       "         2.6484e-02,  7.5328e-02,  3.3857e-02,  1.6079e-02,  6.9198e-02,\n",
       "        -5.9800e-02,  1.2569e-01, -3.3195e-03,  7.0211e-02, -2.0361e-02,\n",
       "        -2.3659e-02, -6.8085e-02, -8.2717e-03, -9.2561e-02,  6.4189e-02,\n",
       "         5.4724e-02, -2.5061e-02, -6.9251e-02, -1.1177e-03, -1.5826e-02,\n",
       "        -1.5914e-02, -1.4413e-02,  1.2587e-01,  1.4106e-01, -3.5848e-02,\n",
       "         3.1298e-04,  4.9775e-02, -1.9188e-02,  5.2998e-03,  5.6199e-02,\n",
       "        -3.0183e-02, -4.1522e-02,  5.5708e-02,  9.6429e-02,  1.0489e-01,\n",
       "         1.8989e-01,  2.3053e-01,  5.4516e-03, -1.4345e-02,  6.4166e-02,\n",
       "         8.1795e-02,  3.2163e-02, -1.9433e-01, -1.7814e-01,  1.5610e-01,\n",
       "         4.6796e-02,  1.6577e-01, -1.7953e-01,  1.9409e-01, -3.2803e-02,\n",
       "        -9.1183e-03, -1.3341e-01, -8.4511e-02,  1.3134e-01, -1.7424e-01,\n",
       "        -7.4281e-02, -2.2600e-01,  1.0690e-01,  1.5900e-01,  1.0985e-01,\n",
       "        -1.8252e-01,  6.8460e-02,  9.5344e-02, -7.9874e-02, -5.5933e-02,\n",
       "        -1.1369e-02, -6.6311e-02, -1.5390e-01, -1.0869e-01,  2.5441e-02,\n",
       "        -2.2509e-01,  1.0533e-01,  2.0403e-02, -1.1195e-01, -2.2535e-01,\n",
       "         2.9697e-03,  3.1386e-02, -2.9968e-03,  3.7162e-02,  5.4720e-02,\n",
       "        -1.1231e-01,  1.4205e-01, -6.5057e-06, -7.0764e-06,  3.7421e-06,\n",
       "        -2.0166e-06, -1.2356e-05, -2.5593e-06, -3.1904e-06,  4.6997e-06,\n",
       "        -7.7547e-06, -1.9689e-06, -1.0125e-05, -1.1658e-05, -1.0043e-05,\n",
       "         1.4630e-05, -4.9768e-06,  7.2710e-07, -4.1527e-07, -5.7933e-06,\n",
       "        -8.6928e-06,  7.2949e-06, -1.4098e-05, -7.5106e-06,  9.2135e-06,\n",
       "         5.1398e-06, -1.5048e-06, -6.7764e-06,  7.6130e-07,  5.3331e-06,\n",
       "        -1.3136e-06, -7.1179e-06, -7.4296e-06, -7.5033e-06, -5.0354e-06,\n",
       "         2.3946e-06, -7.1851e-06, -3.7053e-06,  2.8297e-06, -2.2827e-06,\n",
       "        -5.3683e-06,  3.3629e-06, -1.3121e-06, -7.6834e-06,  4.8597e-07,\n",
       "        -5.3724e-06,  5.7536e-06, -7.2392e-06, -1.0158e-05, -5.1635e-07,\n",
       "        -1.5685e-06,  8.0575e-06, -8.6190e-06, -4.0266e-06,  2.1771e-06,\n",
       "         6.1807e-06, -1.0185e-05,  1.4256e-06, -6.6482e-06, -9.3988e-07,\n",
       "         1.0484e-05,  6.2684e-06, -2.4461e-06,  1.2868e-06,  3.3807e-06,\n",
       "        -9.6079e-06, -1.0451e-06,  5.6985e-06,  3.8938e-06,  1.5543e-06,\n",
       "        -6.1950e-06,  4.7622e-06,  4.9368e-06,  5.3637e-06, -1.9757e-06,\n",
       "         7.1534e-06,  9.4358e-06, -1.5044e-06, -7.6798e-06,  3.1864e-06,\n",
       "        -3.3255e-06,  8.5677e-06,  1.8699e-06,  9.3920e-06,  4.2862e-06,\n",
       "         3.6217e-06,  2.0951e-05,  5.9336e-06, -4.4011e-06, -1.2528e-05,\n",
       "         1.5726e-05,  4.2865e-06, -8.0846e-06,  1.6137e-06, -5.2794e-06,\n",
       "         3.8477e-06, -3.0863e-06,  1.4422e-06, -1.8195e-06, -2.7978e-06,\n",
       "        -3.4908e-06,  3.9427e-06,  1.0204e-05, -4.6609e-07, -1.4795e-06,\n",
       "         3.4507e-06, -1.5536e-06, -1.5025e-06, -3.8499e-06,  5.5031e-07,\n",
       "        -2.5372e-06, -6.6340e-06, -6.9294e-06, -1.9167e-07, -1.9270e-06,\n",
       "        -1.1534e-06,  2.3052e-06,  5.4208e-06,  8.7959e-07,  6.5298e-07,\n",
       "         7.5313e-08,  2.5505e-06,  2.3096e-06,  8.8688e-06,  4.4825e-06,\n",
       "         1.7142e-06, -5.5938e-06,  8.1063e-07, -1.6574e-07,  4.8960e-06,\n",
       "         5.1882e-06, -7.9997e-06, -5.0402e-06, -8.2934e-06,  6.3917e-06,\n",
       "         4.9754e-06,  6.7534e-06,  5.0178e-06, -1.7724e-06,  7.4930e-07,\n",
       "        -6.2737e-06, -1.3607e-06,  6.1511e-07,  3.1505e-07,  5.0712e-07,\n",
       "        -8.6979e-07,  3.1747e-07,  8.9290e-06, -3.5459e-07, -1.0801e-05,\n",
       "        -1.1407e-05,  9.3820e-06, -5.8160e-07, -3.8076e-06, -9.3735e-06,\n",
       "         4.5460e-06,  8.2010e-06,  2.8333e-06,  1.5056e-08, -1.2404e-05,\n",
       "        -3.8821e-06, -3.2701e-07, -1.8181e-06, -6.9650e-06, -6.7588e-06,\n",
       "        -1.7403e-06,  2.1445e-06,  3.8730e-06, -1.3280e-06,  3.7354e-06,\n",
       "         1.1475e-05,  5.1851e-06, -2.6614e-06, -2.1292e-07,  5.7815e-07,\n",
       "        -7.2227e-06,  4.9871e-06, -9.2567e-07, -4.4973e-06, -2.3517e-06,\n",
       "        -1.2250e-06,  5.6164e-06,  5.9067e-06,  5.9379e-06,  4.6954e-06,\n",
       "         6.9731e-07, -4.3795e-07, -2.2880e-06,  7.7874e-06, -5.1595e-06,\n",
       "        -1.7105e-06, -5.5070e-06,  5.7244e-06,  5.4474e-06,  3.0089e-02,\n",
       "         1.1338e-02,  3.9437e-02,  1.7516e-02,  1.7094e-03, -1.8524e-02,\n",
       "         2.3037e-02, -4.1646e-02, -2.9902e-02,  1.4140e-02, -1.8229e-02,\n",
       "         2.9954e-02, -6.1651e-03, -1.0826e-02,  3.9289e-02, -1.8914e-02,\n",
       "        -4.3496e-02, -2.1388e-02,  2.5527e-02, -1.4475e-03, -3.5708e-02,\n",
       "        -1.0787e-02,  2.8714e-02, -3.8172e-02, -1.9748e-02, -5.1771e-02,\n",
       "         4.1120e-02, -5.5818e-02,  4.0496e-02,  5.4719e-02,  1.7898e-02,\n",
       "        -1.6385e-02,  3.8480e-02, -6.0435e-02, -4.2043e-02,  1.4359e-02,\n",
       "         3.5543e-02, -9.7380e-03, -6.5012e-03, -8.0451e-03, -4.4921e-03,\n",
       "         1.0385e-02, -3.3786e-03,  7.0143e-02, -1.2088e-02,  9.3490e-03,\n",
       "         6.8397e-03, -3.3300e-02,  4.8289e-02, -1.2607e-02,  4.5281e-02,\n",
       "         4.0373e-02, -4.3526e-02, -8.5757e-03,  1.6170e-02, -4.7732e-02,\n",
       "         5.9965e-03, -2.2384e-02,  2.7536e-02,  3.4251e-02, -4.3974e-02,\n",
       "        -2.2144e-02,  5.8228e-03,  1.9570e-02, -4.9301e-02,  2.2661e-02,\n",
       "         2.4072e-02, -3.3470e-02,  2.3383e-02, -2.6210e-02,  4.9462e-03,\n",
       "         1.4282e-02, -1.5927e-02, -2.7038e-02,  1.0392e-02, -1.4839e-02,\n",
       "        -1.1217e-02, -1.5057e-02,  2.9870e-02,  4.1216e-02, -3.2408e-02,\n",
       "        -1.4546e-02, -5.5052e-02, -2.4855e-02,  4.1109e-02,  2.6727e-02,\n",
       "         3.1205e-02, -2.5827e-02,  6.7742e-03, -1.2371e-02,  4.5097e-02,\n",
       "         1.4142e-02,  2.5086e-02,  3.9702e-03, -2.9593e-02, -1.8877e-02,\n",
       "         2.9677e-02,  2.1262e-02,  1.2180e-02,  4.0362e-02,  5.3087e-02,\n",
       "         1.4109e-02, -2.5317e-02,  5.1055e-02, -2.2661e-02, -4.1945e-02,\n",
       "        -5.4231e-02, -1.4030e-02, -1.9288e-02, -6.7270e-03,  4.3133e-03,\n",
       "        -5.0349e-02,  5.0856e-02,  3.8530e-02,  2.0852e-02,  4.9339e-02,\n",
       "        -1.9208e-02,  3.5886e-02,  1.1789e-02, -2.3316e-02,  2.9358e-02,\n",
       "        -3.0367e-02,  2.1460e-02, -2.9498e-02, -1.1441e-02,  3.7770e-02,\n",
       "         4.0026e-02, -3.9712e-02, -1.1151e-02, -4.9935e-02, -2.9651e-02,\n",
       "        -1.1969e-02, -1.0445e-02,  1.9312e-02,  5.9869e-02,  4.3904e-02,\n",
       "        -1.9319e-02, -4.9591e-02,  1.4821e-02, -2.2988e-02, -2.5593e-03,\n",
       "         2.1945e-02,  1.1452e-02,  2.5535e-02,  2.5589e-03, -4.1116e-02,\n",
       "        -4.6135e-03,  2.0691e-02, -6.2429e-03,  8.9878e-03,  5.2409e-03,\n",
       "        -3.8400e-02, -7.2674e-03,  5.8039e-04,  1.3122e-02, -3.9467e-02,\n",
       "        -2.0036e-02,  3.9264e-02, -2.0630e-02, -1.7365e-02, -2.7057e-03,\n",
       "         9.6599e-03, -2.2532e-03,  1.6172e-02, -2.0917e-02,  2.0165e-02,\n",
       "        -3.7379e-02,  1.0594e-02, -5.3276e-03,  1.7460e-02,  1.4661e-02,\n",
       "        -1.3612e-03, -1.3143e-02, -3.8006e-03,  4.4998e-02,  2.1867e-02,\n",
       "         3.3483e-02, -3.4989e-03,  1.8276e-02,  9.6856e-03,  1.0981e-02,\n",
       "        -2.9643e-02,  4.7454e-03, -4.4657e-02,  2.6200e-02, -2.2193e-02,\n",
       "        -1.6045e-02, -1.1433e-02, -1.4035e-02,  1.4923e-02, -3.3914e-03,\n",
       "        -8.7830e-03], device='cuda:0')), ('transformer_decoder.layers.0.multihead_attn.out_proj.weight', tensor([[-0.0264, -0.0084,  0.0109,  ..., -0.0427,  0.1266,  0.0344],\n",
       "        [-0.0119,  0.0977, -0.0310,  ..., -0.0671, -0.0113,  0.0943],\n",
       "        [-0.0424, -0.1197,  0.0708,  ...,  0.0140,  0.0529,  0.0096],\n",
       "        ...,\n",
       "        [-0.0667,  0.0559, -0.0101,  ..., -0.0844, -0.0235,  0.0197],\n",
       "        [ 0.0158,  0.0050,  0.0737,  ..., -0.0350, -0.0613, -0.0410],\n",
       "        [ 0.0093,  0.0534, -0.0330,  ..., -0.0644, -0.0587, -0.0672]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.0.multihead_attn.out_proj.bias', tensor([ 2.0904e-02, -3.6296e-02, -7.8835e-03, -5.1018e-03, -2.2020e-02,\n",
       "         1.8243e-02,  2.0913e-03, -3.3842e-02,  2.6335e-02,  9.0636e-03,\n",
       "        -1.5588e-03,  3.0777e-03, -5.7296e-03, -1.8244e-02,  1.6449e-02,\n",
       "        -3.7050e-03, -2.6354e-03, -3.5835e-03,  9.1720e-03,  2.6901e-02,\n",
       "        -2.1391e-02,  1.7155e-03,  8.0978e-03,  5.0808e-03, -8.1524e-03,\n",
       "        -5.3720e-03, -9.1375e-04,  2.8753e-02,  2.8714e-02,  7.4894e-03,\n",
       "        -2.3505e-02,  2.6058e-03, -2.7097e-02, -1.7899e-02, -4.0675e-02,\n",
       "        -1.7815e-02, -9.6137e-04,  9.1175e-03, -1.8800e-03,  1.7129e-02,\n",
       "        -1.7099e-02, -4.9817e-03, -2.2179e-02, -2.5716e-03, -4.6505e-02,\n",
       "        -1.4379e-03, -1.8797e-02,  7.4819e-03, -1.9169e-02,  3.2904e-03,\n",
       "        -7.3656e-03,  3.7000e-03,  2.4859e-03, -6.6691e-05, -5.6468e-03,\n",
       "         4.1991e-02, -3.5084e-02,  1.1769e-03,  2.1795e-02,  2.1057e-02,\n",
       "         2.5820e-02,  1.8087e-02,  1.5780e-02,  3.4255e-02, -4.2019e-02,\n",
       "        -2.0092e-03, -3.3550e-02, -7.3025e-05, -1.6785e-02, -3.0603e-04,\n",
       "         8.4711e-03,  3.7302e-02, -1.1655e-02, -1.6676e-02, -1.0991e-02,\n",
       "         2.4692e-02,  1.2275e-03,  5.0395e-03, -8.7636e-03,  1.6138e-02,\n",
       "         1.4094e-02,  5.4869e-03, -2.3130e-02,  3.3993e-02, -4.6707e-03,\n",
       "         3.9233e-02, -1.9759e-02,  8.0727e-02, -2.6531e-02, -2.6402e-02,\n",
       "        -4.5838e-03,  1.3373e-02, -2.8444e-03,  1.9404e-02,  1.1335e-02,\n",
       "         3.7114e-02,  3.7549e-03,  1.2272e-02,  5.1075e-03,  6.8545e-03,\n",
       "        -6.1033e-03,  2.2125e-03, -9.9100e-03,  1.5353e-02, -4.2213e-02,\n",
       "         2.4608e-02,  2.4468e-02,  2.6330e-02, -2.0711e-02,  2.1468e-02,\n",
       "         2.0510e-02, -7.7880e-03,  1.6115e-02, -1.7265e-03, -3.0733e-02,\n",
       "         2.7025e-02,  4.3766e-03,  2.2566e-02, -4.3188e-03, -6.6172e-03,\n",
       "         5.5764e-03, -2.6051e-03,  1.9897e-02,  3.6237e-02, -1.8636e-02,\n",
       "         2.6804e-02, -4.2881e-03,  1.0497e-02,  9.7343e-03,  4.3110e-02,\n",
       "        -2.0788e-04,  2.7730e-02,  3.3249e-04,  4.4489e-03,  3.2401e-03,\n",
       "         1.5728e-02, -1.3369e-02, -5.4831e-03, -4.5281e-03, -1.8961e-03,\n",
       "        -2.5931e-02,  3.2226e-02, -2.3925e-02,  8.3698e-03, -2.1098e-02,\n",
       "        -9.1900e-04,  4.9404e-03,  1.7156e-02,  1.2565e-02, -2.6390e-02,\n",
       "        -2.3665e-02,  3.1074e-02, -1.7944e-02, -1.3680e-02, -4.7381e-02,\n",
       "        -9.9717e-03,  1.9179e-02,  2.7189e-02, -2.1728e-03,  1.9534e-02,\n",
       "        -3.2275e-02, -3.0420e-02, -4.7778e-03,  2.3953e-02, -1.6428e-02,\n",
       "         2.1846e-02,  1.9485e-02,  3.5273e-02,  4.5470e-04,  1.6808e-02,\n",
       "        -2.8650e-02,  8.0416e-03, -2.3454e-02,  4.0284e-02,  9.8438e-03,\n",
       "        -2.9774e-02, -1.6604e-02,  4.0165e-02, -8.4055e-03, -4.4613e-03,\n",
       "         8.2839e-03, -3.1439e-02,  5.1451e-03, -5.2206e-03,  5.6546e-03,\n",
       "        -2.2619e-03, -1.6286e-02, -1.0356e-02, -3.1248e-02,  1.7470e-02,\n",
       "        -2.0780e-02, -5.5476e-03], device='cuda:0')), ('transformer_decoder.layers.0.linear1.weight', tensor([[ 0.0504,  0.0055, -0.0186,  ...,  0.0315, -0.0197,  0.0049],\n",
       "        [-0.0415, -0.0060, -0.0021,  ...,  0.0308, -0.0030,  0.0122],\n",
       "        [ 0.0020,  0.0323,  0.0387,  ..., -0.0270, -0.0628, -0.0952],\n",
       "        ...,\n",
       "        [-0.0364, -0.0565, -0.0524,  ...,  0.0619, -0.0237, -0.0261],\n",
       "        [-0.0203,  0.0205,  0.0206,  ...,  0.0488,  0.0131, -0.0311],\n",
       "        [-0.0199, -0.0565,  0.0026,  ...,  0.0409, -0.0237,  0.0592]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.0.linear1.bias', tensor([-0.0242, -0.0738, -0.0703,  ..., -0.0637, -0.0254, -0.1045],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.0.linear2.weight', tensor([[ 0.0407, -0.0163, -0.0402,  ...,  0.0033, -0.0159, -0.0044],\n",
       "        [ 0.0535, -0.0424,  0.0337,  ..., -0.0392,  0.0355,  0.0015],\n",
       "        [ 0.0340, -0.0130,  0.0208,  ..., -0.0171,  0.0216, -0.0292],\n",
       "        ...,\n",
       "        [ 0.0120,  0.0138, -0.0165,  ...,  0.0191, -0.0421, -0.0044],\n",
       "        [ 0.0430, -0.0357,  0.0194,  ...,  0.0337, -0.0402,  0.0631],\n",
       "        [ 0.0117,  0.0087,  0.0234,  ...,  0.0453, -0.0381, -0.0415]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.0.linear2.bias', tensor([-0.0593,  0.0648,  0.0023,  0.0535,  0.0226,  0.0122,  0.0188,  0.0426,\n",
       "        -0.0361, -0.0361,  0.0128,  0.0045, -0.0443,  0.0586, -0.0031,  0.0337,\n",
       "         0.0360,  0.0098, -0.0133, -0.0164,  0.0541,  0.0435,  0.0094,  0.0255,\n",
       "         0.0196,  0.0554, -0.0191, -0.0200, -0.0528,  0.0335,  0.0294, -0.0343,\n",
       "        -0.0021,  0.0031,  0.0313,  0.0388, -0.0150,  0.0062,  0.0072, -0.0646,\n",
       "         0.0396,  0.0384, -0.0321,  0.0113,  0.0357, -0.0401,  0.0092,  0.0107,\n",
       "         0.0265, -0.0070, -0.0185,  0.0216,  0.0243, -0.0265,  0.0465, -0.0569,\n",
       "         0.0457,  0.0141, -0.0238, -0.0367, -0.0237, -0.0651, -0.0339, -0.0417,\n",
       "         0.0720,  0.0034,  0.0097, -0.0270, -0.0034, -0.0080, -0.0257, -0.0237,\n",
       "         0.0390,  0.0051,  0.0313, -0.0394,  0.0031, -0.0124,  0.0261, -0.0414,\n",
       "         0.0210, -0.0075, -0.0165, -0.0097,  0.0019, -0.0256,  0.0557, -0.0994,\n",
       "         0.0632,  0.0436,  0.0091,  0.0008,  0.0108, -0.0382, -0.0076, -0.0345,\n",
       "        -0.0041, -0.0655, -0.0157,  0.0029,  0.0295,  0.0089, -0.0063, -0.0376,\n",
       "         0.0347, -0.0009,  0.0025, -0.0151,  0.0502, -0.0274, -0.0101, -0.0190,\n",
       "        -0.0305,  0.0292,  0.0388, -0.0833,  0.0431, -0.0566,  0.0625, -0.0125,\n",
       "        -0.0343, -0.0196, -0.0432, -0.0851,  0.0098, -0.0447,  0.0360, -0.0172,\n",
       "         0.0253, -0.0719,  0.0321, -0.0618,  0.0097, -0.0004,  0.0162,  0.0122,\n",
       "        -0.0092, -0.0200, -0.0183, -0.0253,  0.0440, -0.0472,  0.0652, -0.0365,\n",
       "         0.0265, -0.0083, -0.0130, -0.0326, -0.0118,  0.0450,  0.0297, -0.0418,\n",
       "         0.0632, -0.0308,  0.0790,  0.0477,  0.0165, -0.0370,  0.0019, -0.0569,\n",
       "         0.0397,  0.0545, -0.0142, -0.0424,  0.0241, -0.0529,  0.0214, -0.0698,\n",
       "        -0.0014, -0.0665,  0.0320, -0.0298,  0.0085, -0.0479, -0.0221,  0.0115,\n",
       "         0.0378, -0.0738,  0.0567, -0.0145,  0.0060, -0.0011, -0.0271,  0.0269,\n",
       "         0.0256, -0.0158, -0.0002,  0.0308,  0.0350, -0.0646,  0.0467,  0.0217],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.0.norm1.weight', tensor([1.0122, 1.0732, 1.0125, 1.0210, 1.0419, 1.0138, 0.9997, 0.9772, 0.9951,\n",
       "        1.0300, 0.9524, 1.0194, 0.9656, 1.0051, 0.9797, 1.0167, 1.0122, 0.9929,\n",
       "        0.9762, 0.9869, 1.0062, 1.0185, 1.0091, 1.0150, 0.9800, 1.0136, 0.9989,\n",
       "        0.9809, 1.0030, 0.9640, 0.9693, 0.9960, 0.9668, 1.0201, 0.9832, 0.9945,\n",
       "        0.9349, 0.9979, 0.9513, 1.0317, 0.9487, 1.0099, 0.9532, 1.0094, 0.9604,\n",
       "        0.9876, 0.9999, 0.9870, 0.9991, 0.9716, 0.9971, 0.9631, 1.0068, 0.9360,\n",
       "        1.0292, 0.9317, 1.0063, 0.9248, 1.0179, 0.9477, 1.0142, 0.9318, 1.0214,\n",
       "        0.9137, 1.0768, 0.9036, 1.0288, 0.8940, 1.0545, 0.8833, 1.0464, 0.9185,\n",
       "        1.0753, 0.9014, 1.0653, 0.9105, 1.0339, 0.9169, 1.0686, 0.9421, 1.0594,\n",
       "        0.9258, 0.9851, 0.9194, 1.0410, 0.9125, 1.0941, 0.9806, 1.0655, 0.8837,\n",
       "        1.0784, 0.9110, 1.0630, 0.9186, 1.0332, 0.9188, 1.0714, 0.8587, 1.0477,\n",
       "        0.8790, 1.0546, 0.9161, 1.0712, 0.8889, 1.0803, 0.9000, 1.0678, 0.9159,\n",
       "        1.0430, 0.8937, 1.0413, 0.9287, 1.0302, 0.8803, 1.0467, 0.9223, 1.0748,\n",
       "        0.9033, 1.0590, 0.9242, 1.0510, 0.9030, 1.1041, 0.9772, 1.0555, 0.9036,\n",
       "        1.0430, 0.9185, 1.0606, 0.9328, 1.0745, 0.8873, 1.0444, 0.9406, 1.0735,\n",
       "        0.9098, 1.0662, 0.9133, 1.0484, 0.9219, 1.0408, 0.9180, 1.0523, 0.9104,\n",
       "        1.0890, 0.9043, 1.0655, 0.9031, 1.0411, 0.8859, 1.0664, 0.9345, 1.0536,\n",
       "        0.9042, 1.0687, 0.9107, 1.0676, 0.9206, 1.0770, 0.9249, 1.0646, 0.9140,\n",
       "        1.0554, 0.9444, 1.0579, 0.8974, 1.0733, 0.9318, 1.0696, 0.9192, 1.0699,\n",
       "        0.9183, 1.0461, 0.8980, 1.0579, 0.9057, 1.0620, 0.9138, 1.0648, 0.9078,\n",
       "        1.0314, 0.8800, 1.0751, 0.8980, 1.0852, 0.9375, 1.0621, 0.9114, 1.0517,\n",
       "        0.9108, 1.0575, 0.8997], device='cuda:0')), ('transformer_decoder.layers.0.norm1.bias', tensor([ 0.1107, -0.1105,  0.0496, -0.0711, -0.0341, -0.0068, -0.0040, -0.0071,\n",
       "         0.1108,  0.0745, -0.0282,  0.0257, -0.0214, -0.0482,  0.0447, -0.0122,\n",
       "        -0.0516,  0.0527,  0.0271,  0.1116, -0.0979, -0.0502, -0.0666, -0.0212,\n",
       "        -0.0298,  0.0120,  0.0105, -0.0026,  0.1012, -0.0616, -0.0766, -0.0177,\n",
       "        -0.0647, -0.0232, -0.1045, -0.1019, -0.0128, -0.0210,  0.0015,  0.0742,\n",
       "        -0.1152, -0.0361, -0.0178, -0.0401, -0.1391,  0.0491,  0.0402,  0.0449,\n",
       "        -0.0142, -0.0738,  0.0123, -0.0344, -0.0853,  0.0185, -0.0318,  0.1416,\n",
       "        -0.0769,  0.0086,  0.0450,  0.0627,  0.0608,  0.0846,  0.0451,  0.0763,\n",
       "        -0.1909, -0.0391, -0.0807,  0.0162, -0.0203, -0.0602,  0.0529,  0.0860,\n",
       "        -0.0598, -0.0744, -0.0359,  0.0775, -0.0142,  0.0135, -0.0017,  0.0920,\n",
       "         0.0179, -0.0025,  0.0311,  0.1181, -0.0474,  0.0281, -0.1158,  0.2363,\n",
       "        -0.1158, -0.0379, -0.0127,  0.0199,  0.0235,  0.1015,  0.1062,  0.1071,\n",
       "         0.0157,  0.0700,  0.0134, -0.0070, -0.0442, -0.0338, -0.0091,  0.0182,\n",
       "        -0.1253,  0.0119,  0.0025,  0.0746, -0.0627,  0.0907,  0.0853,  0.0460,\n",
       "         0.0127, -0.0586, -0.0785,  0.0717, -0.0135,  0.1364, -0.0514, -0.0420,\n",
       "         0.0746,  0.0532,  0.0724,  0.0705,  0.0064,  0.0954, -0.0350, -0.0228,\n",
       "        -0.0019,  0.1074, -0.0501,  0.1210, -0.0309, -0.0090,  0.0117,  0.0397,\n",
       "        -0.0191,  0.0781,  0.0157, -0.0224, -0.0531,  0.1213, -0.0753,  0.0318,\n",
       "        -0.0489, -0.0286, -0.0240,  0.0443,  0.0576, -0.0560, -0.0525,  0.0670,\n",
       "        -0.0253,  0.0133, -0.1166, -0.0552,  0.0496,  0.0752,  0.0044,  0.0562,\n",
       "        -0.0612, -0.0961,  0.0582,  0.1190, -0.0170,  0.0406, -0.0037,  0.0483,\n",
       "        -0.0307,  0.0424, -0.0927,  0.0434, -0.0154,  0.0824,  0.0781, -0.0372,\n",
       "        -0.0501,  0.0865, -0.0628,  0.0427, -0.0351, -0.0664,  0.0587, -0.0522,\n",
       "        -0.0056,  0.0581,  0.0198, -0.0723, -0.1109,  0.0646, -0.0722,  0.0223],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.0.norm2.weight', tensor([1.0179, 1.0780, 1.0126, 1.0245, 1.0368, 1.0148, 1.0004, 0.9973, 0.9954,\n",
       "        1.0242, 0.9610, 1.0176, 0.9661, 1.0038, 0.9771, 1.0069, 1.0138, 0.9862,\n",
       "        0.9822, 0.9989, 1.0134, 1.0158, 1.0164, 1.0063, 0.9849, 1.0131, 0.9946,\n",
       "        0.9769, 1.0073, 0.9663, 0.9743, 1.0026, 0.9754, 1.0182, 1.0050, 1.0075,\n",
       "        0.9494, 0.9891, 0.9623, 1.0261, 0.9676, 1.0208, 0.9640, 1.0114, 0.9900,\n",
       "        0.9900, 1.0026, 0.9848, 0.9980, 0.9749, 1.0175, 0.9707, 1.0124, 0.9466,\n",
       "        1.0244, 0.9471, 1.0200, 0.9237, 1.0246, 0.9495, 1.0107, 0.9368, 1.0245,\n",
       "        0.9377, 1.0849, 0.9113, 1.0276, 0.9026, 1.0566, 0.9028, 1.0459, 0.9296,\n",
       "        1.0689, 0.9119, 1.0572, 0.9257, 1.0365, 0.9196, 1.0682, 0.9518, 1.0529,\n",
       "        0.9270, 0.9998, 0.9432, 1.0373, 0.9161, 1.0907, 1.0134, 1.0677, 0.8848,\n",
       "        1.0799, 0.8987, 1.0636, 0.9392, 1.0497, 0.9317, 1.0644, 0.9099, 1.0361,\n",
       "        0.9083, 1.0636, 0.9178, 1.0551, 0.9057, 1.0758, 0.9163, 1.0595, 0.9243,\n",
       "        1.0533, 0.9081, 1.0497, 0.9409, 1.0353, 0.9191, 1.0395, 0.9340, 1.0625,\n",
       "        0.9380, 1.0580, 0.9292, 1.0476, 0.9215, 1.0977, 0.9766, 1.0637, 0.9124,\n",
       "        1.0480, 0.9320, 1.0593, 0.9379, 1.0677, 0.9058, 1.0523, 0.9471, 1.0738,\n",
       "        0.9203, 1.0599, 0.9117, 1.0487, 0.9261, 1.0460, 0.9576, 1.0513, 0.9157,\n",
       "        1.0760, 0.9118, 1.0646, 0.9294, 1.0426, 0.9058, 1.0636, 0.9399, 1.0513,\n",
       "        0.9161, 1.0795, 0.9241, 1.0698, 0.9350, 1.0667, 0.9393, 1.0637, 0.9291,\n",
       "        1.0588, 0.9559, 1.0590, 0.9056, 1.0649, 0.9282, 1.0616, 0.9335, 1.0678,\n",
       "        0.9228, 1.0520, 0.9031, 1.0559, 0.9199, 1.0595, 0.9272, 1.0650, 0.9128,\n",
       "        1.0262, 0.9000, 1.0648, 0.8981, 1.0777, 0.9428, 1.0665, 0.9076, 1.0513,\n",
       "        0.9087, 1.0690, 0.9085], device='cuda:0')), ('transformer_decoder.layers.0.norm2.bias', tensor([ 0.1014, -0.1061,  0.0455, -0.0666, -0.0225, -0.0088, -0.0059, -0.0009,\n",
       "         0.0996,  0.0780, -0.0276,  0.0248, -0.0255, -0.0378,  0.0368, -0.0152,\n",
       "        -0.0538,  0.0463,  0.0192,  0.1225, -0.0884, -0.0507, -0.0788, -0.0237,\n",
       "        -0.0378,  0.0237,  0.0039, -0.0089,  0.0932, -0.0682, -0.0835, -0.0252,\n",
       "        -0.0596, -0.0267, -0.1022, -0.1000, -0.0265, -0.0375, -0.0025,  0.0681,\n",
       "        -0.1205, -0.0338, -0.0247, -0.0453, -0.1385,  0.0407,  0.0401,  0.0434,\n",
       "        -0.0108, -0.0830,  0.0135, -0.0395, -0.0824,  0.0023, -0.0366,  0.1196,\n",
       "        -0.0691,  0.0036,  0.0386,  0.0525,  0.0614,  0.0708,  0.0419,  0.0557,\n",
       "        -0.1815, -0.0453, -0.0672,  0.0109, -0.0235, -0.0705,  0.0541,  0.0686,\n",
       "        -0.0597, -0.0829, -0.0309,  0.0649, -0.0150,  0.0047,  0.0010,  0.0715,\n",
       "         0.0136, -0.0232,  0.0495,  0.1002, -0.0482,  0.0010, -0.1133,  0.2212,\n",
       "        -0.1045, -0.0366, -0.0113, -0.0070,  0.0272,  0.0853,  0.1088,  0.0785,\n",
       "         0.0104,  0.0586,  0.0203, -0.0089, -0.0409, -0.0498, -0.0135,  0.0030,\n",
       "        -0.1149, -0.0031, -0.0124,  0.0541, -0.0558,  0.0746,  0.0801,  0.0359,\n",
       "         0.0117, -0.0725, -0.0714,  0.0500, -0.0162,  0.1242, -0.0445, -0.0558,\n",
       "         0.0707,  0.0431,  0.0680,  0.0546,  0.0152,  0.0749, -0.0323, -0.0346,\n",
       "        -0.0044,  0.0859, -0.0531,  0.1042, -0.0277, -0.0171,  0.0126,  0.0321,\n",
       "        -0.0116,  0.0734,  0.0210, -0.0457, -0.0493,  0.0997, -0.0695,  0.0197,\n",
       "        -0.0376, -0.0389, -0.0258,  0.0323,  0.0549, -0.0537, -0.0480,  0.0431,\n",
       "        -0.0185,  0.0071, -0.1089, -0.0722,  0.0471,  0.0525,  0.0004,  0.0380,\n",
       "        -0.0500, -0.0884,  0.0599,  0.1011, -0.0150,  0.0241, -0.0125,  0.0295,\n",
       "        -0.0248,  0.0204, -0.0919,  0.0168, -0.0124,  0.0682,  0.0804, -0.0443,\n",
       "        -0.0452,  0.0596, -0.0648,  0.0405, -0.0365, -0.0617,  0.0548, -0.0661,\n",
       "        -0.0099,  0.0466,  0.0256, -0.0793, -0.1022,  0.0429, -0.0657,  0.0170],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.0.norm3.weight', tensor([0.9704, 0.9299, 0.9906, 0.9871, 0.9566, 1.0009, 0.9909, 0.9906, 0.9556,\n",
       "        0.9729, 0.9873, 0.9965, 0.9713, 1.0177, 0.9836, 1.0138, 0.9997, 1.0266,\n",
       "        0.9871, 0.9951, 1.0052, 0.9767, 1.0150, 1.0148, 0.9912, 0.9958, 0.9466,\n",
       "        0.9665, 0.9432, 0.9599, 1.0083, 0.9962, 0.9882, 1.0278, 0.9524, 1.0219,\n",
       "        0.9347, 1.0097, 1.0020, 1.0014, 1.0170, 1.0301, 0.9876, 1.0356, 0.9579,\n",
       "        1.0341, 1.0085, 0.9933, 1.0325, 0.9722, 0.9999, 1.0307, 1.0152, 0.9656,\n",
       "        1.0010, 0.9552, 1.0033, 0.9582, 1.0234, 0.9963, 0.9959, 0.9948, 1.0433,\n",
       "        0.9546, 0.9508, 0.9521, 1.0146, 0.9707, 1.0278, 0.9685, 1.0417, 0.9564,\n",
       "        1.0150, 1.0045, 1.0417, 0.9766, 1.0236, 1.0021, 1.0576, 0.9780, 1.0302,\n",
       "        0.9388, 0.9841, 0.9510, 1.0077, 1.0176, 1.0340, 0.8882, 0.9906, 0.9648,\n",
       "        1.0379, 0.9292, 1.0169, 0.9412, 1.0340, 0.9455, 1.0523, 0.9684, 1.0751,\n",
       "        0.9692, 1.0397, 0.9625, 1.0200, 0.9849, 1.0261, 0.9567, 1.0339, 0.9725,\n",
       "        0.9883, 0.9726, 1.0254, 0.9565, 0.9767, 0.9881, 0.9972, 0.9585, 1.0063,\n",
       "        0.9301, 1.0600, 0.9656, 1.0346, 0.9806, 1.0373, 0.9476, 1.0638, 0.9389,\n",
       "        1.0426, 0.9996, 1.0355, 0.9510, 1.0236, 0.9602, 0.9650, 1.0166, 1.0684,\n",
       "        0.9755, 1.0366, 0.9692, 1.0366, 0.9113, 0.9994, 0.9517, 1.0284, 0.9968,\n",
       "        1.0168, 0.9740, 1.0417, 0.9682, 1.0064, 0.9483, 1.0214, 0.8978, 1.0285,\n",
       "        1.0042, 0.9877, 0.9764, 1.0640, 0.9491, 1.0285, 0.9888, 1.0234, 0.9234,\n",
       "        1.0143, 0.9336, 1.0299, 0.9573, 1.0374, 0.9343, 1.0366, 0.9737, 1.0612,\n",
       "        0.9878, 1.0303, 0.9684, 1.0386, 0.9614, 1.0201, 0.9445, 1.0575, 0.9753,\n",
       "        0.9903, 0.9470, 1.0381, 0.9586, 1.0582, 1.0133, 1.0631, 0.9656, 0.9376,\n",
       "        0.9516, 1.0466, 0.9843], device='cuda:0')), ('transformer_decoder.layers.0.norm3.bias', tensor([ 0.0529, -0.0911,  0.0329, -0.0132,  0.0664, -0.0029,  0.0616,  0.0147,\n",
       "         0.0431,  0.1139,  0.0084,  0.0243,  0.1082, -0.0237,  0.0654, -0.0247,\n",
       "        -0.0440,  0.0400,  0.0214,  0.0937, -0.0573, -0.0013, -0.0126,  0.0333,\n",
       "        -0.0606,  0.0376,  0.0162,  0.0690,  0.0361, -0.0089, -0.0672,  0.0823,\n",
       "        -0.0204, -0.0596, -0.0441, -0.0544, -0.0791, -0.0370, -0.0289,  0.0339,\n",
       "        -0.0481, -0.0240,  0.0173, -0.0358, -0.0630,  0.0040,  0.0222, -0.0208,\n",
       "        -0.0569, -0.0605,  0.0126, -0.0439, -0.0294, -0.0367, -0.0366,  0.0320,\n",
       "        -0.0375, -0.0785,  0.0285,  0.0224,  0.0989, -0.0199,  0.0328,  0.0051,\n",
       "        -0.0123, -0.0303, -0.0282, -0.0178,  0.0178, -0.0466,  0.0882,  0.0036,\n",
       "         0.0284, -0.0623, -0.0882, -0.0007,  0.0608, -0.0239,  0.0135, -0.0408,\n",
       "         0.0091, -0.0628,  0.0785,  0.0049, -0.0107, -0.0059, -0.0565,  0.0932,\n",
       "        -0.0017, -0.0661, -0.0071, -0.0885,  0.0305,  0.0094,  0.0466, -0.0492,\n",
       "         0.0611,  0.0378,  0.0952, -0.0158,  0.0466, -0.0963,  0.0065,  0.0155,\n",
       "        -0.0525, -0.0753,  0.0405, -0.0970,  0.0085, -0.0202,  0.0352, -0.0183,\n",
       "         0.1410, -0.0673,  0.0349, -0.0435,  0.0050,  0.0497,  0.0345, -0.0938,\n",
       "         0.0698,  0.0010,  0.1195,  0.0386,  0.0402, -0.0186,  0.0223, -0.0609,\n",
       "         0.0132,  0.0059, -0.0640,  0.0218,  0.1428, -0.0804,  0.0660, -0.0976,\n",
       "        -0.0011, -0.0046,  0.1008, -0.1065,  0.0060, -0.0158, -0.0553, -0.0149,\n",
       "         0.0440, -0.0690,  0.0309, -0.0206,  0.0804, -0.0607, -0.0064, -0.0962,\n",
       "        -0.0244,  0.0118, -0.0059, -0.1390,  0.0514,  0.0225,  0.0490,  0.0075,\n",
       "         0.0084, -0.0225,  0.0754, -0.0261, -0.0165,  0.0044,  0.0245, -0.0490,\n",
       "        -0.0124,  0.0130, -0.0293, -0.0210,  0.0605, -0.0185,  0.1439, -0.1134,\n",
       "         0.0602, -0.0202, -0.0148,  0.0211,  0.0202, -0.0560,  0.0824, -0.0446,\n",
       "         0.0396, -0.0311,  0.0298, -0.0469, -0.0192, -0.0154, -0.0183, -0.0422],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.self_attn.in_proj_weight', tensor([[-0.1119,  0.0588,  0.0002,  ...,  0.0133, -0.0133,  0.0116],\n",
       "        [ 0.0301, -0.0270, -0.1334,  ..., -0.0421,  0.0298, -0.0486],\n",
       "        [-0.0188,  0.0825, -0.0291,  ..., -0.1244, -0.0764, -0.0075],\n",
       "        ...,\n",
       "        [ 0.0014,  0.0188,  0.0348,  ..., -0.0706,  0.0439,  0.0133],\n",
       "        [-0.0917,  0.0005,  0.0726,  ...,  0.0730,  0.0314,  0.0048],\n",
       "        [-0.1028, -0.0489,  0.1067,  ..., -0.0096, -0.0822,  0.0110]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.self_attn.in_proj_bias', tensor([-4.6883e-02, -1.7689e-02, -3.5032e-02,  1.9831e-02, -4.0250e-03,\n",
       "         6.4847e-02,  4.4583e-02, -1.7099e-03, -1.2833e-02,  1.2622e-03,\n",
       "        -2.2965e-02, -1.9850e-02,  2.0853e-03, -2.4800e-02, -6.0025e-02,\n",
       "        -4.0198e-03,  6.5970e-02, -1.9065e-03, -5.2621e-02, -5.6490e-02,\n",
       "         9.1652e-02,  3.0203e-02, -5.5018e-03,  3.0497e-02, -6.4178e-02,\n",
       "         8.2146e-02,  3.5095e-02,  3.9055e-03,  3.0006e-02, -5.3455e-02,\n",
       "         7.8429e-02,  2.2789e-02, -3.7786e-03, -6.5885e-02,  6.2286e-02,\n",
       "         5.3171e-02, -3.7818e-02,  3.8454e-02, -1.0112e-01, -2.0054e-02,\n",
       "         4.3922e-02,  4.9698e-03, -6.7393e-03, -3.9034e-02, -1.1273e-03,\n",
       "         7.6299e-02, -3.0213e-02, -4.7463e-03, -2.6794e-02,  2.8705e-02,\n",
       "         6.7507e-02, -3.5129e-02, -3.1392e-02, -1.6337e-02, -2.5238e-02,\n",
       "         1.0285e-01, -1.3067e-02, -9.6286e-03,  1.6271e-02,  5.8257e-02,\n",
       "        -1.0560e-02,  9.2034e-02, -2.2250e-02, -9.0629e-02, -3.8578e-02,\n",
       "        -1.4965e-02,  2.8649e-02,  6.5088e-02, -5.0830e-02,  9.4831e-02,\n",
       "        -5.7366e-02,  4.7760e-02, -7.0443e-02, -8.0418e-02,  2.1831e-07,\n",
       "        -1.0751e-02,  1.0435e-01,  4.5741e-02, -8.8505e-02, -2.7445e-02,\n",
       "         2.2839e-02, -1.5149e-02, -2.7207e-02,  3.4977e-03,  4.9749e-02,\n",
       "        -4.2513e-02, -1.1560e-02,  3.0572e-02, -4.0768e-03, -8.4038e-02,\n",
       "         1.8262e-02,  6.3885e-02, -5.3466e-02,  7.1422e-04,  9.0777e-02,\n",
       "         9.3107e-02,  3.4152e-02,  4.4870e-03, -5.1810e-02,  1.2621e-01,\n",
       "        -3.2467e-02, -3.7477e-02, -6.9751e-02,  4.9383e-02, -5.6180e-02,\n",
       "         5.6727e-02,  1.1718e-02, -2.7198e-03,  2.1034e-02, -6.5690e-02,\n",
       "         1.6238e-03,  7.2895e-02, -1.3576e-02,  2.0290e-02,  4.0003e-02,\n",
       "        -1.6992e-02,  3.6560e-02,  6.2649e-02,  5.2250e-02, -8.7838e-02,\n",
       "        -2.9428e-02, -3.6050e-02, -3.2043e-02, -5.7541e-02, -3.6915e-03,\n",
       "         1.8416e-02, -4.0111e-02, -3.0585e-03,  8.1765e-02, -6.9614e-03,\n",
       "         3.0550e-02,  7.6814e-02, -2.5128e-03,  3.5678e-03, -7.4245e-03,\n",
       "         4.9970e-02,  2.0363e-02,  7.4293e-02, -3.9016e-02, -6.8782e-02,\n",
       "        -1.9240e-02, -4.9059e-02,  2.3087e-02, -7.5147e-02, -9.5646e-03,\n",
       "        -6.2987e-02, -4.3627e-02,  1.5153e-02, -6.0074e-02, -8.8119e-02,\n",
       "         4.4028e-02, -3.2256e-02,  2.4366e-02,  4.6890e-03, -1.5686e-02,\n",
       "         7.6131e-02, -7.9720e-02,  6.8249e-02, -5.9612e-02, -5.6961e-02,\n",
       "         4.0447e-02, -5.4531e-02,  1.1257e-02, -6.4836e-02,  3.2665e-02,\n",
       "        -1.1279e-02, -6.8678e-02,  8.1423e-02,  6.4479e-03,  8.7029e-02,\n",
       "         6.6353e-03, -4.0897e-02, -4.7400e-02, -2.1320e-02, -9.2970e-03,\n",
       "         1.2130e-02, -4.1210e-02,  5.4055e-02,  1.6114e-02,  4.8390e-02,\n",
       "         6.8868e-02,  7.2520e-02, -7.9469e-02,  8.9908e-02, -2.6710e-02,\n",
       "        -2.5450e-02, -4.7421e-02,  9.1955e-02,  4.6766e-02, -5.6362e-02,\n",
       "        -5.1963e-02, -9.0686e-02,  6.7066e-07, -6.8542e-06, -1.0412e-05,\n",
       "         1.8717e-05,  4.9458e-06,  1.5089e-05,  3.6870e-06, -7.0318e-06,\n",
       "         8.5687e-06, -1.4225e-05, -2.8814e-06, -8.9961e-07, -1.9802e-05,\n",
       "        -2.2285e-06, -9.2259e-06,  1.2833e-05, -4.3311e-07, -4.9876e-06,\n",
       "         1.2974e-05, -1.2378e-05,  4.4406e-06,  8.1023e-06, -1.6453e-05,\n",
       "         8.8154e-06, -2.1751e-06,  1.6634e-06,  5.0101e-07,  1.4763e-05,\n",
       "        -8.9392e-06, -1.1927e-05,  7.3410e-07, -1.8079e-06, -1.0112e-06,\n",
       "         2.1312e-06, -1.3294e-06,  6.4454e-06,  1.5292e-05, -2.2782e-06,\n",
       "         1.4620e-05,  2.3917e-06,  3.5869e-06,  5.1180e-06,  1.4277e-05,\n",
       "         1.6190e-06,  9.3059e-06,  3.4910e-06,  1.3219e-05, -8.7786e-06,\n",
       "        -8.9638e-06,  3.2758e-05, -5.6812e-06,  1.2096e-05, -1.8322e-06,\n",
       "         1.1415e-05, -5.2610e-06, -9.1960e-06,  2.4595e-06,  5.8087e-06,\n",
       "        -1.4308e-05, -7.9415e-06, -8.2228e-06, -3.2715e-05, -1.0647e-05,\n",
       "         8.8445e-07, -4.0231e-06,  2.3951e-06, -4.1686e-06,  2.3579e-05,\n",
       "        -1.4601e-06, -2.3998e-05, -1.1285e-05, -6.9366e-06,  2.5404e-06,\n",
       "        -1.5187e-05,  5.0074e-07,  7.5442e-06, -2.2652e-06, -2.2262e-05,\n",
       "         6.0181e-07,  1.2068e-05,  2.6521e-06, -6.1183e-06,  1.9119e-05,\n",
       "         4.4352e-06, -1.0421e-05,  2.3038e-06, -5.9336e-06,  6.2893e-06,\n",
       "        -5.2309e-06,  9.0303e-06,  4.5187e-06,  8.7036e-06, -1.2103e-06,\n",
       "        -7.0735e-06, -1.0518e-05,  1.6272e-05, -1.2516e-05,  4.7558e-06,\n",
       "         1.0142e-05,  6.8331e-06, -1.1170e-05,  7.9071e-06,  8.7836e-06,\n",
       "        -4.0817e-06,  9.5960e-06, -1.0453e-05,  1.0371e-05,  5.9365e-07,\n",
       "        -8.8530e-06, -8.3707e-06,  2.0282e-07,  1.5774e-05, -1.5736e-06,\n",
       "        -5.3639e-06,  1.4631e-05, -9.6260e-07, -1.7075e-05, -5.5270e-06,\n",
       "        -1.3181e-05,  4.0289e-06,  8.6837e-06,  1.2179e-05,  9.3846e-06,\n",
       "         6.7348e-06,  1.5191e-05, -3.7660e-06,  7.4114e-06, -1.4243e-06,\n",
       "        -1.2655e-05, -4.4605e-06, -3.9999e-06, -1.1263e-05,  8.2569e-07,\n",
       "         2.6240e-06,  1.5060e-05, -4.3887e-06, -5.5399e-06, -1.1687e-05,\n",
       "         2.3589e-06,  8.1158e-06,  6.9327e-07, -1.2371e-06,  6.4682e-06,\n",
       "        -1.8930e-06, -2.3744e-06, -5.3860e-06, -7.1082e-06, -7.0457e-06,\n",
       "        -1.2718e-05,  1.5667e-06,  1.3732e-05,  5.2376e-07,  2.6724e-06,\n",
       "         2.7801e-06, -1.3938e-05, -6.9093e-06,  6.9195e-06,  1.4301e-05,\n",
       "         3.2901e-06,  1.3307e-05, -1.8844e-06, -6.1952e-06, -4.8320e-06,\n",
       "        -5.0136e-06,  6.3665e-06,  5.6536e-06,  2.8044e-05, -6.4470e-06,\n",
       "         6.2553e-06,  3.4509e-06,  7.7146e-06,  6.3251e-06, -1.6008e-05,\n",
       "        -2.3275e-05, -8.8323e-07, -1.6839e-05,  1.0590e-05,  7.6439e-06,\n",
       "        -1.8164e-06, -1.0996e-05, -3.3013e-06, -6.5375e-09,  1.1906e-05,\n",
       "         7.7347e-06,  7.0320e-06,  1.2623e-06,  4.8321e-06,  7.8364e-06,\n",
       "        -1.3552e-05, -1.5539e-05, -1.9772e-06, -1.4583e-05, -1.4083e-02,\n",
       "         1.1176e-02,  9.7251e-03,  1.5138e-02, -6.0981e-03,  7.6033e-03,\n",
       "        -2.9974e-02, -1.1989e-02,  8.4238e-03,  1.7924e-02, -1.1342e-02,\n",
       "         1.7498e-02,  1.7233e-02,  2.4611e-02, -3.2326e-03, -6.2816e-03,\n",
       "        -2.0022e-02, -7.6461e-03,  1.8008e-02,  5.6165e-03,  1.1291e-02,\n",
       "         4.6782e-03,  1.9247e-02,  3.8092e-03,  1.0551e-02,  3.8759e-03,\n",
       "         6.4586e-04,  3.2884e-03, -5.4096e-04, -1.0096e-02,  1.2916e-02,\n",
       "        -6.5504e-03,  4.5368e-03, -4.4401e-03,  7.0199e-03,  4.4013e-03,\n",
       "        -1.4619e-02,  1.2791e-02,  1.3249e-02, -2.4694e-02, -4.8855e-03,\n",
       "        -5.3836e-03, -5.8164e-03,  1.1458e-02,  2.7668e-02, -1.4218e-02,\n",
       "         1.2458e-02, -1.6016e-02,  8.8222e-03,  7.5653e-04, -8.6830e-04,\n",
       "         1.1913e-02, -9.5163e-03, -1.2947e-02,  6.9819e-03, -1.8076e-02,\n",
       "         7.1307e-03, -2.3290e-02,  1.6420e-02, -5.2034e-03,  1.6884e-02,\n",
       "         1.4874e-02, -1.1817e-02, -4.6706e-03,  3.9306e-02,  1.0370e-02,\n",
       "        -1.2274e-02,  7.6153e-03,  7.2630e-03, -9.8423e-03,  1.7785e-02,\n",
       "         2.0041e-03, -1.4072e-02,  1.3066e-02,  1.2530e-02, -1.0354e-02,\n",
       "         1.3929e-02, -1.8552e-02,  3.0378e-02, -7.1660e-03, -1.0186e-03,\n",
       "         1.0420e-02,  9.9631e-03, -6.0956e-03, -1.2155e-02, -6.5960e-03,\n",
       "         1.4070e-02, -1.5161e-02,  1.6140e-02,  1.2424e-02, -6.8124e-05,\n",
       "         2.1549e-02,  5.4264e-03,  1.8213e-02,  7.1934e-03, -1.9516e-02,\n",
       "         9.9552e-03,  5.3198e-04, -1.3909e-03, -2.4340e-02, -1.0219e-02,\n",
       "         6.9933e-03,  1.3917e-03, -8.6553e-03,  2.0894e-02, -2.3368e-02,\n",
       "        -2.0220e-03, -1.5113e-02, -7.0708e-03, -7.0731e-03, -5.6691e-03,\n",
       "         5.3663e-03,  2.8587e-02, -1.3280e-02,  1.3504e-02, -1.3050e-02,\n",
       "        -5.1631e-03,  1.9800e-03, -8.1878e-03,  1.4707e-02, -1.1270e-02,\n",
       "        -3.1284e-02,  1.2387e-02,  3.2550e-03,  2.0075e-02, -2.2253e-04,\n",
       "         2.4929e-02,  2.5022e-02,  7.6679e-03,  2.1497e-02, -3.5650e-03,\n",
       "        -1.7133e-02, -2.4663e-03,  5.8851e-03,  2.0289e-02,  9.5215e-04,\n",
       "         1.9021e-02,  5.2186e-03,  7.6804e-03,  1.2181e-02, -9.6251e-03,\n",
       "         4.2442e-02,  3.4983e-02,  7.6254e-03,  1.2292e-02, -1.0654e-02,\n",
       "        -2.3302e-02, -5.5196e-03,  6.6391e-03, -6.3755e-03,  2.7376e-02,\n",
       "         1.0261e-02, -1.0865e-02,  6.1418e-03,  1.3693e-02,  7.0305e-03,\n",
       "        -6.9481e-03, -1.5277e-02,  8.0434e-03, -1.8173e-02,  1.3320e-02,\n",
       "         6.0668e-03,  7.3001e-03,  1.1019e-02,  3.6146e-03,  1.2082e-02,\n",
       "        -1.6947e-02, -3.7481e-03, -1.0476e-02,  5.9758e-03, -1.7444e-03,\n",
       "        -2.5558e-02, -1.3555e-02,  1.0794e-02, -5.6015e-03,  2.1191e-02,\n",
       "        -1.1795e-02,  1.5423e-02,  2.2444e-02, -2.8323e-03,  9.9287e-03,\n",
       "         2.6240e-02,  1.9329e-03, -3.3978e-03,  1.5984e-02,  1.4085e-02,\n",
       "        -8.8675e-03, -1.9650e-02,  1.1788e-02, -2.9695e-03, -7.8964e-03,\n",
       "        -5.3159e-04], device='cuda:0')), ('transformer_decoder.layers.1.self_attn.out_proj.weight', tensor([[-0.0008, -0.0805,  0.0672,  ...,  0.1154, -0.0272,  0.0385],\n",
       "        [ 0.0514, -0.0521,  0.0722,  ..., -0.0322, -0.0197, -0.0190],\n",
       "        [ 0.0093,  0.0065,  0.0328,  ...,  0.0313,  0.0241,  0.0342],\n",
       "        ...,\n",
       "        [-0.0304, -0.0854,  0.0255,  ...,  0.0012,  0.0079, -0.0530],\n",
       "        [ 0.0110,  0.0005, -0.0343,  ...,  0.0320, -0.0869,  0.0306],\n",
       "        [ 0.0671, -0.0503, -0.0378,  ..., -0.0256, -0.0091,  0.0425]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.self_attn.out_proj.bias', tensor([ 0.0330, -0.0086,  0.0069, -0.0247,  0.0413,  0.0059,  0.0425,  0.0049,\n",
       "         0.0296,  0.0073, -0.0126,  0.0047,  0.0249, -0.0200,  0.0255, -0.0344,\n",
       "        -0.0136,  0.0036, -0.0006,  0.0256, -0.0090, -0.0240, -0.0387,  0.0024,\n",
       "        -0.0373, -0.0038,  0.0210,  0.0173, -0.0134,  0.0180, -0.0298,  0.0486,\n",
       "         0.0087,  0.0013, -0.0209, -0.0106, -0.0313, -0.0179, -0.0076,  0.0152,\n",
       "        -0.0087, -0.0066,  0.0159, -0.0239,  0.0308, -0.0124,  0.0285, -0.0031,\n",
       "         0.0013,  0.0120,  0.0249, -0.0023,  0.0029,  0.0230, -0.0436,  0.0203,\n",
       "         0.0069, -0.0399, -0.0151, -0.0027,  0.0145,  0.0027, -0.0326,  0.0138,\n",
       "        -0.0405,  0.0280,  0.0150, -0.0249,  0.0024, -0.0131,  0.0456,  0.0098,\n",
       "         0.0092,  0.0217, -0.0280,  0.0013,  0.0143, -0.0158, -0.0063, -0.0307,\n",
       "        -0.0246, -0.0197, -0.0005,  0.0065, -0.0031, -0.0207, -0.0020,  0.0236,\n",
       "         0.0240, -0.0029,  0.0201, -0.0196, -0.0036, -0.0084, -0.0172, -0.0191,\n",
       "         0.0059,  0.0231,  0.0641,  0.0007,  0.0243, -0.0290, -0.0008,  0.0530,\n",
       "        -0.0144,  0.0193, -0.0001, -0.0353, -0.0212,  0.0075, -0.0112, -0.0287,\n",
       "         0.0294, -0.0274,  0.0054, -0.0298,  0.0206,  0.0265,  0.0230, -0.0034,\n",
       "        -0.0035, -0.0109,  0.0283,  0.0058, -0.0089,  0.0193,  0.0105, -0.0088,\n",
       "        -0.0238, -0.0008, -0.0313, -0.0031,  0.0528, -0.0233,  0.0214, -0.0085,\n",
       "        -0.0221,  0.0255,  0.0156, -0.0317, -0.0063,  0.0044, -0.0143, -0.0028,\n",
       "         0.0225, -0.0331, -0.0011, -0.0173,  0.0334, -0.0445, -0.0180, -0.0330,\n",
       "        -0.0080,  0.0131,  0.0252, -0.0228, -0.0057,  0.0147,  0.0099, -0.0004,\n",
       "        -0.0257,  0.0080,  0.0321, -0.0160, -0.0098,  0.0135, -0.0089,  0.0008,\n",
       "        -0.0195,  0.0014,  0.0252, -0.0274, -0.0098,  0.0190,  0.0490, -0.0125,\n",
       "         0.0228,  0.0243,  0.0114,  0.0238, -0.0131,  0.0032,  0.0416,  0.0151,\n",
       "         0.0042, -0.0165, -0.0025,  0.0041, -0.0142,  0.0024, -0.0105, -0.0061],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.multihead_attn.in_proj_weight', tensor([[ 0.0400, -0.0830,  0.1026,  ...,  0.0482, -0.0199, -0.0458],\n",
       "        [-0.1486,  0.0807, -0.0066,  ..., -0.0112, -0.0836,  0.0269],\n",
       "        [-0.0611,  0.0616, -0.1253,  ..., -0.0843, -0.0113,  0.1073],\n",
       "        ...,\n",
       "        [ 0.0686,  0.0005, -0.0231,  ..., -0.0429, -0.0058, -0.0189],\n",
       "        [ 0.0458, -0.0076, -0.0780,  ..., -0.0622,  0.1324, -0.0213],\n",
       "        [ 0.1321, -0.0259,  0.0002,  ...,  0.1245, -0.0017,  0.1072]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.multihead_attn.in_proj_bias', tensor([ 1.5504e-01, -5.6370e-02, -1.1369e-01, -1.3652e-01,  4.3207e-03,\n",
       "         1.6370e-01,  6.3209e-02,  1.5051e-01,  1.3203e-01,  1.8422e-01,\n",
       "        -2.0319e-02, -6.3878e-02,  1.6497e-01,  1.8327e-01, -1.1724e-01,\n",
       "         1.9724e-02, -5.9973e-02, -1.4914e-01,  1.6350e-01, -1.2836e-01,\n",
       "         1.8582e-01, -1.9367e-01, -3.6031e-02,  1.1585e-01,  9.7958e-02,\n",
       "        -1.6164e-01, -8.6266e-02,  9.3083e-02,  2.2463e-02, -1.1063e-01,\n",
       "         4.3902e-03,  1.9732e-01, -5.2724e-02,  1.7754e-01, -8.7357e-03,\n",
       "        -1.6333e-01,  1.6326e-01, -2.0917e-01,  1.5877e-01, -7.8540e-02,\n",
       "        -9.2886e-02, -2.0304e-02, -1.7338e-02, -7.0090e-02, -6.6697e-02,\n",
       "        -9.4168e-02,  6.0382e-02, -1.6986e-01,  1.9997e-02,  7.6481e-02,\n",
       "         4.0379e-02,  2.1728e-02, -1.7251e-01, -6.7962e-02, -9.3912e-02,\n",
       "        -2.2624e-01, -2.0715e-02, -4.2494e-03,  5.2871e-02,  9.5855e-02,\n",
       "         1.2396e-01,  4.4612e-02,  1.3755e-01, -6.1753e-03, -4.1619e-02,\n",
       "        -3.4560e-02,  1.6320e-01, -5.0872e-02,  2.9179e-02, -6.7443e-03,\n",
       "        -5.3601e-02, -1.5044e-01,  2.1788e-02, -2.2430e-02,  9.0122e-02,\n",
       "         1.5626e-02,  7.9398e-02,  6.5898e-02,  1.3770e-01,  1.6014e-02,\n",
       "        -4.9615e-02,  1.0683e-02, -1.2002e-01,  4.0162e-02, -2.5270e-02,\n",
       "        -1.0023e-01,  1.1434e-01,  7.4981e-02,  8.7075e-03,  5.3735e-02,\n",
       "        -5.9318e-02,  4.3582e-02, -1.2041e-01, -5.0116e-02,  9.8981e-02,\n",
       "        -1.0764e-01,  5.4857e-02,  1.7231e-02, -2.5794e-02,  2.0714e-01,\n",
       "         1.1127e-01, -2.2029e-02, -1.4357e-02,  1.6007e-01,  9.1329e-02,\n",
       "        -2.4932e-01, -2.6011e-02,  4.3957e-02,  1.1908e-01,  2.3245e-02,\n",
       "        -1.0138e-01, -2.6802e-02,  1.9162e-02, -4.7787e-02,  1.7835e-01,\n",
       "        -2.5350e-02,  1.3947e-01,  4.5914e-02,  1.6342e-01,  1.1585e-02,\n",
       "        -2.7268e-02, -7.0741e-02, -7.3770e-02, -1.6192e-02,  1.1991e-01,\n",
       "        -9.3042e-02,  7.6398e-02,  9.6625e-04,  1.1429e-01, -5.5349e-02,\n",
       "        -6.4933e-02, -2.1002e-01,  4.3806e-03,  7.9301e-03,  4.4888e-03,\n",
       "         1.1197e-01, -1.0898e-01,  1.6126e-01, -5.6258e-02,  6.8537e-02,\n",
       "        -5.4987e-02,  2.0874e-02,  1.6675e-02, -2.8978e-02,  2.0904e-01,\n",
       "         1.1457e-01,  1.1815e-01,  7.5224e-02,  2.9395e-03,  1.5691e-02,\n",
       "         9.7557e-02, -1.8913e-02,  1.2209e-01, -8.4427e-02, -1.1219e-01,\n",
       "         2.4342e-02,  1.1368e-01, -3.0334e-03,  1.8703e-01,  1.0674e-01,\n",
       "         3.5884e-02,  3.6150e-02, -4.2148e-02,  7.0939e-02, -5.2510e-02,\n",
       "        -1.0394e-01, -6.2265e-02,  2.4612e-02, -1.1659e-01,  9.9583e-02,\n",
       "        -1.2409e-01,  1.2987e-01, -1.0682e-01,  1.2009e-01, -7.3495e-02,\n",
       "         5.7528e-02,  2.3724e-02, -2.0681e-01, -1.9926e-02,  2.1003e-02,\n",
       "        -2.0856e-01, -1.0600e-01,  7.1733e-02,  9.6997e-03, -1.8087e-01,\n",
       "         8.5025e-02, -2.5274e-02,  9.8903e-03, -3.2104e-02,  2.0084e-01,\n",
       "         1.4788e-02, -3.2493e-02, -4.1117e-05,  2.7223e-05,  2.3324e-05,\n",
       "         3.2174e-05,  5.7001e-06,  9.8032e-06, -2.2645e-05, -2.6448e-05,\n",
       "        -2.6261e-05,  1.0807e-05,  1.0529e-05,  1.2598e-06, -2.3210e-05,\n",
       "        -1.0075e-05,  2.1350e-05,  3.2488e-07,  1.1537e-05,  4.0996e-05,\n",
       "        -1.4404e-05,  3.4469e-05, -2.4751e-05,  3.4033e-05,  9.5206e-07,\n",
       "        -2.8565e-05, -8.5411e-06,  2.8874e-05,  2.5878e-05, -7.0027e-06,\n",
       "         1.6861e-05,  2.9996e-05, -8.7277e-06, -1.9519e-05,  9.9292e-06,\n",
       "        -2.9802e-05,  9.2801e-06,  2.9021e-05,  7.6878e-06,  3.6465e-05,\n",
       "        -2.3759e-05,  1.7893e-05,  2.3316e-05,  5.8334e-06, -1.1728e-05,\n",
       "        -5.2025e-07,  4.9771e-06,  1.7426e-05,  1.6842e-05,  3.5901e-05,\n",
       "         8.7873e-06, -4.0516e-06,  3.4098e-05, -2.2415e-05, -1.5125e-05,\n",
       "        -8.1865e-06, -1.6379e-05, -2.3339e-05, -3.7938e-05, -1.7359e-06,\n",
       "         1.5998e-05, -1.3250e-05,  3.0115e-05,  1.5000e-08,  2.5526e-05,\n",
       "        -1.2002e-05, -1.0470e-05,  1.6522e-05,  2.4301e-05, -8.7592e-06,\n",
       "         7.2650e-06, -1.7554e-06,  1.6833e-05, -3.1818e-05,  1.1607e-05,\n",
       "         5.1269e-06,  8.3411e-06,  2.9685e-05,  6.3310e-07,  2.0194e-05,\n",
       "         2.6849e-05,  4.9527e-06,  4.5823e-06,  1.7965e-05,  6.4048e-08,\n",
       "         1.8796e-05, -6.2739e-06,  9.2189e-06, -1.7924e-06, -3.2760e-06,\n",
       "         3.5532e-05,  2.8542e-06,  3.0002e-06, -2.1351e-05,  2.7228e-06,\n",
       "         2.0856e-05, -4.4865e-06, -1.5871e-05, -1.2225e-05,  2.4682e-06,\n",
       "         2.0390e-05,  2.6879e-05, -7.3732e-06,  3.0236e-05, -2.5342e-05,\n",
       "         2.3276e-06, -1.2996e-05, -1.5867e-05,  2.4153e-05, -1.5543e-05,\n",
       "        -4.9561e-06, -3.5113e-05,  2.7491e-05,  1.5965e-05, -2.1344e-05,\n",
       "         1.8548e-05,  5.1225e-06, -1.6444e-05,  5.7850e-06, -1.1872e-05,\n",
       "        -3.5670e-06, -1.2509e-05, -5.3082e-05, -2.6372e-05,  9.1574e-06,\n",
       "        -1.1352e-05,  6.7288e-06,  1.3977e-05, -2.0874e-05, -2.1436e-05,\n",
       "        -3.6495e-06,  6.0960e-06, -4.7473e-06, -6.5239e-06,  1.9219e-05,\n",
       "         3.4517e-05, -1.8189e-05, -6.4308e-06,  1.0599e-05,  1.0881e-05,\n",
       "         1.3807e-05, -3.0880e-06,  1.1149e-05, -2.1470e-05,  3.2241e-05,\n",
       "         2.1026e-06,  2.1317e-05, -6.7991e-06, -6.3864e-06,  1.1661e-05,\n",
       "         1.6584e-05,  3.2481e-06, -7.0850e-06, -5.8154e-06, -1.6962e-06,\n",
       "         9.0267e-06,  8.7907e-06,  1.0688e-05, -6.3721e-06,  1.6851e-06,\n",
       "         8.5621e-06,  2.0328e-06,  3.0053e-06, -4.3057e-06, -1.1476e-06,\n",
       "         5.0789e-06,  1.0789e-05,  1.2439e-06,  2.1969e-06, -1.1371e-06,\n",
       "         2.1700e-07,  1.1706e-05,  7.9329e-06, -4.7321e-06, -3.4912e-07,\n",
       "         4.5306e-06,  1.1237e-05,  7.6618e-07, -5.4868e-06, -1.2031e-05,\n",
       "         1.2998e-05, -3.0944e-06, -1.8788e-06,  1.4276e-05, -6.0703e-07,\n",
       "         9.2726e-07,  1.6793e-05,  1.8843e-06,  1.3697e-05,  1.8897e-06,\n",
       "        -2.0896e-06, -1.1035e-05, -1.4035e-05,  3.0443e-06, -1.2417e-03,\n",
       "         1.2986e-02,  1.7110e-02,  2.8946e-02, -2.5770e-02, -2.2517e-02,\n",
       "        -1.6412e-02, -2.6122e-02,  6.4382e-03, -2.9509e-02,  1.3172e-02,\n",
       "         5.9058e-03,  7.4972e-03,  8.5920e-03,  2.4156e-02,  5.1145e-03,\n",
       "        -2.6836e-02, -3.2139e-02,  3.4703e-02, -2.0623e-02, -5.3632e-03,\n",
       "        -4.5038e-03, -9.3564e-03, -2.0998e-02, -2.6330e-02, -2.6907e-02,\n",
       "         5.0041e-02, -1.3542e-02,  3.9234e-03,  5.7549e-02,  1.7672e-02,\n",
       "         4.5998e-03,  4.3968e-02, -2.1731e-02, -3.5134e-02,  1.5940e-02,\n",
       "         4.1254e-02, -1.5624e-02, -1.4713e-03,  2.0806e-03, -2.4027e-02,\n",
       "         1.0437e-02, -5.0316e-02,  3.3368e-02,  2.1649e-03,  3.8862e-03,\n",
       "         2.1318e-02, -2.1336e-02,  1.6735e-02, -8.0728e-03,  1.4615e-02,\n",
       "         6.2820e-03, -7.2301e-03, -1.8009e-02,  2.9891e-02, -1.8430e-02,\n",
       "        -7.9581e-03, -1.0302e-02, -2.0487e-02,  2.0978e-02, -2.6380e-02,\n",
       "        -2.4799e-02, -4.5737e-03, -4.4790e-03, -3.0404e-02, -8.8197e-03,\n",
       "         4.8223e-03,  2.4362e-02,  1.9523e-02, -1.5462e-02, -2.1916e-02,\n",
       "        -1.8568e-02,  4.0839e-03, -1.2365e-02, -3.6640e-03, -7.4302e-03,\n",
       "         6.3905e-03,  2.0606e-03, -2.2020e-03,  1.6706e-02, -1.8979e-02,\n",
       "         2.0243e-02, -2.4288e-02, -3.9204e-02,  4.0020e-03, -9.8654e-03,\n",
       "         1.8450e-03,  2.9801e-02, -8.4133e-03,  1.3646e-02,  1.8222e-02,\n",
       "        -1.3713e-02, -4.2595e-03, -2.2416e-04,  1.1639e-02, -1.4164e-02,\n",
       "         2.1221e-02,  2.4912e-02,  8.2495e-03,  5.8912e-03,  1.7524e-02,\n",
       "         2.2233e-02, -2.6181e-02, -2.2839e-03, -2.0001e-02, -8.3314e-03,\n",
       "        -2.4315e-02,  2.6870e-02, -2.0131e-02, -4.3033e-02,  1.9417e-02,\n",
       "        -9.2477e-03,  7.5161e-03,  1.1657e-02, -2.4600e-02, -1.6079e-03,\n",
       "        -1.1613e-02,  2.3990e-03, -3.9418e-03,  1.0759e-02,  1.6646e-02,\n",
       "         6.1001e-03, -2.8120e-04, -9.0739e-03, -8.7504e-03, -9.8231e-03,\n",
       "         1.6593e-02,  3.1811e-03, -2.0796e-02, -4.3438e-03, -2.3748e-02,\n",
       "        -2.9214e-03, -2.4150e-02,  1.1972e-02,  2.0657e-02,  2.0410e-02,\n",
       "        -2.4166e-02, -1.1841e-02,  9.0982e-03, -1.6724e-02,  3.8315e-02,\n",
       "         1.7728e-02,  1.4104e-03,  6.0435e-03,  5.3134e-03, -8.8090e-04,\n",
       "         2.7553e-03,  3.0202e-02, -1.4383e-02,  1.6060e-02,  6.6492e-03,\n",
       "        -3.5899e-02, -2.8970e-02, -2.1914e-02,  1.1662e-02, -5.6504e-02,\n",
       "        -2.1874e-02,  1.5731e-02,  4.3625e-03, -3.3903e-02,  3.3354e-03,\n",
       "         9.8275e-04,  6.8465e-04,  1.8499e-02,  3.2426e-02,  6.2430e-02,\n",
       "         6.2513e-03, -3.3024e-03, -1.1179e-02, -2.5409e-03,  1.4897e-02,\n",
       "        -1.6796e-02, -2.3393e-02, -1.0614e-02,  4.5039e-02, -1.4194e-02,\n",
       "         2.8163e-02,  9.0386e-03, -4.2222e-03, -3.1192e-02,  7.6414e-03,\n",
       "        -2.5173e-02, -2.4883e-02, -2.2236e-02,  4.4253e-02, -4.6075e-06,\n",
       "        -2.7811e-02,  9.4191e-03, -3.3411e-02, -7.6351e-03,  1.5647e-03,\n",
       "        -1.4231e-02], device='cuda:0')), ('transformer_decoder.layers.1.multihead_attn.out_proj.weight', tensor([[-0.0059,  0.0194,  0.0176,  ..., -0.0292,  0.0565,  0.0259],\n",
       "        [ 0.0185, -0.0124, -0.0953,  ...,  0.0345, -0.0260,  0.0659],\n",
       "        [-0.0256, -0.0572,  0.0228,  ...,  0.0291,  0.0632,  0.0159],\n",
       "        ...,\n",
       "        [-0.0546,  0.0549, -0.0161,  ..., -0.0509, -0.0635,  0.0253],\n",
       "        [ 0.0032, -0.0369,  0.0664,  ..., -0.0100, -0.0601,  0.0399],\n",
       "        [ 0.0765,  0.0205, -0.0186,  ..., -0.0496, -0.0788, -0.0422]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.multihead_attn.out_proj.bias', tensor([-0.0046, -0.0390, -0.0213,  0.0041, -0.0133,  0.0255,  0.0131, -0.0110,\n",
       "         0.0093,  0.0288,  0.0300,  0.0075,  0.0213, -0.0053,  0.0313, -0.0094,\n",
       "         0.0030,  0.0099,  0.0037,  0.0432, -0.0034, -0.0020,  0.0028,  0.0200,\n",
       "        -0.0218,  0.0318,  0.0109,  0.0560,  0.0434, -0.0144, -0.0268,  0.0173,\n",
       "        -0.0095, -0.0119, -0.0198, -0.0083, -0.0297,  0.0154,  0.0116,  0.0057,\n",
       "        -0.0145, -0.0016,  0.0119,  0.0030, -0.0191,  0.0091,  0.0134, -0.0010,\n",
       "        -0.0080, -0.0055,  0.0062,  0.0026,  0.0146, -0.0415, -0.0024, -0.0013,\n",
       "        -0.0172,  0.0127,  0.0254,  0.0166,  0.0322,  0.0038,  0.0069,  0.0182,\n",
       "         0.0129,  0.0120, -0.0217, -0.0100, -0.0262,  0.0065,  0.0059,  0.0133,\n",
       "         0.0148, -0.0301, -0.0139, -0.0144,  0.0209, -0.0129, -0.0274, -0.0055,\n",
       "        -0.0176, -0.0116,  0.0064,  0.0098, -0.0010,  0.0266, -0.0059,  0.0448,\n",
       "         0.0126, -0.0032, -0.0306,  0.0099, -0.0085, -0.0051,  0.0221, -0.0005,\n",
       "        -0.0008, -0.0072,  0.0263, -0.0060, -0.0043, -0.0212, -0.0244, -0.0057,\n",
       "        -0.0159,  0.0009,  0.0251, -0.0106, -0.0172, -0.0027,  0.0011, -0.0136,\n",
       "         0.0402,  0.0243, -0.0023,  0.0054,  0.0274,  0.0048,  0.0297, -0.0070,\n",
       "        -0.0200,  0.0033,  0.0073,  0.0115, -0.0380,  0.0022,  0.0298,  0.0092,\n",
       "         0.0055,  0.0277, -0.0236, -0.0019,  0.0163, -0.0184,  0.0004, -0.0122,\n",
       "         0.0005, -0.0268,  0.0013, -0.0336, -0.0122,  0.0113,  0.0137,  0.0034,\n",
       "        -0.0182, -0.0154,  0.0276, -0.0253,  0.0123, -0.0533,  0.0128,  0.0073,\n",
       "        -0.0157, -0.0139, -0.0295, -0.0181,  0.0296,  0.0030,  0.0008, -0.0124,\n",
       "        -0.0151, -0.0158, -0.0128,  0.0025, -0.0088,  0.0237, -0.0107, -0.0217,\n",
       "         0.0003, -0.0268, -0.0175, -0.0081, -0.0430, -0.0006,  0.0335, -0.0352,\n",
       "        -0.0070, -0.0085, -0.0054,  0.0167,  0.0291, -0.0116,  0.0151, -0.0091,\n",
       "         0.0039, -0.0374, -0.0186,  0.0028,  0.0069, -0.0265, -0.0110,  0.0177],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.linear1.weight', tensor([[ 0.0315,  0.0020, -0.0214,  ...,  0.0625, -0.0140,  0.0430],\n",
       "        [-0.0332, -0.0116, -0.0333,  ...,  0.0123,  0.0962,  0.0318],\n",
       "        [ 0.0176,  0.0624,  0.0023,  ...,  0.0043, -0.0408, -0.0713],\n",
       "        ...,\n",
       "        [ 0.0034, -0.0222, -0.0172,  ...,  0.0616, -0.0484, -0.0138],\n",
       "        [-0.0903,  0.1201,  0.0455,  ...,  0.0744,  0.0083, -0.0166],\n",
       "        [ 0.0174, -0.0477,  0.0110,  ...,  0.0345,  0.0207, -0.0004]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.linear1.bias', tensor([-0.0123, -0.0777, -0.1128,  ..., -0.0315, -0.0392, -0.1384],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.linear2.weight', tensor([[-0.0004, -0.0038, -0.0331,  ...,  0.0354, -0.0150,  0.0024],\n",
       "        [ 0.0365, -0.0252, -0.0177,  ...,  0.0002,  0.0386,  0.0061],\n",
       "        [ 0.0007, -0.0517,  0.0137,  ..., -0.0052,  0.0227, -0.0482],\n",
       "        ...,\n",
       "        [ 0.0326,  0.0009, -0.0065,  ..., -0.0114,  0.0102,  0.0077],\n",
       "        [ 0.0342, -0.0072,  0.0182,  ...,  0.0495,  0.0420, -0.0258],\n",
       "        [ 0.0363,  0.0280,  0.0295,  ...,  0.0480, -0.0108,  0.0228]],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.linear2.bias', tensor([-0.0728,  0.0723, -0.0512,  0.0804, -0.0300,  0.0526,  0.0555,  0.0696,\n",
       "        -0.0574, -0.0719,  0.0583,  0.0234, -0.0683,  0.1099, -0.0511,  0.0811,\n",
       "         0.0261, -0.0471, -0.0725,  0.0384,  0.0786,  0.0769,  0.0104,  0.0503,\n",
       "        -0.0355,  0.0548, -0.0192, -0.0366, -0.0683,  0.0580,  0.0499, -0.0842,\n",
       "         0.0502,  0.0561,  0.0447,  0.0171,  0.0201,  0.0572,  0.0450, -0.0725,\n",
       "         0.0780,  0.0468, -0.0439,  0.0454,  0.0638, -0.0927, -0.0427, -0.0281,\n",
       "         0.0752,  0.0562, -0.0777,  0.0534,  0.0663, -0.0388,  0.0682, -0.0765,\n",
       "         0.0948,  0.0716,  0.0091, -0.0602, -0.0377, -0.0689, -0.0661, -0.0538,\n",
       "         0.0344,  0.0584,  0.0329, -0.0520, -0.0124,  0.0563, -0.0630, -0.0340,\n",
       "         0.0377,  0.0391,  0.0627, -0.0854, -0.0138, -0.0651,  0.0372, -0.0558,\n",
       "        -0.0178, -0.0322, -0.0804, -0.0608,  0.0079, -0.0209,  0.0522, -0.0765,\n",
       "         0.0517,  0.0731,  0.0145,  0.0681, -0.0408, -0.0925, -0.0676, -0.0315,\n",
       "        -0.0133, -0.1050, -0.0100, -0.0068,  0.0684,  0.0593,  0.0403,  0.0149,\n",
       "         0.0581,  0.0197,  0.0100, -0.0056,  0.0545, -0.0304, -0.0657, -0.0251,\n",
       "        -0.0581,  0.0793,  0.0424, -0.0865,  0.0749, -0.0933,  0.0927,  0.0431,\n",
       "        -0.0673, -0.0661, -0.0136, -0.0408, -0.0432, -0.0688,  0.0893,  0.0784,\n",
       "        -0.0007, -0.0659,  0.0664, -0.0348, -0.0613, -0.0126,  0.0096,  0.0386,\n",
       "         0.0082, -0.0103, -0.0681, -0.0163, -0.0317, -0.0590,  0.0967, -0.0443,\n",
       "         0.0330,  0.0531,  0.0273, -0.0614, -0.0460,  0.0621,  0.0620,  0.0021,\n",
       "         0.0637, -0.0263,  0.0843,  0.0391, -0.0222, -0.0303, -0.0017, -0.0741,\n",
       "         0.0401,  0.0648, -0.0611, -0.0372,  0.0425, -0.0816, -0.0172, -0.0705,\n",
       "        -0.0371, -0.1074,  0.0532,  0.0011, -0.0363, -0.0571, -0.0407,  0.0491,\n",
       "        -0.0022, -0.0471,  0.0585, -0.0725, -0.0345,  0.0369, -0.0409,  0.0142,\n",
       "         0.0480, -0.0611, -0.0693,  0.0912,  0.0636, -0.0551,  0.0640,  0.0256],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.norm1.weight', tensor([0.9731, 0.8455, 0.9837, 1.0036, 0.9621, 0.9957, 0.9784, 0.9806, 0.9593,\n",
       "        0.9068, 0.9514, 0.9911, 0.9506, 1.0348, 0.9797, 0.9808, 0.9744, 0.9782,\n",
       "        0.9860, 0.9780, 1.0024, 0.9764, 1.0013, 0.9711, 0.9924, 0.9625, 0.9387,\n",
       "        0.9430, 0.8797, 0.9367, 1.0149, 0.9653, 0.9861, 1.0104, 0.9464, 1.0102,\n",
       "        0.9693, 0.9710, 0.9649, 0.9702, 1.0018, 1.0131, 0.9428, 1.0015, 0.9554,\n",
       "        1.0018, 0.9960, 0.9837, 0.9992, 1.0006, 0.9862, 0.9970, 0.9938, 0.9823,\n",
       "        0.9613, 0.9825, 0.9944, 0.9515, 0.9984, 0.9970, 0.9892, 0.9772, 0.9622,\n",
       "        0.9577, 0.8811, 0.9697, 0.9908, 0.9699, 0.9944, 0.9795, 1.0141, 1.0081,\n",
       "        0.9742, 0.9797, 1.0149, 0.9584, 0.9850, 0.9971, 1.0124, 0.9546, 1.0109,\n",
       "        0.9359, 0.9818, 0.9832, 0.9814, 1.0288, 0.9974, 0.9397, 1.0160, 0.9666,\n",
       "        1.0069, 0.9276, 0.9554, 0.9330, 1.0347, 0.9899, 1.0282, 0.9848, 1.0288,\n",
       "        0.9977, 1.0132, 0.9613, 0.9992, 0.9769, 0.9951, 0.9632, 1.0041, 0.9878,\n",
       "        0.9869, 1.0040, 1.0105, 0.9984, 1.0036, 1.0026, 0.9865, 0.9458, 0.9694,\n",
       "        0.9669, 0.9967, 0.9480, 0.9669, 1.0065, 0.9947, 0.9305, 1.0410, 0.9450,\n",
       "        1.0363, 0.9947, 1.0298, 0.9041, 1.0149, 0.9766, 0.9643, 0.9549, 1.0312,\n",
       "        0.9675, 1.0077, 0.9833, 1.0071, 0.9420, 1.0136, 0.9795, 0.9982, 1.0080,\n",
       "        1.0197, 0.9631, 1.0128, 0.9857, 0.9721, 0.9482, 1.0020, 0.9332, 0.9949,\n",
       "        0.9902, 0.9549, 0.9517, 0.9958, 0.9875, 1.0339, 0.9789, 1.0125, 0.9474,\n",
       "        0.9837, 0.9026, 1.0183, 0.9507, 1.0527, 0.9604, 1.0299, 0.9629, 1.0224,\n",
       "        0.9452, 0.9818, 0.9830, 1.0441, 0.9945, 0.9615, 0.9455, 1.0376, 0.9900,\n",
       "        0.9857, 0.9615, 1.0278, 0.9556, 1.0060, 1.0015, 1.0358, 0.9474, 0.9050,\n",
       "        0.9742, 1.0229, 0.9913], device='cuda:0')), ('transformer_decoder.layers.1.norm1.bias', tensor([ 0.0198, -0.0869,  0.0126, -0.0674,  0.0581, -0.0429,  0.0935,  0.0003,\n",
       "         0.0501,  0.1397, -0.0256, -0.0095,  0.1157, -0.0771,  0.1142, -0.0662,\n",
       "        -0.0338,  0.0047,  0.0477,  0.1550, -0.0794, -0.0682, -0.0354,  0.0389,\n",
       "        -0.0712,  0.0525,  0.0436,  0.0689,  0.0550, -0.0285, -0.1059,  0.1068,\n",
       "        -0.0190, -0.1067, -0.0418, -0.0710, -0.1003, -0.0755, -0.0256,  0.0569,\n",
       "        -0.1083, -0.0130,  0.0313, -0.0317, -0.0942,  0.0184,  0.0650,  0.0326,\n",
       "        -0.0592, -0.0801,  0.0189, -0.0276, -0.0660, -0.0598, -0.0486,  0.0616,\n",
       "        -0.0889, -0.1056,  0.0841,  0.0904,  0.1379, -0.0034,  0.0332,  0.0366,\n",
       "         0.0367, -0.0464, -0.0651, -0.0215, -0.0330, -0.0781,  0.1470,  0.0598,\n",
       "         0.0352, -0.0929, -0.1209,  0.0768,  0.0355, -0.0047, -0.0092, -0.0115,\n",
       "        -0.0098, -0.0993,  0.1376,  0.0528, -0.0365,  0.0321, -0.0874,  0.1204,\n",
       "        -0.0297, -0.0483, -0.0123, -0.1384,  0.0777,  0.0461,  0.0854, -0.0174,\n",
       "         0.0564,  0.0787,  0.1205,  0.0074,  0.0752, -0.1571, -0.0133,  0.0455,\n",
       "        -0.0957, -0.0833,  0.0182, -0.1271, -0.0036,  0.0162,  0.0601,  0.0190,\n",
       "         0.1787, -0.0917,  0.0319, -0.0501, -0.0059,  0.1064,  0.0314, -0.1634,\n",
       "         0.0655,  0.0594,  0.0747,  0.0355,  0.0278,  0.0098,  0.0036, -0.0641,\n",
       "        -0.0152,  0.0107, -0.1165,  0.0419,  0.2074, -0.0610,  0.0572, -0.0853,\n",
       "        -0.0377,  0.0434,  0.1225, -0.1124, -0.0291,  0.0578, -0.0687,  0.0232,\n",
       "         0.0508, -0.0772, -0.0152, -0.0011,  0.0820, -0.0721, -0.0457, -0.1113,\n",
       "        -0.0302,  0.0409, -0.0213, -0.1605,  0.0651,  0.0701,  0.0296,  0.0032,\n",
       "        -0.0193,  0.0060,  0.1141, -0.0261, -0.0179,  0.0563,  0.0035, -0.0646,\n",
       "        -0.0505,  0.0320, -0.0691, -0.0640,  0.0690,  0.0529,  0.1879, -0.1739,\n",
       "         0.0594, -0.0182, -0.0813,  0.0973,  0.0430, -0.0603,  0.1456, -0.0096,\n",
       "         0.0439,  0.0018,  0.0080, -0.0532, -0.0253, -0.0576, -0.0771, -0.0186],\n",
       "       device='cuda:0')), ('transformer_decoder.layers.1.norm2.weight', tensor([0.9742, 0.8801, 0.9925, 1.0076, 0.9853, 1.0096, 0.9951, 1.0002, 0.9659,\n",
       "        0.9282, 0.9661, 0.9978, 0.9790, 1.0367, 0.9862, 0.9805, 0.9821, 0.9732,\n",
       "        0.9930, 1.0025, 1.0099, 0.9891, 1.0105, 0.9630, 1.0084, 0.9679, 0.9538,\n",
       "        0.9524, 0.9181, 0.9618, 1.0292, 0.9847, 1.0018, 1.0069, 0.9671, 1.0225,\n",
       "        1.0126, 0.9757, 0.9812, 0.9737, 1.0053, 1.0297, 0.9820, 1.0080, 0.9823,\n",
       "        1.0176, 0.9977, 0.9868, 1.0124, 1.0061, 1.0137, 1.0125, 1.0068, 1.0081,\n",
       "        0.9690, 0.9846, 1.0079, 0.9991, 1.0257, 0.9994, 1.0046, 0.9850, 0.9766,\n",
       "        0.9791, 0.8851, 0.9933, 1.0005, 0.9850, 1.0057, 1.0012, 1.0231, 1.0268,\n",
       "        0.9809, 0.9930, 1.0223, 0.9670, 1.0029, 1.0076, 1.0276, 0.9635, 1.0022,\n",
       "        0.9630, 1.0138, 0.9847, 0.9826, 1.0317, 1.0011, 0.9550, 1.0192, 0.9650,\n",
       "        1.0355, 0.9717, 0.9788, 0.9537, 1.0243, 0.9922, 1.0266, 0.9929, 1.0278,\n",
       "        1.0074, 1.0352, 0.9793, 0.9930, 1.0136, 1.0113, 0.9750, 0.9958, 0.9881,\n",
       "        1.0054, 1.0002, 1.0151, 1.0088, 1.0201, 1.0294, 1.0005, 0.9633, 0.9834,\n",
       "        0.9772, 1.0177, 0.9903, 0.9630, 1.0071, 0.9940, 0.9375, 1.0521, 0.9581,\n",
       "        1.0328, 0.9951, 1.0322, 0.9090, 1.0275, 0.9719, 0.9926, 0.9622, 1.0347,\n",
       "        0.9659, 1.0227, 0.9895, 1.0429, 0.9608, 1.0346, 0.9927, 1.0206, 1.0072,\n",
       "        1.0072, 0.9722, 1.0197, 0.9781, 0.9958, 0.9757, 1.0086, 0.9489, 1.0016,\n",
       "        1.0070, 0.9726, 1.0091, 1.0300, 0.9934, 1.0247, 0.9843, 0.9973, 0.9706,\n",
       "        0.9963, 0.9191, 1.0301, 0.9525, 1.0398, 0.9668, 1.0269, 0.9723, 1.0349,\n",
       "        0.9451, 1.0042, 0.9918, 1.0562, 1.0271, 0.9564, 0.9491, 1.0341, 1.0058,\n",
       "        1.0063, 0.9541, 1.0300, 0.9608, 1.0119, 1.0126, 1.0391, 0.9559, 0.9391,\n",
       "        0.9776, 1.0254, 0.9866], device='cuda:0')), ('transformer_decoder.layers.1.norm2.bias', tensor([-6.8920e-03, -7.2111e-02,  7.9891e-03, -5.9260e-02,  5.5812e-02,\n",
       "        -4.0608e-02,  1.0242e-01,  1.8335e-03,  1.9658e-02,  1.2593e-01,\n",
       "        -3.3519e-02, -1.4055e-02,  1.0899e-01, -6.4207e-02,  1.0087e-01,\n",
       "        -6.2346e-02, -2.5078e-02, -2.2093e-02,  2.8857e-02,  1.6391e-01,\n",
       "        -6.0728e-02, -6.6126e-02, -3.3980e-02,  4.5222e-02, -8.5235e-02,\n",
       "         5.1175e-02,  2.3125e-02,  4.2020e-02,  2.6068e-02, -2.8990e-02,\n",
       "        -9.2827e-02,  8.8299e-02, -5.6933e-03, -9.7521e-02, -3.1562e-02,\n",
       "        -4.4766e-02, -8.0784e-02, -8.1661e-02, -3.1638e-02,  5.7038e-02,\n",
       "        -1.0289e-01, -1.0766e-02, -1.4374e-03, -3.1641e-02, -9.6235e-02,\n",
       "         5.0753e-03,  4.7085e-02,  1.9778e-02, -6.0350e-02, -5.9486e-02,\n",
       "         8.1317e-03, -3.0062e-02, -5.6837e-02, -6.1819e-02, -4.3450e-02,\n",
       "         4.1574e-02, -7.2482e-02, -1.0855e-01,  8.8677e-02,  8.3320e-02,\n",
       "         1.3007e-01, -2.1862e-02,  2.1758e-02,  1.5764e-02,  5.9907e-02,\n",
       "        -4.0504e-02, -5.4790e-02, -2.3311e-02, -5.3295e-02, -7.9235e-02,\n",
       "         1.4554e-01,  5.0846e-02,  3.3909e-02, -8.2725e-02, -1.1319e-01,\n",
       "         5.7359e-02,  2.2162e-02, -1.8503e-02, -4.6059e-03, -3.1436e-02,\n",
       "        -2.1263e-02, -1.2375e-01,  1.3234e-01,  3.2774e-02, -3.1062e-02,\n",
       "         4.0217e-03, -8.6824e-02,  9.1485e-02, -2.1540e-02, -3.7683e-02,\n",
       "        -1.2644e-02, -1.4852e-01,  7.8963e-02,  3.6596e-02,  5.6371e-02,\n",
       "        -5.4107e-02,  4.6956e-02,  6.4316e-02,  1.1535e-01, -4.2919e-05,\n",
       "         9.6756e-02, -1.5499e-01, -1.5210e-02,  2.8213e-02, -8.4908e-02,\n",
       "        -9.3644e-02,  1.5095e-02, -1.4895e-01, -4.0220e-05, -8.2155e-03,\n",
       "         4.6576e-02,  1.8349e-02,  1.4895e-01, -9.7923e-02,  4.1825e-02,\n",
       "        -7.2580e-02, -1.1028e-02,  8.9832e-02,  4.7372e-02, -1.6943e-01,\n",
       "         5.6088e-02,  5.8194e-02,  7.6173e-02,  2.4986e-02,  3.7966e-02,\n",
       "         2.6056e-03,  9.8641e-04, -5.4875e-02, -1.0071e-02, -1.8660e-02,\n",
       "        -9.9124e-02,  1.8528e-02,  1.9838e-01, -6.5790e-02,  3.8815e-02,\n",
       "        -9.2702e-02, -3.3865e-02,  3.2837e-02,  1.1691e-01, -1.2156e-01,\n",
       "        -3.4788e-02,  2.5079e-02, -7.2349e-02, -1.3093e-03,  6.1893e-02,\n",
       "        -6.5288e-02, -2.6841e-02, -7.9301e-03,  7.3063e-02, -4.9616e-02,\n",
       "        -2.6508e-02, -1.2164e-01, -1.6969e-02,  3.7896e-02, -2.6305e-03,\n",
       "        -1.7341e-01,  3.5728e-02,  6.8970e-02,  2.7231e-02, -5.8719e-03,\n",
       "         1.0030e-02,  3.1528e-02,  1.0657e-01, -4.8645e-02, -8.1379e-03,\n",
       "         3.9293e-02, -1.1886e-02, -7.2036e-02, -6.1012e-02,  1.7504e-02,\n",
       "        -5.3645e-02, -8.0437e-02,  7.9758e-02,  4.7421e-02,  1.8195e-01,\n",
       "        -1.6304e-01,  5.7535e-02, -4.0829e-02, -7.4070e-02,  9.5699e-02,\n",
       "         3.9215e-02, -4.3308e-02,  1.4764e-01, -1.1513e-02,  5.2592e-02,\n",
       "        -1.6017e-02,  1.7335e-02, -4.3716e-02, -2.9863e-02, -7.7705e-02,\n",
       "        -6.0049e-02, -3.3052e-02], device='cuda:0')), ('transformer_decoder.layers.1.norm3.weight', tensor([1.5975, 1.2724, 1.6548, 1.5620, 1.5888, 1.4758, 1.6184, 1.6951, 1.5243,\n",
       "        1.4638, 1.5494, 1.4919, 1.4811, 1.4739, 1.4174, 1.4991, 1.6934, 1.6613,\n",
       "        1.5637, 1.5082, 1.5144, 1.4759, 1.5891, 1.6599, 1.6046, 1.5935, 1.5738,\n",
       "        1.5326, 1.4682, 1.4928, 1.5036, 1.5927, 1.5237, 1.5367, 1.5264, 1.6365,\n",
       "        1.6331, 1.5854, 1.6481, 1.5102, 1.5754, 1.6723, 1.7262, 1.6386, 1.4230,\n",
       "        1.6149, 1.6269, 1.5825, 1.5622, 1.4946, 1.6169, 1.5873, 1.5803, 1.6863,\n",
       "        1.5078, 1.4214, 1.5883, 1.5988, 1.6939, 1.5567, 1.5356, 1.6329, 1.4972,\n",
       "        1.5688, 1.4995, 1.5494, 1.5703, 1.6860, 1.6307, 1.5239, 1.4986, 1.3610,\n",
       "        1.6621, 1.5923, 1.5038, 1.5266, 1.6668, 1.6143, 1.5333, 1.6409, 1.7163,\n",
       "        1.5194, 1.6427, 1.5934, 1.6433, 1.5330, 1.3579, 1.1677, 1.4122, 1.5534,\n",
       "        1.5612, 1.5729, 1.5860, 1.5081, 1.6167, 1.4766, 1.6344, 1.5414, 1.5861,\n",
       "        1.6728, 1.6470, 1.5270, 1.6229, 1.6673, 1.5391, 1.6425, 1.5835, 1.4465,\n",
       "        1.6218, 1.6223, 1.5890, 1.6183, 1.4834, 1.5697, 1.5915, 1.6561, 1.5420,\n",
       "        1.4091, 1.6105, 1.5370, 1.5680, 1.5285, 1.4782, 1.3529, 1.6642, 1.5768,\n",
       "        1.6011, 1.5639, 1.6438, 1.4897, 1.5292, 1.5429, 1.3970, 1.6128, 1.6716,\n",
       "        1.5921, 1.6126, 1.6582, 1.5526, 1.4635, 1.4761, 1.6187, 1.4952, 1.6069,\n",
       "        1.4046, 1.5375, 1.5449, 1.6226, 1.6520, 1.5129, 1.6531, 1.5954, 1.6067,\n",
       "        1.6175, 1.5102, 1.3445, 1.6366, 1.4525, 1.6684, 1.5970, 1.6105, 1.5532,\n",
       "        1.6115, 1.5977, 1.6835, 1.4844, 1.6495, 1.5761, 1.5711, 1.5903, 1.5764,\n",
       "        1.5800, 1.6468, 1.4435, 1.4853, 1.5279, 1.5721, 1.6540, 1.4830, 1.4447,\n",
       "        1.4530, 1.6237, 1.4736, 1.5924, 1.7227, 1.6058, 1.7411, 1.4939, 1.5363,\n",
       "        1.4588, 1.6092, 1.6925], device='cuda:0')), ('transformer_decoder.layers.1.norm3.bias', tensor([-2.1745e-02, -3.7432e-02,  9.1398e-02, -4.1320e-02,  3.1379e-02,\n",
       "        -6.1644e-02,  9.6546e-02,  2.8034e-02, -3.1854e-02,  6.8596e-02,\n",
       "        -1.2323e-01,  1.1661e-02,  1.6202e-02, -1.2381e-01,  8.6480e-02,\n",
       "        -5.8939e-02,  2.9780e-02, -1.2212e-03,  6.2275e-02, -3.1589e-02,\n",
       "        -8.3103e-02,  1.1854e-03,  1.2437e-02,  4.1205e-02,  4.1702e-02,\n",
       "         9.3354e-02, -4.5256e-02,  4.3816e-03, -4.4604e-02,  5.3999e-02,\n",
       "        -1.9950e-02,  1.2070e-01, -1.7267e-02, -1.6632e-01,  8.4606e-02,\n",
       "         1.8302e-02, -1.2448e-02,  1.2394e-02,  1.3967e-02,  8.4074e-03,\n",
       "        -6.2931e-02,  8.9536e-02, -8.0722e-02, -1.1229e-03, -2.6511e-02,\n",
       "         1.9918e-02,  3.9635e-02,  1.3602e-02, -4.6308e-02, -4.1713e-02,\n",
       "         7.2625e-02, -3.7655e-03,  5.8490e-02, -8.1118e-02,  1.7010e-02,\n",
       "        -2.1432e-02, -6.9998e-02, -4.1613e-02,  5.8596e-02,  7.4762e-02,\n",
       "         3.3998e-02, -1.8953e-02, -4.4246e-02, -2.5177e-02,  1.3385e-01,\n",
       "        -3.5204e-02, -1.8826e-02,  4.2173e-02, -6.9824e-02, -5.1474e-02,\n",
       "         8.0345e-02, -2.2259e-02,  7.4933e-02,  3.9226e-03, -8.5856e-02,\n",
       "        -1.5467e-03, -5.7900e-02,  3.4713e-02, -6.3154e-02, -6.3245e-02,\n",
       "        -1.8890e-02, -4.6423e-02,  1.0968e-01,  7.3472e-02, -2.3538e-03,\n",
       "         3.4127e-02,  5.6415e-02, -4.6972e-02,  9.3600e-04, -3.3573e-02,\n",
       "         2.3302e-02, -1.0016e-01,  8.3620e-02,  8.4229e-02,  2.8950e-02,\n",
       "        -3.6067e-02, -3.6434e-03,  8.7206e-02,  8.3662e-02, -3.3972e-02,\n",
       "         5.6259e-02, -3.2464e-02, -6.7635e-02, -9.7480e-02, -4.9164e-02,\n",
       "        -1.0579e-01,  6.9177e-02, -4.9910e-02,  1.2666e-01, -6.0323e-02,\n",
       "         6.7384e-03,  1.3177e-02,  1.0023e-01, -6.8097e-02,  4.8643e-02,\n",
       "        -6.8356e-02,  3.6083e-02,  1.0359e-01,  4.7605e-02, -8.2346e-02,\n",
       "         4.0556e-02,  7.5959e-02, -7.4442e-02, -6.0737e-02,  4.5956e-02,\n",
       "         2.3323e-02, -3.7467e-02, -4.0692e-02, -1.7497e-02, -1.7762e-02,\n",
       "        -5.7937e-02, -8.8918e-02,  9.5461e-02,  4.9966e-03,  3.5089e-02,\n",
       "        -2.9846e-02,  7.0613e-03, -6.9217e-02,  9.9124e-02, -5.5895e-02,\n",
       "         7.3908e-02,  4.2186e-03, -6.6830e-02,  2.2228e-03,  1.3826e-03,\n",
       "        -5.0106e-02, -8.1044e-02,  8.6144e-02,  9.9316e-02,  5.8107e-02,\n",
       "        -4.2341e-03, -1.2161e-01,  1.7558e-02, -2.0554e-02,  6.4554e-02,\n",
       "         6.3170e-02, -5.9232e-02,  3.0071e-02, -9.1322e-02,  1.1285e-02,\n",
       "         1.0183e-01,  9.0252e-02,  6.0811e-02, -5.7993e-02, -8.9038e-03,\n",
       "         3.9626e-02, -3.0313e-02, -6.0946e-02, -6.2827e-02,  5.1603e-02,\n",
       "        -4.9608e-02, -1.0293e-01,  9.8684e-02,  5.9090e-02,  8.2171e-02,\n",
       "        -1.2210e-01,  2.2958e-02,  1.0011e-04,  1.1252e-02,  1.1200e-01,\n",
       "         4.7166e-02, -3.9170e-02,  7.1433e-02,  5.6726e-02,  1.1172e-01,\n",
       "         3.0972e-02,  1.0202e-01, -2.1346e-02, -1.0029e-03, -2.3210e-02,\n",
       "         4.9386e-02,  1.7554e-02], device='cuda:0')), ('word_emb.weight', tensor([[-0.0231, -0.1089, -0.0314,  ..., -0.0823,  0.0072, -0.0278],\n",
       "        [-0.0085, -0.1220,  0.0351,  ..., -0.0374,  0.0094, -0.0614],\n",
       "        [-0.0476,  0.0218, -0.0224,  ...,  0.0235, -0.0009, -0.0247],\n",
       "        ...,\n",
       "        [-0.0081, -0.0108,  0.0223,  ...,  0.0252,  0.0296,  0.0094],\n",
       "        [-0.0247, -0.0056, -0.0418,  ...,  0.0059, -0.0127, -0.0348],\n",
       "        [ 0.0083, -0.0188,  0.0275,  ...,  0.0063,  0.0331,  0.0015]],\n",
       "       device='cuda:0')), ('fc.weight', tensor([[ 0.1444,  0.0340,  0.0644,  ..., -0.0600,  0.0713,  0.0388],\n",
       "        [-0.0251,  0.0054, -0.0187,  ..., -0.0408,  0.0636, -0.0873],\n",
       "        [-0.0032,  0.0023, -0.0051,  ...,  0.0436, -0.0230,  0.0074],\n",
       "        ...,\n",
       "        [-0.1845,  0.0455,  0.0306,  ..., -0.0771,  0.1305, -0.0463],\n",
       "        [ 0.0742,  0.0575,  0.0213,  ..., -0.0602, -0.1442,  0.0134],\n",
       "        [-0.0883, -0.0248, -0.0477,  ..., -0.0651,  0.1710,  0.0396]],\n",
       "       device='cuda:0')), ('fc.bias', tensor([ 0.0367,  0.0367,  0.0446,  0.0219,  0.0460,  0.0366,  0.0208,  0.0368,\n",
       "         0.0274,  0.0283,  0.0334,  0.0452,  0.0585,  0.0373,  0.0305,  0.0137,\n",
       "         0.0124,  0.0298,  0.0421,  0.0277,  0.0452,  0.0322,  0.0301,  0.0492,\n",
       "         0.0437,  0.0297,  0.0410,  0.0243,  0.0189,  0.0304,  0.0339,  0.0521,\n",
       "         0.0296,  0.0292,  0.0365,  0.0424,  0.0394,  0.0260,  0.0290, -0.1153,\n",
       "         0.0482,  0.0323,  0.0422,  0.0447,  0.0325,  0.0543,  0.0319,  0.0278,\n",
       "         0.0530,  0.0400,  0.0210,  0.0288,  0.0223,  0.0430,  0.0277,  0.0460,\n",
       "         0.0547,  0.0531,  0.0318,  0.0242,  0.0095,  0.0335,  0.0366,  0.0305,\n",
       "         0.0343,  0.0316, -0.1597, -0.0946,  0.0412,  0.0336,  0.0254,  0.0271,\n",
       "         0.0375,  0.0436,  0.0252,  0.0342,  0.0261,  0.0067,  0.0355,  0.0286,\n",
       "         0.0010,  0.0413,  0.0498,  0.0209,  0.0460,  0.0273,  0.0414,  0.0326,\n",
       "         0.0336,  0.0391,  0.0352,  0.0262,  0.0508,  0.0134, -0.0046,  0.0165,\n",
       "         0.0193, -0.0025,  0.0485,  0.0472,  0.0201,  0.0363,  0.0423,  0.0370,\n",
       "         0.0229,  0.0158,  0.0182,  0.0356,  0.0272,  0.0355,  0.0479,  0.0462,\n",
       "         0.0214,  0.0181,  0.0375,  0.0341,  0.0451,  0.0350,  0.0255,  0.0278,\n",
       "         0.0413,  0.0445,  0.0490,  0.0332,  0.0314,  0.0382,  0.0394,  0.0175,\n",
       "         0.0292,  0.0529,  0.0226,  0.0281,  0.0379,  0.0319,  0.0512,  0.0271,\n",
       "        -0.0647,  0.0412,  0.0312,  0.0391,  0.0211,  0.0336,  0.0289,  0.0191,\n",
       "         0.0337,  0.0268,  0.0303,  0.0473,  0.0328,  0.0516,  0.0380,  0.0246,\n",
       "         0.0456,  0.0212,  0.0294,  0.0486,  0.0393,  0.0429,  0.0533,  0.0540,\n",
       "         0.0356,  0.0228,  0.0508,  0.0241,  0.0382,  0.0146,  0.0449,  0.0329,\n",
       "        -0.0008,  0.0428,  0.0238,  0.0272,  0.0252,  0.0412,  0.0356,  0.0387,\n",
       "         0.0285,  0.0429,  0.0443,  0.0244,  0.0293,  0.0614,  0.0343,  0.0398,\n",
       "         0.0358,  0.0491,  0.0581,  0.0435,  0.0199,  0.0336,  0.0417,  0.0509,\n",
       "         0.0435,  0.0375, -0.1228,  0.0485,  0.0345,  0.0338,  0.0488,  0.0187,\n",
       "         0.0395,  0.0460,  0.0413,  0.0592,  0.0222,  0.0452,  0.0471,  0.0249,\n",
       "         0.0293,  0.0283,  0.0338,  0.0372,  0.0125,  0.0387,  0.0422,  0.0441,\n",
       "         0.0643,  0.0339,  0.0435,  0.0504,  0.0268,  0.0346,  0.0377,  0.0376,\n",
       "         0.0362,  0.0357,  0.0412,  0.0415,  0.0405,  0.0390,  0.0456,  0.0138,\n",
       "         0.0539,  0.0319,  0.0322,  0.0483,  0.0394,  0.0345,  0.0548,  0.0461,\n",
       "         0.0425,  0.0331,  0.0341,  0.0517,  0.0350,  0.0444,  0.0211,  0.0616,\n",
       "         0.0328,  0.0437,  0.0298,  0.0275,  0.0497,  0.0511,  0.0505,  0.0459,\n",
       "         0.0424,  0.0362,  0.0318,  0.0293,  0.0406,  0.0104, -0.0026,  0.0369,\n",
       "         0.0401,  0.0542,  0.0514,  0.0374,  0.0310,  0.0505,  0.0122,  0.0537,\n",
       "         0.0231,  0.0114,  0.0334,  0.0269,  0.0314,  0.0742,  0.0416,  0.0607,\n",
       "         0.0224,  0.0553,  0.0150,  0.0325,  0.0202,  0.0368,  0.0151,  0.0342,\n",
       "         0.0258,  0.0234,  0.0251,  0.0300,  0.0288,  0.0273,  0.0321,  0.0297,\n",
       "         0.0494,  0.0158,  0.0285,  0.0372,  0.0474,  0.0394,  0.0414,  0.0234,\n",
       "         0.0215,  0.0232,  0.0512,  0.0542,  0.0233,  0.0346,  0.0339,  0.0299,\n",
       "         0.0217,  0.0494,  0.0446,  0.0281,  0.0337,  0.0264,  0.0284,  0.0275,\n",
       "         0.0436,  0.0378,  0.0382,  0.0647,  0.0230,  0.0205,  0.0480,  0.0513,\n",
       "         0.0315,  0.0357,  0.0339,  0.0303,  0.0326,  0.0506,  0.0328,  0.0204,\n",
       "         0.0381,  0.0416,  0.0173,  0.0411,  0.0272,  0.0085,  0.0156,  0.0360,\n",
       "         0.0204,  0.0305,  0.0407,  0.0119,  0.0505,  0.0621,  0.0526,  0.0305,\n",
       "         0.0336,  0.0358,  0.0229,  0.0184,  0.0481,  0.0507,  0.0355,  0.0514,\n",
       "         0.0353,  0.0256,  0.0560,  0.0376,  0.0208,  0.0431,  0.0445,  0.0349,\n",
       "         0.0406,  0.0528,  0.0362,  0.0411,  0.0235,  0.0435,  0.0254,  0.0380,\n",
       "         0.0340,  0.0437,  0.0214,  0.0261,  0.0569,  0.0366,  0.0340,  0.0397,\n",
       "         0.0292,  0.0318,  0.0499,  0.0217,  0.0362,  0.0489,  0.0325,  0.0299,\n",
       "         0.0347,  0.0140,  0.0401,  0.0337,  0.0293,  0.0319,  0.0401,  0.0166,\n",
       "         0.0409,  0.0283,  0.0460,  0.0292, -0.0452,  0.0404,  0.0409,  0.0639,\n",
       "         0.0544,  0.0192,  0.0343,  0.0396,  0.0338,  0.0390,  0.0247,  0.0402,\n",
       "         0.0303,  0.0520,  0.0566,  0.0459,  0.0324,  0.0446,  0.0416,  0.0417,\n",
       "         0.0429,  0.0408,  0.0326,  0.0238,  0.0261,  0.0343,  0.0249,  0.0375,\n",
       "         0.0517,  0.0296,  0.0351,  0.0362,  0.0383,  0.0249,  0.0307,  0.0346,\n",
       "         0.0210,  0.0310,  0.0382,  0.0436,  0.0326,  0.0161,  0.0220,  0.0578,\n",
       "         0.0383,  0.0368,  0.0376,  0.0232,  0.0282,  0.0396,  0.0293,  0.0221,\n",
       "         0.0396,  0.0393,  0.0216,  0.0416,  0.0284,  0.0104,  0.0295,  0.0528,\n",
       "         0.0223,  0.0359,  0.0386,  0.0502,  0.0375,  0.0359,  0.0299,  0.0444,\n",
       "         0.0233,  0.0225,  0.0430,  0.0231,  0.0368,  0.0465,  0.0291,  0.0449,\n",
       "         0.0453, -0.0254,  0.0386,  0.0067,  0.0203,  0.0294,  0.0479,  0.0145,\n",
       "         0.0424,  0.0439,  0.0434,  0.0364,  0.0114,  0.0381,  0.0510,  0.0276,\n",
       "         0.0504,  0.0410,  0.0253,  0.0479,  0.0389,  0.0160,  0.0780,  0.0393,\n",
       "         0.0206,  0.0410,  0.0437,  0.0506,  0.0463,  0.0419,  0.0185,  0.0493],\n",
       "       device='cuda:0')), ('fc1.weight', tensor([[-0.0307,  0.1376, -0.1259,  ...,  0.1168, -0.0896,  0.1418],\n",
       "        [-0.0776,  0.0154,  0.0732,  ...,  0.1017,  0.0250,  0.1068],\n",
       "        [ 0.1295,  0.0259,  0.0450,  ...,  0.0666, -0.1836,  0.0254],\n",
       "        ...,\n",
       "        [-0.0734,  0.1149, -0.0034,  ...,  0.0244,  0.0729,  0.0403],\n",
       "        [ 0.0233, -0.0057, -0.1105,  ...,  0.0581,  0.0574,  0.0630],\n",
       "        [ 0.0348, -0.0349, -0.0884,  ..., -0.0703,  0.0813, -0.0675]],\n",
       "       device='cuda:0')), ('fc1.bias', tensor([ 0.0504,  0.0212,  0.0022,  0.0093,  0.0279,  0.0439,  0.0426,  0.0800,\n",
       "         0.0185,  0.0387,  0.0355, -0.0141,  0.0065,  0.0312,  0.0551,  0.0058,\n",
       "         0.0553,  0.0417,  0.0232,  0.0351,  0.0283,  0.0414,  0.0464,  0.0411,\n",
       "         0.0505,  0.0191,  0.0164, -0.0267,  0.0300,  0.0226,  0.0367,  0.0480,\n",
       "         0.0487,  0.0170,  0.0403,  0.0387,  0.0288,  0.0126,  0.0152,  0.0068,\n",
       "        -0.0252,  0.0085,  0.0476,  0.0299,  0.0429,  0.0683, -0.0072,  0.0150,\n",
       "         0.0333,  0.0331,  0.0442,  0.0381,  0.0241,  0.0525,  0.0020,  0.0364,\n",
       "         0.0290,  0.0310,  0.0431,  0.0215, -0.0232,  0.0296,  0.0324,  0.0382,\n",
       "         0.0364,  0.0607,  0.0559,  0.0478,  0.0713,  0.0584,  0.0340,  0.0627,\n",
       "         0.0277,  0.0508,  0.0381,  0.0389,  0.0223,  0.0102,  0.0263,  0.0363,\n",
       "         0.0284,  0.0330,  0.0585,  0.0214,  0.0577,  0.0327,  0.0353,  0.0040,\n",
       "         0.0646,  0.0359,  0.0555,  0.0409,  0.0464,  0.0225,  0.0331,  0.1127,\n",
       "         0.0509,  0.0386,  0.0013,  0.0639,  0.0400,  0.0592,  0.0370,  0.0509,\n",
       "         0.0241,  0.0281,  0.0544,  0.0423,  0.0530,  0.0372,  0.0399,  0.0856,\n",
       "         0.0171, -0.0294,  0.0445,  0.0151,  0.0490,  0.0433,  0.0189,  0.0435,\n",
       "         0.0258,  0.0083,  0.0336,  0.0276,  0.0512,  0.0406,  0.0370,  0.0197,\n",
       "         0.0316,  0.0330,  0.0477,  0.0169,  0.0220,  0.0433,  0.0575,  0.0413,\n",
       "         0.0679,  0.0384, -0.0251,  0.0254,  0.0546,  0.0362,  0.0482,  0.0326,\n",
       "         0.0263, -0.0047, -0.0019,  0.0080, -0.0008,  0.0616, -0.0103,  0.0510,\n",
       "         0.0318,  0.0506,  0.0032,  0.0481,  0.0234,  0.0524,  0.0317,  0.0267,\n",
       "         0.0231,  0.0564, -0.0108,  0.0599,  0.0200,  0.0225,  0.0330,  0.0373,\n",
       "         0.0364,  0.0255,  0.0035,  0.0215,  0.0492,  0.0392,  0.0290,  0.0336,\n",
       "         0.0435,  0.0183,  0.0220,  0.0075,  0.0397,  0.0468,  0.0087,  0.0283,\n",
       "         0.0179,  0.0056,  0.0041,  0.0308,  0.0331,  0.0268,  0.0514,  0.0010],\n",
       "       device='cuda:0')), ('dec_fc.weight', tensor([[-0.0114,  0.0572, -0.0272,  ..., -0.0415,  0.0233,  0.0115],\n",
       "        [-0.0003, -0.0729,  0.0486,  ...,  0.0926, -0.0621, -0.0563],\n",
       "        [-0.0375, -0.0020, -0.0117,  ..., -0.0593,  0.0189,  0.0245],\n",
       "        ...,\n",
       "        [-0.0326,  0.0691, -0.0299,  ..., -0.0161,  0.0336,  0.0115],\n",
       "        [-0.0013,  0.0943,  0.0008,  ..., -0.0436,  0.0268,  0.0173],\n",
       "        [-0.0258,  0.0902, -0.0465,  ..., -0.0315,  0.0217,  0.0177]],\n",
       "       device='cuda:0')), ('dec_fc.bias', tensor([-0.1765,  0.1406, -0.0783,  ..., -0.0784, -0.0632, -0.0761],\n",
       "       device='cuda:0')), ('encoder.base.bn0.weight', tensor([1.2579, 1.2287, 1.1752, 1.1472, 1.1341, 1.1017, 1.0914, 1.0787, 1.0651,\n",
       "        1.0756, 1.0683, 1.0589, 1.0478, 1.0323, 1.0432, 1.0094, 1.0038, 1.0202,\n",
       "        1.0210, 1.0268, 1.0409, 1.0565, 1.0200, 1.0603, 1.0618, 1.0505, 1.0631,\n",
       "        1.0512, 1.0770, 1.0790, 1.0833, 1.0788, 1.0826, 1.0741, 1.0893, 1.0994,\n",
       "        1.1181, 1.1037, 1.1052, 1.1233, 1.1174, 1.1264, 1.1512, 1.1866, 1.2267,\n",
       "        1.2610, 1.2632, 1.3015, 1.2884, 1.3413, 1.3513, 1.3659, 1.3383, 1.3445,\n",
       "        1.3790, 1.3468, 1.3447, 1.3394, 1.2890, 1.2610, 1.2722, 1.2695, 1.2540,\n",
       "        1.2942], device='cuda:0')), ('encoder.base.bn0.bias', tensor([ 0.1418,  0.1614,  0.2051,  0.2250,  0.2054,  0.2128,  0.2234,  0.2539,\n",
       "         0.2251,  0.2122,  0.2185,  0.2002,  0.2017,  0.1822,  0.1683,  0.1444,\n",
       "         0.1269,  0.1714,  0.1422,  0.1387,  0.1513,  0.1419,  0.1510,  0.1334,\n",
       "         0.1520,  0.1332,  0.1163,  0.1276,  0.1073,  0.1257,  0.1314,  0.1131,\n",
       "         0.1414,  0.1328,  0.1064,  0.1035,  0.0991,  0.1022,  0.1113,  0.1031,\n",
       "         0.0918,  0.0667,  0.0340,  0.0058, -0.0343, -0.0510, -0.0735, -0.0952,\n",
       "        -0.1210, -0.1620, -0.1719, -0.1713, -0.1978, -0.1898, -0.2296, -0.2104,\n",
       "        -0.2010, -0.2143, -0.1837, -0.2698, -0.2991, -0.3428, -0.3216, -0.2706],\n",
       "       device='cuda:0')), ('encoder.base.bn0.running_mean', tensor([-11.1140, -11.0367, -11.6734, -12.0733, -12.2690, -13.1829, -12.8244,\n",
       "        -13.8654, -13.6266, -14.1256, -14.2417, -14.2807, -15.1179, -14.4914,\n",
       "        -15.3485, -15.0152, -15.6214, -15.3768, -15.8950, -15.9210, -16.0077,\n",
       "        -16.3230, -16.5533, -16.4185, -16.8656, -16.9338, -17.1143, -17.2644,\n",
       "        -17.5348, -17.6393, -17.8601, -18.0469, -18.2951, -18.5422, -18.7396,\n",
       "        -18.8787, -19.0903, -19.3984, -19.7062, -19.8755, -20.3276, -20.6704,\n",
       "        -20.9696, -21.2577, -21.5934, -21.9502, -22.1573, -22.3885, -22.6773,\n",
       "        -23.0146, -23.3851, -23.7347, -23.9969, -24.3780, -24.8172, -25.1915,\n",
       "        -25.6874, -26.2066, -26.6295, -27.0645, -27.5256, -27.8966, -28.4427,\n",
       "        -29.7023], device='cuda:0')), ('encoder.base.bn0.running_var', tensor([108.5400, 100.5474, 104.6310, 106.9863, 107.7479, 114.1496, 111.6755,\n",
       "        120.0199, 117.8161, 121.8113, 122.4541, 121.5557, 126.3898, 121.3896,\n",
       "        127.6692, 124.6137, 129.6735, 125.9474, 126.5959, 126.0733, 128.5122,\n",
       "        131.1895, 132.9866, 131.1968, 136.2513, 136.4128, 137.8435, 138.7266,\n",
       "        140.4252, 142.1982, 143.6312, 146.2618, 149.1181, 150.0039, 152.3840,\n",
       "        154.4992, 157.6141, 161.5698, 165.2521, 167.2338, 169.0995, 172.5907,\n",
       "        176.6368, 178.3062, 181.3046, 186.4619, 188.5393, 190.9229, 195.1447,\n",
       "        199.3110, 203.5005, 207.1522, 209.5275, 213.5443, 217.1879, 221.1509,\n",
       "        225.1093, 229.9661, 233.8673, 238.2281, 244.0726, 246.9852, 253.2982,\n",
       "        270.9163], device='cuda:0')), ('encoder.base.bn0.num_batches_tracked', tensor(586728, device='cuda:0')), ('encoder.base.conv_block1.conv1.weight', tensor([[[[-3.7039e-02, -4.2758e-01,  4.6078e-01],\n",
       "          [-9.8838e-02, -4.7424e-01,  3.5086e-01],\n",
       "          [ 5.4757e-02, -2.9605e-01,  4.8484e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.3487e-01, -2.7748e-01, -2.2969e-01],\n",
       "          [-2.5529e-03, -1.0134e-01, -9.9216e-02],\n",
       "          [ 8.8498e-02,  4.3399e-01,  3.1902e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.8117e-01,  2.1679e-01,  8.6598e-03],\n",
       "          [-3.0433e-01,  4.2776e-01, -2.8384e-02],\n",
       "          [-3.1323e-01,  3.7712e-01, -8.6349e-02]]],\n",
       "\n",
       "\n",
       "        [[[-5.1328e-01, -4.7214e-01, -1.5421e-01],\n",
       "          [-7.4739e-03,  1.5373e-01, -9.9434e-02],\n",
       "          [ 5.1257e-01,  3.8470e-01,  2.0314e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.2202e-01,  1.1475e-01,  1.7375e-01],\n",
       "          [ 4.6711e-02, -2.4738e-01, -1.1763e-01],\n",
       "          [-1.2941e-01, -1.4176e-01, -8.9102e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.6680e-01, -5.6923e-01, -3.8833e-01],\n",
       "          [ 7.2493e-01, -2.7824e-01,  9.7279e-03],\n",
       "          [ 2.4725e-01, -1.6016e-01,  9.7753e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4617e-01,  1.1877e-01,  9.5465e-02],\n",
       "          [ 5.3723e-02,  1.6259e-02,  3.4303e-02],\n",
       "          [-2.3713e-01, -1.7044e-01, -7.7720e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.7280e-01,  5.4870e-01, -3.0124e-01],\n",
       "          [-3.1358e-01,  4.4885e-01, -2.8404e-01],\n",
       "          [-1.4353e-01,  5.0320e-01, -2.3500e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.4014e-04, -6.3007e-02, -2.5290e-01],\n",
       "          [-1.3695e-02, -7.0924e-02, -1.0243e-01],\n",
       "          [ 1.5860e-01,  2.4922e-01,  7.3565e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.2324e-01, -2.8807e-01,  7.9693e-01],\n",
       "          [-2.5401e-01, -1.1556e-01,  2.5972e-01],\n",
       "          [-2.0476e-01, -4.7462e-01, -3.4198e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.0406e-01,  5.1279e-02, -3.6834e-01],\n",
       "          [-2.3591e-01,  2.6704e-01,  1.5689e-01],\n",
       "          [-2.8982e-01, -2.9980e-02,  1.7038e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 7.3808e-02, -2.1475e-01,  2.4791e-01],\n",
       "          [-1.5626e-01, -2.8334e-01,  9.1087e-02],\n",
       "          [-8.4360e-02, -1.1746e-01,  1.6794e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.2985e-01, -1.6245e-01, -3.5523e-01],\n",
       "          [ 5.0251e-01, -1.0382e-01, -3.8975e-01],\n",
       "          [ 2.4276e-01,  5.4808e-02, -2.7259e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.4744e-01,  2.3009e-01,  8.3530e-01],\n",
       "          [-1.4976e-01, -2.8275e-01,  2.4763e-01],\n",
       "          [-1.9248e-01, -3.3660e-01, -1.4239e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.4622e-02, -5.6861e-02, -4.1197e-01],\n",
       "          [ 5.7208e-01, -5.0864e-02, -4.3210e-01],\n",
       "          [ 5.4853e-01,  5.0650e-02, -3.2082e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.6556e-01, -5.3412e-01, -2.3066e-01],\n",
       "          [-2.8875e-02,  2.4764e-02, -1.6386e-01],\n",
       "          [-3.9200e-03,  5.5788e-01,  2.6252e-01]]],\n",
       "\n",
       "\n",
       "        [[[-6.1720e-01, -4.7870e-01,  1.1784e-01],\n",
       "          [-2.0684e-01,  6.2280e-02,  4.1311e-01],\n",
       "          [ 5.6433e-02,  4.4781e-02,  4.6758e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.1200e-01,  2.7321e-01, -3.9600e-02],\n",
       "          [-3.1901e-01,  3.1452e-01, -2.7479e-03],\n",
       "          [-3.3993e-01,  3.6536e-01,  5.1426e-04]]],\n",
       "\n",
       "\n",
       "        [[[-2.2003e-01,  1.8998e-01,  1.2129e-01],\n",
       "          [-2.7666e-01,  9.2499e-02, -4.6375e-02],\n",
       "          [-1.4448e-01,  6.8090e-02,  7.0098e-02]]],\n",
       "\n",
       "\n",
       "        [[[-9.7226e-02, -1.2127e-01,  2.3658e-01],\n",
       "          [-2.4300e-01, -1.9383e-01,  1.1952e-01],\n",
       "          [ 2.2897e-02, -8.7058e-02,  3.2172e-01]]],\n",
       "\n",
       "\n",
       "        [[[-6.3028e-02, -2.3576e-01,  4.1035e-02],\n",
       "          [ 1.6508e-01, -1.1036e-01,  9.5125e-02],\n",
       "          [-2.9840e-03,  1.8085e-01,  2.6306e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.4316e-01,  1.1665e+00, -4.3412e-01],\n",
       "          [ 6.2403e-02, -5.5574e-01,  1.2445e-01],\n",
       "          [ 5.2582e-02, -3.2262e-01,  1.8072e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.5395e-01,  6.7191e-01, -4.2608e-01],\n",
       "          [ 1.4435e-01,  7.4019e-01, -1.7308e-01],\n",
       "          [-2.6455e-01, -1.5263e-02, -2.0942e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5521e-01, -2.1611e-01,  7.1947e-02],\n",
       "          [ 3.0966e-01, -3.0091e-01, -7.8164e-03],\n",
       "          [ 3.0483e-01, -3.1466e-01,  1.5690e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.9823e-01, -4.2168e-01,  6.0279e-02],\n",
       "          [-3.2808e-01, -3.3818e-01,  3.4307e-01],\n",
       "          [-9.1788e-02,  2.4978e-01,  6.2914e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0916e-01, -1.0632e-02,  4.5488e-01],\n",
       "          [ 1.1837e-02, -5.0426e-01,  5.5825e-02],\n",
       "          [ 1.8273e-01, -5.3850e-01,  8.3406e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 4.7359e-01, -1.8598e-01,  2.1945e-02],\n",
       "          [ 2.8800e-01, -1.5747e-01, -1.0243e-01],\n",
       "          [ 1.2883e-01, -3.4466e-01, -1.4244e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.6872e-01, -1.4464e-01,  2.2020e-01],\n",
       "          [-2.9175e-01,  2.2592e-01,  2.0379e-01],\n",
       "          [-1.6604e-01,  2.6496e-01, -8.3792e-02]]],\n",
       "\n",
       "\n",
       "        [[[-9.5360e-02,  3.8966e-01,  1.4031e-01],\n",
       "          [ 1.2257e-02,  2.1597e-02, -4.7005e-02],\n",
       "          [ 9.1067e-02, -1.6526e-01, -1.9378e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0163e-01, -4.5580e-01,  3.1707e-01],\n",
       "          [ 1.8935e-01, -4.5179e-01,  2.3650e-01],\n",
       "          [ 2.7485e-01, -4.0986e-01,  2.1443e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.7262e-01, -1.0266e-01, -4.1695e-01],\n",
       "          [ 4.8492e-01, -2.3177e-03, -4.4562e-01],\n",
       "          [ 3.3022e-01,  6.2551e-02, -3.2547e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.2101e-01,  1.0126e-01, -3.6913e-02],\n",
       "          [ 1.4700e-01,  6.9705e-02, -3.9404e-02],\n",
       "          [-5.5072e-02, -1.1184e-01, -6.6921e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.8531e-01, -4.7569e-02, -2.3400e-01],\n",
       "          [ 3.4791e-01, -7.7497e-02, -2.4477e-01],\n",
       "          [ 3.7497e-01, -1.4277e-01, -3.4089e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1033e+00,  1.2753e-01, -6.2010e-03],\n",
       "          [-7.2243e-01, -4.6420e-01, -5.2412e-03],\n",
       "          [-3.7374e-01,  4.0990e-01, -7.4779e-02]]],\n",
       "\n",
       "\n",
       "        [[[-6.1552e-01,  5.3512e-01,  8.1034e-02],\n",
       "          [-1.1637e-01,  3.2702e-02,  9.7668e-03],\n",
       "          [ 7.4868e-01, -5.4375e-01, -1.1775e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.5149e-01,  1.8367e-01,  5.9942e-01],\n",
       "          [ 6.4945e-02, -3.3298e-01,  4.7456e-02],\n",
       "          [-7.2457e-02, -6.4503e-01, -2.3545e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.3996e-01, -4.6708e-01,  6.5029e-02],\n",
       "          [ 4.1431e-01, -5.8810e-01, -1.2947e-01],\n",
       "          [ 6.3620e-01, -4.6198e-01,  8.9512e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.8400e-01,  6.0769e-01,  3.9696e-01],\n",
       "          [-1.0041e-01, -5.5067e-02, -6.5041e-02],\n",
       "          [-4.0160e-01, -5.5484e-01, -4.9943e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.7577e-01,  9.2406e-02,  9.8464e-02],\n",
       "          [-2.4153e-01, -1.5672e-02,  1.2420e-01],\n",
       "          [-6.3149e-01, -2.6339e-02,  4.9605e-02]]],\n",
       "\n",
       "\n",
       "        [[[-4.2362e-01, -4.3782e-01, -5.7199e-01],\n",
       "          [ 5.7036e-02,  1.7327e-01,  5.8640e-02],\n",
       "          [ 3.2428e-01,  2.6780e-01,  1.1553e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.2817e-02,  2.5345e-01, -2.3407e-01],\n",
       "          [ 6.5310e-02,  1.0996e-01, -1.5513e-01],\n",
       "          [-2.7904e-02,  2.7827e-01, -2.4337e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1770e-01,  3.1490e-01, -9.0855e-01],\n",
       "          [-1.3766e-01,  3.3192e-03,  7.7066e-01],\n",
       "          [-5.3093e-02, -3.6863e-01,  2.3213e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 5.5213e-02, -4.4828e-01,  6.2535e-02],\n",
       "          [ 5.3619e-02, -4.0840e-01,  4.2392e-03],\n",
       "          [ 2.0112e-01, -2.2866e-01,  3.0056e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9792e-01,  2.0081e-01,  1.9037e-01],\n",
       "          [-2.4127e-01, -3.5608e-01, -2.4821e-01],\n",
       "          [-3.8929e-02,  1.7353e-01, -4.8857e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.0018e-01,  1.3077e-03, -2.7321e-01],\n",
       "          [ 2.7165e-02,  3.3843e-02, -7.1168e-02],\n",
       "          [ 5.3553e-02,  2.3183e-01, -4.2740e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.8983e-01, -3.7882e-02,  7.5205e-01],\n",
       "          [-4.3510e-01, -2.7665e-01,  5.3879e-01],\n",
       "          [-3.7065e-01, -1.9793e-01,  3.8153e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0559e-01,  3.1273e-01,  1.5594e-01],\n",
       "          [ 1.7393e-01, -6.1596e-02, -2.1482e-01],\n",
       "          [ 1.0072e-01, -3.6248e-01, -2.6370e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0709e-01, -2.5422e-01,  5.1832e-02],\n",
       "          [ 2.1006e-01, -1.3040e-01, -6.3120e-02],\n",
       "          [ 6.7084e-02, -9.1186e-02,  8.9826e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.0937e-01,  3.9595e-01,  2.2122e-01],\n",
       "          [-1.6386e-01,  2.8206e-02, -1.7149e-01],\n",
       "          [-4.2785e-01, -1.2610e-01, -1.6499e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.4867e-01, -2.5180e-01, -3.5126e-01],\n",
       "          [-1.1301e-01, -1.2536e-01, -8.0463e-02],\n",
       "          [ 8.8822e-01,  3.9861e-01,  2.1695e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0753e-02,  4.4991e-02, -2.4421e-01],\n",
       "          [ 9.5658e-03,  2.3654e-01, -2.5991e-01],\n",
       "          [ 2.4366e-02,  3.8166e-01, -2.2451e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.7838e-01, -5.9983e-02,  1.4472e-01],\n",
       "          [ 2.1890e-01, -8.2260e-02,  3.5236e-02],\n",
       "          [-1.6305e-01, -5.5475e-01, -3.4149e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.1640e-01,  7.8737e-02, -1.7762e-01],\n",
       "          [-1.4516e-02,  1.3225e-01,  2.5413e-02],\n",
       "          [-2.8115e-02,  1.8151e-01, -3.3639e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.3240e-01, -3.6960e-01, -1.5010e-01],\n",
       "          [ 6.2620e-02,  2.2893e-02,  1.1247e-01],\n",
       "          [ 2.6827e-01,  3.7458e-01, -8.5182e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0860e-01,  1.1462e+00, -4.2346e-02],\n",
       "          [-1.4127e-01,  3.0784e-01, -4.1399e-02],\n",
       "          [-3.6094e-01, -1.9679e-01, -2.6113e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.3481e-01, -2.5167e-01,  3.8530e-01],\n",
       "          [-1.3977e-01, -3.6216e-01,  1.1309e-03],\n",
       "          [ 2.0413e-01, -4.5980e-01,  2.9574e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 7.7680e-02,  2.6627e-01, -2.8784e-01],\n",
       "          [-3.3592e-01,  2.4736e-01, -1.2399e-01],\n",
       "          [-2.8255e-01,  8.0267e-01, -4.0267e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.3659e-01, -5.6885e-01, -5.8263e-02],\n",
       "          [ 2.3202e-01, -3.7275e-01,  4.3137e-02],\n",
       "          [ 2.3751e-01, -1.1991e-01,  2.6967e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.7833e-01,  6.2141e-01,  4.1701e-01],\n",
       "          [-9.2735e-02, -3.6468e-02, -3.5021e-01],\n",
       "          [-5.1336e-02,  1.1924e-01, -1.3558e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 7.9185e-01,  2.7757e-01,  1.5429e-01],\n",
       "          [ 2.0638e-01, -9.3221e-02, -4.2492e-02],\n",
       "          [-3.6869e-01, -2.5070e-01, -3.6196e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.1912e-01, -3.4506e-01, -2.0505e-01],\n",
       "          [-3.5524e-02,  5.3625e-02,  3.3577e-01],\n",
       "          [ 1.5814e-01, -1.6911e-02,  5.5144e-01]]],\n",
       "\n",
       "\n",
       "        [[[-7.1422e-01, -9.4341e-02,  4.3752e-02],\n",
       "          [ 1.3863e+00, -7.7188e-02,  1.9691e-02],\n",
       "          [-3.5302e-01, -1.1650e-01, -4.4031e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.5821e-01,  1.7370e-01,  3.0065e-01],\n",
       "          [-4.7475e-01, -6.5231e-01, -4.0496e-01],\n",
       "          [ 1.6438e-01,  4.0722e-01,  1.4705e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.6765e-01, -3.5122e-01, -3.0718e-01],\n",
       "          [-3.7997e-02, -1.8845e-01,  5.6407e-02],\n",
       "          [ 2.3948e-01,  2.0316e-01,  6.8780e-01]]]], device='cuda:0')), ('encoder.base.conv_block1.conv2.weight', tensor([[[[ 3.7716e-02,  3.8377e-01, -2.6829e-02],\n",
       "          [ 1.4405e-02, -2.7071e-02, -1.1790e-01],\n",
       "          [ 3.1483e-02, -1.2675e-01,  1.0402e-01]],\n",
       "\n",
       "         [[-1.3191e-01,  5.1577e-02,  9.3906e-02],\n",
       "          [-1.0973e-01,  1.2606e-01,  6.9330e-02],\n",
       "          [-7.9789e-02,  1.4824e-01, -2.2891e-01]],\n",
       "\n",
       "         [[ 8.4112e-02, -6.5050e-02,  2.2053e-02],\n",
       "          [-1.6003e-02,  3.6255e-02, -1.0961e-01],\n",
       "          [ 2.1383e-03,  1.7355e-01, -2.0730e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.2900e-01, -9.4333e-02, -4.8292e-01],\n",
       "          [ 1.5381e-01, -8.5188e-03,  2.9697e-02],\n",
       "          [ 1.7547e-01,  5.9568e-02,  4.1180e-01]],\n",
       "\n",
       "         [[-6.4412e-02,  2.3372e-02, -8.3541e-02],\n",
       "          [-5.3537e-02, -8.9693e-02, -1.3112e-02],\n",
       "          [-5.3418e-02, -4.0995e-02,  1.0250e-01]],\n",
       "\n",
       "         [[-2.1671e-01,  2.8036e-02, -1.3197e-04],\n",
       "          [-3.4290e-02,  5.9299e-02, -1.8906e-02],\n",
       "          [-5.3243e-02, -4.2178e-02,  2.6321e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0785e+00, -2.0748e-01,  7.5568e-02],\n",
       "          [ 2.0621e-01, -5.9543e-02,  6.3722e-02],\n",
       "          [-6.5188e-01, -1.2228e-02,  1.1816e-01]],\n",
       "\n",
       "         [[-1.2173e-01,  1.9149e-01,  8.3929e-02],\n",
       "          [ 8.3358e-02, -2.0013e-01, -1.1041e-02],\n",
       "          [ 2.7151e-01, -3.6403e-01, -4.3889e-02]],\n",
       "\n",
       "         [[-1.7432e-01,  1.5744e-01, -2.0128e-01],\n",
       "          [ 2.6894e-02, -1.1746e-01, -5.5749e-03],\n",
       "          [ 2.9326e-01, -4.2377e-01,  5.7002e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.5385e-01, -8.2642e-01,  3.3079e-01],\n",
       "          [-4.6052e-02, -1.7915e-01,  1.1808e-01],\n",
       "          [-5.4963e-01,  1.0333e+00, -2.4473e-01]],\n",
       "\n",
       "         [[-6.9922e-02,  1.3253e-01,  8.7043e-02],\n",
       "          [ 1.5732e-01,  1.6859e-01, -2.4649e-02],\n",
       "          [ 4.5574e-02, -1.4071e-01, -1.5539e-01]],\n",
       "\n",
       "         [[ 1.2706e-01,  3.1828e-02,  1.1200e-01],\n",
       "          [ 9.8312e-02,  3.1909e-02,  8.6010e-02],\n",
       "          [ 1.4542e-02, -3.4562e-04,  8.4735e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.7297e-02, -1.1035e-01, -1.1087e-01],\n",
       "          [-7.3131e-02, -9.5376e-02, -9.5487e-02],\n",
       "          [-8.0729e-02, -9.2381e-04,  2.4190e-02]],\n",
       "\n",
       "         [[-1.7203e-01, -4.6300e-01,  2.5281e-01],\n",
       "          [-1.5188e-01, -4.7515e-01, -3.0280e-02],\n",
       "          [ 6.9937e-02, -1.2466e-01,  4.5305e-01]],\n",
       "\n",
       "         [[ 8.2297e-02,  1.0682e-01,  2.8612e-02],\n",
       "          [ 1.3627e-01,  4.2858e-02, -3.2870e-02],\n",
       "          [-3.5023e-02, -7.2602e-02, -2.1970e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.8166e-02,  1.6987e-01,  2.3324e-01],\n",
       "          [ 2.0293e-01, -1.0903e-02, -1.6093e-01],\n",
       "          [ 1.5683e-01, -1.1523e-01, -3.9176e-01]],\n",
       "\n",
       "         [[ 2.7918e-02, -5.2651e-02, -3.0204e-02],\n",
       "          [-6.0518e-02, -1.3612e-01, -2.5142e-01],\n",
       "          [ 8.2353e-02, -6.1556e-02,  5.9971e-02]],\n",
       "\n",
       "         [[-7.5691e-02, -5.9457e-03, -4.2270e-02],\n",
       "          [-4.8160e-02, -3.5608e-02, -2.8247e-02],\n",
       "          [-1.7834e-02, -7.6805e-02,  2.5366e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-4.9454e-02, -5.7105e-03, -8.8107e-02],\n",
       "          [-3.6103e-02,  2.0379e-01,  3.4189e-01],\n",
       "          [-4.2215e-02, -2.1860e-01, -2.4045e-01]],\n",
       "\n",
       "         [[-3.0638e-01, -1.8374e-01, -3.8692e-01],\n",
       "          [ 4.3731e-01,  6.7990e-01,  3.9994e-01],\n",
       "          [-3.8064e-01, -3.3509e-01, -6.1751e-01]],\n",
       "\n",
       "         [[-1.5306e-02, -1.0777e-02, -4.1142e-02],\n",
       "          [-8.7511e-02, -1.0601e-01, -1.5231e-01],\n",
       "          [-1.8568e-02,  3.6170e-02, -7.9173e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.1569e-01,  2.8898e-01,  3.5592e-01],\n",
       "          [-1.0991e+00, -7.5708e-01, -8.5644e-01],\n",
       "          [ 6.9730e-01,  1.2808e-01,  4.9305e-01]],\n",
       "\n",
       "         [[-6.9309e-02, -2.3946e-02, -6.7120e-02],\n",
       "          [ 7.7438e-02,  7.9852e-02, -2.2187e-02],\n",
       "          [-5.7858e-02, -7.3175e-03, -4.6205e-02]],\n",
       "\n",
       "         [[ 2.4485e-01,  3.5203e-01,  1.8942e-01],\n",
       "          [-2.1788e-01, -1.4184e-01, -1.8707e-01],\n",
       "          [-1.7722e-01, -9.8066e-02, -2.2995e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.2625e-02,  1.0379e-02, -8.0609e-02],\n",
       "          [ 5.3149e-02, -9.3726e-02, -1.0543e-01],\n",
       "          [ 4.8197e-02, -5.4563e-02, -4.1949e-02]],\n",
       "\n",
       "         [[ 1.4315e-02,  7.2706e-02, -6.4910e-02],\n",
       "          [-3.9319e-02, -1.9981e-01, -9.3217e-02],\n",
       "          [ 5.4948e-02,  7.2174e-02,  5.5379e-02]],\n",
       "\n",
       "         [[-2.6129e-02, -1.1373e-02, -1.9768e-02],\n",
       "          [ 2.1967e-02,  6.3522e-02,  1.2756e-02],\n",
       "          [ 9.7849e-02,  8.7106e-02,  4.9843e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.5595e-02, -1.5106e-01,  2.8897e-01],\n",
       "          [ 9.5800e-02, -1.1059e-01,  1.5325e-01],\n",
       "          [ 2.9394e-02, -2.9501e-02,  1.2501e-01]],\n",
       "\n",
       "         [[ 1.2613e-01,  6.3016e-02,  2.7176e-02],\n",
       "          [-5.3751e-02, -8.8469e-02, -2.4307e-02],\n",
       "          [ 7.0750e-02,  2.2604e-02,  1.4919e-02]],\n",
       "\n",
       "         [[ 2.6332e-02, -2.9871e-02,  7.3902e-02],\n",
       "          [ 5.8938e-02,  8.6006e-02,  3.4223e-02],\n",
       "          [-2.8744e-02,  8.2594e-03,  1.7609e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7435e-01,  4.7874e-02,  7.0055e-02],\n",
       "          [ 8.6948e-02,  3.3030e-01,  1.3110e-01],\n",
       "          [ 1.5556e-01,  3.2963e-01,  1.5869e-01]],\n",
       "\n",
       "         [[-6.3539e-01, -6.0424e-01, -2.4252e-01],\n",
       "          [-1.3502e-01, -1.3486e-01, -3.6140e-01],\n",
       "          [-5.2280e-01, -4.7667e-01, -5.4187e-01]],\n",
       "\n",
       "         [[ 1.0034e-01, -3.9097e-01, -6.2816e-01],\n",
       "          [-5.8587e-02, -3.5102e-01, -4.4382e-01],\n",
       "          [-1.9356e-02, -2.9316e-01, -2.4458e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3339e-01, -3.5807e-01, -7.3283e-03],\n",
       "          [ 9.7241e-03, -1.2542e-01,  4.9291e-02],\n",
       "          [ 2.5228e-01, -1.4051e-01, -8.6471e-02]],\n",
       "\n",
       "         [[-6.5190e-02, -1.7026e-01, -9.0556e-02],\n",
       "          [ 1.3915e-01, -3.3030e-02, -7.1347e-02],\n",
       "          [-2.2762e-05, -1.7184e-01, -1.6950e-02]],\n",
       "\n",
       "         [[ 7.2244e-02,  7.6516e-02, -2.7654e-03],\n",
       "          [ 1.0507e-01, -4.3255e-04,  5.2007e-02],\n",
       "          [ 2.0332e-02,  1.0466e-01,  5.0690e-02]]]], device='cuda:0')), ('encoder.base.conv_block1.bn1.weight', tensor([1.0147, 1.8317, 0.8301, 1.2968, 0.5953, 0.7233, 0.7475, 1.2259, 0.7721,\n",
       "        1.0568, 1.3650, 0.3360, 0.4459, 0.6781, 0.6541, 0.3440, 0.5908, 1.0499,\n",
       "        0.6292, 0.5092, 0.6707, 2.1327, 1.5605, 0.8525, 0.6335, 0.9048, 0.8897,\n",
       "        0.6496, 1.0510, 1.3799, 0.9359, 0.6482, 0.5818, 1.7507, 2.3637, 0.6982,\n",
       "        0.9968, 0.4719, 0.5994, 0.5357, 0.7040, 2.0022, 0.6293, 0.2890, 0.5688,\n",
       "        0.9239, 0.6793, 0.5159, 0.4398, 0.5231, 0.6452, 0.8483, 0.5375, 1.9732,\n",
       "        0.8341, 0.7305, 1.1377, 1.0964, 0.8403, 0.4709, 0.7815, 1.3541, 0.9502,\n",
       "        1.0875], device='cuda:0')), ('encoder.base.conv_block1.bn1.bias', tensor([ 0.6754,  0.1345,  0.0220,  1.3368, -0.6749,  0.0839, -1.3812, -1.3433,\n",
       "        -0.7652,  0.2082, -1.0769,  0.1627,  0.0673,  0.0511,  0.1200,  0.1681,\n",
       "         0.0150,  0.0098, -0.7188, -0.5221, -0.8065,  0.4152,  0.2131, -1.1045,\n",
       "         0.0147, -1.0571,  0.0904, -0.7248, -0.9289, -0.0724,  0.0621, -0.8089,\n",
       "         0.0928,  0.1172,  0.0503,  0.1471,  0.6545,  0.1610, -0.4684,  0.0174,\n",
       "        -0.8001,  0.3992, -0.6326,  0.1002, -0.7923,  0.0503, -0.4399, -0.1764,\n",
       "        -1.0168,  0.0272, -0.1202,  0.1499, -0.9979,  0.2602, -0.7370,  0.1048,\n",
       "         0.8390, -0.2476,  0.0871,  0.0680,  0.1174,  1.5486, -1.0039, -1.6553],\n",
       "       device='cuda:0')), ('encoder.base.conv_block1.bn1.running_mean', tensor([-2.6442e-03, -1.0105e-03, -7.4347e-03, -5.6551e-04, -5.9022e-03,\n",
       "         8.1001e-03, -7.3443e-04, -3.3866e-03, -3.5781e-06, -1.8388e-03,\n",
       "         2.9289e-04, -1.3109e-02,  4.9675e-03, -5.5409e-03,  4.4445e-03,\n",
       "        -1.7432e-02, -1.1836e-02, -6.5054e-03, -8.9932e-03, -4.7090e-03,\n",
       "         1.2896e-02,  1.2038e-03,  1.9172e-04,  3.8127e-03, -9.4586e-03,\n",
       "        -1.5608e-03,  3.7078e-03, -9.7344e-04,  6.8434e-03,  1.3096e-03,\n",
       "         5.8198e-03, -7.2441e-03,  1.2007e-02,  3.0239e-04,  6.6009e-04,\n",
       "         4.3699e-03,  6.0325e-03, -1.0725e-02, -4.3649e-02, -1.8055e-02,\n",
       "         1.5195e-03, -1.7206e-03, -1.6533e-02, -7.0380e-03, -9.7681e-03,\n",
       "        -5.4719e-03,  5.8173e-04,  8.5079e-04, -4.3638e-03,  1.9839e-02,\n",
       "         7.8969e-04,  8.3074e-03, -7.5507e-03, -1.3189e-03,  2.5798e-02,\n",
       "         5.1496e-03, -2.1499e-03,  2.5010e-03, -1.7609e-03,  1.6992e-02,\n",
       "         4.3116e-03,  3.5006e-03,  6.6559e-04, -7.5510e-04], device='cuda:0')), ('encoder.base.conv_block1.bn1.running_var', tensor([0.0990, 0.0290, 0.0589, 0.0637, 0.0521, 0.1160, 0.0099, 0.0679, 0.0146,\n",
       "        0.0908, 0.0122, 0.1292, 0.1407, 0.1051, 0.1647, 0.2356, 0.1505, 0.0526,\n",
       "        0.0477, 0.0382, 0.1537, 0.0292, 0.0740, 0.0330, 0.1240, 0.0544, 0.0538,\n",
       "        0.0369, 0.0421, 0.0523, 0.1617, 0.1542, 0.1353, 0.0649, 0.0190, 0.0816,\n",
       "        0.1264, 0.2075, 1.1808, 0.3108, 0.0238, 0.0288, 0.2683, 0.0547, 0.0837,\n",
       "        0.2347, 0.0352, 0.0102, 0.0502, 0.3289, 0.0327, 0.1034, 0.0380, 0.0303,\n",
       "        0.6256, 0.0560, 0.0578, 0.0475, 0.0395, 0.2082, 0.0961, 0.0619, 0.0489,\n",
       "        0.0635], device='cuda:0')), ('encoder.base.conv_block1.bn1.num_batches_tracked', tensor(586728, device='cuda:0')), ('encoder.base.conv_block1.bn2.weight', tensor([1.4841, 1.2917, 1.0752, 0.9392, 1.3012, 0.5648, 0.7395, 1.2967, 0.3735,\n",
       "        1.2988, 1.5531, 1.1796, 1.5098, 0.8108, 0.5671, 1.0800, 1.0263, 1.2715,\n",
       "        1.3641, 1.3163, 1.5201, 0.6631, 1.1183, 1.1883, 1.2024, 0.8789, 1.3421,\n",
       "        0.3771, 1.0490, 1.4551, 1.1245, 1.5359, 0.6782, 1.5352, 0.9282, 1.1248,\n",
       "        1.3073, 0.9236, 1.2908, 1.3024, 0.4935, 1.0720, 0.8583, 1.5085, 1.4076,\n",
       "        1.4440, 0.6413, 0.6526, 1.0588, 0.5574, 0.6595, 1.0363, 0.7635, 1.3950,\n",
       "        1.3622, 1.1709, 0.8593, 0.5827, 0.9331, 1.3578, 1.2215, 0.9420, 0.5712,\n",
       "        0.5443], device='cuda:0')), ('encoder.base.conv_block1.bn2.bias', tensor([-0.8234, -0.8081, -0.4838, -0.5944, -0.8566, -0.2404, -0.5236, -0.9160,\n",
       "        -0.0529, -0.3748, -0.7467, -0.8183, -1.0355, -0.2404, -0.3608, -0.5537,\n",
       "        -0.6094, -0.5815, -0.5941, -0.8944, -0.6258, -0.1631, -0.5619, -0.8486,\n",
       "        -0.4367, -0.3251, -0.8718, -0.0486, -0.5740, -0.9323, -0.6806, -0.7423,\n",
       "        -0.9645, -1.0283, -0.6479, -0.5786, -0.9397, -0.1561, -0.6581, -0.7995,\n",
       "        -0.1054, -0.5006, -0.2690, -0.9833, -0.6177, -1.0039, -0.5419, -0.7335,\n",
       "        -0.4527, -0.3228, -0.2103, -0.3911, -0.2588, -0.8303, -0.6102, -0.4021,\n",
       "        -0.2842, -0.4564, -0.4216, -0.6266, -0.8774, -0.5110, -0.9052, -0.2076],\n",
       "       device='cuda:0')), ('encoder.base.conv_block1.bn2.running_mean', tensor([ -7.5214,  -3.5263,  -7.6195,  -7.3292, -10.1689,  -3.5676,  -5.5123,\n",
       "         -6.4482,   2.5568,  -7.0457,  -4.9308,  -4.0243,  -5.7459,  -3.0006,\n",
       "         -0.4771,  -5.7695,  -6.4044,  -8.2480,  -9.8571,  -7.5985,  -7.1609,\n",
       "        -10.7915,  -5.2936,  -5.5477,  -4.2093, -14.3836,  -9.0733,   0.5924,\n",
       "         -5.9486,  -4.5786,  -9.5296, -18.9389,   7.1328,  -3.7252,  -4.3018,\n",
       "         -4.3027,  -9.6727, -11.4089,  -8.2913,  -4.0851,  -8.5113, -13.2303,\n",
       "         -5.4044,  -5.5494,  -6.0409,  -5.7176,  -0.3189,   2.1054, -11.1128,\n",
       "          0.1121, -10.7496,  -4.8157,  -1.3577,  -5.7857,  -4.9932,  -8.8108,\n",
       "         -5.8132,   0.7328,  -4.6833, -11.2964,  -6.6940,  -5.2393,   3.5756,\n",
       "        -13.2411], device='cuda:0')), ('encoder.base.conv_block1.bn2.running_var', tensor([ 83.4874,  49.2280,  79.8500,  65.7017, 104.6649, 147.6423,  30.4582,\n",
       "         79.2726,  38.4524, 135.0762,  43.4954,  34.0307,  43.2262,  56.8076,\n",
       "         15.2798,  73.5737, 124.5944, 136.4150, 159.5756,  71.4369,  73.7142,\n",
       "        121.5120,  84.3253,  40.6370,  41.4570, 250.3013, 146.4842,  39.3805,\n",
       "        119.0096,  81.0722,  91.1335, 299.9778,  30.1207,  33.7678,  31.2618,\n",
       "         38.2270,  95.4588, 211.1729, 157.5682,  25.0145,  58.4743, 142.2299,\n",
       "         40.8495,  94.0520,  56.1689,  40.2752,  15.1789,  34.4148, 209.8351,\n",
       "         20.2163,  81.0546,  39.9090,  31.7404,  59.5921,  76.8075, 138.7216,\n",
       "        183.5796,  25.3117,  73.6397, 243.3807,  62.6100,  55.8699,  17.5195,\n",
       "        227.4245], device='cuda:0')), ('encoder.base.conv_block1.bn2.num_batches_tracked', tensor(586728, device='cuda:0')), ('encoder.base.conv_block2.conv1.weight', tensor([[[[-6.6612e-02, -5.9600e-02, -3.3646e-02],\n",
       "          [-9.0082e-03, -3.4218e-02, -1.2638e-01],\n",
       "          [-1.5268e-01, -5.2480e-02, -6.7372e-02]],\n",
       "\n",
       "         [[ 1.1773e-01,  1.3273e-01,  1.4331e-01],\n",
       "          [ 1.5485e-02, -5.2641e-02,  6.5574e-02],\n",
       "          [ 3.9865e-02,  6.6218e-02,  1.6867e-01]],\n",
       "\n",
       "         [[ 9.3612e-03, -3.2874e-03, -5.0931e-03],\n",
       "          [ 1.0213e-02,  2.7881e-02,  5.9696e-02],\n",
       "          [ 2.5336e-03,  5.3899e-02,  1.0334e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.3382e-02,  6.7181e-02,  6.3629e-02],\n",
       "          [-8.2463e-03,  3.0971e-02,  3.6543e-02],\n",
       "          [-3.2838e-02, -5.4525e-02, -1.0010e-01]],\n",
       "\n",
       "         [[ 5.8703e-03, -5.4488e-03, -7.4210e-03],\n",
       "          [-8.8855e-03,  9.4491e-03, -2.4393e-02],\n",
       "          [ 4.0046e-02,  2.7267e-02, -2.4605e-02]],\n",
       "\n",
       "         [[ 3.4274e-03, -1.7679e-02, -1.0506e-02],\n",
       "          [-6.6787e-02, -2.9965e-02, -3.4468e-02],\n",
       "          [-4.4432e-02, -1.3806e-02, -4.1295e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 5.9368e-02, -4.6169e-02, -3.1849e-02],\n",
       "          [ 1.1523e-01,  1.7957e-01,  4.6607e-02],\n",
       "          [ 5.8586e-03,  1.2307e-01,  1.4036e-02]],\n",
       "\n",
       "         [[-1.8446e-01, -2.0808e-01, -7.5956e-02],\n",
       "          [-2.9685e-01, -2.9554e-01,  5.7040e-02],\n",
       "          [-2.7504e-01,  6.5192e-02,  2.9643e-02]],\n",
       "\n",
       "         [[ 3.1143e-02,  5.7940e-02,  5.3295e-02],\n",
       "          [-1.4687e-01, -2.6303e-01,  4.0375e-02],\n",
       "          [ 8.0275e-02, -1.9773e-01,  7.4133e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.7884e-02, -6.6429e-02, -6.8187e-03],\n",
       "          [-8.8455e-02, -2.1068e-01, -1.0393e-01],\n",
       "          [ 4.0991e-02, -1.4381e-01, -1.1891e-01]],\n",
       "\n",
       "         [[ 3.8864e-02, -7.3408e-02, -1.0042e-01],\n",
       "          [ 6.2543e-02, -1.5229e-02,  3.8400e-02],\n",
       "          [-4.9299e-02, -1.4120e-01, -1.5871e-01]],\n",
       "\n",
       "         [[ 1.2304e-01,  1.6561e-01,  1.1603e-01],\n",
       "          [-3.1976e-03,  1.5427e-01,  1.0683e-01],\n",
       "          [ 1.0294e-01,  1.0579e-01,  1.8109e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.3461e-01,  3.3709e-01, -1.2679e-01],\n",
       "          [-1.1710e-01, -1.9431e-01, -2.6899e-01],\n",
       "          [ 1.2496e-01, -2.3303e-01, -3.0178e-01]],\n",
       "\n",
       "         [[-7.5645e-01, -1.8989e-02, -1.4834e-01],\n",
       "          [-1.5400e+00, -1.4846e+00, -2.8898e-01],\n",
       "          [-1.9606e+00, -1.8870e+00, -6.1143e-01]],\n",
       "\n",
       "         [[ 7.4252e-02, -3.6760e-02,  2.5229e-01],\n",
       "          [-5.4651e-03, -4.8606e-01,  6.3125e-02],\n",
       "          [ 1.1650e-01, -6.2473e-01,  9.7307e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.3681e-02,  1.0975e-01, -1.4098e-01],\n",
       "          [-1.3643e-02, -1.8806e-02, -1.1949e-01],\n",
       "          [-1.5424e-01,  2.1139e-02, -1.2501e-01]],\n",
       "\n",
       "         [[-2.0506e-01, -3.0328e-01, -7.0644e-03],\n",
       "          [ 6.5120e-02, -1.5298e-02,  8.4776e-02],\n",
       "          [ 9.8368e-02,  2.2104e-01,  4.7331e-02]],\n",
       "\n",
       "         [[ 1.0543e-02, -3.8799e-02,  1.2879e-01],\n",
       "          [-1.4161e-03, -1.6089e-01, -1.1688e-01],\n",
       "          [ 1.8923e-01,  2.9672e-02, -8.9577e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 2.5869e-01,  2.4997e-01,  1.0919e-01],\n",
       "          [ 8.0202e-02, -7.0330e-02, -1.1587e-01],\n",
       "          [-1.7754e-01, -9.0353e-02, -1.1497e-02]],\n",
       "\n",
       "         [[ 3.2115e-01,  2.9448e-01, -5.0417e-02],\n",
       "          [ 1.6544e-01,  5.9469e-02,  1.6220e-02],\n",
       "          [-3.3938e-02, -2.0441e-02,  2.2820e-01]],\n",
       "\n",
       "         [[-2.6324e-01, -2.1927e-01,  1.9276e-02],\n",
       "          [-1.1829e-01, -9.9668e-02, -3.7246e-02],\n",
       "          [-1.5414e-01, -3.0073e-01, -3.8076e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.8569e-01, -8.8609e-02, -2.7967e-01],\n",
       "          [-1.7912e-01, -1.2283e-01, -1.4729e-01],\n",
       "          [-1.1130e-01, -1.5198e-01, -4.9355e-02]],\n",
       "\n",
       "         [[-1.5297e-01, -6.4467e-02, -1.4488e-02],\n",
       "          [ 8.3452e-02,  1.1420e-01,  1.4201e-01],\n",
       "          [ 6.5947e-02,  7.5174e-02,  1.4104e-02]],\n",
       "\n",
       "         [[-3.9835e-01, -4.4832e-01,  4.2174e-02],\n",
       "          [-4.3757e-02,  3.5249e-03,  1.9157e-01],\n",
       "          [ 5.1002e-01,  2.7074e-01,  2.1804e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.0083e-01, -2.0754e-01, -1.2930e-01],\n",
       "          [-4.3015e-02,  7.0285e-02,  3.9884e-02],\n",
       "          [ 4.1164e-03, -1.0237e-02, -2.3977e-01]],\n",
       "\n",
       "         [[-2.5900e-01, -4.4998e-01,  1.5604e-01],\n",
       "          [-1.7697e-01, -4.5872e-01,  2.1617e-01],\n",
       "          [ 3.7660e-02, -7.4408e-01,  6.8443e-02]],\n",
       "\n",
       "         [[-1.1396e-01, -5.3961e-02, -3.6279e-01],\n",
       "          [ 1.1854e-01, -1.2681e-01, -2.1725e-01],\n",
       "          [ 2.6696e-01, -3.6346e-01, -9.5176e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.7260e-04, -6.8171e-02,  8.3130e-02],\n",
       "          [-6.1544e-02, -1.0541e-01,  1.3370e-01],\n",
       "          [-1.3495e-02, -3.3459e-01, -3.7672e-01]],\n",
       "\n",
       "         [[ 4.4782e-02, -4.8111e-02, -3.0118e-01],\n",
       "          [ 7.5534e-02,  1.4195e-02, -9.2084e-02],\n",
       "          [ 5.9530e-02,  2.4830e-01, -1.9449e-02]],\n",
       "\n",
       "         [[-5.6514e-02, -4.7786e-01, -5.4551e-01],\n",
       "          [ 6.7129e-02, -1.0447e-01, -3.5393e-01],\n",
       "          [ 2.0524e-01,  1.4802e-01, -1.2159e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1755e-01,  1.8948e-01, -8.5609e-02],\n",
       "          [ 1.8041e-03,  9.2940e-02,  4.3612e-03],\n",
       "          [-2.8400e-02,  8.6866e-02,  5.8296e-02]],\n",
       "\n",
       "         [[ 1.5267e-01,  9.4688e-02,  1.0845e-01],\n",
       "          [ 1.2109e-02,  1.7323e-02,  7.2662e-02],\n",
       "          [ 1.5045e-01,  6.3335e-02,  1.3530e-01]],\n",
       "\n",
       "         [[-1.1404e-02, -6.6846e-05,  3.2670e-02],\n",
       "          [ 1.3148e-02, -9.1374e-03,  7.4029e-02],\n",
       "          [ 7.1019e-02, -1.2960e-02,  2.3726e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.7098e-02,  6.7599e-02,  1.4238e-02],\n",
       "          [ 4.8238e-02,  1.3659e-02, -1.2117e-01],\n",
       "          [ 1.4043e-02, -4.1660e-02, -1.5624e-01]],\n",
       "\n",
       "         [[ 7.8119e-02,  5.5463e-02, -4.3440e-02],\n",
       "          [ 4.9839e-02,  1.5844e-02,  6.5254e-03],\n",
       "          [-1.8330e-03,  3.8192e-02, -6.3780e-02]],\n",
       "\n",
       "         [[ 1.2015e-03, -5.0034e-02, -4.7408e-03],\n",
       "          [-9.7093e-02, -1.0198e-01, -1.2352e-01],\n",
       "          [-4.9896e-02, -4.3457e-02, -1.8967e-02]]]], device='cuda:0')), ('encoder.base.conv_block2.conv2.weight', tensor([[[[-1.2165e-01, -3.4758e-02, -3.1801e-02],\n",
       "          [-2.2202e-01, -4.2053e-02, -8.9334e-03],\n",
       "          [-2.1968e-01,  1.4105e-02, -7.2417e-02]],\n",
       "\n",
       "         [[-1.8230e-02,  4.9553e-02,  2.1746e-03],\n",
       "          [-5.1542e-03,  1.5157e-01, -5.8213e-02],\n",
       "          [-6.2584e-02,  8.8796e-02, -9.7473e-02]],\n",
       "\n",
       "         [[-7.6419e-02,  2.6815e-01, -4.1798e-01],\n",
       "          [ 1.1087e-01,  1.8604e-01, -4.2441e-01],\n",
       "          [ 6.6051e-01,  6.7546e-02, -2.2249e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.7164e-01,  6.9644e-02, -1.1054e-01],\n",
       "          [-1.9934e-01,  1.2364e-01, -1.8217e-01],\n",
       "          [ 1.9870e-01, -2.1927e-01, -4.7338e-01]],\n",
       "\n",
       "         [[ 6.0575e-01,  1.9189e-01, -3.9298e-01],\n",
       "          [ 3.8937e-01, -5.2282e-01, -3.3441e-01],\n",
       "          [ 5.0963e-02, -8.0754e-01,  2.1472e-01]],\n",
       "\n",
       "         [[-5.4394e-02, -4.4702e-02, -4.1633e-02],\n",
       "          [-7.9942e-02,  2.0425e-02, -1.1764e-01],\n",
       "          [-6.7712e-02, -4.8692e-02, -8.1700e-02]]],\n",
       "\n",
       "\n",
       "        [[[-8.8303e-02, -1.1456e-01, -6.3068e-02],\n",
       "          [-3.1676e-02, -7.5469e-02, -8.8714e-02],\n",
       "          [ 1.6190e-02, -1.3691e-01, -1.2982e-02]],\n",
       "\n",
       "         [[ 1.3800e-02,  4.3082e-02,  1.2921e-01],\n",
       "          [-6.6615e-02,  3.9583e-02,  5.1345e-02],\n",
       "          [-9.0941e-02, -3.3695e-02, -1.6292e-01]],\n",
       "\n",
       "         [[-2.9417e-01, -2.7346e-01, -2.8625e-01],\n",
       "          [-4.8340e-01, -3.0853e-01, -2.9241e-01],\n",
       "          [-4.6969e-01, -4.4771e-01, -2.2531e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.3768e-01, -1.3367e-01,  6.3965e-02],\n",
       "          [-1.8034e-01, -1.0056e-01,  4.9152e-02],\n",
       "          [ 6.9681e-02,  4.4886e-02, -1.5970e-02]],\n",
       "\n",
       "         [[ 6.3910e-02,  5.0630e-02, -1.5643e-01],\n",
       "          [-1.2564e-02,  8.7770e-02, -2.5424e-01],\n",
       "          [-1.5242e-01,  3.2650e-02, -3.4847e-01]],\n",
       "\n",
       "         [[-1.0796e-02, -6.4269e-02, -5.0478e-03],\n",
       "          [-9.9691e-02, -6.7211e-02, -5.9294e-02],\n",
       "          [-5.5320e-02, -4.8565e-02, -8.5714e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 3.3092e-01,  9.5969e-02,  1.5641e-01],\n",
       "          [ 1.9266e-01,  1.9806e-01,  3.0072e-01],\n",
       "          [ 1.0866e-01,  6.0311e-02,  1.0739e-01]],\n",
       "\n",
       "         [[-4.7209e-02, -7.3073e-02, -1.1407e-01],\n",
       "          [ 3.4073e-02, -6.4070e-02,  7.7815e-02],\n",
       "          [ 2.4749e-02, -6.8775e-02,  7.9206e-02]],\n",
       "\n",
       "         [[-2.8662e-02, -6.8921e-03, -1.5398e-01],\n",
       "          [ 1.1468e-01,  1.0031e-01, -2.7129e-02],\n",
       "          [ 1.9977e-01,  1.8576e-01,  5.5038e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.7789e-01, -1.6586e-01, -5.8020e-02],\n",
       "          [-1.0732e-01, -1.4870e-01, -1.8783e-01],\n",
       "          [ 1.1411e-01,  1.8217e-03,  6.5047e-03]],\n",
       "\n",
       "         [[ 5.4595e-02,  7.4122e-02, -2.3456e-01],\n",
       "          [-1.3140e-01, -1.0850e-02, -2.9233e-01],\n",
       "          [-3.5969e-02,  2.3044e-01, -1.8797e-01]],\n",
       "\n",
       "         [[ 1.4259e-01,  7.6576e-02,  9.8668e-02],\n",
       "          [ 2.4371e-01,  1.9889e-01,  1.1936e-01],\n",
       "          [ 1.4846e-01,  1.9596e-01,  1.3475e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-2.1735e-02, -1.3602e-03, -6.8345e-03],\n",
       "          [-3.9126e-02, -2.0053e-02, -6.9146e-02],\n",
       "          [-4.7897e-02, -3.2232e-02, -3.0127e-02]],\n",
       "\n",
       "         [[-1.1223e-01, -2.3186e-03,  1.0385e-01],\n",
       "          [-1.8395e-02, -9.9355e-03,  2.3772e-02],\n",
       "          [ 9.9456e-03,  3.8746e-02,  3.2703e-02]],\n",
       "\n",
       "         [[ 5.2624e-01,  3.0441e-01, -2.7560e-02],\n",
       "          [ 3.8298e-01,  3.3152e-01,  3.2366e-01],\n",
       "          [-1.7045e-01, -1.2247e-01, -6.2685e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.2901e-01,  1.6458e-01, -5.7356e-02],\n",
       "          [ 1.9583e-01,  1.6779e-01,  2.3444e-02],\n",
       "          [-1.3751e-01, -1.7650e-01, -3.1298e-01]],\n",
       "\n",
       "         [[ 1.4263e-01, -1.8176e-01, -1.3101e-01],\n",
       "          [-3.3003e-01, -1.7546e-01, -1.4912e-01],\n",
       "          [-4.1653e-01, -2.7350e-01, -2.3506e-01]],\n",
       "\n",
       "         [[-3.4305e-03, -1.1950e-02, -2.6996e-02],\n",
       "          [-3.5794e-02, -1.4185e-02, -2.9764e-02],\n",
       "          [ 2.7390e-02, -6.2543e-02, -3.8219e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0635e-02, -2.6808e-03, -9.0777e-02],\n",
       "          [-3.8485e-02,  3.2833e-02, -1.6659e-02],\n",
       "          [-1.8095e-02,  8.3388e-03,  1.3049e-02]],\n",
       "\n",
       "         [[-4.0688e-02, -2.1189e-01, -1.4189e-01],\n",
       "          [-4.1159e-02, -1.1777e-01, -3.9503e-02],\n",
       "          [ 4.0488e-02,  6.5073e-02, -1.2451e-01]],\n",
       "\n",
       "         [[-1.9807e-01, -1.4593e-01, -3.1981e-01],\n",
       "          [-2.6858e-01, -9.8892e-02, -2.4597e-01],\n",
       "          [-3.9285e-01, -2.7522e-02, -2.4347e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.2200e-01, -2.3795e-01, -4.5053e-01],\n",
       "          [-4.3874e-01, -2.1310e-02, -6.6127e-02],\n",
       "          [ 1.4589e-01,  1.8029e-01, -2.1881e-01]],\n",
       "\n",
       "         [[ 1.2308e-02,  3.8618e-01,  4.7723e-02],\n",
       "          [ 1.1494e-02,  2.0954e-01,  1.6211e-02],\n",
       "          [-1.2337e-01, -1.7129e-01, -2.3508e-01]],\n",
       "\n",
       "         [[-2.2188e-03, -2.6811e-02, -4.6226e-03],\n",
       "          [-7.3100e-02, -4.6282e-02, -5.9734e-02],\n",
       "          [ 1.5354e-02, -7.1094e-02, -4.0344e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.9619e-02, -1.3767e-02, -6.4492e-02],\n",
       "          [ 7.0084e-02,  2.1040e-02, -1.6778e-02],\n",
       "          [ 2.5448e-02, -2.0526e-02, -1.5553e-02]],\n",
       "\n",
       "         [[ 6.7199e-02,  5.4012e-02, -5.1086e-02],\n",
       "          [-1.6294e-02,  2.6211e-03, -5.9751e-02],\n",
       "          [ 1.1546e-01,  7.7307e-02, -3.1984e-02]],\n",
       "\n",
       "         [[-1.3045e-01,  4.2094e-01,  3.6570e-01],\n",
       "          [ 5.6246e-02,  7.0460e-01,  5.7300e-01],\n",
       "          [-8.8699e-02,  4.3950e-01,  6.2013e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.6621e-01, -1.4640e-01,  1.2067e-01],\n",
       "          [ 3.1655e-02,  3.4726e-01,  4.2844e-01],\n",
       "          [-4.9609e-02,  3.7723e-01,  2.6148e-01]],\n",
       "\n",
       "         [[ 1.0608e-02,  5.0214e-01,  1.0745e-01],\n",
       "          [-1.9865e-01,  2.3390e-01,  7.7547e-03],\n",
       "          [-1.2779e-01,  2.3408e-01, -2.2846e-02]],\n",
       "\n",
       "         [[ 2.3396e-02, -2.1005e-02, -6.9662e-03],\n",
       "          [-2.6809e-02, -3.2222e-02, -9.1260e-03],\n",
       "          [-5.6296e-04, -2.4745e-03, -5.7847e-02]]]], device='cuda:0')), ('encoder.base.conv_block2.bn1.weight', tensor([0.7172, 1.1233, 1.1306, 1.0778, 1.2900, 1.3358, 1.0254, 0.9637, 1.0924,\n",
       "        1.9560, 1.1531, 1.0244, 0.9168, 0.9906, 1.3675, 1.0856, 1.0364, 1.4014,\n",
       "        0.6489, 1.1420, 1.0177, 1.0153, 0.4829, 1.3125, 1.0182, 1.2070, 0.8518,\n",
       "        1.1346, 1.0194, 1.0389, 0.6530, 1.6765, 1.3377, 1.0420, 1.1963, 1.4562,\n",
       "        1.2257, 0.8529, 1.2123, 1.0886, 1.2572, 0.9541, 1.2606, 1.1860, 0.7690,\n",
       "        1.0909, 0.8198, 1.6815, 1.5043, 0.9400, 0.9319, 1.2516, 1.2181, 0.7739,\n",
       "        1.5223, 1.2250, 0.5551, 0.8316, 1.1723, 0.6180, 1.2489, 1.3083, 1.2504,\n",
       "        1.1648, 0.9319, 0.8519, 1.1785, 1.1199, 1.0065, 1.0437, 0.8517, 0.9715,\n",
       "        1.1117, 0.8660, 1.2616, 0.6270, 1.4886, 0.8508, 1.6452, 0.9375, 0.9837,\n",
       "        0.9614, 0.9463, 0.9444, 1.3023, 0.9668, 0.9989, 0.8529, 1.2239, 1.2258,\n",
       "        0.8677, 1.0991, 1.2224, 1.3239, 1.0160, 0.8423, 0.7899, 1.0761, 0.9532,\n",
       "        1.1130, 1.0155, 1.4508, 0.9422, 0.4902, 1.3575, 1.2227, 0.6806, 1.0196,\n",
       "        1.1379, 1.3348, 0.8498, 1.1620, 1.0342, 1.0171, 0.7932, 1.2207, 1.0058,\n",
       "        1.1235, 0.9424, 0.7260, 1.1394, 1.4980, 0.9080, 1.0551, 0.7560, 1.6658,\n",
       "        1.0238, 0.7015], device='cuda:0')), ('encoder.base.conv_block2.bn1.bias', tensor([-1.3539, -0.9176, -0.3358, -0.6793, -0.2511, -0.5147,  0.1780,  0.0788,\n",
       "        -0.9521, -3.2531, -0.3384, -0.2269, -0.1342, -0.4940, -0.5501, -0.7990,\n",
       "        -0.2480, -0.7214, -1.2223, -0.8328,  0.1423, -0.7698, -0.0695, -0.9567,\n",
       "        -0.6748, -0.8609, -1.0909, -0.6635, -0.5919, -0.3254, -0.5232, -1.0573,\n",
       "        -0.5956,  0.2500, -1.2381, -0.9972, -1.1012, -0.7308, -0.9487, -0.4341,\n",
       "        -0.7429, -0.7259, -0.9874, -0.2327, -1.4147, -0.8253, -0.5465, -2.2435,\n",
       "        -0.7619, -0.4607, -1.0012, -0.7680,  0.0576, -0.1711, -0.9545, -0.4789,\n",
       "        -0.2734, -0.1463, -0.9236, -0.4300, -1.3015, -0.8899, -1.5931, -0.5611,\n",
       "        -0.2354,  0.1681, -0.6901, -0.1235, -0.6812, -0.5706, -0.0539, -0.2259,\n",
       "        -0.7704, -0.1603, -0.9158, -1.2511, -1.1759, -0.4254, -1.5772,  0.0548,\n",
       "        -0.3023, -0.2560, -0.9098,  0.1258, -0.8445,  0.2932, -0.5789, -1.4806,\n",
       "        -0.7398, -0.6939, -0.2297, -0.3205, -1.0558, -0.5916, -0.7359, -0.6250,\n",
       "         0.0800, -0.9542, -0.1950, -0.3094, -0.5269, -0.8853, -0.4104, -0.0767,\n",
       "        -0.9139, -0.6508, -0.2267, -0.5620, -0.0352, -0.6384,  0.3548, -0.7505,\n",
       "        -0.5176, -0.8099, -0.5966, -0.7521, -1.1145, -0.2763, -0.7157, -0.2710,\n",
       "        -0.5462, -0.9088, -0.2783, -0.7310,  0.0219, -0.8976, -0.0224, -1.1168],\n",
       "       device='cuda:0')), ('encoder.base.conv_block2.bn1.running_mean', tensor([-2.3564e+00, -7.8623e-01, -4.6387e+00, -1.5049e+00, -2.2726e+00,\n",
       "        -2.7921e+00, -7.8990e-01, -2.8141e+00, -5.9426e-01, -2.2119e-01,\n",
       "        -2.2360e+00, -1.1295e+00, -4.6336e-01, -6.6574e-02, -3.6455e+00,\n",
       "        -8.3942e-01, -2.1146e+00, -3.3238e+00, -1.4186e-01, -3.0691e+00,\n",
       "        -2.2668e+00, -1.1178e+00, -8.3395e-01, -2.8017e+00, -1.6393e+00,\n",
       "        -3.2161e+00,  2.2586e+00, -2.7256e+00, -1.5868e+00, -2.5973e+00,\n",
       "         5.9631e-01, -2.0146e+00, -3.9246e+00, -4.6789e-01, -1.3337e+00,\n",
       "        -2.9259e+00, -3.4471e+00,  4.0029e-01, -2.7329e+00, -1.4647e+00,\n",
       "        -2.7654e+00, -7.8124e-01, -2.8880e+00, -2.2220e+00, -3.1499e+00,\n",
       "        -2.0553e+00, -1.3198e+00, -1.3732e+00, -1.1723e+00, -3.7504e+00,\n",
       "        -2.9886e+00, -2.1853e+00, -1.5485e+00, -3.1541e+00, -2.1112e+00,\n",
       "        -1.7010e+00, -7.4233e-01, -1.2257e+00, -1.9303e+00, -1.8361e+00,\n",
       "        -8.7065e-01, -1.9204e+00, -7.5239e-01, -1.1576e+00, -1.1160e+00,\n",
       "        -2.2270e+00, -9.1154e-01, -2.0062e+00, -2.4841e+00, -2.2993e+00,\n",
       "        -1.4874e+00, -1.1571e+00, -2.4260e+00, -3.6369e-01, -3.3601e+00,\n",
       "        -1.9821e+00, -7.2913e-01, -1.6621e+00, -1.3400e+00, -1.2716e+00,\n",
       "        -1.3281e+00, -2.1497e-01, -1.1626e+00, -2.3756e+00, -2.5502e+00,\n",
       "        -1.1670e+00, -6.4745e-01,  5.7326e-01, -1.6173e+00, -2.3845e+00,\n",
       "         4.2936e-03, -2.3031e+00, -2.2605e+00, -1.4771e+00, -1.5212e+00,\n",
       "         6.9390e-01, -9.1834e-01,  2.9509e-01, -2.1181e+00, -1.3780e+00,\n",
       "        -2.6048e-02, -1.7809e+00, -2.0320e+00,  1.7299e+00, -3.1834e+00,\n",
       "        -8.1315e-01,  3.8306e-01, -1.1156e+00, -1.8082e+00, -1.4379e+00,\n",
       "        -2.8346e+00, -1.0881e+00, -1.2295e+00, -1.1997e+00,  1.3506e+00,\n",
       "        -1.8708e+00, -7.6548e-01, -3.8635e+00, -9.9921e-01, -2.0282e+00,\n",
       "        -4.2747e+00, -3.8394e+00, -3.5665e+00, -2.8408e+00, -2.4622e-01,\n",
       "        -1.8582e+00, -2.5839e+00, -1.9727e+00], device='cuda:0')), ('encoder.base.conv_block2.bn1.running_var', tensor([ 1.1628,  2.2944,  8.6532,  2.7921,  6.7483,  3.9477,  6.2737, 11.0114,\n",
       "         1.1497,  2.9575,  6.1196,  4.8618,  2.6658,  1.2191,  9.8697,  1.8588,\n",
       "         7.7485,  3.2064,  0.7007,  2.6209,  7.0998,  0.9956,  8.4282,  4.6423,\n",
       "         1.8855,  3.9211,  2.0303,  6.6025,  3.2229,  4.9314,  4.0883,  8.9942,\n",
       "         5.5522,  2.3270,  1.9216,  5.1352,  2.6981,  1.1372,  2.9688,  3.6854,\n",
       "         7.6050,  7.3443,  2.6095,  2.1476,  2.4595,  3.0240,  4.5101,  2.0808,\n",
       "         4.8284,  6.4665,  2.4399,  2.4437,  3.4446,  6.3414,  8.9221,  3.9288,\n",
       "         4.5559,  4.1219,  1.5601,  7.2267,  1.0878,  2.0362,  1.5766,  6.8748,\n",
       "         3.5607,  6.7264,  1.2537, 15.1972,  3.8910,  5.8348,  4.1857,  3.3512,\n",
       "         2.7344,  3.2213,  4.6379,  1.4182,  1.2774, 10.6226,  1.4496,  3.8304,\n",
       "         5.4729,  2.5310,  1.2216,  3.1023,  3.2071,  2.9372,  5.2183,  0.7089,\n",
       "         1.9102,  3.0293,  1.9638,  2.7152,  1.6664,  4.4831,  2.3184,  1.3854,\n",
       "         5.7960,  0.8607,  3.7067,  3.5862,  3.1024,  1.7274,  6.0427,  8.3279,\n",
       "         4.1307,  2.4674,  2.2121,  4.5371,  2.9238,  2.9484, 12.1494,  0.9848,\n",
       "         4.5319,  2.2995,  8.1437,  6.4259,  2.4978,  5.0054,  1.7669,  6.3232,\n",
       "         9.9577,  8.3383,  5.7918,  5.6132,  5.2834,  7.8332,  4.3388,  1.1185],\n",
       "       device='cuda:0')), ('encoder.base.conv_block2.bn1.num_batches_tracked', tensor(586728, device='cuda:0')), ('encoder.base.conv_block2.bn2.weight', tensor([1.3141, 0.9743, 0.9400, 0.9704, 1.1382, 1.0515, 0.7056, 0.8917, 1.2728,\n",
       "        0.8739, 0.8869, 1.0483, 0.6003, 0.7180, 0.9838, 0.9419, 1.2941, 1.2745,\n",
       "        1.1587, 1.3949, 0.7573, 0.7964, 1.2028, 1.1286, 0.5101, 1.5309, 1.7043,\n",
       "        1.0253, 1.2643, 1.5136, 0.9687, 1.1254, 0.9008, 1.0613, 1.2545, 1.9371,\n",
       "        1.0074, 1.1867, 0.6400, 0.8690, 1.2913, 1.1891, 1.5210, 1.2264, 1.1337,\n",
       "        1.5098, 0.7860, 1.1929, 0.9391, 1.0299, 0.8509, 1.0739, 1.1180, 1.0300,\n",
       "        1.1998, 0.9821, 0.9817, 1.3478, 0.9603, 0.9633, 0.6857, 0.6026, 0.7475,\n",
       "        0.7358, 0.7933, 0.9335, 0.9808, 1.0397, 0.8151, 0.7391, 0.6320, 1.2441,\n",
       "        1.0984, 1.2876, 0.8579, 1.6905, 0.7509, 0.7957, 0.7060, 1.0145, 0.9281,\n",
       "        0.8951, 1.7811, 1.0739, 1.3654, 1.0729, 0.7540, 0.7065, 1.2138, 1.0745,\n",
       "        0.9565, 0.9216, 1.0931, 0.6989, 1.1158, 0.9414, 0.7919, 1.2018, 1.0087,\n",
       "        1.4503, 0.6382, 0.8017, 0.9373, 1.1921, 1.0555, 1.2000, 1.3124, 1.1891,\n",
       "        0.8393, 1.0704, 0.7054, 1.2592, 0.7358, 0.9641, 1.1372, 0.8094, 1.0117,\n",
       "        1.2514, 1.1951, 1.0004, 0.8262, 0.7046, 0.8043, 1.1598, 0.6865, 1.4700,\n",
       "        0.8981, 0.9085], device='cuda:0')), ('encoder.base.conv_block2.bn2.bias', tensor([-1.3503, -0.4413, -0.6789, -0.9455, -1.0849, -0.4448, -0.5752, -0.7186,\n",
       "        -0.8108, -0.2051, -0.4654, -0.7822, -0.4704, -0.3479, -0.7247, -0.6463,\n",
       "        -1.1507, -0.8867, -0.7556, -0.8274, -0.4405, -0.4568, -0.9801, -0.6102,\n",
       "        -1.2241, -1.2244, -1.5618, -0.8782, -0.5003, -0.9520, -0.5820, -1.1252,\n",
       "        -0.9082, -0.9316, -1.0885, -1.7258, -0.9305, -0.9675, -0.2319, -0.6314,\n",
       "        -0.8341, -1.1461, -0.9772, -0.9146, -0.7383, -1.1380, -0.6114, -0.9168,\n",
       "        -1.1098, -0.8108, -0.2102, -0.8518, -0.5361, -0.4911, -0.9719, -0.7816,\n",
       "        -0.7263, -1.1259, -0.3177, -0.4689, -0.2683, -0.5677, -0.5023, -0.3059,\n",
       "        -0.5004, -0.7979, -0.7226, -0.8363, -0.3814, -0.5096, -2.4209, -1.0990,\n",
       "        -0.7452, -1.0950, -0.4069, -1.6483, -0.4548, -0.4833, -0.4344, -0.7627,\n",
       "        -0.5733, -0.4171, -1.7487, -1.0344, -0.9407, -0.8883, -0.0773, -0.2880,\n",
       "        -1.0581, -0.7470, -0.6575, -0.5272, -0.7539, -0.3000, -0.6706, -0.6163,\n",
       "        -0.3594, -0.7435, -2.1373, -1.4771, -0.2047, -0.3021, -0.4441, -0.8505,\n",
       "        -0.7633, -1.0400, -0.6749, -0.8543, -0.2337, -0.7890, -0.1617, -0.7715,\n",
       "        -0.4618, -0.8388, -0.8737, -0.8112, -0.6466, -0.8895, -0.7215, -0.9477,\n",
       "        -0.6900, -0.5412, -0.4516, -1.3314, -0.2638, -1.1401, -0.6788, -0.7952],\n",
       "       device='cuda:0')), ('encoder.base.conv_block2.bn2.running_mean', tensor([-6.9297, -4.3337, -5.7589, -0.8863, -2.2412, -1.4413, -3.4932, -6.0370,\n",
       "        -5.2845, -2.1129, -5.9746, -2.2982, -0.1805, -1.9609, -3.9859, -2.5096,\n",
       "        -9.8723, -4.8601, -5.3042, -2.1145, -3.4193, -3.2424, -4.6652, -1.9158,\n",
       "         0.2138, -3.6972, -1.9212, -3.2995, -3.1840, -8.4560, -7.4588, -8.7266,\n",
       "        -1.2513, -1.9974, -5.5300, -4.2195, -3.7250, -2.1256, -3.6457, -6.0307,\n",
       "        -2.3493, -1.5394, -5.7551, -4.4863, -5.5497, -4.5754, -3.0556, -5.5282,\n",
       "         4.0172, -6.1605, -3.4883, -3.7118, -7.3187, -8.2365, -3.5258, -1.8673,\n",
       "        -0.7454, -1.8293, -3.3306, -6.0135, -0.3439, -1.7986, -4.1060, -8.0788,\n",
       "        -6.2054, -4.6057, -8.8555, -5.2569, -3.6296, -6.3634, -4.6917, -5.0731,\n",
       "        -3.5708, -3.3057, -4.4096, -5.6592, -7.4107, -2.9892, -6.6684, -3.7112,\n",
       "        -0.1329, -7.2910, -5.4560, -7.7363, -6.1466, -4.1547, -5.3513, -9.7286,\n",
       "        -4.6962, -7.7151, -8.1191, -3.9913, -1.1417, -2.8012, -5.0069, -5.7323,\n",
       "        -2.7388, -4.5593, -8.8022, -4.6429, -1.6462, -6.3479, -3.9436, -3.4581,\n",
       "        -3.9018, -2.6764, -4.2597, -3.6427, -5.7447, -4.2069, -2.9528, -6.0274,\n",
       "        -2.2515, -7.0223, -2.5649, -0.8349, -6.6115, -3.0227, -5.8236, -5.4464,\n",
       "        -4.9398,  0.5112, -5.7200, -2.4090, -1.9134, -1.6693, -8.4573, -7.5632],\n",
       "       device='cuda:0')), ('encoder.base.conv_block2.bn2.running_var', tensor([30.6659, 44.3200, 18.3157, 20.5948, 15.7070, 15.0497,  6.2826, 38.1174,\n",
       "        17.1388, 41.9682, 27.3024, 12.1402, 22.9494, 13.0412, 24.8706, 15.3759,\n",
       "        34.4519, 18.4692, 20.1711, 17.2156, 29.4188, 23.2388, 16.7092, 22.9201,\n",
       "         2.3241, 25.2681, 19.5696, 18.9731, 31.4712, 37.6598, 30.9196, 35.2994,\n",
       "        12.7409, 12.1795, 10.5677, 24.4400, 32.0738, 23.1013, 22.0267, 24.0519,\n",
       "        30.1795, 28.6623, 35.2770, 17.5137, 14.4632, 34.9817, 13.1082, 22.4076,\n",
       "        12.2356, 27.6757, 42.7241, 11.3820, 23.2812, 39.8190, 16.6850, 16.6628,\n",
       "        11.7425, 13.5440, 14.1517, 16.3527, 17.1861, 17.4135, 15.5357, 22.4912,\n",
       "        20.4443, 15.9669, 16.4832, 17.2318,  7.1193, 20.2935,  6.8821, 24.5627,\n",
       "        20.3342, 14.7529, 22.7395, 34.7625, 61.4325, 17.0555, 45.7971, 19.0875,\n",
       "        13.7665, 27.6330, 16.5559, 25.3476, 20.9822, 23.3057, 16.2179, 45.1180,\n",
       "        34.5436, 18.5065, 19.3175, 20.1623, 11.7982, 19.0447, 22.6937, 27.3784,\n",
       "        17.4375, 14.3894, 23.7390, 21.1173, 32.1722, 13.5240, 26.1376, 13.4418,\n",
       "        26.0792, 11.1197, 22.5386, 34.6845, 43.4385, 20.0209, 30.8511, 14.8955,\n",
       "        25.5031, 25.1505, 13.1208, 45.8165, 26.7770, 35.5371, 17.3669, 15.0885,\n",
       "        11.7473, 12.7117, 25.2792, 11.6972, 56.6025, 13.2156, 36.0186, 25.4881],\n",
       "       device='cuda:0')), ('encoder.base.conv_block2.bn2.num_batches_tracked', tensor(586728, device='cuda:0')), ('encoder.base.conv_block3.conv1.weight', tensor([[[[ 0.1918,  0.2914,  0.2449],\n",
       "          [ 0.1409,  0.4522,  0.5067],\n",
       "          [-0.0884,  0.0737,  0.0301]],\n",
       "\n",
       "         [[ 0.1019,  0.0240,  0.1687],\n",
       "          [ 0.1553,  0.1560,  0.1272],\n",
       "          [ 0.3152,  0.1944,  0.5959]],\n",
       "\n",
       "         [[-0.0959,  0.0195, -0.0181],\n",
       "          [ 0.1306,  0.3360,  0.2106],\n",
       "          [ 0.0172,  0.2755,  0.1774]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0589, -0.0836, -0.0707],\n",
       "          [-0.0466, -0.0364, -0.0165],\n",
       "          [-0.1360, -0.1182, -0.2067]],\n",
       "\n",
       "         [[ 0.1215, -0.0398,  0.0103],\n",
       "          [ 0.2076,  0.1056,  0.0358],\n",
       "          [ 0.2488,  0.1140,  0.0059]],\n",
       "\n",
       "         [[-0.1999,  0.1547, -0.0563],\n",
       "          [ 0.0262,  0.1187,  0.0150],\n",
       "          [-0.0092,  0.0139, -0.0758]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2419,  0.0038,  0.0491],\n",
       "          [ 0.1142,  0.1323,  0.0855],\n",
       "          [ 0.0182,  0.1687,  0.1369]],\n",
       "\n",
       "         [[ 0.0632, -0.0132, -0.2317],\n",
       "          [-0.0641,  0.1044, -0.1256],\n",
       "          [-0.2285, -0.0290, -0.1301]],\n",
       "\n",
       "         [[ 0.1610,  0.1163, -0.5981],\n",
       "          [-0.1550,  0.0303, -0.5493],\n",
       "          [-0.0474,  0.0092, -0.9042]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0083,  0.0083,  0.0075],\n",
       "          [ 0.0145,  0.0950,  0.0511],\n",
       "          [ 0.0830,  0.1164,  0.0494]],\n",
       "\n",
       "         [[ 0.2263,  0.1090,  0.0101],\n",
       "          [ 0.1972,  0.0947,  0.0223],\n",
       "          [ 0.2290,  0.0657,  0.0559]],\n",
       "\n",
       "         [[ 0.0564,  0.0782, -0.1155],\n",
       "          [-0.0289,  0.0121, -0.1669],\n",
       "          [-0.1572, -0.0734, -0.2753]]],\n",
       "\n",
       "\n",
       "        [[[-0.1550,  0.0760, -0.0711],\n",
       "          [ 0.0081,  0.0031,  0.2342],\n",
       "          [-0.0559, -0.0469,  0.0951]],\n",
       "\n",
       "         [[-0.2200, -0.1018,  0.0902],\n",
       "          [-0.0272, -0.0195, -0.0870],\n",
       "          [-0.0746,  0.0177, -0.0156]],\n",
       "\n",
       "         [[ 0.1937,  0.1846, -0.1088],\n",
       "          [-0.0464, -0.0803, -0.1807],\n",
       "          [-0.2460, -0.4201, -0.2906]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2961,  0.0428,  0.0576],\n",
       "          [-0.0060, -0.0896, -0.0119],\n",
       "          [-0.0070, -0.1107, -0.0374]],\n",
       "\n",
       "         [[ 0.0958, -0.1339, -0.5265],\n",
       "          [ 0.2807, -0.0662, -0.3240],\n",
       "          [ 0.1958, -0.0395,  0.0079]],\n",
       "\n",
       "         [[-0.1234, -0.1167,  0.0425],\n",
       "          [-0.1760, -0.0356,  0.1057],\n",
       "          [ 0.0918,  0.0630,  0.0935]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.1052,  0.0447, -0.0383],\n",
       "          [ 0.3132, -0.0677,  0.2181],\n",
       "          [ 0.3347,  0.1222,  0.1651]],\n",
       "\n",
       "         [[-0.1390, -0.1263, -0.2003],\n",
       "          [ 0.0697,  0.2888,  0.1418],\n",
       "          [-0.1250,  0.1076, -0.2513]],\n",
       "\n",
       "         [[ 0.1868,  0.4712, -0.2973],\n",
       "          [ 0.4597,  0.3130,  0.0224],\n",
       "          [ 0.6202,  0.3876,  0.2023]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1832, -0.2164, -0.1429],\n",
       "          [-1.0208, -0.7868, -0.6915],\n",
       "          [ 0.0429, -0.0640,  0.0734]],\n",
       "\n",
       "         [[ 0.3000, -0.1256, -0.1552],\n",
       "          [ 0.3883,  0.0413, -0.0672],\n",
       "          [-0.0734, -0.2630, -0.1852]],\n",
       "\n",
       "         [[-0.0130, -0.1501, -0.0803],\n",
       "          [-0.0735, -0.1439, -0.1835],\n",
       "          [-0.0352, -0.1001, -0.0571]]],\n",
       "\n",
       "\n",
       "        [[[-0.1292, -0.0475, -0.2751],\n",
       "          [-0.0806, -0.0832, -0.1058],\n",
       "          [-0.2897, -0.2348, -0.2851]],\n",
       "\n",
       "         [[ 0.3081, -0.0171,  0.0433],\n",
       "          [ 0.3938, -0.0264,  0.0846],\n",
       "          [-0.0721, -0.1088,  0.0143]],\n",
       "\n",
       "         [[-0.2201, -0.1279,  0.0128],\n",
       "          [-0.0203, -0.0936,  0.2572],\n",
       "          [-0.0513,  0.0027,  0.2839]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1582,  0.0710, -0.0582],\n",
       "          [-0.1213,  0.0654,  0.0037],\n",
       "          [-0.0399,  0.0586, -0.0409]],\n",
       "\n",
       "         [[ 0.1604, -0.0942, -0.0826],\n",
       "          [ 0.0975,  0.0810,  0.0280],\n",
       "          [ 0.1393,  0.1117,  0.0537]],\n",
       "\n",
       "         [[-0.0604, -0.2456, -0.2025],\n",
       "          [ 0.0392, -0.1012, -0.0784],\n",
       "          [-0.0073, -0.2827, -0.0562]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0430,  0.2113,  0.5149],\n",
       "          [-0.0677,  0.0607,  0.4389],\n",
       "          [-0.2325, -0.0065,  0.1742]],\n",
       "\n",
       "         [[-0.3542, -0.1437,  0.3854],\n",
       "          [-0.2052, -0.2274,  0.2500],\n",
       "          [-0.4057, -0.3395, -0.0143]],\n",
       "\n",
       "         [[-0.1930, -0.0256, -0.0375],\n",
       "          [ 0.0103, -0.0207, -0.0794],\n",
       "          [ 0.3867,  0.2394,  0.1966]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1049,  0.0724, -0.0165],\n",
       "          [ 0.0512,  0.0242, -0.0029],\n",
       "          [ 0.0762,  0.0376,  0.0533]],\n",
       "\n",
       "         [[-0.0143,  0.0353,  0.0516],\n",
       "          [-0.0515,  0.0574,  0.0636],\n",
       "          [ 0.1108,  0.1316,  0.1324]],\n",
       "\n",
       "         [[ 0.2118, -0.2252,  0.0978],\n",
       "          [ 0.4146, -0.1564,  0.0487],\n",
       "          [ 0.1328, -0.3897, -0.1263]]]], device='cuda:0')), ('encoder.base.conv_block3.conv2.weight', tensor([[[[ 1.3757e-01,  4.3896e-02,  7.7711e-02],\n",
       "          [ 3.9155e-02, -1.6810e-02, -5.3194e-03],\n",
       "          [-7.1487e-02, -8.9337e-02, -9.6639e-02]],\n",
       "\n",
       "         [[ 1.0051e-01,  5.4529e-02,  2.5286e-01],\n",
       "          [ 2.2643e-01,  1.0918e-01,  2.1707e-01],\n",
       "          [ 2.2286e-01,  1.7694e-01,  1.8261e-01]],\n",
       "\n",
       "         [[ 1.0463e-01,  4.7260e-02,  1.4341e-01],\n",
       "          [ 6.8646e-03,  3.5136e-02, -1.8568e-01],\n",
       "          [ 1.4691e-02,  2.7523e-02, -8.4363e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.6073e-02, -1.0391e-01, -5.4284e-01],\n",
       "          [-1.1898e-01, -1.1015e-01, -2.7668e-01],\n",
       "          [-1.6836e-01, -1.7446e-01, -4.8569e-01]],\n",
       "\n",
       "         [[-2.9016e-01, -1.0900e-01, -5.3641e-02],\n",
       "          [-2.6679e-01, -1.2469e-01, -1.4308e-01],\n",
       "          [-1.3673e-01, -1.5387e-02,  1.9499e-02]],\n",
       "\n",
       "         [[-3.0667e-02, -2.2987e-01, -2.8192e-01],\n",
       "          [-1.4152e-01, -1.1759e-01, -1.8855e-01],\n",
       "          [-1.6718e-01, -2.3168e-01, -2.6251e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.8786e-01,  1.6873e-01,  1.3946e-01],\n",
       "          [-1.7823e-01,  5.2950e-02,  1.0508e-01],\n",
       "          [ 3.9748e-02,  1.1322e-01,  9.1565e-02]],\n",
       "\n",
       "         [[ 1.6513e-01,  7.0866e-02,  2.9959e-02],\n",
       "          [ 1.8623e-01,  8.5402e-02,  1.0393e-01],\n",
       "          [ 1.6429e-01,  6.0174e-02,  9.9975e-02]],\n",
       "\n",
       "         [[-2.9346e-02,  2.7225e-01,  4.5111e-03],\n",
       "          [-1.6765e-01,  8.2408e-02, -6.9969e-02],\n",
       "          [-3.3864e-01, -3.1999e-01, -4.8076e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 8.7067e-02,  3.7755e-02,  1.4875e-01],\n",
       "          [ 1.3623e-01,  5.7685e-02,  1.2049e-01],\n",
       "          [-4.3463e-02,  8.5667e-02,  2.6807e-01]],\n",
       "\n",
       "         [[ 3.3094e-02, -3.1364e-02, -9.8045e-02],\n",
       "          [ 5.5394e-02,  1.4516e-01,  4.4614e-02],\n",
       "          [ 1.2437e-01,  6.7197e-02,  2.6299e-01]],\n",
       "\n",
       "         [[ 1.3716e-02,  2.9617e-02, -8.5375e-03],\n",
       "          [-5.4299e-02, -9.0567e-03, -3.2639e-02],\n",
       "          [-3.9753e-02, -3.7975e-02,  1.0959e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.2729e-02,  1.2983e-02, -1.1082e-03],\n",
       "          [-1.0104e-02, -2.4775e-03, -1.8996e-03],\n",
       "          [-6.1798e-02, -5.7441e-02, -7.8250e-02]],\n",
       "\n",
       "         [[-1.8100e-02, -8.1336e-02,  8.5607e-03],\n",
       "          [ 2.4292e-02,  3.0190e-03,  6.1094e-03],\n",
       "          [ 5.0470e-02, -2.3951e-03,  3.9983e-02]],\n",
       "\n",
       "         [[-1.2726e-02, -9.6699e-02, -1.3851e-01],\n",
       "          [-2.9790e-02, -8.6112e-02, -1.5020e-01],\n",
       "          [-7.4393e-02, -9.5068e-02, -1.3827e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.0869e-02, -7.1531e-02, -3.1412e-03],\n",
       "          [-2.2586e-02, -4.4022e-03, -1.1555e-02],\n",
       "          [-3.3323e-02, -7.2141e-02, -3.3744e-02]],\n",
       "\n",
       "         [[ 3.9286e-02,  2.1935e-02, -1.1812e-02],\n",
       "          [ 8.7210e-02,  4.9117e-02,  3.8273e-02],\n",
       "          [ 7.9813e-03,  2.1938e-02, -2.2139e-02]],\n",
       "\n",
       "         [[-1.0034e-01, -6.9140e-02, -9.8685e-02],\n",
       "          [ 7.6026e-03,  5.4144e-04, -2.7368e-02],\n",
       "          [ 2.0734e-02,  2.5915e-02, -4.8275e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-3.3179e-03, -1.0582e-01, -7.0599e-02],\n",
       "          [ 3.1258e-02,  2.8049e-02,  2.0656e-03],\n",
       "          [ 1.3279e-01,  4.2829e-02,  9.6902e-02]],\n",
       "\n",
       "         [[-2.8050e-01, -2.3010e-01, -2.8824e-01],\n",
       "          [-3.2654e-02,  7.5081e-02, -1.0713e-01],\n",
       "          [ 2.2023e-01,  1.2251e-01, -3.1004e-02]],\n",
       "\n",
       "         [[-2.2567e-02, -1.0412e-01, -2.9561e-01],\n",
       "          [-6.5547e-02, -1.8374e-01, -2.1960e-01],\n",
       "          [ 4.5878e-02, -5.6491e-02, -1.8567e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.2591e-01, -2.1784e-02, -4.0365e-02],\n",
       "          [-5.7017e-02,  8.3478e-02, -3.8980e-02],\n",
       "          [ 7.2135e-02,  1.7239e-01,  1.7608e-01]],\n",
       "\n",
       "         [[-3.4503e-01, -3.1989e-01, -3.2226e-01],\n",
       "          [-1.6589e-01, -1.6011e-01, -1.2297e-01],\n",
       "          [-7.5813e-02, -5.2137e-02, -5.5259e-02]],\n",
       "\n",
       "         [[-1.4890e-01,  1.2244e-02,  3.4804e-03],\n",
       "          [ 9.9097e-02,  1.0039e-01,  1.1039e-01],\n",
       "          [ 2.7918e-01,  2.4813e-01,  2.0999e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.2763e-02,  3.3710e-02,  9.8060e-02],\n",
       "          [ 4.1523e-02,  1.0447e-01,  1.1888e-01],\n",
       "          [ 9.0085e-02,  1.0030e-01,  1.2675e-01]],\n",
       "\n",
       "         [[-2.0796e-02,  1.4305e-01, -8.5851e-02],\n",
       "          [ 9.9763e-02,  1.7328e-01,  1.0501e-01],\n",
       "          [ 9.9091e-02,  1.1628e-01,  5.7350e-02]],\n",
       "\n",
       "         [[-1.8043e-01, -6.2085e-02, -4.5798e-02],\n",
       "          [-8.4020e-02,  1.2727e-01,  9.6284e-02],\n",
       "          [ 1.7993e-01,  1.3537e-01,  1.8061e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.6259e-02, -5.4515e-02,  1.0738e-01],\n",
       "          [-1.6335e-01, -1.6188e-01, -4.7400e-02],\n",
       "          [-4.4075e-01, -2.0570e-01, -2.3790e-01]],\n",
       "\n",
       "         [[ 6.3876e-02,  5.0798e-02,  3.0333e-02],\n",
       "          [ 1.7889e-02,  1.8676e-02,  2.0114e-02],\n",
       "          [ 3.7309e-03,  6.1642e-02,  1.0740e-01]],\n",
       "\n",
       "         [[ 7.5402e-02,  6.8505e-02,  1.2329e-02],\n",
       "          [ 9.4484e-02,  1.3652e-01,  7.6856e-02],\n",
       "          [ 2.4983e-01,  2.6860e-01,  1.3195e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.5039e-02,  3.9122e-02, -4.0369e-03],\n",
       "          [-1.2478e-01, -5.6188e-02, -2.4111e-02],\n",
       "          [-6.4421e-02, -1.1154e-02,  3.1546e-02]],\n",
       "\n",
       "         [[ 6.7863e-02, -1.7155e-02,  8.1381e-02],\n",
       "          [-3.2866e-02, -1.4610e-01, -7.5981e-03],\n",
       "          [-9.6189e-02, -1.5031e-01, -2.5742e-02]],\n",
       "\n",
       "         [[-6.0012e-02,  7.6986e-02,  5.3144e-01],\n",
       "          [ 1.6253e-01,  2.6311e-02,  2.9028e-01],\n",
       "          [ 2.8924e-01,  4.3638e-01,  9.5001e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.4443e-02,  8.4047e-02,  9.4683e-02],\n",
       "          [ 7.5064e-02,  8.1519e-03,  9.3771e-02],\n",
       "          [ 4.4937e-02,  1.1582e-02,  3.0661e-02]],\n",
       "\n",
       "         [[-4.2403e-02,  5.5279e-02,  7.3614e-02],\n",
       "          [-1.4714e-01, -1.1489e-01, -1.1970e-01],\n",
       "          [-2.2739e-01, -2.6858e-01, -2.7262e-01]],\n",
       "\n",
       "         [[ 5.3812e-02,  1.3348e-01,  9.6792e-02],\n",
       "          [ 1.7793e-02,  9.1173e-02,  1.9585e-02],\n",
       "          [ 7.9299e-03,  8.6664e-02,  1.0111e-02]]]], device='cuda:0')), ('encoder.base.conv_block3.bn1.weight', tensor([1.0210, 1.0682, 1.3787, 1.2665, 1.1524, 1.2183, 0.7760, 0.9235, 1.3536,\n",
       "        1.1974, 1.3259, 1.0340, 0.7915, 1.4988, 1.3355, 1.0443, 1.5879, 1.0444,\n",
       "        1.4216, 1.0978, 0.9139, 1.1532, 1.1720, 1.4551, 0.9114, 1.1548, 0.2007,\n",
       "        0.9233, 0.9801, 1.4392, 1.2658, 1.2461, 1.2587, 0.9034, 1.2150, 0.9803,\n",
       "        0.9793, 1.0596, 1.2942, 1.0567, 0.9321, 1.1342, 1.5601, 1.0315, 1.2391,\n",
       "        1.0022, 0.9950, 1.2044, 1.0443, 1.0558, 1.0039, 1.3602, 1.1981, 1.2316,\n",
       "        1.3122, 1.0064, 0.7829, 1.3809, 1.1030, 1.4282, 0.9289, 1.1313, 1.3792,\n",
       "        0.9184, 1.0905, 1.0623, 1.2476, 1.4465, 1.1163, 1.2293, 1.0798, 1.3139,\n",
       "        1.7250, 0.8172, 1.5012, 1.3231, 1.0144, 1.1767, 0.8729, 1.1869, 0.9012,\n",
       "        1.0563, 0.7078, 1.3326, 1.0936, 1.0224, 1.3593, 0.9392, 1.0068, 0.9863,\n",
       "        1.1849, 0.9958, 1.2248, 0.9927, 0.3141, 1.3952, 1.0526, 0.9720, 1.1495,\n",
       "        1.1253, 0.9783, 1.0597, 1.0248, 1.4366, 1.3393, 1.2572, 0.9937, 1.1931,\n",
       "        1.1437, 0.8957, 1.2098, 0.2566, 1.0649, 1.3017, 1.0800, 0.5224, 1.0450,\n",
       "        1.1513, 1.1263, 0.8780, 1.3537, 1.1516, 1.5164, 1.1235, 0.9574, 0.9924,\n",
       "        1.1335, 1.0409, 0.9817, 0.9195, 0.9063, 0.7173, 1.1560, 1.2215, 1.1700,\n",
       "        1.4139, 1.2205, 0.9432, 1.0820, 1.4721, 1.3174, 1.0905, 1.2970, 0.8261,\n",
       "        0.9812, 1.0475, 1.2826, 1.2452, 0.8185, 1.0462, 1.0750, 1.5156, 1.1132,\n",
       "        1.3410, 1.1077, 1.1155, 1.2860, 0.9671, 0.5262, 1.1721, 0.9906, 1.1165,\n",
       "        1.2943, 0.9292, 1.0349, 1.1765, 1.1188, 1.1820, 0.9491, 0.9734, 1.3175,\n",
       "        1.2034, 1.2084, 0.9865, 1.2615, 0.8739, 0.7807, 1.1073, 0.7385, 0.9734,\n",
       "        1.4519, 0.9854, 1.0787, 1.0790, 1.0758, 1.1872, 1.0594, 0.9354, 0.5785,\n",
       "        1.2671, 0.6805, 1.1030, 1.2096, 1.1690, 0.8356, 0.8897, 1.0657, 1.2187,\n",
       "        0.9070, 0.7119, 0.9653, 0.9849, 1.0520, 0.2849, 0.9442, 1.1167, 1.2524,\n",
       "        1.0367, 1.4768, 1.2307, 1.2085, 0.8254, 1.2146, 1.1639, 0.2181, 1.2649,\n",
       "        1.1123, 1.2077, 1.2347, 1.0788, 1.5626, 1.0067, 1.1525, 1.1592, 1.1814,\n",
       "        1.2216, 1.1346, 0.6273, 1.3089, 1.5136, 1.1486, 0.7495, 1.3114, 0.9355,\n",
       "        1.1059, 1.4022, 1.3204, 1.5235, 1.3346, 1.1735, 1.1633, 1.0751, 1.3056,\n",
       "        1.0540, 1.0776, 0.9134, 0.7332, 1.1821, 0.9479, 0.8942, 1.1816, 1.1299,\n",
       "        0.9147, 1.0555, 0.8702, 1.0005], device='cuda:0')), ('encoder.base.conv_block3.bn1.bias', tensor([-0.8982, -0.5593, -0.8299, -0.8870, -0.6938, -0.3829, -1.0505, -0.7719,\n",
       "        -0.6779, -0.5489, -0.8549, -0.9675, -0.3858, -1.1915, -0.7939, -0.5287,\n",
       "        -1.0818, -0.6826, -1.1990, -0.5504, -0.6985, -0.5265, -0.7031, -0.7221,\n",
       "        -0.6240, -0.7923, -0.7477, -0.6211, -0.4847, -0.9305, -0.8672, -0.9640,\n",
       "        -0.5970, -0.7963, -1.0095, -0.7041, -0.6201, -0.8272, -0.8642, -0.7149,\n",
       "        -0.1486, -0.8913, -1.5533, -0.5700, -0.7954, -0.9663, -0.5202, -1.0395,\n",
       "        -1.0383, -0.8046, -0.7002, -1.1470, -0.5868, -0.7367, -0.7754, -0.4929,\n",
       "        -0.6644, -0.7077, -0.7026, -0.8174, -0.6611, -0.5234, -0.6234, -0.5961,\n",
       "        -0.5143, -0.7454, -0.6751, -0.6286, -1.0052, -1.2545, -0.4291, -1.1618,\n",
       "        -0.8726, -0.8077, -1.0296, -0.9257, -1.2397, -0.9032, -1.1586, -0.6834,\n",
       "        -0.3203, -0.7832,  0.3590, -0.7680, -0.7617, -0.9250, -0.9485, -0.8702,\n",
       "        -0.5869, -0.2732, -1.1147, -0.6329, -0.7087, -0.5849, -1.2142, -0.8736,\n",
       "        -1.2073, -0.4033, -0.6485, -0.9067, -0.1779, -0.7485, -1.5761, -0.8470,\n",
       "        -0.5936, -1.3240, -0.8528, -0.7504, -0.8944, -0.4018, -0.9139, -0.2481,\n",
       "        -1.2777, -0.6512, -0.5649,  0.1888, -0.9627, -0.8056, -0.6371, -0.6132,\n",
       "        -1.0691, -0.5870, -1.7209, -0.3129, -0.5256, -1.5523, -0.5553, -0.8495,\n",
       "        -0.0422, -0.3014, -0.5068, -0.6025, -0.5146, -1.0281, -0.7575, -1.0009,\n",
       "        -0.9620, -0.3392, -0.7340, -0.9131, -1.0636, -0.7621, -0.8121, -0.3924,\n",
       "        -1.2843, -0.4223, -0.8621, -0.7582, -0.4664, -0.6746, -0.9525, -0.7069,\n",
       "        -0.6494, -1.2329, -0.9510, -0.5987, -0.8122, -0.2585, -2.3511, -0.4336,\n",
       "        -0.4982, -1.0574, -0.6793, -0.3944, -0.4837, -0.6630, -1.0718, -0.7356,\n",
       "        -0.3307, -0.7226, -0.8178, -0.3179, -0.6890, -0.4605, -1.2686, -0.4719,\n",
       "        -0.4427, -0.6833, -0.3259, -0.6951, -1.1053, -0.9664, -0.7898, -0.8774,\n",
       "        -0.1740, -0.9885, -0.3770, -0.7380, -1.2202, -1.1224, -0.1347, -0.7182,\n",
       "        -0.7212, -0.3407, -0.2000, -0.8056, -0.8408, -0.6210, -1.0593, -3.0333,\n",
       "        -0.3586, -1.0164, -0.5091, -0.7474, -0.7502, -0.5594, -0.7063, -0.6198,\n",
       "        -1.2757, -0.9516, -0.7334, -0.6935, -0.7772, -0.7707, -0.4082, -1.0337,\n",
       "        -0.6719, -0.8486, -0.8674, -0.7073, -0.8083, -0.7788, -0.8789, -0.3953,\n",
       "        -1.1115, -0.7206, -0.9332,  0.0890, -0.8098, -0.9703, -1.0459, -0.3908,\n",
       "        -0.4484, -0.9225, -0.8505, -0.7879, -0.9284, -1.4579, -1.1448, -0.5124,\n",
       "        -0.8017, -0.4046, -0.8617, -0.6982, -0.5067, -0.4861, -0.2880, -0.7619,\n",
       "        -0.6610, -0.4801, -0.9662, -0.7079, -0.0607, -0.8820, -0.4338, -0.8083],\n",
       "       device='cuda:0')), ('encoder.base.conv_block3.bn1.running_mean', tensor([-3.6716, -4.4998, -3.3928, -4.3136, -4.6425, -6.1826,  2.4349, -2.4528,\n",
       "        -5.3190, -4.4415, -5.0642, -4.3423, -0.9123, -1.6092, -3.6615, -4.2036,\n",
       "        -5.0053, -5.8946, -1.9175, -2.6510, -2.0259, -3.2013, -2.9067, -3.4250,\n",
       "        -3.6012, -2.8132,  0.2122, -1.4167, -2.3176, -4.8757, -1.5723, -3.1555,\n",
       "        -3.8470, -3.5484, -4.6692, -1.2059, -5.4423, -6.5821, -2.9674, -3.6584,\n",
       "        -5.3014, -2.0395, -3.5407, -3.4778, -3.0371,  0.2025, -0.0142, -0.6985,\n",
       "        -3.6262, -5.2778, -1.2839, -0.6250, -3.5389, -1.7519, -7.4743, -1.9592,\n",
       "        -5.1269, -5.5833, -3.8974, -5.2696, -4.9513, -2.1108, -5.9900, -2.8826,\n",
       "         0.3543, -2.9952, -4.6341, -2.8891, -3.0032, -5.8718, -3.6505, -2.1396,\n",
       "        -3.3803,  0.5207, -1.3521, -3.7571, -0.0504, -3.8170,  2.6244, -3.5578,\n",
       "        -5.7465, -5.9931, -2.0362, -7.6235, -3.8140, -1.5547, -4.4511, -4.1878,\n",
       "        -3.8005, -3.5834,  1.3269, -3.9786, -1.9909, -3.7507,  0.1906, -6.9346,\n",
       "         1.3870, -2.8135, -3.8540, -1.1593, -4.5123, -2.3343,  0.0959, -1.7825,\n",
       "        -3.6221, -1.7327, -0.6540, -6.8581, -0.6884, -6.3777, -2.5159, -0.2136,\n",
       "        -0.7809, -4.1160, -2.5850, -3.2121, -4.0634, -1.8600, -3.4295,  1.6156,\n",
       "        -3.2638, -5.7367, -4.3896, -3.4009, -1.5803,  5.5251, -3.7837, -1.5342,\n",
       "        -1.6288, -2.4254, -4.1731, -1.9629, -4.0375, -4.3813, -1.0746, -1.9116,\n",
       "        -3.3286, -1.3124, -3.1905, -2.5201, -4.8249, -2.8369, -2.2420, -8.3987,\n",
       "         5.3649, -3.0550, -4.4956, -3.3828, -1.4829, -3.6053, -4.1002, -4.3864,\n",
       "        -3.4545, -1.2725, -1.7832, -3.7080, -3.4804, -4.7292,  0.0678, -5.4915,\n",
       "        -2.0888, -2.6093, -2.9651, -3.9596, -3.0122, -6.6763, -3.8709, -2.6090,\n",
       "        -0.7712, -2.2966, -2.8729, -2.7528, -2.3835, -3.5038, -8.4375, -5.2468,\n",
       "        -1.0841, -4.8295, -5.4690, -5.4507, -4.4401,  0.3135, -4.0276, -3.3131,\n",
       "        -2.2113, -4.1910, -6.2188, -0.8436,  0.2293,  1.4562, -6.2594, -3.6078,\n",
       "        -1.6662, -3.9950, -2.1669, -4.7181, -0.4500, -3.1043, -0.6794, -1.1833,\n",
       "        -4.7434,  0.2188, -2.0610,  0.3194, -0.1356, -4.5057, -3.3635, -1.3687,\n",
       "        -4.0310, -2.8598, -3.1592, -0.2566, -2.2996, -4.2440,  0.4073, -4.5379,\n",
       "        -4.2696, -3.6634, -3.5430, -2.7403, -3.3694,  1.1686, -2.6047, -2.3251,\n",
       "        -3.5192, -2.8872, -1.9932, -2.2582, -3.1104, -7.5036, -1.8841, -0.2710,\n",
       "        -2.5072,  2.6645, -1.1727, -3.0118, -4.0894, -5.0187, -3.1375, -3.0995,\n",
       "        -4.8769, -0.5808, -2.1449, -0.8675, -2.4263, -5.6197, -5.6222, -1.7829,\n",
       "        -3.5098, -1.2072, -3.4861, -3.3749, -3.2012, -3.6895, -4.1671, -1.3001],\n",
       "       device='cuda:0')), ('encoder.base.conv_block3.bn1.running_var', tensor([5.7976e+00, 1.0303e+01, 1.8532e+01, 8.1071e+00, 1.4653e+01, 3.4577e+01,\n",
       "        6.6280e+00, 1.8159e+01, 1.8759e+01, 9.0697e+00, 1.4710e+01, 7.8978e+00,\n",
       "        1.3225e+01, 5.6688e+00, 1.2380e+01, 5.3476e+00, 1.6595e+01, 1.1957e+01,\n",
       "        4.3686e+00, 5.3855e+00, 7.4871e+00, 1.5339e+01, 1.3848e+01, 1.3873e+01,\n",
       "        7.8771e+00, 2.1859e+01, 3.1837e-01, 9.6762e+00, 2.1956e+01, 1.9514e+01,\n",
       "        5.6002e+00, 8.6276e+00, 1.2053e+01, 1.1066e+01, 1.0630e+01, 1.0872e+01,\n",
       "        1.0524e+01, 1.3720e+01, 1.5714e+01, 1.2064e+01, 1.4017e+01, 1.1442e+01,\n",
       "        8.7009e+00, 7.3242e+00, 1.1817e+01, 1.1544e+01, 1.1481e+01, 7.0910e+00,\n",
       "        7.4718e+00, 6.3352e+00, 3.4908e+00, 7.1058e+00, 1.2840e+01, 4.7154e+00,\n",
       "        1.7992e+01, 4.9718e+00, 1.1630e+01, 1.3115e+01, 1.5667e+01, 1.6031e+01,\n",
       "        9.7328e+00, 1.1478e+01, 1.5452e+01, 1.1953e+01, 1.5424e+01, 1.4640e+01,\n",
       "        1.1706e+01, 1.8597e+01, 6.2712e+00, 1.6643e+01, 9.9804e+00, 5.3885e+00,\n",
       "        2.4392e+01, 3.0136e+00, 9.2681e+00, 1.4552e+01, 3.7358e+00, 1.0519e+01,\n",
       "        5.7727e+00, 8.1866e+00, 1.3902e+01, 9.1539e+00, 1.3845e+01, 1.7084e+01,\n",
       "        5.6192e+00, 3.4896e+00, 8.8599e+00, 6.4242e+00, 1.5906e+01, 1.4505e+01,\n",
       "        4.7681e+00, 5.7155e+00, 1.1734e+01, 6.9707e+00, 5.5136e-01, 1.6104e+01,\n",
       "        2.5965e+00, 1.0944e+01, 8.1110e+00, 1.0195e+01, 1.6952e+01, 1.3493e+01,\n",
       "        6.0901e+00, 8.9571e+00, 8.6324e+00, 6.5912e+00, 3.7050e+00, 1.6901e+01,\n",
       "        4.3927e+00, 1.3979e+01, 1.5108e+01, 2.7228e-01, 5.8820e+00, 7.7603e+00,\n",
       "        9.9676e+00, 1.1688e+01, 5.9136e+00, 7.2226e+00, 9.1692e+00, 1.8006e+01,\n",
       "        1.0924e+01, 1.6213e+01, 9.1611e+00, 1.4584e+01, 8.2220e+00, 1.5949e+01,\n",
       "        8.6650e+00, 5.9576e+00, 1.2013e+01, 6.9288e+00, 1.4488e+01, 7.2608e+00,\n",
       "        1.0110e+01, 1.5923e+01, 1.0383e+01, 8.5505e+00, 6.5930e+00, 1.4222e+01,\n",
       "        8.4192e+00, 9.4597e+00, 2.0852e+01, 9.6252e+00, 6.1861e+00, 1.9565e+01,\n",
       "        6.1862e+00, 1.0905e+01, 2.3752e+01, 1.0633e+01, 8.1979e+00, 1.2115e+01,\n",
       "        5.8161e+00, 2.5614e+01, 1.5373e+01, 6.8529e+00, 4.8582e+00, 7.2487e+00,\n",
       "        2.3886e+01, 1.2444e+01, 9.5726e-03, 2.1607e+01, 1.3386e+01, 8.6087e+00,\n",
       "        1.9674e+01, 1.5994e+01, 1.9218e+01, 1.3990e+01, 5.4658e+00, 1.3306e+01,\n",
       "        1.0966e+01, 7.3778e+00, 4.8761e+00, 7.2859e+00, 5.9489e+00, 7.2654e+00,\n",
       "        1.2752e+01, 9.5316e+00, 3.8809e+00, 1.2131e+01, 1.4180e+01, 7.5931e+00,\n",
       "        1.1456e+01, 5.7739e+00, 1.1338e+01, 1.2067e+01, 1.4043e+01, 7.3046e+00,\n",
       "        1.2074e+01, 9.8756e+00, 4.7968e-01, 6.9488e+00, 9.4756e+00, 4.8433e+00,\n",
       "        1.2606e+01, 1.4359e+01, 1.3846e+01, 1.1663e+01, 6.2291e+00, 7.9061e+00,\n",
       "        2.4580e+00, 2.8053e+00, 8.1402e+00, 3.1479e+00, 6.6411e+00, 3.8595e-01,\n",
       "        8.5913e+00, 1.4635e+01, 1.4451e+01, 1.1988e+01, 8.3239e+00, 1.5531e+01,\n",
       "        6.2787e+00, 1.2057e+01, 8.8100e+00, 1.2882e+01, 3.0027e-01, 1.1884e+01,\n",
       "        7.3730e+00, 1.1336e+01, 9.5796e+00, 6.9708e+00, 2.2095e+01, 5.0976e+00,\n",
       "        8.6211e+00, 1.3601e+01, 1.0556e+01, 6.3089e+00, 7.0896e+00, 1.6363e+01,\n",
       "        1.1323e+01, 1.5216e+01, 9.0809e+00, 1.5924e+01, 1.8947e+01, 6.5797e+00,\n",
       "        1.5773e+01, 1.1652e+01, 1.3167e+01, 1.4312e+01, 8.1882e+00, 7.4336e+00,\n",
       "        1.5864e+01, 9.0699e+00, 4.2691e+00, 9.8060e+00, 4.7070e+00, 1.8503e+01,\n",
       "        1.4675e+01, 6.3952e+00, 1.0764e+01, 1.0295e+01, 1.0047e+01, 1.5425e+01,\n",
       "        1.5972e+01, 1.4392e+01, 1.6011e+01, 8.0134e+00], device='cuda:0')), ('encoder.base.conv_block3.bn1.num_batches_tracked', tensor(586728, device='cuda:0')), ('encoder.base.conv_block3.bn2.weight', tensor([0.9051, 0.9394, 0.3467, 1.0366, 1.0479, 1.1572, 1.6049, 1.1137, 0.9935,\n",
       "        1.1752, 0.8874, 1.0937, 0.6876, 1.1102, 1.4864, 1.3248, 0.9897, 1.4706,\n",
       "        1.4177, 0.2613, 1.1516, 0.9729, 1.2617, 0.2820, 1.0827, 0.2616, 1.4487,\n",
       "        1.0664, 1.4253, 1.3209, 1.0332, 1.2626, 0.9325, 1.1220, 0.8981, 1.0424,\n",
       "        0.9619, 1.2507, 1.3945, 1.1734, 0.9084, 0.8654, 1.2673, 1.0337, 1.0987,\n",
       "        1.3766, 1.6624, 0.8357, 1.0707, 0.9537, 0.2633, 0.9885, 0.9755, 1.3231,\n",
       "        1.2518, 1.4758, 1.3703, 1.1539, 1.1889, 1.1905, 1.4671, 1.0795, 0.8962,\n",
       "        0.8735, 1.1473, 1.0061, 0.9262, 0.9056, 0.9279, 1.1607, 1.1400, 1.3418,\n",
       "        0.2692, 1.0091, 1.3077, 0.5176, 0.9112, 0.9307, 1.0229, 0.8897, 1.0297,\n",
       "        0.9391, 1.0971, 0.4626, 0.9116, 1.4098, 1.0808, 1.0182, 1.5772, 1.0186,\n",
       "        1.0702, 0.9926, 1.3717, 0.9138, 1.1040, 1.0963, 0.8279, 1.0532, 1.3980,\n",
       "        1.2943, 1.0913, 0.8435, 1.0859, 0.9802, 1.0216, 0.2935, 1.1645, 0.9617,\n",
       "        1.4009, 1.1233, 0.9578, 0.6571, 1.0725, 0.7002, 1.0372, 1.1292, 1.2509,\n",
       "        0.9716, 1.5299, 1.2976, 1.0172, 1.2507, 1.0353, 1.0831, 0.9625, 0.9419,\n",
       "        1.1977, 1.0909, 1.2755, 0.8902, 1.2145, 1.3266, 0.8319, 0.9505, 0.9411,\n",
       "        1.1432, 0.9254, 1.1651, 1.1642, 0.2505, 1.2972, 1.1613, 0.9954, 1.1288,\n",
       "        1.1554, 1.1024, 1.4579, 0.8870, 1.1077, 1.3331, 1.1827, 1.0637, 0.9267,\n",
       "        1.1762, 1.0574, 1.2458, 1.3292, 0.9216, 1.0776, 1.2446, 1.3153, 1.2265,\n",
       "        1.1726, 1.0782, 0.2623, 0.8875, 0.2963, 1.2376, 1.4084, 1.0460, 1.2456,\n",
       "        1.2219, 1.0095, 1.0642, 0.9782, 1.2341, 1.0097, 1.0705, 0.8490, 0.9098,\n",
       "        1.0768, 1.0270, 1.1807, 1.2606, 1.3560, 1.4065, 1.1395, 1.1043, 1.0956,\n",
       "        0.9400, 0.9232, 0.9482, 1.0033, 0.7078, 1.1307, 1.1774, 0.9191, 1.1546,\n",
       "        0.9854, 0.8554, 1.0341, 0.8977, 0.8860, 0.9033, 1.0850, 1.0711, 1.1451,\n",
       "        0.9898, 1.1208, 1.0563, 1.3754, 0.8993, 1.0484, 0.8753, 0.9922, 1.2163,\n",
       "        1.0892, 1.1947, 0.7565, 0.9142, 1.3299, 0.9942, 1.0805, 1.3669, 0.8534,\n",
       "        1.3016, 1.4345, 1.2004, 1.1323, 0.7956, 0.9888, 1.0292, 1.1574, 1.1866,\n",
       "        1.1543, 1.0344, 1.4174, 0.3030, 1.4229, 1.2801, 0.2937, 0.9351, 0.9618,\n",
       "        1.1582, 1.2652, 0.9315, 1.1234, 1.0876, 1.0357, 1.2522, 0.9250, 1.1716,\n",
       "        1.2080, 1.2942, 1.3198, 1.2777], device='cuda:0')), ('encoder.base.conv_block3.bn2.bias', tensor([-0.6634, -0.5544, -0.0422, -0.6581, -0.8572, -0.9712, -1.6261, -0.5950,\n",
       "        -0.7201, -1.2496, -0.5318, -0.7978, -0.1393, -0.6118, -1.3631, -1.3863,\n",
       "        -0.6188, -1.2326, -1.6330, -0.1872, -0.8443, -0.7549, -1.2820, -0.0505,\n",
       "        -1.1499, -0.0781, -1.2581, -1.0880, -1.3273, -1.2754, -0.6035, -0.7674,\n",
       "        -0.4481, -1.0971, -0.9998, -0.6411, -0.5971, -1.3235, -1.3134, -0.8110,\n",
       "        -0.5895, -0.6744, -0.8855, -1.1614, -1.0477, -1.3588, -1.3315, -0.6502,\n",
       "        -1.0932, -0.7254, -0.3861, -0.5992, -1.0614, -1.1524, -1.2114, -1.0342,\n",
       "        -1.3392, -0.7853, -0.7540, -0.9350, -1.7840, -0.9019, -0.7942, -0.5565,\n",
       "        -1.1643, -0.6610, -0.6357, -0.4942, -0.7252, -1.0780, -0.9504, -1.2680,\n",
       "        -0.0283, -0.9093, -1.0604,  0.0534, -0.5707, -0.8475, -0.7689, -0.7964,\n",
       "        -1.0437, -0.7244, -0.6308, -0.0799, -0.6952, -1.1794, -0.9914, -0.9248,\n",
       "        -1.2379, -0.8964, -1.0408, -0.6191, -1.2270, -0.5548, -0.9034, -1.1669,\n",
       "        -0.6484, -0.8183, -1.1430, -1.5660, -0.9298, -0.2687, -0.6611, -0.5908,\n",
       "        -0.7479, -0.0536, -1.2109, -0.8190, -1.3240, -0.9726, -0.5736, -0.2446,\n",
       "        -0.9323, -0.2670, -0.8135, -0.9782, -1.0693, -0.8946, -1.2197, -1.2017,\n",
       "        -0.8493, -1.0271, -0.7801, -0.9973, -0.5407, -0.5843, -0.8183, -0.9339,\n",
       "        -1.1637, -0.6353, -0.8803, -1.1417, -0.6053, -0.5750, -0.9905, -1.1236,\n",
       "        -0.7335, -0.7768, -1.1079, -0.0484, -1.5820, -1.2682, -0.9510, -0.8856,\n",
       "        -1.1036, -1.2498, -1.1422, -0.8046, -0.9191, -1.1010, -0.9548, -0.9208,\n",
       "        -0.7223, -0.7993, -0.9130, -0.6914, -1.4146, -0.8214, -0.7783, -0.7009,\n",
       "        -1.1782, -0.8517, -0.7981, -1.0004, -0.0658, -0.6777,  0.1841, -0.9849,\n",
       "        -1.3402, -0.8736, -0.5267, -0.7914, -0.9291, -1.1181, -0.5579, -0.9340,\n",
       "        -1.1616, -1.0515, -0.6710, -0.8138, -0.8020, -0.6899, -1.1364, -1.0139,\n",
       "        -0.7805, -1.3099, -0.3936, -0.8767, -0.4665, -0.8453, -0.6968, -0.5989,\n",
       "        -0.8351, -0.6806, -0.9338, -1.0715, -0.7662, -1.4438, -0.6182, -0.7659,\n",
       "        -1.0537, -0.5319, -0.5135, -0.9045, -0.5828, -0.8373, -0.9134, -0.7420,\n",
       "        -1.1932, -0.9939, -0.7015, -0.5463, -1.0515, -0.5218, -0.5948, -0.8505,\n",
       "        -1.0803, -0.9453, -0.5138, -0.3713, -1.3711, -0.6823, -0.7744, -1.3687,\n",
       "        -0.5889, -0.9297, -1.4539, -0.9427, -0.8768, -0.5206, -1.0093, -0.6510,\n",
       "        -0.8140, -1.1389, -1.1334, -0.8144, -1.4738,  0.0231, -1.1460, -1.0632,\n",
       "        -0.0401, -0.7883, -0.5025, -0.6524, -1.0350, -0.7857, -0.7549, -0.8493,\n",
       "        -0.7969, -0.8876, -0.9356, -0.6092, -1.0583, -1.3752, -1.4297, -1.2696],\n",
       "       device='cuda:0')), ('encoder.base.conv_block3.bn2.running_mean', tensor([-3.7632e+00, -9.0942e+00, -5.2324e+00, -1.6265e+01, -5.5120e+00,\n",
       "        -8.4833e+00, -9.1915e+00, -6.0935e+00, -8.4992e+00, -8.5229e+00,\n",
       "        -2.8742e+00, -7.1312e+00, -3.9346e+00, -8.3223e+00, -6.6446e+00,\n",
       "        -1.4633e+01, -1.2050e+01, -7.4102e+00, -4.1665e+00, -3.8852e+00,\n",
       "        -1.1782e+01,  2.0337e+00, -8.9674e+00, -3.5421e-02, -5.4318e+00,\n",
       "        -6.3430e-02, -6.1789e+00, -6.2252e-01, -1.2175e+01, -5.7403e+00,\n",
       "        -1.2922e+01, -5.8772e+00, -2.4498e+00, -1.0857e+01, -5.8939e+00,\n",
       "        -9.4072e+00, -1.1868e+01, -3.9199e+00, -5.9831e+00, -2.7893e+00,\n",
       "         3.7596e+00, -3.8224e+00, -3.7453e+00, -4.5187e+00, -5.4211e+00,\n",
       "        -1.2399e+01, -4.2647e+00, -4.7974e+00, -8.3507e+00, -6.2286e+00,\n",
       "        -8.4950e-04, -8.1919e+00, -4.1917e+00, -6.9957e+00, -7.5349e+00,\n",
       "        -6.9743e+00, -9.6604e+00, -1.1177e+01, -7.9157e+00, -1.6553e+01,\n",
       "        -9.1609e+00, -3.0231e+00, -2.9965e+00, -5.3564e+00, -9.3424e-01,\n",
       "        -9.2723e+00, -1.2275e+00, -7.0908e+00, -4.9050e+00, -1.0858e+01,\n",
       "        -7.0457e+00, -9.2624e+00, -1.0445e-01, -7.1027e+00, -8.7540e+00,\n",
       "        -1.2387e+00, -9.5546e+00, -1.3784e+01, -9.9896e+00, -3.3787e+00,\n",
       "        -3.7355e+00, -5.9943e+00, -7.1598e+00, -7.0738e+00, -7.9076e+00,\n",
       "        -1.8110e+00, -4.4033e+00, -1.7395e+00, -8.2204e+00, -6.1652e+00,\n",
       "        -4.9114e+00, -5.9712e+00, -7.1176e+00, -8.5425e+00, -1.4877e+01,\n",
       "        -8.2049e+00,  5.1621e+00, -1.2247e+01, -5.9140e+00, -1.8665e+00,\n",
       "        -1.9099e+00, -3.5394e+00, -5.9519e+00, -1.1243e+01, -1.0292e+01,\n",
       "         1.1542e-02, -6.1347e+00, -6.6159e+00, -9.0597e+00, -8.9896e+00,\n",
       "        -1.0409e+01, -7.9867e+00, -8.1136e+00, -3.0078e+00, -3.3415e+00,\n",
       "        -5.1625e+00, -1.3732e+01, -1.0659e+01, -5.9755e+00, -1.0130e+01,\n",
       "        -5.5045e+00, -2.5274e+00, -3.5657e+00, -9.2018e+00, -7.4413e+00,\n",
       "        -7.7006e+00, -7.7164e+00, -9.6146e+00, -6.2727e+00, -1.0488e+01,\n",
       "        -8.7456e+00, -2.5740e+00, -8.4706e+00, -4.7237e+00, -1.0442e+01,\n",
       "        -9.2775e+00, -1.2671e+01, -6.6309e+00, -4.2030e+00, -7.1187e-02,\n",
       "        -6.0836e+00, -1.0300e+01, -8.1018e+00, -2.2341e+00, -1.0689e+01,\n",
       "        -3.6317e+00, -6.1755e+00, -1.0596e+01, -7.7081e+00, -8.6579e+00,\n",
       "        -8.9929e+00, -1.1972e+01, -7.4886e+00, -7.2483e+00, -3.7808e+00,\n",
       "        -6.2587e+00, -9.2261e+00, -1.3240e+00, -5.2833e+00, -9.6430e-01,\n",
       "        -4.5933e+00, -1.0360e+01, -9.6514e+00, -5.7713e+00,  2.4909e-03,\n",
       "        -2.9826e+00, -1.4669e+00, -3.6351e+00, -8.7625e+00, -9.2196e+00,\n",
       "        -7.2660e+00, -6.4894e+00, -1.0512e+01, -4.7800e+00, -4.0744e+00,\n",
       "        -6.5161e+00, -6.5730e+00, -6.1712e+00, -5.0224e+00, -4.8053e+00,\n",
       "        -9.2358e+00, -1.0091e+01, -6.6775e+00, -5.6374e+00, -1.1505e+01,\n",
       "        -6.4864e+00, -4.7991e+00, -1.3428e+01, -4.4413e+00, -1.2248e+01,\n",
       "        -6.2546e+00, -6.6766e+00, -8.0788e+00,  3.5028e-01, -1.3248e+01,\n",
       "        -3.1043e+00, -6.8361e+00,  4.3378e-01, -6.2018e+00, -6.6109e+00,\n",
       "        -8.8146e+00, -5.1341e+00, -3.5145e+00, -5.8523e+00, -1.0397e+01,\n",
       "        -6.2023e+00, -1.1400e+01, -3.9769e+00,  3.1227e+00, -6.3729e+00,\n",
       "        -9.1428e+00, -8.1317e+00, -8.6478e+00, -1.1008e+01, -5.5727e+00,\n",
       "        -9.6256e+00,  2.6206e+00, -8.8840e+00, -3.4394e+00, -1.0024e+01,\n",
       "         2.8129e+00, -1.0264e+01, -7.9636e+00, -1.0159e+01, -7.5524e+00,\n",
       "        -7.6272e+00, -5.8084e+00, -7.2452e+00, -1.0212e+01, -2.0675e+00,\n",
       "        -6.7425e+00, -4.5466e+00, -1.0737e+01, -6.6364e+00, -3.5613e+00,\n",
       "        -1.0022e+01, -1.0441e+01,  2.3489e+00, -5.4235e+00, -5.9015e+00,\n",
       "        -5.0889e-02, -1.1071e+01, -1.1174e+01, -1.0034e+01, -6.0598e+00,\n",
       "        -7.0747e+00, -2.3704e+00, -1.0295e+01, -1.0242e+00, -4.4956e+00,\n",
       "        -8.1543e+00, -6.5005e+00, -5.4108e+00, -9.8053e+00, -6.2623e+00,\n",
       "        -9.3068e+00], device='cuda:0')), ('encoder.base.conv_block3.bn2.running_var', tensor([ 40.5723,  65.7030,  11.8584,  67.4836,  26.6316,  50.4351,  54.1779,\n",
       "         30.1589,  42.8167,  49.9692,  28.4224,  31.3713,  32.0274,  46.6070,\n",
       "         48.1286,  58.4122,  31.7544,  44.7766,  27.0445,   4.2099,  77.1243,\n",
       "         30.4201,  58.8890,   0.4141,  20.1350,   0.2635,  45.1380,  20.2287,\n",
       "         68.0608,  23.5049,  37.5302,  53.7064,  54.6602,  58.0534,  29.1404,\n",
       "         47.6535,  51.5917,  63.7634,  55.1338,  25.2223,  41.3617,  52.7705,\n",
       "         34.5100,  53.7506,  58.5715,  46.6809,  34.5419,  36.1039,  36.5626,\n",
       "         25.8292,   0.2981,  28.9679,  40.5153,  60.2064,  33.9075,  30.9585,\n",
       "         36.4447,  51.0632,  52.7367,  81.1930,  42.4597,  43.4219,  22.2235,\n",
       "         40.2748,  34.3417,  72.5276,  45.0313,  53.1840,  34.8067,  42.1514,\n",
       "         47.2410,  58.1298,   0.4201,  56.7860,  30.6251,  20.6250,  42.2545,\n",
       "         76.7949,  25.8407,  49.3553,  76.2543,  51.0976,  22.5277,  15.0258,\n",
       "         38.6420,  30.9443,  61.9598,  59.8144,  44.0024,  55.4643,  46.6360,\n",
       "         43.7867,  43.8053,  51.5570,  97.5555,  23.4702,  22.3750,  35.2476,\n",
       "         50.9145,  19.7545,  36.8942,  21.6182,  36.6579,  56.8219,  43.5087,\n",
       "          0.3208,  36.8081,  42.6586,  53.6447,  42.7517,  53.7115,  24.3025,\n",
       "         44.2902,  32.6030,  67.9141,  46.2343,  49.2114,  41.4842,  31.3825,\n",
       "         52.1681,  76.2221,  33.6903,  59.1630,  35.9490,  39.6129,  37.6400,\n",
       "         32.5703,  65.5450,  30.8750,  45.4082,  45.8819,  26.3946,  47.4205,\n",
       "         49.1348,  43.3766,  27.2011,  75.8063,  63.7155,  46.3493,   0.3979,\n",
       "         26.5054,  45.8701,  69.3298,  56.8755,  59.8682,  42.5232,  41.1253,\n",
       "         43.6935,  53.3741,  32.5585,  35.8902,  43.9328,  45.5414,  31.5621,\n",
       "         48.7838,  47.2220,  29.6616,  15.5673,  22.2395,  28.9994,  24.2479,\n",
       "        102.9704,  39.9512,  32.3244,   0.2558,  24.3601,   5.2302,  29.5106,\n",
       "         41.3319,  75.3155,  37.3672,  22.4993,  59.5364,  46.9117,  39.3268,\n",
       "         40.9311,  52.5730,  72.9468,  33.1480,  19.0017,  71.2979,  35.3832,\n",
       "         37.9487,  45.4771,  41.7069,  36.8463,  41.5128,  85.9343,  30.5077,\n",
       "         42.6010,  37.2925,  42.0592,  56.6934,  15.7602,  47.6612,  30.0385,\n",
       "         47.0208,  33.2221,  44.7548,  24.5391,  45.9706,  31.9674,  36.1938,\n",
       "         60.4913,  29.1829,  31.4370,  53.4403,  28.3113,  34.7869,  70.9355,\n",
       "         68.1365,  40.4803,  36.3636,  47.1711,  22.1173,  38.4825,  39.3975,\n",
       "         43.7432,  29.4210,  34.8596,  30.4687,  68.7060,  67.3378,  26.3805,\n",
       "         41.5847,  35.6842,  35.0291,  37.1290,  36.2059,  46.2787,  39.5105,\n",
       "         37.2341,  50.8404,  27.8260,  38.5722,  46.0524,  38.2611,  10.2442,\n",
       "         46.6448,  30.8053,   0.3152,  29.1311,  45.0049,  35.8925,  31.2280,\n",
       "         37.7955,  27.8912,  45.8276,  33.1744,  29.8663,  32.7236,  57.9544,\n",
       "         47.7023,  37.2118,  48.3244,  38.3405], device='cuda:0')), ('encoder.base.conv_block3.bn2.num_batches_tracked', tensor(586728, device='cuda:0')), ('encoder.base.conv_block4.conv1.weight', tensor([[[[-2.8117e-01, -1.9448e-01, -3.2072e-01],\n",
       "          [ 1.6667e-01,  7.5469e-03, -1.2761e-01],\n",
       "          [ 1.5804e-01,  1.4452e-01,  5.4735e-03]],\n",
       "\n",
       "         [[ 5.7425e-03, -1.6190e-02, -4.9775e-01],\n",
       "          [ 6.9577e-02,  3.7016e-02, -2.2179e-01],\n",
       "          [-2.1399e-01, -1.8292e-01, -2.7259e-01]],\n",
       "\n",
       "         [[-3.2275e-02,  6.3697e-02,  3.6232e-02],\n",
       "          [-1.0834e-02,  2.3389e-01, -1.6246e-02],\n",
       "          [ 1.3494e-01,  1.3342e-01, -1.4910e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0493e-01,  6.6150e-03,  9.4810e-02],\n",
       "          [ 7.5323e-02, -8.4515e-02, -2.6031e-01],\n",
       "          [-4.4923e-02,  1.3767e-01, -1.3903e-02]],\n",
       "\n",
       "         [[ 5.8768e-02,  3.0249e-03,  1.2129e-01],\n",
       "          [-1.4058e-02, -1.4894e-02,  1.1285e-01],\n",
       "          [ 7.8302e-02, -5.2702e-03,  1.2461e-01]],\n",
       "\n",
       "         [[-2.8437e-02, -1.5080e-01, -1.7280e-02],\n",
       "          [ 2.3192e-01, -1.1718e-02, -4.4942e-02],\n",
       "          [ 6.1271e-01,  2.4129e-01,  1.4843e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.8397e-01,  1.0231e-01, -3.6553e-04],\n",
       "          [ 3.4619e-01,  2.6139e-01,  2.4499e-01],\n",
       "          [ 3.5390e-01,  2.8168e-01,  3.8342e-01]],\n",
       "\n",
       "         [[ 8.4976e-02,  2.6384e-01,  9.5468e-02],\n",
       "          [-2.7714e-02, -2.2332e-02, -4.8102e-02],\n",
       "          [-1.7257e-01,  6.8492e-02,  1.0205e-01]],\n",
       "\n",
       "         [[-2.5342e-02, -1.5528e-02, -6.1688e-02],\n",
       "          [-2.7608e-02, -2.5081e-02, -6.0266e-02],\n",
       "          [ 6.7514e-04, -1.2479e-03, -4.8764e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.2393e-01, -9.4306e-02, -1.9476e-01],\n",
       "          [ 5.8398e-03, -7.9925e-02, -4.1517e-01],\n",
       "          [-5.0327e-02, -1.9655e-01, -1.1735e-01]],\n",
       "\n",
       "         [[ 2.7297e-01, -4.6044e-02,  2.8592e-02],\n",
       "          [ 7.4112e-01, -5.0212e-02, -1.0976e-01],\n",
       "          [ 6.0514e-01, -6.1636e-02,  1.5829e-01]],\n",
       "\n",
       "         [[-8.9858e-02, -1.4299e-01, -8.8171e-02],\n",
       "          [-2.7729e-02, -5.3546e-02,  1.1596e-03],\n",
       "          [ 1.9970e-01,  5.9318e-02,  1.9625e-01]]],\n",
       "\n",
       "\n",
       "        [[[-5.5145e-02, -7.8992e-02, -2.5136e-02],\n",
       "          [-4.0007e-02, -3.4993e-02, -4.9632e-02],\n",
       "          [ 2.2835e-02, -8.2773e-02, -1.4480e-01]],\n",
       "\n",
       "         [[ 8.8546e-02, -1.3631e-03,  7.4954e-05],\n",
       "          [ 2.7300e-02, -2.4629e-02, -6.8863e-02],\n",
       "          [ 9.9173e-02,  2.9239e-02, -1.0297e-02]],\n",
       "\n",
       "         [[ 1.6983e-02,  3.6542e-03, -6.4787e-02],\n",
       "          [ 9.0322e-02,  2.4170e-02, -5.2050e-02],\n",
       "          [ 6.6579e-02,  4.9823e-02, -2.5309e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.4695e-02,  4.1721e-02, -5.1636e-02],\n",
       "          [-6.5091e-02, -4.3530e-02, -1.4238e-01],\n",
       "          [-5.6960e-02, -3.9052e-02, -1.4414e-01]],\n",
       "\n",
       "         [[ 1.1531e-02,  5.8840e-02,  4.7447e-02],\n",
       "          [ 6.2048e-02,  1.1637e-01,  5.8397e-02],\n",
       "          [ 5.2231e-03, -4.5418e-03, -3.0628e-02]],\n",
       "\n",
       "         [[ 5.5873e-03,  3.9302e-02, -1.9303e-02],\n",
       "          [-8.0556e-02,  4.2154e-03, -8.2461e-02],\n",
       "          [-1.3790e-01, -1.9746e-02, -1.8784e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.5198e-01, -3.6075e-02, -1.4837e-01],\n",
       "          [-2.3885e-01, -2.8460e-02, -1.0875e-01],\n",
       "          [-1.4545e-01, -7.0426e-02, -6.8133e-02]],\n",
       "\n",
       "         [[-5.5952e-02, -4.0911e-02, -3.3310e-02],\n",
       "          [-1.7451e-01, -8.7108e-02,  1.2693e-02],\n",
       "          [-7.0759e-02, -4.8385e-02, -3.3718e-03]],\n",
       "\n",
       "         [[ 2.9875e-02,  6.5026e-03, -1.0522e-01],\n",
       "          [ 9.7180e-02,  5.2470e-02, -5.8483e-02],\n",
       "          [ 1.0137e-02,  2.4127e-02, -2.8789e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.7989e-02,  1.1075e-01,  9.5427e-02],\n",
       "          [ 2.2058e-02,  4.7560e-02,  4.7533e-02],\n",
       "          [-1.4979e-02, -4.1187e-02, -8.4268e-03]],\n",
       "\n",
       "         [[-5.8950e-03, -4.3256e-02, -1.0115e-01],\n",
       "          [-4.2977e-02,  7.3435e-04, -1.7013e-02],\n",
       "          [-1.0561e-01, -1.1956e-01, -4.2652e-02]],\n",
       "\n",
       "         [[-3.0934e-02, -1.9715e-02, -4.4373e-02],\n",
       "          [ 1.9279e-01,  1.6256e-01,  1.3915e-01],\n",
       "          [ 4.7260e-02,  1.3291e-01, -8.4166e-03]]],\n",
       "\n",
       "\n",
       "        [[[-3.3602e-02,  2.0539e-02,  1.2633e-01],\n",
       "          [-2.9732e-02,  6.9290e-02,  1.5418e-01],\n",
       "          [ 7.1638e-02,  9.3394e-02,  1.5287e-01]],\n",
       "\n",
       "         [[-1.8831e-02,  1.6386e-02, -3.7939e-02],\n",
       "          [-5.5418e-02,  3.2672e-03, -3.0469e-02],\n",
       "          [ 1.9739e-03,  4.9307e-02, -2.8697e-02]],\n",
       "\n",
       "         [[ 1.1110e-02, -9.3922e-03, -1.0620e-01],\n",
       "          [ 5.1250e-02,  4.8479e-02, -1.5916e-01],\n",
       "          [ 2.6691e-02,  6.9313e-02, -1.7979e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.3847e-02, -1.4713e-02, -1.0052e-01],\n",
       "          [ 1.9321e-02,  8.7875e-03, -5.4893e-02],\n",
       "          [ 3.4401e-02,  1.7562e-02,  1.9163e-02]],\n",
       "\n",
       "         [[-1.8030e-04,  7.7708e-02,  1.5777e-01],\n",
       "          [ 1.7430e-02,  5.9972e-02,  1.0575e-01],\n",
       "          [-6.3385e-03,  6.1964e-02,  2.0596e-01]],\n",
       "\n",
       "         [[ 4.0382e-02,  1.6917e-01,  1.4179e-01],\n",
       "          [ 6.5023e-02,  7.9723e-02,  1.8729e-01],\n",
       "          [ 4.7586e-02,  1.4556e-01,  8.0061e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.9561e-02,  1.6063e-02,  4.5139e-02],\n",
       "          [-1.0781e-01, -1.5374e-02,  8.8728e-05],\n",
       "          [-4.4376e-02,  5.6114e-03,  6.6437e-02]],\n",
       "\n",
       "         [[-2.1091e-02,  1.9502e-03, -5.8937e-02],\n",
       "          [-4.3717e-02, -4.9178e-03, -1.5190e-01],\n",
       "          [ 6.7578e-02,  5.1915e-02,  2.1604e-02]],\n",
       "\n",
       "         [[ 2.7038e-03, -4.4696e-02, -8.6027e-02],\n",
       "          [ 8.1351e-02,  3.4863e-02, -1.7840e-01],\n",
       "          [ 3.4614e-02,  3.6288e-02, -1.2641e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.3675e-03,  1.8449e-02, -4.5892e-02],\n",
       "          [ 3.9285e-02,  1.1169e-02, -4.6597e-02],\n",
       "          [ 1.1016e-02, -1.7599e-02, -4.0958e-02]],\n",
       "\n",
       "         [[ 1.7124e-02,  4.0852e-02,  7.1878e-02],\n",
       "          [ 1.9256e-02,  2.0039e-02,  6.9166e-02],\n",
       "          [ 8.0109e-02,  1.0178e-01,  1.2642e-01]],\n",
       "\n",
       "         [[-1.3671e-02,  2.6154e-02, -1.1227e-03],\n",
       "          [-5.0951e-02,  1.0144e-02, -8.1067e-02],\n",
       "          [-4.0022e-02, -1.2864e-02, -1.0272e-01]]]], device='cuda:0')), ('encoder.base.conv_block4.conv2.weight', tensor([[[[-1.3141e-01, -1.7014e-01, -3.1536e-01],\n",
       "          [ 1.4788e-04, -1.2086e-01, -3.0856e-01],\n",
       "          [-5.1835e-02, -1.7605e-01, -3.0941e-01]],\n",
       "\n",
       "         [[-1.5246e-01, -1.2831e-01, -4.4812e-02],\n",
       "          [-1.6314e-01, -1.2917e-01, -7.5320e-02],\n",
       "          [-1.5122e-01, -1.1717e-01, -1.5710e-01]],\n",
       "\n",
       "         [[-5.3818e-02, -5.1342e-02, -1.5757e-01],\n",
       "          [-7.5635e-02, -9.9171e-02, -2.1828e-01],\n",
       "          [-1.0729e-03, -1.0431e-01, -2.2602e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4321e-02, -2.2552e-02, -8.8848e-02],\n",
       "          [-2.5956e-02, -3.5327e-02, -1.3773e-01],\n",
       "          [ 8.9133e-03,  3.0740e-03, -1.0050e-01]],\n",
       "\n",
       "         [[ 6.3828e-02,  1.4987e-05, -3.2330e-02],\n",
       "          [ 1.6951e-03, -2.7668e-02, -1.7322e-01],\n",
       "          [-6.9142e-03, -5.0586e-02, -1.9127e-01]],\n",
       "\n",
       "         [[-3.0931e-02, -6.4165e-02, -1.4262e-01],\n",
       "          [-5.3583e-02, -1.3207e-01, -2.6642e-01],\n",
       "          [-4.2838e-02, -6.4026e-02, -2.8391e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 9.9623e-02, -6.3867e-02,  2.5452e-02],\n",
       "          [ 1.1098e-01, -3.8810e-02,  1.3309e-01],\n",
       "          [ 1.2145e-01, -2.1395e-02,  1.1927e-01]],\n",
       "\n",
       "         [[ 2.8668e-01,  1.7305e-02,  8.8408e-02],\n",
       "          [ 2.5384e-01, -1.9117e-01, -2.0238e-01],\n",
       "          [ 2.4004e-01, -2.0833e-01, -1.6091e-01]],\n",
       "\n",
       "         [[-2.6671e-02, -1.1001e-01,  3.0393e-02],\n",
       "          [ 4.0007e-04, -1.1037e-01,  4.0861e-03],\n",
       "          [-1.8974e-02, -1.4899e-01,  2.3437e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.5335e-02, -6.9298e-02, -4.2384e-03],\n",
       "          [-3.2748e-02, -7.9837e-02, -3.2012e-02],\n",
       "          [-9.6534e-02, -1.6497e-01, -8.8456e-02]],\n",
       "\n",
       "         [[-1.4191e-02, -5.7730e-02,  7.7663e-02],\n",
       "          [-1.6944e-02, -1.2329e-01,  6.6457e-02],\n",
       "          [-3.9793e-02, -5.5077e-02,  1.8633e-02]],\n",
       "\n",
       "         [[-4.3596e-02, -1.3971e-01,  1.0534e-02],\n",
       "          [-4.4777e-02, -1.0370e-01,  2.5256e-02],\n",
       "          [-2.9126e-02, -1.2420e-01,  1.6884e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.2084e-01, -6.4760e-02,  1.3030e-01],\n",
       "          [-1.3044e-01, -2.5075e-02,  1.6151e-02],\n",
       "          [-8.7644e-02,  1.5531e-03,  1.7084e-02]],\n",
       "\n",
       "         [[ 1.0630e-01,  6.8825e-02,  1.0841e-01],\n",
       "          [ 6.3294e-02,  5.6313e-02,  9.1738e-02],\n",
       "          [-8.5978e-02,  4.0142e-03,  4.2442e-02]],\n",
       "\n",
       "         [[-7.9506e-02, -5.3952e-01, -4.3850e-02],\n",
       "          [-1.0070e-01, -6.0278e-01, -6.0825e-02],\n",
       "          [-4.1294e-02, -4.5038e-01, -5.5793e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.0779e-02, -9.0226e-03,  3.3375e-03],\n",
       "          [ 8.1960e-04, -7.6463e-02, -3.6247e-02],\n",
       "          [ 1.9942e-02, -4.3963e-02, -3.7640e-02]],\n",
       "\n",
       "         [[-4.5117e-02, -9.3657e-02, -1.9836e-03],\n",
       "          [-5.8529e-02, -8.0018e-02, -3.1515e-02],\n",
       "          [-1.2475e-02, -7.1371e-02, -4.3010e-03]],\n",
       "\n",
       "         [[-5.3049e-02, -1.5731e-01, -2.5275e-02],\n",
       "          [-5.1301e-02, -2.0356e-01, -2.3456e-02],\n",
       "          [-2.6011e-02, -1.6314e-01, -5.0286e-03]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.3632e-03, -1.2925e-02,  6.8488e-04],\n",
       "          [-9.8775e-02, -8.1714e-02, -3.4547e-02],\n",
       "          [-1.1710e-02, -7.6958e-02, -6.0914e-02]],\n",
       "\n",
       "         [[-1.0509e-01, -1.0036e-01, -3.5899e-02],\n",
       "          [-1.3978e-01, -1.4804e-01, -3.0534e-02],\n",
       "          [-1.9116e-01, -1.2482e-01, -7.7175e-02]],\n",
       "\n",
       "         [[ 1.0296e-02, -6.9565e-02,  7.9738e-02],\n",
       "          [ 2.8699e-02, -1.6072e-01,  6.3567e-02],\n",
       "          [ 1.6107e-02, -1.5727e-01,  4.8203e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.1035e-02, -1.2945e-01,  1.2868e-02],\n",
       "          [-1.6226e-01, -2.2084e-01, -4.9709e-03],\n",
       "          [-2.6686e-02, -8.8472e-02,  4.4570e-02]],\n",
       "\n",
       "         [[-5.2616e-03, -5.7111e-02,  5.4005e-02],\n",
       "          [-2.7419e-02, -9.5018e-02,  4.9039e-02],\n",
       "          [-2.7858e-04, -2.4506e-02,  3.1993e-02]],\n",
       "\n",
       "         [[-3.8276e-02, -7.3607e-02, -9.0714e-03],\n",
       "          [-5.5761e-02, -1.2196e-01,  4.7025e-03],\n",
       "          [-1.7847e-02, -1.2619e-01,  4.5440e-02]]],\n",
       "\n",
       "\n",
       "        [[[-9.4819e-02, -1.4828e-01, -1.0668e-01],\n",
       "          [ 4.5886e-02,  2.8900e-02,  4.0922e-02],\n",
       "          [ 1.8913e-03,  2.3505e-02,  1.6824e-01]],\n",
       "\n",
       "         [[ 1.5831e-01,  1.1025e-01,  3.2725e-01],\n",
       "          [ 3.3227e-01,  2.0414e-01,  3.9934e-01],\n",
       "          [ 3.2118e-01,  2.7469e-01,  3.1816e-01]],\n",
       "\n",
       "         [[ 4.3839e-03, -1.8127e-01,  3.0586e-02],\n",
       "          [-5.1334e-02, -2.2614e-01,  6.0986e-02],\n",
       "          [-9.7718e-03, -2.2800e-01,  7.6102e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.9273e-02, -9.4798e-02, -1.8765e-02],\n",
       "          [ 2.7452e-02, -1.2884e-01, -6.5547e-03],\n",
       "          [-1.1060e-01, -2.2181e-01, -8.4998e-02]],\n",
       "\n",
       "         [[-1.2539e-02, -9.0758e-02,  3.2262e-02],\n",
       "          [-2.7983e-02, -1.2655e-01,  1.7510e-03],\n",
       "          [-7.8804e-03, -1.0630e-01,  3.6500e-02]],\n",
       "\n",
       "         [[-4.5780e-02, -1.7082e-01,  3.4723e-02],\n",
       "          [-4.5897e-02, -2.2459e-01, -1.2138e-02],\n",
       "          [-5.9276e-02, -1.9904e-01, -7.6359e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.4527e-02,  2.3626e-03,  3.5323e-02],\n",
       "          [ 5.2964e-02,  8.6002e-03,  9.5076e-02],\n",
       "          [ 2.5534e-01,  2.2776e-01,  6.3691e-01]],\n",
       "\n",
       "         [[-3.1473e-01, -1.5584e-01, -2.4066e-01],\n",
       "          [-5.6614e-01, -2.5919e-01, -4.8721e-01],\n",
       "          [-4.7625e-01, -4.3592e-01, -5.6699e-01]],\n",
       "\n",
       "         [[-8.0138e-02, -2.7227e-01, -3.8287e-03],\n",
       "          [-8.9857e-02, -3.3922e-01, -7.3446e-03],\n",
       "          [-8.2277e-02, -2.2914e-01, -2.5482e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.4436e-02, -1.6535e-01, -6.6169e-02],\n",
       "          [-1.0076e-01, -1.9541e-01, -2.1543e-02],\n",
       "          [-4.8573e-02, -2.3831e-01, -7.6474e-02]],\n",
       "\n",
       "         [[-6.5030e-02, -1.0340e-01, -1.7654e-02],\n",
       "          [-4.2388e-02, -9.1843e-02, -4.4946e-02],\n",
       "          [-5.0771e-02, -9.4325e-02, -3.5689e-02]],\n",
       "\n",
       "         [[-1.0607e-01, -1.3761e-01, -1.6891e-01],\n",
       "          [-7.1688e-02, -1.0667e-01, -9.9844e-02],\n",
       "          [-6.6565e-02, -1.0376e-01, -2.3241e-02]]]], device='cuda:0')), ('encoder.base.conv_block4.bn1.weight', tensor([1.0171, 0.5798, 0.5005, 0.9467, 0.4131, 0.9769, 0.4462, 1.0130, 0.9361,\n",
       "        1.1435, 1.0755, 0.8172, 1.2160, 1.1708, 0.8326, 1.0605, 1.3565, 1.1408,\n",
       "        0.9933, 1.1301, 1.0148, 1.1272, 0.9770, 0.5058, 0.8135, 0.6770, 1.1596,\n",
       "        1.0459, 1.0975, 1.0943, 1.0097, 0.8133, 1.1153, 0.8899, 1.0428, 1.2536,\n",
       "        0.9832, 0.6203, 0.9139, 0.8731, 0.6918, 1.1260, 0.2733, 1.0130, 1.0926,\n",
       "        1.0720, 1.1631, 1.1839, 0.5973, 1.1405, 1.1763, 0.9800, 1.0225, 1.0436,\n",
       "        0.8502, 1.1530, 0.9835, 1.3239, 0.6362, 0.9547, 0.8648, 0.7036, 0.9891,\n",
       "        0.8956, 0.6684, 1.0972, 0.9076, 0.6384, 0.8603, 1.0418, 0.8226, 0.9889,\n",
       "        0.4692, 0.4991, 0.8975, 0.8536, 1.2099, 0.9635, 1.1211, 1.0741, 1.1748,\n",
       "        1.0328, 0.9639, 0.8464, 0.9222, 0.8646, 0.9812, 1.0259, 0.9026, 1.0985,\n",
       "        1.3200, 1.3520, 0.8091, 0.8493, 1.0194, 0.5287, 0.9658, 0.9977, 0.9788,\n",
       "        1.3655, 0.4898, 0.7785, 0.9938, 0.4714, 0.3356, 0.9735, 0.8762, 0.8690,\n",
       "        1.3053, 0.7439, 0.7643, 0.6878, 1.0019, 1.0641, 1.0696, 1.1539, 1.1049,\n",
       "        0.8718, 1.3012, 0.9538, 0.9531, 0.5643, 1.0746, 0.9723, 0.8656, 1.3475,\n",
       "        0.9380, 0.8953, 1.3727, 0.4535, 1.1457, 0.6542, 1.0409, 1.0981, 0.9023,\n",
       "        1.1144, 1.0815, 1.2134, 0.8978, 0.9925, 0.8624, 1.0421, 1.3380, 1.1504,\n",
       "        0.9870, 0.4670, 1.0330, 1.1302, 1.1419, 1.2744, 1.2785, 1.2513, 1.0941,\n",
       "        1.1802, 1.2290, 1.3752, 0.9396, 0.9662, 0.9707, 1.0778, 0.3860, 0.9183,\n",
       "        1.1586, 0.8619, 0.6188, 1.1147, 1.3675, 1.0019, 1.1476, 1.0775, 1.0792,\n",
       "        1.1930, 0.9706, 0.9071, 0.9174, 0.9868, 0.7037, 0.7321, 0.8768, 1.0496,\n",
       "        0.9915, 1.0660, 0.8966, 0.9964, 0.8852, 1.2159, 1.1580, 0.7111, 0.4730,\n",
       "        1.0353, 1.0192, 0.8928, 1.2706, 1.4263, 0.9980, 0.3532, 0.4918, 0.9829,\n",
       "        0.7474, 1.0839, 0.5446, 1.0956, 1.0380, 1.0943, 1.0517, 0.7094, 1.0557,\n",
       "        0.6625, 1.1248, 1.0023, 1.5281, 1.3572, 1.0759, 0.7746, 1.2011, 1.1546,\n",
       "        0.5964, 0.9852, 0.8495, 0.9046, 0.9232, 1.2807, 0.5028, 0.9053, 1.1093,\n",
       "        1.2315, 1.0267, 1.0194, 1.2623, 0.9689, 1.0482, 1.0786, 0.8586, 0.4864,\n",
       "        1.2161, 1.0685, 1.0953, 0.9853, 0.8778, 1.0397, 1.2730, 0.9377, 1.2230,\n",
       "        0.9753, 1.0981, 0.5209, 0.9376, 0.6086, 0.4151, 0.7702, 0.9797, 1.2388,\n",
       "        1.0349, 0.9509, 0.8632, 1.2876, 1.6126, 1.1258, 0.4149, 1.0089, 1.0519,\n",
       "        0.8221, 1.2245, 1.0256, 1.0461, 0.9651, 0.8645, 1.0192, 1.0774, 1.0158,\n",
       "        1.1035, 0.9729, 1.2657, 1.1162, 1.0492, 0.8497, 1.1300, 1.0705, 0.9149,\n",
       "        0.5904, 0.9442, 1.1462, 0.9009, 1.3760, 0.4095, 1.0837, 1.2117, 0.5813,\n",
       "        1.1220, 1.3137, 0.5588, 1.1104, 0.7647, 0.8270, 1.7138, 1.0442, 0.9528,\n",
       "        1.1511, 0.8160, 1.0942, 1.2062, 1.0723, 0.9839, 1.4398, 1.0917, 1.1048,\n",
       "        1.0294, 1.0739, 1.1939, 1.0529, 1.0129, 1.0052, 1.4338, 1.0208, 0.9004,\n",
       "        1.1145, 0.8237, 1.2433, 0.9026, 1.0068, 1.1364, 0.9539, 0.7693, 1.0401,\n",
       "        1.3652, 0.4287, 1.0163, 0.9942, 1.1042, 0.4577, 0.9942, 0.9551, 0.9146,\n",
       "        1.0011, 1.1516, 0.9862, 0.7260, 1.1630, 1.0532, 0.9281, 0.9433, 0.6011,\n",
       "        0.6257, 1.1354, 0.9504, 0.9805, 0.9760, 0.9792, 0.4477, 0.7953, 0.9629,\n",
       "        0.8023, 1.1022, 1.1797, 0.8836, 1.0323, 0.5699, 1.0605, 1.1273, 1.0621,\n",
       "        0.7290, 0.9571, 0.8671, 0.6478, 0.3853, 0.9439, 0.8821, 0.8617, 0.4659,\n",
       "        1.0389, 0.3590, 1.1582, 0.9726, 1.0988, 1.0964, 0.8692, 1.2900, 0.8554,\n",
       "        1.1174, 0.9015, 0.9937, 1.2691, 0.9923, 0.9630, 1.0504, 0.7922, 0.5388,\n",
       "        1.0412, 1.0914, 0.9493, 1.1033, 0.9571, 0.9168, 0.9361, 1.1429, 0.4560,\n",
       "        1.0962, 1.0570, 0.6944, 1.0913, 1.0084, 0.9310, 0.8042, 0.9676, 1.1645,\n",
       "        1.0108, 0.9704, 0.8509, 0.8505, 0.9832, 0.9930, 1.0751, 0.9806, 1.0307,\n",
       "        1.1843, 1.0450, 0.8979, 0.8262, 0.7724, 0.8858, 0.9827, 1.0757, 1.1863,\n",
       "        0.9124, 0.8604, 1.0140, 1.1726, 0.8133, 0.9450, 0.7757, 0.9359, 0.8902,\n",
       "        0.4347, 0.8054, 0.9967, 0.8918, 1.1201, 0.8330, 1.3714, 0.6347, 0.6996,\n",
       "        0.9285, 0.9511, 1.2236, 1.0164, 0.8717, 1.0107, 1.2076, 0.9399, 1.1091,\n",
       "        0.9706, 1.1365, 1.0346, 1.1798, 1.2603, 1.0090, 0.9313, 0.8644, 1.0968,\n",
       "        0.7437, 1.1048, 1.1171, 0.9892, 0.9939, 1.4142, 1.0721, 1.1209, 1.0621,\n",
       "        1.1425, 0.8798, 1.1274, 0.9831, 1.0430, 0.9428, 0.3956, 0.9816, 1.0278,\n",
       "        0.9393, 0.9891, 1.3775, 1.0050, 0.8539, 0.9556, 1.1961, 1.1283, 1.0901,\n",
       "        0.9547, 1.0527, 1.6421, 1.0322, 1.0283, 0.7542, 0.9550, 1.1278, 0.9013,\n",
       "        1.0847, 1.1320, 0.8843, 1.1033, 1.0025, 1.0018, 1.0766, 0.2731, 1.0976,\n",
       "        1.3175, 1.2517, 1.0063, 1.2144, 1.1150, 0.8921, 0.4834, 0.4870],\n",
       "       device='cuda:0')), ('encoder.base.conv_block4.bn1.bias', tensor([-0.9268, -0.6266, -0.5309, -0.6357, -0.5046, -1.1536, -0.5173, -1.4939,\n",
       "        -0.7832, -1.5075, -0.6342, -0.5730, -1.1893, -1.1652, -0.7942, -1.0887,\n",
       "        -1.3104, -1.3070, -0.8438, -1.5253, -0.9678, -1.0071, -0.9260, -0.5962,\n",
       "        -1.2304, -0.2258, -0.6201, -0.8741, -0.9973, -0.2882, -1.0181, -0.0473,\n",
       "        -1.2342, -0.8188, -0.9273, -1.0032, -1.1131, -0.5810, -0.9244, -0.8191,\n",
       "        -0.4738, -0.7664, -0.1053, -1.1785, -1.2238, -1.2519, -1.0774, -1.7462,\n",
       "        -1.2521, -1.0098, -1.3732, -1.0013, -0.9384, -0.9089, -0.7262, -1.2270,\n",
       "        -1.0483, -1.5191, -0.4390, -1.0361, -0.8670, -0.8597, -1.4813, -0.6777,\n",
       "        -0.4823, -1.1131, -0.8683, -0.1681, -0.6160, -1.1000, -0.6691, -0.6610,\n",
       "         0.1074, -0.4299, -0.8592, -0.8151, -1.7040, -1.0895, -0.9872, -1.5288,\n",
       "        -1.1496, -0.6807, -0.8016, -0.7891, -0.9479, -0.6210, -1.0759, -1.1950,\n",
       "        -0.9956, -1.2665, -1.5158, -1.7583, -0.7382, -0.5999, -0.9451, -0.5500,\n",
       "        -1.0278, -0.6882, -1.0760, -1.4877, -0.7106, -0.9699, -1.1468, -0.5725,\n",
       "        -0.2269, -1.4250, -0.7481, -0.9016, -1.3545, -0.4090, -0.5920, -0.7844,\n",
       "        -1.2422, -1.0947, -1.3283, -1.2184, -1.1426, -0.8193, -1.3204, -0.8605,\n",
       "        -0.7378, -0.5170, -1.3469, -1.0916, -0.9371, -1.4747, -1.0785, -1.3800,\n",
       "        -1.3396, -0.4237, -1.3274, -0.8327, -0.8605, -1.2755, -0.9883, -1.0643,\n",
       "        -1.1332, -1.2407, -1.0683, -0.9353, -0.8443, -1.0549, -1.1899, -1.0002,\n",
       "        -1.4368, -0.4605, -0.8931, -1.3795, -1.1537, -1.2295, -1.5573, -1.3294,\n",
       "        -1.2111, -1.4382, -1.0037, -1.4445, -0.7545, -1.1937, -1.0555, -0.8604,\n",
       "        -0.3483, -0.8547, -1.4832, -0.9992, -0.6245, -1.1271, -1.8393, -0.8570,\n",
       "        -1.1873, -0.9002, -1.1650, -1.4616, -1.0966, -1.0338, -0.8798, -1.0539,\n",
       "        -0.5295, -0.5991, -0.5281, -1.1401, -1.3800, -1.1607, -1.0025, -0.7102,\n",
       "        -0.9779, -1.1512, -1.1975, -0.7246, -0.4748, -0.9941, -0.7571, -0.8653,\n",
       "        -1.4647, -1.8294, -0.6385, -0.2421, -0.4240, -0.7561, -0.7323, -1.0429,\n",
       "        -0.5567, -0.7589, -0.8982, -1.1422, -1.3670, -0.8966, -0.7570, -0.8501,\n",
       "        -1.4752, -1.3566, -1.5417, -1.3120, -1.4789, -0.8098, -1.1903, -1.1919,\n",
       "        -0.5641, -1.0068, -0.6368, -1.1082, -0.6602, -1.2209, -0.5706, -0.8450,\n",
       "        -1.4457, -1.1181, -0.5517, -1.0157, -1.0188, -1.3320, -1.1227, -0.8480,\n",
       "        -0.9637, -0.3996, -1.1952, -1.4615, -1.0471, -0.8518, -1.3566, -1.1436,\n",
       "        -1.2017, -0.7486, -1.5245, -0.9609, -1.2642, -0.4812, -1.1266, -0.8732,\n",
       "        -0.4258, -0.7096, -0.8881, -1.1568, -1.1495, -1.0584, -0.5065, -2.0450,\n",
       "        -1.8439, -1.0001, -0.4478, -1.3064, -1.2587, -0.7340, -0.7342, -0.9460,\n",
       "        -1.0269, -0.9412, -0.7271, -0.9116, -0.7955, -1.3599, -1.3335, -1.3596,\n",
       "        -2.0832, -1.4160, -0.9864, -0.7417, -0.7941, -1.4409, -0.8184, -0.5528,\n",
       "        -0.7167, -1.1789, -0.8158, -1.4325, -0.2628, -1.1581, -1.9050, -0.4080,\n",
       "        -1.2944, -1.1235, -0.6202, -1.1652, -0.9671, -1.1774, -1.8213, -0.8847,\n",
       "        -0.6611, -1.5906, -0.7409, -1.0386, -1.0712, -1.1633, -1.0001, -1.3512,\n",
       "        -0.9485, -1.2225, -1.0768, -1.1959, -1.0779, -1.0752, -1.1522, -0.9081,\n",
       "        -1.0947, -0.8541, -0.9721, -1.3169, -0.8332, -1.1959, -0.8614, -1.2096,\n",
       "        -1.2910, -1.3517, -0.7324, -0.7874, -1.2204, -0.3987, -1.2808, -1.0477,\n",
       "        -1.0734, -0.4106, -0.8290, -0.8418, -1.1694, -1.0074, -1.2381, -1.2645,\n",
       "        -0.4686, -0.9527, -0.7772, -0.9946, -0.5623, -0.7630, -0.8910, -1.0892,\n",
       "        -0.8300, -0.9807, -0.9775, -1.3635, -0.4377, -0.6563, -1.3178, -0.7624,\n",
       "        -1.1922, -1.3888, -1.3011, -0.8241, -0.6315, -1.0948, -1.0740, -1.1862,\n",
       "        -1.2401, -0.8922, -0.8188, -0.4529, -0.3196, -0.9116, -0.5977, -0.7753,\n",
       "        -0.3463, -0.9359, -0.2351, -1.1351, -0.8505, -1.2622, -0.8808, -0.8275,\n",
       "        -1.4604, -0.6374, -0.9875, -0.5543, -0.9385, -1.4324, -1.0252, -0.7666,\n",
       "        -1.3167, -0.6675, -0.3785, -0.6188, -1.1109, -0.7665, -0.6459, -1.3750,\n",
       "        -0.9565, -0.8162, -1.1617, -0.2942, -1.1032, -0.9313, -0.6704, -0.9382,\n",
       "        -1.4996, -0.6677, -0.9241, -0.9116, -1.5874, -1.2366, -0.9990, -0.7313,\n",
       "        -0.6550, -0.9268, -0.9094, -1.2075, -0.7507, -1.5805, -1.3963, -1.1001,\n",
       "        -0.8197, -0.6291, -0.5572, -0.6652, -1.0816, -1.0449, -1.2613, -0.6382,\n",
       "        -0.4380, -1.4386, -1.2137, -0.5551, -1.0229, -0.9086, -0.8036, -0.8823,\n",
       "        -0.4433, -0.5666, -1.3386, -0.8249, -1.0241, -0.9359, -1.3669, -0.1792,\n",
       "        -0.4910, -0.6613, -0.6006, -1.2904, -1.2362, -0.9800, -0.7748, -0.8731,\n",
       "        -0.9160, -1.3455, -0.6145, -1.3676, -0.9559, -0.8511, -1.0169, -1.0877,\n",
       "        -0.6715, -0.8468, -0.9053, -0.6382, -0.7508, -1.1323, -1.2330, -1.0002,\n",
       "        -1.0657, -1.0172, -1.3319, -1.0393, -1.2256, -0.7244, -1.3001, -1.1020,\n",
       "        -1.2895, -0.6108, -0.4768, -1.4196, -1.3897, -0.7835, -1.0923, -1.2570,\n",
       "        -0.9177, -0.8924, -0.9494, -0.8150, -1.1034, -1.1010, -0.7710, -1.2923,\n",
       "        -1.7607, -0.8246, -1.0299, -0.7357, -0.8449, -1.3700, -0.9031, -1.1970,\n",
       "        -1.0119, -0.7387, -1.1051, -1.0061, -1.1059, -0.8715, -0.2503, -0.7411,\n",
       "        -1.5400, -1.4532, -0.8578, -1.6902, -1.4873, -0.8968, -0.5279, -0.5539],\n",
       "       device='cuda:0')), ('encoder.base.conv_block4.bn1.running_mean', tensor([-10.2793,  -5.1050,   0.5770, -12.2499,   1.1114,  -5.0149,   2.6296,\n",
       "         -5.7523,  -4.7333,  -9.0336,  -4.5115,  -7.6067,  -9.8591,  -4.0122,\n",
       "        -10.7823,  -5.9085,  -7.6807,  -4.9074,  -5.2075,  -5.1058,  -6.3960,\n",
       "         -8.2817,  -5.2456,   0.0449,  -2.5947,  -5.1229,   3.0265,  -9.0198,\n",
       "         -7.9768,  -2.0162, -16.2726,  -3.1200,  -5.7590,  -3.1134,  -8.1856,\n",
       "         -5.2627,  -6.8978,   1.6054,  -2.5897,  -2.4606,  -6.4149,  -0.0205,\n",
       "          1.8035, -11.9931,  -7.4352,  -4.6106,  -6.3099,  -1.2977,  -1.6846,\n",
       "         -9.3642,  -5.2194,  -6.9079,  -4.9136,  -2.1780,  -5.5695,  -6.6912,\n",
       "         -4.2017,  -7.7757,  -3.1779,  -4.0478,  -8.0861,  -3.7367,  -5.8779,\n",
       "         -3.1723,  -1.7294,  -6.1344,  -4.8933,   0.0762,  -8.5907,  -5.8002,\n",
       "         -9.0861,  -1.2178,  -0.4124,   2.0606,  -2.1005,  -7.2921,  -5.3342,\n",
       "         -3.6185,  -6.3721,  -6.5325,  -6.0726,  -7.7600,  -3.4875,  -4.4815,\n",
       "         -6.0967,  -1.5140,  -6.1712,  -3.2782,  -4.4434,  -9.1119,  -5.0394,\n",
       "         -4.1701,  -8.7567,  -8.5084,  -7.7246,  -1.0465,  -1.7473,  -5.7842,\n",
       "         -1.8228,  -6.2296,   2.0070,  -3.7328,  -7.6452,   0.0470,   1.9210,\n",
       "         -8.1234,  -7.0801,  -3.7098, -13.6400,  -1.5657,  -6.4982,  -0.9597,\n",
       "         -7.3450,  -5.1298, -13.1911,  -8.3593,  -6.5813,  -9.8701,  -8.2120,\n",
       "        -10.2244,  -1.7166,   0.3624,  -6.1199,  -5.2311,  -2.4564,  -6.3264,\n",
       "         -7.9257,  -7.9577,  -3.4013,   1.5921,  -5.8668,  -0.8193,  -2.5089,\n",
       "         -5.0900,  -8.0176,  -6.4210,  -1.1759,  -6.7921,  -0.3481,  -9.2427,\n",
       "         -9.9008,  -8.3225,  -9.3032,  -8.9493,  -5.2085,   1.5023,  -5.2136,\n",
       "         -6.0105,  -6.2447,  -6.5079,  -4.2751,  -9.7660,  -6.1132,  -1.8229,\n",
       "         -5.8968,  -8.7571,  -9.2568,  -0.3043,  -5.9986,  -0.7422,   2.8028,\n",
       "         -3.2696,  -5.3210,  -3.5418,  -1.2045,  -5.7917, -10.0467, -10.2704,\n",
       "         -6.2779,  -7.2943,  -5.7070,  -6.7291, -11.9753,  -4.7874, -12.9624,\n",
       "         -8.8783,  -2.5503,  -0.9713, -10.5295, -12.2764,  -5.5694,  -6.0106,\n",
       "         -4.0255,  -7.1279,  -8.2322,  -3.4059,  -1.6601,  -5.5689,   0.5852,\n",
       "         -3.9591,  -4.6329,  -3.0914,  -7.8443,  -6.0076,  -6.4779,   1.6296,\n",
       "          0.1636,  -6.4931,  -1.9335,  -6.2480,   0.8268,  -5.4800,  -9.3580,\n",
       "         -3.8273,  -6.9180,  -3.8009,  -5.3921,  -1.0332,  -7.8456,  -4.3468,\n",
       "         -3.9134,  -2.0628,  -0.8970,  -3.7377,  -5.2491,  -3.9716,   1.7836,\n",
       "         -4.8697,  -9.8217, -12.0063,  -5.8720,  -6.0146,   1.1641,  -4.2303,\n",
       "         -6.2902,  -7.7341,  -6.0825,  -7.5879,  -5.5148,  -6.5780,   0.0881,\n",
       "         -7.2020,  -5.0114,  -4.3173,  -2.5251,  -4.9577,  -6.3364,  -7.3803,\n",
       "         -2.9454,  -6.4389,  -5.0101,  -6.6061,  -6.5512,  -5.1629,  -4.6097,\n",
       "         -1.5746,  -2.8374,  -0.5122,   0.7712,  -4.4144,  -5.8370,  -3.9464,\n",
       "        -12.3806,  -4.7935,  -3.9609,  -3.2923,  -7.0694,  -6.3033,   2.0305,\n",
       "         -6.3570,  -5.0539,  -5.1913,  -3.5339,  -2.1619,  -6.7763,  -6.3931,\n",
       "        -11.1211,  -9.3622, -11.0594,  -5.0233,  -4.9589,  -6.3624,  -7.0158,\n",
       "        -12.1250, -11.4559,  -5.3347,  -3.3384,  -1.9951,  -4.3446,  -1.8381,\n",
       "         -6.8602,  -6.8828,  -1.9819,  -3.8376,   0.9528,  -7.9761,  -8.2387,\n",
       "         -0.2785,  -7.7605,  -5.6871,   0.1998, -10.1335,  -5.3290,   1.1781,\n",
       "        -10.0592,  -6.3349,  -0.9074,  -2.5916,  -8.9815,  -5.5814,  -7.6576,\n",
       "         -7.7590,  -5.6901,  -5.7995,  -6.4633,  -7.0798,  -9.2863,  -3.3237,\n",
       "         -0.7928,  -8.3835,  -3.3632,  -5.5329,  -5.8154,  -7.5749,  -5.4600,\n",
       "         -3.2018,  -3.7958,  -1.2822,  -7.5610,  -8.0757,  -6.4004,   0.0784,\n",
       "        -12.9392,  -7.0685,  -6.5679,   0.6536,  -9.9785,  -4.6147,  -8.3518,\n",
       "          0.6975,  -7.0733,  -6.0345,  -6.5054, -11.3228, -10.2335,  -3.2918,\n",
       "         -3.5762,   1.4748,  -5.7224,  -8.3526,  -4.4862,   0.8099,   0.4632,\n",
       "         -3.3076,  -4.9378,  -7.3780,  -6.9124,  -4.9742,   0.9185,  -8.1968,\n",
       "         -4.2707,  -8.3432,  -7.4695,  -2.3438,  -6.6042,  -7.4780,   1.3620,\n",
       "         -7.4275,  -4.6859,  -9.7884,   0.5683,  -6.4116,  -4.6786,  -6.0446,\n",
       "          2.2747,  -4.5395,  -7.1189,  -1.0410,  -0.2631,  -7.2017,   2.1779,\n",
       "        -10.9636,  -6.8035,  -6.5435,  -6.0287,  -0.9497, -10.6271,  -5.2722,\n",
       "         -6.2655,  -3.8363,  -7.2287,  -2.5849,  -2.7195,  -2.5114,  -2.4181,\n",
       "         -3.6162,   1.2660,  -4.8813,  -7.8794,  -2.1826,  -5.0133,  -5.9276,\n",
       "         -1.0022,  -5.2859,  -6.3448,  -0.0995,  -7.2606,  -4.8345,  -3.4389,\n",
       "         -7.7076,  -6.0039,  -7.0864,  -1.5581, -11.9516,  -6.6842,  -4.7997,\n",
       "         -7.9832,  -1.8929,  -3.8697,  -7.2771, -11.0676,  -8.2769,  -0.1662,\n",
       "         -5.9941,  -5.0723, -12.7834,  -7.3765,  -8.0371,  -8.8059,  -7.5946,\n",
       "         -6.9716,  -8.1132, -10.4097,   0.7244,  -8.5828,  -6.2128,  -9.7671,\n",
       "         -6.6599,  -5.2965,  -0.7537,  -3.7555,  -4.3002,   2.1005,  -6.0888,\n",
       "         -8.4214,  -6.9165,  -5.9569,  -4.5327,  -6.1004,  -2.8920,  -6.0032,\n",
       "         -2.2724,  -3.9450,  -5.6058, -10.2554,  -9.5931,  -6.6777,  -7.4380,\n",
       "         -8.7531, -11.3134,  -4.8196,  -5.7835,  -6.5160,   0.3841,  -8.8216,\n",
       "         -3.3551,  -4.4611,  -9.0977,  -4.4484,   1.4702,  -2.2733,  -4.6829,\n",
       "         -3.5563,  -7.8723,  -5.1950,  -4.8242,  -7.0583,  -8.7942,  -5.7782,\n",
       "         -4.5458,  -8.1177,  -7.6210,  -3.1566,  -7.1672,   0.6632,  -4.1542,\n",
       "         -4.2291,  -6.6208,  -7.1946,  -5.2934,  -9.6849,  -5.4624,  -3.5769,\n",
       "         -3.4177,  -5.3127,  -6.7569,  -4.6155,  -6.7661,  -6.3095,  -3.6367,\n",
       "         -4.8903,   2.3502,  -0.6025,  -9.1916,   2.1711,  -7.7282,  -5.9922,\n",
       "         -8.2701,  -4.6847,  -5.7975,  -5.2849,  -7.1303,   1.8561,  -6.2341,\n",
       "         -4.0587,  -4.0731,  -8.7921,  -6.9323,  -5.1966,  -2.1089,   1.8824,\n",
       "          1.2020], device='cuda:0')), ('encoder.base.conv_block4.bn1.running_var', tensor([25.9477, 16.5733,  4.9564, 28.6898,  7.1413, 17.8488,  3.8144, 14.5970,\n",
       "        17.3948, 38.2940, 13.0234, 29.2071, 31.1680,  8.8923, 30.8701, 12.7928,\n",
       "        19.2679, 14.7399, 21.9500, 15.5500, 10.6833, 21.7241, 11.5524,  4.0457,\n",
       "         7.9603, 16.8295, 15.5251, 32.9095, 23.1123, 14.0936, 37.5358, 12.4848,\n",
       "        21.5845, 15.5798, 19.2634, 15.0854, 18.4694,  5.2985,  7.7973, 27.5669,\n",
       "        15.9851,  9.6565,  3.9385, 20.3290, 28.3304, 12.5070, 14.7064, 26.1982,\n",
       "         3.9066, 18.9662, 13.9175, 19.6702, 24.5714, 13.0022, 53.1503, 14.5090,\n",
       "        14.9587, 12.9142,  4.3092, 14.5339, 24.8722, 10.7357, 28.5289,  8.0343,\n",
       "         8.1199, 39.9542, 19.8778, 10.3461, 30.5962, 19.5617, 20.5699,  7.4316,\n",
       "         7.8675,  7.7964,  7.1674, 33.1144, 13.7808, 20.8220, 15.3775, 13.9209,\n",
       "        11.9177, 22.2030,  7.4819, 18.6825, 16.9285,  9.8723, 10.3241, 28.9917,\n",
       "        16.9282, 27.4749, 34.3637,  8.9852, 22.4466, 38.7172, 34.9716, 11.5602,\n",
       "        13.5902, 13.6143,  9.9763, 12.4859,  4.4295,  8.3284, 37.5300,  4.3734,\n",
       "         3.0895, 41.6860, 34.0726, 10.5124, 36.2825,  8.2954, 29.2960,  6.3537,\n",
       "        20.5536,  9.4501, 36.9986, 20.8720, 12.8368, 37.7083, 24.7643, 23.0841,\n",
       "        12.6122,  4.0673, 14.8067, 38.4710, 14.2712, 13.7243, 10.6322, 19.8489,\n",
       "        12.2712,  4.8436, 19.0219,  6.3717,  7.0603, 12.1327, 20.4187, 20.3443,\n",
       "        13.9391, 32.7323, 13.4792, 28.6418, 26.6187, 31.5201, 23.0340, 22.5258,\n",
       "        15.2911,  4.4022, 17.8964, 18.6309, 11.5805, 17.1843, 10.7487, 27.3265,\n",
       "        11.7636, 27.5499, 13.4789, 26.4110, 48.1084, 10.9896, 19.1405, 11.0402,\n",
       "         6.7606,  9.4307, 20.0629, 32.8033,  6.7211, 14.6987, 30.0069, 18.2410,\n",
       "        14.6452, 26.7315, 14.6979, 28.7509, 37.2557, 21.9850, 32.0598, 26.7120,\n",
       "         7.0789, 10.0965, 44.3797, 33.8998, 24.1027, 13.7562, 10.4648, 25.6448,\n",
       "        23.1698, 24.1747, 13.5981, 19.5093,  4.4610, 11.9872, 11.1300,  4.4206,\n",
       "        22.5331, 23.6396, 15.7599,  6.3538,  3.2810, 14.8751, 16.0796, 10.9207,\n",
       "         5.1066, 16.0795, 31.8497, 20.7898, 13.5729, 17.2899, 15.2702,  7.9741,\n",
       "        16.0184, 16.0046, 15.0117, 11.9559, 17.4703,  8.5567, 16.5416,  8.6536,\n",
       "         3.1471, 13.3657, 36.9750, 29.1694, 13.3317, 11.3734,  4.7904, 11.2839,\n",
       "        12.1372, 31.8972, 11.1363, 15.1774, 16.3388, 19.4651,  8.1487, 21.0309,\n",
       "         9.1159, 11.8341, 15.9305, 18.3443, 19.2887, 23.6510, 19.0304, 25.6219,\n",
       "        13.7310, 11.1023, 28.5880,  8.2523, 11.3362,  3.9850, 11.8526,  5.8452,\n",
       "         4.6486, 13.1018, 18.2617, 25.5351, 26.5429, 22.0399, 14.0497, 18.8683,\n",
       "        15.0423, 19.3316,  4.9169, 17.1923, 11.2731, 20.3997, 17.1153, 14.7711,\n",
       "        13.1216, 14.6626, 18.7908, 33.7767, 31.1224, 16.8063, 19.4649, 26.5509,\n",
       "        10.4670, 40.6961, 56.8420, 13.9113, 19.8506, 15.9927, 13.1833,  5.3747,\n",
       "        12.9164, 19.6825, 11.7234, 10.5552,  3.2164, 19.0529, 18.6243,  3.8479,\n",
       "        17.3073, 17.8297,  6.0869, 19.2629,  9.5786,  7.3701, 27.4588, 17.7705,\n",
       "        17.8569, 10.5123, 23.3862, 21.5240, 13.3133, 22.4450, 18.8869, 15.9933,\n",
       "        20.2897, 15.5485, 30.0565, 23.1910, 13.0794, 21.1492,  7.7913, 14.5334,\n",
       "        17.4401, 11.9952, 13.4288, 12.8075,  7.4606, 21.0727, 18.0289, 19.0485,\n",
       "        16.3264,  8.6855, 34.4725, 16.3944, 38.3138,  4.3363, 39.7006, 13.5680,\n",
       "        25.1719,  2.3369, 14.6388, 22.5186, 15.4152, 31.3699, 20.9004, 18.2541,\n",
       "         8.4245, 14.0153, 10.9995, 29.2076,  7.6909,  3.7396,  8.4154, 10.0600,\n",
       "        16.5012, 19.1621, 21.0240, 20.0611,  5.7387, 18.8005,  6.1813, 12.2710,\n",
       "        22.5044, 15.4921, 21.4759, 13.4136,  6.9473, 17.1352, 13.0289, 22.4990,\n",
       "         6.0225, 10.6556, 16.2021, 32.8283,  4.7706, 14.8738, 11.1560,  5.3743,\n",
       "         5.7921, 13.3604,  2.7482, 21.5029, 18.7508, 10.4992, 11.8807, 12.2436,\n",
       "        20.7739, 19.8033, 14.8469, 29.4510, 16.5537, 11.8768, 14.7347,  8.0578,\n",
       "        19.0071,  7.7629,  5.1596, 14.3560, 22.3317, 13.3205, 19.7466, 24.0590,\n",
       "         6.4785, 15.4873, 12.4923,  3.4095, 13.0653, 28.5847, 11.8347, 21.4392,\n",
       "         9.8598, 21.0303,  6.1335, 41.6386, 38.8693, 13.3092, 37.4739, 24.0293,\n",
       "        29.3321, 20.2335, 25.1091, 15.4169, 20.7976, 11.3012, 18.0666, 31.7064,\n",
       "        29.0671, 22.3197, 24.9146, 26.9031, 16.6671, 10.1967, 28.5814,  4.7615,\n",
       "        12.0240, 24.9222, 47.2419, 14.4547, 15.7475,  8.2459, 14.8922, 18.0402,\n",
       "         4.3960, 17.3405, 18.5886, 20.8925, 20.4716, 24.4640, 12.8354, 22.0989,\n",
       "        11.8033,  8.9580, 29.3541, 14.4815, 44.2939, 45.6635, 12.4235, 14.7183,\n",
       "        30.9570, 20.2884, 17.1768, 23.2277, 23.9515, 10.5962, 23.8915, 13.6565,\n",
       "         5.5642, 14.8275, 18.0266,  6.5589,  6.7854, 11.0593, 15.2008, 14.4204,\n",
       "        15.2472, 15.3347, 23.7237, 35.7539, 16.3468, 10.1289, 19.9992, 24.8273,\n",
       "        20.1210, 10.2618,  2.7819, 10.3906,  9.9954, 16.3208, 10.1581, 13.0410,\n",
       "        44.9760, 20.8118, 20.8414, 10.9393, 19.6904, 12.4679, 10.3500, 15.2428,\n",
       "        15.8127, 14.6952, 11.2404,  6.7499,  7.6787, 20.9956, 15.3474, 27.1440,\n",
       "        43.7911, 31.7482, 11.0519, 18.2463, 19.6826, 21.1500,  5.7881, 14.8946,\n",
       "        20.2056, 12.6739, 27.8798, 16.1588, 19.6985,  6.2127,  5.5244,  3.4680],\n",
       "       device='cuda:0')), ('encoder.base.conv_block4.bn1.num_batches_tracked', tensor(586728, device='cuda:0')), ('encoder.base.conv_block4.bn2.weight', tensor([0.8692, 1.0196, 0.9362, 0.9131, 1.0375, 1.0444, 1.0132, 1.0092, 1.0608,\n",
       "        1.0743, 1.0304, 1.1891, 1.0405, 1.0412, 1.0269, 0.9653, 1.0626, 1.0576,\n",
       "        1.0416, 1.0394, 1.0032, 0.9530, 1.0887, 1.1196, 1.2284, 1.1845, 1.2006,\n",
       "        1.0038, 0.9120, 0.9737, 1.0074, 1.0234, 0.9587, 0.9566, 1.1203, 1.0380,\n",
       "        1.2199, 1.0974, 1.0536, 0.7612, 0.9293, 1.2127, 1.0957, 1.0487, 1.0060,\n",
       "        0.9303, 1.1301, 0.9962, 0.9253, 0.9390, 1.0552, 1.0215, 0.6022, 1.1631,\n",
       "        1.0075, 0.9166, 1.1436, 1.1242, 0.9639, 0.8867, 0.8757, 1.0242, 1.0773,\n",
       "        1.0337, 1.0872, 0.9788, 0.9669, 0.9332, 0.7769, 1.0834, 1.1052, 1.0670,\n",
       "        1.2093, 1.0479, 0.8535, 1.0409, 1.0113, 0.8261, 0.9043, 1.0220, 1.0291,\n",
       "        1.0649, 0.9358, 1.2345, 0.9310, 0.9950, 1.1893, 1.0115, 0.7559, 1.0712,\n",
       "        1.0209, 0.9954, 0.8501, 1.0186, 1.1557, 0.9994, 0.9954, 1.0819, 1.0597,\n",
       "        1.0474, 1.0162, 0.9761, 0.9244, 0.9922, 0.9519, 1.1067, 0.9372, 0.9337,\n",
       "        1.1715, 1.0161, 1.0217, 1.0195, 1.1220, 1.0149, 1.1270, 1.1602, 0.9379,\n",
       "        1.0706, 1.1358, 1.0445, 0.9419, 1.0347, 0.9873, 1.0045, 0.9723, 1.0441,\n",
       "        0.8574, 1.0103, 1.0524, 0.9981, 0.9770, 1.0063, 1.0351, 1.0704, 1.0712,\n",
       "        1.1775, 1.0923, 1.0152, 1.0871, 1.0963, 0.9691, 1.0647, 0.6194, 1.0080,\n",
       "        1.0311, 1.1069, 0.9379, 1.0183, 1.0397, 0.9723, 1.0926, 0.9570, 1.1201,\n",
       "        0.6124, 1.0335, 1.0131, 1.0401, 1.0126, 0.9381, 1.0591, 1.0451, 0.6448,\n",
       "        1.2713, 0.8568, 1.0401, 0.9968, 0.9266, 0.9932, 1.0042, 1.0146, 0.9523,\n",
       "        1.0785, 1.0504, 1.0440, 0.8292, 1.0258, 0.8946, 1.0836, 0.9695, 1.1255,\n",
       "        1.0539, 1.0798, 1.0433, 0.9571, 1.0015, 1.0899, 0.9283, 1.0606, 0.9519,\n",
       "        0.7614, 0.7617, 0.9541, 1.1838, 0.9471, 1.0733, 1.1440, 1.0788, 1.0504,\n",
       "        0.9725, 0.7654, 1.0277, 0.7071, 0.9312, 1.0306, 1.0887, 1.1121, 0.9629,\n",
       "        1.0552, 1.0747, 1.1719, 0.8791, 1.0809, 1.0920, 0.8258, 1.0560, 0.9856,\n",
       "        1.0623, 0.8904, 0.9770, 0.9496, 1.1909, 0.8231, 0.9825, 0.9999, 1.0781,\n",
       "        1.0322, 0.9479, 0.6987, 1.0529, 0.9777, 1.0731, 1.0085, 1.0309, 0.9760,\n",
       "        1.1300, 1.0308, 0.9500, 0.8970, 1.0981, 0.9828, 1.0356, 1.0897, 1.0457,\n",
       "        1.1373, 1.0823, 1.0683, 1.1204, 1.0674, 1.1082, 1.0366, 1.0477, 0.7976,\n",
       "        1.0946, 1.0202, 0.9869, 0.9141, 0.9358, 1.0071, 1.0090, 0.9882, 1.2007,\n",
       "        0.9805, 0.9280, 0.9648, 1.1031, 1.0952, 1.0682, 0.9051, 0.9703, 0.9847,\n",
       "        1.0507, 1.0302, 1.0373, 1.0126, 1.1133, 0.9373, 1.0751, 1.0259, 0.8999,\n",
       "        0.9758, 1.0634, 0.9822, 0.9974, 1.1841, 1.0385, 0.9460, 1.0757, 1.0571,\n",
       "        0.8684, 0.7430, 1.0869, 1.0043, 0.8735, 0.9567, 1.0572, 1.0317, 1.0294,\n",
       "        1.0523, 1.0352, 1.0453, 1.1801, 1.1518, 1.0357, 1.0031, 1.0059, 1.0505,\n",
       "        0.8497, 0.8277, 0.7445, 1.0762, 1.0021, 1.1202, 1.0641, 0.9924, 1.1110,\n",
       "        1.0767, 0.9756, 1.0253, 1.1018, 0.9259, 0.9461, 1.0254, 1.0322, 0.9632,\n",
       "        1.0843, 0.8916, 0.8301, 1.1465, 0.9954, 0.9512, 0.9322, 0.9779, 0.9065,\n",
       "        0.9694, 0.5169, 1.1076, 1.0327, 0.9517, 1.1000, 0.9666, 0.9286, 0.9862,\n",
       "        1.1279, 0.9118, 0.9248, 0.8618, 0.8209, 0.7729, 0.9371, 0.8842, 0.9992,\n",
       "        1.0429, 1.0914, 0.8012, 1.0192, 1.0117, 1.0623, 1.0231, 1.0377, 1.1539,\n",
       "        0.8518, 0.6366, 1.0854, 0.9593, 0.9821, 0.8839, 1.2614, 0.9315, 0.8245,\n",
       "        0.9191, 1.0720, 0.9815, 0.7630, 1.0368, 1.0000, 1.0597, 0.9025, 1.0035,\n",
       "        1.1145, 0.9382, 1.0012, 0.9382, 0.9492, 1.0129, 0.7285, 1.0805, 0.9569,\n",
       "        1.0730, 1.0464, 0.8662, 0.5841, 0.9371, 0.7384, 0.9628, 1.1045, 0.9737,\n",
       "        1.0557, 1.1154, 1.1908, 0.9917, 0.9906, 0.7624, 1.0398, 0.9751, 1.0418,\n",
       "        1.0149, 0.8918, 0.9710, 0.9319, 0.9814, 0.9381, 0.9196, 1.1777, 1.0211,\n",
       "        1.0665, 0.9604, 1.0621, 1.0200, 0.8991, 0.9888, 0.8206, 1.0428, 1.0212,\n",
       "        1.0214, 1.0759, 1.0050, 0.9450, 0.9638, 1.0861, 1.0789, 0.9607, 0.7226,\n",
       "        0.8935, 1.0180, 0.9566, 1.1027, 0.9531, 0.9753, 1.1532, 1.0002, 0.9920,\n",
       "        1.0342, 0.9385, 0.8641, 0.9388, 0.9327, 1.0506, 1.0106, 1.0389, 0.9956,\n",
       "        1.0707, 1.0160, 1.1350, 1.1605, 0.9819, 0.9502, 1.0184, 1.0517, 1.0610,\n",
       "        1.0803, 0.9218, 0.9971, 1.0046, 1.0675, 0.9909, 1.1060, 0.7715, 1.0106,\n",
       "        0.9804, 1.0199, 1.0249, 1.0042, 1.0969, 0.8566, 1.0517, 0.6326, 1.0388,\n",
       "        1.0691, 1.0669, 0.9527, 1.0403, 1.0416, 0.7403, 1.1037, 1.0038, 1.0177,\n",
       "        0.5930, 0.9599, 1.0896, 0.9358, 0.9490, 0.9979, 1.0591, 0.9622, 0.9875,\n",
       "        0.9553, 1.0062, 1.0119, 1.1283, 1.0414, 1.0745, 1.0687, 0.8101, 1.0115,\n",
       "        1.1221, 1.0903, 0.9864, 1.1624, 1.0129, 1.0907, 0.9775, 0.7475],\n",
       "       device='cuda:0')), ('encoder.base.conv_block4.bn2.bias', tensor([-0.6357, -0.8527, -0.7240, -0.7183, -0.9574, -0.9813, -0.7130, -0.8558,\n",
       "        -0.8158, -0.8945, -0.7349, -0.9749, -1.0785, -0.7781, -0.8201, -0.7343,\n",
       "        -1.2163, -0.9349, -0.9170, -0.7448, -0.8741, -0.8969, -1.0082, -0.9573,\n",
       "        -1.1156, -1.2825, -1.2379, -0.9295, -0.6968, -1.0297, -0.9719, -0.8778,\n",
       "        -0.6440, -0.7050, -1.0121, -1.0072, -1.1827, -0.8992, -0.8494, -0.6630,\n",
       "        -0.6907, -1.1151, -0.9045, -1.0034, -0.8512, -0.8988, -1.0106, -0.6670,\n",
       "        -0.6949, -0.8435, -1.0474, -0.8233, -0.4661, -1.0223, -0.9171, -0.9080,\n",
       "        -1.1544, -1.0028, -1.1745, -0.8494, -0.5735, -1.0519, -0.8442, -0.8575,\n",
       "        -1.1057, -0.8953, -0.8886, -0.8457, -0.5678, -1.0093, -0.9063, -0.9730,\n",
       "        -1.3149, -0.9343, -0.6227, -0.9176, -0.9047, -0.6808, -0.7603, -0.9709,\n",
       "        -0.9282, -1.0250, -0.7901, -1.1732, -0.9183, -0.8938, -1.0894, -0.7654,\n",
       "        -0.7095, -1.1964, -0.8708, -0.8142, -0.8661, -0.9949, -1.1258, -0.9737,\n",
       "        -0.7671, -0.9461, -0.8957, -0.9559, -0.8173, -0.8774, -0.8777, -0.9807,\n",
       "        -0.6896, -0.9080, -0.7666, -0.7901, -0.9920, -1.0560, -0.9186, -0.8876,\n",
       "        -0.9487, -0.8476, -0.9140, -1.0839, -0.7586, -1.0032, -1.0627, -0.9870,\n",
       "        -0.6890, -0.7998, -0.8275, -0.7153, -0.7468, -0.9308, -0.5439, -0.7082,\n",
       "        -0.9491, -0.8077, -0.7686, -0.8005, -1.1216, -1.0302, -0.8449, -1.2532,\n",
       "        -1.0404, -0.8978, -0.8028, -1.0356, -0.8640, -0.9739, -0.3478, -0.7908,\n",
       "        -1.0078, -1.0894, -0.6264, -0.9284, -0.8441, -0.6705, -0.9099, -0.6895,\n",
       "        -1.0781, -0.4041, -0.9598, -0.9002, -0.8591, -0.8593, -0.9035, -0.9717,\n",
       "        -0.8061, -0.4209, -1.1186, -0.6594, -0.9079, -0.8793, -0.6905, -0.7890,\n",
       "        -0.7763, -0.8181, -0.7768, -0.9247, -1.1757, -0.9052, -0.6392, -0.9119,\n",
       "        -0.8816, -1.1514, -0.6032, -1.1121, -1.0446, -0.9701, -0.9160, -0.7903,\n",
       "        -0.9031, -0.9186, -0.8806, -0.9007, -0.8075, -0.5293, -0.7690, -0.7966,\n",
       "        -1.0551, -0.7402, -0.9771, -1.1216, -1.0144, -0.7270, -0.8152, -0.4969,\n",
       "        -0.9188, -0.5080, -0.6954, -0.8943, -0.9111, -0.9846, -0.7691, -0.7996,\n",
       "        -0.9310, -0.9318, -0.7881, -1.0120, -1.1179, -0.6427, -0.8588, -0.8852,\n",
       "        -0.9369, -0.6432, -0.8372, -0.7708, -1.0399, -0.5446, -0.8622, -1.0342,\n",
       "        -1.0385, -0.9053, -0.7958, -0.5640, -1.0736, -0.7351, -0.9306, -0.7655,\n",
       "        -0.9475, -0.9423, -1.0223, -0.8780, -0.8575, -0.8953, -1.0348, -0.9474,\n",
       "        -1.0599, -0.8597, -0.9905, -0.8517, -0.8602, -1.0753, -0.9481, -1.0397,\n",
       "        -0.9873, -0.9807, -0.9107, -0.8368, -0.9407, -0.9491, -0.9919, -0.6827,\n",
       "        -1.0033, -0.8495, -0.9439, -0.7659, -0.9812, -0.7008, -0.6716, -0.7872,\n",
       "        -0.7998, -0.9925, -0.7968, -0.6551, -0.9045, -0.9280, -1.0423, -0.9507,\n",
       "        -0.8546, -0.7400, -1.2037, -0.9359, -0.8926, -0.8114, -0.8905, -0.9073,\n",
       "        -0.9369, -0.8521, -0.9964, -0.9729, -0.9072, -0.6744, -0.9125, -0.8992,\n",
       "        -0.6318, -0.5347, -0.9464, -1.0394, -0.8523, -0.7701, -0.8907, -0.9499,\n",
       "        -1.0483, -0.9705, -0.9066, -0.9237, -1.2272, -1.3275, -0.8460, -0.7763,\n",
       "        -0.6645, -0.9437, -0.4811, -0.6286, -0.5974, -0.9572, -0.8808, -0.9409,\n",
       "        -0.9350, -0.8788, -0.9325, -0.9302, -0.9094, -0.8218, -1.0726, -0.7214,\n",
       "        -0.9896, -0.8111, -1.0361, -0.7955, -0.7910, -0.7099, -0.6057, -0.9668,\n",
       "        -0.8110, -0.9454, -0.8162, -0.7066, -0.6406, -0.9381, -0.2838, -1.2096,\n",
       "        -0.8564, -0.9551, -1.0171, -0.8412, -0.7527, -0.7537, -0.9505, -0.7497,\n",
       "        -0.8901, -0.6481, -0.7140, -0.4668, -0.8714, -0.9210, -1.0737, -0.9736,\n",
       "        -0.9253, -0.8462, -0.9520, -0.7971, -1.1652, -0.9690, -0.9288, -0.8844,\n",
       "        -0.7713, -0.4085, -0.9273, -0.7709, -0.9965, -0.7296, -1.0591, -0.8909,\n",
       "        -0.6816, -0.7582, -0.8895, -1.0022, -0.4112, -0.9052, -0.8330, -0.7699,\n",
       "        -0.6271, -0.7419, -0.9814, -0.8401, -0.8756, -0.7851, -0.8853, -0.9722,\n",
       "        -0.4361, -1.0040, -0.8905, -0.9258, -0.8468, -0.6977, -0.3273, -0.7692,\n",
       "        -0.5724, -0.7710, -0.9961, -0.9429, -1.0810, -1.0256, -1.0846, -0.8732,\n",
       "        -0.8395, -0.6623, -0.7299, -0.7672, -1.0518, -0.8442, -0.7411, -1.0576,\n",
       "        -1.0265, -0.9971, -0.9094, -0.6428, -1.1716, -0.7394, -0.8364, -0.8228,\n",
       "        -0.9271, -0.7503, -0.7941, -0.9165, -0.6003, -0.7904, -0.8405, -1.0136,\n",
       "        -0.8585, -0.9383, -0.6179, -0.9837, -1.0112, -0.8642, -0.8000, -0.4619,\n",
       "        -0.7208, -0.9207, -0.8988, -0.8371, -0.9391, -0.8320, -0.9519, -0.8000,\n",
       "        -0.8909, -0.9169, -0.8799, -0.7483, -0.7430, -0.9219, -0.8550, -0.8171,\n",
       "        -0.7724, -0.8056, -0.8571, -0.8749, -1.1316, -1.0753, -1.0479, -0.9392,\n",
       "        -0.8136, -0.8701, -0.9236, -0.9709, -0.8798, -0.6883, -0.9078, -0.9579,\n",
       "        -0.9275, -1.1071, -0.5766, -0.9774, -0.8089, -0.9832, -1.1391, -0.9514,\n",
       "        -0.9571, -0.8613, -0.9184, -0.5020, -1.0454, -0.9861, -0.8187, -0.9366,\n",
       "        -0.9146, -0.9690, -0.4672, -1.0258, -0.9856, -0.9362, -0.3431, -0.7617,\n",
       "        -0.8894, -0.7865, -0.8302, -0.9095, -0.8643, -0.8991, -0.9230, -0.7429,\n",
       "        -0.7601, -0.8827, -1.0443, -0.8199, -0.9924, -0.9508, -0.6007, -0.8046,\n",
       "        -0.9269, -0.9579, -0.7895, -0.9726, -0.8318, -1.0327, -0.9359, -0.5078],\n",
       "       device='cuda:0')), ('encoder.base.conv_block4.bn2.running_mean', tensor([ -7.2217,  -9.4223,  -7.8555, -11.1171, -10.0695, -10.1816,  -9.7072,\n",
       "        -11.7213, -11.2590, -11.6571, -11.2408, -12.6502,  -9.2718, -11.3189,\n",
       "         -9.7495,  -9.7426, -10.5952,  -9.2792, -12.3860, -12.8628,  -9.4238,\n",
       "         -9.1996, -11.4070, -10.2552, -14.0790,  -8.0529, -12.4514, -13.6325,\n",
       "         -6.2170,  -6.2160, -13.5863, -14.3095,  -7.6623,  -8.5154, -15.6250,\n",
       "        -12.8607, -12.8907, -10.0198, -11.2232,  -8.9098,  -8.9619, -11.4442,\n",
       "        -13.6419, -12.4959, -10.6334, -10.8593,  -9.7524,  -9.5926, -10.5570,\n",
       "         -9.5048,  -9.8907, -11.6446,  -5.3319, -11.6572,  -8.4265,  -9.6813,\n",
       "        -13.1681, -13.0823, -11.3458,  -8.7367,  -7.2302, -12.3392,  -9.5577,\n",
       "        -10.3921,  -8.5522,  -8.0391,  -7.5973,  -9.0618,  -6.4561, -13.9282,\n",
       "        -11.7446,  -8.7068, -11.7447,  -9.6265, -10.5582, -11.7715,  -6.6955,\n",
       "         -6.5593,  -7.6174, -14.4919,  -9.2879,  -9.6648,  -8.8314, -14.4307,\n",
       "         -9.2314,  -9.1620, -13.7911,  -8.6315,  -7.4932, -12.4490, -13.6174,\n",
       "        -12.8365,  -8.1795, -11.0466, -14.5331, -11.1737, -10.7006, -13.7215,\n",
       "        -10.2419, -10.5857, -11.3194,  -8.6429, -14.4091, -11.8756, -10.0178,\n",
       "        -15.7342, -12.2482, -10.7726,  -9.0064,  -7.0679,  -8.7856,  -9.3819,\n",
       "         -8.7810,  -8.2171, -11.0313, -12.0236, -10.7850,  -8.3264, -12.4882,\n",
       "        -12.3049, -12.1004, -11.7934,  -8.6513,  -9.9407, -12.6059,  -6.4946,\n",
       "        -11.3678, -10.3008, -15.7178,  -9.4577, -12.9797, -11.8957,  -9.2470,\n",
       "        -11.4784,  -8.8219, -12.2327, -11.2816,  -7.2670,  -9.0750, -10.4724,\n",
       "         -7.4391, -11.9796,  -9.0265,  -9.7816, -10.7094,  -7.7733,  -6.4624,\n",
       "         -9.9683,  -8.1779,  -9.5215, -12.2368,  -7.7565, -11.2028,  -4.9102,\n",
       "         -7.1140, -10.6850, -12.9298,  -7.5132, -10.5257, -10.9926, -10.7832,\n",
       "         -8.8580, -18.0062,  -9.4415, -10.2365, -11.5155,  -8.0074,  -6.9057,\n",
       "        -11.1964,  -8.3443,  -6.8587, -11.6304,  -9.6873,  -8.6372,  -9.6715,\n",
       "         -8.7017, -11.9263,  -9.1683,  -8.5967, -12.6367,  -9.3720,  -7.4918,\n",
       "        -13.1590, -10.0388,  -9.7203, -10.3351,  -7.9317, -10.7264,  -9.6274,\n",
       "         -8.1217,  -9.2193, -12.2071, -13.4013, -10.6536, -10.3623, -10.3160,\n",
       "        -10.0965,  -8.1060,  -8.5414,  -9.2067, -11.1811,  -6.1787,  -9.7677,\n",
       "         -7.1946,  -8.3545,  -9.4483, -11.4419, -13.4036, -10.8391, -12.5806,\n",
       "         -7.6436, -14.4315, -10.3716, -10.1163, -10.5008,  -9.3274, -15.0703,\n",
       "        -12.0637,  -9.0438, -10.4931, -11.8402, -10.3053,  -9.4609,  -7.6577,\n",
       "        -10.5881, -12.5979,  -8.0026,  -6.9366, -11.1863, -10.6480, -12.0001,\n",
       "        -11.1000, -12.4991, -10.0910,  -8.9072, -12.4983, -12.2681, -10.1324,\n",
       "        -11.1406, -10.9403, -12.6944, -11.3389, -10.4013, -11.9818, -11.3081,\n",
       "         -9.9142, -13.1472,  -9.2163, -13.2241, -11.7402, -11.6737,  -9.6230,\n",
       "        -13.4140, -12.1015, -11.5829,  -8.9552,  -9.0485,  -9.6531,  -9.9278,\n",
       "        -11.3367,  -9.3939, -10.8233,  -9.8794,  -8.1579, -14.4697, -11.9489,\n",
       "         -8.7169,  -6.3876, -12.5473,  -7.8143,  -9.4044,  -9.3503,  -7.3239,\n",
       "        -15.4242, -13.2306,  -8.0393, -10.4300, -11.2145,  -9.9549,  -9.5331,\n",
       "        -13.3521, -11.4589, -10.0917, -10.9457,  -6.9367,  -8.9972,  -9.4621,\n",
       "        -12.0825, -12.3788,  -9.2887,  -8.7469, -12.6476,  -8.6055,  -9.1447,\n",
       "        -10.5725,  -8.6255,  -8.3522, -12.0912,  -7.6991, -12.8994, -11.6844,\n",
       "        -10.7394,  -9.3927, -11.6476,  -7.7208, -11.9528,  -8.8031,  -9.6025,\n",
       "         -8.3256,  -9.1556, -11.2885,  -7.9890, -10.5148, -10.8330, -14.7228,\n",
       "        -12.7514, -12.7055, -11.4063, -11.3698,  -9.0356,  -8.7748, -10.5433,\n",
       "        -11.1318,  -7.7884, -10.5276, -12.0900,  -9.2404, -13.7438, -10.4205,\n",
       "        -12.8268, -12.3967,  -8.6786, -10.9816, -10.9238,  -5.9067, -11.4906,\n",
       "        -10.0465, -12.1413,  -7.2672, -11.3725,  -4.9285, -11.6286, -10.8008,\n",
       "        -10.3324, -12.3026,  -9.6679, -10.3923,  -9.8403,  -8.6109, -12.4986,\n",
       "         -8.9889, -16.8392, -13.0485, -11.0315, -10.8717,  -8.3067, -10.5114,\n",
       "        -14.8787, -12.6069, -10.4141,  -7.3667,  -9.0827,  -8.5039, -13.4819,\n",
       "         -6.4613,  -5.1190,  -9.6952, -11.0072, -10.8268, -12.5833,  -7.9105,\n",
       "        -12.5562,  -6.2074, -10.0806, -11.3504,  -9.3440,  -7.1545, -10.8582,\n",
       "         -8.7306,  -9.0149,  -8.8829, -10.9102, -11.2524,  -8.9335,  -8.7774,\n",
       "        -10.2540, -13.7164, -11.3447, -11.1530,  -8.0848,  -5.1182,  -7.2847,\n",
       "         -9.5097,  -6.8421, -11.2962, -11.4274, -11.5100,  -9.4415,  -9.5615,\n",
       "         -8.6290, -10.4914,  -5.1203, -14.6960, -12.8453, -11.7213,  -9.3324,\n",
       "        -13.3476,  -9.4075, -11.5146,  -7.7887,  -9.4822,  -9.4678,  -9.3904,\n",
       "        -11.4133, -12.7036, -11.6822,  -9.2775,  -8.9780, -11.1748,  -9.4884,\n",
       "         -8.8757,  -6.3992, -11.8633,  -9.8954, -12.3142, -10.4113,  -8.0166,\n",
       "         -8.0830, -16.9970,  -8.0023, -11.6493,  -6.2276, -11.0222, -14.8319,\n",
       "         -8.3396,  -9.7679,  -7.3102,  -9.2206, -10.8120, -11.0586, -10.9502,\n",
       "         -8.7739, -11.9664, -12.3467,  -9.1712,  -8.8585, -11.9318, -13.1968,\n",
       "        -10.9864,  -7.0135, -11.3529, -10.9490, -10.8191, -14.6997,  -9.9752,\n",
       "         -9.8470, -10.3471,  -9.8631, -16.0614, -11.2940,  -6.3747, -10.9368,\n",
       "         -8.2019,  -9.1173,  -9.5453, -11.2364, -11.6317, -10.6414, -10.2458,\n",
       "        -15.1182,  -8.8647, -10.5941, -11.7257,  -8.2518,  -7.7674,  -6.1582,\n",
       "        -12.5324, -10.5480, -15.6717,  -9.8634,  -8.9418,  -9.5094,  -5.1978,\n",
       "         -9.5818, -12.6270, -11.0348,  -6.8526,  -8.4254,  -9.6214,  -8.7497,\n",
       "         -6.8091, -11.9404, -12.8351,  -9.0511,  -7.4129, -10.5719,  -8.1175,\n",
       "         -9.1278, -15.8671, -10.2872, -13.2889,  -9.5792, -12.3235,  -9.9624,\n",
       "        -11.6903, -10.9088,  -5.9552, -10.1533, -11.9592, -10.2975, -15.1941,\n",
       "         -8.0593], device='cuda:0')), ('encoder.base.conv_block4.bn2.running_var', tensor([110.1013,  96.6726,  98.5284, 169.1435, 125.3366, 131.8992, 157.7085,\n",
       "        141.3341, 149.2600, 217.5996, 176.2289, 182.7384,  80.2694, 209.9898,\n",
       "        125.8025, 135.3296,  91.9456,  91.7280, 142.9655, 209.0277,  88.5425,\n",
       "         82.1984, 148.4225, 135.6134, 160.7234,  63.7350,  93.9494, 200.4517,\n",
       "         66.7372,  31.2505, 165.5277, 217.5831, 150.6635, 124.6320, 186.7790,\n",
       "        148.4877, 144.1012, 131.7364, 189.5228,  83.9388, 107.3515, 102.9139,\n",
       "        165.2373, 128.3841, 136.5176,  88.6900,  97.4081, 174.6878, 156.0142,\n",
       "         84.7350,  80.9815, 166.5275,  87.9052, 121.1472,  66.6285,  81.6391,\n",
       "        121.2194, 158.9013,  67.9545, 115.1811, 103.4202,  78.5062,  92.2965,\n",
       "        158.7301,  49.4481, 102.7154,  47.7885, 108.4013,  73.1864, 152.3747,\n",
       "        143.2400,  86.5247,  96.5657,  98.6674, 143.7276, 166.4690,  50.6137,\n",
       "         93.5723,  74.5582, 185.1402, 110.8337,  94.8524, 114.5059, 142.2812,\n",
       "         58.9620, 148.6631, 143.0482, 116.4142,  57.8174, 119.7907, 159.5803,\n",
       "        235.4661,  87.1023, 116.2071, 124.5230,  72.2186, 168.6625, 220.6602,\n",
       "        132.6162, 140.5872, 119.5533,  67.9487, 179.9690, 114.5721, 200.1702,\n",
       "        190.9090, 133.7323, 166.5645,  90.8927,  44.1526,  89.1107,  81.5050,\n",
       "         69.9309,  75.3521, 121.8020, 143.3390, 136.8282,  81.7913, 119.4934,\n",
       "        128.8568, 183.8851, 135.8139,  92.1185, 190.1746, 202.9908,  66.4810,\n",
       "        116.3261, 147.3400, 223.4248, 160.3358, 151.2916, 169.2514,  71.6559,\n",
       "         90.9859,  96.6361,  92.7306,  98.1640,  50.6953,  97.8228, 109.0772,\n",
       "         62.8536, 121.9632, 177.8334,  76.8715,  74.1420,  80.4216,  97.8073,\n",
       "         87.0813,  86.5070, 211.5015, 168.8579, 103.6034, 111.8142,  81.8090,\n",
       "         55.8474, 122.8912, 149.1518,  70.3364,  86.0826,  82.7988, 155.4536,\n",
       "        120.4539, 239.7780, 127.3867, 146.4868, 139.6124, 100.1240,  84.6870,\n",
       "        161.9178,  84.3400,  68.0607, 111.1455,  90.4961, 120.1926, 146.9254,\n",
       "         78.8875, 108.2526,  83.5099, 170.5288, 114.0824,  57.6681,  83.1408,\n",
       "        154.8800, 130.4887,  69.8103, 114.7006,  58.8390, 130.3068, 112.9413,\n",
       "         95.5596,  76.9168, 107.3800, 221.2277, 131.5453, 101.0562,  74.8707,\n",
       "         79.0981, 148.5423,  78.7560, 143.8539, 160.5497,  91.7535, 114.0328,\n",
       "         56.7479,  86.7435, 140.3108, 175.3329, 207.8251, 169.8280, 132.7879,\n",
       "         90.0089, 162.7866,  90.4319, 104.3550,  93.4183,  70.2525, 193.8038,\n",
       "        145.8176, 119.6230, 180.1873, 130.2723, 249.5124,  95.7630,  43.2008,\n",
       "         71.8060, 133.5331,  85.6062, 107.4483,  81.1492, 157.1075, 161.8346,\n",
       "        184.4619, 162.2600,  74.3426,  70.5584, 120.7091, 144.7428,  68.3063,\n",
       "        110.9502,  85.8114, 105.6033, 189.9105,  94.4094, 185.3419, 158.1815,\n",
       "         69.1600, 161.4762,  65.7762, 166.5166, 111.9396, 163.1152,  72.1205,\n",
       "        174.4374, 158.1032, 122.6268, 183.1980,  79.2362, 124.0882,  86.4705,\n",
       "        127.4449, 113.9221, 213.7068, 273.2770,  84.5255, 223.4370, 151.7839,\n",
       "        122.4230,  91.7628, 118.4312,  93.5417, 118.1462,  78.5812,  77.4551,\n",
       "        310.5958, 106.2299,  46.5142,  96.5988, 170.8459,  72.7737, 110.2889,\n",
       "        172.8573, 141.7009, 100.1371, 166.6598,  70.4011, 120.2401, 110.3596,\n",
       "        257.4808, 206.7974, 128.4669, 112.8255,  94.8757,  70.4902, 117.4317,\n",
       "        125.2519,  91.7481,  72.0719, 127.7492,  94.7460, 144.4422,  89.8823,\n",
       "         58.0244, 112.2464, 141.9746,  97.7469, 148.0883, 158.9829, 114.1908,\n",
       "        112.5693,  86.8755,  95.8040,  68.1667, 123.8803, 132.8888, 183.8204,\n",
       "        157.2871, 108.9738, 145.1028, 126.2896, 152.6040,  58.9737, 114.8399,\n",
       "        129.9149, 101.2524, 155.0703, 228.5103, 187.0171, 184.6077, 150.3114,\n",
       "        120.3314, 138.5758, 114.6693, 275.3282, 111.4841, 144.9713,  72.2476,\n",
       "        107.7681,  89.2029,  57.9141, 130.5548,  62.9172, 157.2776, 138.3540,\n",
       "        166.7440, 131.0383, 137.9407,  83.9371, 153.9592,  73.4197, 127.9162,\n",
       "         62.7614, 201.9830, 171.1706,  96.5811, 105.9448, 120.7381,  82.2109,\n",
       "        212.9325, 152.6997, 132.3338,  69.9235, 111.8345,  73.2308, 292.5711,\n",
       "         42.3482,  77.1124, 108.5411,  97.8758, 128.8943, 150.3757, 124.9101,\n",
       "         85.6510, 147.2085, 125.9798, 157.2897, 128.7485, 117.7546, 164.0232,\n",
       "         71.6350,  81.0349,  73.1138, 102.3292, 124.0345,  71.3246,  81.5554,\n",
       "        107.3662, 149.7952, 125.9802, 175.7148,  76.6589, 213.6187,  90.5383,\n",
       "        160.0675,  57.0136, 129.2416,  95.9125, 100.5742, 105.0315,  90.8378,\n",
       "         72.2433, 139.2287,  81.7090, 282.4514, 147.1225, 111.8001,  84.1852,\n",
       "        181.8748,  85.6247,  83.1833,  51.0131,  80.0823, 158.6868,  68.2417,\n",
       "        183.6794, 146.5224, 187.7189, 100.0812, 130.7287, 105.3006,  70.1932,\n",
       "         97.1133,  77.9340, 190.2665,  79.4642, 160.6101, 118.4879, 130.7286,\n",
       "         47.0878, 217.4846,  89.7300, 177.2421, 109.4929, 201.4668, 246.0836,\n",
       "        119.2581, 115.1693,  52.8004,  97.3680, 120.0003, 194.6324, 124.6765,\n",
       "         80.3927,  91.8537, 184.7792, 106.4194,  64.6763, 165.3777, 196.0274,\n",
       "        167.1150,  70.6278,  97.2015, 161.7706, 103.0451, 142.7020,  95.7354,\n",
       "         90.0979, 134.3394, 120.6295, 206.8418, 165.7470,  48.3387, 189.5372,\n",
       "         85.3331,  85.3150,  73.5294,  92.7901, 220.5452,  99.2099, 196.0856,\n",
       "        202.2265,  51.3303,  86.5851, 114.2133,  68.9200,  75.2077,  66.1028,\n",
       "        122.0823, 117.7750, 245.7526,  66.1286, 123.7523,  65.8125,  87.0287,\n",
       "        104.8593, 113.6976,  81.1487, 157.0695, 153.1468, 102.4417, 109.2315,\n",
       "         72.9572, 148.5748, 182.4391,  71.6832,  72.7795, 162.9872, 106.4467,\n",
       "         93.8314, 162.9913, 129.5555, 196.3907, 164.7498, 165.6248, 114.9831,\n",
       "        168.4438, 115.9995, 101.6505, 129.2027, 130.0742,  97.4615, 142.0679,\n",
       "        144.2227], device='cuda:0')), ('encoder.base.conv_block4.bn2.num_batches_tracked', tensor(586728, device='cuda:0')), ('pos_encoder.pe', tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "           0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 8.4147e-01,  5.4030e-01,  7.8859e-01,  ...,  1.0000e+00,\n",
       "           1.1007e-04,  1.0000e+00]],\n",
       "\n",
       "        [[ 9.0930e-01, -4.1615e-01,  9.6984e-01,  ...,  1.0000e+00,\n",
       "           2.2014e-04,  1.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.7961e-01, -9.2515e-01,  1.6091e-01,  ...,  9.9993e-01,\n",
       "           1.0677e-02,  9.9994e-01]],\n",
       "\n",
       "        [[-5.7338e-01, -8.1929e-01,  8.7726e-01,  ...,  9.9993e-01,\n",
       "           1.0787e-02,  9.9994e-01]],\n",
       "\n",
       "        [[-9.9921e-01,  3.9821e-02,  9.1797e-01,  ...,  9.9993e-01,\n",
       "           1.0897e-02,  9.9994e-01]]], device='cuda:0'))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f539b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "orderedDict = collections.OrderedDict()\n",
    "\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5c4a46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#맞추기\n",
    "#best = torch.load(state_dict_path)\n",
    "new_state_dict = OrderedDict()\n",
    "for n, v in best.items():\n",
    "    name = n.replace(\"base.\",\"\") # .module이 중간에 포함된 형태라면 (\".module\",\"\")로 치환\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b6a3b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.startswith('encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8f57a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.startswith('encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d0dffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x7fd1c2e5fb10>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "398fb916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'base.bn0.weight'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.replace('encoder','base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623be615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85e789ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:transformer_decoder.layers.0.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:word_emb.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.bn0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.bn0.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 1, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "#model parameter 확인\n",
    "for name, param in model.named_parameters(): \n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14ee54d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:transformer_decoder.layers.0.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:word_emb.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.bn0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.bn0.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 1, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.conv_block4.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "#model parameter 확인\n",
    "for name, param in model.named_parameters(): \n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3255704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swa\n",
    "from torchcontrib.optim import SWA\n",
    "import torchcontrib\n",
    "\n",
    "base_opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=hp.lr, weight_decay=1e-6)\n",
    "optimizer = torchcontrib.optim.SWA(base_opt, swa_start=10, swa_freq=5, swa_lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, hp.scheduler_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "77b5da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swa 안할때\n",
    "optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=hp.lr, weight_decay=1e-6)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, hp.scheduler_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1809dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = hp.data_dir\n",
    "eval_data_dir = hp.eval_data_dir\n",
    "train_data_dir = hp.train_data_dir\n",
    "word_dict_pickle_path = hp.word_dict_pickle_path\n",
    "word_freq_pickle_path = hp.word_freq_pickle_path\n",
    "test_data_dir = hp.test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4fa72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixup\n",
    "#data_dir = hp.data_dir\n",
    "#eval_data_dir = hp.eval_data_dir\n",
    "#train_data_dir = hp.train_data_dir\n",
    "word_dict_pickle_path = hp.word_dict_pickle_path\n",
    "word_freq_pickle_path = hp.word_freq_pickle_path\n",
    "#test_data_dir = hp.test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2cc2cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = get_clotho_loader(data_dir=data_dir, split='development',\n",
    "                                      input_field_name='features',\n",
    "                                      output_field_name='words_ind',\n",
    "                                      load_into_memory=False,\n",
    "                                      batch_size=hp.batch_size,\n",
    "                                      nb_t_steps_pad='max',\n",
    "                                      num_workers=4, return_reference=True, augment=hp.spec_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29c2b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3051 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3051 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전체 데이터 \n",
    "from tqdm import tqdm\n",
    "tqdm(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2304b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24420,\n",
       " 24739,\n",
       " 1,\n",
       " 718,\n",
       " 4808,\n",
       " 46,\n",
       " 16,\n",
       " 13138,\n",
       " 17,\n",
       " 24420,\n",
       " 45,\n",
       " 28,\n",
       " 71,\n",
       " 329,\n",
       " 873,\n",
       " 5,\n",
       " 7333,\n",
       " 12184,\n",
       " 768,\n",
       " 1,\n",
       " 97,\n",
       " 149,\n",
       " 45,\n",
       " 168,\n",
       " 132,\n",
       " 555,\n",
       " 1,\n",
       " 49,\n",
       " 3225,\n",
       " 1,\n",
       " 241,\n",
       " 1844,\n",
       " 9147,\n",
       " 81,\n",
       " 1,\n",
       " 991,\n",
       " 455,\n",
       " 14,\n",
       " 7,\n",
       " 3,\n",
       " 330,\n",
       " 1935,\n",
       " 36,\n",
       " 12,\n",
       " 62,\n",
       " 2,\n",
       " 3654,\n",
       " 258,\n",
       " 90,\n",
       " 84,\n",
       " 79,\n",
       " 2134,\n",
       " 1,\n",
       " 5,\n",
       " 75,\n",
       " 4060,\n",
       " 1703,\n",
       " 40,\n",
       " 2369,\n",
       " 468,\n",
       " 67,\n",
       " 630,\n",
       " 2,\n",
       " 114,\n",
       " 15,\n",
       " 5,\n",
       " 2986,\n",
       " 1905,\n",
       " 52,\n",
       " 481,\n",
       " 2,\n",
       " 5,\n",
       " 315,\n",
       " 3003,\n",
       " 121,\n",
       " 811,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 31,\n",
       " 2541,\n",
       " 15,\n",
       " 13,\n",
       " 172,\n",
       " 502,\n",
       " 567,\n",
       " 301,\n",
       " 844,\n",
       " 1,\n",
       " 2748,\n",
       " 2229,\n",
       " 28,\n",
       " 60,\n",
       " 133,\n",
       " 2,\n",
       " 423,\n",
       " 262,\n",
       " 88,\n",
       " 52,\n",
       " 1,\n",
       " 806,\n",
       " 282,\n",
       " 22,\n",
       " 211,\n",
       " 41,\n",
       " 759,\n",
       " 447,\n",
       " 338,\n",
       " 142,\n",
       " 454,\n",
       " 2337,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 22,\n",
       " 1,\n",
       " 129,\n",
       " 23,\n",
       " 268,\n",
       " 809,\n",
       " 692,\n",
       " 630,\n",
       " 417,\n",
       " 3,\n",
       " 148,\n",
       " 20,\n",
       " 55,\n",
       " 91,\n",
       " 38,\n",
       " 241,\n",
       " 2309,\n",
       " 783,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 52,\n",
       " 2,\n",
       " 134,\n",
       " 428,\n",
       " 107,\n",
       " 25,\n",
       " 1,\n",
       " 461,\n",
       " 11,\n",
       " 129,\n",
       " 36,\n",
       " 87,\n",
       " 492,\n",
       " 508,\n",
       " 7,\n",
       " 16,\n",
       " 28,\n",
       " 61,\n",
       " 27,\n",
       " 397,\n",
       " 40,\n",
       " 15,\n",
       " 25,\n",
       " 117,\n",
       " 22,\n",
       " 77,\n",
       " 873,\n",
       " 68,\n",
       " 21,\n",
       " 5,\n",
       " 1,\n",
       " 10,\n",
       " 44,\n",
       " 298,\n",
       " 428,\n",
       " 29,\n",
       " 103,\n",
       " 1259,\n",
       " 128,\n",
       " 1404,\n",
       " 1,\n",
       " 1149,\n",
       " 271,\n",
       " 1,\n",
       " 1,\n",
       " 274,\n",
       " 123,\n",
       " 59,\n",
       " 933,\n",
       " 404,\n",
       " 650,\n",
       " 446,\n",
       " 18,\n",
       " 600,\n",
       " 120,\n",
       " 1608,\n",
       " 11,\n",
       " 372,\n",
       " 209,\n",
       " 2,\n",
       " 900,\n",
       " 97,\n",
       " 46,\n",
       " 240,\n",
       " 60,\n",
       " 57,\n",
       " 9,\n",
       " 31,\n",
       " 175,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 526,\n",
       " 260,\n",
       " 44,\n",
       " 35,\n",
       " 319,\n",
       " 446,\n",
       " 87,\n",
       " 17,\n",
       " 5,\n",
       " 1,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 26,\n",
       " 15,\n",
       " 13,\n",
       " 1,\n",
       " 46,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 398,\n",
       " 8,\n",
       " 27,\n",
       " 6,\n",
       " 2,\n",
       " 10,\n",
       " 94,\n",
       " 241,\n",
       " 125,\n",
       " 2,\n",
       " 44,\n",
       " 77,\n",
       " 13,\n",
       " 29,\n",
       " 13,\n",
       " 538,\n",
       " 524,\n",
       " 410,\n",
       " 293,\n",
       " 209,\n",
       " 164,\n",
       " 107,\n",
       " 142,\n",
       " 137,\n",
       " 679,\n",
       " 104,\n",
       " 708,\n",
       " 323,\n",
       " 903,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 22,\n",
       " 32,\n",
       " 23,\n",
       " 3,\n",
       " 3,\n",
       " 298,\n",
       " 91,\n",
       " 1,\n",
       " 173,\n",
       " 9,\n",
       " 18,\n",
       " 115,\n",
       " 17,\n",
       " 1,\n",
       " 43,\n",
       " 2,\n",
       " 5,\n",
       " 299,\n",
       " 1325,\n",
       " 119,\n",
       " 423,\n",
       " 112,\n",
       " 30,\n",
       " 46,\n",
       " 423,\n",
       " 3,\n",
       " 174,\n",
       " 4,\n",
       " 1,\n",
       " 122,\n",
       " 65,\n",
       " 2,\n",
       " 206,\n",
       " 423,\n",
       " 17,\n",
       " 2216,\n",
       " 163,\n",
       " 14,\n",
       " 864,\n",
       " 273,\n",
       " 55,\n",
       " 61,\n",
       " 387,\n",
       " 15,\n",
       " 61,\n",
       " 4,\n",
       " 111,\n",
       " 136,\n",
       " 121,\n",
       " 372,\n",
       " 23,\n",
       " 238,\n",
       " 220,\n",
       " 20,\n",
       " 4,\n",
       " 124,\n",
       " 2,\n",
       " 16,\n",
       " 3,\n",
       " 12,\n",
       " 133,\n",
       " 967,\n",
       " 28,\n",
       " 1,\n",
       " 1,\n",
       " 191,\n",
       " 548,\n",
       " 189,\n",
       " 34,\n",
       " 4,\n",
       " 19,\n",
       " 5,\n",
       " 3,\n",
       " 10,\n",
       " 64,\n",
       " 468,\n",
       " 92,\n",
       " 146,\n",
       " 52,\n",
       " 160,\n",
       " 144,\n",
       " 180,\n",
       " 3,\n",
       " 342,\n",
       " 127,\n",
       " 430,\n",
       " 3,\n",
       " 1,\n",
       " 119,\n",
       " 4,\n",
       " 70,\n",
       " 5,\n",
       " 35,\n",
       " 1,\n",
       " 63,\n",
       " 73,\n",
       " 22,\n",
       " 5,\n",
       " 28,\n",
       " 1,\n",
       " 3,\n",
       " 158,\n",
       " 21,\n",
       " 25,\n",
       " 176,\n",
       " 4,\n",
       " 12,\n",
       " 181,\n",
       " 431,\n",
       " 81,\n",
       " 96,\n",
       " 8,\n",
       " 34,\n",
       " 522,\n",
       " 127,\n",
       " 1,\n",
       " 11,\n",
       " 8,\n",
       " 17,\n",
       " 3,\n",
       " 3,\n",
       " 30,\n",
       " 32,\n",
       " 899,\n",
       " 250,\n",
       " 50,\n",
       " 13,\n",
       " 1,\n",
       " 27,\n",
       " 10,\n",
       " 2,\n",
       " 15,\n",
       " 97,\n",
       " 4,\n",
       " 85,\n",
       " 5,\n",
       " 21,\n",
       " 12,\n",
       " 523,\n",
       " 537,\n",
       " 72,\n",
       " 12,\n",
       " 20,\n",
       " 128,\n",
       " 17,\n",
       " 44,\n",
       " 3,\n",
       " 9,\n",
       " 61,\n",
       " 3,\n",
       " 2,\n",
       " 20,\n",
       " 31,\n",
       " 160,\n",
       " 103,\n",
       " 47,\n",
       " 24,\n",
       " 126,\n",
       " 18,\n",
       " 124,\n",
       " 1,\n",
       " 8,\n",
       " 35,\n",
       " 76,\n",
       " 13,\n",
       " 13,\n",
       " 56,\n",
       " 1,\n",
       " 30,\n",
       " 17,\n",
       " 56,\n",
       " 990,\n",
       " 64,\n",
       " 4,\n",
       " 55,\n",
       " 64,\n",
       " 20,\n",
       " 39,\n",
       " 33,\n",
       " 633,\n",
       " 5,\n",
       " 137,\n",
       " 19,\n",
       " 3,\n",
       " 1170,\n",
       " 180,\n",
       " 1,\n",
       " 43,\n",
       " 629,\n",
       " 1,\n",
       " 4,\n",
       " 47,\n",
       " 373,\n",
       " 314,\n",
       " 47,\n",
       " 337,\n",
       " 217,\n",
       " 76,\n",
       " 335,\n",
       " 1011,\n",
       " 549,\n",
       " 75,\n",
       " 196,\n",
       " 224,\n",
       " 196,\n",
       " 22,\n",
       " 9,\n",
       " 227,\n",
       " 11,\n",
       " 9,\n",
       " 1,\n",
       " 87,\n",
       " 57,\n",
       " 1,\n",
       " 41,\n",
       " 1,\n",
       " 44,\n",
       " 150,\n",
       " 72,\n",
       " 33,\n",
       " 65,\n",
       " 10,\n",
       " 1,\n",
       " 4,\n",
       " 306,\n",
       " 39,\n",
       " 24,\n",
       " 6,\n",
       " 600,\n",
       " 149,\n",
       " 36,\n",
       " 19,\n",
       " 5,\n",
       " 11,\n",
       " 263,\n",
       " 39,\n",
       " 2,\n",
       " 926,\n",
       " 4,\n",
       " 79,\n",
       " 34,\n",
       " 1,\n",
       " 65,\n",
       " 61,\n",
       " 3,\n",
       " 37,\n",
       " 157,\n",
       " 25,\n",
       " 15,\n",
       " 193,\n",
       " 17,\n",
       " 4,\n",
       " 29,\n",
       " 67,\n",
       " 12,\n",
       " 759,\n",
       " 56,\n",
       " 16,\n",
       " 92,\n",
       " 20,\n",
       " 18,\n",
       " 95,\n",
       " 11,\n",
       " 5,\n",
       " 3,\n",
       " 29,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 103,\n",
       " 171,\n",
       " 411,\n",
       " 170,\n",
       " 100,\n",
       " 10,\n",
       " 142,\n",
       " 132,\n",
       " 4,\n",
       " 47,\n",
       " 4,\n",
       " 2,\n",
       " 127,\n",
       " 6,\n",
       " 2,\n",
       " 86,\n",
       " 106,\n",
       " 26,\n",
       " 40,\n",
       " 15,\n",
       " 32,\n",
       " 3,\n",
       " 4,\n",
       " 14,\n",
       " 68,\n",
       " 8,\n",
       " 13,\n",
       " 10,\n",
       " 672,\n",
       " 69,\n",
       " 36,\n",
       " 5,\n",
       " 15,\n",
       " 19,\n",
       " 50,\n",
       " 11,\n",
       " 313,\n",
       " 13,\n",
       " 21,\n",
       " 40,\n",
       " 33,\n",
       " 25,\n",
       " 41,\n",
       " 79,\n",
       " 111,\n",
       " 42,\n",
       " 75,\n",
       " 2,\n",
       " 1,\n",
       " 12,\n",
       " 23,\n",
       " 20,\n",
       " 124,\n",
       " 9,\n",
       " 7,\n",
       " 66,\n",
       " 43,\n",
       " 155,\n",
       " 85,\n",
       " 2,\n",
       " 7,\n",
       " 17,\n",
       " 145,\n",
       " 305,\n",
       " 51,\n",
       " 2,\n",
       " 441,\n",
       " 1,\n",
       " 34,\n",
       " 3,\n",
       " 24,\n",
       " 42,\n",
       " 47,\n",
       " 58,\n",
       " 2,\n",
       " 48,\n",
       " 7,\n",
       " 69,\n",
       " 126,\n",
       " 16,\n",
       " 169,\n",
       " 79,\n",
       " 17,\n",
       " 667,\n",
       " 232,\n",
       " 353,\n",
       " 38,\n",
       " 3,\n",
       " 3,\n",
       " 590,\n",
       " 399,\n",
       " 63,\n",
       " 82,\n",
       " 4,\n",
       " 3,\n",
       " 131,\n",
       " 9,\n",
       " 47,\n",
       " 288,\n",
       " 195,\n",
       " 8,\n",
       " 56,\n",
       " 1,\n",
       " 346,\n",
       " 6,\n",
       " 17,\n",
       " 60,\n",
       " 28,\n",
       " 47,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 41,\n",
       " 53,\n",
       " 32,\n",
       " 107,\n",
       " 50,\n",
       " 69,\n",
       " 97,\n",
       " 35,\n",
       " 22,\n",
       " 99,\n",
       " 107,\n",
       " 54,\n",
       " 849,\n",
       " 360,\n",
       " 115,\n",
       " 1,\n",
       " 43,\n",
       " 4,\n",
       " 1,\n",
       " 19,\n",
       " 170,\n",
       " 1,\n",
       " 3,\n",
       " 18,\n",
       " 38,\n",
       " 59,\n",
       " 112,\n",
       " 17,\n",
       " 140,\n",
       " 1,\n",
       " 130,\n",
       " 24,\n",
       " 7,\n",
       " 66,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 70,\n",
       " 6,\n",
       " 4,\n",
       " 23,\n",
       " 104,\n",
       " 25,\n",
       " 156,\n",
       " 28,\n",
       " 15,\n",
       " 5,\n",
       " 425,\n",
       " 86,\n",
       " 237,\n",
       " 92,\n",
       " 2,\n",
       " 10,\n",
       " 30,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 11,\n",
       " 6,\n",
       " 1,\n",
       " 52,\n",
       " 268,\n",
       " 176,\n",
       " 11,\n",
       " 7,\n",
       " 159,\n",
       " 33,\n",
       " 79,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 48,\n",
       " 2,\n",
       " 15,\n",
       " 139,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 131,\n",
       " 263,\n",
       " 12,\n",
       " 376,\n",
       " 9,\n",
       " 238,\n",
       " 21,\n",
       " 5,\n",
       " 128,\n",
       " 9,\n",
       " 107,\n",
       " 69,\n",
       " 129,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 116,\n",
       " 29,\n",
       " 43,\n",
       " 84,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 26,\n",
       " 279,\n",
       " 1,\n",
       " 157,\n",
       " 136,\n",
       " 48,\n",
       " 20,\n",
       " 16,\n",
       " 34,\n",
       " 223,\n",
       " 34,\n",
       " 16,\n",
       " 50,\n",
       " 5,\n",
       " 221,\n",
       " 55,\n",
       " 73,\n",
       " 43,\n",
       " 2,\n",
       " 80,\n",
       " 10,\n",
       " 89,\n",
       " 94,\n",
       " 3,\n",
       " 55,\n",
       " 57,\n",
       " 1,\n",
       " 51,\n",
       " 28,\n",
       " 115,\n",
       " 306,\n",
       " 12,\n",
       " 25,\n",
       " 275,\n",
       " 157,\n",
       " 8,\n",
       " 240,\n",
       " 8,\n",
       " 13,\n",
       " 43,\n",
       " 9,\n",
       " 31,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 22,\n",
       " 11,\n",
       " 5,\n",
       " 39,\n",
       " 17,\n",
       " 8,\n",
       " 14,\n",
       " 2,\n",
       " 39,\n",
       " 63,\n",
       " 6,\n",
       " 15,\n",
       " 8,\n",
       " 8,\n",
       " 14,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 24,\n",
       " 4,\n",
       " 10,\n",
       " 113,\n",
       " 3,\n",
       " 15,\n",
       " 20,\n",
       " 27,\n",
       " 21,\n",
       " 2,\n",
       " 48,\n",
       " 102,\n",
       " 75,\n",
       " 52,\n",
       " 314,\n",
       " 26,\n",
       " 26,\n",
       " 150,\n",
       " 6,\n",
       " 379,\n",
       " 9,\n",
       " 10,\n",
       " 2,\n",
       " 9,\n",
       " 91,\n",
       " 5,\n",
       " 195,\n",
       " 2,\n",
       " 27,\n",
       " 32,\n",
       " 51,\n",
       " 3,\n",
       " 35,\n",
       " 135,\n",
       " 60,\n",
       " 19,\n",
       " 1,\n",
       " 251,\n",
       " 33,\n",
       " 266,\n",
       " 28,\n",
       " 1,\n",
       " 13,\n",
       " 72,\n",
       " 25,\n",
       " 2,\n",
       " 79,\n",
       " 13,\n",
       " 41,\n",
       " 2,\n",
       " 5,\n",
       " 15,\n",
       " 101,\n",
       " 12,\n",
       " 56,\n",
       " 4,\n",
       " 27,\n",
       " 61,\n",
       " 61,\n",
       " 3,\n",
       " 4,\n",
       " 41,\n",
       " 9,\n",
       " 26,\n",
       " 188,\n",
       " 73,\n",
       " 36,\n",
       " 31,\n",
       " 17,\n",
       " 4,\n",
       " 10,\n",
       " 94,\n",
       " 23,\n",
       " 1,\n",
       " 16,\n",
       " 38,\n",
       " 131,\n",
       " 202,\n",
       " 27,\n",
       " 1,\n",
       " 180,\n",
       " 30,\n",
       " 3,\n",
       " 3,\n",
       " 84,\n",
       " 1,\n",
       " 147,\n",
       " 41,\n",
       " 3,\n",
       " 60,\n",
       " 1,\n",
       " 4,\n",
       " 21,\n",
       " 45,\n",
       " 175,\n",
       " 2,\n",
       " 104,\n",
       " 7,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 18,\n",
       " 8,\n",
       " 130,\n",
       " 2,\n",
       " 133,\n",
       " 9,\n",
       " 58,\n",
       " 20,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 133,\n",
       " 61,\n",
       " 8,\n",
       " 5,\n",
       " 103,\n",
       " 63,\n",
       " 5,\n",
       " 5,\n",
       " 251,\n",
       " 44,\n",
       " 3,\n",
       " 109,\n",
       " 2,\n",
       " 15,\n",
       " 7,\n",
       " 17,\n",
       " 76,\n",
       " 233,\n",
       " 282,\n",
       " 2,\n",
       " 29,\n",
       " 202,\n",
       " 50,\n",
       " 2,\n",
       " 56,\n",
       " 56,\n",
       " 73,\n",
       " 30,\n",
       " 89,\n",
       " 1,\n",
       " 5,\n",
       " 32,\n",
       " 2,\n",
       " 134,\n",
       " 2,\n",
       " 2,\n",
       " 179,\n",
       " 28,\n",
       " 87,\n",
       " 160,\n",
       " 12,\n",
       " 7,\n",
       " 4,\n",
       " 35,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 13,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 115,\n",
       " 2,\n",
       " 11,\n",
       " 39,\n",
       " 22,\n",
       " 62,\n",
       " 57,\n",
       " 3,\n",
       " 36,\n",
       " 1,\n",
       " 18,\n",
       " 1,\n",
       " 41,\n",
       " 34,\n",
       " 5,\n",
       " 17,\n",
       " 12,\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "#워드 개수 확인\n",
    "with open('./create_dataset/data/pickles/words_frequencies.p','rb') as f:\n",
    "    words_freq=pickle.load(f)\n",
    "words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85ae9cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4371"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9f1f1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_beam = get_clotho_loader(data_dir=data_dir, split='evaluation',\n",
    "                                        input_field_name='features',\n",
    "                                        output_field_name='words_ind',\n",
    "                                        load_into_memory=False,\n",
    "                                        batch_size=32,\n",
    "                                        nb_t_steps_pad='max',\n",
    "                                        shuffle=False,\n",
    "                                        return_reference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1cf2eb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "test_data = get_test_data_loader(data_dir=test_data_dir,\n",
    "                                     batch_size=hp.batch_size * 2,\n",
    "                                     nb_t_steps_pad='max',\n",
    "                                     shuffle=False,\n",
    "                                     drop_last=False,\n",
    "                                     input_pad_at='start',\n",
    "                                     num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "475347a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss_text = 0.\n",
    "    start_time = time.time()\n",
    "    batch = 0\n",
    "    for src, tgt, tgt_len,ref in training_data:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        tgt_pad_mask = get_padding(tgt, tgt_len)\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        tgt_pad_mask = tgt_pad_mask[:, :-1]\n",
    "        tgt_y = tgt[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, tgt_in, target_padding_mask=tgt_pad_mask)\n",
    "\n",
    "        loss_text = criterion(output.contiguous().view(-1, hp.ntoken), tgt_y.transpose(0, 1).contiguous().view(-1))\n",
    "        loss = loss_text\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), hp.clip_grad)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "        total_loss_text += loss_text.item()\n",
    "\n",
    "        writer.add_scalar('Loss/train-text', loss_text.item(), (epoch - 1) * len(training_data) + batch)\n",
    "        \n",
    "        \n",
    "        batch += 1\n",
    "        \n",
    "        if batch % hp.log_interval == 0 and batch > 0:\n",
    "            mean_text_loss = total_loss_text / hp.log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            current_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\n",
    "            logging.info('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2e} | ms/batch {:5.2f} | '\n",
    "                         'loss-text {:5.4f}'.format(\n",
    "                epoch, batch, len(training_data), current_lr,\n",
    "                elapsed * 1000 / hp.log_interval, mean_text_loss))\n",
    "            total_loss_text = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "            \n",
    "\n",
    "def eval_all(evaluation_data, max_len=30, eos_ind=9, word_dict_pickle_path=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_sentence_all = []\n",
    "        ref_all = []\n",
    "        for src, tgt, _, ref in evaluation_data:\n",
    "            src = src.to(device)\n",
    "            output = greedy_decode(model, src, max_len=max_len)\n",
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for i in range(output.size()[0]):\n",
    "                output_sentence_ind = []\n",
    "                for j in range(1, output.size(1)):\n",
    "                    sym = output[i, j]\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n",
    "\n",
    "        loss_mean = score\n",
    "        writer.add_scalar(f'Loss/eval_greddy', loss_mean, epoch)\n",
    "        msg = f'eval_greddy SPIDEr: {loss_mean:2.4f}'\n",
    "        logging.info(msg)\n",
    "\n",
    "\n",
    "def eval_with_beam(evaluation_data, max_len=30, eos_ind=9, word_dict_pickle_path=None, beam_size=3):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_sentence_all = []\n",
    "        ref_all = []\n",
    "        for src, tgt, _, ref in evaluation_data:\n",
    "            src = src.to(device)\n",
    "            output = beam_search(model, src, max_len, start_symbol_ind=0, beam_size=beam_size)\n",
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for single_sample in output:\n",
    "                output_sentence_ind = []\n",
    "                for sym in single_sample:\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n",
    "\n",
    "        loss_mean = score\n",
    "        writer.add_scalar(f'Loss/eval_beam', loss_mean, epoch)\n",
    "        msg = f'eval_beam_{beam_size} SPIDEr: {loss_mean:2.4f}'\n",
    "        logging.info(msg)\n",
    "\n",
    "\n",
    "def test_with_beam(test_data, max_len=30, eos_ind=9, beam_size=3):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with open(\"test_out.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['file_name', 'caption_predicted'])\n",
    "            for src, filename in test_data:\n",
    "                src = src.to(device)\n",
    "                output = beam_search(model, src, max_len, start_symbol_ind=0, beam_size=beam_size)\n",
    "\n",
    "                output_sentence_ind_batch = []\n",
    "                for single_sample in output:\n",
    "                    output_sentence_ind = []\n",
    "                    for sym in single_sample:\n",
    "                        if sym == eos_ind: break\n",
    "                        output_sentence_ind.append(sym.item())\n",
    "                    output_sentence_ind_batch.append(output_sentence_ind)\n",
    "                out_str = gen_str(output_sentence_ind_batch, hp.word_dict_pickle_path)\n",
    "                for caption, fn in zip(out_str, filename):\n",
    "                    writer.writerow(['{}.wav'.format(fn), caption])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d583cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hp.label_smoothing:\n",
    "    criterion = LabelSmoothingLoss(hp.ntoken, smoothing=0.1)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=hp.ntoken - 1)\n",
    "\n",
    "now_time = str(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(time.time())))\n",
    "log_dir = 'models/{name}'.format(name=hp.name)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "log_path = os.path.join(log_dir, 'train.log')\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                        format=\n",
    "                        '%(asctime)s - %(levelname)s: %(message)s',\n",
    "                        handlers=[\n",
    "                            logging.FileHandler(log_path),\n",
    "                            logging.StreamHandler(sys.stdout)]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0708d0f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-16 00:37:39,204 - INFO: TransformerModel(\n",
      "  (transformer_decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (dropout3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (dropout3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_emb): Embedding(4371, 192)\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc1): Linear(in_features=512, out_features=192, bias=True)\n",
      "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
      "  (encoder): Cnn10(\n",
      "    (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_block1): ConvBlock(\n",
      "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_block2): ConvBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_block3): ConvBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_block4): ConvBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (generator): Softmax(dim=-1)\n",
      ")\n",
      "2021-12-16 00:37:39,205 - INFO: {'batch_size': 8, 'beam_width': 3, 'checkpoint_save_interval': 5, 'clip_grad': 2.5, 'data_dir': PosixPath('/home/hj20/dcase_2020_T6/create_dataset/data/data_splits'), 'device': 'cuda', 'eval_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/data_splits/evaluation', 'freeze_cnn': True, 'label_smoothing': True, 'load_pretrain_cnn': True, 'load_pretrain_emb': False, 'load_pretrain_model': True, 'log_interval': 100, 'lr': 1e-05, 'mode': 'train', 'name': '1214lr_0.00001', 'nhead': 4, 'nhid': 192, 'ninp': 64, 'nkeyword': 4979, 'nlayers': 2, 'ntoken': 4371, 'pretrain_cnn_path': '/home/hj20/dcase_2020_T6/models/tag_models/TagModel_45.pt', 'pretrain_emb_path': '/home/hj20/dcase_2020_T6/models/w2v_192.mod', 'pretrain_model_path': '/home/hj20/dcase_2020_T6/models/base/46.pt', 'scheduler_decay': 0.98, 'seed': 1111, 'spec_augmentation': True, 'test_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/test_data', 'train_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/data_splits/development', 'training_epochs': 50, 'word_dict_pickle_path': '/home/hj20/dcase_2020_T6/create_dataset/data/pickles/words_list.p', 'word_freq_pickle_path': '/home/hj20/dcase_2020_T6/create_dataset/data/pickles/words_frequencies.p'}\n",
      "2021-12-16 00:37:39,206 - INFO: Data loaded!\n",
      "2021-12-16 00:37:39,207 - INFO: Data size: 3051\n",
      "2021-12-16 00:37:39,207 - INFO: Total Model parameters: 4216531\n"
     ]
    }
   ],
   "source": [
    "    logging.info(str(model))\n",
    "\n",
    "    logging.info(str(print_hparams(hp)))\n",
    "\n",
    "    logging.info('Data loaded!')\n",
    "    logging.info('Data size: ' + str(len(training_data)))\n",
    "\n",
    "    logging.info('Total Model parameters: ' + str(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc51859f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-16 00:39:29,618 - INFO: | epoch   1 |   100/ 3051 batches | lr 1.00e-05 | ms/batch 60.72 | loss-text 2.9574\n",
      "2021-12-16 00:39:35,475 - INFO: | epoch   1 |   200/ 3051 batches | lr 1.00e-05 | ms/batch 58.55 | loss-text 2.9344\n",
      "2021-12-16 00:39:41,375 - INFO: | epoch   1 |   300/ 3051 batches | lr 1.00e-05 | ms/batch 59.00 | loss-text 2.9563\n",
      "2021-12-16 00:39:47,252 - INFO: | epoch   1 |   400/ 3051 batches | lr 1.00e-05 | ms/batch 58.76 | loss-text 2.9104\n",
      "2021-12-16 00:39:53,143 - INFO: | epoch   1 |   500/ 3051 batches | lr 1.00e-05 | ms/batch 58.90 | loss-text 2.9760\n",
      "2021-12-16 00:39:59,063 - INFO: | epoch   1 |   600/ 3051 batches | lr 1.00e-05 | ms/batch 59.20 | loss-text 2.9816\n",
      "2021-12-16 00:40:04,971 - INFO: | epoch   1 |   700/ 3051 batches | lr 1.00e-05 | ms/batch 59.07 | loss-text 2.9294\n",
      "2021-12-16 00:40:10,889 - INFO: | epoch   1 |   800/ 3051 batches | lr 1.00e-05 | ms/batch 59.18 | loss-text 2.9552\n",
      "2021-12-16 00:40:16,811 - INFO: | epoch   1 |   900/ 3051 batches | lr 1.00e-05 | ms/batch 59.21 | loss-text 3.0063\n",
      "2021-12-16 00:40:22,703 - INFO: | epoch   1 |  1000/ 3051 batches | lr 1.00e-05 | ms/batch 58.91 | loss-text 2.9932\n",
      "2021-12-16 00:40:28,632 - INFO: | epoch   1 |  1100/ 3051 batches | lr 1.00e-05 | ms/batch 59.29 | loss-text 2.9313\n",
      "2021-12-16 00:40:34,547 - INFO: | epoch   1 |  1200/ 3051 batches | lr 1.00e-05 | ms/batch 59.14 | loss-text 2.9882\n",
      "2021-12-16 00:40:40,433 - INFO: | epoch   1 |  1300/ 3051 batches | lr 1.00e-05 | ms/batch 58.85 | loss-text 2.9583\n",
      "2021-12-16 00:40:46,366 - INFO: | epoch   1 |  1400/ 3051 batches | lr 1.00e-05 | ms/batch 59.32 | loss-text 2.9663\n",
      "2021-12-16 00:40:52,319 - INFO: | epoch   1 |  1500/ 3051 batches | lr 1.00e-05 | ms/batch 59.53 | loss-text 2.9550\n",
      "2021-12-16 00:40:58,273 - INFO: | epoch   1 |  1600/ 3051 batches | lr 1.00e-05 | ms/batch 59.53 | loss-text 2.9713\n",
      "2021-12-16 00:41:04,227 - INFO: | epoch   1 |  1700/ 3051 batches | lr 1.00e-05 | ms/batch 59.54 | loss-text 2.9626\n",
      "2021-12-16 00:41:10,153 - INFO: | epoch   1 |  1800/ 3051 batches | lr 1.00e-05 | ms/batch 59.26 | loss-text 2.9607\n",
      "2021-12-16 00:41:16,163 - INFO: | epoch   1 |  1900/ 3051 batches | lr 1.00e-05 | ms/batch 60.09 | loss-text 2.9572\n",
      "2021-12-16 00:41:22,122 - INFO: | epoch   1 |  2000/ 3051 batches | lr 1.00e-05 | ms/batch 59.58 | loss-text 2.9568\n",
      "2021-12-16 00:41:28,009 - INFO: | epoch   1 |  2100/ 3051 batches | lr 1.00e-05 | ms/batch 58.87 | loss-text 2.9779\n",
      "2021-12-16 00:41:33,922 - INFO: | epoch   1 |  2200/ 3051 batches | lr 1.00e-05 | ms/batch 59.12 | loss-text 2.9802\n",
      "2021-12-16 00:41:39,897 - INFO: | epoch   1 |  2300/ 3051 batches | lr 1.00e-05 | ms/batch 59.75 | loss-text 2.9542\n",
      "2021-12-16 00:41:45,839 - INFO: | epoch   1 |  2400/ 3051 batches | lr 1.00e-05 | ms/batch 59.41 | loss-text 2.9886\n",
      "2021-12-16 00:41:51,773 - INFO: | epoch   1 |  2500/ 3051 batches | lr 1.00e-05 | ms/batch 59.33 | loss-text 2.9694\n",
      "2021-12-16 00:41:57,705 - INFO: | epoch   1 |  2600/ 3051 batches | lr 1.00e-05 | ms/batch 59.31 | loss-text 2.9416\n",
      "2021-12-16 00:42:03,632 - INFO: | epoch   1 |  2700/ 3051 batches | lr 1.00e-05 | ms/batch 59.27 | loss-text 2.9774\n",
      "2021-12-16 00:42:09,661 - INFO: | epoch   1 |  2800/ 3051 batches | lr 1.00e-05 | ms/batch 60.28 | loss-text 2.9844\n",
      "2021-12-16 00:42:15,647 - INFO: | epoch   1 |  2900/ 3051 batches | lr 1.00e-05 | ms/batch 59.85 | loss-text 2.9330\n",
      "2021-12-16 00:42:21,591 - INFO: | epoch   1 |  3000/ 3051 batches | lr 1.00e-05 | ms/batch 59.43 | loss-text 2.9415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003981\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9969, 'reflen': 10179, 'guess': [9969, 8945, 7921, 6897], 'correct': [5399, 1813, 679, 214]}\n",
      "ratio: 0.979369289714021\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.324\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.307\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.205\n",
      "2021-12-16 00:42:47,483 - INFO: eval_greddy SPIDEr: 0.2053\n",
      "loading annotations into memory...\n",
      "0:00:00.004043\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9258, 'reflen': 9711, 'guess': [9258, 8234, 7210, 6186], 'correct': [5229, 1883, 741, 242]}\n",
      "ratio: 0.9533518690144214\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.342\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.349\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2021-12-16 00:43:13,660 - INFO: eval_beam_2 SPIDEr: 0.2274\n",
      "loading annotations into memory...\n",
      "0:00:00.003784\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9033, 'reflen': 9550, 'guess': [9033, 8009, 6985, 5961], 'correct': [5205, 1917, 800, 281]}\n",
      "ratio: 0.9458638743454506\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 00:43:42,055 - INFO: eval_beam_3 SPIDEr: 0.2346\n",
      "loading annotations into memory...\n",
      "0:00:00.003898\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8873, 'reflen': 9453, 'guess': [8873, 7849, 6825, 5801], 'correct': [5107, 1893, 788, 288]}\n",
      "ratio: 0.9386438167776432\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 00:44:12,841 - INFO: eval_beam_4 SPIDEr: 0.2336\n",
      "2021-12-16 00:44:18,960 - INFO: | epoch   2 |   100/ 3051 batches | lr 9.80e-06 | ms/batch 61.16 | loss-text 2.9410\n",
      "2021-12-16 00:44:24,876 - INFO: | epoch   2 |   200/ 3051 batches | lr 9.80e-06 | ms/batch 59.15 | loss-text 2.9447\n",
      "2021-12-16 00:44:30,813 - INFO: | epoch   2 |   300/ 3051 batches | lr 9.80e-06 | ms/batch 59.36 | loss-text 2.9529\n",
      "2021-12-16 00:44:36,822 - INFO: | epoch   2 |   400/ 3051 batches | lr 9.80e-06 | ms/batch 60.09 | loss-text 2.9582\n",
      "2021-12-16 00:44:42,740 - INFO: | epoch   2 |   500/ 3051 batches | lr 9.80e-06 | ms/batch 59.17 | loss-text 2.9273\n",
      "2021-12-16 00:44:48,703 - INFO: | epoch   2 |   600/ 3051 batches | lr 9.80e-06 | ms/batch 59.63 | loss-text 2.9358\n",
      "2021-12-16 00:44:54,639 - INFO: | epoch   2 |   700/ 3051 batches | lr 9.80e-06 | ms/batch 59.35 | loss-text 2.9343\n",
      "2021-12-16 00:45:00,599 - INFO: | epoch   2 |   800/ 3051 batches | lr 9.80e-06 | ms/batch 59.60 | loss-text 2.9382\n",
      "2021-12-16 00:45:06,572 - INFO: | epoch   2 |   900/ 3051 batches | lr 9.80e-06 | ms/batch 59.72 | loss-text 2.9842\n",
      "2021-12-16 00:45:12,509 - INFO: | epoch   2 |  1000/ 3051 batches | lr 9.80e-06 | ms/batch 59.36 | loss-text 2.9837\n",
      "2021-12-16 00:45:18,478 - INFO: | epoch   2 |  1100/ 3051 batches | lr 9.80e-06 | ms/batch 59.69 | loss-text 2.9360\n",
      "2021-12-16 00:45:24,388 - INFO: | epoch   2 |  1200/ 3051 batches | lr 9.80e-06 | ms/batch 59.10 | loss-text 2.9598\n",
      "2021-12-16 00:45:30,328 - INFO: | epoch   2 |  1300/ 3051 batches | lr 9.80e-06 | ms/batch 59.39 | loss-text 2.9081\n",
      "2021-12-16 00:45:36,280 - INFO: | epoch   2 |  1400/ 3051 batches | lr 9.80e-06 | ms/batch 59.52 | loss-text 2.9341\n",
      "2021-12-16 00:45:42,286 - INFO: | epoch   2 |  1500/ 3051 batches | lr 9.80e-06 | ms/batch 60.06 | loss-text 2.9481\n",
      "2021-12-16 00:45:48,270 - INFO: | epoch   2 |  1600/ 3051 batches | lr 9.80e-06 | ms/batch 59.83 | loss-text 2.9750\n",
      "2021-12-16 00:45:54,253 - INFO: | epoch   2 |  1700/ 3051 batches | lr 9.80e-06 | ms/batch 59.83 | loss-text 2.9992\n",
      "2021-12-16 00:46:00,206 - INFO: | epoch   2 |  1800/ 3051 batches | lr 9.80e-06 | ms/batch 59.53 | loss-text 2.9942\n",
      "2021-12-16 00:46:06,189 - INFO: | epoch   2 |  1900/ 3051 batches | lr 9.80e-06 | ms/batch 59.82 | loss-text 2.9503\n",
      "2021-12-16 00:46:12,187 - INFO: | epoch   2 |  2000/ 3051 batches | lr 9.80e-06 | ms/batch 59.97 | loss-text 2.9282\n",
      "2021-12-16 00:46:18,147 - INFO: | epoch   2 |  2100/ 3051 batches | lr 9.80e-06 | ms/batch 59.59 | loss-text 2.9856\n",
      "2021-12-16 00:46:24,144 - INFO: | epoch   2 |  2200/ 3051 batches | lr 9.80e-06 | ms/batch 59.97 | loss-text 2.9502\n",
      "2021-12-16 00:46:30,123 - INFO: | epoch   2 |  2300/ 3051 batches | lr 9.80e-06 | ms/batch 59.78 | loss-text 2.9360\n",
      "2021-12-16 00:46:36,095 - INFO: | epoch   2 |  2400/ 3051 batches | lr 9.80e-06 | ms/batch 59.71 | loss-text 2.9334\n",
      "2021-12-16 00:46:42,055 - INFO: | epoch   2 |  2500/ 3051 batches | lr 9.80e-06 | ms/batch 59.60 | loss-text 2.9670\n",
      "2021-12-16 00:46:47,986 - INFO: | epoch   2 |  2600/ 3051 batches | lr 9.80e-06 | ms/batch 59.30 | loss-text 2.9450\n",
      "2021-12-16 00:46:53,974 - INFO: | epoch   2 |  2700/ 3051 batches | lr 9.80e-06 | ms/batch 59.88 | loss-text 2.9435\n",
      "2021-12-16 00:46:59,978 - INFO: | epoch   2 |  2800/ 3051 batches | lr 9.80e-06 | ms/batch 60.04 | loss-text 2.9554\n",
      "2021-12-16 00:47:05,991 - INFO: | epoch   2 |  2900/ 3051 batches | lr 9.80e-06 | ms/batch 60.13 | loss-text 2.9530\n",
      "2021-12-16 00:47:11,958 - INFO: | epoch   2 |  3000/ 3051 batches | lr 9.80e-06 | ms/batch 59.65 | loss-text 2.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003903\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10008, 'reflen': 10195, 'guess': [10008, 8984, 7960, 6936], 'correct': [5432, 1829, 677, 211]}\n",
      "ratio: 0.9816576753309483\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.326\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.314\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.209\n",
      "2021-12-16 00:47:39,592 - INFO: eval_greddy SPIDEr: 0.2089\n",
      "loading annotations into memory...\n",
      "0:00:00.003825\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9314, 'reflen': 9737, 'guess': [9314, 8290, 7266, 6242], 'correct': [5266, 1894, 745, 254]}\n",
      "ratio: 0.9565574612302602\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.354\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2021-12-16 00:48:03,815 - INFO: eval_beam_2 SPIDEr: 0.2304\n",
      "loading annotations into memory...\n",
      "0:00:00.003944\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9050, 'reflen': 9568, 'guess': [9050, 8026, 7002, 5978], 'correct': [5216, 1929, 801, 283]}\n",
      "ratio: 0.945861204013279\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 00:48:30,801 - INFO: eval_beam_3 SPIDEr: 0.2345\n",
      "loading annotations into memory...\n",
      "0:00:00.003943\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8868, 'reflen': 9449, 'guess': [8868, 7844, 6820, 5796], 'correct': [5069, 1872, 766, 272]}\n",
      "ratio: 0.9385120118530068\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.354\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2021-12-16 00:49:02,678 - INFO: eval_beam_4 SPIDEr: 0.2278\n",
      "2021-12-16 00:49:08,862 - INFO: | epoch   3 |   100/ 3051 batches | lr 9.60e-06 | ms/batch 61.81 | loss-text 2.9112\n",
      "2021-12-16 00:49:14,771 - INFO: | epoch   3 |   200/ 3051 batches | lr 9.60e-06 | ms/batch 59.08 | loss-text 2.9627\n",
      "2021-12-16 00:49:20,688 - INFO: | epoch   3 |   300/ 3051 batches | lr 9.60e-06 | ms/batch 59.16 | loss-text 2.9481\n",
      "2021-12-16 00:49:26,642 - INFO: | epoch   3 |   400/ 3051 batches | lr 9.60e-06 | ms/batch 59.54 | loss-text 2.9243\n",
      "2021-12-16 00:49:32,559 - INFO: | epoch   3 |   500/ 3051 batches | lr 9.60e-06 | ms/batch 59.17 | loss-text 2.9379\n",
      "2021-12-16 00:49:38,491 - INFO: | epoch   3 |   600/ 3051 batches | lr 9.60e-06 | ms/batch 59.31 | loss-text 2.9439\n",
      "2021-12-16 00:49:44,434 - INFO: | epoch   3 |   700/ 3051 batches | lr 9.60e-06 | ms/batch 59.41 | loss-text 2.9297\n",
      "2021-12-16 00:49:50,387 - INFO: | epoch   3 |   800/ 3051 batches | lr 9.60e-06 | ms/batch 59.53 | loss-text 2.9688\n",
      "2021-12-16 00:49:56,365 - INFO: | epoch   3 |   900/ 3051 batches | lr 9.60e-06 | ms/batch 59.77 | loss-text 2.9365\n",
      "2021-12-16 00:50:02,348 - INFO: | epoch   3 |  1000/ 3051 batches | lr 9.60e-06 | ms/batch 59.82 | loss-text 2.9507\n",
      "2021-12-16 00:50:08,316 - INFO: | epoch   3 |  1100/ 3051 batches | lr 9.60e-06 | ms/batch 59.68 | loss-text 2.9573\n",
      "2021-12-16 00:50:14,280 - INFO: | epoch   3 |  1200/ 3051 batches | lr 9.60e-06 | ms/batch 59.63 | loss-text 2.9157\n",
      "2021-12-16 00:50:20,269 - INFO: | epoch   3 |  1300/ 3051 batches | lr 9.60e-06 | ms/batch 59.89 | loss-text 2.9335\n",
      "2021-12-16 00:50:26,260 - INFO: | epoch   3 |  1400/ 3051 batches | lr 9.60e-06 | ms/batch 59.90 | loss-text 2.9743\n",
      "2021-12-16 00:50:32,334 - INFO: | epoch   3 |  1500/ 3051 batches | lr 9.60e-06 | ms/batch 60.74 | loss-text 2.9400\n",
      "2021-12-16 00:50:38,264 - INFO: | epoch   3 |  1600/ 3051 batches | lr 9.60e-06 | ms/batch 59.29 | loss-text 2.9281\n",
      "2021-12-16 00:50:44,231 - INFO: | epoch   3 |  1700/ 3051 batches | lr 9.60e-06 | ms/batch 59.67 | loss-text 2.9440\n",
      "2021-12-16 00:50:50,218 - INFO: | epoch   3 |  1800/ 3051 batches | lr 9.60e-06 | ms/batch 59.86 | loss-text 2.9648\n",
      "2021-12-16 00:50:56,212 - INFO: | epoch   3 |  1900/ 3051 batches | lr 9.60e-06 | ms/batch 59.92 | loss-text 2.9526\n",
      "2021-12-16 00:51:02,284 - INFO: | epoch   3 |  2000/ 3051 batches | lr 9.60e-06 | ms/batch 60.72 | loss-text 2.9372\n",
      "2021-12-16 00:51:08,257 - INFO: | epoch   3 |  2100/ 3051 batches | lr 9.60e-06 | ms/batch 59.72 | loss-text 2.9620\n",
      "2021-12-16 00:51:14,244 - INFO: | epoch   3 |  2200/ 3051 batches | lr 9.60e-06 | ms/batch 59.86 | loss-text 2.9466\n",
      "2021-12-16 00:51:20,260 - INFO: | epoch   3 |  2300/ 3051 batches | lr 9.60e-06 | ms/batch 60.16 | loss-text 2.9445\n",
      "2021-12-16 00:51:26,215 - INFO: | epoch   3 |  2400/ 3051 batches | lr 9.60e-06 | ms/batch 59.54 | loss-text 2.9628\n",
      "2021-12-16 00:51:32,225 - INFO: | epoch   3 |  2500/ 3051 batches | lr 9.60e-06 | ms/batch 60.09 | loss-text 2.9182\n",
      "2021-12-16 00:51:38,264 - INFO: | epoch   3 |  2600/ 3051 batches | lr 9.60e-06 | ms/batch 60.38 | loss-text 2.9490\n",
      "2021-12-16 00:51:44,272 - INFO: | epoch   3 |  2700/ 3051 batches | lr 9.60e-06 | ms/batch 60.08 | loss-text 2.9434\n",
      "2021-12-16 00:51:50,239 - INFO: | epoch   3 |  2800/ 3051 batches | lr 9.60e-06 | ms/batch 59.66 | loss-text 2.9343\n",
      "2021-12-16 00:51:56,227 - INFO: | epoch   3 |  2900/ 3051 batches | lr 9.60e-06 | ms/batch 59.87 | loss-text 2.9286\n",
      "2021-12-16 00:52:02,259 - INFO: | epoch   3 |  3000/ 3051 batches | lr 9.60e-06 | ms/batch 60.31 | loss-text 2.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003967\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9947, 'reflen': 10120, 'guess': [9947, 8923, 7899, 6875], 'correct': [5336, 1796, 663, 211]}\n",
      "ratio: 0.9829051383398237\n",
      "Bleu_1: 0.527\n",
      "Bleu_2: 0.323\n",
      "Bleu_3: 0.205\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.312\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.207\n",
      "2021-12-16 00:52:28,344 - INFO: eval_greddy SPIDEr: 0.2073\n",
      "loading annotations into memory...\n",
      "0:00:00.004100\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9178, 'reflen': 9653, 'guess': [9178, 8154, 7130, 6106], 'correct': [5219, 1891, 752, 249]}\n",
      "ratio: 0.9507924997409146\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 00:52:52,913 - INFO: eval_beam_2 SPIDEr: 0.2362\n",
      "loading annotations into memory...\n",
      "0:00:00.003950\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9045, 'reflen': 9539, 'guess': [9045, 8021, 6997, 5973], 'correct': [5195, 1915, 806, 279]}\n",
      "ratio: 0.9482126009014625\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 00:53:20,616 - INFO: eval_beam_3 SPIDEr: 0.2369\n",
      "loading annotations into memory...\n",
      "0:00:00.003818\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8849, 'reflen': 9433, 'guess': [8849, 7825, 6801, 5777], 'correct': [5108, 1913, 809, 292]}\n",
      "ratio: 0.9380896851477856\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 00:53:53,481 - INFO: eval_beam_4 SPIDEr: 0.2375\n",
      "2021-12-16 00:53:59,663 - INFO: | epoch   4 |   100/ 3051 batches | lr 9.41e-06 | ms/batch 61.78 | loss-text 2.9246\n",
      "2021-12-16 00:54:05,603 - INFO: | epoch   4 |   200/ 3051 batches | lr 9.41e-06 | ms/batch 59.39 | loss-text 2.9216\n",
      "2021-12-16 00:54:11,516 - INFO: | epoch   4 |   300/ 3051 batches | lr 9.41e-06 | ms/batch 59.12 | loss-text 2.9142\n",
      "2021-12-16 00:54:17,443 - INFO: | epoch   4 |   400/ 3051 batches | lr 9.41e-06 | ms/batch 59.26 | loss-text 2.9595\n",
      "2021-12-16 00:54:23,417 - INFO: | epoch   4 |   500/ 3051 batches | lr 9.41e-06 | ms/batch 59.74 | loss-text 2.9377\n",
      "2021-12-16 00:54:29,354 - INFO: | epoch   4 |   600/ 3051 batches | lr 9.41e-06 | ms/batch 59.36 | loss-text 2.9570\n",
      "2021-12-16 00:54:35,358 - INFO: | epoch   4 |   700/ 3051 batches | lr 9.41e-06 | ms/batch 60.03 | loss-text 2.9504\n",
      "2021-12-16 00:54:41,358 - INFO: | epoch   4 |   800/ 3051 batches | lr 9.41e-06 | ms/batch 59.99 | loss-text 2.9783\n",
      "2021-12-16 00:54:47,338 - INFO: | epoch   4 |   900/ 3051 batches | lr 9.41e-06 | ms/batch 59.79 | loss-text 2.9546\n",
      "2021-12-16 00:54:53,315 - INFO: | epoch   4 |  1000/ 3051 batches | lr 9.41e-06 | ms/batch 59.76 | loss-text 2.9720\n",
      "2021-12-16 00:54:59,256 - INFO: | epoch   4 |  1100/ 3051 batches | lr 9.41e-06 | ms/batch 59.41 | loss-text 2.9606\n",
      "2021-12-16 00:55:05,225 - INFO: | epoch   4 |  1200/ 3051 batches | lr 9.41e-06 | ms/batch 59.68 | loss-text 2.9277\n",
      "2021-12-16 00:55:11,228 - INFO: | epoch   4 |  1300/ 3051 batches | lr 9.41e-06 | ms/batch 60.03 | loss-text 2.9634\n",
      "2021-12-16 00:55:17,205 - INFO: | epoch   4 |  1400/ 3051 batches | lr 9.41e-06 | ms/batch 59.77 | loss-text 2.8886\n",
      "2021-12-16 00:55:23,149 - INFO: | epoch   4 |  1500/ 3051 batches | lr 9.41e-06 | ms/batch 59.43 | loss-text 2.9361\n",
      "2021-12-16 00:55:29,124 - INFO: | epoch   4 |  1600/ 3051 batches | lr 9.41e-06 | ms/batch 59.74 | loss-text 2.9680\n",
      "2021-12-16 00:55:35,156 - INFO: | epoch   4 |  1700/ 3051 batches | lr 9.41e-06 | ms/batch 60.31 | loss-text 2.9419\n",
      "2021-12-16 00:55:41,227 - INFO: | epoch   4 |  1800/ 3051 batches | lr 9.41e-06 | ms/batch 60.70 | loss-text 2.9492\n",
      "2021-12-16 00:55:47,201 - INFO: | epoch   4 |  1900/ 3051 batches | lr 9.41e-06 | ms/batch 59.73 | loss-text 2.9134\n",
      "2021-12-16 00:55:53,193 - INFO: | epoch   4 |  2000/ 3051 batches | lr 9.41e-06 | ms/batch 59.92 | loss-text 2.9143\n",
      "2021-12-16 00:55:59,188 - INFO: | epoch   4 |  2100/ 3051 batches | lr 9.41e-06 | ms/batch 59.94 | loss-text 2.9673\n",
      "2021-12-16 00:56:05,210 - INFO: | epoch   4 |  2200/ 3051 batches | lr 9.41e-06 | ms/batch 60.21 | loss-text 2.9084\n",
      "2021-12-16 00:56:11,255 - INFO: | epoch   4 |  2300/ 3051 batches | lr 9.41e-06 | ms/batch 60.45 | loss-text 2.9425\n",
      "2021-12-16 00:56:17,278 - INFO: | epoch   4 |  2400/ 3051 batches | lr 9.41e-06 | ms/batch 60.22 | loss-text 2.9058\n",
      "2021-12-16 00:56:23,285 - INFO: | epoch   4 |  2500/ 3051 batches | lr 9.41e-06 | ms/batch 60.06 | loss-text 2.9709\n",
      "2021-12-16 00:56:29,292 - INFO: | epoch   4 |  2600/ 3051 batches | lr 9.41e-06 | ms/batch 60.07 | loss-text 2.9529\n",
      "2021-12-16 00:56:35,283 - INFO: | epoch   4 |  2700/ 3051 batches | lr 9.41e-06 | ms/batch 59.90 | loss-text 2.9395\n",
      "2021-12-16 00:56:41,312 - INFO: | epoch   4 |  2800/ 3051 batches | lr 9.41e-06 | ms/batch 60.29 | loss-text 2.9114\n",
      "2021-12-16 00:56:47,347 - INFO: | epoch   4 |  2900/ 3051 batches | lr 9.41e-06 | ms/batch 60.34 | loss-text 2.9423\n",
      "2021-12-16 00:56:53,350 - INFO: | epoch   4 |  3000/ 3051 batches | lr 9.41e-06 | ms/batch 60.03 | loss-text 2.9571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003922\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9989, 'reflen': 10187, 'guess': [9989, 8965, 7941, 6917], 'correct': [5426, 1862, 704, 215]}\n",
      "ratio: 0.9805634632373632\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2021-12-16 00:57:19,797 - INFO: eval_greddy SPIDEr: 0.2145\n",
      "loading annotations into memory...\n",
      "0:00:00.004029\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9283, 'reflen': 9731, 'guess': [9283, 8259, 7235, 6211], 'correct': [5291, 1911, 754, 246]}\n",
      "ratio: 0.9539615661287685\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.352\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2021-12-16 00:57:43,956 - INFO: eval_beam_2 SPIDEr: 0.2293\n",
      "loading annotations into memory...\n",
      "0:00:00.003941\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9053, 'reflen': 9583, 'guess': [9053, 8029, 7005, 5981], 'correct': [5185, 1905, 801, 285]}\n",
      "ratio: 0.9446937284774136\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-16 00:58:08,007 - INFO: eval_beam_3 SPIDEr: 0.2316\n",
      "loading annotations into memory...\n",
      "0:00:00.003831\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8856, 'reflen': 9448, 'guess': [8856, 7832, 6808, 5784], 'correct': [5088, 1899, 809, 297]}\n",
      "ratio: 0.9373412362403749\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 00:58:39,834 - INFO: eval_beam_4 SPIDEr: 0.2353\n",
      "2021-12-16 00:58:45,961 - INFO: | epoch   5 |   100/ 3051 batches | lr 9.22e-06 | ms/batch 61.25 | loss-text 2.9669\n",
      "2021-12-16 00:58:51,933 - INFO: | epoch   5 |   200/ 3051 batches | lr 9.22e-06 | ms/batch 59.71 | loss-text 2.9209\n",
      "2021-12-16 00:58:57,827 - INFO: | epoch   5 |   300/ 3051 batches | lr 9.22e-06 | ms/batch 58.93 | loss-text 2.9421\n",
      "2021-12-16 00:59:03,779 - INFO: | epoch   5 |   400/ 3051 batches | lr 9.22e-06 | ms/batch 59.51 | loss-text 2.9259\n",
      "2021-12-16 00:59:09,808 - INFO: | epoch   5 |   500/ 3051 batches | lr 9.22e-06 | ms/batch 60.29 | loss-text 2.9286\n",
      "2021-12-16 00:59:15,792 - INFO: | epoch   5 |   600/ 3051 batches | lr 9.22e-06 | ms/batch 59.83 | loss-text 2.9394\n",
      "2021-12-16 00:59:21,695 - INFO: | epoch   5 |   700/ 3051 batches | lr 9.22e-06 | ms/batch 59.02 | loss-text 2.9176\n",
      "2021-12-16 00:59:27,720 - INFO: | epoch   5 |   800/ 3051 batches | lr 9.22e-06 | ms/batch 60.25 | loss-text 2.9635\n",
      "2021-12-16 00:59:33,700 - INFO: | epoch   5 |   900/ 3051 batches | lr 9.22e-06 | ms/batch 59.79 | loss-text 2.9194\n",
      "2021-12-16 00:59:39,716 - INFO: | epoch   5 |  1000/ 3051 batches | lr 9.22e-06 | ms/batch 60.16 | loss-text 2.9544\n",
      "2021-12-16 00:59:45,675 - INFO: | epoch   5 |  1100/ 3051 batches | lr 9.22e-06 | ms/batch 59.59 | loss-text 2.9189\n",
      "2021-12-16 00:59:51,659 - INFO: | epoch   5 |  1200/ 3051 batches | lr 9.22e-06 | ms/batch 59.83 | loss-text 2.9603\n",
      "2021-12-16 00:59:57,650 - INFO: | epoch   5 |  1300/ 3051 batches | lr 9.22e-06 | ms/batch 59.90 | loss-text 2.9271\n",
      "2021-12-16 01:00:03,608 - INFO: | epoch   5 |  1400/ 3051 batches | lr 9.22e-06 | ms/batch 59.57 | loss-text 2.9472\n",
      "2021-12-16 01:00:09,591 - INFO: | epoch   5 |  1500/ 3051 batches | lr 9.22e-06 | ms/batch 59.82 | loss-text 2.9049\n",
      "2021-12-16 01:00:15,595 - INFO: | epoch   5 |  1600/ 3051 batches | lr 9.22e-06 | ms/batch 60.03 | loss-text 2.9693\n",
      "2021-12-16 01:00:21,595 - INFO: | epoch   5 |  1700/ 3051 batches | lr 9.22e-06 | ms/batch 59.99 | loss-text 2.9214\n",
      "2021-12-16 01:00:27,606 - INFO: | epoch   5 |  1800/ 3051 batches | lr 9.22e-06 | ms/batch 60.11 | loss-text 2.9321\n",
      "2021-12-16 01:00:33,593 - INFO: | epoch   5 |  1900/ 3051 batches | lr 9.22e-06 | ms/batch 59.86 | loss-text 2.9202\n",
      "2021-12-16 01:00:39,570 - INFO: | epoch   5 |  2000/ 3051 batches | lr 9.22e-06 | ms/batch 59.77 | loss-text 2.9222\n",
      "2021-12-16 01:00:45,562 - INFO: | epoch   5 |  2100/ 3051 batches | lr 9.22e-06 | ms/batch 59.91 | loss-text 2.9162\n",
      "2021-12-16 01:00:51,530 - INFO: | epoch   5 |  2200/ 3051 batches | lr 9.22e-06 | ms/batch 59.67 | loss-text 2.9571\n",
      "2021-12-16 01:00:57,551 - INFO: | epoch   5 |  2300/ 3051 batches | lr 9.22e-06 | ms/batch 60.20 | loss-text 2.9316\n",
      "2021-12-16 01:01:03,540 - INFO: | epoch   5 |  2400/ 3051 batches | lr 9.22e-06 | ms/batch 59.88 | loss-text 2.9477\n",
      "2021-12-16 01:01:09,553 - INFO: | epoch   5 |  2500/ 3051 batches | lr 9.22e-06 | ms/batch 60.12 | loss-text 2.9301\n",
      "2021-12-16 01:01:15,542 - INFO: | epoch   5 |  2600/ 3051 batches | lr 9.22e-06 | ms/batch 59.89 | loss-text 2.9710\n",
      "2021-12-16 01:01:21,586 - INFO: | epoch   5 |  2700/ 3051 batches | lr 9.22e-06 | ms/batch 60.44 | loss-text 2.9588\n",
      "2021-12-16 01:01:27,578 - INFO: | epoch   5 |  2800/ 3051 batches | lr 9.22e-06 | ms/batch 59.92 | loss-text 2.8812\n",
      "2021-12-16 01:01:33,614 - INFO: | epoch   5 |  2900/ 3051 batches | lr 9.22e-06 | ms/batch 60.35 | loss-text 2.9105\n",
      "2021-12-16 01:01:39,646 - INFO: | epoch   5 |  3000/ 3051 batches | lr 9.22e-06 | ms/batch 60.32 | loss-text 2.9066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003843\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10067, 'reflen': 10231, 'guess': [10067, 9043, 8019, 6995], 'correct': [5439, 1837, 688, 213]}\n",
      "ratio: 0.9839702863844214\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.326\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.313\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.209\n",
      "2021-12-16 01:02:04,782 - INFO: eval_greddy SPIDEr: 0.2085\n",
      "loading annotations into memory...\n",
      "0:00:00.003876\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9298, 'reflen': 9735, 'guess': [9298, 8274, 7250, 6226], 'correct': [5320, 1971, 787, 260]}\n",
      "ratio: 0.9551104262967688\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 01:02:28,875 - INFO: eval_beam_2 SPIDEr: 0.2357\n",
      "loading annotations into memory...\n",
      "0:00:00.003715\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9033, 'reflen': 9568, 'guess': [9033, 8009, 6985, 5961], 'correct': [5209, 1944, 812, 292]}\n",
      "ratio: 0.9440844481604364\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 01:02:55,775 - INFO: eval_beam_3 SPIDEr: 0.2370\n",
      "loading annotations into memory...\n",
      "0:00:00.003911\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8841, 'reflen': 9449, 'guess': [8841, 7817, 6793, 5769], 'correct': [5130, 1918, 800, 279]}\n",
      "ratio: 0.9356545666207073\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 01:03:28,653 - INFO: eval_beam_4 SPIDEr: 0.2372\n",
      "2021-12-16 01:03:34,861 - INFO: | epoch   6 |   100/ 3051 batches | lr 9.04e-06 | ms/batch 62.05 | loss-text 2.9367\n",
      "2021-12-16 01:03:40,818 - INFO: | epoch   6 |   200/ 3051 batches | lr 9.04e-06 | ms/batch 59.56 | loss-text 2.9203\n",
      "2021-12-16 01:03:46,753 - INFO: | epoch   6 |   300/ 3051 batches | lr 9.04e-06 | ms/batch 59.34 | loss-text 2.9293\n",
      "2021-12-16 01:03:52,719 - INFO: | epoch   6 |   400/ 3051 batches | lr 9.04e-06 | ms/batch 59.66 | loss-text 2.9443\n",
      "2021-12-16 01:03:58,621 - INFO: | epoch   6 |   500/ 3051 batches | lr 9.04e-06 | ms/batch 59.01 | loss-text 2.9055\n",
      "2021-12-16 01:04:04,576 - INFO: | epoch   6 |   600/ 3051 batches | lr 9.04e-06 | ms/batch 59.54 | loss-text 2.8657\n",
      "2021-12-16 01:04:10,524 - INFO: | epoch   6 |   700/ 3051 batches | lr 9.04e-06 | ms/batch 59.48 | loss-text 2.9304\n",
      "2021-12-16 01:04:16,519 - INFO: | epoch   6 |   800/ 3051 batches | lr 9.04e-06 | ms/batch 59.94 | loss-text 2.9514\n",
      "2021-12-16 01:04:22,454 - INFO: | epoch   6 |   900/ 3051 batches | lr 9.04e-06 | ms/batch 59.34 | loss-text 2.9386\n",
      "2021-12-16 01:04:28,455 - INFO: | epoch   6 |  1000/ 3051 batches | lr 9.04e-06 | ms/batch 60.01 | loss-text 2.9452\n",
      "2021-12-16 01:04:34,427 - INFO: | epoch   6 |  1100/ 3051 batches | lr 9.04e-06 | ms/batch 59.71 | loss-text 2.8900\n",
      "2021-12-16 01:04:40,381 - INFO: | epoch   6 |  1200/ 3051 batches | lr 9.04e-06 | ms/batch 59.54 | loss-text 2.9268\n",
      "2021-12-16 01:04:46,351 - INFO: | epoch   6 |  1300/ 3051 batches | lr 9.04e-06 | ms/batch 59.69 | loss-text 2.9257\n",
      "2021-12-16 01:04:52,424 - INFO: | epoch   6 |  1400/ 3051 batches | lr 9.04e-06 | ms/batch 60.72 | loss-text 2.9350\n",
      "2021-12-16 01:04:58,433 - INFO: | epoch   6 |  1500/ 3051 batches | lr 9.04e-06 | ms/batch 60.09 | loss-text 2.9647\n",
      "2021-12-16 01:05:04,454 - INFO: | epoch   6 |  1600/ 3051 batches | lr 9.04e-06 | ms/batch 60.20 | loss-text 2.9159\n",
      "2021-12-16 01:05:10,466 - INFO: | epoch   6 |  1700/ 3051 batches | lr 9.04e-06 | ms/batch 60.11 | loss-text 2.9215\n",
      "2021-12-16 01:05:16,511 - INFO: | epoch   6 |  1800/ 3051 batches | lr 9.04e-06 | ms/batch 60.45 | loss-text 2.9352\n",
      "2021-12-16 01:05:22,498 - INFO: | epoch   6 |  1900/ 3051 batches | lr 9.04e-06 | ms/batch 59.87 | loss-text 2.9666\n",
      "2021-12-16 01:05:28,545 - INFO: | epoch   6 |  2000/ 3051 batches | lr 9.04e-06 | ms/batch 60.45 | loss-text 2.9396\n",
      "2021-12-16 01:05:34,545 - INFO: | epoch   6 |  2100/ 3051 batches | lr 9.04e-06 | ms/batch 60.00 | loss-text 2.9290\n",
      "2021-12-16 01:05:40,577 - INFO: | epoch   6 |  2200/ 3051 batches | lr 9.04e-06 | ms/batch 60.31 | loss-text 2.9197\n",
      "2021-12-16 01:05:46,588 - INFO: | epoch   6 |  2300/ 3051 batches | lr 9.04e-06 | ms/batch 60.11 | loss-text 2.9216\n",
      "2021-12-16 01:05:52,587 - INFO: | epoch   6 |  2400/ 3051 batches | lr 9.04e-06 | ms/batch 59.98 | loss-text 2.9248\n",
      "2021-12-16 01:05:58,574 - INFO: | epoch   6 |  2500/ 3051 batches | lr 9.04e-06 | ms/batch 59.87 | loss-text 2.9135\n",
      "2021-12-16 01:06:04,566 - INFO: | epoch   6 |  2600/ 3051 batches | lr 9.04e-06 | ms/batch 59.91 | loss-text 2.9141\n",
      "2021-12-16 01:06:10,550 - INFO: | epoch   6 |  2700/ 3051 batches | lr 9.04e-06 | ms/batch 59.84 | loss-text 2.9252\n",
      "2021-12-16 01:06:16,554 - INFO: | epoch   6 |  2800/ 3051 batches | lr 9.04e-06 | ms/batch 60.03 | loss-text 2.9537\n",
      "2021-12-16 01:06:22,511 - INFO: | epoch   6 |  2900/ 3051 batches | lr 9.04e-06 | ms/batch 59.57 | loss-text 2.9352\n",
      "2021-12-16 01:06:28,526 - INFO: | epoch   6 |  3000/ 3051 batches | lr 9.04e-06 | ms/batch 60.14 | loss-text 2.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003949\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9997, 'reflen': 10192, 'guess': [9997, 8973, 7949, 6925], 'correct': [5391, 1831, 698, 223]}\n",
      "ratio: 0.9808673469386793\n",
      "Bleu_1: 0.529\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.318\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.212\n",
      "2021-12-16 01:06:55,067 - INFO: eval_greddy SPIDEr: 0.2115\n",
      "loading annotations into memory...\n",
      "0:00:00.003879\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9268, 'reflen': 9701, 'guess': [9268, 8244, 7220, 6196], 'correct': [5301, 1936, 767, 246]}\n",
      "ratio: 0.9553654262446185\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 01:07:19,816 - INFO: eval_beam_2 SPIDEr: 0.2375\n",
      "loading annotations into memory...\n",
      "0:00:00.003917\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9038, 'reflen': 9549, 'guess': [9038, 8014, 6990, 5966], 'correct': [5189, 1938, 798, 276]}\n",
      "ratio: 0.9464865430934185\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 01:07:47,036 - INFO: eval_beam_3 SPIDEr: 0.2383\n",
      "loading annotations into memory...\n",
      "0:00:00.004016\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8822, 'reflen': 9432, 'guess': [8822, 7798, 6774, 5750], 'correct': [5090, 1914, 796, 277]}\n",
      "ratio: 0.9353265479218685\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 01:08:19,945 - INFO: eval_beam_4 SPIDEr: 0.2381\n",
      "2021-12-16 01:08:26,126 - INFO: | epoch   7 |   100/ 3051 batches | lr 8.86e-06 | ms/batch 61.78 | loss-text 2.9279\n",
      "2021-12-16 01:08:32,080 - INFO: | epoch   7 |   200/ 3051 batches | lr 8.86e-06 | ms/batch 59.53 | loss-text 2.9432\n",
      "2021-12-16 01:08:38,006 - INFO: | epoch   7 |   300/ 3051 batches | lr 8.86e-06 | ms/batch 59.25 | loss-text 2.9410\n",
      "2021-12-16 01:08:43,921 - INFO: | epoch   7 |   400/ 3051 batches | lr 8.86e-06 | ms/batch 59.14 | loss-text 2.9523\n",
      "2021-12-16 01:08:49,887 - INFO: | epoch   7 |   500/ 3051 batches | lr 8.86e-06 | ms/batch 59.65 | loss-text 2.9204\n",
      "2021-12-16 01:08:55,824 - INFO: | epoch   7 |   600/ 3051 batches | lr 8.86e-06 | ms/batch 59.37 | loss-text 2.9389\n",
      "2021-12-16 01:09:01,842 - INFO: | epoch   7 |   700/ 3051 batches | lr 8.86e-06 | ms/batch 60.17 | loss-text 2.8824\n",
      "2021-12-16 01:09:07,797 - INFO: | epoch   7 |   800/ 3051 batches | lr 8.86e-06 | ms/batch 59.54 | loss-text 2.9405\n",
      "2021-12-16 01:09:13,779 - INFO: | epoch   7 |   900/ 3051 batches | lr 8.86e-06 | ms/batch 59.81 | loss-text 2.9111\n",
      "2021-12-16 01:09:19,728 - INFO: | epoch   7 |  1000/ 3051 batches | lr 8.86e-06 | ms/batch 59.49 | loss-text 2.9396\n",
      "2021-12-16 01:09:25,718 - INFO: | epoch   7 |  1100/ 3051 batches | lr 8.86e-06 | ms/batch 59.89 | loss-text 2.9231\n",
      "2021-12-16 01:09:31,705 - INFO: | epoch   7 |  1200/ 3051 batches | lr 8.86e-06 | ms/batch 59.87 | loss-text 2.8915\n",
      "2021-12-16 01:09:37,697 - INFO: | epoch   7 |  1300/ 3051 batches | lr 8.86e-06 | ms/batch 59.91 | loss-text 2.9185\n",
      "2021-12-16 01:09:43,741 - INFO: | epoch   7 |  1400/ 3051 batches | lr 8.86e-06 | ms/batch 60.43 | loss-text 2.9391\n",
      "2021-12-16 01:09:49,726 - INFO: | epoch   7 |  1500/ 3051 batches | lr 8.86e-06 | ms/batch 59.85 | loss-text 2.9099\n",
      "2021-12-16 01:09:55,685 - INFO: | epoch   7 |  1600/ 3051 batches | lr 8.86e-06 | ms/batch 59.59 | loss-text 2.9256\n",
      "2021-12-16 01:10:01,715 - INFO: | epoch   7 |  1700/ 3051 batches | lr 8.86e-06 | ms/batch 60.29 | loss-text 2.9503\n",
      "2021-12-16 01:10:07,723 - INFO: | epoch   7 |  1800/ 3051 batches | lr 8.86e-06 | ms/batch 60.08 | loss-text 2.9105\n",
      "2021-12-16 01:10:13,753 - INFO: | epoch   7 |  1900/ 3051 batches | lr 8.86e-06 | ms/batch 60.29 | loss-text 2.9574\n",
      "2021-12-16 01:10:19,797 - INFO: | epoch   7 |  2000/ 3051 batches | lr 8.86e-06 | ms/batch 60.43 | loss-text 2.9256\n",
      "2021-12-16 01:10:25,744 - INFO: | epoch   7 |  2100/ 3051 batches | lr 8.86e-06 | ms/batch 59.47 | loss-text 2.9558\n",
      "2021-12-16 01:10:31,718 - INFO: | epoch   7 |  2200/ 3051 batches | lr 8.86e-06 | ms/batch 59.73 | loss-text 2.9209\n",
      "2021-12-16 01:10:37,741 - INFO: | epoch   7 |  2300/ 3051 batches | lr 8.86e-06 | ms/batch 60.23 | loss-text 2.9150\n",
      "2021-12-16 01:10:43,771 - INFO: | epoch   7 |  2400/ 3051 batches | lr 8.86e-06 | ms/batch 60.29 | loss-text 2.9239\n",
      "2021-12-16 01:10:49,779 - INFO: | epoch   7 |  2500/ 3051 batches | lr 8.86e-06 | ms/batch 60.08 | loss-text 2.9091\n",
      "2021-12-16 01:10:55,793 - INFO: | epoch   7 |  2600/ 3051 batches | lr 8.86e-06 | ms/batch 60.13 | loss-text 2.9312\n",
      "2021-12-16 01:11:01,739 - INFO: | epoch   7 |  2700/ 3051 batches | lr 8.86e-06 | ms/batch 59.45 | loss-text 2.8815\n",
      "2021-12-16 01:11:07,737 - INFO: | epoch   7 |  2800/ 3051 batches | lr 8.86e-06 | ms/batch 59.98 | loss-text 2.9279\n",
      "2021-12-16 01:11:13,759 - INFO: | epoch   7 |  2900/ 3051 batches | lr 8.86e-06 | ms/batch 60.21 | loss-text 2.9147\n",
      "2021-12-16 01:11:19,732 - INFO: | epoch   7 |  3000/ 3051 batches | lr 8.86e-06 | ms/batch 59.72 | loss-text 2.8816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003959\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9971, 'reflen': 10191, 'guess': [9971, 8947, 7923, 6899], 'correct': [5406, 1819, 672, 213]}\n",
      "ratio: 0.9784123246000413\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.315\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.210\n",
      "2021-12-16 01:11:44,174 - INFO: eval_greddy SPIDEr: 0.2099\n",
      "loading annotations into memory...\n",
      "0:00:00.003933\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9215, 'reflen': 9668, 'guess': [9215, 8191, 7167, 6143], 'correct': [5261, 1917, 760, 249]}\n",
      "ratio: 0.953144393876608\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 01:12:09,961 - INFO: eval_beam_2 SPIDEr: 0.2373\n",
      "loading annotations into memory...\n",
      "0:00:00.003662\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9006, 'reflen': 9541, 'guess': [9006, 7982, 6958, 5934], 'correct': [5196, 1905, 783, 267]}\n",
      "ratio: 0.9439262131851017\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 01:12:34,648 - INFO: eval_beam_3 SPIDEr: 0.2365\n",
      "loading annotations into memory...\n",
      "0:00:00.003948\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8817, 'reflen': 9431, 'guess': [8817, 7793, 6769, 5745], 'correct': [5080, 1850, 772, 270]}\n",
      "ratio: 0.9348955572048632\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-16 01:13:06,811 - INFO: eval_beam_4 SPIDEr: 0.2323\n",
      "2021-12-16 01:13:12,940 - INFO: | epoch   8 |   100/ 3051 batches | lr 8.68e-06 | ms/batch 61.26 | loss-text 2.8876\n",
      "2021-12-16 01:13:18,891 - INFO: | epoch   8 |   200/ 3051 batches | lr 8.68e-06 | ms/batch 59.49 | loss-text 2.9282\n",
      "2021-12-16 01:13:24,848 - INFO: | epoch   8 |   300/ 3051 batches | lr 8.68e-06 | ms/batch 59.57 | loss-text 2.9052\n",
      "2021-12-16 01:13:30,772 - INFO: | epoch   8 |   400/ 3051 batches | lr 8.68e-06 | ms/batch 59.23 | loss-text 2.8998\n",
      "2021-12-16 01:13:36,758 - INFO: | epoch   8 |   500/ 3051 batches | lr 8.68e-06 | ms/batch 59.84 | loss-text 2.8839\n",
      "2021-12-16 01:13:42,697 - INFO: | epoch   8 |   600/ 3051 batches | lr 8.68e-06 | ms/batch 59.39 | loss-text 2.9290\n",
      "2021-12-16 01:13:48,660 - INFO: | epoch   8 |   700/ 3051 batches | lr 8.68e-06 | ms/batch 59.62 | loss-text 2.9160\n",
      "2021-12-16 01:13:54,703 - INFO: | epoch   8 |   800/ 3051 batches | lr 8.68e-06 | ms/batch 60.42 | loss-text 2.9136\n",
      "2021-12-16 01:14:00,688 - INFO: | epoch   8 |   900/ 3051 batches | lr 8.68e-06 | ms/batch 59.85 | loss-text 2.9136\n",
      "2021-12-16 01:14:06,678 - INFO: | epoch   8 |  1000/ 3051 batches | lr 8.68e-06 | ms/batch 59.90 | loss-text 2.9163\n",
      "2021-12-16 01:14:12,670 - INFO: | epoch   8 |  1100/ 3051 batches | lr 8.68e-06 | ms/batch 59.91 | loss-text 2.9209\n",
      "2021-12-16 01:14:18,679 - INFO: | epoch   8 |  1200/ 3051 batches | lr 8.68e-06 | ms/batch 60.08 | loss-text 2.9189\n",
      "2021-12-16 01:14:24,651 - INFO: | epoch   8 |  1300/ 3051 batches | lr 8.68e-06 | ms/batch 59.72 | loss-text 2.9446\n",
      "2021-12-16 01:14:30,625 - INFO: | epoch   8 |  1400/ 3051 batches | lr 8.68e-06 | ms/batch 59.73 | loss-text 2.9025\n",
      "2021-12-16 01:14:36,625 - INFO: | epoch   8 |  1500/ 3051 batches | lr 8.68e-06 | ms/batch 59.99 | loss-text 2.9464\n",
      "2021-12-16 01:14:42,589 - INFO: | epoch   8 |  1600/ 3051 batches | lr 8.68e-06 | ms/batch 59.64 | loss-text 2.8921\n",
      "2021-12-16 01:14:48,593 - INFO: | epoch   8 |  1700/ 3051 batches | lr 8.68e-06 | ms/batch 60.03 | loss-text 2.9175\n",
      "2021-12-16 01:14:54,551 - INFO: | epoch   8 |  1800/ 3051 batches | lr 8.68e-06 | ms/batch 59.57 | loss-text 2.9534\n",
      "2021-12-16 01:15:00,534 - INFO: | epoch   8 |  1900/ 3051 batches | lr 8.68e-06 | ms/batch 59.83 | loss-text 2.9551\n",
      "2021-12-16 01:15:06,565 - INFO: | epoch   8 |  2000/ 3051 batches | lr 8.68e-06 | ms/batch 60.30 | loss-text 2.9078\n",
      "2021-12-16 01:15:12,533 - INFO: | epoch   8 |  2100/ 3051 batches | lr 8.68e-06 | ms/batch 59.68 | loss-text 2.9302\n",
      "2021-12-16 01:15:18,488 - INFO: | epoch   8 |  2200/ 3051 batches | lr 8.68e-06 | ms/batch 59.54 | loss-text 2.9310\n",
      "2021-12-16 01:15:24,493 - INFO: | epoch   8 |  2300/ 3051 batches | lr 8.68e-06 | ms/batch 60.05 | loss-text 2.9238\n",
      "2021-12-16 01:15:30,548 - INFO: | epoch   8 |  2400/ 3051 batches | lr 8.68e-06 | ms/batch 60.54 | loss-text 2.9183\n",
      "2021-12-16 01:15:36,561 - INFO: | epoch   8 |  2500/ 3051 batches | lr 8.68e-06 | ms/batch 60.12 | loss-text 2.9539\n",
      "2021-12-16 01:15:42,554 - INFO: | epoch   8 |  2600/ 3051 batches | lr 8.68e-06 | ms/batch 59.93 | loss-text 2.9105\n",
      "2021-12-16 01:15:48,577 - INFO: | epoch   8 |  2700/ 3051 batches | lr 8.68e-06 | ms/batch 60.22 | loss-text 2.8960\n",
      "2021-12-16 01:15:54,565 - INFO: | epoch   8 |  2800/ 3051 batches | lr 8.68e-06 | ms/batch 59.87 | loss-text 2.9168\n",
      "2021-12-16 01:16:00,606 - INFO: | epoch   8 |  2900/ 3051 batches | lr 8.68e-06 | ms/batch 60.40 | loss-text 2.9027\n",
      "2021-12-16 01:16:06,641 - INFO: | epoch   8 |  3000/ 3051 batches | lr 8.68e-06 | ms/batch 60.35 | loss-text 2.9332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003926\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9901, 'reflen': 10129, 'guess': [9901, 8877, 7853, 6829], 'correct': [5412, 1838, 682, 219]}\n",
      "ratio: 0.9774903741730696\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.319\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.212\n",
      "2021-12-16 01:16:34,536 - INFO: eval_greddy SPIDEr: 0.2120\n",
      "loading annotations into memory...\n",
      "0:00:00.003816\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9298, 'reflen': 9705, 'guess': [9298, 8274, 7250, 6226], 'correct': [5287, 1906, 757, 252]}\n",
      "ratio: 0.9580628541987678\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.355\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-16 01:17:00,218 - INFO: eval_beam_2 SPIDEr: 0.2305\n",
      "loading annotations into memory...\n",
      "0:00:00.003954\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9032, 'reflen': 9546, 'guess': [9032, 8008, 6984, 5960], 'correct': [5204, 1916, 797, 272]}\n",
      "ratio: 0.9461554577832656\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 01:17:28,383 - INFO: eval_beam_3 SPIDEr: 0.2349\n",
      "loading annotations into memory...\n",
      "0:00:00.003909\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8827, 'reflen': 9427, 'guess': [8827, 7803, 6779, 5755], 'correct': [5059, 1877, 782, 265]}\n",
      "ratio: 0.9363530285349595\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-16 01:17:58,095 - INFO: eval_beam_4 SPIDEr: 0.2315\n",
      "2021-12-16 01:18:04,260 - INFO: | epoch   9 |   100/ 3051 batches | lr 8.51e-06 | ms/batch 61.62 | loss-text 2.9253\n",
      "2021-12-16 01:18:10,197 - INFO: | epoch   9 |   200/ 3051 batches | lr 8.51e-06 | ms/batch 59.36 | loss-text 2.9340\n",
      "2021-12-16 01:18:16,155 - INFO: | epoch   9 |   300/ 3051 batches | lr 8.51e-06 | ms/batch 59.58 | loss-text 2.9207\n",
      "2021-12-16 01:18:22,114 - INFO: | epoch   9 |   400/ 3051 batches | lr 8.51e-06 | ms/batch 59.58 | loss-text 2.9090\n",
      "2021-12-16 01:18:28,110 - INFO: | epoch   9 |   500/ 3051 batches | lr 8.51e-06 | ms/batch 59.95 | loss-text 2.9367\n",
      "2021-12-16 01:18:34,058 - INFO: | epoch   9 |   600/ 3051 batches | lr 8.51e-06 | ms/batch 59.47 | loss-text 2.8803\n",
      "2021-12-16 01:18:40,106 - INFO: | epoch   9 |   700/ 3051 batches | lr 8.51e-06 | ms/batch 60.47 | loss-text 2.8654\n",
      "2021-12-16 01:18:46,123 - INFO: | epoch   9 |   800/ 3051 batches | lr 8.51e-06 | ms/batch 60.16 | loss-text 2.9137\n",
      "2021-12-16 01:18:52,097 - INFO: | epoch   9 |   900/ 3051 batches | lr 8.51e-06 | ms/batch 59.74 | loss-text 2.9457\n",
      "2021-12-16 01:18:58,053 - INFO: | epoch   9 |  1000/ 3051 batches | lr 8.51e-06 | ms/batch 59.55 | loss-text 2.9552\n",
      "2021-12-16 01:19:04,076 - INFO: | epoch   9 |  1100/ 3051 batches | lr 8.51e-06 | ms/batch 60.23 | loss-text 2.9161\n",
      "2021-12-16 01:19:10,049 - INFO: | epoch   9 |  1200/ 3051 batches | lr 8.51e-06 | ms/batch 59.73 | loss-text 2.8853\n",
      "2021-12-16 01:19:16,031 - INFO: | epoch   9 |  1300/ 3051 batches | lr 8.51e-06 | ms/batch 59.81 | loss-text 2.9159\n",
      "2021-12-16 01:19:22,052 - INFO: | epoch   9 |  1400/ 3051 batches | lr 8.51e-06 | ms/batch 60.21 | loss-text 2.9383\n",
      "2021-12-16 01:19:28,075 - INFO: | epoch   9 |  1500/ 3051 batches | lr 8.51e-06 | ms/batch 60.22 | loss-text 2.9419\n",
      "2021-12-16 01:19:34,126 - INFO: | epoch   9 |  1600/ 3051 batches | lr 8.51e-06 | ms/batch 60.50 | loss-text 2.9049\n",
      "2021-12-16 01:19:40,167 - INFO: | epoch   9 |  1700/ 3051 batches | lr 8.51e-06 | ms/batch 60.41 | loss-text 2.9017\n",
      "2021-12-16 01:19:46,164 - INFO: | epoch   9 |  1800/ 3051 batches | lr 8.51e-06 | ms/batch 59.96 | loss-text 2.9684\n",
      "2021-12-16 01:19:52,154 - INFO: | epoch   9 |  1900/ 3051 batches | lr 8.51e-06 | ms/batch 59.90 | loss-text 2.9206\n",
      "2021-12-16 01:19:58,105 - INFO: | epoch   9 |  2000/ 3051 batches | lr 8.51e-06 | ms/batch 59.50 | loss-text 2.9225\n",
      "2021-12-16 01:20:04,100 - INFO: | epoch   9 |  2100/ 3051 batches | lr 8.51e-06 | ms/batch 59.94 | loss-text 2.9270\n",
      "2021-12-16 01:20:10,109 - INFO: | epoch   9 |  2200/ 3051 batches | lr 8.51e-06 | ms/batch 60.08 | loss-text 2.9105\n",
      "2021-12-16 01:20:16,100 - INFO: | epoch   9 |  2300/ 3051 batches | lr 8.51e-06 | ms/batch 59.91 | loss-text 2.9061\n",
      "2021-12-16 01:20:22,103 - INFO: | epoch   9 |  2400/ 3051 batches | lr 8.51e-06 | ms/batch 60.02 | loss-text 2.9095\n",
      "2021-12-16 01:20:28,080 - INFO: | epoch   9 |  2500/ 3051 batches | lr 8.51e-06 | ms/batch 59.76 | loss-text 2.9019\n",
      "2021-12-16 01:20:34,113 - INFO: | epoch   9 |  2600/ 3051 batches | lr 8.51e-06 | ms/batch 60.32 | loss-text 2.9329\n",
      "2021-12-16 01:20:40,090 - INFO: | epoch   9 |  2700/ 3051 batches | lr 8.51e-06 | ms/batch 59.77 | loss-text 2.9016\n",
      "2021-12-16 01:20:46,090 - INFO: | epoch   9 |  2800/ 3051 batches | lr 8.51e-06 | ms/batch 59.99 | loss-text 2.8825\n",
      "2021-12-16 01:20:52,088 - INFO: | epoch   9 |  2900/ 3051 batches | lr 8.51e-06 | ms/batch 59.97 | loss-text 2.8936\n",
      "2021-12-16 01:20:58,089 - INFO: | epoch   9 |  3000/ 3051 batches | lr 8.51e-06 | ms/batch 60.00 | loss-text 2.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004098\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10011, 'reflen': 10164, 'guess': [10011, 8987, 7963, 6939], 'correct': [5413, 1840, 688, 222]}\n",
      "ratio: 0.9849468713104107\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.316\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.211\n",
      "2021-12-16 01:21:23,899 - INFO: eval_greddy SPIDEr: 0.2108\n",
      "loading annotations into memory...\n",
      "0:00:00.004026\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9293, 'reflen': 9721, 'guess': [9293, 8269, 7245, 6221], 'correct': [5293, 1956, 769, 254]}\n",
      "ratio: 0.9559716078591753\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 01:21:45,235 - INFO: eval_beam_2 SPIDEr: 0.2367\n",
      "loading annotations into memory...\n",
      "0:00:00.003708\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9039, 'reflen': 9564, 'guess': [9039, 8015, 6991, 5967], 'correct': [5221, 1950, 812, 287]}\n",
      "ratio: 0.9451066499371659\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 01:22:13,449 - INFO: eval_beam_3 SPIDEr: 0.2367\n",
      "loading annotations into memory...\n",
      "0:00:00.003968\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8818, 'reflen': 9426, 'guess': [8818, 7794, 6770, 5746], 'correct': [5087, 1882, 778, 275]}\n",
      "ratio: 0.9354975599404906\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.360\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-16 01:22:41,329 - INFO: eval_beam_4 SPIDEr: 0.2308\n",
      "2021-12-16 01:22:47,449 - INFO: | epoch  10 |   100/ 3051 batches | lr 8.34e-06 | ms/batch 61.18 | loss-text 2.9133\n",
      "2021-12-16 01:22:53,407 - INFO: | epoch  10 |   200/ 3051 batches | lr 8.34e-06 | ms/batch 59.56 | loss-text 2.9177\n",
      "2021-12-16 01:22:59,377 - INFO: | epoch  10 |   300/ 3051 batches | lr 8.34e-06 | ms/batch 59.69 | loss-text 2.9165\n",
      "2021-12-16 01:23:05,327 - INFO: | epoch  10 |   400/ 3051 batches | lr 8.34e-06 | ms/batch 59.50 | loss-text 2.8992\n",
      "2021-12-16 01:23:11,322 - INFO: | epoch  10 |   500/ 3051 batches | lr 8.34e-06 | ms/batch 59.94 | loss-text 2.9259\n",
      "2021-12-16 01:23:17,276 - INFO: | epoch  10 |   600/ 3051 batches | lr 8.34e-06 | ms/batch 59.53 | loss-text 2.9074\n",
      "2021-12-16 01:23:23,253 - INFO: | epoch  10 |   700/ 3051 batches | lr 8.34e-06 | ms/batch 59.77 | loss-text 2.8749\n",
      "2021-12-16 01:23:29,317 - INFO: | epoch  10 |   800/ 3051 batches | lr 8.34e-06 | ms/batch 60.64 | loss-text 2.9636\n",
      "2021-12-16 01:23:35,309 - INFO: | epoch  10 |   900/ 3051 batches | lr 8.34e-06 | ms/batch 59.92 | loss-text 2.8957\n",
      "2021-12-16 01:23:41,318 - INFO: | epoch  10 |  1000/ 3051 batches | lr 8.34e-06 | ms/batch 60.08 | loss-text 2.8766\n",
      "2021-12-16 01:23:47,285 - INFO: | epoch  10 |  1100/ 3051 batches | lr 8.34e-06 | ms/batch 59.66 | loss-text 2.9046\n",
      "2021-12-16 01:23:53,226 - INFO: | epoch  10 |  1200/ 3051 batches | lr 8.34e-06 | ms/batch 59.40 | loss-text 2.8924\n",
      "2021-12-16 01:23:59,240 - INFO: | epoch  10 |  1300/ 3051 batches | lr 8.34e-06 | ms/batch 60.13 | loss-text 2.9414\n",
      "2021-12-16 01:24:05,216 - INFO: | epoch  10 |  1400/ 3051 batches | lr 8.34e-06 | ms/batch 59.76 | loss-text 2.8881\n",
      "2021-12-16 01:24:11,188 - INFO: | epoch  10 |  1500/ 3051 batches | lr 8.34e-06 | ms/batch 59.71 | loss-text 2.9061\n",
      "2021-12-16 01:24:17,229 - INFO: | epoch  10 |  1600/ 3051 batches | lr 8.34e-06 | ms/batch 60.40 | loss-text 2.9053\n",
      "2021-12-16 01:24:23,236 - INFO: | epoch  10 |  1700/ 3051 batches | lr 8.34e-06 | ms/batch 60.06 | loss-text 2.9430\n",
      "2021-12-16 01:24:29,248 - INFO: | epoch  10 |  1800/ 3051 batches | lr 8.34e-06 | ms/batch 60.11 | loss-text 2.9230\n",
      "2021-12-16 01:24:35,265 - INFO: | epoch  10 |  1900/ 3051 batches | lr 8.34e-06 | ms/batch 60.17 | loss-text 2.9218\n",
      "2021-12-16 01:24:41,279 - INFO: | epoch  10 |  2000/ 3051 batches | lr 8.34e-06 | ms/batch 60.13 | loss-text 2.9843\n",
      "2021-12-16 01:24:47,277 - INFO: | epoch  10 |  2100/ 3051 batches | lr 8.34e-06 | ms/batch 59.97 | loss-text 2.9133\n",
      "2021-12-16 01:24:53,270 - INFO: | epoch  10 |  2200/ 3051 batches | lr 8.34e-06 | ms/batch 59.93 | loss-text 2.9349\n",
      "2021-12-16 01:24:59,309 - INFO: | epoch  10 |  2300/ 3051 batches | lr 8.34e-06 | ms/batch 60.38 | loss-text 2.9130\n",
      "2021-12-16 01:25:05,303 - INFO: | epoch  10 |  2400/ 3051 batches | lr 8.34e-06 | ms/batch 59.93 | loss-text 2.8906\n",
      "2021-12-16 01:25:11,289 - INFO: | epoch  10 |  2500/ 3051 batches | lr 8.34e-06 | ms/batch 59.85 | loss-text 2.8943\n",
      "2021-12-16 01:25:17,291 - INFO: | epoch  10 |  2600/ 3051 batches | lr 8.34e-06 | ms/batch 60.02 | loss-text 2.9090\n",
      "2021-12-16 01:25:23,277 - INFO: | epoch  10 |  2700/ 3051 batches | lr 8.34e-06 | ms/batch 59.85 | loss-text 2.9244\n",
      "2021-12-16 01:25:29,274 - INFO: | epoch  10 |  2800/ 3051 batches | lr 8.34e-06 | ms/batch 59.96 | loss-text 2.9091\n",
      "2021-12-16 01:25:35,285 - INFO: | epoch  10 |  2900/ 3051 batches | lr 8.34e-06 | ms/batch 60.11 | loss-text 2.9255\n",
      "2021-12-16 01:25:41,231 - INFO: | epoch  10 |  3000/ 3051 batches | lr 8.34e-06 | ms/batch 59.45 | loss-text 2.9477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003950\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10026, 'reflen': 10215, 'guess': [10026, 9002, 7978, 6954], 'correct': [5447, 1867, 687, 214]}\n",
      "ratio: 0.981497797356732\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.322\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2021-12-16 01:26:09,906 - INFO: eval_greddy SPIDEr: 0.2139\n",
      "loading annotations into memory...\n",
      "0:00:00.003769\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9338, 'reflen': 9732, 'guess': [9338, 8314, 7290, 6266], 'correct': [5313, 1904, 737, 240]}\n",
      "ratio: 0.9595150020549774\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.356\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-16 01:26:34,204 - INFO: eval_beam_2 SPIDEr: 0.2313\n",
      "loading annotations into memory...\n",
      "0:00:00.003843\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9068, 'reflen': 9591, 'guess': [9068, 8044, 7020, 5996], 'correct': [5168, 1886, 783, 278]}\n",
      "ratio: 0.945469711187473\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-16 01:27:01,412 - INFO: eval_beam_3 SPIDEr: 0.2334\n",
      "loading annotations into memory...\n",
      "0:00:00.003921\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8838, 'reflen': 9438, 'guess': [8838, 7814, 6790, 5766], 'correct': [5097, 1896, 789, 278]}\n",
      "ratio: 0.9364272091543826\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 01:27:29,969 - INFO: eval_beam_4 SPIDEr: 0.2357\n",
      "2021-12-16 01:27:36,101 - INFO: | epoch  11 |   100/ 3051 batches | lr 8.17e-06 | ms/batch 61.29 | loss-text 2.9053\n",
      "2021-12-16 01:27:42,028 - INFO: | epoch  11 |   200/ 3051 batches | lr 8.17e-06 | ms/batch 59.26 | loss-text 2.9261\n",
      "2021-12-16 01:27:48,007 - INFO: | epoch  11 |   300/ 3051 batches | lr 8.17e-06 | ms/batch 59.79 | loss-text 2.9211\n",
      "2021-12-16 01:27:53,940 - INFO: | epoch  11 |   400/ 3051 batches | lr 8.17e-06 | ms/batch 59.32 | loss-text 2.8667\n",
      "2021-12-16 01:27:59,910 - INFO: | epoch  11 |   500/ 3051 batches | lr 8.17e-06 | ms/batch 59.70 | loss-text 2.8736\n",
      "2021-12-16 01:28:05,886 - INFO: | epoch  11 |   600/ 3051 batches | lr 8.17e-06 | ms/batch 59.75 | loss-text 2.9180\n",
      "2021-12-16 01:28:11,866 - INFO: | epoch  11 |   700/ 3051 batches | lr 8.17e-06 | ms/batch 59.79 | loss-text 2.9324\n",
      "2021-12-16 01:28:17,792 - INFO: | epoch  11 |   800/ 3051 batches | lr 8.17e-06 | ms/batch 59.26 | loss-text 2.9345\n",
      "2021-12-16 01:28:23,865 - INFO: | epoch  11 |   900/ 3051 batches | lr 8.17e-06 | ms/batch 60.72 | loss-text 2.9123\n",
      "2021-12-16 01:28:29,881 - INFO: | epoch  11 |  1000/ 3051 batches | lr 8.17e-06 | ms/batch 60.15 | loss-text 2.9175\n",
      "2021-12-16 01:28:35,791 - INFO: | epoch  11 |  1100/ 3051 batches | lr 8.17e-06 | ms/batch 59.09 | loss-text 2.8954\n",
      "2021-12-16 01:28:41,746 - INFO: | epoch  11 |  1200/ 3051 batches | lr 8.17e-06 | ms/batch 59.55 | loss-text 2.9126\n",
      "2021-12-16 01:28:47,688 - INFO: | epoch  11 |  1300/ 3051 batches | lr 8.17e-06 | ms/batch 59.41 | loss-text 2.9039\n",
      "2021-12-16 01:28:53,653 - INFO: | epoch  11 |  1400/ 3051 batches | lr 8.17e-06 | ms/batch 59.64 | loss-text 2.8843\n",
      "2021-12-16 01:28:59,609 - INFO: | epoch  11 |  1500/ 3051 batches | lr 8.17e-06 | ms/batch 59.56 | loss-text 2.9099\n",
      "2021-12-16 01:29:05,571 - INFO: | epoch  11 |  1600/ 3051 batches | lr 8.17e-06 | ms/batch 59.61 | loss-text 2.8963\n",
      "2021-12-16 01:29:11,625 - INFO: | epoch  11 |  1700/ 3051 batches | lr 8.17e-06 | ms/batch 60.54 | loss-text 2.9242\n",
      "2021-12-16 01:29:17,621 - INFO: | epoch  11 |  1800/ 3051 batches | lr 8.17e-06 | ms/batch 59.95 | loss-text 2.9189\n",
      "2021-12-16 01:29:23,637 - INFO: | epoch  11 |  1900/ 3051 batches | lr 8.17e-06 | ms/batch 60.15 | loss-text 2.9169\n",
      "2021-12-16 01:29:29,617 - INFO: | epoch  11 |  2000/ 3051 batches | lr 8.17e-06 | ms/batch 59.79 | loss-text 2.9456\n",
      "2021-12-16 01:29:35,588 - INFO: | epoch  11 |  2100/ 3051 batches | lr 8.17e-06 | ms/batch 59.71 | loss-text 2.9051\n",
      "2021-12-16 01:29:41,574 - INFO: | epoch  11 |  2200/ 3051 batches | lr 8.17e-06 | ms/batch 59.86 | loss-text 2.9121\n",
      "2021-12-16 01:29:47,588 - INFO: | epoch  11 |  2300/ 3051 batches | lr 8.17e-06 | ms/batch 60.13 | loss-text 2.8708\n",
      "2021-12-16 01:29:53,548 - INFO: | epoch  11 |  2400/ 3051 batches | lr 8.17e-06 | ms/batch 59.59 | loss-text 2.8834\n",
      "2021-12-16 01:29:59,605 - INFO: | epoch  11 |  2500/ 3051 batches | lr 8.17e-06 | ms/batch 60.56 | loss-text 2.9462\n",
      "2021-12-16 01:30:05,637 - INFO: | epoch  11 |  2600/ 3051 batches | lr 8.17e-06 | ms/batch 60.31 | loss-text 2.9456\n",
      "2021-12-16 01:30:11,630 - INFO: | epoch  11 |  2700/ 3051 batches | lr 8.17e-06 | ms/batch 59.93 | loss-text 2.9223\n",
      "2021-12-16 01:30:17,651 - INFO: | epoch  11 |  2800/ 3051 batches | lr 8.17e-06 | ms/batch 60.20 | loss-text 2.9050\n",
      "2021-12-16 01:30:23,703 - INFO: | epoch  11 |  2900/ 3051 batches | lr 8.17e-06 | ms/batch 60.50 | loss-text 2.9124\n",
      "2021-12-16 01:30:29,780 - INFO: | epoch  11 |  3000/ 3051 batches | lr 8.17e-06 | ms/batch 60.76 | loss-text 2.8868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003996\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10030, 'reflen': 10201, 'guess': [10030, 9006, 7982, 6958], 'correct': [5458, 1847, 673, 204]}\n",
      "ratio: 0.9832369375550453\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.317\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.210\n",
      "2021-12-16 01:30:53,854 - INFO: eval_greddy SPIDEr: 0.2104\n",
      "loading annotations into memory...\n",
      "0:00:00.003939\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9289, 'reflen': 9698, 'guess': [9289, 8265, 7241, 6217], 'correct': [5267, 1895, 741, 240]}\n",
      "ratio: 0.9578263559495815\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.353\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2021-12-16 01:31:14,474 - INFO: eval_beam_2 SPIDEr: 0.2296\n",
      "loading annotations into memory...\n",
      "0:00:00.003742\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9088, 'reflen': 9574, 'guess': [9088, 8064, 7040, 6016], 'correct': [5191, 1915, 786, 275]}\n",
      "ratio: 0.9492375182785722\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 01:31:42,003 - INFO: eval_beam_3 SPIDEr: 0.2342\n",
      "loading annotations into memory...\n",
      "0:00:00.004077\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8853, 'reflen': 9438, 'guess': [8853, 7829, 6805, 5781], 'correct': [5086, 1879, 768, 255]}\n",
      "ratio: 0.9380165289255205\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-16 01:32:10,826 - INFO: eval_beam_4 SPIDEr: 0.2330\n",
      "2021-12-16 01:32:16,973 - INFO: | epoch  12 |   100/ 3051 batches | lr 8.01e-06 | ms/batch 61.43 | loss-text 2.9226\n",
      "2021-12-16 01:32:22,872 - INFO: | epoch  12 |   200/ 3051 batches | lr 8.01e-06 | ms/batch 58.98 | loss-text 2.9322\n",
      "2021-12-16 01:32:28,847 - INFO: | epoch  12 |   300/ 3051 batches | lr 8.01e-06 | ms/batch 59.74 | loss-text 2.9066\n",
      "2021-12-16 01:32:34,790 - INFO: | epoch  12 |   400/ 3051 batches | lr 8.01e-06 | ms/batch 59.42 | loss-text 2.9147\n",
      "2021-12-16 01:32:40,718 - INFO: | epoch  12 |   500/ 3051 batches | lr 8.01e-06 | ms/batch 59.28 | loss-text 2.8720\n",
      "2021-12-16 01:32:46,695 - INFO: | epoch  12 |   600/ 3051 batches | lr 8.01e-06 | ms/batch 59.76 | loss-text 2.8715\n",
      "2021-12-16 01:32:52,698 - INFO: | epoch  12 |   700/ 3051 batches | lr 8.01e-06 | ms/batch 60.03 | loss-text 2.8591\n",
      "2021-12-16 01:32:58,659 - INFO: | epoch  12 |   800/ 3051 batches | lr 8.01e-06 | ms/batch 59.60 | loss-text 2.9182\n",
      "2021-12-16 01:33:04,619 - INFO: | epoch  12 |   900/ 3051 batches | lr 8.01e-06 | ms/batch 59.60 | loss-text 2.8992\n",
      "2021-12-16 01:33:10,582 - INFO: | epoch  12 |  1000/ 3051 batches | lr 8.01e-06 | ms/batch 59.62 | loss-text 2.9230\n",
      "2021-12-16 01:33:16,585 - INFO: | epoch  12 |  1100/ 3051 batches | lr 8.01e-06 | ms/batch 60.03 | loss-text 2.9103\n",
      "2021-12-16 01:33:22,570 - INFO: | epoch  12 |  1200/ 3051 batches | lr 8.01e-06 | ms/batch 59.84 | loss-text 2.8901\n",
      "2021-12-16 01:33:28,584 - INFO: | epoch  12 |  1300/ 3051 batches | lr 8.01e-06 | ms/batch 60.14 | loss-text 2.9026\n",
      "2021-12-16 01:33:34,563 - INFO: | epoch  12 |  1400/ 3051 batches | lr 8.01e-06 | ms/batch 59.78 | loss-text 2.9372\n",
      "2021-12-16 01:33:40,549 - INFO: | epoch  12 |  1500/ 3051 batches | lr 8.01e-06 | ms/batch 59.86 | loss-text 2.9337\n",
      "2021-12-16 01:33:46,597 - INFO: | epoch  12 |  1600/ 3051 batches | lr 8.01e-06 | ms/batch 60.47 | loss-text 2.9231\n",
      "2021-12-16 01:33:52,630 - INFO: | epoch  12 |  1700/ 3051 batches | lr 8.01e-06 | ms/batch 60.33 | loss-text 2.9055\n",
      "2021-12-16 01:33:58,617 - INFO: | epoch  12 |  1800/ 3051 batches | lr 8.01e-06 | ms/batch 59.87 | loss-text 2.9371\n",
      "2021-12-16 01:34:04,639 - INFO: | epoch  12 |  1900/ 3051 batches | lr 8.01e-06 | ms/batch 60.21 | loss-text 2.9119\n",
      "2021-12-16 01:34:10,697 - INFO: | epoch  12 |  2000/ 3051 batches | lr 8.01e-06 | ms/batch 60.57 | loss-text 2.8577\n",
      "2021-12-16 01:34:16,752 - INFO: | epoch  12 |  2100/ 3051 batches | lr 8.01e-06 | ms/batch 60.55 | loss-text 2.8912\n",
      "2021-12-16 01:34:22,787 - INFO: | epoch  12 |  2200/ 3051 batches | lr 8.01e-06 | ms/batch 60.34 | loss-text 2.8841\n",
      "2021-12-16 01:34:28,784 - INFO: | epoch  12 |  2300/ 3051 batches | lr 8.01e-06 | ms/batch 59.96 | loss-text 2.9359\n",
      "2021-12-16 01:34:34,804 - INFO: | epoch  12 |  2400/ 3051 batches | lr 8.01e-06 | ms/batch 60.19 | loss-text 2.9080\n",
      "2021-12-16 01:34:40,792 - INFO: | epoch  12 |  2500/ 3051 batches | lr 8.01e-06 | ms/batch 59.87 | loss-text 2.9266\n",
      "2021-12-16 01:34:46,769 - INFO: | epoch  12 |  2600/ 3051 batches | lr 8.01e-06 | ms/batch 59.77 | loss-text 2.9143\n",
      "2021-12-16 01:34:52,794 - INFO: | epoch  12 |  2700/ 3051 batches | lr 8.01e-06 | ms/batch 60.24 | loss-text 2.9052\n",
      "2021-12-16 01:34:58,822 - INFO: | epoch  12 |  2800/ 3051 batches | lr 8.01e-06 | ms/batch 60.27 | loss-text 2.9178\n",
      "2021-12-16 01:35:04,849 - INFO: | epoch  12 |  2900/ 3051 batches | lr 8.01e-06 | ms/batch 60.27 | loss-text 2.9620\n",
      "2021-12-16 01:35:10,865 - INFO: | epoch  12 |  3000/ 3051 batches | lr 8.01e-06 | ms/batch 60.14 | loss-text 2.9070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003938\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10033, 'reflen': 10223, 'guess': [10033, 9009, 7985, 6961], 'correct': [5442, 1829, 674, 206]}\n",
      "ratio: 0.9814144575955217\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.326\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.126\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.314\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.209\n",
      "2021-12-16 01:35:37,865 - INFO: eval_greddy SPIDEr: 0.2093\n",
      "loading annotations into memory...\n",
      "0:00:00.004072\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9281, 'reflen': 9711, 'guess': [9281, 8257, 7233, 6209], 'correct': [5253, 1888, 742, 236]}\n",
      "ratio: 0.9557203171660018\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.351\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2021-12-16 01:36:02,614 - INFO: eval_beam_2 SPIDEr: 0.2285\n",
      "loading annotations into memory...\n",
      "0:00:00.003895\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9056, 'reflen': 9574, 'guess': [9056, 8032, 7008, 5984], 'correct': [5134, 1883, 781, 278]}\n",
      "ratio: 0.9458951326508308\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 01:36:29,644 - INFO: eval_beam_3 SPIDEr: 0.2339\n",
      "loading annotations into memory...\n",
      "0:00:00.004001\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8842, 'reflen': 9447, 'guess': [8842, 7818, 6794, 5770], 'correct': [5069, 1865, 773, 268]}\n",
      "ratio: 0.9359585053455133\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 01:37:01,895 - INFO: eval_beam_4 SPIDEr: 0.2335\n",
      "2021-12-16 01:37:08,023 - INFO: | epoch  13 |   100/ 3051 batches | lr 7.85e-06 | ms/batch 61.25 | loss-text 2.8728\n",
      "2021-12-16 01:37:13,988 - INFO: | epoch  13 |   200/ 3051 batches | lr 7.85e-06 | ms/batch 59.63 | loss-text 2.8870\n",
      "2021-12-16 01:37:19,987 - INFO: | epoch  13 |   300/ 3051 batches | lr 7.85e-06 | ms/batch 59.98 | loss-text 2.8851\n",
      "2021-12-16 01:37:25,931 - INFO: | epoch  13 |   400/ 3051 batches | lr 7.85e-06 | ms/batch 59.43 | loss-text 2.8746\n",
      "2021-12-16 01:37:31,918 - INFO: | epoch  13 |   500/ 3051 batches | lr 7.85e-06 | ms/batch 59.87 | loss-text 2.8607\n",
      "2021-12-16 01:37:37,911 - INFO: | epoch  13 |   600/ 3051 batches | lr 7.85e-06 | ms/batch 59.91 | loss-text 2.9027\n",
      "2021-12-16 01:37:43,893 - INFO: | epoch  13 |   700/ 3051 batches | lr 7.85e-06 | ms/batch 59.82 | loss-text 2.9030\n",
      "2021-12-16 01:37:49,895 - INFO: | epoch  13 |   800/ 3051 batches | lr 7.85e-06 | ms/batch 60.01 | loss-text 2.9096\n",
      "2021-12-16 01:37:55,836 - INFO: | epoch  13 |   900/ 3051 batches | lr 7.85e-06 | ms/batch 59.41 | loss-text 2.8812\n",
      "2021-12-16 01:38:01,882 - INFO: | epoch  13 |  1000/ 3051 batches | lr 7.85e-06 | ms/batch 60.45 | loss-text 2.9251\n",
      "2021-12-16 01:38:07,834 - INFO: | epoch  13 |  1100/ 3051 batches | lr 7.85e-06 | ms/batch 59.51 | loss-text 2.9012\n",
      "2021-12-16 01:38:13,823 - INFO: | epoch  13 |  1200/ 3051 batches | lr 7.85e-06 | ms/batch 59.88 | loss-text 2.9022\n",
      "2021-12-16 01:38:19,844 - INFO: | epoch  13 |  1300/ 3051 batches | lr 7.85e-06 | ms/batch 60.21 | loss-text 2.9157\n",
      "2021-12-16 01:38:25,839 - INFO: | epoch  13 |  1400/ 3051 batches | lr 7.85e-06 | ms/batch 59.94 | loss-text 2.9397\n",
      "2021-12-16 01:38:31,857 - INFO: | epoch  13 |  1500/ 3051 batches | lr 7.85e-06 | ms/batch 60.18 | loss-text 2.8727\n",
      "2021-12-16 01:38:37,902 - INFO: | epoch  13 |  1600/ 3051 batches | lr 7.85e-06 | ms/batch 60.44 | loss-text 2.9143\n",
      "2021-12-16 01:38:43,884 - INFO: | epoch  13 |  1700/ 3051 batches | lr 7.85e-06 | ms/batch 59.82 | loss-text 2.9328\n",
      "2021-12-16 01:38:49,869 - INFO: | epoch  13 |  1800/ 3051 batches | lr 7.85e-06 | ms/batch 59.85 | loss-text 2.8771\n",
      "2021-12-16 01:38:55,880 - INFO: | epoch  13 |  1900/ 3051 batches | lr 7.85e-06 | ms/batch 60.10 | loss-text 2.8825\n",
      "2021-12-16 01:39:01,944 - INFO: | epoch  13 |  2000/ 3051 batches | lr 7.85e-06 | ms/batch 60.63 | loss-text 2.9150\n",
      "2021-12-16 01:39:07,975 - INFO: | epoch  13 |  2100/ 3051 batches | lr 7.85e-06 | ms/batch 60.31 | loss-text 2.9143\n",
      "2021-12-16 01:39:13,949 - INFO: | epoch  13 |  2200/ 3051 batches | lr 7.85e-06 | ms/batch 59.73 | loss-text 2.9145\n",
      "2021-12-16 01:39:19,932 - INFO: | epoch  13 |  2300/ 3051 batches | lr 7.85e-06 | ms/batch 59.82 | loss-text 2.9112\n",
      "2021-12-16 01:39:25,988 - INFO: | epoch  13 |  2400/ 3051 batches | lr 7.85e-06 | ms/batch 60.56 | loss-text 2.9113\n",
      "2021-12-16 01:39:32,001 - INFO: | epoch  13 |  2500/ 3051 batches | lr 7.85e-06 | ms/batch 60.12 | loss-text 2.9136\n",
      "2021-12-16 01:39:38,089 - INFO: | epoch  13 |  2600/ 3051 batches | lr 7.85e-06 | ms/batch 60.87 | loss-text 2.9440\n",
      "2021-12-16 01:39:44,106 - INFO: | epoch  13 |  2700/ 3051 batches | lr 7.85e-06 | ms/batch 60.17 | loss-text 2.8635\n",
      "2021-12-16 01:39:50,149 - INFO: | epoch  13 |  2800/ 3051 batches | lr 7.85e-06 | ms/batch 60.42 | loss-text 2.9304\n",
      "2021-12-16 01:39:56,178 - INFO: | epoch  13 |  2900/ 3051 batches | lr 7.85e-06 | ms/batch 60.28 | loss-text 2.9185\n",
      "2021-12-16 01:40:02,185 - INFO: | epoch  13 |  3000/ 3051 batches | lr 7.85e-06 | ms/batch 60.06 | loss-text 2.8887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004060\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10016, 'reflen': 10223, 'guess': [10016, 8992, 7968, 6944], 'correct': [5495, 1904, 724, 238]}\n",
      "ratio: 0.9797515406435507\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.334\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.327\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2021-12-16 01:40:27,999 - INFO: eval_greddy SPIDEr: 0.2169\n",
      "loading annotations into memory...\n",
      "0:00:00.004112\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9278, 'reflen': 9697, 'guess': [9278, 8254, 7230, 6206], 'correct': [5283, 1905, 747, 250]}\n",
      "ratio: 0.9567907600287762\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-16 01:40:48,842 - INFO: eval_beam_2 SPIDEr: 0.2322\n",
      "loading annotations into memory...\n",
      "0:00:00.003852\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9065, 'reflen': 9578, 'guess': [9065, 8041, 7017, 5993], 'correct': [5183, 1867, 768, 263]}\n",
      "ratio: 0.9464397577781429\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.356\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2021-12-16 01:41:12,995 - INFO: eval_beam_3 SPIDEr: 0.2302\n",
      "loading annotations into memory...\n",
      "0:00:00.003898\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8822, 'reflen': 9423, 'guess': [8822, 7798, 6774, 5750], 'correct': [5074, 1856, 770, 265]}\n",
      "ratio: 0.9362198875091864\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 01:41:40,808 - INFO: eval_beam_4 SPIDEr: 0.2346\n",
      "2021-12-16 01:41:46,959 - INFO: | epoch  14 |   100/ 3051 batches | lr 7.69e-06 | ms/batch 61.48 | loss-text 2.9470\n",
      "2021-12-16 01:41:52,930 - INFO: | epoch  14 |   200/ 3051 batches | lr 7.69e-06 | ms/batch 59.70 | loss-text 2.9280\n",
      "2021-12-16 01:41:58,839 - INFO: | epoch  14 |   300/ 3051 batches | lr 7.69e-06 | ms/batch 59.08 | loss-text 2.8814\n",
      "2021-12-16 01:42:04,822 - INFO: | epoch  14 |   400/ 3051 batches | lr 7.69e-06 | ms/batch 59.83 | loss-text 2.9503\n",
      "2021-12-16 01:42:10,824 - INFO: | epoch  14 |   500/ 3051 batches | lr 7.69e-06 | ms/batch 60.01 | loss-text 2.9122\n",
      "2021-12-16 01:42:16,823 - INFO: | epoch  14 |   600/ 3051 batches | lr 7.69e-06 | ms/batch 59.98 | loss-text 2.9046\n",
      "2021-12-16 01:42:22,805 - INFO: | epoch  14 |   700/ 3051 batches | lr 7.69e-06 | ms/batch 59.82 | loss-text 2.9002\n",
      "2021-12-16 01:42:28,805 - INFO: | epoch  14 |   800/ 3051 batches | lr 7.69e-06 | ms/batch 59.99 | loss-text 2.9328\n",
      "2021-12-16 01:42:34,787 - INFO: | epoch  14 |   900/ 3051 batches | lr 7.69e-06 | ms/batch 59.82 | loss-text 2.8989\n",
      "2021-12-16 01:42:40,777 - INFO: | epoch  14 |  1000/ 3051 batches | lr 7.69e-06 | ms/batch 59.89 | loss-text 2.9014\n",
      "2021-12-16 01:42:46,758 - INFO: | epoch  14 |  1100/ 3051 batches | lr 7.69e-06 | ms/batch 59.81 | loss-text 2.8853\n",
      "2021-12-16 01:42:52,759 - INFO: | epoch  14 |  1200/ 3051 batches | lr 7.69e-06 | ms/batch 60.01 | loss-text 2.8818\n",
      "2021-12-16 01:42:58,736 - INFO: | epoch  14 |  1300/ 3051 batches | lr 7.69e-06 | ms/batch 59.76 | loss-text 2.9007\n",
      "2021-12-16 01:43:04,784 - INFO: | epoch  14 |  1400/ 3051 batches | lr 7.69e-06 | ms/batch 60.48 | loss-text 2.9076\n",
      "2021-12-16 01:43:10,754 - INFO: | epoch  14 |  1500/ 3051 batches | lr 7.69e-06 | ms/batch 59.69 | loss-text 2.8984\n",
      "2021-12-16 01:43:16,744 - INFO: | epoch  14 |  1600/ 3051 batches | lr 7.69e-06 | ms/batch 59.90 | loss-text 2.8775\n",
      "2021-12-16 01:43:22,713 - INFO: | epoch  14 |  1700/ 3051 batches | lr 7.69e-06 | ms/batch 59.68 | loss-text 2.9053\n",
      "2021-12-16 01:43:28,703 - INFO: | epoch  14 |  1800/ 3051 batches | lr 7.69e-06 | ms/batch 59.89 | loss-text 2.8953\n",
      "2021-12-16 01:43:34,702 - INFO: | epoch  14 |  1900/ 3051 batches | lr 7.69e-06 | ms/batch 59.97 | loss-text 2.8924\n",
      "2021-12-16 01:43:40,740 - INFO: | epoch  14 |  2000/ 3051 batches | lr 7.69e-06 | ms/batch 60.38 | loss-text 2.8735\n",
      "2021-12-16 01:43:46,732 - INFO: | epoch  14 |  2100/ 3051 batches | lr 7.69e-06 | ms/batch 59.91 | loss-text 2.9102\n",
      "2021-12-16 01:43:52,719 - INFO: | epoch  14 |  2200/ 3051 batches | lr 7.69e-06 | ms/batch 59.86 | loss-text 2.9284\n",
      "2021-12-16 01:43:58,742 - INFO: | epoch  14 |  2300/ 3051 batches | lr 7.69e-06 | ms/batch 60.23 | loss-text 2.9437\n",
      "2021-12-16 01:44:04,781 - INFO: | epoch  14 |  2400/ 3051 batches | lr 7.69e-06 | ms/batch 60.38 | loss-text 2.8680\n",
      "2021-12-16 01:44:10,789 - INFO: | epoch  14 |  2500/ 3051 batches | lr 7.69e-06 | ms/batch 60.08 | loss-text 2.9122\n",
      "2021-12-16 01:44:16,840 - INFO: | epoch  14 |  2600/ 3051 batches | lr 7.69e-06 | ms/batch 60.50 | loss-text 2.8749\n",
      "2021-12-16 01:44:22,850 - INFO: | epoch  14 |  2700/ 3051 batches | lr 7.69e-06 | ms/batch 60.09 | loss-text 2.8814\n",
      "2021-12-16 01:44:28,883 - INFO: | epoch  14 |  2800/ 3051 batches | lr 7.69e-06 | ms/batch 60.33 | loss-text 2.8911\n",
      "2021-12-16 01:44:34,928 - INFO: | epoch  14 |  2900/ 3051 batches | lr 7.69e-06 | ms/batch 60.45 | loss-text 2.9263\n",
      "2021-12-16 01:44:40,935 - INFO: | epoch  14 |  3000/ 3051 batches | lr 7.69e-06 | ms/batch 60.06 | loss-text 2.8822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003894\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10064, 'reflen': 10234, 'guess': [10064, 9040, 8016, 6992], 'correct': [5477, 1852, 692, 215]}\n",
      "ratio: 0.9833887043188407\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.318\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.211\n",
      "2021-12-16 01:45:08,200 - INFO: eval_greddy SPIDEr: 0.2115\n",
      "loading annotations into memory...\n",
      "0:00:00.003751\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9330, 'reflen': 9724, 'guess': [9330, 8306, 7282, 6258], 'correct': [5320, 1915, 745, 246]}\n",
      "ratio: 0.9594816947757137\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 01:45:32,832 - INFO: eval_beam_2 SPIDEr: 0.2343\n",
      "loading annotations into memory...\n",
      "0:00:00.003948\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9079, 'reflen': 9568, 'guess': [9079, 8055, 7031, 6007], 'correct': [5215, 1927, 805, 293]}\n",
      "ratio: 0.9488921404681282\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.375\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-16 01:45:57,143 - INFO: eval_beam_3 SPIDEr: 0.2403\n",
      "loading annotations into memory...\n",
      "0:00:00.004054\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8891, 'reflen': 9449, 'guess': [8891, 7867, 6843, 5819], 'correct': [5147, 1912, 791, 271]}\n",
      "ratio: 0.9409461318657063\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 01:46:29,419 - INFO: eval_beam_4 SPIDEr: 0.2375\n",
      "2021-12-16 01:46:35,528 - INFO: | epoch  15 |   100/ 3051 batches | lr 7.54e-06 | ms/batch 61.06 | loss-text 2.8893\n",
      "2021-12-16 01:46:41,514 - INFO: | epoch  15 |   200/ 3051 batches | lr 7.54e-06 | ms/batch 59.85 | loss-text 2.9412\n",
      "2021-12-16 01:46:47,459 - INFO: | epoch  15 |   300/ 3051 batches | lr 7.54e-06 | ms/batch 59.44 | loss-text 2.9131\n",
      "2021-12-16 01:46:53,394 - INFO: | epoch  15 |   400/ 3051 batches | lr 7.54e-06 | ms/batch 59.34 | loss-text 2.9155\n",
      "2021-12-16 01:46:59,345 - INFO: | epoch  15 |   500/ 3051 batches | lr 7.54e-06 | ms/batch 59.50 | loss-text 2.8375\n",
      "2021-12-16 01:47:05,290 - INFO: | epoch  15 |   600/ 3051 batches | lr 7.54e-06 | ms/batch 59.45 | loss-text 2.9166\n",
      "2021-12-16 01:47:11,271 - INFO: | epoch  15 |   700/ 3051 batches | lr 7.54e-06 | ms/batch 59.81 | loss-text 2.8627\n",
      "2021-12-16 01:47:17,261 - INFO: | epoch  15 |   800/ 3051 batches | lr 7.54e-06 | ms/batch 59.89 | loss-text 2.8537\n",
      "2021-12-16 01:47:23,205 - INFO: | epoch  15 |   900/ 3051 batches | lr 7.54e-06 | ms/batch 59.43 | loss-text 2.9075\n",
      "2021-12-16 01:47:29,184 - INFO: | epoch  15 |  1000/ 3051 batches | lr 7.54e-06 | ms/batch 59.78 | loss-text 2.9063\n",
      "2021-12-16 01:47:35,157 - INFO: | epoch  15 |  1100/ 3051 batches | lr 7.54e-06 | ms/batch 59.72 | loss-text 2.9036\n",
      "2021-12-16 01:47:41,146 - INFO: | epoch  15 |  1200/ 3051 batches | lr 7.54e-06 | ms/batch 59.89 | loss-text 2.8897\n",
      "2021-12-16 01:47:47,191 - INFO: | epoch  15 |  1300/ 3051 batches | lr 7.54e-06 | ms/batch 60.45 | loss-text 2.9162\n",
      "2021-12-16 01:47:53,137 - INFO: | epoch  15 |  1400/ 3051 batches | lr 7.54e-06 | ms/batch 59.44 | loss-text 2.8720\n",
      "2021-12-16 01:47:59,124 - INFO: | epoch  15 |  1500/ 3051 batches | lr 7.54e-06 | ms/batch 59.87 | loss-text 2.8877\n",
      "2021-12-16 01:48:05,087 - INFO: | epoch  15 |  1600/ 3051 batches | lr 7.54e-06 | ms/batch 59.62 | loss-text 2.8843\n",
      "2021-12-16 01:48:11,122 - INFO: | epoch  15 |  1700/ 3051 batches | lr 7.54e-06 | ms/batch 60.34 | loss-text 2.9206\n",
      "2021-12-16 01:48:17,145 - INFO: | epoch  15 |  1800/ 3051 batches | lr 7.54e-06 | ms/batch 60.22 | loss-text 2.9301\n",
      "2021-12-16 01:48:23,144 - INFO: | epoch  15 |  1900/ 3051 batches | lr 7.54e-06 | ms/batch 59.98 | loss-text 2.9108\n",
      "2021-12-16 01:48:29,220 - INFO: | epoch  15 |  2000/ 3051 batches | lr 7.54e-06 | ms/batch 60.76 | loss-text 2.9129\n",
      "2021-12-16 01:48:35,223 - INFO: | epoch  15 |  2100/ 3051 batches | lr 7.54e-06 | ms/batch 60.02 | loss-text 2.9076\n",
      "2021-12-16 01:48:41,205 - INFO: | epoch  15 |  2200/ 3051 batches | lr 7.54e-06 | ms/batch 59.82 | loss-text 2.8924\n",
      "2021-12-16 01:48:47,130 - INFO: | epoch  15 |  2300/ 3051 batches | lr 7.54e-06 | ms/batch 59.24 | loss-text 2.9379\n",
      "2021-12-16 01:48:53,103 - INFO: | epoch  15 |  2400/ 3051 batches | lr 7.54e-06 | ms/batch 59.72 | loss-text 2.8995\n",
      "2021-12-16 01:48:59,098 - INFO: | epoch  15 |  2500/ 3051 batches | lr 7.54e-06 | ms/batch 59.94 | loss-text 2.8818\n",
      "2021-12-16 01:49:05,117 - INFO: | epoch  15 |  2600/ 3051 batches | lr 7.54e-06 | ms/batch 60.19 | loss-text 2.8923\n",
      "2021-12-16 01:49:11,192 - INFO: | epoch  15 |  2700/ 3051 batches | lr 7.54e-06 | ms/batch 60.74 | loss-text 2.9079\n",
      "2021-12-16 01:49:17,203 - INFO: | epoch  15 |  2800/ 3051 batches | lr 7.54e-06 | ms/batch 60.11 | loss-text 2.8977\n",
      "2021-12-16 01:49:23,218 - INFO: | epoch  15 |  2900/ 3051 batches | lr 7.54e-06 | ms/batch 60.14 | loss-text 2.9334\n",
      "2021-12-16 01:49:29,232 - INFO: | epoch  15 |  3000/ 3051 batches | lr 7.54e-06 | ms/batch 60.13 | loss-text 2.8556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004064\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9954, 'reflen': 10186, 'guess': [9954, 8930, 7906, 6882], 'correct': [5412, 1832, 674, 215]}\n",
      "ratio: 0.9772236402904989\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.326\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.321\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.213\n",
      "2021-12-16 01:49:56,383 - INFO: eval_greddy SPIDEr: 0.2135\n",
      "loading annotations into memory...\n",
      "0:00:00.003987\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9263, 'reflen': 9666, 'guess': [9263, 8239, 7215, 6191], 'correct': [5267, 1891, 737, 242]}\n",
      "ratio: 0.9583074694805547\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.358\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-16 01:50:22,108 - INFO: eval_beam_2 SPIDEr: 0.2322\n",
      "loading annotations into memory...\n",
      "0:00:00.003858\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9028, 'reflen': 9558, 'guess': [9028, 8004, 6980, 5956], 'correct': [5129, 1847, 769, 278]}\n",
      "ratio: 0.9445490688427552\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.341\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-16 01:50:46,645 - INFO: eval_beam_3 SPIDEr: 0.2316\n",
      "loading annotations into memory...\n",
      "0:00:00.003948\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8827, 'reflen': 9420, 'guess': [8827, 7803, 6779, 5755], 'correct': [5086, 1864, 758, 262]}\n",
      "ratio: 0.9370488322716627\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 01:51:14,585 - INFO: eval_beam_4 SPIDEr: 0.2358\n",
      "2021-12-16 01:51:20,720 - INFO: | epoch  16 |   100/ 3051 batches | lr 7.39e-06 | ms/batch 61.32 | loss-text 2.8611\n",
      "2021-12-16 01:51:26,699 - INFO: | epoch  16 |   200/ 3051 batches | lr 7.39e-06 | ms/batch 59.78 | loss-text 2.9159\n",
      "2021-12-16 01:51:32,663 - INFO: | epoch  16 |   300/ 3051 batches | lr 7.39e-06 | ms/batch 59.64 | loss-text 2.8796\n",
      "2021-12-16 01:51:38,602 - INFO: | epoch  16 |   400/ 3051 batches | lr 7.39e-06 | ms/batch 59.38 | loss-text 2.9052\n",
      "2021-12-16 01:51:44,643 - INFO: | epoch  16 |   500/ 3051 batches | lr 7.39e-06 | ms/batch 60.41 | loss-text 2.8320\n",
      "2021-12-16 01:51:50,587 - INFO: | epoch  16 |   600/ 3051 batches | lr 7.39e-06 | ms/batch 59.43 | loss-text 2.9352\n",
      "2021-12-16 01:51:56,621 - INFO: | epoch  16 |   700/ 3051 batches | lr 7.39e-06 | ms/batch 60.33 | loss-text 2.8545\n",
      "2021-12-16 01:52:02,544 - INFO: | epoch  16 |   800/ 3051 batches | lr 7.39e-06 | ms/batch 59.23 | loss-text 2.8727\n",
      "2021-12-16 01:52:08,551 - INFO: | epoch  16 |   900/ 3051 batches | lr 7.39e-06 | ms/batch 60.06 | loss-text 2.9103\n",
      "2021-12-16 01:52:14,529 - INFO: | epoch  16 |  1000/ 3051 batches | lr 7.39e-06 | ms/batch 59.77 | loss-text 2.8912\n",
      "2021-12-16 01:52:20,521 - INFO: | epoch  16 |  1100/ 3051 batches | lr 7.39e-06 | ms/batch 59.92 | loss-text 2.9154\n",
      "2021-12-16 01:52:26,509 - INFO: | epoch  16 |  1200/ 3051 batches | lr 7.39e-06 | ms/batch 59.87 | loss-text 2.8670\n",
      "2021-12-16 01:52:32,497 - INFO: | epoch  16 |  1300/ 3051 batches | lr 7.39e-06 | ms/batch 59.88 | loss-text 2.9547\n",
      "2021-12-16 01:52:38,579 - INFO: | epoch  16 |  1400/ 3051 batches | lr 7.39e-06 | ms/batch 60.81 | loss-text 2.8687\n",
      "2021-12-16 01:52:44,594 - INFO: | epoch  16 |  1500/ 3051 batches | lr 7.39e-06 | ms/batch 60.14 | loss-text 2.8636\n",
      "2021-12-16 01:52:50,584 - INFO: | epoch  16 |  1600/ 3051 batches | lr 7.39e-06 | ms/batch 59.89 | loss-text 2.8894\n",
      "2021-12-16 01:52:56,634 - INFO: | epoch  16 |  1700/ 3051 batches | lr 7.39e-06 | ms/batch 60.49 | loss-text 2.9056\n",
      "2021-12-16 01:53:02,636 - INFO: | epoch  16 |  1800/ 3051 batches | lr 7.39e-06 | ms/batch 60.01 | loss-text 2.9165\n",
      "2021-12-16 01:53:08,670 - INFO: | epoch  16 |  1900/ 3051 batches | lr 7.39e-06 | ms/batch 60.33 | loss-text 2.9145\n",
      "2021-12-16 01:53:14,621 - INFO: | epoch  16 |  2000/ 3051 batches | lr 7.39e-06 | ms/batch 59.51 | loss-text 2.9391\n",
      "2021-12-16 01:53:20,611 - INFO: | epoch  16 |  2100/ 3051 batches | lr 7.39e-06 | ms/batch 59.88 | loss-text 2.8775\n",
      "2021-12-16 01:53:26,564 - INFO: | epoch  16 |  2200/ 3051 batches | lr 7.39e-06 | ms/batch 59.52 | loss-text 2.9161\n",
      "2021-12-16 01:53:32,594 - INFO: | epoch  16 |  2300/ 3051 batches | lr 7.39e-06 | ms/batch 60.30 | loss-text 2.8930\n",
      "2021-12-16 01:53:38,606 - INFO: | epoch  16 |  2400/ 3051 batches | lr 7.39e-06 | ms/batch 60.12 | loss-text 2.8739\n",
      "2021-12-16 01:53:44,625 - INFO: | epoch  16 |  2500/ 3051 batches | lr 7.39e-06 | ms/batch 60.18 | loss-text 2.9346\n",
      "2021-12-16 01:53:50,601 - INFO: | epoch  16 |  2600/ 3051 batches | lr 7.39e-06 | ms/batch 59.75 | loss-text 2.9380\n",
      "2021-12-16 01:53:56,585 - INFO: | epoch  16 |  2700/ 3051 batches | lr 7.39e-06 | ms/batch 59.83 | loss-text 2.9177\n",
      "2021-12-16 01:54:02,602 - INFO: | epoch  16 |  2800/ 3051 batches | lr 7.39e-06 | ms/batch 60.16 | loss-text 2.8763\n",
      "2021-12-16 01:54:08,594 - INFO: | epoch  16 |  2900/ 3051 batches | lr 7.39e-06 | ms/batch 59.92 | loss-text 2.8911\n",
      "2021-12-16 01:54:14,585 - INFO: | epoch  16 |  3000/ 3051 batches | lr 7.39e-06 | ms/batch 59.90 | loss-text 2.8941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003764\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10096, 'reflen': 10275, 'guess': [10096, 9072, 8048, 7024], 'correct': [5491, 1886, 705, 222]}\n",
      "ratio: 0.9825790754256951\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.131\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2021-12-16 01:54:40,301 - INFO: eval_greddy SPIDEr: 0.2152\n",
      "loading annotations into memory...\n",
      "0:00:00.003741\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9308, 'reflen': 9715, 'guess': [9308, 8284, 7260, 6236], 'correct': [5287, 1884, 737, 235]}\n",
      "ratio: 0.9581060216159589\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.352\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2021-12-16 01:55:04,230 - INFO: eval_beam_2 SPIDEr: 0.2293\n",
      "loading annotations into memory...\n",
      "0:00:00.003918\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9071, 'reflen': 9592, 'guess': [9071, 8047, 7023, 5999], 'correct': [5153, 1888, 786, 270]}\n",
      "ratio: 0.945683903252612\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-16 01:55:31,571 - INFO: eval_beam_3 SPIDEr: 0.2311\n",
      "loading annotations into memory...\n",
      "0:00:00.003938\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8852, 'reflen': 9426, 'guess': [8852, 7828, 6804, 5780], 'correct': [5093, 1883, 785, 270]}\n",
      "ratio: 0.9391046042859177\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 01:56:00,769 - INFO: eval_beam_4 SPIDEr: 0.2349\n",
      "2021-12-16 01:56:06,912 - INFO: | epoch  17 |   100/ 3051 batches | lr 7.24e-06 | ms/batch 61.40 | loss-text 2.8676\n",
      "2021-12-16 01:56:12,857 - INFO: | epoch  17 |   200/ 3051 batches | lr 7.24e-06 | ms/batch 59.43 | loss-text 2.8657\n",
      "2021-12-16 01:56:18,810 - INFO: | epoch  17 |   300/ 3051 batches | lr 7.24e-06 | ms/batch 59.53 | loss-text 2.9113\n",
      "2021-12-16 01:56:24,765 - INFO: | epoch  17 |   400/ 3051 batches | lr 7.24e-06 | ms/batch 59.54 | loss-text 2.8908\n",
      "2021-12-16 01:56:30,736 - INFO: | epoch  17 |   500/ 3051 batches | lr 7.24e-06 | ms/batch 59.71 | loss-text 2.8663\n",
      "2021-12-16 01:56:36,749 - INFO: | epoch  17 |   600/ 3051 batches | lr 7.24e-06 | ms/batch 60.12 | loss-text 2.8996\n",
      "2021-12-16 01:56:42,704 - INFO: | epoch  17 |   700/ 3051 batches | lr 7.24e-06 | ms/batch 59.54 | loss-text 2.8758\n",
      "2021-12-16 01:56:48,711 - INFO: | epoch  17 |   800/ 3051 batches | lr 7.24e-06 | ms/batch 60.07 | loss-text 2.9058\n",
      "2021-12-16 01:56:54,698 - INFO: | epoch  17 |   900/ 3051 batches | lr 7.24e-06 | ms/batch 59.87 | loss-text 2.8579\n",
      "2021-12-16 01:57:00,705 - INFO: | epoch  17 |  1000/ 3051 batches | lr 7.24e-06 | ms/batch 60.06 | loss-text 2.8853\n",
      "2021-12-16 01:57:06,681 - INFO: | epoch  17 |  1100/ 3051 batches | lr 7.24e-06 | ms/batch 59.76 | loss-text 2.8678\n",
      "2021-12-16 01:57:12,702 - INFO: | epoch  17 |  1200/ 3051 batches | lr 7.24e-06 | ms/batch 60.20 | loss-text 2.9065\n",
      "2021-12-16 01:57:18,668 - INFO: | epoch  17 |  1300/ 3051 batches | lr 7.24e-06 | ms/batch 59.65 | loss-text 2.8871\n",
      "2021-12-16 01:57:24,631 - INFO: | epoch  17 |  1400/ 3051 batches | lr 7.24e-06 | ms/batch 59.62 | loss-text 2.9341\n",
      "2021-12-16 01:57:30,583 - INFO: | epoch  17 |  1500/ 3051 batches | lr 7.24e-06 | ms/batch 59.51 | loss-text 2.8974\n",
      "2021-12-16 01:57:36,562 - INFO: | epoch  17 |  1600/ 3051 batches | lr 7.24e-06 | ms/batch 59.79 | loss-text 2.9199\n",
      "2021-12-16 01:57:42,524 - INFO: | epoch  17 |  1700/ 3051 batches | lr 7.24e-06 | ms/batch 59.61 | loss-text 2.9327\n",
      "2021-12-16 01:57:48,506 - INFO: | epoch  17 |  1800/ 3051 batches | lr 7.24e-06 | ms/batch 59.82 | loss-text 2.8877\n",
      "2021-12-16 01:57:54,467 - INFO: | epoch  17 |  1900/ 3051 batches | lr 7.24e-06 | ms/batch 59.60 | loss-text 2.8911\n",
      "2021-12-16 01:58:00,488 - INFO: | epoch  17 |  2000/ 3051 batches | lr 7.24e-06 | ms/batch 60.20 | loss-text 2.8818\n",
      "2021-12-16 01:58:06,532 - INFO: | epoch  17 |  2100/ 3051 batches | lr 7.24e-06 | ms/batch 60.43 | loss-text 2.8878\n",
      "2021-12-16 01:58:12,561 - INFO: | epoch  17 |  2200/ 3051 batches | lr 7.24e-06 | ms/batch 60.29 | loss-text 2.8940\n",
      "2021-12-16 01:58:18,533 - INFO: | epoch  17 |  2300/ 3051 batches | lr 7.24e-06 | ms/batch 59.70 | loss-text 2.9018\n",
      "2021-12-16 01:58:24,527 - INFO: | epoch  17 |  2400/ 3051 batches | lr 7.24e-06 | ms/batch 59.94 | loss-text 2.8621\n",
      "2021-12-16 01:58:30,511 - INFO: | epoch  17 |  2500/ 3051 batches | lr 7.24e-06 | ms/batch 59.83 | loss-text 2.8763\n",
      "2021-12-16 01:58:36,491 - INFO: | epoch  17 |  2600/ 3051 batches | lr 7.24e-06 | ms/batch 59.79 | loss-text 2.8630\n",
      "2021-12-16 01:58:42,553 - INFO: | epoch  17 |  2700/ 3051 batches | lr 7.24e-06 | ms/batch 60.62 | loss-text 2.9044\n",
      "2021-12-16 01:58:48,602 - INFO: | epoch  17 |  2800/ 3051 batches | lr 7.24e-06 | ms/batch 60.48 | loss-text 2.8911\n",
      "2021-12-16 01:58:54,601 - INFO: | epoch  17 |  2900/ 3051 batches | lr 7.24e-06 | ms/batch 59.98 | loss-text 2.8823\n",
      "2021-12-16 01:59:00,649 - INFO: | epoch  17 |  3000/ 3051 batches | lr 7.24e-06 | ms/batch 60.47 | loss-text 2.9017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004128\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10044, 'reflen': 10235, 'guess': [10044, 9020, 7996, 6972], 'correct': [5435, 1828, 670, 211]}\n",
      "ratio: 0.9813385442109446\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.322\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2021-12-16 01:59:25,958 - INFO: eval_greddy SPIDEr: 0.2136\n",
      "loading annotations into memory...\n",
      "0:00:00.004346\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9290, 'reflen': 9682, 'guess': [9290, 8266, 7242, 6218], 'correct': [5277, 1900, 740, 243]}\n",
      "ratio: 0.9595124974177898\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.358\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-16 01:59:50,613 - INFO: eval_beam_2 SPIDEr: 0.2321\n",
      "loading annotations into memory...\n",
      "0:00:00.003622\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9080, 'reflen': 9576, 'guess': [9080, 8056, 7032, 6008], 'correct': [5167, 1909, 798, 273]}\n",
      "ratio: 0.948203842940586\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 02:00:14,373 - INFO: eval_beam_3 SPIDEr: 0.2341\n",
      "loading annotations into memory...\n",
      "0:00:00.004077\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8869, 'reflen': 9442, 'guess': [8869, 7845, 6821, 5797], 'correct': [5101, 1889, 788, 272]}\n",
      "ratio: 0.939313704723476\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 02:00:44,074 - INFO: eval_beam_4 SPIDEr: 0.2337\n",
      "2021-12-16 02:00:50,220 - INFO: | epoch  18 |   100/ 3051 batches | lr 7.09e-06 | ms/batch 61.43 | loss-text 2.8721\n",
      "2021-12-16 02:00:56,199 - INFO: | epoch  18 |   200/ 3051 batches | lr 7.09e-06 | ms/batch 59.78 | loss-text 2.9087\n",
      "2021-12-16 02:01:02,096 - INFO: | epoch  18 |   300/ 3051 batches | lr 7.09e-06 | ms/batch 58.97 | loss-text 2.9004\n",
      "2021-12-16 02:01:08,092 - INFO: | epoch  18 |   400/ 3051 batches | lr 7.09e-06 | ms/batch 59.95 | loss-text 2.9090\n",
      "2021-12-16 02:01:14,042 - INFO: | epoch  18 |   500/ 3051 batches | lr 7.09e-06 | ms/batch 59.50 | loss-text 2.8833\n",
      "2021-12-16 02:01:20,007 - INFO: | epoch  18 |   600/ 3051 batches | lr 7.09e-06 | ms/batch 59.65 | loss-text 2.9006\n",
      "2021-12-16 02:01:25,967 - INFO: | epoch  18 |   700/ 3051 batches | lr 7.09e-06 | ms/batch 59.59 | loss-text 2.8705\n",
      "2021-12-16 02:01:31,910 - INFO: | epoch  18 |   800/ 3051 batches | lr 7.09e-06 | ms/batch 59.42 | loss-text 2.9144\n",
      "2021-12-16 02:01:37,875 - INFO: | epoch  18 |   900/ 3051 batches | lr 7.09e-06 | ms/batch 59.65 | loss-text 2.9122\n",
      "2021-12-16 02:01:43,879 - INFO: | epoch  18 |  1000/ 3051 batches | lr 7.09e-06 | ms/batch 60.03 | loss-text 2.9135\n",
      "2021-12-16 02:01:49,847 - INFO: | epoch  18 |  1100/ 3051 batches | lr 7.09e-06 | ms/batch 59.68 | loss-text 2.9212\n",
      "2021-12-16 02:01:55,879 - INFO: | epoch  18 |  1200/ 3051 batches | lr 7.09e-06 | ms/batch 60.32 | loss-text 2.8975\n",
      "2021-12-16 02:02:01,843 - INFO: | epoch  18 |  1300/ 3051 batches | lr 7.09e-06 | ms/batch 59.63 | loss-text 2.8725\n",
      "2021-12-16 02:02:07,848 - INFO: | epoch  18 |  1400/ 3051 batches | lr 7.09e-06 | ms/batch 60.04 | loss-text 2.9213\n",
      "2021-12-16 02:02:13,853 - INFO: | epoch  18 |  1500/ 3051 batches | lr 7.09e-06 | ms/batch 60.05 | loss-text 2.9206\n",
      "2021-12-16 02:02:19,875 - INFO: | epoch  18 |  1600/ 3051 batches | lr 7.09e-06 | ms/batch 60.21 | loss-text 2.8557\n",
      "2021-12-16 02:02:25,884 - INFO: | epoch  18 |  1700/ 3051 batches | lr 7.09e-06 | ms/batch 60.09 | loss-text 2.8684\n",
      "2021-12-16 02:02:31,863 - INFO: | epoch  18 |  1800/ 3051 batches | lr 7.09e-06 | ms/batch 59.78 | loss-text 2.8716\n",
      "2021-12-16 02:02:37,882 - INFO: | epoch  18 |  1900/ 3051 batches | lr 7.09e-06 | ms/batch 60.18 | loss-text 2.8972\n",
      "2021-12-16 02:02:43,893 - INFO: | epoch  18 |  2000/ 3051 batches | lr 7.09e-06 | ms/batch 60.11 | loss-text 2.8878\n",
      "2021-12-16 02:02:49,894 - INFO: | epoch  18 |  2100/ 3051 batches | lr 7.09e-06 | ms/batch 60.00 | loss-text 2.8539\n",
      "2021-12-16 02:02:55,919 - INFO: | epoch  18 |  2200/ 3051 batches | lr 7.09e-06 | ms/batch 60.24 | loss-text 2.8944\n",
      "2021-12-16 02:03:01,925 - INFO: | epoch  18 |  2300/ 3051 batches | lr 7.09e-06 | ms/batch 60.06 | loss-text 2.8806\n",
      "2021-12-16 02:03:07,928 - INFO: | epoch  18 |  2400/ 3051 batches | lr 7.09e-06 | ms/batch 60.03 | loss-text 2.9026\n",
      "2021-12-16 02:03:13,964 - INFO: | epoch  18 |  2500/ 3051 batches | lr 7.09e-06 | ms/batch 60.35 | loss-text 2.8789\n",
      "2021-12-16 02:03:19,953 - INFO: | epoch  18 |  2600/ 3051 batches | lr 7.09e-06 | ms/batch 59.88 | loss-text 2.8692\n",
      "2021-12-16 02:03:25,958 - INFO: | epoch  18 |  2700/ 3051 batches | lr 7.09e-06 | ms/batch 60.04 | loss-text 2.8669\n",
      "2021-12-16 02:03:31,927 - INFO: | epoch  18 |  2800/ 3051 batches | lr 7.09e-06 | ms/batch 59.69 | loss-text 2.9059\n",
      "2021-12-16 02:03:37,963 - INFO: | epoch  18 |  2900/ 3051 batches | lr 7.09e-06 | ms/batch 60.35 | loss-text 2.9037\n",
      "2021-12-16 02:03:43,944 - INFO: | epoch  18 |  3000/ 3051 batches | lr 7.09e-06 | ms/batch 59.80 | loss-text 2.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003910\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9962, 'reflen': 10186, 'guess': [9962, 8938, 7914, 6890], 'correct': [5433, 1859, 685, 214]}\n",
      "ratio: 0.9780090320046163\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.318\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.211\n",
      "2021-12-16 02:04:08,309 - INFO: eval_greddy SPIDEr: 0.2112\n",
      "loading annotations into memory...\n",
      "0:00:00.003916\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9318, 'reflen': 9705, 'guess': [9318, 8294, 7270, 6246], 'correct': [5303, 1915, 753, 253]}\n",
      "ratio: 0.9601236476042286\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.358\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-16 02:04:29,518 - INFO: eval_beam_2 SPIDEr: 0.2322\n",
      "loading annotations into memory...\n",
      "0:00:00.003924\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9109, 'reflen': 9603, 'guess': [9109, 8085, 7061, 6037], 'correct': [5174, 1884, 773, 264]}\n",
      "ratio: 0.9485577423720766\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-16 02:04:54,444 - INFO: eval_beam_3 SPIDEr: 0.2311\n",
      "loading annotations into memory...\n",
      "0:00:00.003955\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8904, 'reflen': 9471, 'guess': [8904, 7880, 6856, 5832], 'correct': [5095, 1862, 756, 258]}\n",
      "ratio: 0.940133037693914\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.360\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-16 02:05:23,265 - INFO: eval_beam_4 SPIDEr: 0.2311\n",
      "2021-12-16 02:05:29,464 - INFO: | epoch  19 |   100/ 3051 batches | lr 6.95e-06 | ms/batch 61.96 | loss-text 2.8992\n",
      "2021-12-16 02:05:35,419 - INFO: | epoch  19 |   200/ 3051 batches | lr 6.95e-06 | ms/batch 59.54 | loss-text 2.8823\n",
      "2021-12-16 02:05:41,340 - INFO: | epoch  19 |   300/ 3051 batches | lr 6.95e-06 | ms/batch 59.20 | loss-text 2.9030\n",
      "2021-12-16 02:05:47,313 - INFO: | epoch  19 |   400/ 3051 batches | lr 6.95e-06 | ms/batch 59.72 | loss-text 2.8481\n",
      "2021-12-16 02:05:53,250 - INFO: | epoch  19 |   500/ 3051 batches | lr 6.95e-06 | ms/batch 59.36 | loss-text 2.8910\n",
      "2021-12-16 02:05:59,174 - INFO: | epoch  19 |   600/ 3051 batches | lr 6.95e-06 | ms/batch 59.24 | loss-text 2.8831\n",
      "2021-12-16 02:06:05,167 - INFO: | epoch  19 |   700/ 3051 batches | lr 6.95e-06 | ms/batch 59.92 | loss-text 2.8548\n",
      "2021-12-16 02:06:11,151 - INFO: | epoch  19 |   800/ 3051 batches | lr 6.95e-06 | ms/batch 59.83 | loss-text 2.9011\n",
      "2021-12-16 02:06:17,059 - INFO: | epoch  19 |   900/ 3051 batches | lr 6.95e-06 | ms/batch 59.08 | loss-text 2.9009\n",
      "2021-12-16 02:06:23,068 - INFO: | epoch  19 |  1000/ 3051 batches | lr 6.95e-06 | ms/batch 60.08 | loss-text 2.8976\n",
      "2021-12-16 02:06:29,097 - INFO: | epoch  19 |  1100/ 3051 batches | lr 6.95e-06 | ms/batch 60.29 | loss-text 2.9144\n",
      "2021-12-16 02:06:35,092 - INFO: | epoch  19 |  1200/ 3051 batches | lr 6.95e-06 | ms/batch 59.95 | loss-text 2.8844\n",
      "2021-12-16 02:06:41,146 - INFO: | epoch  19 |  1300/ 3051 batches | lr 6.95e-06 | ms/batch 60.53 | loss-text 2.9075\n",
      "2021-12-16 02:06:47,122 - INFO: | epoch  19 |  1400/ 3051 batches | lr 6.95e-06 | ms/batch 59.75 | loss-text 2.8718\n",
      "2021-12-16 02:06:53,157 - INFO: | epoch  19 |  1500/ 3051 batches | lr 6.95e-06 | ms/batch 60.35 | loss-text 2.9191\n",
      "2021-12-16 02:06:59,189 - INFO: | epoch  19 |  1600/ 3051 batches | lr 6.95e-06 | ms/batch 60.31 | loss-text 2.8929\n",
      "2021-12-16 02:07:05,173 - INFO: | epoch  19 |  1700/ 3051 batches | lr 6.95e-06 | ms/batch 59.83 | loss-text 2.8858\n",
      "2021-12-16 02:07:11,162 - INFO: | epoch  19 |  1800/ 3051 batches | lr 6.95e-06 | ms/batch 59.89 | loss-text 2.8463\n",
      "2021-12-16 02:07:17,136 - INFO: | epoch  19 |  1900/ 3051 batches | lr 6.95e-06 | ms/batch 59.73 | loss-text 2.9055\n",
      "2021-12-16 02:07:23,131 - INFO: | epoch  19 |  2000/ 3051 batches | lr 6.95e-06 | ms/batch 59.95 | loss-text 2.8895\n",
      "2021-12-16 02:07:29,149 - INFO: | epoch  19 |  2100/ 3051 batches | lr 6.95e-06 | ms/batch 60.16 | loss-text 2.9039\n",
      "2021-12-16 02:07:35,186 - INFO: | epoch  19 |  2200/ 3051 batches | lr 6.95e-06 | ms/batch 60.36 | loss-text 2.8633\n",
      "2021-12-16 02:07:41,204 - INFO: | epoch  19 |  2300/ 3051 batches | lr 6.95e-06 | ms/batch 60.18 | loss-text 2.8834\n",
      "2021-12-16 02:07:47,220 - INFO: | epoch  19 |  2400/ 3051 batches | lr 6.95e-06 | ms/batch 60.16 | loss-text 2.9147\n",
      "2021-12-16 02:07:53,204 - INFO: | epoch  19 |  2500/ 3051 batches | lr 6.95e-06 | ms/batch 59.83 | loss-text 2.9066\n",
      "2021-12-16 02:07:59,255 - INFO: | epoch  19 |  2600/ 3051 batches | lr 6.95e-06 | ms/batch 60.51 | loss-text 2.8985\n",
      "2021-12-16 02:08:05,287 - INFO: | epoch  19 |  2700/ 3051 batches | lr 6.95e-06 | ms/batch 60.31 | loss-text 2.8834\n",
      "2021-12-16 02:08:11,296 - INFO: | epoch  19 |  2800/ 3051 batches | lr 6.95e-06 | ms/batch 60.08 | loss-text 2.8709\n",
      "2021-12-16 02:08:17,287 - INFO: | epoch  19 |  2900/ 3051 batches | lr 6.95e-06 | ms/batch 59.91 | loss-text 2.9251\n",
      "2021-12-16 02:08:23,324 - INFO: | epoch  19 |  3000/ 3051 batches | lr 6.95e-06 | ms/batch 60.37 | loss-text 2.8848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003894\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9965, 'reflen': 10205, 'guess': [9965, 8941, 7917, 6893], 'correct': [5411, 1860, 704, 230]}\n",
      "ratio: 0.9764821166094094\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.325\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2021-12-16 02:08:47,266 - INFO: eval_greddy SPIDEr: 0.2152\n",
      "loading annotations into memory...\n",
      "0:00:00.003956\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9267, 'reflen': 9687, 'guess': [9267, 8243, 7219, 6195], 'correct': [5285, 1919, 755, 253]}\n",
      "ratio: 0.9566429235056305\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 02:09:07,661 - INFO: eval_beam_2 SPIDEr: 0.2355\n",
      "loading annotations into memory...\n",
      "0:00:00.003907\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9055, 'reflen': 9558, 'guess': [9055, 8031, 7007, 5983], 'correct': [5178, 1911, 795, 283]}\n",
      "ratio: 0.9473739275998171\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 02:09:35,563 - INFO: eval_beam_3 SPIDEr: 0.2368\n",
      "loading annotations into memory...\n",
      "0:00:00.003937\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8871, 'reflen': 9437, 'guess': [8871, 7847, 6823, 5799], 'correct': [5108, 1893, 780, 268]}\n",
      "ratio: 0.9400233124932775\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 02:10:03,665 - INFO: eval_beam_4 SPIDEr: 0.2348\n",
      "2021-12-16 02:10:09,836 - INFO: | epoch  20 |   100/ 3051 batches | lr 6.81e-06 | ms/batch 61.68 | loss-text 2.8258\n",
      "2021-12-16 02:10:15,799 - INFO: | epoch  20 |   200/ 3051 batches | lr 6.81e-06 | ms/batch 59.62 | loss-text 2.8694\n",
      "2021-12-16 02:10:21,763 - INFO: | epoch  20 |   300/ 3051 batches | lr 6.81e-06 | ms/batch 59.63 | loss-text 2.8557\n",
      "2021-12-16 02:10:27,723 - INFO: | epoch  20 |   400/ 3051 batches | lr 6.81e-06 | ms/batch 59.59 | loss-text 2.8939\n",
      "2021-12-16 02:10:33,737 - INFO: | epoch  20 |   500/ 3051 batches | lr 6.81e-06 | ms/batch 60.14 | loss-text 2.9519\n",
      "2021-12-16 02:10:39,687 - INFO: | epoch  20 |   600/ 3051 batches | lr 6.81e-06 | ms/batch 59.49 | loss-text 2.9035\n",
      "2021-12-16 02:10:45,631 - INFO: | epoch  20 |   700/ 3051 batches | lr 6.81e-06 | ms/batch 59.44 | loss-text 2.8959\n",
      "2021-12-16 02:10:51,630 - INFO: | epoch  20 |   800/ 3051 batches | lr 6.81e-06 | ms/batch 59.98 | loss-text 2.8817\n",
      "2021-12-16 02:10:57,615 - INFO: | epoch  20 |   900/ 3051 batches | lr 6.81e-06 | ms/batch 59.85 | loss-text 2.8725\n",
      "2021-12-16 02:11:03,672 - INFO: | epoch  20 |  1000/ 3051 batches | lr 6.81e-06 | ms/batch 60.56 | loss-text 2.8779\n",
      "2021-12-16 02:11:09,665 - INFO: | epoch  20 |  1100/ 3051 batches | lr 6.81e-06 | ms/batch 59.93 | loss-text 2.8660\n",
      "2021-12-16 02:11:15,646 - INFO: | epoch  20 |  1200/ 3051 batches | lr 6.81e-06 | ms/batch 59.80 | loss-text 2.8833\n",
      "2021-12-16 02:11:21,905 - INFO: | epoch  20 |  1300/ 3051 batches | lr 6.81e-06 | ms/batch 60.12 | loss-text 2.8804\n",
      "2021-12-16 02:11:27,910 - INFO: | epoch  20 |  1400/ 3051 batches | lr 6.81e-06 | ms/batch 60.05 | loss-text 2.8642\n",
      "2021-12-16 02:11:33,831 - INFO: | epoch  20 |  1500/ 3051 batches | lr 6.81e-06 | ms/batch 59.20 | loss-text 2.8943\n",
      "2021-12-16 02:11:39,841 - INFO: | epoch  20 |  1600/ 3051 batches | lr 6.81e-06 | ms/batch 60.10 | loss-text 2.8735\n",
      "2021-12-16 02:11:45,819 - INFO: | epoch  20 |  1700/ 3051 batches | lr 6.81e-06 | ms/batch 59.77 | loss-text 2.9156\n",
      "2021-12-16 02:11:51,825 - INFO: | epoch  20 |  1800/ 3051 batches | lr 6.81e-06 | ms/batch 60.06 | loss-text 2.8663\n",
      "2021-12-16 02:11:57,874 - INFO: | epoch  20 |  1900/ 3051 batches | lr 6.81e-06 | ms/batch 60.48 | loss-text 2.9156\n",
      "2021-12-16 02:12:03,915 - INFO: | epoch  20 |  2000/ 3051 batches | lr 6.81e-06 | ms/batch 60.40 | loss-text 2.8489\n",
      "2021-12-16 02:12:09,952 - INFO: | epoch  20 |  2100/ 3051 batches | lr 6.81e-06 | ms/batch 60.36 | loss-text 2.8401\n",
      "2021-12-16 02:12:15,916 - INFO: | epoch  20 |  2200/ 3051 batches | lr 6.81e-06 | ms/batch 59.63 | loss-text 2.9003\n",
      "2021-12-16 02:12:21,960 - INFO: | epoch  20 |  2300/ 3051 batches | lr 6.81e-06 | ms/batch 60.44 | loss-text 2.8930\n",
      "2021-12-16 02:12:27,971 - INFO: | epoch  20 |  2400/ 3051 batches | lr 6.81e-06 | ms/batch 60.11 | loss-text 2.8938\n",
      "2021-12-16 02:12:33,992 - INFO: | epoch  20 |  2500/ 3051 batches | lr 6.81e-06 | ms/batch 60.20 | loss-text 2.8943\n",
      "2021-12-16 02:12:40,034 - INFO: | epoch  20 |  2600/ 3051 batches | lr 6.81e-06 | ms/batch 60.41 | loss-text 2.9358\n",
      "2021-12-16 02:12:46,007 - INFO: | epoch  20 |  2700/ 3051 batches | lr 6.81e-06 | ms/batch 59.73 | loss-text 2.9039\n",
      "2021-12-16 02:12:51,986 - INFO: | epoch  20 |  2800/ 3051 batches | lr 6.81e-06 | ms/batch 59.78 | loss-text 2.8853\n",
      "2021-12-16 02:12:57,972 - INFO: | epoch  20 |  2900/ 3051 batches | lr 6.81e-06 | ms/batch 59.84 | loss-text 2.9189\n",
      "2021-12-16 02:13:04,035 - INFO: | epoch  20 |  3000/ 3051 batches | lr 6.81e-06 | ms/batch 60.63 | loss-text 2.8936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003905\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10035, 'reflen': 10203, 'guess': [10035, 9011, 7987, 6963], 'correct': [5432, 1842, 691, 221]}\n",
      "ratio: 0.9835342546308945\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.321\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2021-12-16 02:13:30,081 - INFO: eval_greddy SPIDEr: 0.2137\n",
      "loading annotations into memory...\n",
      "0:00:00.003895\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9319, 'reflen': 9703, 'guess': [9319, 8295, 7271, 6247], 'correct': [5296, 1894, 751, 250]}\n",
      "ratio: 0.9604246109449696\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-16 02:13:54,909 - INFO: eval_beam_2 SPIDEr: 0.2332\n",
      "loading annotations into memory...\n",
      "0:00:00.003882\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9066, 'reflen': 9570, 'guess': [9066, 8042, 7018, 5994], 'correct': [5189, 1892, 782, 272]}\n",
      "ratio: 0.9473354231973932\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 02:14:22,864 - INFO: eval_beam_3 SPIDEr: 0.2355\n",
      "loading annotations into memory...\n",
      "0:00:00.003938\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8876, 'reflen': 9456, 'guess': [8876, 7852, 6828, 5804], 'correct': [5106, 1879, 768, 257]}\n",
      "ratio: 0.9386632825718128\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 02:14:51,067 - INFO: eval_beam_4 SPIDEr: 0.2340\n",
      "2021-12-16 02:14:57,260 - INFO: | epoch  21 |   100/ 3051 batches | lr 6.68e-06 | ms/batch 61.90 | loss-text 2.8938\n",
      "2021-12-16 02:15:03,226 - INFO: | epoch  21 |   200/ 3051 batches | lr 6.68e-06 | ms/batch 59.65 | loss-text 2.8647\n",
      "2021-12-16 02:15:09,223 - INFO: | epoch  21 |   300/ 3051 batches | lr 6.68e-06 | ms/batch 59.96 | loss-text 2.8891\n",
      "2021-12-16 02:15:15,173 - INFO: | epoch  21 |   400/ 3051 batches | lr 6.68e-06 | ms/batch 59.50 | loss-text 2.8881\n",
      "2021-12-16 02:15:21,135 - INFO: | epoch  21 |   500/ 3051 batches | lr 6.68e-06 | ms/batch 59.61 | loss-text 2.9121\n",
      "2021-12-16 02:15:27,109 - INFO: | epoch  21 |   600/ 3051 batches | lr 6.68e-06 | ms/batch 59.73 | loss-text 2.8480\n",
      "2021-12-16 02:15:33,123 - INFO: | epoch  21 |   700/ 3051 batches | lr 6.68e-06 | ms/batch 60.13 | loss-text 2.8697\n",
      "2021-12-16 02:15:39,078 - INFO: | epoch  21 |   800/ 3051 batches | lr 6.68e-06 | ms/batch 59.55 | loss-text 2.8394\n",
      "2021-12-16 02:15:45,039 - INFO: | epoch  21 |   900/ 3051 batches | lr 6.68e-06 | ms/batch 59.59 | loss-text 2.8595\n",
      "2021-12-16 02:15:51,009 - INFO: | epoch  21 |  1000/ 3051 batches | lr 6.68e-06 | ms/batch 59.70 | loss-text 2.8973\n",
      "2021-12-16 02:15:56,986 - INFO: | epoch  21 |  1100/ 3051 batches | lr 6.68e-06 | ms/batch 59.76 | loss-text 2.8621\n",
      "2021-12-16 02:16:02,993 - INFO: | epoch  21 |  1200/ 3051 batches | lr 6.68e-06 | ms/batch 60.07 | loss-text 2.8650\n",
      "2021-12-16 02:16:09,020 - INFO: | epoch  21 |  1300/ 3051 batches | lr 6.68e-06 | ms/batch 60.26 | loss-text 2.8724\n",
      "2021-12-16 02:16:15,036 - INFO: | epoch  21 |  1400/ 3051 batches | lr 6.68e-06 | ms/batch 60.15 | loss-text 2.9179\n",
      "2021-12-16 02:16:21,002 - INFO: | epoch  21 |  1500/ 3051 batches | lr 6.68e-06 | ms/batch 59.65 | loss-text 2.9190\n",
      "2021-12-16 02:16:27,006 - INFO: | epoch  21 |  1600/ 3051 batches | lr 6.68e-06 | ms/batch 60.04 | loss-text 2.9032\n",
      "2021-12-16 02:16:32,953 - INFO: | epoch  21 |  1700/ 3051 batches | lr 6.68e-06 | ms/batch 59.46 | loss-text 2.8468\n",
      "2021-12-16 02:16:38,929 - INFO: | epoch  21 |  1800/ 3051 batches | lr 6.68e-06 | ms/batch 59.75 | loss-text 2.8898\n",
      "2021-12-16 02:16:44,955 - INFO: | epoch  21 |  1900/ 3051 batches | lr 6.68e-06 | ms/batch 60.26 | loss-text 2.8912\n",
      "2021-12-16 02:16:50,943 - INFO: | epoch  21 |  2000/ 3051 batches | lr 6.68e-06 | ms/batch 59.88 | loss-text 2.9135\n",
      "2021-12-16 02:16:56,917 - INFO: | epoch  21 |  2100/ 3051 batches | lr 6.68e-06 | ms/batch 59.73 | loss-text 2.8887\n",
      "2021-12-16 02:17:02,924 - INFO: | epoch  21 |  2200/ 3051 batches | lr 6.68e-06 | ms/batch 60.06 | loss-text 2.9018\n",
      "2021-12-16 02:17:08,944 - INFO: | epoch  21 |  2300/ 3051 batches | lr 6.68e-06 | ms/batch 60.20 | loss-text 2.8950\n",
      "2021-12-16 02:17:14,953 - INFO: | epoch  21 |  2400/ 3051 batches | lr 6.68e-06 | ms/batch 60.09 | loss-text 2.8919\n",
      "2021-12-16 02:17:21,020 - INFO: | epoch  21 |  2500/ 3051 batches | lr 6.68e-06 | ms/batch 60.66 | loss-text 2.9171\n",
      "2021-12-16 02:17:27,023 - INFO: | epoch  21 |  2600/ 3051 batches | lr 6.68e-06 | ms/batch 60.02 | loss-text 2.8829\n",
      "2021-12-16 02:17:33,002 - INFO: | epoch  21 |  2700/ 3051 batches | lr 6.68e-06 | ms/batch 59.79 | loss-text 2.8516\n",
      "2021-12-16 02:17:39,003 - INFO: | epoch  21 |  2800/ 3051 batches | lr 6.68e-06 | ms/batch 60.00 | loss-text 2.8640\n",
      "2021-12-16 02:17:45,040 - INFO: | epoch  21 |  2900/ 3051 batches | lr 6.68e-06 | ms/batch 60.37 | loss-text 2.8562\n",
      "2021-12-16 02:17:51,021 - INFO: | epoch  21 |  3000/ 3051 batches | lr 6.68e-06 | ms/batch 59.79 | loss-text 2.8823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004072\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10038, 'reflen': 10236, 'guess': [10038, 9014, 7990, 6966], 'correct': [5446, 1833, 680, 214]}\n",
      "ratio: 0.9806565064477354\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.326\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.318\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.211\n",
      "2021-12-16 02:18:16,107 - INFO: eval_greddy SPIDEr: 0.2112\n",
      "loading annotations into memory...\n",
      "0:00:00.003977\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9323, 'reflen': 9718, 'guess': [9323, 8299, 7275, 6251], 'correct': [5316, 1910, 759, 245]}\n",
      "ratio: 0.9593537764971228\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 02:18:40,470 - INFO: eval_beam_2 SPIDEr: 0.2359\n",
      "loading annotations into memory...\n",
      "0:00:00.003815\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9078, 'reflen': 9576, 'guess': [9078, 8054, 7030, 6006], 'correct': [5202, 1909, 801, 278]}\n",
      "ratio: 0.9479949874685727\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 02:19:04,079 - INFO: eval_beam_3 SPIDEr: 0.2384\n",
      "loading annotations into memory...\n",
      "0:00:00.003975\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8852, 'reflen': 9445, 'guess': [8852, 7828, 6804, 5780], 'correct': [5100, 1884, 781, 262]}\n",
      "ratio: 0.9372154579141411\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 02:19:32,040 - INFO: eval_beam_4 SPIDEr: 0.2370\n",
      "2021-12-16 02:19:38,208 - INFO: | epoch  22 |   100/ 3051 batches | lr 6.54e-06 | ms/batch 61.65 | loss-text 2.8804\n",
      "2021-12-16 02:19:44,147 - INFO: | epoch  22 |   200/ 3051 batches | lr 6.54e-06 | ms/batch 59.38 | loss-text 2.8955\n",
      "2021-12-16 02:19:50,072 - INFO: | epoch  22 |   300/ 3051 batches | lr 6.54e-06 | ms/batch 59.25 | loss-text 2.8648\n",
      "2021-12-16 02:19:56,085 - INFO: | epoch  22 |   400/ 3051 batches | lr 6.54e-06 | ms/batch 60.12 | loss-text 2.8151\n",
      "2021-12-16 02:20:02,057 - INFO: | epoch  22 |   500/ 3051 batches | lr 6.54e-06 | ms/batch 59.71 | loss-text 2.9008\n",
      "2021-12-16 02:20:08,061 - INFO: | epoch  22 |   600/ 3051 batches | lr 6.54e-06 | ms/batch 60.04 | loss-text 2.8697\n",
      "2021-12-16 02:20:14,021 - INFO: | epoch  22 |   700/ 3051 batches | lr 6.54e-06 | ms/batch 59.60 | loss-text 2.8778\n",
      "2021-12-16 02:20:19,976 - INFO: | epoch  22 |   800/ 3051 batches | lr 6.54e-06 | ms/batch 59.54 | loss-text 2.8778\n",
      "2021-12-16 02:20:25,988 - INFO: | epoch  22 |   900/ 3051 batches | lr 6.54e-06 | ms/batch 60.12 | loss-text 2.8864\n",
      "2021-12-16 02:20:31,956 - INFO: | epoch  22 |  1000/ 3051 batches | lr 6.54e-06 | ms/batch 59.67 | loss-text 2.9012\n",
      "2021-12-16 02:20:37,926 - INFO: | epoch  22 |  1100/ 3051 batches | lr 6.54e-06 | ms/batch 59.69 | loss-text 2.8733\n",
      "2021-12-16 02:20:43,962 - INFO: | epoch  22 |  1200/ 3051 batches | lr 6.54e-06 | ms/batch 60.36 | loss-text 2.8633\n",
      "2021-12-16 02:20:49,936 - INFO: | epoch  22 |  1300/ 3051 batches | lr 6.54e-06 | ms/batch 59.73 | loss-text 2.8534\n",
      "2021-12-16 02:20:55,881 - INFO: | epoch  22 |  1400/ 3051 batches | lr 6.54e-06 | ms/batch 59.44 | loss-text 2.9235\n",
      "2021-12-16 02:21:01,858 - INFO: | epoch  22 |  1500/ 3051 batches | lr 6.54e-06 | ms/batch 59.77 | loss-text 2.8618\n",
      "2021-12-16 02:21:07,912 - INFO: | epoch  22 |  1600/ 3051 batches | lr 6.54e-06 | ms/batch 60.54 | loss-text 2.9498\n",
      "2021-12-16 02:21:13,904 - INFO: | epoch  22 |  1700/ 3051 batches | lr 6.54e-06 | ms/batch 59.91 | loss-text 2.8681\n",
      "2021-12-16 02:21:19,939 - INFO: | epoch  22 |  1800/ 3051 batches | lr 6.54e-06 | ms/batch 60.35 | loss-text 2.9098\n",
      "2021-12-16 02:21:25,926 - INFO: | epoch  22 |  1900/ 3051 batches | lr 6.54e-06 | ms/batch 59.86 | loss-text 2.8795\n",
      "2021-12-16 02:21:31,936 - INFO: | epoch  22 |  2000/ 3051 batches | lr 6.54e-06 | ms/batch 60.10 | loss-text 2.9126\n",
      "2021-12-16 02:21:37,963 - INFO: | epoch  22 |  2100/ 3051 batches | lr 6.54e-06 | ms/batch 60.26 | loss-text 2.8999\n",
      "2021-12-16 02:21:43,981 - INFO: | epoch  22 |  2200/ 3051 batches | lr 6.54e-06 | ms/batch 60.18 | loss-text 2.8797\n",
      "2021-12-16 02:21:49,933 - INFO: | epoch  22 |  2300/ 3051 batches | lr 6.54e-06 | ms/batch 59.50 | loss-text 2.8686\n",
      "2021-12-16 02:21:55,987 - INFO: | epoch  22 |  2400/ 3051 batches | lr 6.54e-06 | ms/batch 60.54 | loss-text 2.8852\n",
      "2021-12-16 02:22:02,038 - INFO: | epoch  22 |  2500/ 3051 batches | lr 6.54e-06 | ms/batch 60.49 | loss-text 2.9172\n",
      "2021-12-16 02:22:08,059 - INFO: | epoch  22 |  2600/ 3051 batches | lr 6.54e-06 | ms/batch 60.21 | loss-text 2.8763\n",
      "2021-12-16 02:22:14,073 - INFO: | epoch  22 |  2700/ 3051 batches | lr 6.54e-06 | ms/batch 60.13 | loss-text 2.8599\n",
      "2021-12-16 02:22:20,072 - INFO: | epoch  22 |  2800/ 3051 batches | lr 6.54e-06 | ms/batch 59.99 | loss-text 2.8501\n",
      "2021-12-16 02:22:26,055 - INFO: | epoch  22 |  2900/ 3051 batches | lr 6.54e-06 | ms/batch 59.83 | loss-text 2.8921\n",
      "2021-12-16 02:22:32,043 - INFO: | epoch  22 |  3000/ 3051 batches | lr 6.54e-06 | ms/batch 59.87 | loss-text 2.8983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003841\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10049, 'reflen': 10242, 'guess': [10049, 9025, 8001, 6977], 'correct': [5495, 1895, 720, 235]}\n",
      "ratio: 0.9811560242139249\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.329\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2021-12-16 02:22:57,168 - INFO: eval_greddy SPIDEr: 0.2174\n",
      "loading annotations into memory...\n",
      "0:00:00.003995\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9341, 'reflen': 9747, 'guess': [9341, 8317, 7293, 6269], 'correct': [5302, 1894, 742, 249]}\n",
      "ratio: 0.9583461577920428\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.357\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-16 02:23:21,432 - INFO: eval_beam_2 SPIDEr: 0.2320\n",
      "loading annotations into memory...\n",
      "0:00:00.004039\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9088, 'reflen': 9598, 'guess': [9088, 8064, 7040, 6016], 'correct': [5189, 1888, 783, 272]}\n",
      "ratio: 0.9468639299853149\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-16 02:23:45,815 - INFO: eval_beam_3 SPIDEr: 0.2330\n",
      "loading annotations into memory...\n",
      "0:00:00.003867\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8877, 'reflen': 9464, 'guess': [8877, 7853, 6829, 5805], 'correct': [5091, 1847, 771, 269]}\n",
      "ratio: 0.93797548605231\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 02:24:17,542 - INFO: eval_beam_4 SPIDEr: 0.2345\n",
      "2021-12-16 02:24:23,756 - INFO: | epoch  23 |   100/ 3051 batches | lr 6.41e-06 | ms/batch 62.11 | loss-text 2.8908\n",
      "2021-12-16 02:24:29,734 - INFO: | epoch  23 |   200/ 3051 batches | lr 6.41e-06 | ms/batch 59.77 | loss-text 2.9282\n",
      "2021-12-16 02:24:35,687 - INFO: | epoch  23 |   300/ 3051 batches | lr 6.41e-06 | ms/batch 59.52 | loss-text 2.8847\n",
      "2021-12-16 02:24:41,644 - INFO: | epoch  23 |   400/ 3051 batches | lr 6.41e-06 | ms/batch 59.57 | loss-text 2.8706\n",
      "2021-12-16 02:24:47,583 - INFO: | epoch  23 |   500/ 3051 batches | lr 6.41e-06 | ms/batch 59.38 | loss-text 2.8523\n",
      "2021-12-16 02:24:53,536 - INFO: | epoch  23 |   600/ 3051 batches | lr 6.41e-06 | ms/batch 59.52 | loss-text 2.8504\n",
      "2021-12-16 02:24:59,488 - INFO: | epoch  23 |   700/ 3051 batches | lr 6.41e-06 | ms/batch 59.52 | loss-text 2.8662\n",
      "2021-12-16 02:25:05,436 - INFO: | epoch  23 |   800/ 3051 batches | lr 6.41e-06 | ms/batch 59.48 | loss-text 2.8721\n",
      "2021-12-16 02:25:11,483 - INFO: | epoch  23 |   900/ 3051 batches | lr 6.41e-06 | ms/batch 60.46 | loss-text 2.8575\n",
      "2021-12-16 02:25:17,491 - INFO: | epoch  23 |  1000/ 3051 batches | lr 6.41e-06 | ms/batch 60.08 | loss-text 2.8973\n",
      "2021-12-16 02:25:23,394 - INFO: | epoch  23 |  1100/ 3051 batches | lr 6.41e-06 | ms/batch 59.02 | loss-text 2.8571\n",
      "2021-12-16 02:25:29,318 - INFO: | epoch  23 |  1200/ 3051 batches | lr 6.41e-06 | ms/batch 59.24 | loss-text 2.8990\n",
      "2021-12-16 02:25:35,350 - INFO: | epoch  23 |  1300/ 3051 batches | lr 6.41e-06 | ms/batch 60.31 | loss-text 2.8618\n",
      "2021-12-16 02:25:41,397 - INFO: | epoch  23 |  1400/ 3051 batches | lr 6.41e-06 | ms/batch 60.47 | loss-text 2.8938\n",
      "2021-12-16 02:25:47,397 - INFO: | epoch  23 |  1500/ 3051 batches | lr 6.41e-06 | ms/batch 59.99 | loss-text 2.8609\n",
      "2021-12-16 02:25:53,421 - INFO: | epoch  23 |  1600/ 3051 batches | lr 6.41e-06 | ms/batch 60.24 | loss-text 2.8592\n",
      "2021-12-16 02:25:59,430 - INFO: | epoch  23 |  1700/ 3051 batches | lr 6.41e-06 | ms/batch 60.08 | loss-text 2.8448\n",
      "2021-12-16 02:26:05,391 - INFO: | epoch  23 |  1800/ 3051 batches | lr 6.41e-06 | ms/batch 59.60 | loss-text 2.8635\n",
      "2021-12-16 02:26:11,311 - INFO: | epoch  23 |  1900/ 3051 batches | lr 6.41e-06 | ms/batch 59.19 | loss-text 2.8938\n",
      "2021-12-16 02:26:17,364 - INFO: | epoch  23 |  2000/ 3051 batches | lr 6.41e-06 | ms/batch 60.52 | loss-text 2.8860\n",
      "2021-12-16 02:26:23,405 - INFO: | epoch  23 |  2100/ 3051 batches | lr 6.41e-06 | ms/batch 60.41 | loss-text 2.8609\n",
      "2021-12-16 02:26:29,390 - INFO: | epoch  23 |  2200/ 3051 batches | lr 6.41e-06 | ms/batch 59.85 | loss-text 2.8960\n",
      "2021-12-16 02:26:35,439 - INFO: | epoch  23 |  2300/ 3051 batches | lr 6.41e-06 | ms/batch 60.48 | loss-text 2.9116\n",
      "2021-12-16 02:26:41,482 - INFO: | epoch  23 |  2400/ 3051 batches | lr 6.41e-06 | ms/batch 60.43 | loss-text 2.8653\n",
      "2021-12-16 02:26:47,490 - INFO: | epoch  23 |  2500/ 3051 batches | lr 6.41e-06 | ms/batch 60.07 | loss-text 2.8803\n",
      "2021-12-16 02:26:53,535 - INFO: | epoch  23 |  2600/ 3051 batches | lr 6.41e-06 | ms/batch 60.44 | loss-text 2.9224\n",
      "2021-12-16 02:26:59,599 - INFO: | epoch  23 |  2700/ 3051 batches | lr 6.41e-06 | ms/batch 60.64 | loss-text 2.8732\n",
      "2021-12-16 02:27:05,650 - INFO: | epoch  23 |  2800/ 3051 batches | lr 6.41e-06 | ms/batch 60.50 | loss-text 2.9129\n",
      "2021-12-16 02:27:11,665 - INFO: | epoch  23 |  2900/ 3051 batches | lr 6.41e-06 | ms/batch 60.14 | loss-text 2.8371\n",
      "2021-12-16 02:27:17,701 - INFO: | epoch  23 |  3000/ 3051 batches | lr 6.41e-06 | ms/batch 60.35 | loss-text 2.9134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003839\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10082, 'reflen': 10280, 'guess': [10082, 9058, 8034, 7010], 'correct': [5424, 1843, 683, 221]}\n",
      "ratio: 0.9807392996107995\n",
      "Bleu_1: 0.528\n",
      "Bleu_2: 0.324\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.322\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2021-12-16 02:27:41,721 - INFO: eval_greddy SPIDEr: 0.2135\n",
      "loading annotations into memory...\n",
      "0:00:00.004068\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9301, 'reflen': 9730, 'guess': [9301, 8277, 7253, 6229], 'correct': [5277, 1917, 756, 256]}\n",
      "ratio: 0.9559095580677331\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-16 02:28:03,075 - INFO: eval_beam_2 SPIDEr: 0.2327\n",
      "loading annotations into memory...\n",
      "0:00:00.003917\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9068, 'reflen': 9579, 'guess': [9068, 8044, 7020, 5996], 'correct': [5190, 1921, 798, 285]}\n",
      "ratio: 0.9466541392628722\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 02:28:28,055 - INFO: eval_beam_3 SPIDEr: 0.2394\n",
      "loading annotations into memory...\n",
      "0:00:00.003904\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8843, 'reflen': 9446, 'guess': [8843, 7819, 6795, 5771], 'correct': [5100, 1907, 795, 282]}\n",
      "ratio: 0.9361634554307711\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 02:28:56,324 - INFO: eval_beam_4 SPIDEr: 0.2381\n",
      "2021-12-16 02:29:02,552 - INFO: | epoch  24 |   100/ 3051 batches | lr 6.28e-06 | ms/batch 62.24 | loss-text 2.8559\n",
      "2021-12-16 02:29:08,523 - INFO: | epoch  24 |   200/ 3051 batches | lr 6.28e-06 | ms/batch 59.71 | loss-text 2.8620\n",
      "2021-12-16 02:29:14,466 - INFO: | epoch  24 |   300/ 3051 batches | lr 6.28e-06 | ms/batch 59.42 | loss-text 2.8773\n",
      "2021-12-16 02:29:20,509 - INFO: | epoch  24 |   400/ 3051 batches | lr 6.28e-06 | ms/batch 60.43 | loss-text 2.9291\n",
      "2021-12-16 02:29:26,484 - INFO: | epoch  24 |   500/ 3051 batches | lr 6.28e-06 | ms/batch 59.74 | loss-text 2.8905\n",
      "2021-12-16 02:29:32,486 - INFO: | epoch  24 |   600/ 3051 batches | lr 6.28e-06 | ms/batch 60.01 | loss-text 2.8864\n",
      "2021-12-16 02:29:38,495 - INFO: | epoch  24 |   700/ 3051 batches | lr 6.28e-06 | ms/batch 60.08 | loss-text 2.8756\n",
      "2021-12-16 02:29:44,473 - INFO: | epoch  24 |   800/ 3051 batches | lr 6.28e-06 | ms/batch 59.77 | loss-text 2.8793\n",
      "2021-12-16 02:29:50,439 - INFO: | epoch  24 |   900/ 3051 batches | lr 6.28e-06 | ms/batch 59.66 | loss-text 2.8880\n",
      "2021-12-16 02:29:56,454 - INFO: | epoch  24 |  1000/ 3051 batches | lr 6.28e-06 | ms/batch 60.14 | loss-text 2.9200\n",
      "2021-12-16 02:30:02,459 - INFO: | epoch  24 |  1100/ 3051 batches | lr 6.28e-06 | ms/batch 60.05 | loss-text 2.8789\n",
      "2021-12-16 02:30:08,442 - INFO: | epoch  24 |  1200/ 3051 batches | lr 6.28e-06 | ms/batch 59.83 | loss-text 2.8914\n",
      "2021-12-16 02:30:14,450 - INFO: | epoch  24 |  1300/ 3051 batches | lr 6.28e-06 | ms/batch 60.08 | loss-text 2.8676\n",
      "2021-12-16 02:30:20,452 - INFO: | epoch  24 |  1400/ 3051 batches | lr 6.28e-06 | ms/batch 60.02 | loss-text 2.8520\n",
      "2021-12-16 02:30:26,414 - INFO: | epoch  24 |  1500/ 3051 batches | lr 6.28e-06 | ms/batch 59.61 | loss-text 2.8714\n",
      "2021-12-16 02:30:32,374 - INFO: | epoch  24 |  1600/ 3051 batches | lr 6.28e-06 | ms/batch 59.59 | loss-text 2.8670\n",
      "2021-12-16 02:30:38,396 - INFO: | epoch  24 |  1700/ 3051 batches | lr 6.28e-06 | ms/batch 60.22 | loss-text 2.8823\n",
      "2021-12-16 02:30:44,359 - INFO: | epoch  24 |  1800/ 3051 batches | lr 6.28e-06 | ms/batch 59.63 | loss-text 2.8628\n",
      "2021-12-16 02:30:50,374 - INFO: | epoch  24 |  1900/ 3051 batches | lr 6.28e-06 | ms/batch 60.14 | loss-text 2.8650\n",
      "2021-12-16 02:30:56,399 - INFO: | epoch  24 |  2000/ 3051 batches | lr 6.28e-06 | ms/batch 60.24 | loss-text 2.8545\n",
      "2021-12-16 02:31:02,370 - INFO: | epoch  24 |  2100/ 3051 batches | lr 6.28e-06 | ms/batch 59.70 | loss-text 2.8923\n",
      "2021-12-16 02:31:08,406 - INFO: | epoch  24 |  2200/ 3051 batches | lr 6.28e-06 | ms/batch 60.36 | loss-text 2.8900\n",
      "2021-12-16 02:31:14,463 - INFO: | epoch  24 |  2300/ 3051 batches | lr 6.28e-06 | ms/batch 60.56 | loss-text 2.8658\n",
      "2021-12-16 02:31:20,506 - INFO: | epoch  24 |  2400/ 3051 batches | lr 6.28e-06 | ms/batch 60.43 | loss-text 2.8482\n",
      "2021-12-16 02:31:26,494 - INFO: | epoch  24 |  2500/ 3051 batches | lr 6.28e-06 | ms/batch 59.88 | loss-text 2.8762\n",
      "2021-12-16 02:31:32,525 - INFO: | epoch  24 |  2600/ 3051 batches | lr 6.28e-06 | ms/batch 60.30 | loss-text 2.8767\n",
      "2021-12-16 02:31:38,522 - INFO: | epoch  24 |  2700/ 3051 batches | lr 6.28e-06 | ms/batch 59.96 | loss-text 2.9128\n",
      "2021-12-16 02:31:44,592 - INFO: | epoch  24 |  2800/ 3051 batches | lr 6.28e-06 | ms/batch 60.70 | loss-text 2.8886\n",
      "2021-12-16 02:31:50,644 - INFO: | epoch  24 |  2900/ 3051 batches | lr 6.28e-06 | ms/batch 60.51 | loss-text 2.9238\n",
      "2021-12-16 02:31:56,652 - INFO: | epoch  24 |  3000/ 3051 batches | lr 6.28e-06 | ms/batch 60.07 | loss-text 2.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003802\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9984, 'reflen': 10189, 'guess': [9984, 8960, 7936, 6912], 'correct': [5450, 1848, 675, 208]}\n",
      "ratio: 0.9798802630286603\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.322\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.213\n",
      "2021-12-16 02:32:22,754 - INFO: eval_greddy SPIDEr: 0.2132\n",
      "loading annotations into memory...\n",
      "0:00:00.003932\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9254, 'reflen': 9683, 'guess': [9254, 8230, 7206, 6182], 'correct': [5305, 1913, 750, 251]}\n",
      "ratio: 0.9556955489000355\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 02:32:47,214 - INFO: eval_beam_2 SPIDEr: 0.2369\n",
      "loading annotations into memory...\n",
      "0:00:00.003972\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9054, 'reflen': 9566, 'guess': [9054, 8030, 7006, 5982], 'correct': [5161, 1893, 777, 273]}\n",
      "ratio: 0.9464771064184667\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 02:33:11,011 - INFO: eval_beam_3 SPIDEr: 0.2355\n",
      "loading annotations into memory...\n",
      "0:00:00.003957\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8823, 'reflen': 9440, 'guess': [8823, 7799, 6775, 5751], 'correct': [5114, 1915, 794, 273]}\n",
      "ratio: 0.9346398305083755\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 02:33:39,716 - INFO: eval_beam_4 SPIDEr: 0.2379\n",
      "2021-12-16 02:33:45,930 - INFO: | epoch  25 |   100/ 3051 batches | lr 6.16e-06 | ms/batch 62.11 | loss-text 2.8658\n",
      "2021-12-16 02:33:51,869 - INFO: | epoch  25 |   200/ 3051 batches | lr 6.16e-06 | ms/batch 59.37 | loss-text 2.8979\n",
      "2021-12-16 02:33:57,895 - INFO: | epoch  25 |   300/ 3051 batches | lr 6.16e-06 | ms/batch 60.26 | loss-text 2.8905\n",
      "2021-12-16 02:34:03,850 - INFO: | epoch  25 |   400/ 3051 batches | lr 6.16e-06 | ms/batch 59.54 | loss-text 2.8798\n",
      "2021-12-16 02:34:09,806 - INFO: | epoch  25 |   500/ 3051 batches | lr 6.16e-06 | ms/batch 59.55 | loss-text 2.8872\n",
      "2021-12-16 02:34:15,785 - INFO: | epoch  25 |   600/ 3051 batches | lr 6.16e-06 | ms/batch 59.79 | loss-text 2.8654\n",
      "2021-12-16 02:34:21,732 - INFO: | epoch  25 |   700/ 3051 batches | lr 6.16e-06 | ms/batch 59.47 | loss-text 2.8296\n",
      "2021-12-16 02:34:27,686 - INFO: | epoch  25 |   800/ 3051 batches | lr 6.16e-06 | ms/batch 59.53 | loss-text 2.8588\n",
      "2021-12-16 02:34:33,648 - INFO: | epoch  25 |   900/ 3051 batches | lr 6.16e-06 | ms/batch 59.62 | loss-text 2.8764\n",
      "2021-12-16 02:34:39,679 - INFO: | epoch  25 |  1000/ 3051 batches | lr 6.16e-06 | ms/batch 60.31 | loss-text 2.8737\n",
      "2021-12-16 02:34:45,639 - INFO: | epoch  25 |  1100/ 3051 batches | lr 6.16e-06 | ms/batch 59.59 | loss-text 2.8654\n",
      "2021-12-16 02:34:51,638 - INFO: | epoch  25 |  1200/ 3051 batches | lr 6.16e-06 | ms/batch 59.98 | loss-text 2.8828\n",
      "2021-12-16 02:34:57,607 - INFO: | epoch  25 |  1300/ 3051 batches | lr 6.16e-06 | ms/batch 59.68 | loss-text 2.8920\n",
      "2021-12-16 02:35:03,592 - INFO: | epoch  25 |  1400/ 3051 batches | lr 6.16e-06 | ms/batch 59.85 | loss-text 2.8697\n",
      "2021-12-16 02:35:09,605 - INFO: | epoch  25 |  1500/ 3051 batches | lr 6.16e-06 | ms/batch 60.12 | loss-text 2.8932\n",
      "2021-12-16 02:35:15,623 - INFO: | epoch  25 |  1600/ 3051 batches | lr 6.16e-06 | ms/batch 60.18 | loss-text 2.8851\n",
      "2021-12-16 02:35:21,707 - INFO: | epoch  25 |  1700/ 3051 batches | lr 6.16e-06 | ms/batch 60.83 | loss-text 2.8887\n",
      "2021-12-16 02:35:27,732 - INFO: | epoch  25 |  1800/ 3051 batches | lr 6.16e-06 | ms/batch 60.24 | loss-text 2.8769\n",
      "2021-12-16 02:35:33,739 - INFO: | epoch  25 |  1900/ 3051 batches | lr 6.16e-06 | ms/batch 60.06 | loss-text 2.8535\n",
      "2021-12-16 02:35:39,748 - INFO: | epoch  25 |  2000/ 3051 batches | lr 6.16e-06 | ms/batch 60.08 | loss-text 2.8507\n",
      "2021-12-16 02:35:45,745 - INFO: | epoch  25 |  2100/ 3051 batches | lr 6.16e-06 | ms/batch 59.96 | loss-text 2.8796\n",
      "2021-12-16 02:35:51,747 - INFO: | epoch  25 |  2200/ 3051 batches | lr 6.16e-06 | ms/batch 60.02 | loss-text 2.8992\n",
      "2021-12-16 02:35:57,782 - INFO: | epoch  25 |  2300/ 3051 batches | lr 6.16e-06 | ms/batch 60.34 | loss-text 2.9059\n",
      "2021-12-16 02:36:03,769 - INFO: | epoch  25 |  2400/ 3051 batches | lr 6.16e-06 | ms/batch 59.86 | loss-text 2.8619\n",
      "2021-12-16 02:36:09,759 - INFO: | epoch  25 |  2500/ 3051 batches | lr 6.16e-06 | ms/batch 59.89 | loss-text 2.8656\n",
      "2021-12-16 02:36:15,748 - INFO: | epoch  25 |  2600/ 3051 batches | lr 6.16e-06 | ms/batch 59.89 | loss-text 2.9365\n",
      "2021-12-16 02:36:21,829 - INFO: | epoch  25 |  2700/ 3051 batches | lr 6.16e-06 | ms/batch 60.80 | loss-text 2.8706\n",
      "2021-12-16 02:36:27,853 - INFO: | epoch  25 |  2800/ 3051 batches | lr 6.16e-06 | ms/batch 60.23 | loss-text 2.8665\n",
      "2021-12-16 02:36:33,794 - INFO: | epoch  25 |  2900/ 3051 batches | lr 6.16e-06 | ms/batch 59.41 | loss-text 2.9098\n",
      "2021-12-16 02:36:39,804 - INFO: | epoch  25 |  3000/ 3051 batches | lr 6.16e-06 | ms/batch 60.09 | loss-text 2.8932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003864\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9969, 'reflen': 10191, 'guess': [9969, 8945, 7921, 6897], 'correct': [5431, 1853, 689, 221]}\n",
      "ratio: 0.9782160730054972\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2021-12-16 02:37:05,517 - INFO: eval_greddy SPIDEr: 0.2147\n",
      "loading annotations into memory...\n",
      "0:00:00.004465\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9305, 'reflen': 9720, 'guess': [9305, 8281, 7257, 6233], 'correct': [5291, 1898, 745, 242]}\n",
      "ratio: 0.9573045267488727\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.360\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 02:37:31,073 - INFO: eval_beam_2 SPIDEr: 0.2340\n",
      "loading annotations into memory...\n",
      "0:00:00.004016\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9075, 'reflen': 9595, 'guess': [9075, 8051, 7027, 6003], 'correct': [5173, 1880, 774, 264]}\n",
      "ratio: 0.9458051068263735\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 02:37:56,872 - INFO: eval_beam_3 SPIDEr: 0.2358\n",
      "loading annotations into memory...\n",
      "0:00:00.003802\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8857, 'reflen': 9451, 'guess': [8857, 7833, 6809, 5785], 'correct': [5109, 1886, 785, 272]}\n",
      "ratio: 0.9371495079884734\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 02:38:24,616 - INFO: eval_beam_4 SPIDEr: 0.2363\n",
      "2021-12-16 02:38:30,789 - INFO: | epoch  26 |   100/ 3051 batches | lr 6.03e-06 | ms/batch 61.70 | loss-text 2.8346\n",
      "2021-12-16 02:38:36,759 - INFO: | epoch  26 |   200/ 3051 batches | lr 6.03e-06 | ms/batch 59.69 | loss-text 2.8995\n",
      "2021-12-16 02:38:42,716 - INFO: | epoch  26 |   300/ 3051 batches | lr 6.03e-06 | ms/batch 59.57 | loss-text 2.8683\n",
      "2021-12-16 02:38:48,741 - INFO: | epoch  26 |   400/ 3051 batches | lr 6.03e-06 | ms/batch 60.22 | loss-text 2.8567\n",
      "2021-12-16 02:38:54,696 - INFO: | epoch  26 |   500/ 3051 batches | lr 6.03e-06 | ms/batch 59.55 | loss-text 2.9023\n",
      "2021-12-16 02:39:00,650 - INFO: | epoch  26 |   600/ 3051 batches | lr 6.03e-06 | ms/batch 59.53 | loss-text 2.8531\n",
      "2021-12-16 02:39:06,694 - INFO: | epoch  26 |   700/ 3051 batches | lr 6.03e-06 | ms/batch 60.43 | loss-text 2.8570\n",
      "2021-12-16 02:39:12,602 - INFO: | epoch  26 |   800/ 3051 batches | lr 6.03e-06 | ms/batch 59.07 | loss-text 2.8631\n",
      "2021-12-16 02:39:18,634 - INFO: | epoch  26 |   900/ 3051 batches | lr 6.03e-06 | ms/batch 60.32 | loss-text 2.8957\n",
      "2021-12-16 02:39:24,599 - INFO: | epoch  26 |  1000/ 3051 batches | lr 6.03e-06 | ms/batch 59.64 | loss-text 2.8826\n",
      "2021-12-16 02:39:30,607 - INFO: | epoch  26 |  1100/ 3051 batches | lr 6.03e-06 | ms/batch 60.07 | loss-text 2.8872\n",
      "2021-12-16 02:39:36,611 - INFO: | epoch  26 |  1200/ 3051 batches | lr 6.03e-06 | ms/batch 60.04 | loss-text 2.8557\n",
      "2021-12-16 02:39:42,586 - INFO: | epoch  26 |  1300/ 3051 batches | lr 6.03e-06 | ms/batch 59.75 | loss-text 2.8491\n",
      "2021-12-16 02:39:48,589 - INFO: | epoch  26 |  1400/ 3051 batches | lr 6.03e-06 | ms/batch 60.02 | loss-text 2.8984\n",
      "2021-12-16 02:39:54,548 - INFO: | epoch  26 |  1500/ 3051 batches | lr 6.03e-06 | ms/batch 59.58 | loss-text 2.8783\n",
      "2021-12-16 02:40:00,551 - INFO: | epoch  26 |  1600/ 3051 batches | lr 6.03e-06 | ms/batch 60.03 | loss-text 2.8734\n",
      "2021-12-16 02:40:06,549 - INFO: | epoch  26 |  1700/ 3051 batches | lr 6.03e-06 | ms/batch 59.97 | loss-text 2.8460\n",
      "2021-12-16 02:40:12,527 - INFO: | epoch  26 |  1800/ 3051 batches | lr 6.03e-06 | ms/batch 59.78 | loss-text 2.8594\n",
      "2021-12-16 02:40:18,533 - INFO: | epoch  26 |  1900/ 3051 batches | lr 6.03e-06 | ms/batch 60.06 | loss-text 2.9163\n",
      "2021-12-16 02:40:24,490 - INFO: | epoch  26 |  2000/ 3051 batches | lr 6.03e-06 | ms/batch 59.56 | loss-text 2.8523\n",
      "2021-12-16 02:40:30,450 - INFO: | epoch  26 |  2100/ 3051 batches | lr 6.03e-06 | ms/batch 59.60 | loss-text 2.8937\n",
      "2021-12-16 02:40:36,467 - INFO: | epoch  26 |  2200/ 3051 batches | lr 6.03e-06 | ms/batch 60.16 | loss-text 2.8627\n",
      "2021-12-16 02:40:42,473 - INFO: | epoch  26 |  2300/ 3051 batches | lr 6.03e-06 | ms/batch 60.06 | loss-text 2.8954\n",
      "2021-12-16 02:40:48,429 - INFO: | epoch  26 |  2400/ 3051 batches | lr 6.03e-06 | ms/batch 59.55 | loss-text 2.8321\n",
      "2021-12-16 02:40:54,469 - INFO: | epoch  26 |  2500/ 3051 batches | lr 6.03e-06 | ms/batch 60.39 | loss-text 2.8756\n",
      "2021-12-16 02:41:00,463 - INFO: | epoch  26 |  2600/ 3051 batches | lr 6.03e-06 | ms/batch 59.93 | loss-text 2.8606\n",
      "2021-12-16 02:41:06,480 - INFO: | epoch  26 |  2700/ 3051 batches | lr 6.03e-06 | ms/batch 60.16 | loss-text 2.9088\n",
      "2021-12-16 02:41:12,525 - INFO: | epoch  26 |  2800/ 3051 batches | lr 6.03e-06 | ms/batch 60.45 | loss-text 2.8730\n",
      "2021-12-16 02:41:18,592 - INFO: | epoch  26 |  2900/ 3051 batches | lr 6.03e-06 | ms/batch 60.66 | loss-text 2.8830\n",
      "2021-12-16 02:41:24,640 - INFO: | epoch  26 |  3000/ 3051 batches | lr 6.03e-06 | ms/batch 60.47 | loss-text 2.8778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003917\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10055, 'reflen': 10219, 'guess': [10055, 9031, 8007, 6983], 'correct': [5476, 1859, 694, 220]}\n",
      "ratio: 0.9839514629610545\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.323\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2021-12-16 02:41:49,283 - INFO: eval_greddy SPIDEr: 0.2148\n",
      "loading annotations into memory...\n",
      "0:00:00.004049\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9322, 'reflen': 9705, 'guess': [9322, 8298, 7274, 6250], 'correct': [5304, 1900, 745, 248]}\n",
      "ratio: 0.9605358062853209\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-16 02:42:14,321 - INFO: eval_beam_2 SPIDEr: 0.2326\n",
      "loading annotations into memory...\n",
      "0:00:00.003894\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9069, 'reflen': 9590, 'guess': [9069, 8045, 7021, 5997], 'correct': [5177, 1879, 771, 272]}\n",
      "ratio: 0.9456725755994843\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-16 02:42:38,552 - INFO: eval_beam_3 SPIDEr: 0.2331\n",
      "loading annotations into memory...\n",
      "0:00:00.003933\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8862, 'reflen': 9465, 'guess': [8862, 7838, 6814, 5790], 'correct': [5088, 1865, 780, 275]}\n",
      "ratio: 0.9362916006338154\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 02:43:07,115 - INFO: eval_beam_4 SPIDEr: 0.2345\n",
      "2021-12-16 02:43:13,390 - INFO: | epoch  27 |   100/ 3051 batches | lr 5.91e-06 | ms/batch 62.72 | loss-text 2.8206\n",
      "2021-12-16 02:43:19,365 - INFO: | epoch  27 |   200/ 3051 batches | lr 5.91e-06 | ms/batch 59.74 | loss-text 2.8694\n",
      "2021-12-16 02:43:25,341 - INFO: | epoch  27 |   300/ 3051 batches | lr 5.91e-06 | ms/batch 59.75 | loss-text 2.8512\n",
      "2021-12-16 02:43:31,273 - INFO: | epoch  27 |   400/ 3051 batches | lr 5.91e-06 | ms/batch 59.32 | loss-text 2.8700\n",
      "2021-12-16 02:43:37,201 - INFO: | epoch  27 |   500/ 3051 batches | lr 5.91e-06 | ms/batch 59.27 | loss-text 2.8977\n",
      "2021-12-16 02:43:43,090 - INFO: | epoch  27 |   600/ 3051 batches | lr 5.91e-06 | ms/batch 58.89 | loss-text 2.8861\n",
      "2021-12-16 02:43:49,020 - INFO: | epoch  27 |   700/ 3051 batches | lr 5.91e-06 | ms/batch 59.29 | loss-text 2.8820\n",
      "2021-12-16 02:43:54,991 - INFO: | epoch  27 |   800/ 3051 batches | lr 5.91e-06 | ms/batch 59.70 | loss-text 2.8551\n",
      "2021-12-16 02:44:00,990 - INFO: | epoch  27 |   900/ 3051 batches | lr 5.91e-06 | ms/batch 59.99 | loss-text 2.8717\n",
      "2021-12-16 02:44:07,026 - INFO: | epoch  27 |  1000/ 3051 batches | lr 5.91e-06 | ms/batch 60.35 | loss-text 2.8994\n",
      "2021-12-16 02:44:12,996 - INFO: | epoch  27 |  1100/ 3051 batches | lr 5.91e-06 | ms/batch 59.69 | loss-text 2.9033\n",
      "2021-12-16 02:44:18,964 - INFO: | epoch  27 |  1200/ 3051 batches | lr 5.91e-06 | ms/batch 59.68 | loss-text 2.9296\n",
      "2021-12-16 02:44:24,961 - INFO: | epoch  27 |  1300/ 3051 batches | lr 5.91e-06 | ms/batch 59.96 | loss-text 2.8583\n",
      "2021-12-16 02:44:30,921 - INFO: | epoch  27 |  1400/ 3051 batches | lr 5.91e-06 | ms/batch 59.60 | loss-text 2.8690\n",
      "2021-12-16 02:44:36,944 - INFO: | epoch  27 |  1500/ 3051 batches | lr 5.91e-06 | ms/batch 60.22 | loss-text 2.8833\n",
      "2021-12-16 02:44:42,914 - INFO: | epoch  27 |  1600/ 3051 batches | lr 5.91e-06 | ms/batch 59.69 | loss-text 2.8645\n",
      "2021-12-16 02:44:48,917 - INFO: | epoch  27 |  1700/ 3051 batches | lr 5.91e-06 | ms/batch 60.03 | loss-text 2.8618\n",
      "2021-12-16 02:44:54,930 - INFO: | epoch  27 |  1800/ 3051 batches | lr 5.91e-06 | ms/batch 60.12 | loss-text 2.9281\n",
      "2021-12-16 02:45:00,971 - INFO: | epoch  27 |  1900/ 3051 batches | lr 5.91e-06 | ms/batch 60.41 | loss-text 2.8583\n",
      "2021-12-16 02:45:07,005 - INFO: | epoch  27 |  2000/ 3051 batches | lr 5.91e-06 | ms/batch 60.33 | loss-text 2.8836\n",
      "2021-12-16 02:45:13,032 - INFO: | epoch  27 |  2100/ 3051 batches | lr 5.91e-06 | ms/batch 60.26 | loss-text 2.8695\n",
      "2021-12-16 02:45:19,039 - INFO: | epoch  27 |  2200/ 3051 batches | lr 5.91e-06 | ms/batch 60.07 | loss-text 2.7996\n",
      "2021-12-16 02:45:25,094 - INFO: | epoch  27 |  2300/ 3051 batches | lr 5.91e-06 | ms/batch 60.54 | loss-text 2.8425\n",
      "2021-12-16 02:45:31,133 - INFO: | epoch  27 |  2400/ 3051 batches | lr 5.91e-06 | ms/batch 60.38 | loss-text 2.9078\n",
      "2021-12-16 02:45:37,137 - INFO: | epoch  27 |  2500/ 3051 batches | lr 5.91e-06 | ms/batch 60.04 | loss-text 2.8733\n",
      "2021-12-16 02:45:43,214 - INFO: | epoch  27 |  2600/ 3051 batches | lr 5.91e-06 | ms/batch 60.77 | loss-text 2.8697\n",
      "2021-12-16 02:45:49,171 - INFO: | epoch  27 |  2700/ 3051 batches | lr 5.91e-06 | ms/batch 59.56 | loss-text 2.8939\n",
      "2021-12-16 02:45:55,169 - INFO: | epoch  27 |  2800/ 3051 batches | lr 5.91e-06 | ms/batch 59.98 | loss-text 2.8394\n",
      "2021-12-16 02:46:01,217 - INFO: | epoch  27 |  2900/ 3051 batches | lr 5.91e-06 | ms/batch 60.47 | loss-text 2.8745\n",
      "2021-12-16 02:46:07,238 - INFO: | epoch  27 |  3000/ 3051 batches | lr 5.91e-06 | ms/batch 60.20 | loss-text 2.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003940\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10015, 'reflen': 10203, 'guess': [10015, 8991, 7967, 6943], 'correct': [5486, 1855, 697, 219]}\n",
      "ratio: 0.9815740468488697\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.325\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-16 02:46:33,003 - INFO: eval_greddy SPIDEr: 0.2160\n",
      "loading annotations into memory...\n",
      "0:00:00.003947\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9324, 'reflen': 9724, 'guess': [9324, 8300, 7276, 6252], 'correct': [5320, 1923, 756, 252]}\n",
      "ratio: 0.958864664746919\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 02:46:58,002 - INFO: eval_beam_2 SPIDEr: 0.2362\n",
      "loading annotations into memory...\n",
      "0:00:00.003978\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9073, 'reflen': 9567, 'guess': [9073, 8049, 7025, 6001], 'correct': [5195, 1925, 800, 285]}\n",
      "ratio: 0.9483641684957721\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 02:47:25,109 - INFO: eval_beam_3 SPIDEr: 0.2386\n",
      "loading annotations into memory...\n",
      "0:00:00.003804\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8856, 'reflen': 9435, 'guess': [8856, 7832, 6808, 5784], 'correct': [5130, 1882, 775, 266]}\n",
      "ratio: 0.9386327503973567\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 02:47:52,887 - INFO: eval_beam_4 SPIDEr: 0.2388\n",
      "2021-12-16 02:47:59,049 - INFO: | epoch  28 |   100/ 3051 batches | lr 5.80e-06 | ms/batch 61.59 | loss-text 2.8607\n",
      "2021-12-16 02:48:05,007 - INFO: | epoch  28 |   200/ 3051 batches | lr 5.80e-06 | ms/batch 59.57 | loss-text 2.9106\n",
      "2021-12-16 02:48:10,927 - INFO: | epoch  28 |   300/ 3051 batches | lr 5.80e-06 | ms/batch 59.20 | loss-text 2.8494\n",
      "2021-12-16 02:48:16,894 - INFO: | epoch  28 |   400/ 3051 batches | lr 5.80e-06 | ms/batch 59.66 | loss-text 2.8804\n",
      "2021-12-16 02:48:22,850 - INFO: | epoch  28 |   500/ 3051 batches | lr 5.80e-06 | ms/batch 59.55 | loss-text 2.8432\n",
      "2021-12-16 02:48:28,728 - INFO: | epoch  28 |   600/ 3051 batches | lr 5.80e-06 | ms/batch 58.77 | loss-text 2.8321\n",
      "2021-12-16 02:48:34,688 - INFO: | epoch  28 |   700/ 3051 batches | lr 5.80e-06 | ms/batch 59.59 | loss-text 2.8997\n",
      "2021-12-16 02:48:40,643 - INFO: | epoch  28 |   800/ 3051 batches | lr 5.80e-06 | ms/batch 59.55 | loss-text 2.8987\n",
      "2021-12-16 02:48:46,664 - INFO: | epoch  28 |   900/ 3051 batches | lr 5.80e-06 | ms/batch 60.20 | loss-text 2.8680\n",
      "2021-12-16 02:48:52,671 - INFO: | epoch  28 |  1000/ 3051 batches | lr 5.80e-06 | ms/batch 60.06 | loss-text 2.8548\n",
      "2021-12-16 02:48:58,675 - INFO: | epoch  28 |  1100/ 3051 batches | lr 5.80e-06 | ms/batch 60.03 | loss-text 2.8979\n",
      "2021-12-16 02:49:04,676 - INFO: | epoch  28 |  1200/ 3051 batches | lr 5.80e-06 | ms/batch 60.00 | loss-text 2.9030\n",
      "2021-12-16 02:49:10,681 - INFO: | epoch  28 |  1300/ 3051 batches | lr 5.80e-06 | ms/batch 60.05 | loss-text 2.8252\n",
      "2021-12-16 02:49:16,661 - INFO: | epoch  28 |  1400/ 3051 batches | lr 5.80e-06 | ms/batch 59.79 | loss-text 2.9057\n",
      "2021-12-16 02:49:22,637 - INFO: | epoch  28 |  1500/ 3051 batches | lr 5.80e-06 | ms/batch 59.76 | loss-text 2.8483\n",
      "2021-12-16 02:49:28,664 - INFO: | epoch  28 |  1600/ 3051 batches | lr 5.80e-06 | ms/batch 60.26 | loss-text 2.8283\n",
      "2021-12-16 02:49:34,668 - INFO: | epoch  28 |  1700/ 3051 batches | lr 5.80e-06 | ms/batch 60.03 | loss-text 2.8782\n",
      "2021-12-16 02:49:40,655 - INFO: | epoch  28 |  1800/ 3051 batches | lr 5.80e-06 | ms/batch 59.86 | loss-text 2.8966\n",
      "2021-12-16 02:49:46,655 - INFO: | epoch  28 |  1900/ 3051 batches | lr 5.80e-06 | ms/batch 59.99 | loss-text 2.8624\n",
      "2021-12-16 02:49:52,620 - INFO: | epoch  28 |  2000/ 3051 batches | lr 5.80e-06 | ms/batch 59.65 | loss-text 2.8771\n",
      "2021-12-16 02:49:58,629 - INFO: | epoch  28 |  2100/ 3051 batches | lr 5.80e-06 | ms/batch 60.08 | loss-text 2.8921\n",
      "2021-12-16 02:50:04,646 - INFO: | epoch  28 |  2200/ 3051 batches | lr 5.80e-06 | ms/batch 60.17 | loss-text 2.8554\n",
      "2021-12-16 02:50:10,661 - INFO: | epoch  28 |  2300/ 3051 batches | lr 5.80e-06 | ms/batch 60.14 | loss-text 2.8700\n",
      "2021-12-16 02:50:16,644 - INFO: | epoch  28 |  2400/ 3051 batches | lr 5.80e-06 | ms/batch 59.82 | loss-text 2.8668\n",
      "2021-12-16 02:50:22,623 - INFO: | epoch  28 |  2500/ 3051 batches | lr 5.80e-06 | ms/batch 59.78 | loss-text 2.8857\n",
      "2021-12-16 02:50:28,589 - INFO: | epoch  28 |  2600/ 3051 batches | lr 5.80e-06 | ms/batch 59.66 | loss-text 2.8650\n",
      "2021-12-16 02:50:34,614 - INFO: | epoch  28 |  2700/ 3051 batches | lr 5.80e-06 | ms/batch 60.24 | loss-text 2.8896\n",
      "2021-12-16 02:50:40,635 - INFO: | epoch  28 |  2800/ 3051 batches | lr 5.80e-06 | ms/batch 60.20 | loss-text 2.8782\n",
      "2021-12-16 02:50:46,655 - INFO: | epoch  28 |  2900/ 3051 batches | lr 5.80e-06 | ms/batch 60.20 | loss-text 2.8750\n",
      "2021-12-16 02:50:52,700 - INFO: | epoch  28 |  3000/ 3051 batches | lr 5.80e-06 | ms/batch 60.44 | loss-text 2.9129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003937\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10042, 'reflen': 10268, 'guess': [10042, 9018, 7994, 6970], 'correct': [5472, 1883, 700, 219]}\n",
      "ratio: 0.9779898714451716\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.327\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2021-12-16 02:51:17,814 - INFO: eval_greddy SPIDEr: 0.2166\n",
      "loading annotations into memory...\n",
      "0:00:00.003925\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9309, 'reflen': 9719, 'guess': [9309, 8285, 7261, 6237], 'correct': [5281, 1930, 757, 255]}\n",
      "ratio: 0.9578145899782943\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 02:51:42,555 - INFO: eval_beam_2 SPIDEr: 0.2337\n",
      "loading annotations into memory...\n",
      "0:00:00.003804\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9069, 'reflen': 9578, 'guess': [9069, 8045, 7021, 5997], 'correct': [5156, 1891, 780, 270]}\n",
      "ratio: 0.9468573814991702\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.360\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-16 02:52:06,970 - INFO: eval_beam_3 SPIDEr: 0.2314\n",
      "loading annotations into memory...\n",
      "0:00:00.003897\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8902, 'reflen': 9472, 'guess': [8902, 7878, 6854, 5830], 'correct': [5123, 1900, 786, 262]}\n",
      "ratio: 0.9398226351350358\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 02:52:35,136 - INFO: eval_beam_4 SPIDEr: 0.2369\n",
      "2021-12-16 02:52:41,261 - INFO: | epoch  29 |   100/ 3051 batches | lr 5.68e-06 | ms/batch 61.22 | loss-text 2.9013\n",
      "2021-12-16 02:52:47,255 - INFO: | epoch  29 |   200/ 3051 batches | lr 5.68e-06 | ms/batch 59.92 | loss-text 2.8856\n",
      "2021-12-16 02:52:53,171 - INFO: | epoch  29 |   300/ 3051 batches | lr 5.68e-06 | ms/batch 59.16 | loss-text 2.8638\n",
      "2021-12-16 02:52:59,128 - INFO: | epoch  29 |   400/ 3051 batches | lr 5.68e-06 | ms/batch 59.56 | loss-text 2.8133\n",
      "2021-12-16 02:53:05,039 - INFO: | epoch  29 |   500/ 3051 batches | lr 5.68e-06 | ms/batch 59.11 | loss-text 2.8578\n",
      "2021-12-16 02:53:11,054 - INFO: | epoch  29 |   600/ 3051 batches | lr 5.68e-06 | ms/batch 60.15 | loss-text 2.8953\n",
      "2021-12-16 02:53:16,993 - INFO: | epoch  29 |   700/ 3051 batches | lr 5.68e-06 | ms/batch 59.38 | loss-text 2.8705\n",
      "2021-12-16 02:53:22,961 - INFO: | epoch  29 |   800/ 3051 batches | lr 5.68e-06 | ms/batch 59.68 | loss-text 2.8888\n",
      "2021-12-16 02:53:28,944 - INFO: | epoch  29 |   900/ 3051 batches | lr 5.68e-06 | ms/batch 59.82 | loss-text 2.8303\n",
      "2021-12-16 02:53:34,927 - INFO: | epoch  29 |  1000/ 3051 batches | lr 5.68e-06 | ms/batch 59.83 | loss-text 2.8689\n",
      "2021-12-16 02:53:40,875 - INFO: | epoch  29 |  1100/ 3051 batches | lr 5.68e-06 | ms/batch 59.48 | loss-text 2.8667\n",
      "2021-12-16 02:53:46,859 - INFO: | epoch  29 |  1200/ 3051 batches | lr 5.68e-06 | ms/batch 59.83 | loss-text 2.8852\n",
      "2021-12-16 02:53:52,841 - INFO: | epoch  29 |  1300/ 3051 batches | lr 5.68e-06 | ms/batch 59.81 | loss-text 2.8832\n",
      "2021-12-16 02:53:58,848 - INFO: | epoch  29 |  1400/ 3051 batches | lr 5.68e-06 | ms/batch 60.06 | loss-text 2.8847\n",
      "2021-12-16 02:54:04,893 - INFO: | epoch  29 |  1500/ 3051 batches | lr 5.68e-06 | ms/batch 60.45 | loss-text 2.9061\n",
      "2021-12-16 02:54:10,958 - INFO: | epoch  29 |  1600/ 3051 batches | lr 5.68e-06 | ms/batch 60.64 | loss-text 2.8442\n",
      "2021-12-16 02:54:16,962 - INFO: | epoch  29 |  1700/ 3051 batches | lr 5.68e-06 | ms/batch 60.03 | loss-text 2.8675\n",
      "2021-12-16 02:54:22,928 - INFO: | epoch  29 |  1800/ 3051 batches | lr 5.68e-06 | ms/batch 59.65 | loss-text 2.9196\n",
      "2021-12-16 02:54:28,892 - INFO: | epoch  29 |  1900/ 3051 batches | lr 5.68e-06 | ms/batch 59.63 | loss-text 2.8675\n",
      "2021-12-16 02:54:34,895 - INFO: | epoch  29 |  2000/ 3051 batches | lr 5.68e-06 | ms/batch 60.03 | loss-text 2.8541\n",
      "2021-12-16 02:54:40,873 - INFO: | epoch  29 |  2100/ 3051 batches | lr 5.68e-06 | ms/batch 59.77 | loss-text 2.8743\n",
      "2021-12-16 02:54:46,877 - INFO: | epoch  29 |  2200/ 3051 batches | lr 5.68e-06 | ms/batch 60.04 | loss-text 2.8438\n",
      "2021-12-16 02:54:52,910 - INFO: | epoch  29 |  2300/ 3051 batches | lr 5.68e-06 | ms/batch 60.32 | loss-text 2.9042\n",
      "2021-12-16 02:54:58,974 - INFO: | epoch  29 |  2400/ 3051 batches | lr 5.68e-06 | ms/batch 60.63 | loss-text 2.8660\n",
      "2021-12-16 02:55:05,021 - INFO: | epoch  29 |  2500/ 3051 batches | lr 5.68e-06 | ms/batch 60.46 | loss-text 2.8533\n",
      "2021-12-16 02:55:10,985 - INFO: | epoch  29 |  2600/ 3051 batches | lr 5.68e-06 | ms/batch 59.62 | loss-text 2.8605\n",
      "2021-12-16 02:55:17,013 - INFO: | epoch  29 |  2700/ 3051 batches | lr 5.68e-06 | ms/batch 60.27 | loss-text 2.8768\n",
      "2021-12-16 02:55:23,024 - INFO: | epoch  29 |  2800/ 3051 batches | lr 5.68e-06 | ms/batch 60.10 | loss-text 2.8771\n",
      "2021-12-16 02:55:28,985 - INFO: | epoch  29 |  2900/ 3051 batches | lr 5.68e-06 | ms/batch 59.60 | loss-text 2.8528\n",
      "2021-12-16 02:55:35,003 - INFO: | epoch  29 |  3000/ 3051 batches | lr 5.68e-06 | ms/batch 60.17 | loss-text 2.8469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004031\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10039, 'reflen': 10225, 'guess': [10039, 9015, 7991, 6967], 'correct': [5489, 1888, 701, 216]}\n",
      "ratio: 0.9818092909534492\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.329\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.218\n",
      "2021-12-16 02:56:01,393 - INFO: eval_greddy SPIDEr: 0.2180\n",
      "loading annotations into memory...\n",
      "0:00:00.003848\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9302, 'reflen': 9695, 'guess': [9302, 8278, 7254, 6230], 'correct': [5269, 1892, 743, 242]}\n",
      "ratio: 0.9594636410519897\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 02:56:26,256 - INFO: eval_beam_2 SPIDEr: 0.2351\n",
      "loading annotations into memory...\n",
      "0:00:00.003997\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9110, 'reflen': 9597, 'guess': [9110, 8086, 7062, 6038], 'correct': [5193, 1871, 769, 259]}\n",
      "ratio: 0.9492549755130822\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 02:56:51,062 - INFO: eval_beam_3 SPIDEr: 0.2343\n",
      "loading annotations into memory...\n",
      "0:00:00.004003\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8891, 'reflen': 9454, 'guess': [8891, 7867, 6843, 5819], 'correct': [5148, 1878, 787, 275]}\n",
      "ratio: 0.9404484874126359\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 02:57:24,009 - INFO: eval_beam_4 SPIDEr: 0.2394\n",
      "2021-12-16 02:57:30,190 - INFO: | epoch  30 |   100/ 3051 batches | lr 5.57e-06 | ms/batch 61.78 | loss-text 2.8308\n",
      "2021-12-16 02:57:36,133 - INFO: | epoch  30 |   200/ 3051 batches | lr 5.57e-06 | ms/batch 59.42 | loss-text 2.8699\n",
      "2021-12-16 02:57:42,104 - INFO: | epoch  30 |   300/ 3051 batches | lr 5.57e-06 | ms/batch 59.70 | loss-text 2.8680\n",
      "2021-12-16 02:57:48,043 - INFO: | epoch  30 |   400/ 3051 batches | lr 5.57e-06 | ms/batch 59.38 | loss-text 2.9004\n",
      "2021-12-16 02:57:53,957 - INFO: | epoch  30 |   500/ 3051 batches | lr 5.57e-06 | ms/batch 59.14 | loss-text 2.8580\n",
      "2021-12-16 02:57:59,918 - INFO: | epoch  30 |   600/ 3051 batches | lr 5.57e-06 | ms/batch 59.60 | loss-text 2.8860\n",
      "2021-12-16 02:58:05,900 - INFO: | epoch  30 |   700/ 3051 batches | lr 5.57e-06 | ms/batch 59.82 | loss-text 2.8703\n",
      "2021-12-16 02:58:11,846 - INFO: | epoch  30 |   800/ 3051 batches | lr 5.57e-06 | ms/batch 59.45 | loss-text 2.8477\n",
      "2021-12-16 02:58:17,824 - INFO: | epoch  30 |   900/ 3051 batches | lr 5.57e-06 | ms/batch 59.77 | loss-text 2.8484\n",
      "2021-12-16 02:58:23,793 - INFO: | epoch  30 |  1000/ 3051 batches | lr 5.57e-06 | ms/batch 59.68 | loss-text 2.8692\n",
      "2021-12-16 02:58:29,782 - INFO: | epoch  30 |  1100/ 3051 batches | lr 5.57e-06 | ms/batch 59.89 | loss-text 2.9017\n",
      "2021-12-16 02:58:35,753 - INFO: | epoch  30 |  1200/ 3051 batches | lr 5.57e-06 | ms/batch 59.71 | loss-text 2.8840\n",
      "2021-12-16 02:58:41,799 - INFO: | epoch  30 |  1300/ 3051 batches | lr 5.57e-06 | ms/batch 60.45 | loss-text 2.8913\n",
      "2021-12-16 02:58:47,823 - INFO: | epoch  30 |  1400/ 3051 batches | lr 5.57e-06 | ms/batch 60.23 | loss-text 2.8596\n",
      "2021-12-16 02:58:53,779 - INFO: | epoch  30 |  1500/ 3051 batches | lr 5.57e-06 | ms/batch 59.55 | loss-text 2.8435\n",
      "2021-12-16 02:58:59,766 - INFO: | epoch  30 |  1600/ 3051 batches | lr 5.57e-06 | ms/batch 59.86 | loss-text 2.9129\n",
      "2021-12-16 02:59:05,800 - INFO: | epoch  30 |  1700/ 3051 batches | lr 5.57e-06 | ms/batch 60.34 | loss-text 2.8650\n",
      "2021-12-16 02:59:11,787 - INFO: | epoch  30 |  1800/ 3051 batches | lr 5.57e-06 | ms/batch 59.86 | loss-text 2.8517\n",
      "2021-12-16 02:59:17,760 - INFO: | epoch  30 |  1900/ 3051 batches | lr 5.57e-06 | ms/batch 59.72 | loss-text 2.8440\n",
      "2021-12-16 02:59:23,761 - INFO: | epoch  30 |  2000/ 3051 batches | lr 5.57e-06 | ms/batch 60.00 | loss-text 2.8677\n",
      "2021-12-16 02:59:29,751 - INFO: | epoch  30 |  2100/ 3051 batches | lr 5.57e-06 | ms/batch 59.89 | loss-text 2.8694\n",
      "2021-12-16 02:59:35,782 - INFO: | epoch  30 |  2200/ 3051 batches | lr 5.57e-06 | ms/batch 60.31 | loss-text 2.8782\n",
      "2021-12-16 02:59:41,836 - INFO: | epoch  30 |  2300/ 3051 batches | lr 5.57e-06 | ms/batch 60.53 | loss-text 2.8532\n",
      "2021-12-16 02:59:47,835 - INFO: | epoch  30 |  2400/ 3051 batches | lr 5.57e-06 | ms/batch 59.99 | loss-text 2.8861\n",
      "2021-12-16 02:59:53,853 - INFO: | epoch  30 |  2500/ 3051 batches | lr 5.57e-06 | ms/batch 60.17 | loss-text 2.9141\n",
      "2021-12-16 02:59:59,849 - INFO: | epoch  30 |  2600/ 3051 batches | lr 5.57e-06 | ms/batch 59.95 | loss-text 2.8636\n",
      "2021-12-16 03:00:05,801 - INFO: | epoch  30 |  2700/ 3051 batches | lr 5.57e-06 | ms/batch 59.51 | loss-text 2.8499\n",
      "2021-12-16 03:00:11,787 - INFO: | epoch  30 |  2800/ 3051 batches | lr 5.57e-06 | ms/batch 59.86 | loss-text 2.8647\n",
      "2021-12-16 03:00:17,766 - INFO: | epoch  30 |  2900/ 3051 batches | lr 5.57e-06 | ms/batch 59.78 | loss-text 2.8639\n",
      "2021-12-16 03:00:23,824 - INFO: | epoch  30 |  3000/ 3051 batches | lr 5.57e-06 | ms/batch 60.57 | loss-text 2.8897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003556\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9983, 'reflen': 10213, 'guess': [9983, 8959, 7935, 6911], 'correct': [5455, 1874, 699, 210]}\n",
      "ratio: 0.9774796827571743\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.325\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-16 03:00:48,945 - INFO: eval_greddy SPIDEr: 0.2159\n",
      "loading annotations into memory...\n",
      "0:00:00.003896\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9281, 'reflen': 9676, 'guess': [9281, 8257, 7233, 6209], 'correct': [5250, 1885, 737, 244]}\n",
      "ratio: 0.9591773460106491\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.358\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-16 03:01:13,163 - INFO: eval_beam_2 SPIDEr: 0.2323\n",
      "loading annotations into memory...\n",
      "0:00:00.003946\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9079, 'reflen': 9582, 'guess': [9079, 8055, 7031, 6007], 'correct': [5182, 1904, 795, 281]}\n",
      "ratio: 0.9475057399289347\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 03:01:40,342 - INFO: eval_beam_3 SPIDEr: 0.2370\n",
      "loading annotations into memory...\n",
      "0:00:00.003867\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8881, 'reflen': 9456, 'guess': [8881, 7857, 6833, 5809], 'correct': [5108, 1879, 772, 271]}\n",
      "ratio: 0.9391920473772272\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 03:02:08,472 - INFO: eval_beam_4 SPIDEr: 0.2354\n",
      "2021-12-16 03:02:14,601 - INFO: | epoch  31 |   100/ 3051 batches | lr 5.45e-06 | ms/batch 61.27 | loss-text 2.8398\n",
      "2021-12-16 03:02:20,571 - INFO: | epoch  31 |   200/ 3051 batches | lr 5.45e-06 | ms/batch 59.69 | loss-text 2.8933\n",
      "2021-12-16 03:02:26,515 - INFO: | epoch  31 |   300/ 3051 batches | lr 5.45e-06 | ms/batch 59.43 | loss-text 2.8185\n",
      "2021-12-16 03:02:32,394 - INFO: | epoch  31 |   400/ 3051 batches | lr 5.45e-06 | ms/batch 58.78 | loss-text 2.8680\n",
      "2021-12-16 03:02:38,342 - INFO: | epoch  31 |   500/ 3051 batches | lr 5.45e-06 | ms/batch 59.47 | loss-text 2.8656\n",
      "2021-12-16 03:02:44,304 - INFO: | epoch  31 |   600/ 3051 batches | lr 5.45e-06 | ms/batch 59.61 | loss-text 2.8924\n",
      "2021-12-16 03:02:50,231 - INFO: | epoch  31 |   700/ 3051 batches | lr 5.45e-06 | ms/batch 59.27 | loss-text 2.8690\n",
      "2021-12-16 03:02:56,170 - INFO: | epoch  31 |   800/ 3051 batches | lr 5.45e-06 | ms/batch 59.39 | loss-text 2.8665\n",
      "2021-12-16 03:03:02,203 - INFO: | epoch  31 |   900/ 3051 batches | lr 5.45e-06 | ms/batch 60.32 | loss-text 2.8479\n",
      "2021-12-16 03:03:08,191 - INFO: | epoch  31 |  1000/ 3051 batches | lr 5.45e-06 | ms/batch 59.88 | loss-text 2.8632\n",
      "2021-12-16 03:03:14,165 - INFO: | epoch  31 |  1100/ 3051 batches | lr 5.45e-06 | ms/batch 59.73 | loss-text 2.8643\n",
      "2021-12-16 03:03:20,164 - INFO: | epoch  31 |  1200/ 3051 batches | lr 5.45e-06 | ms/batch 59.98 | loss-text 2.8777\n",
      "2021-12-16 03:03:26,142 - INFO: | epoch  31 |  1300/ 3051 batches | lr 5.45e-06 | ms/batch 59.78 | loss-text 2.8667\n",
      "2021-12-16 03:03:32,132 - INFO: | epoch  31 |  1400/ 3051 batches | lr 5.45e-06 | ms/batch 59.88 | loss-text 2.8296\n",
      "2021-12-16 03:03:38,141 - INFO: | epoch  31 |  1500/ 3051 batches | lr 5.45e-06 | ms/batch 60.09 | loss-text 2.9087\n",
      "2021-12-16 03:03:44,118 - INFO: | epoch  31 |  1600/ 3051 batches | lr 5.45e-06 | ms/batch 59.76 | loss-text 2.8438\n",
      "2021-12-16 03:03:50,105 - INFO: | epoch  31 |  1700/ 3051 batches | lr 5.45e-06 | ms/batch 59.87 | loss-text 2.8522\n",
      "2021-12-16 03:03:56,116 - INFO: | epoch  31 |  1800/ 3051 batches | lr 5.45e-06 | ms/batch 60.10 | loss-text 2.8514\n",
      "2021-12-16 03:04:02,160 - INFO: | epoch  31 |  1900/ 3051 batches | lr 5.45e-06 | ms/batch 60.44 | loss-text 2.8481\n",
      "2021-12-16 03:04:08,172 - INFO: | epoch  31 |  2000/ 3051 batches | lr 5.45e-06 | ms/batch 60.11 | loss-text 2.8299\n",
      "2021-12-16 03:04:14,145 - INFO: | epoch  31 |  2100/ 3051 batches | lr 5.45e-06 | ms/batch 59.72 | loss-text 2.9083\n",
      "2021-12-16 03:04:20,159 - INFO: | epoch  31 |  2200/ 3051 batches | lr 5.45e-06 | ms/batch 60.13 | loss-text 2.8584\n",
      "2021-12-16 03:04:26,207 - INFO: | epoch  31 |  2300/ 3051 batches | lr 5.45e-06 | ms/batch 60.47 | loss-text 2.9061\n",
      "2021-12-16 03:04:32,195 - INFO: | epoch  31 |  2400/ 3051 batches | lr 5.45e-06 | ms/batch 59.87 | loss-text 2.8492\n",
      "2021-12-16 03:04:38,248 - INFO: | epoch  31 |  2500/ 3051 batches | lr 5.45e-06 | ms/batch 60.52 | loss-text 2.8672\n",
      "2021-12-16 03:04:44,286 - INFO: | epoch  31 |  2600/ 3051 batches | lr 5.45e-06 | ms/batch 60.37 | loss-text 2.8888\n",
      "2021-12-16 03:04:50,301 - INFO: | epoch  31 |  2700/ 3051 batches | lr 5.45e-06 | ms/batch 60.15 | loss-text 2.8746\n",
      "2021-12-16 03:04:56,296 - INFO: | epoch  31 |  2800/ 3051 batches | lr 5.45e-06 | ms/batch 59.95 | loss-text 2.9117\n",
      "2021-12-16 03:05:02,290 - INFO: | epoch  31 |  2900/ 3051 batches | lr 5.45e-06 | ms/batch 59.93 | loss-text 2.8597\n",
      "2021-12-16 03:05:08,333 - INFO: | epoch  31 |  3000/ 3051 batches | lr 5.45e-06 | ms/batch 60.42 | loss-text 2.8953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003921\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9978, 'reflen': 10195, 'guess': [9978, 8954, 7930, 6906], 'correct': [5446, 1851, 697, 223]}\n",
      "ratio: 0.9787150564001001\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.131\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.325\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-16 03:05:33,069 - INFO: eval_greddy SPIDEr: 0.2159\n",
      "loading annotations into memory...\n",
      "0:00:00.003994\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9303, 'reflen': 9700, 'guess': [9303, 8279, 7255, 6231], 'correct': [5337, 1911, 755, 257]}\n",
      "ratio: 0.9590721649483547\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-16 03:05:59,549 - INFO: eval_beam_2 SPIDEr: 0.2424\n",
      "loading annotations into memory...\n",
      "0:00:00.003998\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9059, 'reflen': 9567, 'guess': [9059, 8035, 7011, 5987], 'correct': [5209, 1902, 788, 277]}\n",
      "ratio: 0.9469008048499062\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 03:06:28,027 - INFO: eval_beam_3 SPIDEr: 0.2377\n",
      "loading annotations into memory...\n",
      "0:00:00.003790\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8889, 'reflen': 9457, 'guess': [8889, 7865, 6841, 5817], 'correct': [5152, 1900, 789, 269]}\n",
      "ratio: 0.9399386697683261\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-16 03:06:59,410 - INFO: eval_beam_4 SPIDEr: 0.2404\n",
      "2021-12-16 03:07:05,598 - INFO: | epoch  32 |   100/ 3051 batches | lr 5.35e-06 | ms/batch 61.85 | loss-text 2.8788\n",
      "2021-12-16 03:07:11,591 - INFO: | epoch  32 |   200/ 3051 batches | lr 5.35e-06 | ms/batch 59.92 | loss-text 2.8195\n",
      "2021-12-16 03:07:17,582 - INFO: | epoch  32 |   300/ 3051 batches | lr 5.35e-06 | ms/batch 59.90 | loss-text 2.8706\n",
      "2021-12-16 03:07:23,583 - INFO: | epoch  32 |   400/ 3051 batches | lr 5.35e-06 | ms/batch 60.00 | loss-text 2.8428\n",
      "2021-12-16 03:07:29,545 - INFO: | epoch  32 |   500/ 3051 batches | lr 5.35e-06 | ms/batch 59.61 | loss-text 2.8945\n",
      "2021-12-16 03:07:35,491 - INFO: | epoch  32 |   600/ 3051 batches | lr 5.35e-06 | ms/batch 59.46 | loss-text 2.8710\n",
      "2021-12-16 03:07:41,424 - INFO: | epoch  32 |   700/ 3051 batches | lr 5.35e-06 | ms/batch 59.33 | loss-text 2.8637\n",
      "2021-12-16 03:07:47,381 - INFO: | epoch  32 |   800/ 3051 batches | lr 5.35e-06 | ms/batch 59.56 | loss-text 2.8820\n",
      "2021-12-16 03:07:53,353 - INFO: | epoch  32 |   900/ 3051 batches | lr 5.35e-06 | ms/batch 59.72 | loss-text 2.8368\n",
      "2021-12-16 03:07:59,345 - INFO: | epoch  32 |  1000/ 3051 batches | lr 5.35e-06 | ms/batch 59.91 | loss-text 2.8831\n",
      "2021-12-16 03:08:05,375 - INFO: | epoch  32 |  1100/ 3051 batches | lr 5.35e-06 | ms/batch 60.30 | loss-text 2.8586\n",
      "2021-12-16 03:08:11,343 - INFO: | epoch  32 |  1200/ 3051 batches | lr 5.35e-06 | ms/batch 59.67 | loss-text 2.8512\n",
      "2021-12-16 03:08:17,398 - INFO: | epoch  32 |  1300/ 3051 batches | lr 5.35e-06 | ms/batch 60.54 | loss-text 2.8602\n",
      "2021-12-16 03:08:23,412 - INFO: | epoch  32 |  1400/ 3051 batches | lr 5.35e-06 | ms/batch 60.13 | loss-text 2.8742\n",
      "2021-12-16 03:08:29,359 - INFO: | epoch  32 |  1500/ 3051 batches | lr 5.35e-06 | ms/batch 59.47 | loss-text 2.8799\n",
      "2021-12-16 03:08:35,330 - INFO: | epoch  32 |  1600/ 3051 batches | lr 5.35e-06 | ms/batch 59.70 | loss-text 2.8384\n",
      "2021-12-16 03:08:41,318 - INFO: | epoch  32 |  1700/ 3051 batches | lr 5.35e-06 | ms/batch 59.87 | loss-text 2.8338\n",
      "2021-12-16 03:08:47,300 - INFO: | epoch  32 |  1800/ 3051 batches | lr 5.35e-06 | ms/batch 59.82 | loss-text 2.8876\n",
      "2021-12-16 03:08:53,267 - INFO: | epoch  32 |  1900/ 3051 batches | lr 5.35e-06 | ms/batch 59.66 | loss-text 2.8525\n",
      "2021-12-16 03:08:59,242 - INFO: | epoch  32 |  2000/ 3051 batches | lr 5.35e-06 | ms/batch 59.75 | loss-text 2.9036\n",
      "2021-12-16 03:09:05,239 - INFO: | epoch  32 |  2100/ 3051 batches | lr 5.35e-06 | ms/batch 59.96 | loss-text 2.8796\n",
      "2021-12-16 03:09:11,234 - INFO: | epoch  32 |  2200/ 3051 batches | lr 5.35e-06 | ms/batch 59.94 | loss-text 2.8451\n",
      "2021-12-16 03:09:17,275 - INFO: | epoch  32 |  2300/ 3051 batches | lr 5.35e-06 | ms/batch 60.41 | loss-text 2.8620\n",
      "2021-12-16 03:09:23,210 - INFO: | epoch  32 |  2400/ 3051 batches | lr 5.35e-06 | ms/batch 59.34 | loss-text 2.8386\n",
      "2021-12-16 03:09:29,214 - INFO: | epoch  32 |  2500/ 3051 batches | lr 5.35e-06 | ms/batch 60.04 | loss-text 2.8849\n",
      "2021-12-16 03:09:35,230 - INFO: | epoch  32 |  2600/ 3051 batches | lr 5.35e-06 | ms/batch 60.15 | loss-text 2.9308\n",
      "2021-12-16 03:09:41,224 - INFO: | epoch  32 |  2700/ 3051 batches | lr 5.35e-06 | ms/batch 59.93 | loss-text 2.8375\n",
      "2021-12-16 03:09:47,251 - INFO: | epoch  32 |  2800/ 3051 batches | lr 5.35e-06 | ms/batch 60.26 | loss-text 2.8930\n",
      "2021-12-16 03:09:53,228 - INFO: | epoch  32 |  2900/ 3051 batches | lr 5.35e-06 | ms/batch 59.77 | loss-text 2.8904\n",
      "2021-12-16 03:09:59,230 - INFO: | epoch  32 |  3000/ 3051 batches | lr 5.35e-06 | ms/batch 60.01 | loss-text 2.8945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.100633\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9877, 'reflen': 10107, 'guess': [9877, 8853, 7829, 6805], 'correct': [5391, 1847, 698, 226]}\n",
      "ratio: 0.9772434946076008\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.328\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.218\n",
      "2021-12-16 03:10:25,436 - INFO: eval_greddy SPIDEr: 0.2182\n",
      "loading annotations into memory...\n",
      "0:00:00.003967\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9315, 'reflen': 9719, 'guess': [9315, 8291, 7267, 6243], 'correct': [5282, 1900, 742, 247]}\n",
      "ratio: 0.958431937442025\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 03:10:50,837 - INFO: eval_beam_2 SPIDEr: 0.2364\n",
      "loading annotations into memory...\n",
      "0:00:00.003934\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9085, 'reflen': 9585, 'guess': [9085, 8061, 7037, 6013], 'correct': [5185, 1889, 768, 259]}\n",
      "ratio: 0.9478351591026658\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 03:11:17,932 - INFO: eval_beam_3 SPIDEr: 0.2344\n",
      "loading annotations into memory...\n",
      "0:00:00.003874\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8853, 'reflen': 9438, 'guess': [8853, 7829, 6805, 5781], 'correct': [5099, 1878, 764, 256]}\n",
      "ratio: 0.9380165289255205\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-16 03:11:47,261 - INFO: eval_beam_4 SPIDEr: 0.2334\n",
      "2021-12-16 03:11:53,490 - INFO: | epoch  33 |   100/ 3051 batches | lr 5.24e-06 | ms/batch 62.26 | loss-text 2.8556\n",
      "2021-12-16 03:11:59,435 - INFO: | epoch  33 |   200/ 3051 batches | lr 5.24e-06 | ms/batch 59.43 | loss-text 2.8630\n",
      "2021-12-16 03:12:05,450 - INFO: | epoch  33 |   300/ 3051 batches | lr 5.24e-06 | ms/batch 60.15 | loss-text 2.8674\n",
      "2021-12-16 03:12:11,462 - INFO: | epoch  33 |   400/ 3051 batches | lr 5.24e-06 | ms/batch 60.11 | loss-text 2.9119\n",
      "2021-12-16 03:12:17,426 - INFO: | epoch  33 |   500/ 3051 batches | lr 5.24e-06 | ms/batch 59.64 | loss-text 2.8414\n",
      "2021-12-16 03:12:23,357 - INFO: | epoch  33 |   600/ 3051 batches | lr 5.24e-06 | ms/batch 59.30 | loss-text 2.8609\n",
      "2021-12-16 03:12:29,366 - INFO: | epoch  33 |   700/ 3051 batches | lr 5.24e-06 | ms/batch 60.08 | loss-text 2.8765\n",
      "2021-12-16 03:12:35,307 - INFO: | epoch  33 |   800/ 3051 batches | lr 5.24e-06 | ms/batch 59.40 | loss-text 2.8387\n",
      "2021-12-16 03:12:41,245 - INFO: | epoch  33 |   900/ 3051 batches | lr 5.24e-06 | ms/batch 59.37 | loss-text 2.8659\n",
      "2021-12-16 03:12:47,192 - INFO: | epoch  33 |  1000/ 3051 batches | lr 5.24e-06 | ms/batch 59.46 | loss-text 2.8765\n",
      "2021-12-16 03:12:53,183 - INFO: | epoch  33 |  1100/ 3051 batches | lr 5.24e-06 | ms/batch 59.91 | loss-text 2.8351\n",
      "2021-12-16 03:12:59,170 - INFO: | epoch  33 |  1200/ 3051 batches | lr 5.24e-06 | ms/batch 59.86 | loss-text 2.8524\n",
      "2021-12-16 03:13:05,115 - INFO: | epoch  33 |  1300/ 3051 batches | lr 5.24e-06 | ms/batch 59.44 | loss-text 2.8850\n",
      "2021-12-16 03:13:11,126 - INFO: | epoch  33 |  1400/ 3051 batches | lr 5.24e-06 | ms/batch 60.10 | loss-text 2.8524\n",
      "2021-12-16 03:13:17,152 - INFO: | epoch  33 |  1500/ 3051 batches | lr 5.24e-06 | ms/batch 60.25 | loss-text 2.8930\n",
      "2021-12-16 03:13:23,145 - INFO: | epoch  33 |  1600/ 3051 batches | lr 5.24e-06 | ms/batch 59.93 | loss-text 2.8970\n",
      "2021-12-16 03:13:29,125 - INFO: | epoch  33 |  1700/ 3051 batches | lr 5.24e-06 | ms/batch 59.79 | loss-text 2.8578\n",
      "2021-12-16 03:13:35,142 - INFO: | epoch  33 |  1800/ 3051 batches | lr 5.24e-06 | ms/batch 60.16 | loss-text 2.8805\n",
      "2021-12-16 03:13:41,136 - INFO: | epoch  33 |  1900/ 3051 batches | lr 5.24e-06 | ms/batch 59.94 | loss-text 2.8699\n",
      "2021-12-16 03:13:47,177 - INFO: | epoch  33 |  2000/ 3051 batches | lr 5.24e-06 | ms/batch 60.40 | loss-text 2.8361\n",
      "2021-12-16 03:13:53,255 - INFO: | epoch  33 |  2100/ 3051 batches | lr 5.24e-06 | ms/batch 60.78 | loss-text 2.8697\n",
      "2021-12-16 03:13:59,229 - INFO: | epoch  33 |  2200/ 3051 batches | lr 5.24e-06 | ms/batch 59.73 | loss-text 2.8756\n",
      "2021-12-16 03:14:05,216 - INFO: | epoch  33 |  2300/ 3051 batches | lr 5.24e-06 | ms/batch 59.86 | loss-text 2.8367\n",
      "2021-12-16 03:14:11,193 - INFO: | epoch  33 |  2400/ 3051 batches | lr 5.24e-06 | ms/batch 59.76 | loss-text 2.8605\n",
      "2021-12-16 03:14:17,211 - INFO: | epoch  33 |  2500/ 3051 batches | lr 5.24e-06 | ms/batch 60.18 | loss-text 2.8794\n",
      "2021-12-16 03:14:23,226 - INFO: | epoch  33 |  2600/ 3051 batches | lr 5.24e-06 | ms/batch 60.14 | loss-text 2.8619\n",
      "2021-12-16 03:14:29,296 - INFO: | epoch  33 |  2700/ 3051 batches | lr 5.24e-06 | ms/batch 60.69 | loss-text 2.8641\n",
      "2021-12-16 03:14:35,329 - INFO: | epoch  33 |  2800/ 3051 batches | lr 5.24e-06 | ms/batch 60.32 | loss-text 2.9000\n",
      "2021-12-16 03:14:41,296 - INFO: | epoch  33 |  2900/ 3051 batches | lr 5.24e-06 | ms/batch 59.67 | loss-text 2.8698\n",
      "2021-12-16 03:14:47,295 - INFO: | epoch  33 |  3000/ 3051 batches | lr 5.24e-06 | ms/batch 59.98 | loss-text 2.8821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003857\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9942, 'reflen': 10144, 'guess': [9942, 8918, 7894, 6870], 'correct': [5383, 1816, 671, 209]}\n",
      "ratio: 0.9800867507885469\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.322\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2021-12-16 03:15:11,937 - INFO: eval_greddy SPIDEr: 0.2138\n",
      "loading annotations into memory...\n",
      "0:00:00.003912\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9293, 'reflen': 9685, 'guess': [9293, 8269, 7245, 6221], 'correct': [5318, 1932, 755, 257]}\n",
      "ratio: 0.9595250387195705\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 03:15:32,572 - INFO: eval_beam_2 SPIDEr: 0.2393\n",
      "loading annotations into memory...\n",
      "0:00:00.003874\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9058, 'reflen': 9582, 'guess': [9058, 8034, 7010, 5986], 'correct': [5183, 1886, 782, 283]}\n",
      "ratio: 0.9453141306615586\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 03:15:56,042 - INFO: eval_beam_3 SPIDEr: 0.2360\n",
      "loading annotations into memory...\n",
      "0:00:00.003882\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8899, 'reflen': 9474, 'guess': [8899, 7875, 6851, 5827], 'correct': [5150, 1903, 798, 285]}\n",
      "ratio: 0.9393075786361685\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 03:16:24,553 - INFO: eval_beam_4 SPIDEr: 0.2393\n",
      "2021-12-16 03:16:30,731 - INFO: | epoch  34 |   100/ 3051 batches | lr 5.13e-06 | ms/batch 61.75 | loss-text 2.8836\n",
      "2021-12-16 03:16:36,702 - INFO: | epoch  34 |   200/ 3051 batches | lr 5.13e-06 | ms/batch 59.69 | loss-text 2.8719\n",
      "2021-12-16 03:16:42,642 - INFO: | epoch  34 |   300/ 3051 batches | lr 5.13e-06 | ms/batch 59.40 | loss-text 2.8461\n",
      "2021-12-16 03:16:48,607 - INFO: | epoch  34 |   400/ 3051 batches | lr 5.13e-06 | ms/batch 59.64 | loss-text 2.9100\n",
      "2021-12-16 03:16:54,551 - INFO: | epoch  34 |   500/ 3051 batches | lr 5.13e-06 | ms/batch 59.44 | loss-text 2.8606\n",
      "2021-12-16 03:17:00,578 - INFO: | epoch  34 |   600/ 3051 batches | lr 5.13e-06 | ms/batch 60.26 | loss-text 2.8569\n",
      "2021-12-16 03:17:06,527 - INFO: | epoch  34 |   700/ 3051 batches | lr 5.13e-06 | ms/batch 59.48 | loss-text 2.8659\n",
      "2021-12-16 03:17:12,537 - INFO: | epoch  34 |   800/ 3051 batches | lr 5.13e-06 | ms/batch 60.09 | loss-text 2.8378\n",
      "2021-12-16 03:17:18,514 - INFO: | epoch  34 |   900/ 3051 batches | lr 5.13e-06 | ms/batch 59.77 | loss-text 2.8259\n",
      "2021-12-16 03:17:24,482 - INFO: | epoch  34 |  1000/ 3051 batches | lr 5.13e-06 | ms/batch 59.68 | loss-text 2.8491\n",
      "2021-12-16 03:17:30,509 - INFO: | epoch  34 |  1100/ 3051 batches | lr 5.13e-06 | ms/batch 60.25 | loss-text 2.8614\n",
      "2021-12-16 03:17:36,607 - INFO: | epoch  34 |  1200/ 3051 batches | lr 5.13e-06 | ms/batch 60.98 | loss-text 2.8640\n",
      "2021-12-16 03:17:42,589 - INFO: | epoch  34 |  1300/ 3051 batches | lr 5.13e-06 | ms/batch 59.81 | loss-text 2.8317\n",
      "2021-12-16 03:17:48,546 - INFO: | epoch  34 |  1400/ 3051 batches | lr 5.13e-06 | ms/batch 59.55 | loss-text 2.9136\n",
      "2021-12-16 03:17:54,509 - INFO: | epoch  34 |  1500/ 3051 batches | lr 5.13e-06 | ms/batch 59.62 | loss-text 2.8475\n",
      "2021-12-16 03:18:00,539 - INFO: | epoch  34 |  1600/ 3051 batches | lr 5.13e-06 | ms/batch 60.30 | loss-text 2.8649\n",
      "2021-12-16 03:18:06,512 - INFO: | epoch  34 |  1700/ 3051 batches | lr 5.13e-06 | ms/batch 59.73 | loss-text 2.8766\n",
      "2021-12-16 03:18:12,532 - INFO: | epoch  34 |  1800/ 3051 batches | lr 5.13e-06 | ms/batch 60.19 | loss-text 2.8717\n",
      "2021-12-16 03:18:18,489 - INFO: | epoch  34 |  1900/ 3051 batches | lr 5.13e-06 | ms/batch 59.56 | loss-text 2.8578\n",
      "2021-12-16 03:18:24,539 - INFO: | epoch  34 |  2000/ 3051 batches | lr 5.13e-06 | ms/batch 60.50 | loss-text 2.8789\n",
      "2021-12-16 03:18:30,513 - INFO: | epoch  34 |  2100/ 3051 batches | lr 5.13e-06 | ms/batch 59.73 | loss-text 2.8837\n",
      "2021-12-16 03:18:36,490 - INFO: | epoch  34 |  2200/ 3051 batches | lr 5.13e-06 | ms/batch 59.76 | loss-text 2.8473\n",
      "2021-12-16 03:18:42,474 - INFO: | epoch  34 |  2300/ 3051 batches | lr 5.13e-06 | ms/batch 59.83 | loss-text 2.8760\n",
      "2021-12-16 03:18:48,473 - INFO: | epoch  34 |  2400/ 3051 batches | lr 5.13e-06 | ms/batch 59.99 | loss-text 2.8128\n",
      "2021-12-16 03:18:54,454 - INFO: | epoch  34 |  2500/ 3051 batches | lr 5.13e-06 | ms/batch 59.80 | loss-text 2.8590\n",
      "2021-12-16 03:19:00,480 - INFO: | epoch  34 |  2600/ 3051 batches | lr 5.13e-06 | ms/batch 60.26 | loss-text 2.8805\n",
      "2021-12-16 03:19:06,476 - INFO: | epoch  34 |  2700/ 3051 batches | lr 5.13e-06 | ms/batch 59.95 | loss-text 2.8935\n",
      "2021-12-16 03:19:12,488 - INFO: | epoch  34 |  2800/ 3051 batches | lr 5.13e-06 | ms/batch 60.11 | loss-text 2.8867\n",
      "2021-12-16 03:19:18,469 - INFO: | epoch  34 |  2900/ 3051 batches | lr 5.13e-06 | ms/batch 59.81 | loss-text 2.8881\n",
      "2021-12-16 03:19:24,484 - INFO: | epoch  34 |  3000/ 3051 batches | lr 5.13e-06 | ms/batch 60.14 | loss-text 2.8532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003867\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10016, 'reflen': 10209, 'guess': [10016, 8992, 7968, 6944], 'correct': [5425, 1841, 691, 218]}\n",
      "ratio: 0.9810951121558447\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-16 03:19:51,728 - INFO: eval_greddy SPIDEr: 0.2156\n",
      "loading annotations into memory...\n",
      "0:00:00.003991\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9319, 'reflen': 9743, 'guess': [9319, 8295, 7271, 6247], 'correct': [5277, 1884, 762, 258]}\n",
      "ratio: 0.9564815765163751\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 03:20:16,609 - INFO: eval_beam_2 SPIDEr: 0.2352\n",
      "loading annotations into memory...\n",
      "0:00:00.003858\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9076, 'reflen': 9580, 'guess': [9076, 8052, 7028, 6004], 'correct': [5200, 1905, 786, 271]}\n",
      "ratio: 0.9473903966596088\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-16 03:20:40,011 - INFO: eval_beam_3 SPIDEr: 0.2403\n",
      "loading annotations into memory...\n",
      "0:00:00.003883\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8851, 'reflen': 9449, 'guess': [8851, 7827, 6803, 5779], 'correct': [5107, 1904, 789, 275]}\n",
      "ratio: 0.9367128796697072\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.375\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-16 03:21:08,558 - INFO: eval_beam_4 SPIDEr: 0.2400\n",
      "2021-12-16 03:21:14,806 - INFO: | epoch  35 |   100/ 3051 batches | lr 5.03e-06 | ms/batch 62.45 | loss-text 2.8479\n",
      "2021-12-16 03:21:20,694 - INFO: | epoch  35 |   200/ 3051 batches | lr 5.03e-06 | ms/batch 58.86 | loss-text 2.8295\n",
      "2021-12-16 03:21:26,667 - INFO: | epoch  35 |   300/ 3051 batches | lr 5.03e-06 | ms/batch 59.73 | loss-text 2.8807\n",
      "2021-12-16 03:21:32,633 - INFO: | epoch  35 |   400/ 3051 batches | lr 5.03e-06 | ms/batch 59.65 | loss-text 2.8462\n",
      "2021-12-16 03:21:38,557 - INFO: | epoch  35 |   500/ 3051 batches | lr 5.03e-06 | ms/batch 59.24 | loss-text 2.8442\n",
      "2021-12-16 03:21:44,552 - INFO: | epoch  35 |   600/ 3051 batches | lr 5.03e-06 | ms/batch 59.94 | loss-text 2.8533\n",
      "2021-12-16 03:21:50,564 - INFO: | epoch  35 |   700/ 3051 batches | lr 5.03e-06 | ms/batch 60.12 | loss-text 2.8427\n",
      "2021-12-16 03:21:56,547 - INFO: | epoch  35 |   800/ 3051 batches | lr 5.03e-06 | ms/batch 59.82 | loss-text 2.9122\n",
      "2021-12-16 03:22:02,484 - INFO: | epoch  35 |   900/ 3051 batches | lr 5.03e-06 | ms/batch 59.36 | loss-text 2.8607\n",
      "2021-12-16 03:22:08,460 - INFO: | epoch  35 |  1000/ 3051 batches | lr 5.03e-06 | ms/batch 59.75 | loss-text 2.9004\n",
      "2021-12-16 03:22:14,466 - INFO: | epoch  35 |  1100/ 3051 batches | lr 5.03e-06 | ms/batch 60.06 | loss-text 2.8253\n",
      "2021-12-16 03:22:20,459 - INFO: | epoch  35 |  1200/ 3051 batches | lr 5.03e-06 | ms/batch 59.92 | loss-text 2.8550\n",
      "2021-12-16 03:22:26,425 - INFO: | epoch  35 |  1300/ 3051 batches | lr 5.03e-06 | ms/batch 59.66 | loss-text 2.8669\n",
      "2021-12-16 03:22:32,445 - INFO: | epoch  35 |  1400/ 3051 batches | lr 5.03e-06 | ms/batch 60.19 | loss-text 2.8860\n",
      "2021-12-16 03:22:38,451 - INFO: | epoch  35 |  1500/ 3051 batches | lr 5.03e-06 | ms/batch 60.05 | loss-text 2.8452\n",
      "2021-12-16 03:22:44,459 - INFO: | epoch  35 |  1600/ 3051 batches | lr 5.03e-06 | ms/batch 60.07 | loss-text 2.8752\n",
      "2021-12-16 03:22:50,463 - INFO: | epoch  35 |  1700/ 3051 batches | lr 5.03e-06 | ms/batch 60.04 | loss-text 2.8681\n",
      "2021-12-16 03:22:56,487 - INFO: | epoch  35 |  1800/ 3051 batches | lr 5.03e-06 | ms/batch 60.24 | loss-text 2.8732\n",
      "2021-12-16 03:23:02,504 - INFO: | epoch  35 |  1900/ 3051 batches | lr 5.03e-06 | ms/batch 60.16 | loss-text 2.8715\n",
      "2021-12-16 03:23:08,483 - INFO: | epoch  35 |  2000/ 3051 batches | lr 5.03e-06 | ms/batch 59.78 | loss-text 2.8701\n",
      "2021-12-16 03:23:14,462 - INFO: | epoch  35 |  2100/ 3051 batches | lr 5.03e-06 | ms/batch 59.79 | loss-text 2.8272\n",
      "2021-12-16 03:23:20,538 - INFO: | epoch  35 |  2200/ 3051 batches | lr 5.03e-06 | ms/batch 60.75 | loss-text 2.8566\n",
      "2021-12-16 03:23:26,612 - INFO: | epoch  35 |  2300/ 3051 batches | lr 5.03e-06 | ms/batch 60.73 | loss-text 2.8873\n",
      "2021-12-16 03:23:32,596 - INFO: | epoch  35 |  2400/ 3051 batches | lr 5.03e-06 | ms/batch 59.84 | loss-text 2.8778\n",
      "2021-12-16 03:23:38,572 - INFO: | epoch  35 |  2500/ 3051 batches | lr 5.03e-06 | ms/batch 59.75 | loss-text 2.8055\n",
      "2021-12-16 03:23:44,600 - INFO: | epoch  35 |  2600/ 3051 batches | lr 5.03e-06 | ms/batch 60.28 | loss-text 2.8396\n",
      "2021-12-16 03:23:50,604 - INFO: | epoch  35 |  2700/ 3051 batches | lr 5.03e-06 | ms/batch 60.04 | loss-text 2.8276\n",
      "2021-12-16 03:23:56,644 - INFO: | epoch  35 |  2800/ 3051 batches | lr 5.03e-06 | ms/batch 60.39 | loss-text 2.8808\n",
      "2021-12-16 03:24:02,624 - INFO: | epoch  35 |  2900/ 3051 batches | lr 5.03e-06 | ms/batch 59.79 | loss-text 2.8607\n",
      "2021-12-16 03:24:08,651 - INFO: | epoch  35 |  3000/ 3051 batches | lr 5.03e-06 | ms/batch 60.26 | loss-text 2.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003886\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10050, 'reflen': 10241, 'guess': [10050, 9026, 8002, 6978], 'correct': [5466, 1864, 693, 213]}\n",
      "ratio: 0.9813494775899833\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-16 03:24:35,278 - INFO: eval_greddy SPIDEr: 0.2158\n",
      "loading annotations into memory...\n",
      "0:00:00.003948\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9327, 'reflen': 9734, 'guess': [9327, 8303, 7279, 6255], 'correct': [5284, 1906, 737, 243]}\n",
      "ratio: 0.958187795356384\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 03:24:56,174 - INFO: eval_beam_2 SPIDEr: 0.2380\n",
      "loading annotations into memory...\n",
      "0:00:00.003874\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9076, 'reflen': 9599, 'guess': [9076, 8052, 7028, 6004], 'correct': [5191, 1908, 784, 271]}\n",
      "ratio: 0.945515157828842\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 03:25:24,084 - INFO: eval_beam_3 SPIDEr: 0.2391\n",
      "loading annotations into memory...\n",
      "0:00:00.004061\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8876, 'reflen': 9476, 'guess': [8876, 7852, 6828, 5804], 'correct': [5120, 1876, 773, 266]}\n",
      "ratio: 0.936682144364612\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 03:25:54,077 - INFO: eval_beam_4 SPIDEr: 0.2354\n",
      "2021-12-16 03:26:00,361 - INFO: | epoch  36 |   100/ 3051 batches | lr 4.93e-06 | ms/batch 62.81 | loss-text 2.8937\n",
      "2021-12-16 03:26:06,409 - INFO: | epoch  36 |   200/ 3051 batches | lr 4.93e-06 | ms/batch 60.47 | loss-text 2.8624\n",
      "2021-12-16 03:26:13,105 - INFO: | epoch  36 |   300/ 3051 batches | lr 4.93e-06 | ms/batch 66.95 | loss-text 2.8109\n",
      "2021-12-16 03:26:19,081 - INFO: | epoch  36 |   400/ 3051 batches | lr 4.93e-06 | ms/batch 59.76 | loss-text 2.8552\n",
      "2021-12-16 03:26:25,158 - INFO: | epoch  36 |   500/ 3051 batches | lr 4.93e-06 | ms/batch 60.76 | loss-text 2.8758\n",
      "2021-12-16 03:26:31,206 - INFO: | epoch  36 |   600/ 3051 batches | lr 4.93e-06 | ms/batch 60.47 | loss-text 2.8877\n",
      "2021-12-16 03:26:37,203 - INFO: | epoch  36 |   700/ 3051 batches | lr 4.93e-06 | ms/batch 59.96 | loss-text 2.8733\n",
      "2021-12-16 03:26:43,225 - INFO: | epoch  36 |   800/ 3051 batches | lr 4.93e-06 | ms/batch 60.22 | loss-text 2.8741\n",
      "2021-12-16 03:26:49,174 - INFO: | epoch  36 |   900/ 3051 batches | lr 4.93e-06 | ms/batch 59.48 | loss-text 2.8383\n",
      "2021-12-16 03:26:55,130 - INFO: | epoch  36 |  1000/ 3051 batches | lr 4.93e-06 | ms/batch 59.55 | loss-text 2.8211\n",
      "2021-12-16 03:27:01,113 - INFO: | epoch  36 |  1100/ 3051 batches | lr 4.93e-06 | ms/batch 59.82 | loss-text 2.8670\n",
      "2021-12-16 03:27:07,105 - INFO: | epoch  36 |  1200/ 3051 batches | lr 4.93e-06 | ms/batch 59.91 | loss-text 2.8523\n",
      "2021-12-16 03:27:13,124 - INFO: | epoch  36 |  1300/ 3051 batches | lr 4.93e-06 | ms/batch 60.18 | loss-text 2.8593\n",
      "2021-12-16 03:27:19,132 - INFO: | epoch  36 |  1400/ 3051 batches | lr 4.93e-06 | ms/batch 60.08 | loss-text 2.8672\n",
      "2021-12-16 03:27:25,138 - INFO: | epoch  36 |  1500/ 3051 batches | lr 4.93e-06 | ms/batch 60.05 | loss-text 2.8838\n",
      "2021-12-16 03:27:31,114 - INFO: | epoch  36 |  1600/ 3051 batches | lr 4.93e-06 | ms/batch 59.75 | loss-text 2.8777\n",
      "2021-12-16 03:27:37,087 - INFO: | epoch  36 |  1700/ 3051 batches | lr 4.93e-06 | ms/batch 59.73 | loss-text 2.8464\n",
      "2021-12-16 03:27:43,101 - INFO: | epoch  36 |  1800/ 3051 batches | lr 4.93e-06 | ms/batch 60.14 | loss-text 2.8036\n",
      "2021-12-16 03:27:49,082 - INFO: | epoch  36 |  1900/ 3051 batches | lr 4.93e-06 | ms/batch 59.80 | loss-text 2.8609\n",
      "2021-12-16 03:27:55,042 - INFO: | epoch  36 |  2000/ 3051 batches | lr 4.93e-06 | ms/batch 59.60 | loss-text 2.8561\n",
      "2021-12-16 03:28:01,032 - INFO: | epoch  36 |  2100/ 3051 batches | lr 4.93e-06 | ms/batch 59.89 | loss-text 2.8406\n",
      "2021-12-16 03:28:07,057 - INFO: | epoch  36 |  2200/ 3051 batches | lr 4.93e-06 | ms/batch 60.24 | loss-text 2.8280\n",
      "2021-12-16 03:28:13,070 - INFO: | epoch  36 |  2300/ 3051 batches | lr 4.93e-06 | ms/batch 60.13 | loss-text 2.8640\n",
      "2021-12-16 03:28:19,149 - INFO: | epoch  36 |  2400/ 3051 batches | lr 4.93e-06 | ms/batch 60.78 | loss-text 2.8963\n",
      "2021-12-16 03:28:25,219 - INFO: | epoch  36 |  2500/ 3051 batches | lr 4.93e-06 | ms/batch 60.70 | loss-text 2.9295\n",
      "2021-12-16 03:28:31,273 - INFO: | epoch  36 |  2600/ 3051 batches | lr 4.93e-06 | ms/batch 60.53 | loss-text 2.8735\n",
      "2021-12-16 03:28:37,305 - INFO: | epoch  36 |  2700/ 3051 batches | lr 4.93e-06 | ms/batch 60.32 | loss-text 2.8844\n",
      "2021-12-16 03:28:43,361 - INFO: | epoch  36 |  2800/ 3051 batches | lr 4.93e-06 | ms/batch 60.55 | loss-text 2.8766\n",
      "2021-12-16 03:28:49,374 - INFO: | epoch  36 |  2900/ 3051 batches | lr 4.93e-06 | ms/batch 60.12 | loss-text 2.8241\n",
      "2021-12-16 03:28:55,440 - INFO: | epoch  36 |  3000/ 3051 batches | lr 4.93e-06 | ms/batch 60.66 | loss-text 2.8652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003846\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10068, 'reflen': 10226, 'guess': [10068, 9044, 8020, 6996], 'correct': [5485, 1859, 696, 221]}\n",
      "ratio: 0.9845491883433419\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2021-12-16 03:29:21,208 - INFO: eval_greddy SPIDEr: 0.2168\n",
      "loading annotations into memory...\n",
      "0:00:00.004075\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9328, 'reflen': 9724, 'guess': [9328, 8304, 7280, 6256], 'correct': [5342, 1928, 752, 259]}\n",
      "ratio: 0.9592760180994488\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 03:29:43,052 - INFO: eval_beam_2 SPIDEr: 0.2393\n",
      "loading annotations into memory...\n",
      "0:00:00.003989\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9112, 'reflen': 9588, 'guess': [9112, 8088, 7064, 6040], 'correct': [5246, 1914, 780, 265]}\n",
      "ratio: 0.9503546099289788\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 03:30:06,849 - INFO: eval_beam_3 SPIDEr: 0.2389\n",
      "loading annotations into memory...\n",
      "0:00:00.003950\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8917, 'reflen': 9489, 'guess': [8917, 7893, 6869, 5845], 'correct': [5138, 1891, 784, 273]}\n",
      "ratio: 0.9397196754135377\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 03:30:34,708 - INFO: eval_beam_4 SPIDEr: 0.2379\n",
      "2021-12-16 03:30:40,860 - INFO: | epoch  37 |   100/ 3051 batches | lr 4.83e-06 | ms/batch 61.49 | loss-text 2.8369\n",
      "2021-12-16 03:30:46,818 - INFO: | epoch  37 |   200/ 3051 batches | lr 4.83e-06 | ms/batch 59.57 | loss-text 2.8283\n",
      "2021-12-16 03:30:52,818 - INFO: | epoch  37 |   300/ 3051 batches | lr 4.83e-06 | ms/batch 59.99 | loss-text 2.8594\n",
      "2021-12-16 03:30:58,721 - INFO: | epoch  37 |   400/ 3051 batches | lr 4.83e-06 | ms/batch 59.02 | loss-text 2.8708\n",
      "2021-12-16 03:31:04,692 - INFO: | epoch  37 |   500/ 3051 batches | lr 4.83e-06 | ms/batch 59.71 | loss-text 2.9071\n",
      "2021-12-16 03:31:10,701 - INFO: | epoch  37 |   600/ 3051 batches | lr 4.83e-06 | ms/batch 60.07 | loss-text 2.8324\n",
      "2021-12-16 03:31:16,681 - INFO: | epoch  37 |   700/ 3051 batches | lr 4.83e-06 | ms/batch 59.80 | loss-text 2.8170\n",
      "2021-12-16 03:31:22,622 - INFO: | epoch  37 |   800/ 3051 batches | lr 4.83e-06 | ms/batch 59.41 | loss-text 2.7926\n",
      "2021-12-16 03:31:28,631 - INFO: | epoch  37 |   900/ 3051 batches | lr 4.83e-06 | ms/batch 60.08 | loss-text 2.8803\n",
      "2021-12-16 03:31:34,630 - INFO: | epoch  37 |  1000/ 3051 batches | lr 4.83e-06 | ms/batch 59.98 | loss-text 2.8636\n",
      "2021-12-16 03:31:40,579 - INFO: | epoch  37 |  1100/ 3051 batches | lr 4.83e-06 | ms/batch 59.49 | loss-text 2.8770\n",
      "2021-12-16 03:31:46,558 - INFO: | epoch  37 |  1200/ 3051 batches | lr 4.83e-06 | ms/batch 59.78 | loss-text 2.8665\n",
      "2021-12-16 03:31:52,514 - INFO: | epoch  37 |  1300/ 3051 batches | lr 4.83e-06 | ms/batch 59.55 | loss-text 2.8682\n",
      "2021-12-16 03:31:58,518 - INFO: | epoch  37 |  1400/ 3051 batches | lr 4.83e-06 | ms/batch 60.03 | loss-text 2.8844\n",
      "2021-12-16 03:32:04,467 - INFO: | epoch  37 |  1500/ 3051 batches | lr 4.83e-06 | ms/batch 59.48 | loss-text 2.8593\n",
      "2021-12-16 03:32:10,497 - INFO: | epoch  37 |  1600/ 3051 batches | lr 4.83e-06 | ms/batch 60.29 | loss-text 2.8454\n",
      "2021-12-16 03:32:16,462 - INFO: | epoch  37 |  1700/ 3051 batches | lr 4.83e-06 | ms/batch 59.65 | loss-text 2.8473\n",
      "2021-12-16 03:32:22,446 - INFO: | epoch  37 |  1800/ 3051 batches | lr 4.83e-06 | ms/batch 59.83 | loss-text 2.8843\n",
      "2021-12-16 03:32:28,395 - INFO: | epoch  37 |  1900/ 3051 batches | lr 4.83e-06 | ms/batch 59.49 | loss-text 2.8319\n",
      "2021-12-16 03:32:34,440 - INFO: | epoch  37 |  2000/ 3051 batches | lr 4.83e-06 | ms/batch 60.44 | loss-text 2.8623\n",
      "2021-12-16 03:32:40,414 - INFO: | epoch  37 |  2100/ 3051 batches | lr 4.83e-06 | ms/batch 59.73 | loss-text 2.8750\n",
      "2021-12-16 03:32:46,453 - INFO: | epoch  37 |  2200/ 3051 batches | lr 4.83e-06 | ms/batch 60.39 | loss-text 2.8559\n",
      "2021-12-16 03:32:52,443 - INFO: | epoch  37 |  2300/ 3051 batches | lr 4.83e-06 | ms/batch 59.89 | loss-text 2.8416\n",
      "2021-12-16 03:32:58,410 - INFO: | epoch  37 |  2400/ 3051 batches | lr 4.83e-06 | ms/batch 59.66 | loss-text 2.9112\n",
      "2021-12-16 03:33:04,444 - INFO: | epoch  37 |  2500/ 3051 batches | lr 4.83e-06 | ms/batch 60.34 | loss-text 2.8684\n",
      "2021-12-16 03:33:10,435 - INFO: | epoch  37 |  2600/ 3051 batches | lr 4.83e-06 | ms/batch 59.90 | loss-text 2.8540\n",
      "2021-12-16 03:33:16,404 - INFO: | epoch  37 |  2700/ 3051 batches | lr 4.83e-06 | ms/batch 59.68 | loss-text 2.8933\n",
      "2021-12-16 03:33:22,405 - INFO: | epoch  37 |  2800/ 3051 batches | lr 4.83e-06 | ms/batch 60.00 | loss-text 2.8640\n",
      "2021-12-16 03:33:28,454 - INFO: | epoch  37 |  2900/ 3051 batches | lr 4.83e-06 | ms/batch 60.49 | loss-text 2.8958\n",
      "2021-12-16 03:33:34,494 - INFO: | epoch  37 |  3000/ 3051 batches | lr 4.83e-06 | ms/batch 60.39 | loss-text 2.8905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003888\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9950, 'reflen': 10194, 'guess': [9950, 8926, 7902, 6878], 'correct': [5469, 1878, 708, 228]}\n",
      "ratio: 0.9760643515792646\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.332\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.220\n",
      "2021-12-16 03:33:58,874 - INFO: eval_greddy SPIDEr: 0.2200\n",
      "loading annotations into memory...\n",
      "0:00:00.003945\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9248, 'reflen': 9691, 'guess': [9248, 8224, 7200, 6176], 'correct': [5330, 1946, 764, 260]}\n",
      "ratio: 0.9542874832317662\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-16 03:34:19,981 - INFO: eval_beam_2 SPIDEr: 0.2401\n",
      "loading annotations into memory...\n",
      "0:00:00.004062\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9069, 'reflen': 9581, 'guess': [9069, 8045, 7021, 5997], 'correct': [5233, 1940, 799, 281]}\n",
      "ratio: 0.9465609017846836\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-16 03:34:44,198 - INFO: eval_beam_3 SPIDEr: 0.2408\n",
      "loading annotations into memory...\n",
      "0:00:00.003925\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8908, 'reflen': 9481, 'guess': [8908, 7884, 6860, 5836], 'correct': [5122, 1879, 772, 266]}\n",
      "ratio: 0.9395633372006181\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 03:35:13,128 - INFO: eval_beam_4 SPIDEr: 0.2354\n",
      "2021-12-16 03:35:19,260 - INFO: | epoch  38 |   100/ 3051 batches | lr 4.74e-06 | ms/batch 61.29 | loss-text 2.8739\n",
      "2021-12-16 03:35:25,274 - INFO: | epoch  38 |   200/ 3051 batches | lr 4.74e-06 | ms/batch 60.13 | loss-text 2.8241\n",
      "2021-12-16 03:35:31,250 - INFO: | epoch  38 |   300/ 3051 batches | lr 4.74e-06 | ms/batch 59.75 | loss-text 2.8552\n",
      "2021-12-16 03:35:37,176 - INFO: | epoch  38 |   400/ 3051 batches | lr 4.74e-06 | ms/batch 59.26 | loss-text 2.8473\n",
      "2021-12-16 03:35:43,147 - INFO: | epoch  38 |   500/ 3051 batches | lr 4.74e-06 | ms/batch 59.69 | loss-text 2.8718\n",
      "2021-12-16 03:35:49,050 - INFO: | epoch  38 |   600/ 3051 batches | lr 4.74e-06 | ms/batch 59.03 | loss-text 2.8176\n",
      "2021-12-16 03:35:55,077 - INFO: | epoch  38 |   700/ 3051 batches | lr 4.74e-06 | ms/batch 60.26 | loss-text 2.8648\n",
      "2021-12-16 03:36:01,080 - INFO: | epoch  38 |   800/ 3051 batches | lr 4.74e-06 | ms/batch 60.03 | loss-text 2.8376\n",
      "2021-12-16 03:36:07,048 - INFO: | epoch  38 |   900/ 3051 batches | lr 4.74e-06 | ms/batch 59.67 | loss-text 2.8412\n",
      "2021-12-16 03:36:13,070 - INFO: | epoch  38 |  1000/ 3051 batches | lr 4.74e-06 | ms/batch 60.21 | loss-text 2.8359\n",
      "2021-12-16 03:36:19,019 - INFO: | epoch  38 |  1100/ 3051 batches | lr 4.74e-06 | ms/batch 59.49 | loss-text 2.8557\n",
      "2021-12-16 03:36:25,002 - INFO: | epoch  38 |  1200/ 3051 batches | lr 4.74e-06 | ms/batch 59.82 | loss-text 2.8490\n",
      "2021-12-16 03:36:30,999 - INFO: | epoch  38 |  1300/ 3051 batches | lr 4.74e-06 | ms/batch 59.96 | loss-text 2.8879\n",
      "2021-12-16 03:36:37,127 - INFO: | epoch  38 |  1400/ 3051 batches | lr 4.74e-06 | ms/batch 61.28 | loss-text 2.8454\n",
      "2021-12-16 03:36:43,216 - INFO: | epoch  38 |  1500/ 3051 batches | lr 4.74e-06 | ms/batch 60.88 | loss-text 2.8406\n",
      "2021-12-16 03:36:49,177 - INFO: | epoch  38 |  1600/ 3051 batches | lr 4.74e-06 | ms/batch 59.60 | loss-text 2.8955\n",
      "2021-12-16 03:36:55,247 - INFO: | epoch  38 |  1700/ 3051 batches | lr 4.74e-06 | ms/batch 60.69 | loss-text 2.8932\n",
      "2021-12-16 03:37:01,307 - INFO: | epoch  38 |  1800/ 3051 batches | lr 4.74e-06 | ms/batch 60.60 | loss-text 2.8548\n",
      "2021-12-16 03:37:07,296 - INFO: | epoch  38 |  1900/ 3051 batches | lr 4.74e-06 | ms/batch 59.88 | loss-text 2.8819\n",
      "2021-12-16 03:37:13,306 - INFO: | epoch  38 |  2000/ 3051 batches | lr 4.74e-06 | ms/batch 60.09 | loss-text 2.8433\n",
      "2021-12-16 03:37:19,350 - INFO: | epoch  38 |  2100/ 3051 batches | lr 4.74e-06 | ms/batch 60.43 | loss-text 2.8412\n",
      "2021-12-16 03:37:25,393 - INFO: | epoch  38 |  2200/ 3051 batches | lr 4.74e-06 | ms/batch 60.42 | loss-text 2.8683\n",
      "2021-12-16 03:37:31,399 - INFO: | epoch  38 |  2300/ 3051 batches | lr 4.74e-06 | ms/batch 60.06 | loss-text 2.8671\n",
      "2021-12-16 03:37:37,419 - INFO: | epoch  38 |  2400/ 3051 batches | lr 4.74e-06 | ms/batch 60.19 | loss-text 2.8712\n",
      "2021-12-16 03:37:43,445 - INFO: | epoch  38 |  2500/ 3051 batches | lr 4.74e-06 | ms/batch 60.25 | loss-text 2.8837\n",
      "2021-12-16 03:37:49,464 - INFO: | epoch  38 |  2600/ 3051 batches | lr 4.74e-06 | ms/batch 60.18 | loss-text 2.8512\n",
      "2021-12-16 03:37:55,507 - INFO: | epoch  38 |  2700/ 3051 batches | lr 4.74e-06 | ms/batch 60.42 | loss-text 2.8663\n",
      "2021-12-16 03:38:01,543 - INFO: | epoch  38 |  2800/ 3051 batches | lr 4.74e-06 | ms/batch 60.36 | loss-text 2.8334\n",
      "2021-12-16 03:38:07,523 - INFO: | epoch  38 |  2900/ 3051 batches | lr 4.74e-06 | ms/batch 59.79 | loss-text 2.8399\n",
      "2021-12-16 03:38:13,478 - INFO: | epoch  38 |  3000/ 3051 batches | lr 4.74e-06 | ms/batch 59.54 | loss-text 2.8668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003859\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10090, 'reflen': 10265, 'guess': [10090, 9066, 8042, 7018], 'correct': [5489, 1858, 682, 206]}\n",
      "ratio: 0.9829517778859247\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.323\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2021-12-16 03:38:38,580 - INFO: eval_greddy SPIDEr: 0.2148\n",
      "loading annotations into memory...\n",
      "0:00:00.004237\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9315, 'reflen': 9740, 'guess': [9315, 8291, 7267, 6243], 'correct': [5351, 1949, 768, 253]}\n",
      "ratio: 0.9563655030799839\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-16 03:38:59,183 - INFO: eval_beam_2 SPIDEr: 0.2399\n",
      "loading annotations into memory...\n",
      "0:00:00.003881\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9111, 'reflen': 9618, 'guess': [9111, 8087, 7063, 6039], 'correct': [5218, 1892, 775, 265]}\n",
      "ratio: 0.9472863381159339\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 03:39:27,379 - INFO: eval_beam_3 SPIDEr: 0.2358\n",
      "loading annotations into memory...\n",
      "0:00:00.003896\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8904, 'reflen': 9486, 'guess': [8904, 7880, 6856, 5832], 'correct': [5128, 1882, 776, 265]}\n",
      "ratio: 0.9386464263123615\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 03:39:55,265 - INFO: eval_beam_4 SPIDEr: 0.2361\n",
      "2021-12-16 03:40:01,399 - INFO: | epoch  39 |   100/ 3051 batches | lr 4.64e-06 | ms/batch 61.31 | loss-text 2.8416\n",
      "2021-12-16 03:40:07,377 - INFO: | epoch  39 |   200/ 3051 batches | lr 4.64e-06 | ms/batch 59.77 | loss-text 2.8233\n",
      "2021-12-16 03:40:13,358 - INFO: | epoch  39 |   300/ 3051 batches | lr 4.64e-06 | ms/batch 59.80 | loss-text 2.8862\n",
      "2021-12-16 03:40:19,308 - INFO: | epoch  39 |   400/ 3051 batches | lr 4.64e-06 | ms/batch 59.49 | loss-text 2.8470\n",
      "2021-12-16 03:40:25,371 - INFO: | epoch  39 |   500/ 3051 batches | lr 4.64e-06 | ms/batch 60.63 | loss-text 2.8376\n",
      "2021-12-16 03:40:31,316 - INFO: | epoch  39 |   600/ 3051 batches | lr 4.64e-06 | ms/batch 59.44 | loss-text 2.8634\n",
      "2021-12-16 03:40:37,228 - INFO: | epoch  39 |   700/ 3051 batches | lr 4.64e-06 | ms/batch 59.11 | loss-text 2.8360\n",
      "2021-12-16 03:40:43,160 - INFO: | epoch  39 |   800/ 3051 batches | lr 4.64e-06 | ms/batch 59.31 | loss-text 2.8414\n",
      "2021-12-16 03:40:49,101 - INFO: | epoch  39 |   900/ 3051 batches | lr 4.64e-06 | ms/batch 59.41 | loss-text 2.8623\n",
      "2021-12-16 03:40:55,090 - INFO: | epoch  39 |  1000/ 3051 batches | lr 4.64e-06 | ms/batch 59.88 | loss-text 2.8498\n",
      "2021-12-16 03:41:01,057 - INFO: | epoch  39 |  1100/ 3051 batches | lr 4.64e-06 | ms/batch 59.66 | loss-text 2.8307\n",
      "2021-12-16 03:41:07,068 - INFO: | epoch  39 |  1200/ 3051 batches | lr 4.64e-06 | ms/batch 60.11 | loss-text 2.8819\n",
      "2021-12-16 03:41:13,111 - INFO: | epoch  39 |  1300/ 3051 batches | lr 4.64e-06 | ms/batch 60.42 | loss-text 2.7893\n",
      "2021-12-16 03:41:19,187 - INFO: | epoch  39 |  1400/ 3051 batches | lr 4.64e-06 | ms/batch 60.75 | loss-text 2.8749\n",
      "2021-12-16 03:41:25,236 - INFO: | epoch  39 |  1500/ 3051 batches | lr 4.64e-06 | ms/batch 60.48 | loss-text 2.8980\n",
      "2021-12-16 03:41:31,228 - INFO: | epoch  39 |  1600/ 3051 batches | lr 4.64e-06 | ms/batch 59.92 | loss-text 2.8501\n",
      "2021-12-16 03:41:37,241 - INFO: | epoch  39 |  1700/ 3051 batches | lr 4.64e-06 | ms/batch 60.12 | loss-text 2.8371\n",
      "2021-12-16 03:41:43,375 - INFO: | epoch  39 |  1800/ 3051 batches | lr 4.64e-06 | ms/batch 61.33 | loss-text 2.8690\n",
      "2021-12-16 03:41:49,489 - INFO: | epoch  39 |  1900/ 3051 batches | lr 4.64e-06 | ms/batch 61.13 | loss-text 2.8302\n",
      "2021-12-16 03:41:55,477 - INFO: | epoch  39 |  2000/ 3051 batches | lr 4.64e-06 | ms/batch 59.88 | loss-text 2.8477\n",
      "2021-12-16 03:42:01,510 - INFO: | epoch  39 |  2100/ 3051 batches | lr 4.64e-06 | ms/batch 60.32 | loss-text 2.8386\n",
      "2021-12-16 03:42:07,548 - INFO: | epoch  39 |  2200/ 3051 batches | lr 4.64e-06 | ms/batch 60.38 | loss-text 2.8421\n",
      "2021-12-16 03:42:13,570 - INFO: | epoch  39 |  2300/ 3051 batches | lr 4.64e-06 | ms/batch 60.21 | loss-text 2.8615\n",
      "2021-12-16 03:42:19,517 - INFO: | epoch  39 |  2400/ 3051 batches | lr 4.64e-06 | ms/batch 59.46 | loss-text 2.8737\n",
      "2021-12-16 03:42:25,532 - INFO: | epoch  39 |  2500/ 3051 batches | lr 4.64e-06 | ms/batch 60.15 | loss-text 2.8576\n",
      "2021-12-16 03:42:31,579 - INFO: | epoch  39 |  2600/ 3051 batches | lr 4.64e-06 | ms/batch 60.47 | loss-text 2.8172\n",
      "2021-12-16 03:42:37,595 - INFO: | epoch  39 |  2700/ 3051 batches | lr 4.64e-06 | ms/batch 60.14 | loss-text 2.8842\n",
      "2021-12-16 03:42:43,581 - INFO: | epoch  39 |  2800/ 3051 batches | lr 4.64e-06 | ms/batch 59.86 | loss-text 2.8568\n",
      "2021-12-16 03:42:49,584 - INFO: | epoch  39 |  2900/ 3051 batches | lr 4.64e-06 | ms/batch 60.02 | loss-text 2.8468\n",
      "2021-12-16 03:42:55,611 - INFO: | epoch  39 |  3000/ 3051 batches | lr 4.64e-06 | ms/batch 60.26 | loss-text 2.8604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003817\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10091, 'reflen': 10236, 'guess': [10091, 9067, 8043, 7019], 'correct': [5482, 1874, 697, 218]}\n",
      "ratio: 0.9858343102773558\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-16 03:43:19,819 - INFO: eval_greddy SPIDEr: 0.2164\n",
      "loading annotations into memory...\n",
      "0:00:00.003855\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9347, 'reflen': 9735, 'guess': [9347, 8323, 7299, 6275], 'correct': [5354, 1936, 753, 246]}\n",
      "ratio: 0.96014381099117\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 03:43:44,014 - INFO: eval_beam_2 SPIDEr: 0.2384\n",
      "loading annotations into memory...\n",
      "0:00:00.003945\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9090, 'reflen': 9597, 'guess': [9090, 8066, 7042, 6018], 'correct': [5229, 1933, 800, 282]}\n",
      "ratio: 0.9471709909345684\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-16 03:44:07,919 - INFO: eval_beam_3 SPIDEr: 0.2421\n",
      "loading annotations into memory...\n",
      "0:00:00.003898\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8907, 'reflen': 9491, 'guess': [8907, 7883, 6859, 5835], 'correct': [5142, 1909, 784, 272]}\n",
      "ratio: 0.9384680223368519\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 03:44:40,641 - INFO: eval_beam_4 SPIDEr: 0.2382\n",
      "2021-12-16 03:44:46,828 - INFO: | epoch  40 |   100/ 3051 batches | lr 4.55e-06 | ms/batch 61.84 | loss-text 2.8224\n",
      "2021-12-16 03:44:52,818 - INFO: | epoch  40 |   200/ 3051 batches | lr 4.55e-06 | ms/batch 59.89 | loss-text 2.8673\n",
      "2021-12-16 03:44:58,786 - INFO: | epoch  40 |   300/ 3051 batches | lr 4.55e-06 | ms/batch 59.67 | loss-text 2.8850\n",
      "2021-12-16 03:45:04,791 - INFO: | epoch  40 |   400/ 3051 batches | lr 4.55e-06 | ms/batch 60.04 | loss-text 2.8584\n",
      "2021-12-16 03:45:10,753 - INFO: | epoch  40 |   500/ 3051 batches | lr 4.55e-06 | ms/batch 59.62 | loss-text 2.8245\n",
      "2021-12-16 03:45:16,713 - INFO: | epoch  40 |   600/ 3051 batches | lr 4.55e-06 | ms/batch 59.59 | loss-text 2.8377\n",
      "2021-12-16 03:45:22,725 - INFO: | epoch  40 |   700/ 3051 batches | lr 4.55e-06 | ms/batch 60.11 | loss-text 2.8852\n",
      "2021-12-16 03:45:28,688 - INFO: | epoch  40 |   800/ 3051 batches | lr 4.55e-06 | ms/batch 59.63 | loss-text 2.8810\n",
      "2021-12-16 03:45:34,729 - INFO: | epoch  40 |   900/ 3051 batches | lr 4.55e-06 | ms/batch 60.40 | loss-text 2.8877\n",
      "2021-12-16 03:45:40,725 - INFO: | epoch  40 |  1000/ 3051 batches | lr 4.55e-06 | ms/batch 59.95 | loss-text 2.8368\n",
      "2021-12-16 03:45:46,680 - INFO: | epoch  40 |  1100/ 3051 batches | lr 4.55e-06 | ms/batch 59.54 | loss-text 2.8408\n",
      "2021-12-16 03:45:52,680 - INFO: | epoch  40 |  1200/ 3051 batches | lr 4.55e-06 | ms/batch 59.99 | loss-text 2.8335\n",
      "2021-12-16 03:45:58,661 - INFO: | epoch  40 |  1300/ 3051 batches | lr 4.55e-06 | ms/batch 59.80 | loss-text 2.8426\n",
      "2021-12-16 03:46:04,963 - INFO: | epoch  40 |  1400/ 3051 batches | lr 4.55e-06 | ms/batch 60.33 | loss-text 2.8612\n",
      "2021-12-16 03:46:10,965 - INFO: | epoch  40 |  1500/ 3051 batches | lr 4.55e-06 | ms/batch 60.02 | loss-text 2.8467\n",
      "2021-12-16 03:46:16,943 - INFO: | epoch  40 |  1600/ 3051 batches | lr 4.55e-06 | ms/batch 59.77 | loss-text 2.8345\n",
      "2021-12-16 03:46:22,976 - INFO: | epoch  40 |  1700/ 3051 batches | lr 4.55e-06 | ms/batch 60.32 | loss-text 2.8577\n",
      "2021-12-16 03:46:28,923 - INFO: | epoch  40 |  1800/ 3051 batches | lr 4.55e-06 | ms/batch 59.47 | loss-text 2.8517\n",
      "2021-12-16 03:46:34,940 - INFO: | epoch  40 |  1900/ 3051 batches | lr 4.55e-06 | ms/batch 60.16 | loss-text 2.8770\n",
      "2021-12-16 03:46:40,954 - INFO: | epoch  40 |  2000/ 3051 batches | lr 4.55e-06 | ms/batch 60.13 | loss-text 2.8085\n",
      "2021-12-16 03:46:46,990 - INFO: | epoch  40 |  2100/ 3051 batches | lr 4.55e-06 | ms/batch 60.35 | loss-text 2.8434\n",
      "2021-12-16 03:46:52,982 - INFO: | epoch  40 |  2200/ 3051 batches | lr 4.55e-06 | ms/batch 59.92 | loss-text 2.8420\n",
      "2021-12-16 03:46:59,005 - INFO: | epoch  40 |  2300/ 3051 batches | lr 4.55e-06 | ms/batch 60.23 | loss-text 2.8271\n",
      "2021-12-16 03:47:04,984 - INFO: | epoch  40 |  2400/ 3051 batches | lr 4.55e-06 | ms/batch 59.78 | loss-text 2.8608\n",
      "2021-12-16 03:47:10,990 - INFO: | epoch  40 |  2500/ 3051 batches | lr 4.55e-06 | ms/batch 60.06 | loss-text 2.8170\n",
      "2021-12-16 03:47:16,969 - INFO: | epoch  40 |  2600/ 3051 batches | lr 4.55e-06 | ms/batch 59.78 | loss-text 2.8894\n",
      "2021-12-16 03:47:23,007 - INFO: | epoch  40 |  2700/ 3051 batches | lr 4.55e-06 | ms/batch 60.37 | loss-text 2.8761\n",
      "2021-12-16 03:47:28,985 - INFO: | epoch  40 |  2800/ 3051 batches | lr 4.55e-06 | ms/batch 59.78 | loss-text 2.8801\n",
      "2021-12-16 03:47:34,993 - INFO: | epoch  40 |  2900/ 3051 batches | lr 4.55e-06 | ms/batch 60.07 | loss-text 2.8430\n",
      "2021-12-16 03:47:41,031 - INFO: | epoch  40 |  3000/ 3051 batches | lr 4.55e-06 | ms/batch 60.37 | loss-text 2.8499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003847\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10128, 'reflen': 10262, 'guess': [10128, 9104, 8080, 7056], 'correct': [5491, 1873, 689, 208]}\n",
      "ratio: 0.986942116546386\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.320\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.213\n",
      "2021-12-16 03:48:06,261 - INFO: eval_greddy SPIDEr: 0.2131\n",
      "loading annotations into memory...\n",
      "0:00:00.003930\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9341, 'reflen': 9754, 'guess': [9341, 8317, 7293, 6269], 'correct': [5303, 1917, 735, 230]}\n",
      "ratio: 0.9576583965551612\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.358\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-16 03:48:31,002 - INFO: eval_beam_2 SPIDEr: 0.2323\n",
      "loading annotations into memory...\n",
      "0:00:00.004022\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9082, 'reflen': 9597, 'guess': [9082, 8058, 7034, 6010], 'correct': [5231, 1909, 773, 266]}\n",
      "ratio: 0.9463373971031628\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 03:48:56,166 - INFO: eval_beam_3 SPIDEr: 0.2374\n",
      "loading annotations into memory...\n",
      "0:00:00.003728\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8913, 'reflen': 9514, 'guess': [8913, 7889, 6865, 5841], 'correct': [5149, 1889, 774, 265]}\n",
      "ratio: 0.9368299348327793\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 03:49:27,967 - INFO: eval_beam_4 SPIDEr: 0.2354\n",
      "2021-12-16 03:49:34,112 - INFO: | epoch  41 |   100/ 3051 batches | lr 4.46e-06 | ms/batch 61.42 | loss-text 2.8559\n",
      "2021-12-16 03:49:39,992 - INFO: | epoch  41 |   200/ 3051 batches | lr 4.46e-06 | ms/batch 58.80 | loss-text 2.8146\n",
      "2021-12-16 03:49:45,988 - INFO: | epoch  41 |   300/ 3051 batches | lr 4.46e-06 | ms/batch 59.95 | loss-text 2.8888\n",
      "2021-12-16 03:49:52,006 - INFO: | epoch  41 |   400/ 3051 batches | lr 4.46e-06 | ms/batch 60.17 | loss-text 2.8643\n",
      "2021-12-16 03:49:57,973 - INFO: | epoch  41 |   500/ 3051 batches | lr 4.46e-06 | ms/batch 59.66 | loss-text 2.9066\n",
      "2021-12-16 03:50:03,995 - INFO: | epoch  41 |   600/ 3051 batches | lr 4.46e-06 | ms/batch 60.21 | loss-text 2.8218\n",
      "2021-12-16 03:50:09,977 - INFO: | epoch  41 |   700/ 3051 batches | lr 4.46e-06 | ms/batch 59.82 | loss-text 2.8345\n",
      "2021-12-16 03:50:15,994 - INFO: | epoch  41 |   800/ 3051 batches | lr 4.46e-06 | ms/batch 60.16 | loss-text 2.8494\n",
      "2021-12-16 03:50:21,944 - INFO: | epoch  41 |   900/ 3051 batches | lr 4.46e-06 | ms/batch 59.49 | loss-text 2.8606\n",
      "2021-12-16 03:50:27,935 - INFO: | epoch  41 |  1000/ 3051 batches | lr 4.46e-06 | ms/batch 59.91 | loss-text 2.8821\n",
      "2021-12-16 03:50:33,859 - INFO: | epoch  41 |  1100/ 3051 batches | lr 4.46e-06 | ms/batch 59.23 | loss-text 2.8523\n",
      "2021-12-16 03:50:39,845 - INFO: | epoch  41 |  1200/ 3051 batches | lr 4.46e-06 | ms/batch 59.86 | loss-text 2.8368\n",
      "2021-12-16 03:50:45,873 - INFO: | epoch  41 |  1300/ 3051 batches | lr 4.46e-06 | ms/batch 60.27 | loss-text 2.8659\n",
      "2021-12-16 03:50:51,857 - INFO: | epoch  41 |  1400/ 3051 batches | lr 4.46e-06 | ms/batch 59.83 | loss-text 2.8513\n",
      "2021-12-16 03:50:57,827 - INFO: | epoch  41 |  1500/ 3051 batches | lr 4.46e-06 | ms/batch 59.70 | loss-text 2.8830\n",
      "2021-12-16 03:51:03,792 - INFO: | epoch  41 |  1600/ 3051 batches | lr 4.46e-06 | ms/batch 59.65 | loss-text 2.8506\n",
      "2021-12-16 03:51:09,821 - INFO: | epoch  41 |  1700/ 3051 batches | lr 4.46e-06 | ms/batch 60.27 | loss-text 2.8490\n",
      "2021-12-16 03:51:15,815 - INFO: | epoch  41 |  1800/ 3051 batches | lr 4.46e-06 | ms/batch 59.93 | loss-text 2.8681\n",
      "2021-12-16 03:51:21,853 - INFO: | epoch  41 |  1900/ 3051 batches | lr 4.46e-06 | ms/batch 60.38 | loss-text 2.8696\n",
      "2021-12-16 03:51:27,876 - INFO: | epoch  41 |  2000/ 3051 batches | lr 4.46e-06 | ms/batch 60.22 | loss-text 2.8697\n",
      "2021-12-16 03:51:33,874 - INFO: | epoch  41 |  2100/ 3051 batches | lr 4.46e-06 | ms/batch 59.97 | loss-text 2.8490\n",
      "2021-12-16 03:51:39,890 - INFO: | epoch  41 |  2200/ 3051 batches | lr 4.46e-06 | ms/batch 60.15 | loss-text 2.8414\n",
      "2021-12-16 03:51:45,948 - INFO: | epoch  41 |  2300/ 3051 batches | lr 4.46e-06 | ms/batch 60.58 | loss-text 2.8408\n",
      "2021-12-16 03:51:51,992 - INFO: | epoch  41 |  2400/ 3051 batches | lr 4.46e-06 | ms/batch 60.43 | loss-text 2.8233\n",
      "2021-12-16 03:51:57,982 - INFO: | epoch  41 |  2500/ 3051 batches | lr 4.46e-06 | ms/batch 59.89 | loss-text 2.8406\n",
      "2021-12-16 03:52:04,039 - INFO: | epoch  41 |  2600/ 3051 batches | lr 4.46e-06 | ms/batch 60.57 | loss-text 2.8173\n",
      "2021-12-16 03:52:10,015 - INFO: | epoch  41 |  2700/ 3051 batches | lr 4.46e-06 | ms/batch 59.75 | loss-text 2.8517\n",
      "2021-12-16 03:52:16,023 - INFO: | epoch  41 |  2800/ 3051 batches | lr 4.46e-06 | ms/batch 60.07 | loss-text 2.8276\n",
      "2021-12-16 03:52:22,000 - INFO: | epoch  41 |  2900/ 3051 batches | lr 4.46e-06 | ms/batch 59.77 | loss-text 2.8548\n",
      "2021-12-16 03:52:27,977 - INFO: | epoch  41 |  3000/ 3051 batches | lr 4.46e-06 | ms/batch 59.76 | loss-text 2.8465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003918\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10035, 'reflen': 10211, 'guess': [10035, 9011, 7987, 6963], 'correct': [5500, 1888, 702, 223]}\n",
      "ratio: 0.982763686220646\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.333\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.329\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.219\n",
      "2021-12-16 03:52:54,567 - INFO: eval_greddy SPIDEr: 0.2187\n",
      "loading annotations into memory...\n",
      "0:00:00.003907\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9369, 'reflen': 9761, 'guess': [9369, 8345, 7321, 6297], 'correct': [5364, 1947, 766, 255]}\n",
      "ratio: 0.9598401803092962\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 03:53:18,777 - INFO: eval_beam_2 SPIDEr: 0.2377\n",
      "loading annotations into memory...\n",
      "0:00:00.003843\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9125, 'reflen': 9593, 'guess': [9125, 8101, 7077, 6053], 'correct': [5247, 1947, 808, 290]}\n",
      "ratio: 0.9512144271863909\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.378\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-16 03:53:46,671 - INFO: eval_beam_3 SPIDEr: 0.2429\n",
      "loading annotations into memory...\n",
      "0:00:00.004052\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8923, 'reflen': 9492, 'guess': [8923, 7899, 6875, 5851], 'correct': [5172, 1901, 783, 272]}\n",
      "ratio: 0.9400547829750379\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-16 03:54:14,734 - INFO: eval_beam_4 SPIDEr: 0.2397\n",
      "2021-12-16 03:54:20,907 - INFO: | epoch  42 |   100/ 3051 batches | lr 4.37e-06 | ms/batch 61.70 | loss-text 2.8597\n",
      "2021-12-16 03:54:26,817 - INFO: | epoch  42 |   200/ 3051 batches | lr 4.37e-06 | ms/batch 59.09 | loss-text 2.8464\n",
      "2021-12-16 03:54:32,788 - INFO: | epoch  42 |   300/ 3051 batches | lr 4.37e-06 | ms/batch 59.71 | loss-text 2.7904\n",
      "2021-12-16 03:54:38,755 - INFO: | epoch  42 |   400/ 3051 batches | lr 4.37e-06 | ms/batch 59.66 | loss-text 2.8731\n",
      "2021-12-16 03:54:44,689 - INFO: | epoch  42 |   500/ 3051 batches | lr 4.37e-06 | ms/batch 59.33 | loss-text 2.8532\n",
      "2021-12-16 03:54:50,670 - INFO: | epoch  42 |   600/ 3051 batches | lr 4.37e-06 | ms/batch 59.80 | loss-text 2.8876\n",
      "2021-12-16 03:54:56,622 - INFO: | epoch  42 |   700/ 3051 batches | lr 4.37e-06 | ms/batch 59.52 | loss-text 2.8426\n",
      "2021-12-16 03:55:02,633 - INFO: | epoch  42 |   800/ 3051 batches | lr 4.37e-06 | ms/batch 60.10 | loss-text 2.8239\n",
      "2021-12-16 03:55:08,652 - INFO: | epoch  42 |   900/ 3051 batches | lr 4.37e-06 | ms/batch 60.18 | loss-text 2.8563\n",
      "2021-12-16 03:55:14,616 - INFO: | epoch  42 |  1000/ 3051 batches | lr 4.37e-06 | ms/batch 59.63 | loss-text 2.8622\n",
      "2021-12-16 03:55:20,546 - INFO: | epoch  42 |  1100/ 3051 batches | lr 4.37e-06 | ms/batch 59.29 | loss-text 2.8600\n",
      "2021-12-16 03:55:26,516 - INFO: | epoch  42 |  1200/ 3051 batches | lr 4.37e-06 | ms/batch 59.70 | loss-text 2.8496\n",
      "2021-12-16 03:55:32,518 - INFO: | epoch  42 |  1300/ 3051 batches | lr 4.37e-06 | ms/batch 60.01 | loss-text 2.8387\n",
      "2021-12-16 03:55:38,500 - INFO: | epoch  42 |  1400/ 3051 batches | lr 4.37e-06 | ms/batch 59.81 | loss-text 2.8203\n",
      "2021-12-16 03:55:44,522 - INFO: | epoch  42 |  1500/ 3051 batches | lr 4.37e-06 | ms/batch 60.22 | loss-text 2.8617\n",
      "2021-12-16 03:55:50,533 - INFO: | epoch  42 |  1600/ 3051 batches | lr 4.37e-06 | ms/batch 60.10 | loss-text 2.8230\n",
      "2021-12-16 03:55:56,487 - INFO: | epoch  42 |  1700/ 3051 batches | lr 4.37e-06 | ms/batch 59.53 | loss-text 2.8540\n",
      "2021-12-16 03:56:02,448 - INFO: | epoch  42 |  1800/ 3051 batches | lr 4.37e-06 | ms/batch 59.61 | loss-text 2.8585\n",
      "2021-12-16 03:56:08,490 - INFO: | epoch  42 |  1900/ 3051 batches | lr 4.37e-06 | ms/batch 60.41 | loss-text 2.8524\n",
      "2021-12-16 03:56:14,492 - INFO: | epoch  42 |  2000/ 3051 batches | lr 4.37e-06 | ms/batch 60.02 | loss-text 2.8384\n",
      "2021-12-16 03:56:20,501 - INFO: | epoch  42 |  2100/ 3051 batches | lr 4.37e-06 | ms/batch 60.08 | loss-text 2.8613\n",
      "2021-12-16 03:56:26,567 - INFO: | epoch  42 |  2200/ 3051 batches | lr 4.37e-06 | ms/batch 60.65 | loss-text 2.8566\n",
      "2021-12-16 03:56:32,580 - INFO: | epoch  42 |  2300/ 3051 batches | lr 4.37e-06 | ms/batch 60.12 | loss-text 2.8748\n",
      "2021-12-16 03:56:38,553 - INFO: | epoch  42 |  2400/ 3051 batches | lr 4.37e-06 | ms/batch 59.73 | loss-text 2.8621\n",
      "2021-12-16 03:56:44,557 - INFO: | epoch  42 |  2500/ 3051 batches | lr 4.37e-06 | ms/batch 60.03 | loss-text 2.8760\n",
      "2021-12-16 03:56:50,506 - INFO: | epoch  42 |  2600/ 3051 batches | lr 4.37e-06 | ms/batch 59.48 | loss-text 2.8705\n",
      "2021-12-16 03:56:56,532 - INFO: | epoch  42 |  2700/ 3051 batches | lr 4.37e-06 | ms/batch 60.26 | loss-text 2.8662\n",
      "2021-12-16 03:57:02,554 - INFO: | epoch  42 |  2800/ 3051 batches | lr 4.37e-06 | ms/batch 60.22 | loss-text 2.8589\n",
      "2021-12-16 03:57:08,583 - INFO: | epoch  42 |  2900/ 3051 batches | lr 4.37e-06 | ms/batch 60.28 | loss-text 2.8625\n",
      "2021-12-16 03:57:14,559 - INFO: | epoch  42 |  3000/ 3051 batches | lr 4.37e-06 | ms/batch 59.75 | loss-text 2.8658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003859\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10058, 'reflen': 10210, 'guess': [10058, 9034, 8010, 6986], 'correct': [5476, 1854, 692, 220]}\n",
      "ratio: 0.9851126346717938\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.327\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2021-12-16 03:57:38,423 - INFO: eval_greddy SPIDEr: 0.2167\n",
      "loading annotations into memory...\n",
      "0:00:00.003937\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9313, 'reflen': 9750, 'guess': [9313, 8289, 7265, 6241], 'correct': [5321, 1917, 756, 250]}\n",
      "ratio: 0.9551794871793892\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 03:58:02,862 - INFO: eval_beam_2 SPIDEr: 0.2387\n",
      "loading annotations into memory...\n",
      "0:00:00.004045\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9096, 'reflen': 9601, 'guess': [9096, 8072, 7048, 6024], 'correct': [5186, 1885, 777, 267]}\n",
      "ratio: 0.9474013123631968\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-16 03:58:28,080 - INFO: eval_beam_3 SPIDEr: 0.2342\n",
      "loading annotations into memory...\n",
      "0:00:00.003939\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8888, 'reflen': 9462, 'guess': [8888, 7864, 6840, 5816], 'correct': [5139, 1900, 783, 269]}\n",
      "ratio: 0.9393362925384761\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 03:58:56,540 - INFO: eval_beam_4 SPIDEr: 0.2383\n",
      "2021-12-16 03:59:02,764 - INFO: | epoch  43 |   100/ 3051 batches | lr 4.28e-06 | ms/batch 62.20 | loss-text 2.8594\n",
      "2021-12-16 03:59:08,707 - INFO: | epoch  43 |   200/ 3051 batches | lr 4.28e-06 | ms/batch 59.42 | loss-text 2.9005\n",
      "2021-12-16 03:59:14,804 - INFO: | epoch  43 |   300/ 3051 batches | lr 4.28e-06 | ms/batch 60.97 | loss-text 2.8163\n",
      "2021-12-16 03:59:20,820 - INFO: | epoch  43 |   400/ 3051 batches | lr 4.28e-06 | ms/batch 60.15 | loss-text 2.8737\n",
      "2021-12-16 03:59:26,800 - INFO: | epoch  43 |   500/ 3051 batches | lr 4.28e-06 | ms/batch 59.79 | loss-text 2.8428\n",
      "2021-12-16 03:59:32,733 - INFO: | epoch  43 |   600/ 3051 batches | lr 4.28e-06 | ms/batch 59.33 | loss-text 2.8256\n",
      "2021-12-16 03:59:38,712 - INFO: | epoch  43 |   700/ 3051 batches | lr 4.28e-06 | ms/batch 59.78 | loss-text 2.8186\n",
      "2021-12-16 03:59:44,695 - INFO: | epoch  43 |   800/ 3051 batches | lr 4.28e-06 | ms/batch 59.83 | loss-text 2.8440\n",
      "2021-12-16 03:59:50,686 - INFO: | epoch  43 |   900/ 3051 batches | lr 4.28e-06 | ms/batch 59.90 | loss-text 2.9023\n",
      "2021-12-16 03:59:56,692 - INFO: | epoch  43 |  1000/ 3051 batches | lr 4.28e-06 | ms/batch 60.05 | loss-text 2.8632\n",
      "2021-12-16 04:00:02,736 - INFO: | epoch  43 |  1100/ 3051 batches | lr 4.28e-06 | ms/batch 60.43 | loss-text 2.8491\n",
      "2021-12-16 04:00:08,731 - INFO: | epoch  43 |  1200/ 3051 batches | lr 4.28e-06 | ms/batch 59.95 | loss-text 2.8293\n",
      "2021-12-16 04:00:14,711 - INFO: | epoch  43 |  1300/ 3051 batches | lr 4.28e-06 | ms/batch 59.79 | loss-text 2.8448\n",
      "2021-12-16 04:00:20,664 - INFO: | epoch  43 |  1400/ 3051 batches | lr 4.28e-06 | ms/batch 59.53 | loss-text 2.8435\n",
      "2021-12-16 04:00:26,638 - INFO: | epoch  43 |  1500/ 3051 batches | lr 4.28e-06 | ms/batch 59.73 | loss-text 2.8366\n",
      "2021-12-16 04:00:32,612 - INFO: | epoch  43 |  1600/ 3051 batches | lr 4.28e-06 | ms/batch 59.74 | loss-text 2.8434\n",
      "2021-12-16 04:00:38,628 - INFO: | epoch  43 |  1700/ 3051 batches | lr 4.28e-06 | ms/batch 60.15 | loss-text 2.8372\n",
      "2021-12-16 04:00:44,612 - INFO: | epoch  43 |  1800/ 3051 batches | lr 4.28e-06 | ms/batch 59.83 | loss-text 2.8812\n",
      "2021-12-16 04:00:50,663 - INFO: | epoch  43 |  1900/ 3051 batches | lr 4.28e-06 | ms/batch 60.51 | loss-text 2.8727\n",
      "2021-12-16 04:00:56,704 - INFO: | epoch  43 |  2000/ 3051 batches | lr 4.28e-06 | ms/batch 60.41 | loss-text 2.8605\n",
      "2021-12-16 04:01:02,709 - INFO: | epoch  43 |  2100/ 3051 batches | lr 4.28e-06 | ms/batch 60.04 | loss-text 2.8785\n",
      "2021-12-16 04:01:08,700 - INFO: | epoch  43 |  2200/ 3051 batches | lr 4.28e-06 | ms/batch 59.90 | loss-text 2.8461\n",
      "2021-12-16 04:01:14,700 - INFO: | epoch  43 |  2300/ 3051 batches | lr 4.28e-06 | ms/batch 60.00 | loss-text 2.8659\n",
      "2021-12-16 04:01:20,706 - INFO: | epoch  43 |  2400/ 3051 batches | lr 4.28e-06 | ms/batch 60.05 | loss-text 2.8455\n",
      "2021-12-16 04:01:26,667 - INFO: | epoch  43 |  2500/ 3051 batches | lr 4.28e-06 | ms/batch 59.61 | loss-text 2.8601\n",
      "2021-12-16 04:01:32,638 - INFO: | epoch  43 |  2600/ 3051 batches | lr 4.28e-06 | ms/batch 59.70 | loss-text 2.8631\n",
      "2021-12-16 04:01:38,714 - INFO: | epoch  43 |  2700/ 3051 batches | lr 4.28e-06 | ms/batch 60.75 | loss-text 2.8353\n",
      "2021-12-16 04:01:44,757 - INFO: | epoch  43 |  2800/ 3051 batches | lr 4.28e-06 | ms/batch 60.43 | loss-text 2.8453\n",
      "2021-12-16 04:01:50,743 - INFO: | epoch  43 |  2900/ 3051 batches | lr 4.28e-06 | ms/batch 59.86 | loss-text 2.8579\n",
      "2021-12-16 04:01:56,764 - INFO: | epoch  43 |  3000/ 3051 batches | lr 4.28e-06 | ms/batch 60.20 | loss-text 2.8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003866\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10023, 'reflen': 10202, 'guess': [10023, 8999, 7975, 6951], 'correct': [5423, 1852, 698, 230]}\n",
      "ratio: 0.9824544207017268\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-16 04:02:23,800 - INFO: eval_greddy SPIDEr: 0.2164\n",
      "loading annotations into memory...\n",
      "0:00:00.003926\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9314, 'reflen': 9708, 'guess': [9314, 8290, 7266, 6242], 'correct': [5319, 1930, 774, 261]}\n",
      "ratio: 0.9594149155334817\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-16 04:02:44,717 - INFO: eval_beam_2 SPIDEr: 0.2395\n",
      "loading annotations into memory...\n",
      "0:00:00.004017\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9057, 'reflen': 9564, 'guess': [9057, 8033, 7009, 5985], 'correct': [5243, 1928, 795, 278]}\n",
      "ratio: 0.9469887076536023\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 04:03:10,268 - INFO: eval_beam_3 SPIDEr: 0.2387\n",
      "loading annotations into memory...\n",
      "0:00:00.003876\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8861, 'reflen': 9466, 'guess': [8861, 7837, 6813, 5789], 'correct': [5172, 1954, 822, 288]}\n",
      "ratio: 0.93608704838359\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.379\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-16 04:03:38,456 - INFO: eval_beam_4 SPIDEr: 0.2433\n",
      "2021-12-16 04:03:44,617 - INFO: | epoch  44 |   100/ 3051 batches | lr 4.19e-06 | ms/batch 61.59 | loss-text 2.8275\n",
      "2021-12-16 04:03:50,582 - INFO: | epoch  44 |   200/ 3051 batches | lr 4.19e-06 | ms/batch 59.63 | loss-text 2.8602\n",
      "2021-12-16 04:03:56,535 - INFO: | epoch  44 |   300/ 3051 batches | lr 4.19e-06 | ms/batch 59.53 | loss-text 2.8843\n",
      "2021-12-16 04:04:02,511 - INFO: | epoch  44 |   400/ 3051 batches | lr 4.19e-06 | ms/batch 59.75 | loss-text 2.8554\n",
      "2021-12-16 04:04:08,479 - INFO: | epoch  44 |   500/ 3051 batches | lr 4.19e-06 | ms/batch 59.67 | loss-text 2.8505\n",
      "2021-12-16 04:04:14,436 - INFO: | epoch  44 |   600/ 3051 batches | lr 4.19e-06 | ms/batch 59.56 | loss-text 2.8600\n",
      "2021-12-16 04:04:20,392 - INFO: | epoch  44 |   700/ 3051 batches | lr 4.19e-06 | ms/batch 59.56 | loss-text 2.8205\n",
      "2021-12-16 04:04:26,394 - INFO: | epoch  44 |   800/ 3051 batches | lr 4.19e-06 | ms/batch 60.01 | loss-text 2.8780\n",
      "2021-12-16 04:04:32,367 - INFO: | epoch  44 |   900/ 3051 batches | lr 4.19e-06 | ms/batch 59.72 | loss-text 2.8510\n",
      "2021-12-16 04:04:38,375 - INFO: | epoch  44 |  1000/ 3051 batches | lr 4.19e-06 | ms/batch 60.08 | loss-text 2.8364\n",
      "2021-12-16 04:04:44,339 - INFO: | epoch  44 |  1100/ 3051 batches | lr 4.19e-06 | ms/batch 59.63 | loss-text 2.8621\n",
      "2021-12-16 04:04:50,334 - INFO: | epoch  44 |  1200/ 3051 batches | lr 4.19e-06 | ms/batch 59.94 | loss-text 2.8735\n",
      "2021-12-16 04:04:56,363 - INFO: | epoch  44 |  1300/ 3051 batches | lr 4.19e-06 | ms/batch 60.28 | loss-text 2.8592\n",
      "2021-12-16 04:05:02,370 - INFO: | epoch  44 |  1400/ 3051 batches | lr 4.19e-06 | ms/batch 60.06 | loss-text 2.8863\n",
      "2021-12-16 04:05:08,428 - INFO: | epoch  44 |  1500/ 3051 batches | lr 4.19e-06 | ms/batch 60.58 | loss-text 2.8612\n",
      "2021-12-16 04:05:14,385 - INFO: | epoch  44 |  1600/ 3051 batches | lr 4.19e-06 | ms/batch 59.56 | loss-text 2.8702\n",
      "2021-12-16 04:05:20,383 - INFO: | epoch  44 |  1700/ 3051 batches | lr 4.19e-06 | ms/batch 59.97 | loss-text 2.8364\n",
      "2021-12-16 04:05:26,359 - INFO: | epoch  44 |  1800/ 3051 batches | lr 4.19e-06 | ms/batch 59.76 | loss-text 2.8666\n",
      "2021-12-16 04:05:32,390 - INFO: | epoch  44 |  1900/ 3051 batches | lr 4.19e-06 | ms/batch 60.30 | loss-text 2.8174\n",
      "2021-12-16 04:05:38,432 - INFO: | epoch  44 |  2000/ 3051 batches | lr 4.19e-06 | ms/batch 60.42 | loss-text 2.8601\n",
      "2021-12-16 04:05:44,416 - INFO: | epoch  44 |  2100/ 3051 batches | lr 4.19e-06 | ms/batch 59.83 | loss-text 2.8677\n",
      "2021-12-16 04:05:50,419 - INFO: | epoch  44 |  2200/ 3051 batches | lr 4.19e-06 | ms/batch 60.02 | loss-text 2.8582\n",
      "2021-12-16 04:05:56,397 - INFO: | epoch  44 |  2300/ 3051 batches | lr 4.19e-06 | ms/batch 59.77 | loss-text 2.8261\n",
      "2021-12-16 04:06:02,360 - INFO: | epoch  44 |  2400/ 3051 batches | lr 4.19e-06 | ms/batch 59.63 | loss-text 2.8282\n",
      "2021-12-16 04:06:08,342 - INFO: | epoch  44 |  2500/ 3051 batches | lr 4.19e-06 | ms/batch 59.81 | loss-text 2.8818\n",
      "2021-12-16 04:06:14,326 - INFO: | epoch  44 |  2600/ 3051 batches | lr 4.19e-06 | ms/batch 59.83 | loss-text 2.8665\n",
      "2021-12-16 04:06:20,348 - INFO: | epoch  44 |  2700/ 3051 batches | lr 4.19e-06 | ms/batch 60.22 | loss-text 2.8860\n",
      "2021-12-16 04:06:26,386 - INFO: | epoch  44 |  2800/ 3051 batches | lr 4.19e-06 | ms/batch 60.37 | loss-text 2.8748\n",
      "2021-12-16 04:06:32,395 - INFO: | epoch  44 |  2900/ 3051 batches | lr 4.19e-06 | ms/batch 60.09 | loss-text 2.8452\n",
      "2021-12-16 04:06:38,401 - INFO: | epoch  44 |  3000/ 3051 batches | lr 4.19e-06 | ms/batch 60.05 | loss-text 2.8064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003981\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10065, 'reflen': 10223, 'guess': [10065, 9041, 8017, 6993], 'correct': [5442, 1844, 687, 215]}\n",
      "ratio: 0.9845446542109962\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.353\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.321\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2021-12-16 04:07:02,380 - INFO: eval_greddy SPIDEr: 0.2140\n",
      "loading annotations into memory...\n",
      "0:00:00.003942\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9413, 'reflen': 9758, 'guess': [9413, 8389, 7365, 6341], 'correct': [5381, 1956, 775, 253]}\n",
      "ratio: 0.9646443943430042\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 04:07:23,784 - INFO: eval_beam_2 SPIDEr: 0.2371\n",
      "loading annotations into memory...\n",
      "0:00:00.003909\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9109, 'reflen': 9596, 'guess': [9109, 8085, 7061, 6037], 'correct': [5227, 1900, 780, 273]}\n",
      "ratio: 0.9492496873696384\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 04:07:50,686 - INFO: eval_beam_3 SPIDEr: 0.2375\n",
      "loading annotations into memory...\n",
      "0:00:00.003984\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8879, 'reflen': 9461, 'guess': [8879, 7855, 6831, 5807], 'correct': [5173, 1919, 809, 288]}\n",
      "ratio: 0.9384843039846804\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-16 04:08:18,405 - INFO: eval_beam_4 SPIDEr: 0.2414\n",
      "2021-12-16 04:08:24,529 - INFO: | epoch  45 |   100/ 3051 batches | lr 4.11e-06 | ms/batch 61.21 | loss-text 2.8470\n",
      "2021-12-16 04:08:30,506 - INFO: | epoch  45 |   200/ 3051 batches | lr 4.11e-06 | ms/batch 59.76 | loss-text 2.8667\n",
      "2021-12-16 04:08:36,403 - INFO: | epoch  45 |   300/ 3051 batches | lr 4.11e-06 | ms/batch 58.97 | loss-text 2.8805\n",
      "2021-12-16 04:08:42,322 - INFO: | epoch  45 |   400/ 3051 batches | lr 4.11e-06 | ms/batch 59.18 | loss-text 2.8354\n",
      "2021-12-16 04:08:48,276 - INFO: | epoch  45 |   500/ 3051 batches | lr 4.11e-06 | ms/batch 59.54 | loss-text 2.8465\n",
      "2021-12-16 04:08:54,248 - INFO: | epoch  45 |   600/ 3051 batches | lr 4.11e-06 | ms/batch 59.71 | loss-text 2.8486\n",
      "2021-12-16 04:09:00,238 - INFO: | epoch  45 |   700/ 3051 batches | lr 4.11e-06 | ms/batch 59.90 | loss-text 2.8310\n",
      "2021-12-16 04:09:06,207 - INFO: | epoch  45 |   800/ 3051 batches | lr 4.11e-06 | ms/batch 59.68 | loss-text 2.8762\n",
      "2021-12-16 04:09:12,219 - INFO: | epoch  45 |   900/ 3051 batches | lr 4.11e-06 | ms/batch 60.11 | loss-text 2.8542\n",
      "2021-12-16 04:09:18,229 - INFO: | epoch  45 |  1000/ 3051 batches | lr 4.11e-06 | ms/batch 60.09 | loss-text 2.8780\n",
      "2021-12-16 04:09:24,236 - INFO: | epoch  45 |  1100/ 3051 batches | lr 4.11e-06 | ms/batch 60.07 | loss-text 2.8563\n",
      "2021-12-16 04:09:30,225 - INFO: | epoch  45 |  1200/ 3051 batches | lr 4.11e-06 | ms/batch 59.88 | loss-text 2.8868\n",
      "2021-12-16 04:09:36,279 - INFO: | epoch  45 |  1300/ 3051 batches | lr 4.11e-06 | ms/batch 60.54 | loss-text 2.8220\n",
      "2021-12-16 04:09:42,301 - INFO: | epoch  45 |  1400/ 3051 batches | lr 4.11e-06 | ms/batch 60.21 | loss-text 2.8173\n",
      "2021-12-16 04:09:48,423 - INFO: | epoch  45 |  1500/ 3051 batches | lr 4.11e-06 | ms/batch 61.21 | loss-text 2.8470\n",
      "2021-12-16 04:09:54,460 - INFO: | epoch  45 |  1600/ 3051 batches | lr 4.11e-06 | ms/batch 60.36 | loss-text 2.8085\n",
      "2021-12-16 04:10:00,449 - INFO: | epoch  45 |  1700/ 3051 batches | lr 4.11e-06 | ms/batch 59.89 | loss-text 2.7916\n",
      "2021-12-16 04:10:06,496 - INFO: | epoch  45 |  1800/ 3051 batches | lr 4.11e-06 | ms/batch 60.46 | loss-text 2.8214\n",
      "2021-12-16 04:10:12,531 - INFO: | epoch  45 |  1900/ 3051 batches | lr 4.11e-06 | ms/batch 60.34 | loss-text 2.8264\n",
      "2021-12-16 04:10:18,534 - INFO: | epoch  45 |  2000/ 3051 batches | lr 4.11e-06 | ms/batch 60.02 | loss-text 2.8552\n",
      "2021-12-16 04:10:24,574 - INFO: | epoch  45 |  2100/ 3051 batches | lr 4.11e-06 | ms/batch 60.40 | loss-text 2.8341\n",
      "2021-12-16 04:10:30,570 - INFO: | epoch  45 |  2200/ 3051 batches | lr 4.11e-06 | ms/batch 59.96 | loss-text 2.8367\n",
      "2021-12-16 04:10:36,549 - INFO: | epoch  45 |  2300/ 3051 batches | lr 4.11e-06 | ms/batch 59.78 | loss-text 2.8462\n",
      "2021-12-16 04:10:42,553 - INFO: | epoch  45 |  2400/ 3051 batches | lr 4.11e-06 | ms/batch 60.04 | loss-text 2.8501\n",
      "2021-12-16 04:10:48,524 - INFO: | epoch  45 |  2500/ 3051 batches | lr 4.11e-06 | ms/batch 59.70 | loss-text 2.8619\n",
      "2021-12-16 04:10:54,494 - INFO: | epoch  45 |  2600/ 3051 batches | lr 4.11e-06 | ms/batch 59.69 | loss-text 2.8681\n",
      "2021-12-16 04:11:00,509 - INFO: | epoch  45 |  2700/ 3051 batches | lr 4.11e-06 | ms/batch 60.14 | loss-text 2.8568\n",
      "2021-12-16 04:11:06,538 - INFO: | epoch  45 |  2800/ 3051 batches | lr 4.11e-06 | ms/batch 60.28 | loss-text 2.8282\n",
      "2021-12-16 04:11:12,535 - INFO: | epoch  45 |  2900/ 3051 batches | lr 4.11e-06 | ms/batch 59.97 | loss-text 2.8685\n",
      "2021-12-16 04:11:18,616 - INFO: | epoch  45 |  3000/ 3051 batches | lr 4.11e-06 | ms/batch 60.80 | loss-text 2.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004018\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9986, 'reflen': 10184, 'guess': [9986, 8962, 7938, 6914], 'correct': [5381, 1808, 674, 219]}\n",
      "ratio: 0.9805577376275549\n",
      "Bleu_1: 0.528\n",
      "Bleu_2: 0.323\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.312\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.209\n",
      "2021-12-16 04:11:43,443 - INFO: eval_greddy SPIDEr: 0.2090\n",
      "loading annotations into memory...\n",
      "0:00:00.003865\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9336, 'reflen': 9718, 'guess': [9336, 8312, 7288, 6264], 'correct': [5301, 1894, 744, 247]}\n",
      "ratio: 0.9606915003086066\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.355\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-16 04:12:10,029 - INFO: eval_beam_2 SPIDEr: 0.2313\n",
      "loading annotations into memory...\n",
      "0:00:00.004015\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9115, 'reflen': 9594, 'guess': [9115, 8091, 7067, 6043], 'correct': [5185, 1873, 780, 275]}\n",
      "ratio: 0.9500729622679851\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-16 04:12:37,868 - INFO: eval_beam_3 SPIDEr: 0.2330\n",
      "loading annotations into memory...\n",
      "0:00:00.003892\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8887, 'reflen': 9459, 'guess': [8887, 7863, 6839, 5815], 'correct': [5105, 1869, 774, 269]}\n",
      "ratio: 0.9395284913837678\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-16 04:13:07,340 - INFO: eval_beam_4 SPIDEr: 0.2352\n",
      "2021-12-16 04:13:13,525 - INFO: | epoch  46 |   100/ 3051 batches | lr 4.03e-06 | ms/batch 61.82 | loss-text 2.8786\n",
      "2021-12-16 04:13:19,490 - INFO: | epoch  46 |   200/ 3051 batches | lr 4.03e-06 | ms/batch 59.64 | loss-text 2.8330\n",
      "2021-12-16 04:13:25,466 - INFO: | epoch  46 |   300/ 3051 batches | lr 4.03e-06 | ms/batch 59.75 | loss-text 2.8356\n",
      "2021-12-16 04:13:31,384 - INFO: | epoch  46 |   400/ 3051 batches | lr 4.03e-06 | ms/batch 59.17 | loss-text 2.8847\n",
      "2021-12-16 04:13:37,351 - INFO: | epoch  46 |   500/ 3051 batches | lr 4.03e-06 | ms/batch 59.67 | loss-text 2.8212\n",
      "2021-12-16 04:13:43,352 - INFO: | epoch  46 |   600/ 3051 batches | lr 4.03e-06 | ms/batch 60.01 | loss-text 2.8153\n",
      "2021-12-16 04:13:49,348 - INFO: | epoch  46 |   700/ 3051 batches | lr 4.03e-06 | ms/batch 59.95 | loss-text 2.8535\n",
      "2021-12-16 04:13:55,281 - INFO: | epoch  46 |   800/ 3051 batches | lr 4.03e-06 | ms/batch 59.32 | loss-text 2.8927\n",
      "2021-12-16 04:14:01,250 - INFO: | epoch  46 |   900/ 3051 batches | lr 4.03e-06 | ms/batch 59.69 | loss-text 2.8199\n",
      "2021-12-16 04:14:07,231 - INFO: | epoch  46 |  1000/ 3051 batches | lr 4.03e-06 | ms/batch 59.80 | loss-text 2.7927\n",
      "2021-12-16 04:14:13,188 - INFO: | epoch  46 |  1100/ 3051 batches | lr 4.03e-06 | ms/batch 59.56 | loss-text 2.8907\n",
      "2021-12-16 04:14:19,177 - INFO: | epoch  46 |  1200/ 3051 batches | lr 4.03e-06 | ms/batch 59.88 | loss-text 2.8649\n",
      "2021-12-16 04:14:25,189 - INFO: | epoch  46 |  1300/ 3051 batches | lr 4.03e-06 | ms/batch 60.11 | loss-text 2.8374\n",
      "2021-12-16 04:14:31,217 - INFO: | epoch  46 |  1400/ 3051 batches | lr 4.03e-06 | ms/batch 60.28 | loss-text 2.8408\n",
      "2021-12-16 04:14:37,228 - INFO: | epoch  46 |  1500/ 3051 batches | lr 4.03e-06 | ms/batch 60.10 | loss-text 2.8631\n",
      "2021-12-16 04:14:43,254 - INFO: | epoch  46 |  1600/ 3051 batches | lr 4.03e-06 | ms/batch 60.26 | loss-text 2.8241\n",
      "2021-12-16 04:14:49,251 - INFO: | epoch  46 |  1700/ 3051 batches | lr 4.03e-06 | ms/batch 59.96 | loss-text 2.8549\n",
      "2021-12-16 04:14:55,261 - INFO: | epoch  46 |  1800/ 3051 batches | lr 4.03e-06 | ms/batch 60.09 | loss-text 2.8063\n",
      "2021-12-16 04:15:01,278 - INFO: | epoch  46 |  1900/ 3051 batches | lr 4.03e-06 | ms/batch 60.16 | loss-text 2.8365\n",
      "2021-12-16 04:15:07,305 - INFO: | epoch  46 |  2000/ 3051 batches | lr 4.03e-06 | ms/batch 60.27 | loss-text 2.8599\n",
      "2021-12-16 04:15:13,254 - INFO: | epoch  46 |  2100/ 3051 batches | lr 4.03e-06 | ms/batch 59.48 | loss-text 2.8827\n",
      "2021-12-16 04:15:19,251 - INFO: | epoch  46 |  2200/ 3051 batches | lr 4.03e-06 | ms/batch 59.96 | loss-text 2.8505\n",
      "2021-12-16 04:15:25,247 - INFO: | epoch  46 |  2300/ 3051 batches | lr 4.03e-06 | ms/batch 59.95 | loss-text 2.8670\n",
      "2021-12-16 04:15:31,225 - INFO: | epoch  46 |  2400/ 3051 batches | lr 4.03e-06 | ms/batch 59.78 | loss-text 2.8223\n",
      "2021-12-16 04:15:37,234 - INFO: | epoch  46 |  2500/ 3051 batches | lr 4.03e-06 | ms/batch 60.08 | loss-text 2.8859\n",
      "2021-12-16 04:15:43,241 - INFO: | epoch  46 |  2600/ 3051 batches | lr 4.03e-06 | ms/batch 60.06 | loss-text 2.8316\n",
      "2021-12-16 04:15:49,219 - INFO: | epoch  46 |  2700/ 3051 batches | lr 4.03e-06 | ms/batch 59.77 | loss-text 2.8380\n",
      "2021-12-16 04:15:55,191 - INFO: | epoch  46 |  2800/ 3051 batches | lr 4.03e-06 | ms/batch 59.72 | loss-text 2.8435\n",
      "2021-12-16 04:16:01,188 - INFO: | epoch  46 |  2900/ 3051 batches | lr 4.03e-06 | ms/batch 59.97 | loss-text 2.8064\n",
      "2021-12-16 04:16:07,214 - INFO: | epoch  46 |  3000/ 3051 batches | lr 4.03e-06 | ms/batch 60.26 | loss-text 2.8497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003893\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10072, 'reflen': 10245, 'guess': [10072, 9048, 8024, 7000], 'correct': [5431, 1848, 686, 214]}\n",
      "ratio: 0.9831137140067366\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.326\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.323\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2021-12-16 04:16:31,611 - INFO: eval_greddy SPIDEr: 0.2145\n",
      "loading annotations into memory...\n",
      "0:00:00.004003\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9389, 'reflen': 9782, 'guess': [9389, 8365, 7341, 6317], 'correct': [5361, 1977, 790, 270]}\n",
      "ratio: 0.9598241668369495\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.377\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-16 04:16:55,218 - INFO: eval_beam_2 SPIDEr: 0.2437\n",
      "loading annotations into memory...\n",
      "0:00:00.004140\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9106, 'reflen': 9604, 'guess': [9106, 8082, 7058, 6034], 'correct': [5204, 1916, 792, 284]}\n",
      "ratio: 0.9481466055809091\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-16 04:17:24,723 - INFO: eval_beam_3 SPIDEr: 0.2400\n",
      "loading annotations into memory...\n",
      "0:00:00.003811\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8930, 'reflen': 9488, 'guess': [8930, 7906, 6882, 5858], 'correct': [5168, 1922, 796, 284]}\n",
      "ratio: 0.9411888701516714\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-16 04:17:52,348 - INFO: eval_beam_4 SPIDEr: 0.2409\n",
      "2021-12-16 04:17:58,508 - INFO: | epoch  47 |   100/ 3051 batches | lr 3.95e-06 | ms/batch 61.57 | loss-text 2.8564\n",
      "2021-12-16 04:18:04,444 - INFO: | epoch  47 |   200/ 3051 batches | lr 3.95e-06 | ms/batch 59.35 | loss-text 2.8480\n",
      "2021-12-16 04:18:10,393 - INFO: | epoch  47 |   300/ 3051 batches | lr 3.95e-06 | ms/batch 59.49 | loss-text 2.8664\n",
      "2021-12-16 04:18:16,314 - INFO: | epoch  47 |   400/ 3051 batches | lr 3.95e-06 | ms/batch 59.20 | loss-text 2.8556\n",
      "2021-12-16 04:18:22,267 - INFO: | epoch  47 |   500/ 3051 batches | lr 3.95e-06 | ms/batch 59.52 | loss-text 2.8567\n",
      "2021-12-16 04:18:28,233 - INFO: | epoch  47 |   600/ 3051 batches | lr 3.95e-06 | ms/batch 59.66 | loss-text 2.8632\n",
      "2021-12-16 04:18:34,183 - INFO: | epoch  47 |   700/ 3051 batches | lr 3.95e-06 | ms/batch 59.49 | loss-text 2.8443\n",
      "2021-12-16 04:18:40,205 - INFO: | epoch  47 |   800/ 3051 batches | lr 3.95e-06 | ms/batch 60.21 | loss-text 2.8653\n",
      "2021-12-16 04:18:46,167 - INFO: | epoch  47 |   900/ 3051 batches | lr 3.95e-06 | ms/batch 59.61 | loss-text 2.8572\n",
      "2021-12-16 04:18:52,162 - INFO: | epoch  47 |  1000/ 3051 batches | lr 3.95e-06 | ms/batch 59.95 | loss-text 2.8260\n",
      "2021-12-16 04:18:58,178 - INFO: | epoch  47 |  1100/ 3051 batches | lr 3.95e-06 | ms/batch 60.15 | loss-text 2.8190\n",
      "2021-12-16 04:19:04,145 - INFO: | epoch  47 |  1200/ 3051 batches | lr 3.95e-06 | ms/batch 59.66 | loss-text 2.8391\n",
      "2021-12-16 04:19:10,150 - INFO: | epoch  47 |  1300/ 3051 batches | lr 3.95e-06 | ms/batch 60.05 | loss-text 2.8738\n",
      "2021-12-16 04:19:16,163 - INFO: | epoch  47 |  1400/ 3051 batches | lr 3.95e-06 | ms/batch 60.12 | loss-text 2.8232\n",
      "2021-12-16 04:19:22,165 - INFO: | epoch  47 |  1500/ 3051 batches | lr 3.95e-06 | ms/batch 60.02 | loss-text 2.8394\n",
      "2021-12-16 04:19:28,160 - INFO: | epoch  47 |  1600/ 3051 batches | lr 3.95e-06 | ms/batch 59.94 | loss-text 2.8574\n",
      "2021-12-16 04:19:34,131 - INFO: | epoch  47 |  1700/ 3051 batches | lr 3.95e-06 | ms/batch 59.70 | loss-text 2.8161\n",
      "2021-12-16 04:19:40,127 - INFO: | epoch  47 |  1800/ 3051 batches | lr 3.95e-06 | ms/batch 59.95 | loss-text 2.8027\n",
      "2021-12-16 04:19:46,151 - INFO: | epoch  47 |  1900/ 3051 batches | lr 3.95e-06 | ms/batch 60.23 | loss-text 2.8433\n",
      "2021-12-16 04:19:52,129 - INFO: | epoch  47 |  2000/ 3051 batches | lr 3.95e-06 | ms/batch 59.77 | loss-text 2.8351\n",
      "2021-12-16 04:19:58,124 - INFO: | epoch  47 |  2100/ 3051 batches | lr 3.95e-06 | ms/batch 59.94 | loss-text 2.8756\n",
      "2021-12-16 04:20:04,147 - INFO: | epoch  47 |  2200/ 3051 batches | lr 3.95e-06 | ms/batch 60.22 | loss-text 2.8690\n",
      "2021-12-16 04:20:10,145 - INFO: | epoch  47 |  2300/ 3051 batches | lr 3.95e-06 | ms/batch 59.97 | loss-text 2.8535\n",
      "2021-12-16 04:20:16,154 - INFO: | epoch  47 |  2400/ 3051 batches | lr 3.95e-06 | ms/batch 60.09 | loss-text 2.8545\n",
      "2021-12-16 04:20:22,120 - INFO: | epoch  47 |  2500/ 3051 batches | lr 3.95e-06 | ms/batch 59.65 | loss-text 2.8414\n",
      "2021-12-16 04:20:28,125 - INFO: | epoch  47 |  2600/ 3051 batches | lr 3.95e-06 | ms/batch 60.04 | loss-text 2.7983\n",
      "2021-12-16 04:20:34,137 - INFO: | epoch  47 |  2700/ 3051 batches | lr 3.95e-06 | ms/batch 60.11 | loss-text 2.8640\n",
      "2021-12-16 04:20:40,120 - INFO: | epoch  47 |  2800/ 3051 batches | lr 3.95e-06 | ms/batch 59.82 | loss-text 2.8362\n",
      "2021-12-16 04:20:46,130 - INFO: | epoch  47 |  2900/ 3051 batches | lr 3.95e-06 | ms/batch 60.09 | loss-text 2.8443\n",
      "2021-12-16 04:20:52,205 - INFO: | epoch  47 |  3000/ 3051 batches | lr 3.95e-06 | ms/batch 60.74 | loss-text 2.8365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003936\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10130, 'reflen': 10276, 'guess': [10130, 9106, 8082, 7058], 'correct': [5512, 1865, 701, 223]}\n",
      "ratio: 0.9857921370181991\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-16 04:21:17,329 - INFO: eval_greddy SPIDEr: 0.2155\n",
      "loading annotations into memory...\n",
      "0:00:00.003953\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9374, 'reflen': 9766, 'guess': [9374, 8350, 7326, 6302], 'correct': [5330, 1929, 758, 265]}\n",
      "ratio: 0.9598607413474339\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-16 04:21:41,214 - INFO: eval_beam_2 SPIDEr: 0.2406\n",
      "loading annotations into memory...\n",
      "0:00:00.003817\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9104, 'reflen': 9602, 'guess': [9104, 8080, 7056, 6032], 'correct': [5211, 1905, 775, 270]}\n",
      "ratio: 0.9481358050405178\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-16 04:22:05,095 - INFO: eval_beam_3 SPIDEr: 0.2372\n",
      "loading annotations into memory...\n",
      "0:00:00.003872\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8890, 'reflen': 9467, 'guess': [8890, 7866, 6842, 5818], 'correct': [5128, 1883, 777, 268]}\n",
      "ratio: 0.9390514418505398\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 04:22:34,143 - INFO: eval_beam_4 SPIDEr: 0.2385\n",
      "2021-12-16 04:22:40,297 - INFO: | epoch  48 |   100/ 3051 batches | lr 3.87e-06 | ms/batch 61.51 | loss-text 2.8425\n",
      "2021-12-16 04:22:46,301 - INFO: | epoch  48 |   200/ 3051 batches | lr 3.87e-06 | ms/batch 60.03 | loss-text 2.8634\n",
      "2021-12-16 04:22:52,280 - INFO: | epoch  48 |   300/ 3051 batches | lr 3.87e-06 | ms/batch 59.78 | loss-text 2.8781\n",
      "2021-12-16 04:22:58,209 - INFO: | epoch  48 |   400/ 3051 batches | lr 3.87e-06 | ms/batch 59.28 | loss-text 2.8299\n",
      "2021-12-16 04:23:04,204 - INFO: | epoch  48 |   500/ 3051 batches | lr 3.87e-06 | ms/batch 59.94 | loss-text 2.8160\n",
      "2021-12-16 04:23:10,188 - INFO: | epoch  48 |   600/ 3051 batches | lr 3.87e-06 | ms/batch 59.84 | loss-text 2.8362\n",
      "2021-12-16 04:23:16,170 - INFO: | epoch  48 |   700/ 3051 batches | lr 3.87e-06 | ms/batch 59.81 | loss-text 2.8274\n",
      "2021-12-16 04:23:22,173 - INFO: | epoch  48 |   800/ 3051 batches | lr 3.87e-06 | ms/batch 60.03 | loss-text 2.8795\n",
      "2021-12-16 04:23:28,139 - INFO: | epoch  48 |   900/ 3051 batches | lr 3.87e-06 | ms/batch 59.65 | loss-text 2.8894\n",
      "2021-12-16 04:23:34,070 - INFO: | epoch  48 |  1000/ 3051 batches | lr 3.87e-06 | ms/batch 59.31 | loss-text 2.8213\n",
      "2021-12-16 04:23:40,054 - INFO: | epoch  48 |  1100/ 3051 batches | lr 3.87e-06 | ms/batch 59.83 | loss-text 2.8704\n",
      "2021-12-16 04:23:46,019 - INFO: | epoch  48 |  1200/ 3051 batches | lr 3.87e-06 | ms/batch 59.64 | loss-text 2.8745\n",
      "2021-12-16 04:23:51,981 - INFO: | epoch  48 |  1300/ 3051 batches | lr 3.87e-06 | ms/batch 59.62 | loss-text 2.7889\n",
      "2021-12-16 04:23:57,973 - INFO: | epoch  48 |  1400/ 3051 batches | lr 3.87e-06 | ms/batch 59.91 | loss-text 2.8216\n",
      "2021-12-16 04:24:04,011 - INFO: | epoch  48 |  1500/ 3051 batches | lr 3.87e-06 | ms/batch 60.38 | loss-text 2.8312\n",
      "2021-12-16 04:24:10,032 - INFO: | epoch  48 |  1600/ 3051 batches | lr 3.87e-06 | ms/batch 60.20 | loss-text 2.8178\n",
      "2021-12-16 04:24:16,050 - INFO: | epoch  48 |  1700/ 3051 batches | lr 3.87e-06 | ms/batch 60.18 | loss-text 2.8686\n",
      "2021-12-16 04:24:21,980 - INFO: | epoch  48 |  1800/ 3051 batches | lr 3.87e-06 | ms/batch 59.29 | loss-text 2.8862\n",
      "2021-12-16 04:24:27,957 - INFO: | epoch  48 |  1900/ 3051 batches | lr 3.87e-06 | ms/batch 59.76 | loss-text 2.8211\n",
      "2021-12-16 04:24:33,982 - INFO: | epoch  48 |  2000/ 3051 batches | lr 3.87e-06 | ms/batch 60.24 | loss-text 2.8531\n",
      "2021-12-16 04:24:39,945 - INFO: | epoch  48 |  2100/ 3051 batches | lr 3.87e-06 | ms/batch 59.63 | loss-text 2.8502\n",
      "2021-12-16 04:24:45,911 - INFO: | epoch  48 |  2200/ 3051 batches | lr 3.87e-06 | ms/batch 59.65 | loss-text 2.8373\n",
      "2021-12-16 04:24:51,930 - INFO: | epoch  48 |  2300/ 3051 batches | lr 3.87e-06 | ms/batch 60.19 | loss-text 2.8257\n",
      "2021-12-16 04:24:57,882 - INFO: | epoch  48 |  2400/ 3051 batches | lr 3.87e-06 | ms/batch 59.51 | loss-text 2.8908\n",
      "2021-12-16 04:25:03,843 - INFO: | epoch  48 |  2500/ 3051 batches | lr 3.87e-06 | ms/batch 59.60 | loss-text 2.8199\n",
      "2021-12-16 04:25:09,892 - INFO: | epoch  48 |  2600/ 3051 batches | lr 3.87e-06 | ms/batch 60.49 | loss-text 2.8350\n",
      "2021-12-16 04:25:15,959 - INFO: | epoch  48 |  2700/ 3051 batches | lr 3.87e-06 | ms/batch 60.66 | loss-text 2.8830\n",
      "2021-12-16 04:25:21,998 - INFO: | epoch  48 |  2800/ 3051 batches | lr 3.87e-06 | ms/batch 60.39 | loss-text 2.8714\n",
      "2021-12-16 04:25:27,973 - INFO: | epoch  48 |  2900/ 3051 batches | lr 3.87e-06 | ms/batch 59.74 | loss-text 2.8470\n",
      "2021-12-16 04:25:33,989 - INFO: | epoch  48 |  3000/ 3051 batches | lr 3.87e-06 | ms/batch 60.16 | loss-text 2.8169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003879\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10060, 'reflen': 10244, 'guess': [10060, 9036, 8012, 6988], 'correct': [5488, 1875, 697, 212]}\n",
      "ratio: 0.9820382663021298\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-16 04:25:58,591 - INFO: eval_greddy SPIDEr: 0.2157\n",
      "loading annotations into memory...\n",
      "0:00:00.003899\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9341, 'reflen': 9761, 'guess': [9341, 8317, 7293, 6269], 'correct': [5354, 1951, 772, 256]}\n",
      "ratio: 0.9569716217599675\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-16 04:26:20,892 - INFO: eval_beam_2 SPIDEr: 0.2407\n",
      "loading annotations into memory...\n",
      "0:00:00.003931\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9082, 'reflen': 9585, 'guess': [9082, 8058, 7034, 6010], 'correct': [5247, 1943, 818, 284]}\n",
      "ratio: 0.9475221700572825\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.378\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-16 04:26:45,299 - INFO: eval_beam_3 SPIDEr: 0.2426\n",
      "loading annotations into memory...\n",
      "0:00:00.004251\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8893, 'reflen': 9482, 'guess': [8893, 7869, 6845, 5821], 'correct': [5148, 1903, 791, 274]}\n",
      "ratio: 0.9378823033114387\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.375\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-16 04:27:14,033 - INFO: eval_beam_4 SPIDEr: 0.2406\n",
      "2021-12-16 04:27:20,208 - INFO: | epoch  49 |   100/ 3051 batches | lr 3.79e-06 | ms/batch 61.72 | loss-text 2.8468\n",
      "2021-12-16 04:27:26,188 - INFO: | epoch  49 |   200/ 3051 batches | lr 3.79e-06 | ms/batch 59.79 | loss-text 2.8659\n",
      "2021-12-16 04:27:32,157 - INFO: | epoch  49 |   300/ 3051 batches | lr 3.79e-06 | ms/batch 59.69 | loss-text 2.8248\n",
      "2021-12-16 04:27:38,097 - INFO: | epoch  49 |   400/ 3051 batches | lr 3.79e-06 | ms/batch 59.39 | loss-text 2.8265\n",
      "2021-12-16 04:27:44,162 - INFO: | epoch  49 |   500/ 3051 batches | lr 3.79e-06 | ms/batch 60.65 | loss-text 2.8246\n",
      "2021-12-16 04:27:50,182 - INFO: | epoch  49 |   600/ 3051 batches | lr 3.79e-06 | ms/batch 60.19 | loss-text 2.8347\n",
      "2021-12-16 04:27:56,146 - INFO: | epoch  49 |   700/ 3051 batches | lr 3.79e-06 | ms/batch 59.63 | loss-text 2.8507\n",
      "2021-12-16 04:28:02,107 - INFO: | epoch  49 |   800/ 3051 batches | lr 3.79e-06 | ms/batch 59.60 | loss-text 2.8628\n",
      "2021-12-16 04:28:08,094 - INFO: | epoch  49 |   900/ 3051 batches | lr 3.79e-06 | ms/batch 59.86 | loss-text 2.8523\n",
      "2021-12-16 04:28:14,037 - INFO: | epoch  49 |  1000/ 3051 batches | lr 3.79e-06 | ms/batch 59.42 | loss-text 2.8484\n",
      "2021-12-16 04:28:19,991 - INFO: | epoch  49 |  1100/ 3051 batches | lr 3.79e-06 | ms/batch 59.53 | loss-text 2.8864\n",
      "2021-12-16 04:28:25,955 - INFO: | epoch  49 |  1200/ 3051 batches | lr 3.79e-06 | ms/batch 59.64 | loss-text 2.8206\n",
      "2021-12-16 04:28:31,957 - INFO: | epoch  49 |  1300/ 3051 batches | lr 3.79e-06 | ms/batch 60.02 | loss-text 2.8124\n",
      "2021-12-16 04:28:37,959 - INFO: | epoch  49 |  1400/ 3051 batches | lr 3.79e-06 | ms/batch 60.01 | loss-text 2.8414\n",
      "2021-12-16 04:28:43,919 - INFO: | epoch  49 |  1500/ 3051 batches | lr 3.79e-06 | ms/batch 59.59 | loss-text 2.8455\n",
      "2021-12-16 04:28:49,906 - INFO: | epoch  49 |  1600/ 3051 batches | lr 3.79e-06 | ms/batch 59.86 | loss-text 2.8552\n",
      "2021-12-16 04:28:55,933 - INFO: | epoch  49 |  1700/ 3051 batches | lr 3.79e-06 | ms/batch 60.27 | loss-text 2.8778\n",
      "2021-12-16 04:29:01,942 - INFO: | epoch  49 |  1800/ 3051 batches | lr 3.79e-06 | ms/batch 60.08 | loss-text 2.8282\n",
      "2021-12-16 04:29:07,930 - INFO: | epoch  49 |  1900/ 3051 batches | lr 3.79e-06 | ms/batch 59.87 | loss-text 2.8308\n",
      "2021-12-16 04:29:13,950 - INFO: | epoch  49 |  2000/ 3051 batches | lr 3.79e-06 | ms/batch 60.19 | loss-text 2.8494\n",
      "2021-12-16 04:29:20,052 - INFO: | epoch  49 |  2100/ 3051 batches | lr 3.79e-06 | ms/batch 61.02 | loss-text 2.8436\n",
      "2021-12-16 04:29:26,105 - INFO: | epoch  49 |  2200/ 3051 batches | lr 3.79e-06 | ms/batch 60.53 | loss-text 2.8915\n",
      "2021-12-16 04:29:32,097 - INFO: | epoch  49 |  2300/ 3051 batches | lr 3.79e-06 | ms/batch 59.91 | loss-text 2.8555\n",
      "2021-12-16 04:29:38,133 - INFO: | epoch  49 |  2400/ 3051 batches | lr 3.79e-06 | ms/batch 60.35 | loss-text 2.8387\n",
      "2021-12-16 04:29:44,172 - INFO: | epoch  49 |  2500/ 3051 batches | lr 3.79e-06 | ms/batch 60.39 | loss-text 2.8613\n",
      "2021-12-16 04:29:50,130 - INFO: | epoch  49 |  2600/ 3051 batches | lr 3.79e-06 | ms/batch 59.57 | loss-text 2.8429\n",
      "2021-12-16 04:29:56,177 - INFO: | epoch  49 |  2700/ 3051 batches | lr 3.79e-06 | ms/batch 60.46 | loss-text 2.8486\n",
      "2021-12-16 04:30:02,252 - INFO: | epoch  49 |  2800/ 3051 batches | lr 3.79e-06 | ms/batch 60.75 | loss-text 2.8331\n",
      "2021-12-16 04:30:08,241 - INFO: | epoch  49 |  2900/ 3051 batches | lr 3.79e-06 | ms/batch 59.88 | loss-text 2.8501\n",
      "2021-12-16 04:30:14,270 - INFO: | epoch  49 |  3000/ 3051 batches | lr 3.79e-06 | ms/batch 60.28 | loss-text 2.8532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003851\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10088, 'reflen': 10263, 'guess': [10088, 9064, 8040, 7016], 'correct': [5488, 1859, 698, 223]}\n",
      "ratio: 0.98294845561717\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.325\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-16 04:30:37,962 - INFO: eval_greddy SPIDEr: 0.2159\n",
      "loading annotations into memory...\n",
      "0:00:00.003743\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9342, 'reflen': 9730, 'guess': [9342, 8318, 7294, 6270], 'correct': [5329, 1930, 751, 244]}\n",
      "ratio: 0.9601233299074039\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-16 04:31:02,518 - INFO: eval_beam_2 SPIDEr: 0.2409\n",
      "loading annotations into memory...\n",
      "0:00:00.003953\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9093, 'reflen': 9602, 'guess': [9093, 8069, 7045, 6021], 'correct': [5218, 1903, 780, 256]}\n",
      "ratio: 0.9469902103727403\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-16 04:31:27,125 - INFO: eval_beam_3 SPIDEr: 0.2378\n",
      "loading annotations into memory...\n",
      "0:00:00.003982\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8892, 'reflen': 9491, 'guess': [8892, 7868, 6844, 5820], 'correct': [5154, 1904, 782, 268]}\n",
      "ratio: 0.9368875777050957\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-16 04:31:55,540 - INFO: eval_beam_4 SPIDEr: 0.2405\n",
      "2021-12-16 04:32:01,669 - INFO: | epoch  50 |   100/ 3051 batches | lr 3.72e-06 | ms/batch 61.26 | loss-text 2.8506\n",
      "2021-12-16 04:32:07,594 - INFO: | epoch  50 |   200/ 3051 batches | lr 3.72e-06 | ms/batch 59.24 | loss-text 2.8434\n",
      "2021-12-16 04:32:13,526 - INFO: | epoch  50 |   300/ 3051 batches | lr 3.72e-06 | ms/batch 59.31 | loss-text 2.8235\n",
      "2021-12-16 04:32:19,460 - INFO: | epoch  50 |   400/ 3051 batches | lr 3.72e-06 | ms/batch 59.33 | loss-text 2.8223\n",
      "2021-12-16 04:32:25,419 - INFO: | epoch  50 |   500/ 3051 batches | lr 3.72e-06 | ms/batch 59.59 | loss-text 2.8246\n",
      "2021-12-16 04:32:31,432 - INFO: | epoch  50 |   600/ 3051 batches | lr 3.72e-06 | ms/batch 60.11 | loss-text 2.8312\n",
      "2021-12-16 04:32:37,398 - INFO: | epoch  50 |   700/ 3051 batches | lr 3.72e-06 | ms/batch 59.65 | loss-text 2.8207\n",
      "2021-12-16 04:32:43,394 - INFO: | epoch  50 |   800/ 3051 batches | lr 3.72e-06 | ms/batch 59.95 | loss-text 2.8360\n",
      "2021-12-16 04:32:49,381 - INFO: | epoch  50 |   900/ 3051 batches | lr 3.72e-06 | ms/batch 59.86 | loss-text 2.8554\n",
      "2021-12-16 04:32:55,382 - INFO: | epoch  50 |  1000/ 3051 batches | lr 3.72e-06 | ms/batch 60.01 | loss-text 2.8729\n",
      "2021-12-16 04:33:01,323 - INFO: | epoch  50 |  1100/ 3051 batches | lr 3.72e-06 | ms/batch 59.40 | loss-text 2.8660\n",
      "2021-12-16 04:33:07,343 - INFO: | epoch  50 |  1200/ 3051 batches | lr 3.72e-06 | ms/batch 60.19 | loss-text 2.8762\n",
      "2021-12-16 04:33:13,286 - INFO: | epoch  50 |  1300/ 3051 batches | lr 3.72e-06 | ms/batch 59.42 | loss-text 2.8773\n",
      "2021-12-16 04:33:19,273 - INFO: | epoch  50 |  1400/ 3051 batches | lr 3.72e-06 | ms/batch 59.87 | loss-text 2.8741\n",
      "2021-12-16 04:33:25,281 - INFO: | epoch  50 |  1500/ 3051 batches | lr 3.72e-06 | ms/batch 60.08 | loss-text 2.8326\n",
      "2021-12-16 04:33:31,299 - INFO: | epoch  50 |  1600/ 3051 batches | lr 3.72e-06 | ms/batch 60.18 | loss-text 2.8933\n",
      "2021-12-16 04:33:37,335 - INFO: | epoch  50 |  1700/ 3051 batches | lr 3.72e-06 | ms/batch 60.35 | loss-text 2.8571\n",
      "2021-12-16 04:33:43,305 - INFO: | epoch  50 |  1800/ 3051 batches | lr 3.72e-06 | ms/batch 59.69 | loss-text 2.8305\n",
      "2021-12-16 04:33:49,304 - INFO: | epoch  50 |  1900/ 3051 batches | lr 3.72e-06 | ms/batch 59.99 | loss-text 2.8869\n",
      "2021-12-16 04:33:55,315 - INFO: | epoch  50 |  2000/ 3051 batches | lr 3.72e-06 | ms/batch 60.11 | loss-text 2.8414\n",
      "2021-12-16 04:34:01,352 - INFO: | epoch  50 |  2100/ 3051 batches | lr 3.72e-06 | ms/batch 60.36 | loss-text 2.8562\n",
      "2021-12-16 04:34:07,355 - INFO: | epoch  50 |  2200/ 3051 batches | lr 3.72e-06 | ms/batch 60.02 | loss-text 2.8369\n",
      "2021-12-16 04:34:13,374 - INFO: | epoch  50 |  2300/ 3051 batches | lr 3.72e-06 | ms/batch 60.19 | loss-text 2.8513\n",
      "2021-12-16 04:34:19,403 - INFO: | epoch  50 |  2400/ 3051 batches | lr 3.72e-06 | ms/batch 60.28 | loss-text 2.8558\n",
      "2021-12-16 04:34:25,414 - INFO: | epoch  50 |  2500/ 3051 batches | lr 3.72e-06 | ms/batch 60.10 | loss-text 2.8471\n",
      "2021-12-16 04:34:31,402 - INFO: | epoch  50 |  2600/ 3051 batches | lr 3.72e-06 | ms/batch 59.87 | loss-text 2.8196\n",
      "2021-12-16 04:34:37,439 - INFO: | epoch  50 |  2700/ 3051 batches | lr 3.72e-06 | ms/batch 60.37 | loss-text 2.8183\n",
      "2021-12-16 04:34:43,451 - INFO: | epoch  50 |  2800/ 3051 batches | lr 3.72e-06 | ms/batch 60.11 | loss-text 2.8466\n",
      "2021-12-16 04:34:49,456 - INFO: | epoch  50 |  2900/ 3051 batches | lr 3.72e-06 | ms/batch 60.04 | loss-text 2.8440\n",
      "2021-12-16 04:34:55,505 - INFO: | epoch  50 |  3000/ 3051 batches | lr 3.72e-06 | ms/batch 60.48 | loss-text 2.8331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003864\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10074, 'reflen': 10227, 'guess': [10074, 9050, 8026, 7002], 'correct': [5476, 1854, 693, 215]}\n",
      "ratio: 0.9850396010559318\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-16 04:35:19,698 - INFO: eval_greddy SPIDEr: 0.2155\n",
      "loading annotations into memory...\n",
      "0:00:00.003919\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9305, 'reflen': 9730, 'guess': [9305, 8281, 7257, 6233], 'correct': [5319, 1947, 778, 269]}\n",
      "ratio: 0.9563206577594083\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-16 04:35:40,667 - INFO: eval_beam_2 SPIDEr: 0.2409\n",
      "loading annotations into memory...\n",
      "0:00:00.103443\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9063, 'reflen': 9588, 'guess': [9063, 8039, 7015, 5991], 'correct': [5180, 1894, 792, 279]}\n",
      "ratio: 0.9452440550687374\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-16 04:36:08,230 - INFO: eval_beam_3 SPIDEr: 0.2359\n",
      "loading annotations into memory...\n",
      "0:00:00.003912\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8911, 'reflen': 9498, 'guess': [8911, 7887, 6863, 5839], 'correct': [5133, 1898, 780, 264]}\n",
      "ratio: 0.938197515266273\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-16 04:36:37,157 - INFO: eval_beam_4 SPIDEr: 0.2389\n"
     ]
    }
   ],
   "source": [
    "#일부 레이어 1131\n",
    "epoch = 1\n",
    "if hp.mode == 'train':\n",
    "    while epoch < hp.training_epochs + 1:\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        torch.save(model.state_dict(), '{log_dir}/{num_epoch}.pt'.format(log_dir=log_dir, num_epoch=epoch))\n",
    "        scheduler.step(epoch)\n",
    "        eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=2)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=3)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=4)\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5950aaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-04 14:04:22,352 - INFO: | epoch   1 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 59.65 | loss-text 5.8095\n",
      "2021-12-04 14:04:28,155 - INFO: | epoch   1 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 58.03 | loss-text 5.0831\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cb09f8526cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{log_dir}/{num_epoch}.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-94649549a569>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_pad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9d2cd804fa0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, input_mask, target_mask, target_padding_mask)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         output = self.decode(mem, tgt, input_mask=input_mask, target_mask=target_mask,\n\u001b[0;32m--> 126\u001b[0;31m                              target_padding_mask=target_padding_mask)\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9d2cd804fa0a>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, mem, tgt, input_mask, target_mask, target_padding_mask)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mtarget_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#mixup\n",
    "epoch = 1\n",
    "if hp.mode == 'train':\n",
    "    while epoch < hp.training_epochs + 1:\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        torch.save(model.state_dict(), '{log_dir}/{num_epoch}.pt'.format(log_dir=log_dir, num_epoch=epoch))\n",
    "        scheduler.step(epoch)\n",
    "        eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=2)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=3)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=4)\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b593960e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-85fdcc81b46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for src, tgt, tgt_len in training_data:\n",
    "    src = src.to(device)\n",
    "    tgt = tgt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3df15dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.training_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6fa65a",
   "metadata": {},
   "source": [
    "epoch=37 eval_beam_3 SPIDEr: 0.2344 # 2개 layer 만 trainable -06/9  \n",
    " SPIDEr: # 5개 layer 만 trainable -06/10 0.2252\n",
    "별 차이 없음 ;;;;;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19ee5c",
   "metadata": {},
   "source": [
    "model score check (eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3852d268",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/base/48.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2f0e4443ea7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#if hp.mode == 'eval':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Evaluation model score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/base/48.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_beam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/base/48.pt'"
     ]
    }
   ],
   "source": [
    "#if hp.mode == 'eval':\n",
    "# Evaluation model score\n",
    "model.load_state_dict(torch.load(\"./models/base/48.pt\"))\n",
    "eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=2)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=3)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1735c2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./models/base/49.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixup(object):\n",
    "    def __init__(self, mixup_alpha, random_seed=1234):\n",
    "        \"\"\"Mixup coefficient generator.\n",
    "        \"\"\"\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    def get_lambda(self, batch_size):\n",
    "        \"\"\"Get mixup random coefficients.\n",
    "        Args:\n",
    "          batch_size: int\n",
    "        Returns:\n",
    "          mixup_lambdas: (batch_size,)\n",
    "        \"\"\"\n",
    "        mixup_lambdas = []\n",
    "        for n in range(0, batch_size, 2):\n",
    "            lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "            mixup_lambdas.append(lam)\n",
    "            mixup_lambdas.append(1. - lam)\n",
    "\n",
    "        return np.array(mixup_lambdas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fecb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd36458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mixup(x, mixup_lambda):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes \n",
    "    (1, 3, 5, ...).\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0 :: 2].transpose(0, -1) * mixup_lambda[0 :: 2] + \\\n",
    "        x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d22dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.feature.inverse import mel_to_audio, mel_to_stft\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University, Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['feature_extraction']\n",
    "\n",
    "\n",
    "def feature_extraction(audio_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"Feature extraction function.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: Log mel-bands energies of shape=(t, nb_mels)\n",
    "    :rtype: numpy.ndarray, numpy.float\n",
    "    \"\"\"\n",
    "    y = audio_data/abs(audio_data).max()\n",
    "    mel_bands = melspectrogram(\n",
    "        y=y, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power, n_mels=nb_mels,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm).T\n",
    "\n",
    "    return np.log(mel_bands + np.finfo(float).eps)\n",
    "\n",
    "\n",
    "def from_mel_to_audio(mel_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"Feature extraction inverse function.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: audio data\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.exp(mel_data) - np.finfo(float).eps\n",
    "    audio_data = mel_to_audio(\n",
    "        M=y.T, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm)\n",
    "\n",
    "    return audio_data\n",
    "\n",
    "\n",
    "def from_mel_to_stft(mel_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"From logmelspectrogram to stft.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: audio data\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.exp(mel_data) - np.finfo(float).eps\n",
    "    stft = mel_to_stft(\n",
    "        M=y.T, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm)\n",
    "\n",
    "    return stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beae2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "#from tools.features_log_mel_bands import feature_extraction, from_mel_to_audio, from_mel_to_stft\n",
    "from pathlib import Path\n",
    "import pysndfx\n",
    "import gc\n",
    "\n",
    "import copy\n",
    "\n",
    "#from tools.file_io import load_audio_file\n",
    "import torch\n",
    "\n",
    "\n",
    "__author__ = 'Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "\n",
    "class MixUp:\n",
    "\n",
    "    def __init__(self, p, settings_features, simple_concat_captions=True,\n",
    "                 sample_audio=False):\n",
    "\n",
    "        self.p = p\n",
    "        self.sample_audio = sample_audio\n",
    "        self.settings_features = settings_features\n",
    "        self.simple_concat_captions = simple_concat_captions\n",
    "\n",
    "    def from_mel(self, mel):\n",
    "        return 700 * (10 ** (mel / 2595.0) - 1)\n",
    "\n",
    "    def to_mel(self, hertz):\n",
    "        return 2595.0 * np.log10(1 + hertz / 700.0)\n",
    "\n",
    "    def mix_audio(self, first_audio, second_audio):\n",
    "\n",
    "        a = np.random.uniform(0.4, 0.6)\n",
    "\n",
    "        shorter, longer = first_audio, second_audio\n",
    "\n",
    "        if shorter.shape[0] == longer.shape[0]:\n",
    "            if self.sample_audio:\n",
    "                return (longer + shorter) / 2.0\n",
    "            else:\n",
    "                longer = from_mel_to_audio(longer, **self.settings_features['process']) * a\n",
    "                shorter = from_mel_to_audio(shorter,\n",
    "                                            **self.settings_features['process'])\n",
    "                return feature_extraction((longer + shorter) / 2, **self.settings_features['process'])\n",
    "\n",
    "        if first_audio.shape[0] > second_audio.shape[0]:\n",
    "            shorter, longer = longer, shorter\n",
    "\n",
    "\n",
    "        if self.sample_audio:\n",
    "            start = random.randint(0, longer.shape[0] - 1 - shorter.shape[0])\n",
    "            end = start + shorter.shape[0]\n",
    "            longer *= a\n",
    "            longer[start:end] += shorter * (1 - a)\n",
    "        else:\n",
    "            longer = from_mel_to_audio(longer, **self.settings_features['process']) * a\n",
    "            shorter = from_mel_to_audio(shorter,\n",
    "                                        **self.settings_features['process'])\n",
    "            start = random.randint(0, longer.shape[0] - 1 - shorter.shape[0])\n",
    "            end = start + shorter.shape[0]\n",
    "            longer[start:end] += shorter * (1 - a)\n",
    "            longer = feature_extraction(longer,\n",
    "                                        **self.settings_features['process'])\n",
    "\n",
    "        return longer\n",
    "\n",
    "    def mix_labels(self, first_labels, second_labels):\n",
    "        if self.simple_concat_captions:\n",
    "            return np.hstack([first_labels[:-1], second_labels[1:]])\n",
    "        else:\n",
    "\n",
    "            first_token = first_labels[0]\n",
    "            last_token = first_labels[-1]\n",
    "            first_labels = first_labels[1:-1]\n",
    "            second_labels = second_labels[1:-1]\n",
    "            res = np.empty((first_labels.size + second_labels.size,),\n",
    "                           dtype=first_labels.dtype)\n",
    "            min_size = min(first_labels.size, second_labels.size)\n",
    "            res[0:2*min_size:2] = first_labels[:min_size]\n",
    "            res[1:2*min_size:2] = second_labels[:min_size]\n",
    "            if first_labels.size > second_labels.size:\n",
    "                res[min_size * 2:] = first_labels[min_size:]\n",
    "            elif second_labels.size > first_labels.size:\n",
    "                res[min_size*2:] = second_labels[min_size:]\n",
    "            res = np.concatenate(([first_token], res))\n",
    "            res = np.concatenate((res, [last_token]))\n",
    "            return res\n",
    "\n",
    "    def mix_audio_and_labels(self,\n",
    "                             first_audio, second_audio,\n",
    "                             first_labels, second_labels):\n",
    "        mixed_audio = self.mix_audio(first_audio, second_audio)\n",
    "        mixed_labels = self.mix_labels(first_labels, second_labels)\n",
    "\n",
    "        return mixed_audio, mixed_labels\n",
    "\n",
    "    def __call__(self, dataset, inputs):\n",
    "        resulted_audio, resulted_labels, filename = inputs[0], inputs[1], inputs[2]\n",
    "        if np.random.uniform() <= self.p:\n",
    "            random_sample = dataset.random_sample(sample_audio=self.sample_audio)\n",
    "            resulted_audio, resulted_labels = self.mix_audio_and_labels(\n",
    "                resulted_audio, random_sample[0],\n",
    "                resulted_labels, random_sample[1]\n",
    "            )\n",
    "        return resulted_audio, resulted_labels\n",
    "\n",
    "\n",
    "class AudioAugmentation:\n",
    "    # https://github.com/ex4sperans/freesound-classification\n",
    "    def __init__(self, p):\n",
    "\n",
    "        self.p = p\n",
    "        self.effects_chain = (\n",
    "            pysndfx.AudioEffectsChain()\n",
    "                .reverb(\n",
    "                reverberance=random.randrange(50),\n",
    "                room_scale=random.randrange(50),\n",
    "                stereo_depth=random.randrange(50)\n",
    "            )\n",
    "                .pitch(shift=random.randrange(-300, 300))\n",
    "                .overdrive(gain=random.randrange(2, 10))\n",
    "                .speed(random.uniform(0.9, 1.1))\n",
    "        )\n",
    "\n",
    "    def __call__(self, dataset, inputs):\n",
    "\n",
    "        resulted_audio = inputs[0]\n",
    "        captions = inputs[1]\n",
    "        del inputs\n",
    "        gc.collect()\n",
    "        if np.random.uniform() < self.p:\n",
    "            resulted_audio = torch.from_numpy(self.effects_chain(resulted_audio.numpy()))\n",
    "        return resulted_audio, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a5ddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysndfx in /home/hj20/anaconda3/lib/python3.7/site-packages (0.3.6)\r\n",
      "Requirement already satisfied: numpy in /home/hj20/anaconda3/lib/python3.7/site-packages (from pysndfx) (1.20.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pysndfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f78e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchaudio\n",
    "from numpy import load as np_load, ndarray\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pympler import muppy, summary\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University, Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['ClothoDataset']\n",
    "\n",
    "\n",
    "class ClothoDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_dir: Path,\n",
    "                 split: str,\n",
    "                 input_field_name: str,\n",
    "                 output_field_name: str,\n",
    "                 load_into_memory: bool,\n",
    "                 settings_audio,\n",
    "                 settings_features,\n",
    "                 online_preprocessing=True,\n",
    "                 transforms=None) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "        :param data_dir: Data directory with Clotho dataset files.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: The split to use (`development`, `validation`)\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name for the input values\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name for the output (target) values.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load the dataset into memory?\n",
    "        :type load_into_memory: bool\n",
    "        :param settings_audio: Settings about audio loading\n",
    "        :type dict\n",
    "        :param settings_features: Settings about audio processing\n",
    "        :type dict\n",
    "        :param indexes: Indexes of files, which depends on validation strategy\n",
    "        :type indexes: numpy array\n",
    "        :param transforms: List of transforms\n",
    "        :type transforms: list\n",
    "        \"\"\"\n",
    "\n",
    "        super(ClothoDataset, self).__init__()\n",
    "        self.online_preprocessing = online_preprocessing\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "        self.split = split\n",
    "\n",
    "        self.settings_audio = settings_audio\n",
    "        self.settings_features = settings_features\n",
    "\n",
    "        #if indexes is None:\n",
    "        self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        #else:\n",
    "        #    self.examples: List[Path] = list(np.array(sorted(the_dir.iterdir()))[indexes])\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.transforms = transforms\n",
    "        self.resampler = torchaudio.transforms.Resample(orig_freq=settings_features['process']['sr'],\n",
    "                                                        new_freq=settings_features['process']['sr_resample'])\n",
    "        if load_into_memory:\n",
    "            self.examples: List[ndarray] = [\n",
    "                np_load(str(f), allow_pickle=True)\n",
    "                for f in self.examples]\n",
    "        self.cnt = 0\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int) \\\n",
    "            -> Tuple[ndarray, ndarray, Path]:\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values, and the Path of the file.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray, Path\n",
    "        \"\"\"\n",
    "\n",
    "        ex = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex = np_load(str(ex), allow_pickle=True)\n",
    "        if self.online_preprocessing:\n",
    "            in_e = torchaudio.load(Path('data', 'clotho_audio_files', self.split, ex.file_name[0]))[0][0]\n",
    "            ou_e = ex[self.output_name].item()\n",
    "        else:\n",
    "            in_e, ou_e = [ex[i].item()\n",
    "                          for i in [self.input_name, self.output_name]]\n",
    "        filename = ex.file_name[0]\n",
    "        del ex\n",
    "        if self.transforms is not None:\n",
    "            for transform in self.transforms:\n",
    "                in_e, ou_e = transform(dataset=self, inputs=(in_e, ou_e, filename))\n",
    "        return in_e, ou_e, filename\n",
    "\n",
    "    def random_sample(self, sample_audio=False):\n",
    "        \"\"\"\n",
    "        Sampling audio or melspectrogram and encoded output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        item = random.randint(0, len(self.examples) - 1)\n",
    "        ex = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex = np_load(str(ex), allow_pickle=True)\n",
    "        if sample_audio:\n",
    "            thedir = Path('./data/clotho_audio_files/').joinpath(self.split)\n",
    "            filename = Path(thedir, ex.file_name[0])\n",
    "            in_e = torchaudio.load(filepath=filename)[0][0]\n",
    "            #in_e = self.resampler.forward(in_e)\n",
    "            ou_e = ex[self.output_name].item()\n",
    "        else:\n",
    "            in_e, ou_e = [ex[i].item()\n",
    "                          for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        return in_e, ou_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c764639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import MutableSequence, MutableMapping, Union,\\\n",
    "    Tuple, List\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import cat, zeros, from_numpy, ones, Tensor\n",
    "from numpy import ndarray\n",
    "\n",
    "#from data_handlers._clotho import ClothoDataset\n",
    "#from tools.augmentations import MixUp, AudioAugmentation\n",
    "\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University. Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['get_clotho_loader']\n",
    "\n",
    "\n",
    "def _clotho_collate_fn(batch: MutableSequence[ndarray]) \\\n",
    "        -> Tuple[Tensor, Tensor, List[str]]:\n",
    "    \"\"\"Pads data.\n",
    "    For each batch, the maximum input and output\\\n",
    "    time-steps are calculated. Then, then input and\\\n",
    "    output data are padded to match the maximum time-steps.\n",
    "    The input data are padded with zeros in front, and\\\n",
    "    the output with] <EOS> tokens at the end.\n",
    "    :param batch: Batch data of batch x time x features.\\\n",
    "                  First element in the list are the input\\\n",
    "                  data, second the output data.\n",
    "    :type batch: list[numpy.ndarray]\n",
    "    :return: Padded data. First tensor is the input data\\\n",
    "             and second the output.\n",
    "    :rtype: torch.Tensor, torch.Tensor, list[str]\n",
    "    \"\"\"\n",
    "    max_input_t_steps = max([i[0].shape[0] for i in batch])\n",
    "    max_output_t_steps = max([i[1].shape[0] for i in batch])\n",
    "\n",
    "    file_names = [i[2] for i in batch]\n",
    "\n",
    "    #input_features = batch[0][0].shape[-1]\n",
    "    eos_token = batch[0][1][-1]\n",
    "    input_tensor = cat([\n",
    "        cat([zeros(\n",
    "            max_input_t_steps - i[0].shape[0]).float(),\n",
    "             i[0].float()]).unsqueeze(0) for i in batch])\n",
    "    output_tensor = cat([\n",
    "        cat([\n",
    "            from_numpy(i[1]).long(),\n",
    "            ones(max_output_t_steps - len(i[1])).mul(eos_token).long()\n",
    "        ]).unsqueeze(0) for i in batch])\n",
    "    return [input_tensor, output_tensor, file_names]\n",
    "\n",
    "\n",
    "def get_clotho_loader(split: str,\n",
    "                      is_training: bool,\n",
    "                      settings_data: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      settings_io: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[\n",
    "                              str, Union[str, MutableMapping[str, str]]]]],\n",
    "                      settings_features: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      settings_dataset: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      ) \\\n",
    "        -> DataLoader:\n",
    "    \"\"\"Gets the data loader.\n",
    "    :param split: Split to be used.\n",
    "    :type split: str\n",
    "    :param is_training: Is training data?\n",
    "    :type is_training: bool\n",
    "    :param settings_data: Data loading and dataset settings.\n",
    "    :type settings_data: dict\n",
    "    :param settings_io: Files I/O settings.\n",
    "    :type settings_io: dict\n",
    "    :param settings_features: Audio preprocessing features.\n",
    "    :type settings_features: dict\n",
    "    :param settings_dataset: Dataset settings.\n",
    "    :type settings_dataset: dict\n",
    "    :param indexes: Indexes of audio files, which depends on validation_strategy.\n",
    "    :type indexes: numpy array\n",
    "    :type settings_training: dict\n",
    "    :return: Data loader.\n",
    "    :rtype: torch.utils.data.DataLoader\n",
    "    \"\"\"\n",
    "    data_dir = Path(\n",
    "        settings_io['root_dirs']['data'],\n",
    "        settings_io['dataset']['features_dirs']['output'])\n",
    "\n",
    "    transforms = []\n",
    "    if settings_data['transforms'] == 'None' or (not is_training):\n",
    "        transforms = None\n",
    "    else:\n",
    "        if 'MixUp' in settings_data['transforms']:\n",
    "            print(settings_features['simple_concat_captions'], 'lalalalalal')\n",
    "            transforms.append(MixUp(p=settings_data['MixUp_p'],\n",
    "                              settings_features=settings_features,\n",
    "                              simple_concat_captions=settings_features['simple_concat_captions'],\n",
    "                              sample_audio=True))\n",
    "        if 'another' in settings_data['transforms']:\n",
    "            transforms.append(AudioAugmentation(p=settings_data['MixUp_p']))\n",
    "\n",
    "    #if settings_training['validation_strategy']\n",
    "    dataset = ClothoDataset(\n",
    "        data_dir=data_dir,\n",
    "        split=split,\n",
    "        input_field_name=settings_data['input_field_name'],\n",
    "        output_field_name=settings_data['output_field_name'],\n",
    "        load_into_memory=settings_data['load_into_memory'],\n",
    "        settings_audio=settings_dataset['audio'],\n",
    "        settings_features=settings_features,\n",
    "        transforms=transforms)\n",
    "\n",
    "    shuffle = settings_data['shuffle'] if is_training else False\n",
    "    drop_last = settings_data['drop_last'] if is_training else False\n",
    "    if is_training:\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=settings_data['batch_size'],\n",
    "            shuffle=shuffle,\n",
    "            num_workers=settings_data['num_workers'],\n",
    "            drop_last=drop_last,\n",
    "            # pin_memory=True,\n",
    "            collate_fn=_clotho_collate_fn)\n",
    "    else:\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=40,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=2,\n",
    "            drop_last=drop_last,\n",
    "            # pin_memory=True,\n",
    "            collate_fn=_clotho_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bdc159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file='main_settings'\n",
    "file_ext='yaml'\n",
    "file_dir='settings' \n",
    "settings = file_io.load_yaml_file(Path(\n",
    "        file_dir, f'{config_file}.{file_ext}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282439e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.file_io import load_audio_file\n",
    "from tools import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba6d900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True lalalalalal\n"
     ]
    }
   ],
   "source": [
    "training_data = get_clotho_loader(\n",
    "            settings_io['dataset']['features_dirs']['development'],\n",
    "            is_training=True,\n",
    "            settings_data=settings_data,\n",
    "            settings_io=settings_io,\n",
    "            settings_features=settings_features,\n",
    "            settings_dataset=settings_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da33e988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fc96caf",
   "metadata": {},
   "outputs": [],
   "source": [
    " =  get_clotho_loader(\n",
    "            settings_io['dataset']['features_dirs']['evaluation'],\n",
    "            is_training=False,\n",
    "            settings_data=settings_data,\n",
    "            settings_io=settings_io,\n",
    "            settings_features=settings_features,\n",
    "            settings_dataset=settings_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2e22027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c197368",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_io=settings['dirs_and_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586cf61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MixUp']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_data['transforms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46972f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_dirs': {'outputs': 'outputs', 'data': 'data'},\n",
       " 'dataset': {'development': 'development',\n",
       "  'evaluation': 'evaluation',\n",
       "  'features_dirs': {'output': 'data_splits_mel',\n",
       "   'development': 'development',\n",
       "   'evaluation': 'evaluation'},\n",
       "  'audio_dirs': {'downloaded': 'clotho_audio_files',\n",
       "   'output': 'data_splits_audio_mel',\n",
       "   'development': 'development',\n",
       "   'evaluation': 'evaluation'},\n",
       "  'annotations_dir': 'clotho_csv_files',\n",
       "  'pickle_files_dir': 'pickles',\n",
       "  'files': {'np_file_name_template': 'clotho_file_{audio_file_name}_{caption_index}.npy',\n",
       "   'words_list_file_name': 'words_list.p',\n",
       "   'words_counter_file_name': 'words_frequencies.p',\n",
       "   'characters_list_file_name': 'characters_list.p',\n",
       "   'characters_frequencies_file_name': 'characters_frequencies.p'}},\n",
       " 'model': {'model_dir': 'models',\n",
       "  'checkpoint_model_name': 'dcase_model_baseline.pt',\n",
       "  'pre_trained_model_name': 'dcase_model_baseline_pre_trained.pt'},\n",
       " 'logging': {'logger_dir': 'logging',\n",
       "  'caption_logger_file': 'captions_baseline.txt'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201948df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'development'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_io['dataset']['features_dirs']['development']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc641b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_data=settings['dnn_training_settings']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa82501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_field_name': 'features',\n",
       " 'output_field_name': 'words_ind',\n",
       " 'load_into_memory': False,\n",
       " 'transforms': ['MixUp'],\n",
       " 'MixUp_p': 0.5,\n",
       " 'batch_size': 16,\n",
       " 'shuffle': True,\n",
       " 'num_workers': 4,\n",
       " 'drop_last': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0419e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_features=settings['feature_extraction_settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f7120db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keep_raw_audio_data': False,\n",
       " 'simple_concat_captions': True,\n",
       " 'process': {'sr': 44100,\n",
       "  'sr_resample': 16000,\n",
       "  'nb_fft': 1024,\n",
       "  'hop_size': 512,\n",
       "  'nb_mels': 64,\n",
       "  'window_function': 'hann',\n",
       "  'center': True,\n",
       "  'f_min': 0.0,\n",
       "  'f_max': None,\n",
       "  'htk': False,\n",
       "  'power': 1.0,\n",
       "  'norm': 1}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04521df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dataset=settings['dataset_creation_settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd805b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workflow': {'create_dataset': True, 'validate_dataset': False},\n",
       " 'annotations': {'development_file': 'clotho_captions_development.csv',\n",
       "  'evaluation_file': 'clotho_captions_evaluation.csv',\n",
       "  'audio_file_column': 'file_name',\n",
       "  'captions_fields_prefix': 'caption_{}',\n",
       "  'use_special_tokens': True,\n",
       "  'nb_captions': 5,\n",
       "  'keep_case': False,\n",
       "  'remove_punctuation_words': True,\n",
       "  'remove_punctuation_chars': True,\n",
       "  'use_unique_words_per_caption': False,\n",
       "  'use_unique_chars_per_caption': False},\n",
       " 'audio': {'sr': 44100, 'to_mono': True, 'max_abs_value': 1.0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from typing import Tuple, List, AnyStr, Union\n",
    "from pathlib import Path\n",
    "\n",
    "from numpy import ndarray, recarray\n",
    "from torch.utils.data import Dataset\n",
    "from numpy import load as np_load\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['ClothoDataset']\n",
    "\n",
    "\n",
    "class ClothoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir: Path,\n",
    "                 split: AnyStr,\n",
    "                 input_field_name: AnyStr,\n",
    "                 output_field_name: AnyStr,\n",
    "                 load_into_memory: bool,\n",
    "                 transforms=transforms) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "\n",
    "        :param data_dir: Directory with data.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name of the clotho data\\\n",
    "                                 to be used as input data to the\\\n",
    "                                 method.\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name of the clotho data\\\n",
    "                                 to be used as output data to the\\\n",
    "                                 method.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load all data into memory?\n",
    "        :type load_into_memory: bool\n",
    "        \"\"\"\n",
    "        super(ClothoDataset, self).__init__()\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "\n",
    "        self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.transforms=transforms\n",
    "        if load_into_memory:\n",
    "            self.examples: List[recarray] = [np_load(str(f), allow_pickle=True)\n",
    "                                             for f in self.examples]\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int) \\\n",
    "            -> Tuple[ndarray, ndarray]:\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray\n",
    "        \"\"\"\n",
    "        ex: Union[Path, recarray] = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex: recarray = np_load(str(ex), allow_pickle=True)\n",
    "\n",
    "        in_e, ou_e = [ex[i].item() for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        return in_e, ou_e\n",
    "\n",
    "\n",
    "class ClothoDatasetEval(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir: Path,\n",
    "                 split: AnyStr,\n",
    "                 input_field_name: AnyStr,\n",
    "                 output_field_name: AnyStr,\n",
    "                 load_into_memory: bool) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "\n",
    "        :param data_dir: Directory with data.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name of the clotho data\\\n",
    "                                 to be used as input data to the\\\n",
    "                                 method.\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name of the clotho data\\\n",
    "                                 to be used as output data to the\\\n",
    "                                 method.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load all data into memory?\n",
    "        :type load_into_memory: bool\n",
    "        \"\"\"\n",
    "        super(ClothoDatasetEval, self).__init__()\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "        if split == 'evaluation':\n",
    "            self.examples: List[Path] = sorted(the_dir.iterdir())[::5]  # changed\n",
    "        else:\n",
    "            self.examples: List[Path] = sorted(the_dir.iterdir())  # changed\n",
    "        # self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.data_dir = the_dir\n",
    "\n",
    "        if load_into_memory:\n",
    "            self.examples: List[recarray] = [np_load(str(f), allow_pickle=True)\n",
    "                                             for f in self.examples]\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int):\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray\n",
    "        \"\"\"\n",
    "        ex: Union[Path, recarray] = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex: recarray = np_load(str(ex), allow_pickle=True)\n",
    "\n",
    "        in_e, ou_e = [ex[i].item() for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        all_ref = get_all_ref(ex['file_name'].item(), self.data_dir)\n",
    "\n",
    "        filename = str(ex['file_name'].item())\n",
    "        out_len = len(ou_e)\n",
    "        return in_e, ou_e, all_ref, filename,out_len\n",
    "\n",
    "\n",
    "def get_all_ref(filename, data_dir):\n",
    "    filename = str(filename)\n",
    "    # tgt = [np.load(d, allow_pickle=True).words_ind.tolist()\n",
    "    tgt = [np.load(d, allow_pickle=True)['words_ind'].item().tolist()\n",
    "           for d in [os.path.join(data_dir, 'clotho_file_{filename}.wav_{i}.npy'.\n",
    "                                  format(filename=filename[:-4],  # 删除'.wav'\n",
    "                                         i=i)) for i in range(5)]  # wav_0-wav_4\n",
    "           ]\n",
    "    return tgt\n",
    "# EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa295a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff041f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from typing import Callable, Union, Tuple, AnyStr, Optional\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from .clotho_dataset import ClothoDataset, ClothoDatasetEval\n",
    "from .collate_fn import clotho_collate_fn, clotho_collate_fn_eval\n",
    "\n",
    "__author__ = 'Konstantinos Drossos'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['get_clotho_loader']\n",
    "\n",
    "\n",
    "def get_clotho_loader(data_dir: Path,\n",
    "                      split: str,\n",
    "                      input_field_name: str,\n",
    "                      output_field_name: str,\n",
    "                      load_into_memory: bool,\n",
    "                      batch_size: int,\n",
    "                      nb_t_steps_pad: Union[AnyStr, Tuple[int, int]],\n",
    "                      shuffle: Optional[bool] = True,\n",
    "                      drop_last: Optional[bool] = True,\n",
    "                      input_pad_at: Optional[str] = 'start',\n",
    "                      output_pad_at: Optional[str] = 'end',\n",
    "                      num_workers: Optional[int] = 1,\n",
    "                      return_reference: Optional[bool] = False,\n",
    "                      augment: Optional[bool] = False) \\\n",
    "        -> DataLoader:\n",
    "    \"\"\"Gets the clotho data loader.\n",
    "\n",
    "    :param return_reference:\n",
    "    :param data_dir: Directory with data.\n",
    "    :type data_dir: pathlib.Path\n",
    "    :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "    :type split: str\n",
    "    :param input_field_name: Field name of the clotho data\\\n",
    "                             to be used as input data to the\\\n",
    "                             method.\n",
    "    :type input_field_name: str\n",
    "    :param output_field_name: Field name of the clotho data\\\n",
    "                             to be used as output data to the\\\n",
    "                             method.\n",
    "    :type output_field_name: str\n",
    "    :param load_into_memory: Load all data into memory?\n",
    "    :type load_into_memory: bool\n",
    "    :param batch_size: Batch size to use.\n",
    "    :type batch_size: int\n",
    "    :param nb_t_steps_pad: Number of time steps to\\\n",
    "                           pad/truncate to. Cab use\\\n",
    "                           'max', 'min', or exact number\\\n",
    "                           e.g. (1024, 10).\n",
    "    :type nb_t_steps_pad: str|(int, int)\n",
    "    :param shuffle: Shuffle examples? Defaults to True.\n",
    "    :type shuffle: bool, optional\n",
    "    :param drop_last: Drop the last examples if not making\\\n",
    "                      a batch of `batch_size`? Defaults to True.\n",
    "    :type drop_last: bool, optional\n",
    "    :param input_pad_at: Pad input at the start or\\\n",
    "                         at the end?\n",
    "    :type input_pad_at: str\n",
    "    :param output_pad_at: Pad output at the start or\\\n",
    "                          at the end?\n",
    "    :type output_pad_at: str\n",
    "    :param num_workers: Amount of workers, defaults to 1.\n",
    "    :type num_workers: int, optional\n",
    "    :return: Dataloader for Clotho data.\n",
    "    :rtype: torch.utils.data.dataloader.DataLoader\n",
    "    \"\"\"\n",
    "    if return_reference:\n",
    "        dataset: ClothoDatasetEval = ClothoDatasetEval(\n",
    "            data_dir=data_dir, split=split,\n",
    "            input_field_name=input_field_name,\n",
    "            output_field_name=output_field_name,\n",
    "            load_into_memory=load_into_memory\n",
    "            transforms=trans)\n",
    "\n",
    "        collate_fn: Callable = partial(\n",
    "            clotho_collate_fn_eval,\n",
    "            nb_t_steps=nb_t_steps_pad,\n",
    "            input_pad_at=input_pad_at,\n",
    "            output_pad_at=output_pad_at, split=split, augment=augment)\n",
    "    else:\n",
    "        dataset: ClothoDataset = ClothoDataset(\n",
    "            data_dir=data_dir, split=split,\n",
    "            input_field_name=input_field_name,\n",
    "            output_field_name=output_field_name,\n",
    "            load_into_memory=load_into_memory)\n",
    "\n",
    "        collate_fn: Callable = partial(\n",
    "            clotho_collate_fn,\n",
    "            nb_t_steps=nb_t_steps_pad,\n",
    "            input_pad_at=input_pad_at,\n",
    "            output_pad_at=output_pad_at)\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset=dataset, batch_size=batch_size,\n",
    "        shuffle=shuffle, num_workers=num_workers,\n",
    "        drop_last=drop_last, collate_fn=collate_fn)\n",
    "\n",
    "# EOF\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcaset6",
   "language": "python",
   "name": "dcase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
