{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89681fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\r\n",
      "\r\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\r\n",
      "       usage information.\r\n",
      "\r\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\r\n",
      "\r\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\r\n",
      "       usage information.\r\n",
      "\r\n",
      "Sat Apr  9 09:38:30 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 35%   39C    P0    61W / 260W |   1861MiB / 11016MiB |     21%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1483      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      2312      G   /usr/bin/totem                     15MiB |\r\n",
      "|    0   N/A  N/A      2948      G   /usr/bin/gnome-shell               17MiB |\r\n",
      "|    0   N/A  N/A      7440      G   /usr/lib/xorg/Xorg                 36MiB |\r\n",
      "|    0   N/A  N/A      7473      G   ...AAAAAAAAA= --shared-files       65MiB |\r\n",
      "|    0   N/A  N/A      7578      G   /usr/bin/gnome-shell              150MiB |\r\n",
      "|    0   N/A  N/A     10718      G   /usr/lib/xorg/Xorg                437MiB |\r\n",
      "|    0   N/A  N/A     10859      G   /usr/bin/gnome-shell              339MiB |\r\n",
      "|    0   N/A  N/A     11307      G   ...AAAAAAAAA= --shared-files      186MiB |\r\n",
      "|    0   N/A  N/A     16220      G   ...AAAAAAAAA= --shared-files       44MiB |\r\n",
      "|    0   N/A  N/A     29045      G   ...AAAAAAAAA= --shared-files      473MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d5288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 28719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f52a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58059f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn14,Cnn10,init_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5214a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a900f95",
   "metadata": {},
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abbeed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transfer_Cnn10(nn.Module):\n",
    "    def __init__(self, freeze_base=True, pretrain_checkpoint=None):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_Cnn10, self).__init__()\n",
    "\n",
    "        audioset_classes_num = 527\n",
    "        self.base = Cnn10()\n",
    "\n",
    "        #self.init_weights()\n",
    "\n",
    "        if pretrain_checkpoint:\n",
    "            self.load_from_pretrain(pretrain_checkpoint)\n",
    "            \n",
    "        #self.base.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        # 안쓰이는이유는 multi-class clasification을 생략하기 때문,\n",
    "\n",
    "        if freeze_base:\n",
    "            # 2단계 freeze / 3단계 freeze X\n",
    "            # Freeze AudioSet pretrained layers\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    #def init_weights(self):\n",
    "        #init_layer(self.fc_transfer)\n",
    "\n",
    "    def load_from_pretrain(self, pretrained_checkpoint):\n",
    "        pretrained_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\"\n",
    "        checkpoint = torch.load(pretrained_checkpoint)\n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_imag.weight')#가중치 삭제  \n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_real.weight')#가중치 삭제\n",
    "        checkpoint['model'].pop('logmel_extractor.melW')#가중치 삭제\n",
    "        checkpoint['model'].pop('fc1.weight')\n",
    "        checkpoint['model'].pop('fc1.bias')\n",
    "        checkpoint['model'].pop('fc_audioset.weight')\n",
    "        checkpoint['model'].pop('fc_audioset.bias')\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        output = self.base(input)\n",
    "\n",
    "        #embedding = output_dict['embedding']\n",
    "        #clipwise_output = output_dict['clipwise_output']\n",
    "\n",
    "        return output #, clipwise_output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2840e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\"\n",
    "checkpoint = torch.load(pretrained_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4cfe7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iteration': 440000,\n",
       " 'model': OrderedDict([('spectrogram_extractor.stft.conv_real.weight',\n",
       "               tensor([[[ 0.0000e+00,  9.4124e-06,  3.7649e-05,  ...,  8.4709e-05,\n",
       "                          3.7649e-05,  9.4124e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00,  9.4122e-06,  3.7646e-05,  ...,  8.4695e-05,\n",
       "                          3.7646e-05,  9.4122e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00,  9.4117e-06,  3.7638e-05,  ...,  8.4652e-05,\n",
       "                          3.7638e-05,  9.4117e-06]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4117e-06,  3.7638e-05,  ..., -8.4652e-05,\n",
       "                          3.7638e-05, -9.4117e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4122e-06,  3.7646e-05,  ..., -8.4695e-05,\n",
       "                          3.7646e-05, -9.4122e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4124e-06,  3.7649e-05,  ..., -8.4709e-05,\n",
       "                          3.7649e-05, -9.4124e-06]]], device='cuda:0')),\n",
       "              ('spectrogram_extractor.stft.conv_imag.weight',\n",
       "               tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -5.7753e-08, -4.6201e-07,  ...,  1.5592e-06,\n",
       "                          4.6201e-07,  5.7753e-08]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1550e-07, -9.2395e-07,  ...,  3.1179e-06,\n",
       "                          9.2395e-07,  1.1550e-07]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1550e-07,  9.2395e-07,  ...,  3.1179e-06,\n",
       "                         -9.2395e-07,  1.1550e-07]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -5.7753e-08,  4.6201e-07,  ...,  1.5592e-06,\n",
       "                         -4.6201e-07,  5.7753e-08]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1527e-21,  9.2214e-21,  ..., -1.7514e-17,\n",
       "                          1.2470e-17, -8.8136e-21]]], device='cuda:0')),\n",
       "              ('logmel_extractor.melW',\n",
       "               tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0043, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       ...,\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "                      device='cuda:0')),\n",
       "              ('bn0.weight',\n",
       "               tensor([1.2579, 1.2287, 1.1752, 1.1472, 1.1341, 1.1017, 1.0914, 1.0787, 1.0651,\n",
       "                       1.0756, 1.0683, 1.0589, 1.0478, 1.0323, 1.0432, 1.0094, 1.0038, 1.0202,\n",
       "                       1.0210, 1.0268, 1.0409, 1.0565, 1.0200, 1.0603, 1.0618, 1.0505, 1.0631,\n",
       "                       1.0512, 1.0770, 1.0790, 1.0833, 1.0788, 1.0826, 1.0741, 1.0893, 1.0994,\n",
       "                       1.1181, 1.1037, 1.1052, 1.1233, 1.1174, 1.1264, 1.1512, 1.1866, 1.2267,\n",
       "                       1.2610, 1.2632, 1.3015, 1.2884, 1.3413, 1.3513, 1.3659, 1.3383, 1.3445,\n",
       "                       1.3790, 1.3468, 1.3447, 1.3394, 1.2890, 1.2610, 1.2722, 1.2695, 1.2540,\n",
       "                       1.2942], device='cuda:0')),\n",
       "              ('bn0.bias',\n",
       "               tensor([ 0.1418,  0.1614,  0.2051,  0.2250,  0.2054,  0.2128,  0.2234,  0.2539,\n",
       "                        0.2251,  0.2122,  0.2185,  0.2002,  0.2017,  0.1822,  0.1683,  0.1444,\n",
       "                        0.1269,  0.1714,  0.1422,  0.1387,  0.1513,  0.1419,  0.1510,  0.1334,\n",
       "                        0.1520,  0.1332,  0.1163,  0.1276,  0.1073,  0.1257,  0.1314,  0.1131,\n",
       "                        0.1414,  0.1328,  0.1064,  0.1035,  0.0991,  0.1022,  0.1113,  0.1031,\n",
       "                        0.0918,  0.0667,  0.0340,  0.0058, -0.0343, -0.0510, -0.0735, -0.0952,\n",
       "                       -0.1210, -0.1620, -0.1719, -0.1713, -0.1978, -0.1898, -0.2296, -0.2104,\n",
       "                       -0.2010, -0.2143, -0.1837, -0.2698, -0.2991, -0.3428, -0.3216, -0.2706],\n",
       "                      device='cuda:0')),\n",
       "              ('bn0.running_mean',\n",
       "               tensor([-14.7698, -13.6179, -13.6138, -13.7430, -14.3962, -14.5996, -15.4520,\n",
       "                       -15.8805, -16.5379, -17.0350, -17.5244, -18.0900, -18.3324, -19.0569,\n",
       "                       -19.5501, -20.2974, -20.4803, -21.0466, -21.3381, -21.5437, -22.0068,\n",
       "                       -22.1964, -22.6461, -23.1714, -23.2960, -23.5023, -23.8864, -24.1805,\n",
       "                       -24.8282, -24.9183, -25.4159, -25.7884, -26.1122, -26.6204, -27.0275,\n",
       "                       -27.5277, -28.0286, -28.3588, -28.8325, -29.3342, -30.0424, -30.7998,\n",
       "                       -31.6253, -32.8063, -33.9453, -34.8903, -35.8278, -36.8257, -37.9765,\n",
       "                       -39.4108, -40.4666, -41.2937, -42.2061, -43.2223, -44.2648, -45.2302,\n",
       "                       -46.2764, -47.3646, -48.5596, -50.5382, -52.2995, -53.9504, -55.6551,\n",
       "                       -57.6545], device='cuda:0')),\n",
       "              ('bn0.running_var',\n",
       "               tensor([596.6601, 575.9350, 560.0305, 552.3881, 547.5211, 543.4526, 540.1447,\n",
       "                       537.5850, 537.4604, 537.6881, 536.0203, 530.9358, 531.9637, 525.5637,\n",
       "                       517.0662, 513.1134, 512.5848, 509.0781, 503.4427, 505.8644, 502.7238,\n",
       "                       499.5360, 499.5542, 495.1674, 495.0078, 492.7249, 487.0581, 484.2194,\n",
       "                       479.8156, 480.9565, 476.3221, 475.1716, 477.7686, 474.1192, 475.2479,\n",
       "                       472.0588, 468.3824, 464.7163, 466.6536, 467.5047, 463.1785, 460.5492,\n",
       "                       459.6526, 470.3666, 489.5420, 499.5362, 507.8021, 513.4002, 517.6402,\n",
       "                       540.6107, 557.5811, 558.7811, 560.7786, 561.4371, 562.8868, 558.7776,\n",
       "                       555.0521, 546.9778, 535.2908, 534.0878, 539.0059, 537.0637, 529.1208,\n",
       "                       521.8989], device='cuda:0')),\n",
       "              ('bn0.num_batches_tracked', tensor(440000, device='cuda:0')),\n",
       "              ('conv_block1.conv1.weight',\n",
       "               tensor([[[[-3.7039e-02, -4.2758e-01,  4.6078e-01],\n",
       "                         [-9.8838e-02, -4.7424e-01,  3.5086e-01],\n",
       "                         [ 5.4757e-02, -2.9605e-01,  4.8484e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.3487e-01, -2.7748e-01, -2.2969e-01],\n",
       "                         [-2.5529e-03, -1.0134e-01, -9.9216e-02],\n",
       "                         [ 8.8498e-02,  4.3399e-01,  3.1902e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.8117e-01,  2.1679e-01,  8.6598e-03],\n",
       "                         [-3.0433e-01,  4.2776e-01, -2.8384e-02],\n",
       "                         [-3.1323e-01,  3.7712e-01, -8.6349e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.1328e-01, -4.7214e-01, -1.5421e-01],\n",
       "                         [-7.4739e-03,  1.5373e-01, -9.9434e-02],\n",
       "                         [ 5.1257e-01,  3.8470e-01,  2.0314e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2202e-01,  1.1475e-01,  1.7375e-01],\n",
       "                         [ 4.6711e-02, -2.4738e-01, -1.1763e-01],\n",
       "                         [-1.2941e-01, -1.4176e-01, -8.9102e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.6680e-01, -5.6923e-01, -3.8833e-01],\n",
       "                         [ 7.2493e-01, -2.7824e-01,  9.7279e-03],\n",
       "                         [ 2.4725e-01, -1.6016e-01,  9.7753e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.4617e-01,  1.1877e-01,  9.5465e-02],\n",
       "                         [ 5.3723e-02,  1.6259e-02,  3.4303e-02],\n",
       "                         [-2.3713e-01, -1.7044e-01, -7.7720e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.7280e-01,  5.4870e-01, -3.0124e-01],\n",
       "                         [-3.1358e-01,  4.4885e-01, -2.8404e-01],\n",
       "                         [-1.4353e-01,  5.0320e-01, -2.3500e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.4014e-04, -6.3007e-02, -2.5290e-01],\n",
       "                         [-1.3695e-02, -7.0924e-02, -1.0243e-01],\n",
       "                         [ 1.5860e-01,  2.4922e-01,  7.3565e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2324e-01, -2.8807e-01,  7.9693e-01],\n",
       "                         [-2.5401e-01, -1.1556e-01,  2.5972e-01],\n",
       "                         [-2.0476e-01, -4.7462e-01, -3.4198e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.0406e-01,  5.1279e-02, -3.6834e-01],\n",
       "                         [-2.3591e-01,  2.6704e-01,  1.5689e-01],\n",
       "                         [-2.8982e-01, -2.9980e-02,  1.7038e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.3808e-02, -2.1475e-01,  2.4791e-01],\n",
       "                         [-1.5626e-01, -2.8334e-01,  9.1087e-02],\n",
       "                         [-8.4360e-02, -1.1746e-01,  1.6794e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.2985e-01, -1.6245e-01, -3.5523e-01],\n",
       "                         [ 5.0251e-01, -1.0382e-01, -3.8975e-01],\n",
       "                         [ 2.4276e-01,  5.4808e-02, -2.7259e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.4744e-01,  2.3009e-01,  8.3530e-01],\n",
       "                         [-1.4976e-01, -2.8275e-01,  2.4763e-01],\n",
       "                         [-1.9248e-01, -3.3660e-01, -1.4239e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.4622e-02, -5.6861e-02, -4.1197e-01],\n",
       "                         [ 5.7208e-01, -5.0864e-02, -4.3210e-01],\n",
       "                         [ 5.4853e-01,  5.0650e-02, -3.2082e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6556e-01, -5.3412e-01, -2.3066e-01],\n",
       "                         [-2.8875e-02,  2.4764e-02, -1.6386e-01],\n",
       "                         [-3.9200e-03,  5.5788e-01,  2.6252e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.1720e-01, -4.7870e-01,  1.1784e-01],\n",
       "                         [-2.0684e-01,  6.2280e-02,  4.1311e-01],\n",
       "                         [ 5.6433e-02,  4.4781e-02,  4.6758e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1200e-01,  2.7321e-01, -3.9600e-02],\n",
       "                         [-3.1901e-01,  3.1452e-01, -2.7479e-03],\n",
       "                         [-3.3993e-01,  3.6536e-01,  5.1426e-04]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.2003e-01,  1.8998e-01,  1.2129e-01],\n",
       "                         [-2.7666e-01,  9.2499e-02, -4.6375e-02],\n",
       "                         [-1.4448e-01,  6.8090e-02,  7.0098e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.7226e-02, -1.2127e-01,  2.3658e-01],\n",
       "                         [-2.4300e-01, -1.9383e-01,  1.1952e-01],\n",
       "                         [ 2.2897e-02, -8.7058e-02,  3.2172e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.3028e-02, -2.3576e-01,  4.1035e-02],\n",
       "                         [ 1.6508e-01, -1.1036e-01,  9.5125e-02],\n",
       "                         [-2.9840e-03,  1.8085e-01,  2.6306e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.4316e-01,  1.1665e+00, -4.3412e-01],\n",
       "                         [ 6.2403e-02, -5.5574e-01,  1.2445e-01],\n",
       "                         [ 5.2582e-02, -3.2262e-01,  1.8072e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.5395e-01,  6.7191e-01, -4.2608e-01],\n",
       "                         [ 1.4435e-01,  7.4019e-01, -1.7308e-01],\n",
       "                         [-2.6455e-01, -1.5263e-02, -2.0942e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.5521e-01, -2.1611e-01,  7.1947e-02],\n",
       "                         [ 3.0966e-01, -3.0091e-01, -7.8164e-03],\n",
       "                         [ 3.0483e-01, -3.1466e-01,  1.5690e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9823e-01, -4.2168e-01,  6.0279e-02],\n",
       "                         [-3.2808e-01, -3.3818e-01,  3.4307e-01],\n",
       "                         [-9.1788e-02,  2.4978e-01,  6.2914e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0916e-01, -1.0632e-02,  4.5488e-01],\n",
       "                         [ 1.1837e-02, -5.0426e-01,  5.5825e-02],\n",
       "                         [ 1.8273e-01, -5.3850e-01,  8.3406e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.7359e-01, -1.8598e-01,  2.1945e-02],\n",
       "                         [ 2.8800e-01, -1.5747e-01, -1.0243e-01],\n",
       "                         [ 1.2883e-01, -3.4466e-01, -1.4244e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.6872e-01, -1.4464e-01,  2.2020e-01],\n",
       "                         [-2.9175e-01,  2.2592e-01,  2.0379e-01],\n",
       "                         [-1.6604e-01,  2.6496e-01, -8.3792e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.5360e-02,  3.8966e-01,  1.4031e-01],\n",
       "                         [ 1.2257e-02,  2.1597e-02, -4.7005e-02],\n",
       "                         [ 9.1067e-02, -1.6526e-01, -1.9378e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0163e-01, -4.5580e-01,  3.1707e-01],\n",
       "                         [ 1.8935e-01, -4.5179e-01,  2.3650e-01],\n",
       "                         [ 2.7485e-01, -4.0986e-01,  2.1443e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.7262e-01, -1.0266e-01, -4.1695e-01],\n",
       "                         [ 4.8492e-01, -2.3177e-03, -4.4562e-01],\n",
       "                         [ 3.3022e-01,  6.2551e-02, -3.2547e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2101e-01,  1.0126e-01, -3.6913e-02],\n",
       "                         [ 1.4700e-01,  6.9705e-02, -3.9404e-02],\n",
       "                         [-5.5072e-02, -1.1184e-01, -6.6921e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.8531e-01, -4.7569e-02, -2.3400e-01],\n",
       "                         [ 3.4791e-01, -7.7497e-02, -2.4477e-01],\n",
       "                         [ 3.7497e-01, -1.4277e-01, -3.4089e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1033e+00,  1.2753e-01, -6.2010e-03],\n",
       "                         [-7.2243e-01, -4.6420e-01, -5.2412e-03],\n",
       "                         [-3.7374e-01,  4.0990e-01, -7.4779e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.1552e-01,  5.3512e-01,  8.1034e-02],\n",
       "                         [-1.1637e-01,  3.2702e-02,  9.7668e-03],\n",
       "                         [ 7.4868e-01, -5.4375e-01, -1.1775e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.5149e-01,  1.8367e-01,  5.9942e-01],\n",
       "                         [ 6.4945e-02, -3.3298e-01,  4.7456e-02],\n",
       "                         [-7.2457e-02, -6.4503e-01, -2.3545e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.3996e-01, -4.6708e-01,  6.5029e-02],\n",
       "                         [ 4.1431e-01, -5.8810e-01, -1.2947e-01],\n",
       "                         [ 6.3620e-01, -4.6198e-01,  8.9512e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.8400e-01,  6.0769e-01,  3.9696e-01],\n",
       "                         [-1.0041e-01, -5.5067e-02, -6.5041e-02],\n",
       "                         [-4.0160e-01, -5.5484e-01, -4.9943e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.7577e-01,  9.2406e-02,  9.8464e-02],\n",
       "                         [-2.4153e-01, -1.5672e-02,  1.2420e-01],\n",
       "                         [-6.3149e-01, -2.6339e-02,  4.9605e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.2362e-01, -4.3782e-01, -5.7199e-01],\n",
       "                         [ 5.7036e-02,  1.7327e-01,  5.8640e-02],\n",
       "                         [ 3.2428e-01,  2.6780e-01,  1.1553e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.2817e-02,  2.5345e-01, -2.3407e-01],\n",
       "                         [ 6.5310e-02,  1.0996e-01, -1.5513e-01],\n",
       "                         [-2.7904e-02,  2.7827e-01, -2.4337e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1770e-01,  3.1490e-01, -9.0855e-01],\n",
       "                         [-1.3766e-01,  3.3192e-03,  7.7066e-01],\n",
       "                         [-5.3093e-02, -3.6863e-01,  2.3213e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.5213e-02, -4.4828e-01,  6.2535e-02],\n",
       "                         [ 5.3619e-02, -4.0840e-01,  4.2392e-03],\n",
       "                         [ 2.0112e-01, -2.2866e-01,  3.0056e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.9792e-01,  2.0081e-01,  1.9037e-01],\n",
       "                         [-2.4127e-01, -3.5608e-01, -2.4821e-01],\n",
       "                         [-3.8929e-02,  1.7353e-01, -4.8857e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.0018e-01,  1.3077e-03, -2.7321e-01],\n",
       "                         [ 2.7165e-02,  3.3843e-02, -7.1168e-02],\n",
       "                         [ 5.3553e-02,  2.3183e-01, -4.2740e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.8983e-01, -3.7882e-02,  7.5205e-01],\n",
       "                         [-4.3510e-01, -2.7665e-01,  5.3879e-01],\n",
       "                         [-3.7065e-01, -1.9793e-01,  3.8153e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0559e-01,  3.1273e-01,  1.5594e-01],\n",
       "                         [ 1.7393e-01, -6.1596e-02, -2.1482e-01],\n",
       "                         [ 1.0072e-01, -3.6248e-01, -2.6370e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0709e-01, -2.5422e-01,  5.1832e-02],\n",
       "                         [ 2.1006e-01, -1.3040e-01, -6.3120e-02],\n",
       "                         [ 6.7084e-02, -9.1186e-02,  8.9826e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.0937e-01,  3.9595e-01,  2.2122e-01],\n",
       "                         [-1.6386e-01,  2.8206e-02, -1.7149e-01],\n",
       "                         [-4.2785e-01, -1.2610e-01, -1.6499e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.4867e-01, -2.5180e-01, -3.5126e-01],\n",
       "                         [-1.1301e-01, -1.2536e-01, -8.0463e-02],\n",
       "                         [ 8.8822e-01,  3.9861e-01,  2.1695e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0753e-02,  4.4991e-02, -2.4421e-01],\n",
       "                         [ 9.5658e-03,  2.3654e-01, -2.5991e-01],\n",
       "                         [ 2.4366e-02,  3.8166e-01, -2.2451e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 8.7838e-01, -5.9983e-02,  1.4472e-01],\n",
       "                         [ 2.1890e-01, -8.2260e-02,  3.5236e-02],\n",
       "                         [-1.6305e-01, -5.5475e-01, -3.4149e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1640e-01,  7.8737e-02, -1.7762e-01],\n",
       "                         [-1.4516e-02,  1.3225e-01,  2.5413e-02],\n",
       "                         [-2.8115e-02,  1.8151e-01, -3.3639e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.3240e-01, -3.6960e-01, -1.5010e-01],\n",
       "                         [ 6.2620e-02,  2.2893e-02,  1.1247e-01],\n",
       "                         [ 2.6827e-01,  3.7458e-01, -8.5182e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0860e-01,  1.1462e+00, -4.2346e-02],\n",
       "                         [-1.4127e-01,  3.0784e-01, -4.1399e-02],\n",
       "                         [-3.6094e-01, -1.9679e-01, -2.6113e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.3481e-01, -2.5167e-01,  3.8530e-01],\n",
       "                         [-1.3977e-01, -3.6216e-01,  1.1309e-03],\n",
       "                         [ 2.0413e-01, -4.5980e-01,  2.9574e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.7680e-02,  2.6627e-01, -2.8784e-01],\n",
       "                         [-3.3592e-01,  2.4736e-01, -1.2399e-01],\n",
       "                         [-2.8255e-01,  8.0267e-01, -4.0267e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.3659e-01, -5.6885e-01, -5.8263e-02],\n",
       "                         [ 2.3202e-01, -3.7275e-01,  4.3137e-02],\n",
       "                         [ 2.3751e-01, -1.1991e-01,  2.6967e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.7833e-01,  6.2141e-01,  4.1701e-01],\n",
       "                         [-9.2735e-02, -3.6468e-02, -3.5021e-01],\n",
       "                         [-5.1336e-02,  1.1924e-01, -1.3558e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.9185e-01,  2.7757e-01,  1.5429e-01],\n",
       "                         [ 2.0638e-01, -9.3221e-02, -4.2492e-02],\n",
       "                         [-3.6869e-01, -2.5070e-01, -3.6196e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1912e-01, -3.4506e-01, -2.0505e-01],\n",
       "                         [-3.5524e-02,  5.3625e-02,  3.3577e-01],\n",
       "                         [ 1.5814e-01, -1.6911e-02,  5.5144e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-7.1422e-01, -9.4341e-02,  4.3752e-02],\n",
       "                         [ 1.3863e+00, -7.7188e-02,  1.9691e-02],\n",
       "                         [-3.5302e-01, -1.1650e-01, -4.4031e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.5821e-01,  1.7370e-01,  3.0065e-01],\n",
       "                         [-4.7475e-01, -6.5231e-01, -4.0496e-01],\n",
       "                         [ 1.6438e-01,  4.0722e-01,  1.4705e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6765e-01, -3.5122e-01, -3.0718e-01],\n",
       "                         [-3.7997e-02, -1.8845e-01,  5.6407e-02],\n",
       "                         [ 2.3948e-01,  2.0316e-01,  6.8780e-01]]]], device='cuda:0')),\n",
       "              ('conv_block1.conv2.weight',\n",
       "               tensor([[[[ 3.7716e-02,  3.8377e-01, -2.6829e-02],\n",
       "                         [ 1.4405e-02, -2.7071e-02, -1.1790e-01],\n",
       "                         [ 3.1483e-02, -1.2675e-01,  1.0402e-01]],\n",
       "               \n",
       "                        [[-1.3191e-01,  5.1577e-02,  9.3906e-02],\n",
       "                         [-1.0973e-01,  1.2606e-01,  6.9330e-02],\n",
       "                         [-7.9789e-02,  1.4824e-01, -2.2891e-01]],\n",
       "               \n",
       "                        [[ 8.4112e-02, -6.5050e-02,  2.2053e-02],\n",
       "                         [-1.6003e-02,  3.6255e-02, -1.0961e-01],\n",
       "                         [ 2.1383e-03,  1.7355e-01, -2.0730e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.2900e-01, -9.4333e-02, -4.8292e-01],\n",
       "                         [ 1.5381e-01, -8.5188e-03,  2.9697e-02],\n",
       "                         [ 1.7547e-01,  5.9568e-02,  4.1180e-01]],\n",
       "               \n",
       "                        [[-6.4412e-02,  2.3372e-02, -8.3541e-02],\n",
       "                         [-5.3537e-02, -8.9693e-02, -1.3112e-02],\n",
       "                         [-5.3418e-02, -4.0995e-02,  1.0250e-01]],\n",
       "               \n",
       "                        [[-2.1671e-01,  2.8036e-02, -1.3197e-04],\n",
       "                         [-3.4290e-02,  5.9299e-02, -1.8906e-02],\n",
       "                         [-5.3243e-02, -4.2178e-02,  2.6321e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0785e+00, -2.0748e-01,  7.5568e-02],\n",
       "                         [ 2.0621e-01, -5.9543e-02,  6.3722e-02],\n",
       "                         [-6.5188e-01, -1.2228e-02,  1.1816e-01]],\n",
       "               \n",
       "                        [[-1.2173e-01,  1.9149e-01,  8.3929e-02],\n",
       "                         [ 8.3358e-02, -2.0013e-01, -1.1041e-02],\n",
       "                         [ 2.7151e-01, -3.6403e-01, -4.3889e-02]],\n",
       "               \n",
       "                        [[-1.7432e-01,  1.5744e-01, -2.0128e-01],\n",
       "                         [ 2.6894e-02, -1.1746e-01, -5.5749e-03],\n",
       "                         [ 2.9326e-01, -4.2377e-01,  5.7002e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.5385e-01, -8.2642e-01,  3.3079e-01],\n",
       "                         [-4.6052e-02, -1.7915e-01,  1.1808e-01],\n",
       "                         [-5.4963e-01,  1.0333e+00, -2.4473e-01]],\n",
       "               \n",
       "                        [[-6.9922e-02,  1.3253e-01,  8.7043e-02],\n",
       "                         [ 1.5732e-01,  1.6859e-01, -2.4649e-02],\n",
       "                         [ 4.5574e-02, -1.4071e-01, -1.5539e-01]],\n",
       "               \n",
       "                        [[ 1.2706e-01,  3.1828e-02,  1.1200e-01],\n",
       "                         [ 9.8312e-02,  3.1909e-02,  8.6010e-02],\n",
       "                         [ 1.4542e-02, -3.4562e-04,  8.4735e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.7297e-02, -1.1035e-01, -1.1087e-01],\n",
       "                         [-7.3131e-02, -9.5376e-02, -9.5487e-02],\n",
       "                         [-8.0729e-02, -9.2381e-04,  2.4190e-02]],\n",
       "               \n",
       "                        [[-1.7203e-01, -4.6300e-01,  2.5281e-01],\n",
       "                         [-1.5188e-01, -4.7515e-01, -3.0280e-02],\n",
       "                         [ 6.9937e-02, -1.2466e-01,  4.5305e-01]],\n",
       "               \n",
       "                        [[ 8.2297e-02,  1.0682e-01,  2.8612e-02],\n",
       "                         [ 1.3627e-01,  4.2858e-02, -3.2870e-02],\n",
       "                         [-3.5023e-02, -7.2602e-02, -2.1970e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.8166e-02,  1.6987e-01,  2.3324e-01],\n",
       "                         [ 2.0293e-01, -1.0903e-02, -1.6093e-01],\n",
       "                         [ 1.5683e-01, -1.1523e-01, -3.9176e-01]],\n",
       "               \n",
       "                        [[ 2.7918e-02, -5.2651e-02, -3.0204e-02],\n",
       "                         [-6.0518e-02, -1.3612e-01, -2.5142e-01],\n",
       "                         [ 8.2353e-02, -6.1556e-02,  5.9971e-02]],\n",
       "               \n",
       "                        [[-7.5691e-02, -5.9457e-03, -4.2270e-02],\n",
       "                         [-4.8160e-02, -3.5608e-02, -2.8247e-02],\n",
       "                         [-1.7834e-02, -7.6805e-02,  2.5366e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-4.9454e-02, -5.7105e-03, -8.8107e-02],\n",
       "                         [-3.6103e-02,  2.0379e-01,  3.4189e-01],\n",
       "                         [-4.2215e-02, -2.1860e-01, -2.4045e-01]],\n",
       "               \n",
       "                        [[-3.0638e-01, -1.8374e-01, -3.8692e-01],\n",
       "                         [ 4.3731e-01,  6.7990e-01,  3.9994e-01],\n",
       "                         [-3.8064e-01, -3.3509e-01, -6.1751e-01]],\n",
       "               \n",
       "                        [[-1.5306e-02, -1.0777e-02, -4.1142e-02],\n",
       "                         [-8.7511e-02, -1.0601e-01, -1.5231e-01],\n",
       "                         [-1.8568e-02,  3.6170e-02, -7.9173e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.1569e-01,  2.8898e-01,  3.5592e-01],\n",
       "                         [-1.0991e+00, -7.5708e-01, -8.5644e-01],\n",
       "                         [ 6.9730e-01,  1.2808e-01,  4.9305e-01]],\n",
       "               \n",
       "                        [[-6.9309e-02, -2.3946e-02, -6.7120e-02],\n",
       "                         [ 7.7438e-02,  7.9852e-02, -2.2187e-02],\n",
       "                         [-5.7858e-02, -7.3175e-03, -4.6205e-02]],\n",
       "               \n",
       "                        [[ 2.4485e-01,  3.5203e-01,  1.8942e-01],\n",
       "                         [-2.1788e-01, -1.4184e-01, -1.8707e-01],\n",
       "                         [-1.7722e-01, -9.8066e-02, -2.2995e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2625e-02,  1.0379e-02, -8.0609e-02],\n",
       "                         [ 5.3149e-02, -9.3726e-02, -1.0543e-01],\n",
       "                         [ 4.8197e-02, -5.4563e-02, -4.1949e-02]],\n",
       "               \n",
       "                        [[ 1.4315e-02,  7.2706e-02, -6.4910e-02],\n",
       "                         [-3.9319e-02, -1.9981e-01, -9.3217e-02],\n",
       "                         [ 5.4948e-02,  7.2174e-02,  5.5379e-02]],\n",
       "               \n",
       "                        [[-2.6129e-02, -1.1373e-02, -1.9768e-02],\n",
       "                         [ 2.1967e-02,  6.3522e-02,  1.2756e-02],\n",
       "                         [ 9.7849e-02,  8.7106e-02,  4.9843e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.5595e-02, -1.5106e-01,  2.8897e-01],\n",
       "                         [ 9.5800e-02, -1.1059e-01,  1.5325e-01],\n",
       "                         [ 2.9394e-02, -2.9501e-02,  1.2501e-01]],\n",
       "               \n",
       "                        [[ 1.2613e-01,  6.3016e-02,  2.7176e-02],\n",
       "                         [-5.3751e-02, -8.8469e-02, -2.4307e-02],\n",
       "                         [ 7.0750e-02,  2.2604e-02,  1.4919e-02]],\n",
       "               \n",
       "                        [[ 2.6332e-02, -2.9871e-02,  7.3902e-02],\n",
       "                         [ 5.8938e-02,  8.6006e-02,  3.4223e-02],\n",
       "                         [-2.8744e-02,  8.2594e-03,  1.7609e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.7435e-01,  4.7874e-02,  7.0055e-02],\n",
       "                         [ 8.6948e-02,  3.3030e-01,  1.3110e-01],\n",
       "                         [ 1.5556e-01,  3.2963e-01,  1.5869e-01]],\n",
       "               \n",
       "                        [[-6.3539e-01, -6.0424e-01, -2.4252e-01],\n",
       "                         [-1.3502e-01, -1.3486e-01, -3.6140e-01],\n",
       "                         [-5.2280e-01, -4.7667e-01, -5.4187e-01]],\n",
       "               \n",
       "                        [[ 1.0034e-01, -3.9097e-01, -6.2816e-01],\n",
       "                         [-5.8587e-02, -3.5102e-01, -4.4382e-01],\n",
       "                         [-1.9356e-02, -2.9316e-01, -2.4458e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.3339e-01, -3.5807e-01, -7.3283e-03],\n",
       "                         [ 9.7241e-03, -1.2542e-01,  4.9291e-02],\n",
       "                         [ 2.5228e-01, -1.4051e-01, -8.6471e-02]],\n",
       "               \n",
       "                        [[-6.5190e-02, -1.7026e-01, -9.0556e-02],\n",
       "                         [ 1.3915e-01, -3.3030e-02, -7.1347e-02],\n",
       "                         [-2.2762e-05, -1.7184e-01, -1.6950e-02]],\n",
       "               \n",
       "                        [[ 7.2244e-02,  7.6516e-02, -2.7654e-03],\n",
       "                         [ 1.0507e-01, -4.3255e-04,  5.2007e-02],\n",
       "                         [ 2.0332e-02,  1.0466e-01,  5.0690e-02]]]], device='cuda:0')),\n",
       "              ('conv_block1.bn1.weight',\n",
       "               tensor([1.0147, 1.8317, 0.8301, 1.2968, 0.5953, 0.7233, 0.7475, 1.2259, 0.7721,\n",
       "                       1.0568, 1.3650, 0.3360, 0.4459, 0.6781, 0.6541, 0.3440, 0.5908, 1.0499,\n",
       "                       0.6292, 0.5092, 0.6707, 2.1327, 1.5605, 0.8525, 0.6335, 0.9048, 0.8897,\n",
       "                       0.6496, 1.0510, 1.3799, 0.9359, 0.6482, 0.5818, 1.7507, 2.3637, 0.6982,\n",
       "                       0.9968, 0.4719, 0.5994, 0.5357, 0.7040, 2.0022, 0.6293, 0.2890, 0.5688,\n",
       "                       0.9239, 0.6793, 0.5159, 0.4398, 0.5231, 0.6452, 0.8483, 0.5375, 1.9732,\n",
       "                       0.8341, 0.7305, 1.1377, 1.0964, 0.8403, 0.4709, 0.7815, 1.3541, 0.9502,\n",
       "                       1.0875], device='cuda:0')),\n",
       "              ('conv_block1.bn1.bias',\n",
       "               tensor([ 0.6754,  0.1345,  0.0220,  1.3368, -0.6749,  0.0839, -1.3812, -1.3433,\n",
       "                       -0.7652,  0.2082, -1.0769,  0.1627,  0.0673,  0.0511,  0.1200,  0.1681,\n",
       "                        0.0150,  0.0098, -0.7188, -0.5221, -0.8065,  0.4152,  0.2131, -1.1045,\n",
       "                        0.0147, -1.0571,  0.0904, -0.7248, -0.9289, -0.0724,  0.0621, -0.8089,\n",
       "                        0.0928,  0.1172,  0.0503,  0.1471,  0.6545,  0.1610, -0.4684,  0.0174,\n",
       "                       -0.8001,  0.3992, -0.6326,  0.1002, -0.7923,  0.0503, -0.4399, -0.1764,\n",
       "                       -1.0168,  0.0272, -0.1202,  0.1499, -0.9979,  0.2602, -0.7370,  0.1048,\n",
       "                        0.8390, -0.2476,  0.0871,  0.0680,  0.1174,  1.5486, -1.0039, -1.6553],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn1.running_mean',\n",
       "               tensor([-0.0030, -0.0002, -0.0097,  0.0008, -0.0108,  0.0094, -0.0018, -0.0032,\n",
       "                       -0.0002, -0.0022,  0.0009, -0.0213,  0.0035, -0.0077,  0.0031, -0.0275,\n",
       "                       -0.0161, -0.0078, -0.0127, -0.0061,  0.0220,  0.0024,  0.0018,  0.0035,\n",
       "                       -0.0123, -0.0039,  0.0027,  0.0010,  0.0109,  0.0010,  0.0048, -0.0150,\n",
       "                        0.0156,  0.0009,  0.0008,  0.0050,  0.0055, -0.0204, -0.0695, -0.0294,\n",
       "                        0.0018, -0.0023, -0.0279, -0.0122, -0.0161, -0.0047, -0.0007,  0.0002,\n",
       "                       -0.0074,  0.0328,  0.0009,  0.0095, -0.0117, -0.0013,  0.0422,  0.0078,\n",
       "                       -0.0017,  0.0020, -0.0008,  0.0251,  0.0097,  0.0051,  0.0014,  0.0013],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn1.running_var',\n",
       "               tensor([0.1543, 0.0237, 0.0862, 0.0526, 0.0313, 0.1704, 0.0081, 0.1066, 0.0159,\n",
       "                       0.1204, 0.0105, 0.0897, 0.2165, 0.1375, 0.2466, 0.1312, 0.1832, 0.0805,\n",
       "                       0.0449, 0.0544, 0.0787, 0.0197, 0.1028, 0.0528, 0.1611, 0.0675, 0.0803,\n",
       "                       0.0510, 0.0249, 0.0835, 0.2510, 0.1207, 0.1927, 0.0362, 0.0125, 0.0803,\n",
       "                       0.1997, 0.1383, 0.6347, 0.1720, 0.0371, 0.0157, 0.1682, 0.0286, 0.0476,\n",
       "                       0.3584, 0.0377, 0.0152, 0.0391, 0.1976, 0.0495, 0.1186, 0.0258, 0.0243,\n",
       "                       0.3662, 0.0665, 0.0868, 0.0709, 0.0456, 0.1456, 0.0848, 0.0315, 0.0196,\n",
       "                       0.0608], device='cuda:0')),\n",
       "              ('conv_block1.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block1.bn2.weight',\n",
       "               tensor([1.4841, 1.2917, 1.0752, 0.9392, 1.3012, 0.5648, 0.7395, 1.2967, 0.3735,\n",
       "                       1.2988, 1.5531, 1.1796, 1.5098, 0.8108, 0.5671, 1.0800, 1.0263, 1.2715,\n",
       "                       1.3641, 1.3163, 1.5201, 0.6631, 1.1183, 1.1883, 1.2024, 0.8789, 1.3421,\n",
       "                       0.3771, 1.0490, 1.4551, 1.1245, 1.5359, 0.6782, 1.5352, 0.9282, 1.1248,\n",
       "                       1.3073, 0.9236, 1.2908, 1.3024, 0.4935, 1.0720, 0.8583, 1.5085, 1.4076,\n",
       "                       1.4440, 0.6413, 0.6526, 1.0588, 0.5574, 0.6595, 1.0363, 0.7635, 1.3950,\n",
       "                       1.3622, 1.1709, 0.8593, 0.5827, 0.9331, 1.3578, 1.2215, 0.9420, 0.5712,\n",
       "                       0.5443], device='cuda:0')),\n",
       "              ('conv_block1.bn2.bias',\n",
       "               tensor([-0.8234, -0.8081, -0.4838, -0.5944, -0.8566, -0.2404, -0.5236, -0.9160,\n",
       "                       -0.0529, -0.3748, -0.7467, -0.8183, -1.0355, -0.2404, -0.3608, -0.5537,\n",
       "                       -0.6094, -0.5815, -0.5941, -0.8944, -0.6258, -0.1631, -0.5619, -0.8486,\n",
       "                       -0.4367, -0.3251, -0.8718, -0.0486, -0.5740, -0.9323, -0.6806, -0.7423,\n",
       "                       -0.9645, -1.0283, -0.6479, -0.5786, -0.9397, -0.1561, -0.6581, -0.7995,\n",
       "                       -0.1054, -0.5006, -0.2690, -0.9833, -0.6177, -1.0039, -0.5419, -0.7335,\n",
       "                       -0.4527, -0.3228, -0.2103, -0.3911, -0.2588, -0.8303, -0.6102, -0.4021,\n",
       "                       -0.2842, -0.4564, -0.4216, -0.6266, -0.8774, -0.5110, -0.9052, -0.2076],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn2.running_mean',\n",
       "               tensor([ -7.9719,  -3.7649,  -7.8810,  -7.6889, -10.5837,  -4.0918,  -5.6065,\n",
       "                        -6.6311,   2.5603,  -7.6045,  -5.1107,  -4.1815,  -5.9455,  -3.2822,\n",
       "                        -0.6395,  -6.0870,  -6.7635,  -9.0023, -10.2618,  -7.7644,  -7.4981,\n",
       "                       -10.6928,  -5.4010,  -5.7467,  -4.5544, -14.6207,  -9.4568,   0.4363,\n",
       "                        -6.0029,  -4.7520, -10.0777, -19.3728,   7.3312,  -3.9146,  -4.1213,\n",
       "                        -4.5376, -10.3372, -11.7089,  -8.8880,  -4.1784,  -8.7844, -13.1679,\n",
       "                        -5.4957,  -5.8013,  -6.2711,  -5.9831,  -0.4317,   2.0526, -11.5915,\n",
       "                         0.2059, -10.6473,  -4.9260,  -1.5417,  -6.0039,  -5.3137,  -8.6857,\n",
       "                        -5.8778,   0.5054,  -4.8357, -11.6665,  -6.8932,  -5.2246,   3.5649,\n",
       "                       -13.4528], device='cuda:0')),\n",
       "              ('conv_block1.bn2.running_var',\n",
       "               tensor([104.4665,  52.4385,  91.5131,  81.1477, 122.0083, 126.2023,  42.4414,\n",
       "                        56.1025,  49.7538, 172.0671,  49.8468,  42.4662,  61.2207,  86.6769,\n",
       "                        18.0178,  74.0177, 108.8776, 173.0154, 178.2723,  87.5935,  94.7047,\n",
       "                       169.9219, 103.4164,  34.5758,  53.0822, 284.2262, 160.3335,  48.1477,\n",
       "                        71.1743,  55.5738, 114.1072, 412.1122,  25.4355,  31.5929,  33.4811,\n",
       "                        55.7246, 103.4648, 273.7428, 177.9740,  32.0147,  52.4685, 176.6447,\n",
       "                        43.8073,  53.1339,  80.3319,  43.6741,  16.8771,  37.1667, 248.7390,\n",
       "                        23.0678, 106.6639,  45.7877,  36.2760,  64.4575, 116.5747, 174.5919,\n",
       "                       161.6967,  24.6345,  87.6809, 261.5728,  88.1909,  33.4879,  24.3092,\n",
       "                       194.4015], device='cuda:0')),\n",
       "              ('conv_block1.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block2.conv1.weight',\n",
       "               tensor([[[[-6.6612e-02, -5.9600e-02, -3.3646e-02],\n",
       "                         [-9.0082e-03, -3.4218e-02, -1.2638e-01],\n",
       "                         [-1.5268e-01, -5.2480e-02, -6.7372e-02]],\n",
       "               \n",
       "                        [[ 1.1773e-01,  1.3273e-01,  1.4331e-01],\n",
       "                         [ 1.5485e-02, -5.2641e-02,  6.5574e-02],\n",
       "                         [ 3.9865e-02,  6.6218e-02,  1.6867e-01]],\n",
       "               \n",
       "                        [[ 9.3612e-03, -3.2874e-03, -5.0931e-03],\n",
       "                         [ 1.0213e-02,  2.7881e-02,  5.9696e-02],\n",
       "                         [ 2.5336e-03,  5.3899e-02,  1.0334e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.3382e-02,  6.7181e-02,  6.3629e-02],\n",
       "                         [-8.2463e-03,  3.0971e-02,  3.6543e-02],\n",
       "                         [-3.2838e-02, -5.4525e-02, -1.0010e-01]],\n",
       "               \n",
       "                        [[ 5.8703e-03, -5.4488e-03, -7.4210e-03],\n",
       "                         [-8.8855e-03,  9.4491e-03, -2.4393e-02],\n",
       "                         [ 4.0046e-02,  2.7267e-02, -2.4605e-02]],\n",
       "               \n",
       "                        [[ 3.4274e-03, -1.7679e-02, -1.0506e-02],\n",
       "                         [-6.6787e-02, -2.9965e-02, -3.4468e-02],\n",
       "                         [-4.4432e-02, -1.3806e-02, -4.1295e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.9368e-02, -4.6169e-02, -3.1849e-02],\n",
       "                         [ 1.1523e-01,  1.7957e-01,  4.6607e-02],\n",
       "                         [ 5.8586e-03,  1.2307e-01,  1.4036e-02]],\n",
       "               \n",
       "                        [[-1.8446e-01, -2.0808e-01, -7.5956e-02],\n",
       "                         [-2.9685e-01, -2.9554e-01,  5.7040e-02],\n",
       "                         [-2.7504e-01,  6.5192e-02,  2.9643e-02]],\n",
       "               \n",
       "                        [[ 3.1143e-02,  5.7940e-02,  5.3295e-02],\n",
       "                         [-1.4687e-01, -2.6303e-01,  4.0375e-02],\n",
       "                         [ 8.0275e-02, -1.9773e-01,  7.4133e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.7884e-02, -6.6429e-02, -6.8187e-03],\n",
       "                         [-8.8455e-02, -2.1068e-01, -1.0393e-01],\n",
       "                         [ 4.0991e-02, -1.4381e-01, -1.1891e-01]],\n",
       "               \n",
       "                        [[ 3.8864e-02, -7.3408e-02, -1.0042e-01],\n",
       "                         [ 6.2543e-02, -1.5229e-02,  3.8400e-02],\n",
       "                         [-4.9299e-02, -1.4120e-01, -1.5871e-01]],\n",
       "               \n",
       "                        [[ 1.2304e-01,  1.6561e-01,  1.1603e-01],\n",
       "                         [-3.1976e-03,  1.5427e-01,  1.0683e-01],\n",
       "                         [ 1.0294e-01,  1.0579e-01,  1.8109e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.3461e-01,  3.3709e-01, -1.2679e-01],\n",
       "                         [-1.1710e-01, -1.9431e-01, -2.6899e-01],\n",
       "                         [ 1.2496e-01, -2.3303e-01, -3.0178e-01]],\n",
       "               \n",
       "                        [[-7.5645e-01, -1.8989e-02, -1.4834e-01],\n",
       "                         [-1.5400e+00, -1.4846e+00, -2.8898e-01],\n",
       "                         [-1.9606e+00, -1.8870e+00, -6.1143e-01]],\n",
       "               \n",
       "                        [[ 7.4252e-02, -3.6760e-02,  2.5229e-01],\n",
       "                         [-5.4651e-03, -4.8606e-01,  6.3125e-02],\n",
       "                         [ 1.1650e-01, -6.2473e-01,  9.7307e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.3681e-02,  1.0975e-01, -1.4098e-01],\n",
       "                         [-1.3643e-02, -1.8806e-02, -1.1949e-01],\n",
       "                         [-1.5424e-01,  2.1139e-02, -1.2501e-01]],\n",
       "               \n",
       "                        [[-2.0506e-01, -3.0328e-01, -7.0644e-03],\n",
       "                         [ 6.5120e-02, -1.5298e-02,  8.4776e-02],\n",
       "                         [ 9.8368e-02,  2.2104e-01,  4.7331e-02]],\n",
       "               \n",
       "                        [[ 1.0543e-02, -3.8799e-02,  1.2879e-01],\n",
       "                         [-1.4161e-03, -1.6089e-01, -1.1688e-01],\n",
       "                         [ 1.8923e-01,  2.9672e-02, -8.9577e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 2.5869e-01,  2.4997e-01,  1.0919e-01],\n",
       "                         [ 8.0202e-02, -7.0330e-02, -1.1587e-01],\n",
       "                         [-1.7754e-01, -9.0353e-02, -1.1497e-02]],\n",
       "               \n",
       "                        [[ 3.2115e-01,  2.9448e-01, -5.0417e-02],\n",
       "                         [ 1.6544e-01,  5.9469e-02,  1.6220e-02],\n",
       "                         [-3.3938e-02, -2.0441e-02,  2.2820e-01]],\n",
       "               \n",
       "                        [[-2.6324e-01, -2.1927e-01,  1.9276e-02],\n",
       "                         [-1.1829e-01, -9.9668e-02, -3.7246e-02],\n",
       "                         [-1.5414e-01, -3.0073e-01, -3.8076e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.8569e-01, -8.8609e-02, -2.7967e-01],\n",
       "                         [-1.7912e-01, -1.2283e-01, -1.4729e-01],\n",
       "                         [-1.1130e-01, -1.5198e-01, -4.9355e-02]],\n",
       "               \n",
       "                        [[-1.5297e-01, -6.4467e-02, -1.4488e-02],\n",
       "                         [ 8.3452e-02,  1.1420e-01,  1.4201e-01],\n",
       "                         [ 6.5947e-02,  7.5174e-02,  1.4104e-02]],\n",
       "               \n",
       "                        [[-3.9835e-01, -4.4832e-01,  4.2174e-02],\n",
       "                         [-4.3757e-02,  3.5249e-03,  1.9157e-01],\n",
       "                         [ 5.1002e-01,  2.7074e-01,  2.1804e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.0083e-01, -2.0754e-01, -1.2930e-01],\n",
       "                         [-4.3015e-02,  7.0285e-02,  3.9884e-02],\n",
       "                         [ 4.1164e-03, -1.0237e-02, -2.3977e-01]],\n",
       "               \n",
       "                        [[-2.5900e-01, -4.4998e-01,  1.5604e-01],\n",
       "                         [-1.7697e-01, -4.5872e-01,  2.1617e-01],\n",
       "                         [ 3.7660e-02, -7.4408e-01,  6.8443e-02]],\n",
       "               \n",
       "                        [[-1.1396e-01, -5.3961e-02, -3.6279e-01],\n",
       "                         [ 1.1854e-01, -1.2681e-01, -2.1725e-01],\n",
       "                         [ 2.6696e-01, -3.6346e-01, -9.5176e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.7260e-04, -6.8171e-02,  8.3130e-02],\n",
       "                         [-6.1544e-02, -1.0541e-01,  1.3370e-01],\n",
       "                         [-1.3495e-02, -3.3459e-01, -3.7672e-01]],\n",
       "               \n",
       "                        [[ 4.4782e-02, -4.8111e-02, -3.0118e-01],\n",
       "                         [ 7.5534e-02,  1.4195e-02, -9.2084e-02],\n",
       "                         [ 5.9530e-02,  2.4830e-01, -1.9449e-02]],\n",
       "               \n",
       "                        [[-5.6514e-02, -4.7786e-01, -5.4551e-01],\n",
       "                         [ 6.7129e-02, -1.0447e-01, -3.5393e-01],\n",
       "                         [ 2.0524e-01,  1.4802e-01, -1.2159e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1755e-01,  1.8948e-01, -8.5609e-02],\n",
       "                         [ 1.8041e-03,  9.2940e-02,  4.3612e-03],\n",
       "                         [-2.8400e-02,  8.6866e-02,  5.8296e-02]],\n",
       "               \n",
       "                        [[ 1.5267e-01,  9.4688e-02,  1.0845e-01],\n",
       "                         [ 1.2109e-02,  1.7323e-02,  7.2662e-02],\n",
       "                         [ 1.5045e-01,  6.3335e-02,  1.3530e-01]],\n",
       "               \n",
       "                        [[-1.1404e-02, -6.6846e-05,  3.2670e-02],\n",
       "                         [ 1.3148e-02, -9.1374e-03,  7.4029e-02],\n",
       "                         [ 7.1019e-02, -1.2960e-02,  2.3726e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.7098e-02,  6.7599e-02,  1.4238e-02],\n",
       "                         [ 4.8238e-02,  1.3659e-02, -1.2117e-01],\n",
       "                         [ 1.4043e-02, -4.1660e-02, -1.5624e-01]],\n",
       "               \n",
       "                        [[ 7.8119e-02,  5.5463e-02, -4.3440e-02],\n",
       "                         [ 4.9839e-02,  1.5844e-02,  6.5254e-03],\n",
       "                         [-1.8330e-03,  3.8192e-02, -6.3780e-02]],\n",
       "               \n",
       "                        [[ 1.2015e-03, -5.0034e-02, -4.7408e-03],\n",
       "                         [-9.7093e-02, -1.0198e-01, -1.2352e-01],\n",
       "                         [-4.9896e-02, -4.3457e-02, -1.8967e-02]]]], device='cuda:0')),\n",
       "              ('conv_block2.conv2.weight',\n",
       "               tensor([[[[-1.2165e-01, -3.4758e-02, -3.1801e-02],\n",
       "                         [-2.2202e-01, -4.2053e-02, -8.9334e-03],\n",
       "                         [-2.1968e-01,  1.4105e-02, -7.2417e-02]],\n",
       "               \n",
       "                        [[-1.8230e-02,  4.9553e-02,  2.1746e-03],\n",
       "                         [-5.1542e-03,  1.5157e-01, -5.8213e-02],\n",
       "                         [-6.2584e-02,  8.8796e-02, -9.7473e-02]],\n",
       "               \n",
       "                        [[-7.6419e-02,  2.6815e-01, -4.1798e-01],\n",
       "                         [ 1.1087e-01,  1.8604e-01, -4.2441e-01],\n",
       "                         [ 6.6051e-01,  6.7546e-02, -2.2249e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.7164e-01,  6.9644e-02, -1.1054e-01],\n",
       "                         [-1.9934e-01,  1.2364e-01, -1.8217e-01],\n",
       "                         [ 1.9870e-01, -2.1927e-01, -4.7338e-01]],\n",
       "               \n",
       "                        [[ 6.0575e-01,  1.9189e-01, -3.9298e-01],\n",
       "                         [ 3.8937e-01, -5.2282e-01, -3.3441e-01],\n",
       "                         [ 5.0963e-02, -8.0754e-01,  2.1472e-01]],\n",
       "               \n",
       "                        [[-5.4394e-02, -4.4702e-02, -4.1633e-02],\n",
       "                         [-7.9942e-02,  2.0425e-02, -1.1764e-01],\n",
       "                         [-6.7712e-02, -4.8692e-02, -8.1700e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.8303e-02, -1.1456e-01, -6.3068e-02],\n",
       "                         [-3.1676e-02, -7.5469e-02, -8.8714e-02],\n",
       "                         [ 1.6190e-02, -1.3691e-01, -1.2982e-02]],\n",
       "               \n",
       "                        [[ 1.3800e-02,  4.3082e-02,  1.2921e-01],\n",
       "                         [-6.6615e-02,  3.9583e-02,  5.1345e-02],\n",
       "                         [-9.0941e-02, -3.3695e-02, -1.6292e-01]],\n",
       "               \n",
       "                        [[-2.9417e-01, -2.7346e-01, -2.8625e-01],\n",
       "                         [-4.8340e-01, -3.0853e-01, -2.9241e-01],\n",
       "                         [-4.6969e-01, -4.4771e-01, -2.2531e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.3768e-01, -1.3367e-01,  6.3965e-02],\n",
       "                         [-1.8034e-01, -1.0056e-01,  4.9152e-02],\n",
       "                         [ 6.9681e-02,  4.4886e-02, -1.5970e-02]],\n",
       "               \n",
       "                        [[ 6.3910e-02,  5.0630e-02, -1.5643e-01],\n",
       "                         [-1.2564e-02,  8.7770e-02, -2.5424e-01],\n",
       "                         [-1.5242e-01,  3.2650e-02, -3.4847e-01]],\n",
       "               \n",
       "                        [[-1.0796e-02, -6.4269e-02, -5.0478e-03],\n",
       "                         [-9.9691e-02, -6.7211e-02, -5.9294e-02],\n",
       "                         [-5.5320e-02, -4.8565e-02, -8.5714e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.3092e-01,  9.5969e-02,  1.5641e-01],\n",
       "                         [ 1.9266e-01,  1.9806e-01,  3.0072e-01],\n",
       "                         [ 1.0866e-01,  6.0311e-02,  1.0739e-01]],\n",
       "               \n",
       "                        [[-4.7209e-02, -7.3073e-02, -1.1407e-01],\n",
       "                         [ 3.4073e-02, -6.4070e-02,  7.7815e-02],\n",
       "                         [ 2.4749e-02, -6.8775e-02,  7.9206e-02]],\n",
       "               \n",
       "                        [[-2.8662e-02, -6.8921e-03, -1.5398e-01],\n",
       "                         [ 1.1468e-01,  1.0031e-01, -2.7129e-02],\n",
       "                         [ 1.9977e-01,  1.8576e-01,  5.5038e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.7789e-01, -1.6586e-01, -5.8020e-02],\n",
       "                         [-1.0732e-01, -1.4870e-01, -1.8783e-01],\n",
       "                         [ 1.1411e-01,  1.8217e-03,  6.5047e-03]],\n",
       "               \n",
       "                        [[ 5.4595e-02,  7.4122e-02, -2.3456e-01],\n",
       "                         [-1.3140e-01, -1.0850e-02, -2.9233e-01],\n",
       "                         [-3.5969e-02,  2.3044e-01, -1.8797e-01]],\n",
       "               \n",
       "                        [[ 1.4259e-01,  7.6576e-02,  9.8668e-02],\n",
       "                         [ 2.4371e-01,  1.9889e-01,  1.1936e-01],\n",
       "                         [ 1.4846e-01,  1.9596e-01,  1.3475e-01]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-2.1735e-02, -1.3602e-03, -6.8345e-03],\n",
       "                         [-3.9126e-02, -2.0053e-02, -6.9146e-02],\n",
       "                         [-4.7897e-02, -3.2232e-02, -3.0127e-02]],\n",
       "               \n",
       "                        [[-1.1223e-01, -2.3186e-03,  1.0385e-01],\n",
       "                         [-1.8395e-02, -9.9355e-03,  2.3772e-02],\n",
       "                         [ 9.9456e-03,  3.8746e-02,  3.2703e-02]],\n",
       "               \n",
       "                        [[ 5.2624e-01,  3.0441e-01, -2.7560e-02],\n",
       "                         [ 3.8298e-01,  3.3152e-01,  3.2366e-01],\n",
       "                         [-1.7045e-01, -1.2247e-01, -6.2685e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.2901e-01,  1.6458e-01, -5.7356e-02],\n",
       "                         [ 1.9583e-01,  1.6779e-01,  2.3444e-02],\n",
       "                         [-1.3751e-01, -1.7650e-01, -3.1298e-01]],\n",
       "               \n",
       "                        [[ 1.4263e-01, -1.8176e-01, -1.3101e-01],\n",
       "                         [-3.3003e-01, -1.7546e-01, -1.4912e-01],\n",
       "                         [-4.1653e-01, -2.7350e-01, -2.3506e-01]],\n",
       "               \n",
       "                        [[-3.4305e-03, -1.1950e-02, -2.6996e-02],\n",
       "                         [-3.5794e-02, -1.4185e-02, -2.9764e-02],\n",
       "                         [ 2.7390e-02, -6.2543e-02, -3.8219e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0635e-02, -2.6808e-03, -9.0777e-02],\n",
       "                         [-3.8485e-02,  3.2833e-02, -1.6659e-02],\n",
       "                         [-1.8095e-02,  8.3388e-03,  1.3049e-02]],\n",
       "               \n",
       "                        [[-4.0688e-02, -2.1189e-01, -1.4189e-01],\n",
       "                         [-4.1159e-02, -1.1777e-01, -3.9503e-02],\n",
       "                         [ 4.0488e-02,  6.5073e-02, -1.2451e-01]],\n",
       "               \n",
       "                        [[-1.9807e-01, -1.4593e-01, -3.1981e-01],\n",
       "                         [-2.6858e-01, -9.8892e-02, -2.4597e-01],\n",
       "                         [-3.9285e-01, -2.7522e-02, -2.4347e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2200e-01, -2.3795e-01, -4.5053e-01],\n",
       "                         [-4.3874e-01, -2.1310e-02, -6.6127e-02],\n",
       "                         [ 1.4589e-01,  1.8029e-01, -2.1881e-01]],\n",
       "               \n",
       "                        [[ 1.2308e-02,  3.8618e-01,  4.7723e-02],\n",
       "                         [ 1.1494e-02,  2.0954e-01,  1.6211e-02],\n",
       "                         [-1.2337e-01, -1.7129e-01, -2.3508e-01]],\n",
       "               \n",
       "                        [[-2.2188e-03, -2.6811e-02, -4.6226e-03],\n",
       "                         [-7.3100e-02, -4.6282e-02, -5.9734e-02],\n",
       "                         [ 1.5354e-02, -7.1094e-02, -4.0344e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9619e-02, -1.3767e-02, -6.4492e-02],\n",
       "                         [ 7.0084e-02,  2.1040e-02, -1.6778e-02],\n",
       "                         [ 2.5448e-02, -2.0526e-02, -1.5553e-02]],\n",
       "               \n",
       "                        [[ 6.7199e-02,  5.4012e-02, -5.1086e-02],\n",
       "                         [-1.6294e-02,  2.6211e-03, -5.9751e-02],\n",
       "                         [ 1.1546e-01,  7.7307e-02, -3.1984e-02]],\n",
       "               \n",
       "                        [[-1.3045e-01,  4.2094e-01,  3.6570e-01],\n",
       "                         [ 5.6246e-02,  7.0460e-01,  5.7300e-01],\n",
       "                         [-8.8699e-02,  4.3950e-01,  6.2013e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.6621e-01, -1.4640e-01,  1.2067e-01],\n",
       "                         [ 3.1655e-02,  3.4726e-01,  4.2844e-01],\n",
       "                         [-4.9609e-02,  3.7723e-01,  2.6148e-01]],\n",
       "               \n",
       "                        [[ 1.0608e-02,  5.0214e-01,  1.0745e-01],\n",
       "                         [-1.9865e-01,  2.3390e-01,  7.7547e-03],\n",
       "                         [-1.2779e-01,  2.3408e-01, -2.2846e-02]],\n",
       "               \n",
       "                        [[ 2.3396e-02, -2.1005e-02, -6.9662e-03],\n",
       "                         [-2.6809e-02, -3.2222e-02, -9.1260e-03],\n",
       "                         [-5.6296e-04, -2.4745e-03, -5.7847e-02]]]], device='cuda:0')),\n",
       "              ('conv_block2.bn1.weight',\n",
       "               tensor([0.7172, 1.1233, 1.1306, 1.0778, 1.2900, 1.3358, 1.0254, 0.9637, 1.0924,\n",
       "                       1.9560, 1.1531, 1.0244, 0.9168, 0.9906, 1.3675, 1.0856, 1.0364, 1.4014,\n",
       "                       0.6489, 1.1420, 1.0177, 1.0153, 0.4829, 1.3125, 1.0182, 1.2070, 0.8518,\n",
       "                       1.1346, 1.0194, 1.0389, 0.6530, 1.6765, 1.3377, 1.0420, 1.1963, 1.4562,\n",
       "                       1.2257, 0.8529, 1.2123, 1.0886, 1.2572, 0.9541, 1.2606, 1.1860, 0.7690,\n",
       "                       1.0909, 0.8198, 1.6815, 1.5043, 0.9400, 0.9319, 1.2516, 1.2181, 0.7739,\n",
       "                       1.5223, 1.2250, 0.5551, 0.8316, 1.1723, 0.6180, 1.2489, 1.3083, 1.2504,\n",
       "                       1.1648, 0.9319, 0.8519, 1.1785, 1.1199, 1.0065, 1.0437, 0.8517, 0.9715,\n",
       "                       1.1117, 0.8660, 1.2616, 0.6270, 1.4886, 0.8508, 1.6452, 0.9375, 0.9837,\n",
       "                       0.9614, 0.9463, 0.9444, 1.3023, 0.9668, 0.9989, 0.8529, 1.2239, 1.2258,\n",
       "                       0.8677, 1.0991, 1.2224, 1.3239, 1.0160, 0.8423, 0.7899, 1.0761, 0.9532,\n",
       "                       1.1130, 1.0155, 1.4508, 0.9422, 0.4902, 1.3575, 1.2227, 0.6806, 1.0196,\n",
       "                       1.1379, 1.3348, 0.8498, 1.1620, 1.0342, 1.0171, 0.7932, 1.2207, 1.0058,\n",
       "                       1.1235, 0.9424, 0.7260, 1.1394, 1.4980, 0.9080, 1.0551, 0.7560, 1.6658,\n",
       "                       1.0238, 0.7015], device='cuda:0')),\n",
       "              ('conv_block2.bn1.bias',\n",
       "               tensor([-1.3539, -0.9176, -0.3358, -0.6793, -0.2511, -0.5147,  0.1780,  0.0788,\n",
       "                       -0.9521, -3.2531, -0.3384, -0.2269, -0.1342, -0.4940, -0.5501, -0.7990,\n",
       "                       -0.2480, -0.7214, -1.2223, -0.8328,  0.1423, -0.7698, -0.0695, -0.9567,\n",
       "                       -0.6748, -0.8609, -1.0909, -0.6635, -0.5919, -0.3254, -0.5232, -1.0573,\n",
       "                       -0.5956,  0.2500, -1.2381, -0.9972, -1.1012, -0.7308, -0.9487, -0.4341,\n",
       "                       -0.7429, -0.7259, -0.9874, -0.2327, -1.4147, -0.8253, -0.5465, -2.2435,\n",
       "                       -0.7619, -0.4607, -1.0012, -0.7680,  0.0576, -0.1711, -0.9545, -0.4789,\n",
       "                       -0.2734, -0.1463, -0.9236, -0.4300, -1.3015, -0.8899, -1.5931, -0.5611,\n",
       "                       -0.2354,  0.1681, -0.6901, -0.1235, -0.6812, -0.5706, -0.0539, -0.2259,\n",
       "                       -0.7704, -0.1603, -0.9158, -1.2511, -1.1759, -0.4254, -1.5772,  0.0548,\n",
       "                       -0.3023, -0.2560, -0.9098,  0.1258, -0.8445,  0.2932, -0.5789, -1.4806,\n",
       "                       -0.7398, -0.6939, -0.2297, -0.3205, -1.0558, -0.5916, -0.7359, -0.6250,\n",
       "                        0.0800, -0.9542, -0.1950, -0.3094, -0.5269, -0.8853, -0.4104, -0.0767,\n",
       "                       -0.9139, -0.6508, -0.2267, -0.5620, -0.0352, -0.6384,  0.3548, -0.7505,\n",
       "                       -0.5176, -0.8099, -0.5966, -0.7521, -1.1145, -0.2763, -0.7157, -0.2710,\n",
       "                       -0.5462, -0.9088, -0.2783, -0.7310,  0.0219, -0.8976, -0.0224, -1.1168],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.running_mean',\n",
       "               tensor([-2.4131, -0.8904, -4.9010, -1.7769, -2.2053, -2.7407, -1.1921, -3.0030,\n",
       "                       -0.4156, -0.3795, -2.3029, -1.2883, -0.4116, -0.1081, -3.7642, -1.0190,\n",
       "                       -2.0777, -3.3611, -0.0486, -3.1341, -2.4077, -1.1157, -0.8847, -2.7711,\n",
       "                       -1.7424, -3.3486,  2.1937, -2.5235, -1.8268, -2.8369,  0.6379, -2.1238,\n",
       "                       -3.7224, -0.4414, -1.3879, -3.3340, -3.3817,  0.3282, -2.7800, -1.5432,\n",
       "                       -2.6469, -1.0276, -3.0478, -2.0544, -3.2316, -2.2868, -1.4719, -1.4437,\n",
       "                       -1.1511, -3.5797, -2.7565, -2.2685, -1.4782, -2.8771, -2.0487, -1.7757,\n",
       "                       -0.8824, -1.3743, -1.8331, -1.9949, -0.8457, -2.1034, -0.5533, -1.3504,\n",
       "                       -1.4081, -2.1844, -1.0006, -2.2973, -2.6539, -2.2386, -1.4796, -1.1708,\n",
       "                       -2.5862, -0.4609, -3.5191, -1.9588, -0.6882, -1.3655, -1.3016, -1.3824,\n",
       "                       -1.6750, -0.4051, -1.0312, -2.7010, -2.5754, -1.1560, -0.3630,  0.7148,\n",
       "                       -1.6863, -2.2299, -0.1336, -2.4699, -2.1001, -1.5359, -1.5326,  0.7923,\n",
       "                       -1.0251,  0.2001, -2.3583, -1.4120, -0.1170, -1.8230, -2.2582,  1.4584,\n",
       "                       -3.3188, -0.8856,  0.3503, -1.2154, -2.1023, -1.5781, -3.0069, -1.1046,\n",
       "                       -1.3731, -1.0934,  1.5682, -2.0638, -0.9050, -3.8840, -1.0200, -1.9753,\n",
       "                       -4.2705, -4.1954, -3.8186, -2.5487, -0.3516, -1.8321, -2.5454, -1.9434],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.running_var',\n",
       "               tensor([ 0.9786,  1.5125,  9.5856,  1.8743,  8.2790,  4.4735,  7.8640, 10.5432,\n",
       "                        1.2490,  2.9350,  6.8486,  6.3948,  3.2540,  1.1393,  9.0964,  1.5334,\n",
       "                        8.2834,  4.2068,  0.9122,  3.0292,  8.1301,  1.0579,  6.6738,  4.5364,\n",
       "                        2.0355,  4.1773,  1.8325,  4.3999,  4.2481,  6.3098,  2.5068,  9.3283,\n",
       "                        6.4492,  3.0384,  1.8923,  5.8473,  3.0599,  0.8678,  2.7243,  5.1903,\n",
       "                        4.7960,  4.2547,  2.5376,  2.5142,  2.3388,  3.6344,  1.5592,  2.2303,\n",
       "                        4.9886,  6.1556,  2.0378,  2.1848,  3.8695,  7.8191,  6.6059,  3.8878,\n",
       "                        3.6203,  4.7165,  1.8168,  2.2955,  1.4972,  2.4463,  2.0767,  7.1414,\n",
       "                        3.5790,  7.7162,  1.4699, 15.7467,  2.9050,  5.4722,  4.5844,  3.5854,\n",
       "                        3.4569,  4.2376,  4.6873,  0.7987,  1.1326,  3.8485,  1.5644,  3.9909,\n",
       "                        5.1989,  2.9923,  1.4127,  3.8168,  3.5553,  3.1785,  3.8540,  0.9011,\n",
       "                        1.4663,  3.4107,  2.3478,  3.1561,  2.1672,  5.4370,  3.1052,  1.8797,\n",
       "                        5.6606,  1.1486,  5.1894,  4.4640,  2.9727,  1.8161,  7.0791,  5.8385,\n",
       "                        4.8354,  2.8537,  2.3023,  5.0950,  3.7036,  3.9769, 11.8580,  1.1699,\n",
       "                        6.9196,  2.8060,  3.8003,  5.5325,  1.3808,  5.8572,  1.1803,  5.3702,\n",
       "                        8.7443,  8.8479,  5.3295,  4.1233,  6.9519,  8.7936,  5.9418,  1.0971],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block2.bn2.weight',\n",
       "               tensor([1.3141, 0.9743, 0.9400, 0.9704, 1.1382, 1.0515, 0.7056, 0.8917, 1.2728,\n",
       "                       0.8739, 0.8869, 1.0483, 0.6003, 0.7180, 0.9838, 0.9419, 1.2941, 1.2745,\n",
       "                       1.1587, 1.3949, 0.7573, 0.7964, 1.2028, 1.1286, 0.5101, 1.5309, 1.7043,\n",
       "                       1.0253, 1.2643, 1.5136, 0.9687, 1.1254, 0.9008, 1.0613, 1.2545, 1.9371,\n",
       "                       1.0074, 1.1867, 0.6400, 0.8690, 1.2913, 1.1891, 1.5210, 1.2264, 1.1337,\n",
       "                       1.5098, 0.7860, 1.1929, 0.9391, 1.0299, 0.8509, 1.0739, 1.1180, 1.0300,\n",
       "                       1.1998, 0.9821, 0.9817, 1.3478, 0.9603, 0.9633, 0.6857, 0.6026, 0.7475,\n",
       "                       0.7358, 0.7933, 0.9335, 0.9808, 1.0397, 0.8151, 0.7391, 0.6320, 1.2441,\n",
       "                       1.0984, 1.2876, 0.8579, 1.6905, 0.7509, 0.7957, 0.7060, 1.0145, 0.9281,\n",
       "                       0.8951, 1.7811, 1.0739, 1.3654, 1.0729, 0.7540, 0.7065, 1.2138, 1.0745,\n",
       "                       0.9565, 0.9216, 1.0931, 0.6989, 1.1158, 0.9414, 0.7919, 1.2018, 1.0087,\n",
       "                       1.4503, 0.6382, 0.8017, 0.9373, 1.1921, 1.0555, 1.2000, 1.3124, 1.1891,\n",
       "                       0.8393, 1.0704, 0.7054, 1.2592, 0.7358, 0.9641, 1.1372, 0.8094, 1.0117,\n",
       "                       1.2514, 1.1951, 1.0004, 0.8262, 0.7046, 0.8043, 1.1598, 0.6865, 1.4700,\n",
       "                       0.8981, 0.9085], device='cuda:0')),\n",
       "              ('conv_block2.bn2.bias',\n",
       "               tensor([-1.3503, -0.4413, -0.6789, -0.9455, -1.0849, -0.4448, -0.5752, -0.7186,\n",
       "                       -0.8108, -0.2051, -0.4654, -0.7822, -0.4704, -0.3479, -0.7247, -0.6463,\n",
       "                       -1.1507, -0.8867, -0.7556, -0.8274, -0.4405, -0.4568, -0.9801, -0.6102,\n",
       "                       -1.2241, -1.2244, -1.5618, -0.8782, -0.5003, -0.9520, -0.5820, -1.1252,\n",
       "                       -0.9082, -0.9316, -1.0885, -1.7258, -0.9305, -0.9675, -0.2319, -0.6314,\n",
       "                       -0.8341, -1.1461, -0.9772, -0.9146, -0.7383, -1.1380, -0.6114, -0.9168,\n",
       "                       -1.1098, -0.8108, -0.2102, -0.8518, -0.5361, -0.4911, -0.9719, -0.7816,\n",
       "                       -0.7263, -1.1259, -0.3177, -0.4689, -0.2683, -0.5677, -0.5023, -0.3059,\n",
       "                       -0.5004, -0.7979, -0.7226, -0.8363, -0.3814, -0.5096, -2.4209, -1.0990,\n",
       "                       -0.7452, -1.0950, -0.4069, -1.6483, -0.4548, -0.4833, -0.4344, -0.7627,\n",
       "                       -0.5733, -0.4171, -1.7487, -1.0344, -0.9407, -0.8883, -0.0773, -0.2880,\n",
       "                       -1.0581, -0.7470, -0.6575, -0.5272, -0.7539, -0.3000, -0.6706, -0.6163,\n",
       "                       -0.3594, -0.7435, -2.1373, -1.4771, -0.2047, -0.3021, -0.4441, -0.8505,\n",
       "                       -0.7633, -1.0400, -0.6749, -0.8543, -0.2337, -0.7890, -0.1617, -0.7715,\n",
       "                       -0.4618, -0.8388, -0.8737, -0.8112, -0.6466, -0.8895, -0.7215, -0.9477,\n",
       "                       -0.6900, -0.5412, -0.4516, -1.3314, -0.2638, -1.1401, -0.6788, -0.7952],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn2.running_mean',\n",
       "               tensor([ -7.3961,  -4.5891,  -5.8213,  -1.0133,  -2.2580,  -1.8642,  -3.5694,\n",
       "                        -6.0996,  -5.6499,  -2.5031,  -5.9163,  -2.2057,  -0.3819,  -1.8356,\n",
       "                        -4.1744,  -2.8422, -10.6328,  -5.2309,  -5.7686,  -2.5634,  -3.7643,\n",
       "                        -3.3726,  -4.8321,  -2.0769,   0.1582,  -3.8061,  -2.4051,  -3.5277,\n",
       "                        -3.9691,  -9.3103,  -8.0612,  -8.9360,  -1.8765,  -2.2820,  -5.7356,\n",
       "                        -4.4611,  -4.0259,  -2.2542,  -3.3550,  -6.5327,  -2.8121,  -2.8097,\n",
       "                        -6.0242,  -4.6169,  -6.0128,  -5.0973,  -3.0608,  -5.6782,   3.8616,\n",
       "                        -6.4063,  -3.3098,  -3.8689,  -7.3669,  -8.6131,  -3.6852,  -1.7822,\n",
       "                        -0.8158,  -2.0991,  -3.4854,  -6.3265,  -0.7037,  -1.9551,  -3.9395,\n",
       "                        -8.3529,  -6.3534,  -5.0519,  -9.2046,  -5.9804,  -3.8782,  -6.5263,\n",
       "                        -5.4163,  -5.5368,  -4.0463,  -3.8354,  -5.0896,  -6.0110,  -7.0405,\n",
       "                        -3.0010,  -6.2386,  -4.0346,  -0.3754,  -7.8277,  -6.0818,  -7.8651,\n",
       "                        -6.4240,  -4.4329,  -5.6176, -10.5690,  -4.8338,  -7.8223,  -8.5971,\n",
       "                        -4.2706,  -1.2760,  -3.1160,  -5.2439,  -6.0792,  -2.8554,  -4.7671,\n",
       "                       -10.1972,  -5.3260,  -1.2649,  -6.3484,  -3.9511,  -3.6146,  -3.9128,\n",
       "                        -2.9004,  -4.7150,  -3.9410,  -6.3880,  -4.4866,  -2.6650,  -6.4564,\n",
       "                        -1.9117,  -7.6207,  -2.6397,  -1.2198,  -6.7517,  -3.4818,  -6.2508,\n",
       "                        -5.4821,  -5.1062,   0.5175,  -5.7855,  -2.5263,  -1.4931,  -2.2290,\n",
       "                        -8.5932,  -7.5575], device='cuda:0')),\n",
       "              ('conv_block2.bn2.running_var',\n",
       "               tensor([39.4738, 50.2512, 22.0735, 19.9018, 19.8698, 20.9728,  7.8593, 25.9285,\n",
       "                       26.7521, 35.7524, 28.5406, 15.7397, 21.2985, 16.1114, 29.1470, 16.3477,\n",
       "                       46.2311, 21.5170, 24.7272, 21.8895, 30.1096, 32.5887, 24.2733, 34.2261,\n",
       "                        2.8262, 31.3546, 27.2281, 20.9851, 38.9086, 58.9054, 41.3042, 36.1662,\n",
       "                       18.2157, 18.5176, 14.1306, 34.1359, 18.4572, 34.3251, 31.8396, 19.9072,\n",
       "                       38.5039, 25.1795, 49.3835, 22.4839, 21.6583, 44.9227, 16.7198, 26.6548,\n",
       "                       14.7740, 30.8616, 37.0285, 14.4538, 35.8281, 49.5567, 20.6141, 18.0857,\n",
       "                       14.2632, 17.1822, 18.9241, 24.8222, 26.1890, 18.4515, 18.8614, 24.9102,\n",
       "                       25.8328, 20.0000, 19.6624, 20.5221, 10.0361, 25.1925,  6.1014, 29.3661,\n",
       "                       23.9723, 16.6776, 31.6900, 38.0337, 37.4205, 19.9710, 23.4294, 23.7631,\n",
       "                       14.4114, 42.7463, 21.7828, 29.3276, 22.0355, 30.7823, 27.8870, 50.3067,\n",
       "                       46.6016, 24.0858, 23.1349, 26.0429, 17.0057, 16.8542, 30.9906, 31.5861,\n",
       "                       24.1196, 21.7915, 22.6303, 24.3610, 26.3884, 19.4191, 31.9319, 17.5472,\n",
       "                       32.2729, 14.9530, 39.7351, 40.5044, 42.4207, 27.4097, 28.9811, 23.9798,\n",
       "                       19.2014, 29.4878, 21.0382, 19.4690, 35.1844, 46.0242, 28.0500, 18.4765,\n",
       "                       14.6201, 15.6444, 29.0666, 13.7840, 45.7339, 16.2414, 32.2088, 29.5621],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block3.conv1.weight',\n",
       "               tensor([[[[ 0.1918,  0.2914,  0.2449],\n",
       "                         [ 0.1409,  0.4522,  0.5067],\n",
       "                         [-0.0884,  0.0737,  0.0301]],\n",
       "               \n",
       "                        [[ 0.1019,  0.0240,  0.1687],\n",
       "                         [ 0.1553,  0.1560,  0.1272],\n",
       "                         [ 0.3152,  0.1944,  0.5959]],\n",
       "               \n",
       "                        [[-0.0959,  0.0195, -0.0181],\n",
       "                         [ 0.1306,  0.3360,  0.2106],\n",
       "                         [ 0.0172,  0.2755,  0.1774]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0589, -0.0836, -0.0707],\n",
       "                         [-0.0466, -0.0364, -0.0165],\n",
       "                         [-0.1360, -0.1182, -0.2067]],\n",
       "               \n",
       "                        [[ 0.1215, -0.0398,  0.0103],\n",
       "                         [ 0.2076,  0.1056,  0.0358],\n",
       "                         [ 0.2488,  0.1140,  0.0059]],\n",
       "               \n",
       "                        [[-0.1999,  0.1547, -0.0563],\n",
       "                         [ 0.0262,  0.1187,  0.0150],\n",
       "                         [-0.0092,  0.0139, -0.0758]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2419,  0.0038,  0.0491],\n",
       "                         [ 0.1142,  0.1323,  0.0855],\n",
       "                         [ 0.0182,  0.1687,  0.1369]],\n",
       "               \n",
       "                        [[ 0.0632, -0.0132, -0.2317],\n",
       "                         [-0.0641,  0.1044, -0.1256],\n",
       "                         [-0.2285, -0.0290, -0.1301]],\n",
       "               \n",
       "                        [[ 0.1610,  0.1163, -0.5981],\n",
       "                         [-0.1550,  0.0303, -0.5493],\n",
       "                         [-0.0474,  0.0092, -0.9042]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0083,  0.0083,  0.0075],\n",
       "                         [ 0.0145,  0.0950,  0.0511],\n",
       "                         [ 0.0830,  0.1164,  0.0494]],\n",
       "               \n",
       "                        [[ 0.2263,  0.1090,  0.0101],\n",
       "                         [ 0.1972,  0.0947,  0.0223],\n",
       "                         [ 0.2290,  0.0657,  0.0559]],\n",
       "               \n",
       "                        [[ 0.0564,  0.0782, -0.1155],\n",
       "                         [-0.0289,  0.0121, -0.1669],\n",
       "                         [-0.1572, -0.0734, -0.2753]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1550,  0.0760, -0.0711],\n",
       "                         [ 0.0081,  0.0031,  0.2342],\n",
       "                         [-0.0559, -0.0469,  0.0951]],\n",
       "               \n",
       "                        [[-0.2200, -0.1018,  0.0902],\n",
       "                         [-0.0272, -0.0195, -0.0870],\n",
       "                         [-0.0746,  0.0177, -0.0156]],\n",
       "               \n",
       "                        [[ 0.1937,  0.1846, -0.1088],\n",
       "                         [-0.0464, -0.0803, -0.1807],\n",
       "                         [-0.2460, -0.4201, -0.2906]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.2961,  0.0428,  0.0576],\n",
       "                         [-0.0060, -0.0896, -0.0119],\n",
       "                         [-0.0070, -0.1107, -0.0374]],\n",
       "               \n",
       "                        [[ 0.0958, -0.1339, -0.5265],\n",
       "                         [ 0.2807, -0.0662, -0.3240],\n",
       "                         [ 0.1958, -0.0395,  0.0079]],\n",
       "               \n",
       "                        [[-0.1234, -0.1167,  0.0425],\n",
       "                         [-0.1760, -0.0356,  0.1057],\n",
       "                         [ 0.0918,  0.0630,  0.0935]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1052,  0.0447, -0.0383],\n",
       "                         [ 0.3132, -0.0677,  0.2181],\n",
       "                         [ 0.3347,  0.1222,  0.1651]],\n",
       "               \n",
       "                        [[-0.1390, -0.1263, -0.2003],\n",
       "                         [ 0.0697,  0.2888,  0.1418],\n",
       "                         [-0.1250,  0.1076, -0.2513]],\n",
       "               \n",
       "                        [[ 0.1868,  0.4712, -0.2973],\n",
       "                         [ 0.4597,  0.3130,  0.0224],\n",
       "                         [ 0.6202,  0.3876,  0.2023]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1832, -0.2164, -0.1429],\n",
       "                         [-1.0208, -0.7868, -0.6915],\n",
       "                         [ 0.0429, -0.0640,  0.0734]],\n",
       "               \n",
       "                        [[ 0.3000, -0.1256, -0.1552],\n",
       "                         [ 0.3883,  0.0413, -0.0672],\n",
       "                         [-0.0734, -0.2630, -0.1852]],\n",
       "               \n",
       "                        [[-0.0130, -0.1501, -0.0803],\n",
       "                         [-0.0735, -0.1439, -0.1835],\n",
       "                         [-0.0352, -0.1001, -0.0571]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1292, -0.0475, -0.2751],\n",
       "                         [-0.0806, -0.0832, -0.1058],\n",
       "                         [-0.2897, -0.2348, -0.2851]],\n",
       "               \n",
       "                        [[ 0.3081, -0.0171,  0.0433],\n",
       "                         [ 0.3938, -0.0264,  0.0846],\n",
       "                         [-0.0721, -0.1088,  0.0143]],\n",
       "               \n",
       "                        [[-0.2201, -0.1279,  0.0128],\n",
       "                         [-0.0203, -0.0936,  0.2572],\n",
       "                         [-0.0513,  0.0027,  0.2839]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1582,  0.0710, -0.0582],\n",
       "                         [-0.1213,  0.0654,  0.0037],\n",
       "                         [-0.0399,  0.0586, -0.0409]],\n",
       "               \n",
       "                        [[ 0.1604, -0.0942, -0.0826],\n",
       "                         [ 0.0975,  0.0810,  0.0280],\n",
       "                         [ 0.1393,  0.1117,  0.0537]],\n",
       "               \n",
       "                        [[-0.0604, -0.2456, -0.2025],\n",
       "                         [ 0.0392, -0.1012, -0.0784],\n",
       "                         [-0.0073, -0.2827, -0.0562]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0430,  0.2113,  0.5149],\n",
       "                         [-0.0677,  0.0607,  0.4389],\n",
       "                         [-0.2325, -0.0065,  0.1742]],\n",
       "               \n",
       "                        [[-0.3542, -0.1437,  0.3854],\n",
       "                         [-0.2052, -0.2274,  0.2500],\n",
       "                         [-0.4057, -0.3395, -0.0143]],\n",
       "               \n",
       "                        [[-0.1930, -0.0256, -0.0375],\n",
       "                         [ 0.0103, -0.0207, -0.0794],\n",
       "                         [ 0.3867,  0.2394,  0.1966]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.1049,  0.0724, -0.0165],\n",
       "                         [ 0.0512,  0.0242, -0.0029],\n",
       "                         [ 0.0762,  0.0376,  0.0533]],\n",
       "               \n",
       "                        [[-0.0143,  0.0353,  0.0516],\n",
       "                         [-0.0515,  0.0574,  0.0636],\n",
       "                         [ 0.1108,  0.1316,  0.1324]],\n",
       "               \n",
       "                        [[ 0.2118, -0.2252,  0.0978],\n",
       "                         [ 0.4146, -0.1564,  0.0487],\n",
       "                         [ 0.1328, -0.3897, -0.1263]]]], device='cuda:0')),\n",
       "              ('conv_block3.conv2.weight',\n",
       "               tensor([[[[ 1.3757e-01,  4.3896e-02,  7.7711e-02],\n",
       "                         [ 3.9155e-02, -1.6810e-02, -5.3194e-03],\n",
       "                         [-7.1487e-02, -8.9337e-02, -9.6639e-02]],\n",
       "               \n",
       "                        [[ 1.0051e-01,  5.4529e-02,  2.5286e-01],\n",
       "                         [ 2.2643e-01,  1.0918e-01,  2.1707e-01],\n",
       "                         [ 2.2286e-01,  1.7694e-01,  1.8261e-01]],\n",
       "               \n",
       "                        [[ 1.0463e-01,  4.7260e-02,  1.4341e-01],\n",
       "                         [ 6.8646e-03,  3.5136e-02, -1.8568e-01],\n",
       "                         [ 1.4691e-02,  2.7523e-02, -8.4363e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.6073e-02, -1.0391e-01, -5.4284e-01],\n",
       "                         [-1.1898e-01, -1.1015e-01, -2.7668e-01],\n",
       "                         [-1.6836e-01, -1.7446e-01, -4.8569e-01]],\n",
       "               \n",
       "                        [[-2.9016e-01, -1.0900e-01, -5.3641e-02],\n",
       "                         [-2.6679e-01, -1.2469e-01, -1.4308e-01],\n",
       "                         [-1.3673e-01, -1.5387e-02,  1.9499e-02]],\n",
       "               \n",
       "                        [[-3.0667e-02, -2.2987e-01, -2.8192e-01],\n",
       "                         [-1.4152e-01, -1.1759e-01, -1.8855e-01],\n",
       "                         [-1.6718e-01, -2.3168e-01, -2.6251e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8786e-01,  1.6873e-01,  1.3946e-01],\n",
       "                         [-1.7823e-01,  5.2950e-02,  1.0508e-01],\n",
       "                         [ 3.9748e-02,  1.1322e-01,  9.1565e-02]],\n",
       "               \n",
       "                        [[ 1.6513e-01,  7.0866e-02,  2.9959e-02],\n",
       "                         [ 1.8623e-01,  8.5402e-02,  1.0393e-01],\n",
       "                         [ 1.6429e-01,  6.0174e-02,  9.9975e-02]],\n",
       "               \n",
       "                        [[-2.9346e-02,  2.7225e-01,  4.5111e-03],\n",
       "                         [-1.6765e-01,  8.2408e-02, -6.9969e-02],\n",
       "                         [-3.3864e-01, -3.1999e-01, -4.8076e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 8.7067e-02,  3.7755e-02,  1.4875e-01],\n",
       "                         [ 1.3623e-01,  5.7685e-02,  1.2049e-01],\n",
       "                         [-4.3463e-02,  8.5667e-02,  2.6807e-01]],\n",
       "               \n",
       "                        [[ 3.3094e-02, -3.1364e-02, -9.8045e-02],\n",
       "                         [ 5.5394e-02,  1.4516e-01,  4.4614e-02],\n",
       "                         [ 1.2437e-01,  6.7197e-02,  2.6299e-01]],\n",
       "               \n",
       "                        [[ 1.3716e-02,  2.9617e-02, -8.5375e-03],\n",
       "                         [-5.4299e-02, -9.0567e-03, -3.2639e-02],\n",
       "                         [-3.9753e-02, -3.7975e-02,  1.0959e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2729e-02,  1.2983e-02, -1.1082e-03],\n",
       "                         [-1.0104e-02, -2.4775e-03, -1.8996e-03],\n",
       "                         [-6.1798e-02, -5.7441e-02, -7.8250e-02]],\n",
       "               \n",
       "                        [[-1.8100e-02, -8.1336e-02,  8.5607e-03],\n",
       "                         [ 2.4292e-02,  3.0190e-03,  6.1094e-03],\n",
       "                         [ 5.0470e-02, -2.3951e-03,  3.9983e-02]],\n",
       "               \n",
       "                        [[-1.2726e-02, -9.6699e-02, -1.3851e-01],\n",
       "                         [-2.9790e-02, -8.6112e-02, -1.5020e-01],\n",
       "                         [-7.4393e-02, -9.5068e-02, -1.3827e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.0869e-02, -7.1531e-02, -3.1412e-03],\n",
       "                         [-2.2586e-02, -4.4022e-03, -1.1555e-02],\n",
       "                         [-3.3323e-02, -7.2141e-02, -3.3744e-02]],\n",
       "               \n",
       "                        [[ 3.9286e-02,  2.1935e-02, -1.1812e-02],\n",
       "                         [ 8.7210e-02,  4.9117e-02,  3.8273e-02],\n",
       "                         [ 7.9813e-03,  2.1938e-02, -2.2139e-02]],\n",
       "               \n",
       "                        [[-1.0034e-01, -6.9140e-02, -9.8685e-02],\n",
       "                         [ 7.6026e-03,  5.4144e-04, -2.7368e-02],\n",
       "                         [ 2.0734e-02,  2.5915e-02, -4.8275e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-3.3179e-03, -1.0582e-01, -7.0599e-02],\n",
       "                         [ 3.1258e-02,  2.8049e-02,  2.0656e-03],\n",
       "                         [ 1.3279e-01,  4.2829e-02,  9.6902e-02]],\n",
       "               \n",
       "                        [[-2.8050e-01, -2.3010e-01, -2.8824e-01],\n",
       "                         [-3.2654e-02,  7.5081e-02, -1.0713e-01],\n",
       "                         [ 2.2023e-01,  1.2251e-01, -3.1004e-02]],\n",
       "               \n",
       "                        [[-2.2567e-02, -1.0412e-01, -2.9561e-01],\n",
       "                         [-6.5547e-02, -1.8374e-01, -2.1960e-01],\n",
       "                         [ 4.5878e-02, -5.6491e-02, -1.8567e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2591e-01, -2.1784e-02, -4.0365e-02],\n",
       "                         [-5.7017e-02,  8.3478e-02, -3.8980e-02],\n",
       "                         [ 7.2135e-02,  1.7239e-01,  1.7608e-01]],\n",
       "               \n",
       "                        [[-3.4503e-01, -3.1989e-01, -3.2226e-01],\n",
       "                         [-1.6589e-01, -1.6011e-01, -1.2297e-01],\n",
       "                         [-7.5813e-02, -5.2137e-02, -5.5259e-02]],\n",
       "               \n",
       "                        [[-1.4890e-01,  1.2244e-02,  3.4804e-03],\n",
       "                         [ 9.9097e-02,  1.0039e-01,  1.1039e-01],\n",
       "                         [ 2.7918e-01,  2.4813e-01,  2.0999e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2763e-02,  3.3710e-02,  9.8060e-02],\n",
       "                         [ 4.1523e-02,  1.0447e-01,  1.1888e-01],\n",
       "                         [ 9.0085e-02,  1.0030e-01,  1.2675e-01]],\n",
       "               \n",
       "                        [[-2.0796e-02,  1.4305e-01, -8.5851e-02],\n",
       "                         [ 9.9763e-02,  1.7328e-01,  1.0501e-01],\n",
       "                         [ 9.9091e-02,  1.1628e-01,  5.7350e-02]],\n",
       "               \n",
       "                        [[-1.8043e-01, -6.2085e-02, -4.5798e-02],\n",
       "                         [-8.4020e-02,  1.2727e-01,  9.6284e-02],\n",
       "                         [ 1.7993e-01,  1.3537e-01,  1.8061e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.6259e-02, -5.4515e-02,  1.0738e-01],\n",
       "                         [-1.6335e-01, -1.6188e-01, -4.7400e-02],\n",
       "                         [-4.4075e-01, -2.0570e-01, -2.3790e-01]],\n",
       "               \n",
       "                        [[ 6.3876e-02,  5.0798e-02,  3.0333e-02],\n",
       "                         [ 1.7889e-02,  1.8676e-02,  2.0114e-02],\n",
       "                         [ 3.7309e-03,  6.1642e-02,  1.0740e-01]],\n",
       "               \n",
       "                        [[ 7.5402e-02,  6.8505e-02,  1.2329e-02],\n",
       "                         [ 9.4484e-02,  1.3652e-01,  7.6856e-02],\n",
       "                         [ 2.4983e-01,  2.6860e-01,  1.3195e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.5039e-02,  3.9122e-02, -4.0369e-03],\n",
       "                         [-1.2478e-01, -5.6188e-02, -2.4111e-02],\n",
       "                         [-6.4421e-02, -1.1154e-02,  3.1546e-02]],\n",
       "               \n",
       "                        [[ 6.7863e-02, -1.7155e-02,  8.1381e-02],\n",
       "                         [-3.2866e-02, -1.4610e-01, -7.5981e-03],\n",
       "                         [-9.6189e-02, -1.5031e-01, -2.5742e-02]],\n",
       "               \n",
       "                        [[-6.0012e-02,  7.6986e-02,  5.3144e-01],\n",
       "                         [ 1.6253e-01,  2.6311e-02,  2.9028e-01],\n",
       "                         [ 2.8924e-01,  4.3638e-01,  9.5001e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.4443e-02,  8.4047e-02,  9.4683e-02],\n",
       "                         [ 7.5064e-02,  8.1519e-03,  9.3771e-02],\n",
       "                         [ 4.4937e-02,  1.1582e-02,  3.0661e-02]],\n",
       "               \n",
       "                        [[-4.2403e-02,  5.5279e-02,  7.3614e-02],\n",
       "                         [-1.4714e-01, -1.1489e-01, -1.1970e-01],\n",
       "                         [-2.2739e-01, -2.6858e-01, -2.7262e-01]],\n",
       "               \n",
       "                        [[ 5.3812e-02,  1.3348e-01,  9.6792e-02],\n",
       "                         [ 1.7793e-02,  9.1173e-02,  1.9585e-02],\n",
       "                         [ 7.9299e-03,  8.6664e-02,  1.0111e-02]]]], device='cuda:0')),\n",
       "              ('conv_block3.bn1.weight',\n",
       "               tensor([1.0210, 1.0682, 1.3787, 1.2665, 1.1524, 1.2183, 0.7760, 0.9235, 1.3536,\n",
       "                       1.1974, 1.3259, 1.0340, 0.7915, 1.4988, 1.3355, 1.0443, 1.5879, 1.0444,\n",
       "                       1.4216, 1.0978, 0.9139, 1.1532, 1.1720, 1.4551, 0.9114, 1.1548, 0.2007,\n",
       "                       0.9233, 0.9801, 1.4392, 1.2658, 1.2461, 1.2587, 0.9034, 1.2150, 0.9803,\n",
       "                       0.9793, 1.0596, 1.2942, 1.0567, 0.9321, 1.1342, 1.5601, 1.0315, 1.2391,\n",
       "                       1.0022, 0.9950, 1.2044, 1.0443, 1.0558, 1.0039, 1.3602, 1.1981, 1.2316,\n",
       "                       1.3122, 1.0064, 0.7829, 1.3809, 1.1030, 1.4282, 0.9289, 1.1313, 1.3792,\n",
       "                       0.9184, 1.0905, 1.0623, 1.2476, 1.4465, 1.1163, 1.2293, 1.0798, 1.3139,\n",
       "                       1.7250, 0.8172, 1.5012, 1.3231, 1.0144, 1.1767, 0.8729, 1.1869, 0.9012,\n",
       "                       1.0563, 0.7078, 1.3326, 1.0936, 1.0224, 1.3593, 0.9392, 1.0068, 0.9863,\n",
       "                       1.1849, 0.9958, 1.2248, 0.9927, 0.3141, 1.3952, 1.0526, 0.9720, 1.1495,\n",
       "                       1.1253, 0.9783, 1.0597, 1.0248, 1.4366, 1.3393, 1.2572, 0.9937, 1.1931,\n",
       "                       1.1437, 0.8957, 1.2098, 0.2566, 1.0649, 1.3017, 1.0800, 0.5224, 1.0450,\n",
       "                       1.1513, 1.1263, 0.8780, 1.3537, 1.1516, 1.5164, 1.1235, 0.9574, 0.9924,\n",
       "                       1.1335, 1.0409, 0.9817, 0.9195, 0.9063, 0.7173, 1.1560, 1.2215, 1.1700,\n",
       "                       1.4139, 1.2205, 0.9432, 1.0820, 1.4721, 1.3174, 1.0905, 1.2970, 0.8261,\n",
       "                       0.9812, 1.0475, 1.2826, 1.2452, 0.8185, 1.0462, 1.0750, 1.5156, 1.1132,\n",
       "                       1.3410, 1.1077, 1.1155, 1.2860, 0.9671, 0.5262, 1.1721, 0.9906, 1.1165,\n",
       "                       1.2943, 0.9292, 1.0349, 1.1765, 1.1188, 1.1820, 0.9491, 0.9734, 1.3175,\n",
       "                       1.2034, 1.2084, 0.9865, 1.2615, 0.8739, 0.7807, 1.1073, 0.7385, 0.9734,\n",
       "                       1.4519, 0.9854, 1.0787, 1.0790, 1.0758, 1.1872, 1.0594, 0.9354, 0.5785,\n",
       "                       1.2671, 0.6805, 1.1030, 1.2096, 1.1690, 0.8356, 0.8897, 1.0657, 1.2187,\n",
       "                       0.9070, 0.7119, 0.9653, 0.9849, 1.0520, 0.2849, 0.9442, 1.1167, 1.2524,\n",
       "                       1.0367, 1.4768, 1.2307, 1.2085, 0.8254, 1.2146, 1.1639, 0.2181, 1.2649,\n",
       "                       1.1123, 1.2077, 1.2347, 1.0788, 1.5626, 1.0067, 1.1525, 1.1592, 1.1814,\n",
       "                       1.2216, 1.1346, 0.6273, 1.3089, 1.5136, 1.1486, 0.7495, 1.3114, 0.9355,\n",
       "                       1.1059, 1.4022, 1.3204, 1.5235, 1.3346, 1.1735, 1.1633, 1.0751, 1.3056,\n",
       "                       1.0540, 1.0776, 0.9134, 0.7332, 1.1821, 0.9479, 0.8942, 1.1816, 1.1299,\n",
       "                       0.9147, 1.0555, 0.8702, 1.0005], device='cuda:0')),\n",
       "              ('conv_block3.bn1.bias',\n",
       "               tensor([-0.8982, -0.5593, -0.8299, -0.8870, -0.6938, -0.3829, -1.0505, -0.7719,\n",
       "                       -0.6779, -0.5489, -0.8549, -0.9675, -0.3858, -1.1915, -0.7939, -0.5287,\n",
       "                       -1.0818, -0.6826, -1.1990, -0.5504, -0.6985, -0.5265, -0.7031, -0.7221,\n",
       "                       -0.6240, -0.7923, -0.7477, -0.6211, -0.4847, -0.9305, -0.8672, -0.9640,\n",
       "                       -0.5970, -0.7963, -1.0095, -0.7041, -0.6201, -0.8272, -0.8642, -0.7149,\n",
       "                       -0.1486, -0.8913, -1.5533, -0.5700, -0.7954, -0.9663, -0.5202, -1.0395,\n",
       "                       -1.0383, -0.8046, -0.7002, -1.1470, -0.5868, -0.7367, -0.7754, -0.4929,\n",
       "                       -0.6644, -0.7077, -0.7026, -0.8174, -0.6611, -0.5234, -0.6234, -0.5961,\n",
       "                       -0.5143, -0.7454, -0.6751, -0.6286, -1.0052, -1.2545, -0.4291, -1.1618,\n",
       "                       -0.8726, -0.8077, -1.0296, -0.9257, -1.2397, -0.9032, -1.1586, -0.6834,\n",
       "                       -0.3203, -0.7832,  0.3590, -0.7680, -0.7617, -0.9250, -0.9485, -0.8702,\n",
       "                       -0.5869, -0.2732, -1.1147, -0.6329, -0.7087, -0.5849, -1.2142, -0.8736,\n",
       "                       -1.2073, -0.4033, -0.6485, -0.9067, -0.1779, -0.7485, -1.5761, -0.8470,\n",
       "                       -0.5936, -1.3240, -0.8528, -0.7504, -0.8944, -0.4018, -0.9139, -0.2481,\n",
       "                       -1.2777, -0.6512, -0.5649,  0.1888, -0.9627, -0.8056, -0.6371, -0.6132,\n",
       "                       -1.0691, -0.5870, -1.7209, -0.3129, -0.5256, -1.5523, -0.5553, -0.8495,\n",
       "                       -0.0422, -0.3014, -0.5068, -0.6025, -0.5146, -1.0281, -0.7575, -1.0009,\n",
       "                       -0.9620, -0.3392, -0.7340, -0.9131, -1.0636, -0.7621, -0.8121, -0.3924,\n",
       "                       -1.2843, -0.4223, -0.8621, -0.7582, -0.4664, -0.6746, -0.9525, -0.7069,\n",
       "                       -0.6494, -1.2329, -0.9510, -0.5987, -0.8122, -0.2585, -2.3511, -0.4336,\n",
       "                       -0.4982, -1.0574, -0.6793, -0.3944, -0.4837, -0.6630, -1.0718, -0.7356,\n",
       "                       -0.3307, -0.7226, -0.8178, -0.3179, -0.6890, -0.4605, -1.2686, -0.4719,\n",
       "                       -0.4427, -0.6833, -0.3259, -0.6951, -1.1053, -0.9664, -0.7898, -0.8774,\n",
       "                       -0.1740, -0.9885, -0.3770, -0.7380, -1.2202, -1.1224, -0.1347, -0.7182,\n",
       "                       -0.7212, -0.3407, -0.2000, -0.8056, -0.8408, -0.6210, -1.0593, -3.0333,\n",
       "                       -0.3586, -1.0164, -0.5091, -0.7474, -0.7502, -0.5594, -0.7063, -0.6198,\n",
       "                       -1.2757, -0.9516, -0.7334, -0.6935, -0.7772, -0.7707, -0.4082, -1.0337,\n",
       "                       -0.6719, -0.8486, -0.8674, -0.7073, -0.8083, -0.7788, -0.8789, -0.3953,\n",
       "                       -1.1115, -0.7206, -0.9332,  0.0890, -0.8098, -0.9703, -1.0459, -0.3908,\n",
       "                       -0.4484, -0.9225, -0.8505, -0.7879, -0.9284, -1.4579, -1.1448, -0.5124,\n",
       "                       -0.8017, -0.4046, -0.8617, -0.6982, -0.5067, -0.4861, -0.2880, -0.7619,\n",
       "                       -0.6610, -0.4801, -0.9662, -0.7079, -0.0607, -0.8820, -0.4338, -0.8083],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.running_mean',\n",
       "               tensor([-3.7360, -4.6233, -3.6557, -4.6322, -4.8712, -6.6473,  2.6305, -2.3720,\n",
       "                       -5.6320, -4.4953, -5.4183, -4.5167, -0.6653, -1.5994, -3.9121, -4.2781,\n",
       "                       -5.1403, -6.3913, -2.0675, -2.6454, -2.2475, -3.3489, -3.0543, -3.3195,\n",
       "                       -3.7124, -2.8566,  0.2100, -1.1776, -2.3026, -5.0968, -1.6714, -3.2174,\n",
       "                       -4.1996, -3.7995, -4.8007, -1.2997, -5.3567, -6.7394, -3.0238, -3.8048,\n",
       "                       -5.4116, -1.9124, -3.5887, -3.7645, -3.0835,  0.4196, -0.1750, -0.8241,\n",
       "                       -3.8663, -5.2823, -1.4541, -0.5725, -3.8569, -1.6381, -7.6170, -2.1444,\n",
       "                       -4.5620, -5.6154, -4.2468, -5.3433, -5.3010, -2.4488, -6.4545, -2.8165,\n",
       "                        0.4223, -3.1771, -4.7437, -3.0589, -3.0745, -5.9238, -3.7874, -2.2076,\n",
       "                       -3.5404,  0.2015, -1.2456, -3.9242,  0.0954, -3.9417,  2.5984, -3.5945,\n",
       "                       -5.9171, -6.4251, -2.2578, -7.8775, -4.0284, -1.5283, -4.6262, -4.2763,\n",
       "                       -3.8058, -3.8550,  1.3800, -4.1743, -2.1319, -3.8210,  0.2053, -6.9632,\n",
       "                        1.3226, -2.8647, -3.8293, -1.0065, -4.6257, -2.2867, -0.0156, -1.9057,\n",
       "                       -3.9294, -1.8285, -0.6933, -7.2701, -0.6164, -6.3500, -2.5230, -0.1673,\n",
       "                       -0.9316, -4.1876, -2.7565, -3.4657, -4.0930, -1.9206, -3.3713,  1.5430,\n",
       "                       -3.6946, -6.0348, -4.5280, -3.2375, -1.6931,  5.8075, -4.1949, -1.6370,\n",
       "                       -1.5397, -2.7168, -4.1562, -2.2200, -4.1181, -4.4697, -1.1916, -2.0798,\n",
       "                       -3.4317, -1.1386, -3.6220, -2.8417, -4.7057, -2.8248, -2.5854, -8.3990,\n",
       "                        5.7105, -3.2966, -4.7009, -3.6105, -1.5590, -3.8793, -4.2679, -4.7801,\n",
       "                       -3.7535, -1.4472, -1.8453, -3.9892, -3.5442, -4.9556,  0.1412, -5.7569,\n",
       "                       -2.0001, -2.6130, -3.2370, -3.9707, -3.0764, -7.3013, -3.8480, -2.5359,\n",
       "                       -0.9426, -2.6543, -2.9104, -2.9212, -2.5907, -3.6120, -8.9578, -5.6857,\n",
       "                       -0.9836, -5.1064, -5.8374, -5.6726, -4.7037,  0.2951, -4.0062, -3.3184,\n",
       "                       -2.3170, -4.5064, -6.1815, -0.9618,  0.3356,  1.5998, -6.5894, -3.6475,\n",
       "                       -1.6931, -4.1432, -2.0141, -4.7789, -0.4445, -3.1385, -0.5600, -1.2760,\n",
       "                       -5.1539,  0.3197, -2.1731,  0.3439, -0.0959, -4.5920, -3.5617, -1.3553,\n",
       "                       -4.1359, -2.9156, -3.2453,  0.2077, -2.4971, -4.5291,  0.4152, -5.2192,\n",
       "                       -4.4310, -4.0784, -3.5517, -2.5801, -3.5983,  1.2604, -2.5246, -2.3927,\n",
       "                       -3.4935, -2.9094, -2.1389, -1.9884, -3.0646, -8.0526, -1.8004, -0.2110,\n",
       "                       -2.6031,  2.8122, -1.1262, -3.0278, -4.2276, -5.0716, -3.3233, -3.3826,\n",
       "                       -5.1959, -0.9382, -2.2691, -0.8058, -2.6139, -5.5010, -5.3529, -1.8328,\n",
       "                       -3.7692, -0.9625, -3.4762, -3.4709, -3.0176, -3.5250, -4.4706, -1.3083],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.running_var',\n",
       "               tensor([ 6.1906, 10.7009, 24.1509, 10.8535, 20.8408, 33.6762,  5.2201,  9.7729,\n",
       "                       23.8067, 10.8420, 21.0792,  9.0527, 12.4375,  6.0220, 12.7975,  4.4165,\n",
       "                       19.1036, 15.9470,  6.0773,  5.3244,  5.8844, 15.2656, 13.7625, 17.2115,\n",
       "                        9.5323, 18.9623,  0.3134,  9.9714, 19.6615, 26.4770,  7.6843,  8.8536,\n",
       "                       19.2414, 11.6547, 12.2803, 10.6438, 12.2425, 16.1193, 18.3075, 13.7481,\n",
       "                       13.2419,  9.7243,  9.2443,  9.2479, 13.4569,  9.9631, 10.7243,  8.8279,\n",
       "                        9.7693,  7.5803,  3.7514,  7.1608, 17.4216,  5.2497, 14.5373,  5.3475,\n",
       "                       14.0407, 21.1500, 12.7579, 19.2692, 11.1483, 16.4439, 27.9443, 12.0953,\n",
       "                       11.8162, 16.3111, 16.5706, 20.7969,  6.6163, 11.7927, 11.9599,  6.9639,\n",
       "                       27.2784,  2.5325, 10.3721, 19.2093,  4.0294,  8.4838,  6.6247, 10.4096,\n",
       "                       14.7797, 14.9003, 15.6197, 22.0655,  6.7335,  4.0474, 13.0321,  4.2047,\n",
       "                       19.2052, 20.2889,  5.2874,  7.2998, 14.2664,  7.5100,  0.7746, 15.2723,\n",
       "                        2.8366, 10.4677,  9.4623, 10.7298, 16.2824, 14.4357,  8.2096,  7.2522,\n",
       "                        9.0731,  6.8159,  5.1362, 13.4172,  5.0952, 14.4018, 15.6126,  0.6714,\n",
       "                        5.5315,  9.3035,  9.0678, 10.5202,  8.3224,  7.0902, 10.3108, 14.5298,\n",
       "                       12.4740, 16.5915, 10.1835, 15.5011,  8.4438, 10.5427, 11.1548,  7.0762,\n",
       "                       11.7243,  7.0338, 14.6593,  7.7724, 11.6558, 15.6894, 10.9430, 10.4501,\n",
       "                        7.1322, 16.6671,  9.2184, 14.6290, 20.1197, 11.5443,  7.8513, 18.9911,\n",
       "                        4.9606, 12.3159, 28.1145, 11.0436,  9.8462, 14.1108,  6.0178, 29.4965,\n",
       "                       14.3037,  7.9433,  5.8518,  8.9415, 22.8256, 13.0112,  0.8590, 29.0803,\n",
       "                       15.0455,  6.8791, 29.8244, 16.2032, 26.9033, 13.4011,  7.0414, 14.9736,\n",
       "                       11.0406,  7.4606,  6.3046,  7.9925,  7.9554,  9.7872, 12.8046, 11.6541,\n",
       "                        3.6507,  9.7574, 16.0379, 10.1677, 17.7478,  4.3765, 11.2913, 11.3733,\n",
       "                       14.5081,  7.4594, 13.1381,  9.7234,  1.3204,  6.6638, 16.0777,  5.1876,\n",
       "                       14.0519, 19.1653, 14.3280,  9.4319,  8.8464,  7.8796,  2.3688,  1.8170,\n",
       "                       10.6819,  2.9820,  8.9859,  0.6444, 10.0688, 16.8911, 16.1451, 11.7682,\n",
       "                       10.2172, 14.2086,  7.7493, 10.2250,  7.0203, 14.0146,  0.5052, 16.7758,\n",
       "                        6.6086, 10.6471, 12.1595,  9.1270, 23.1104,  5.8590, 10.6717, 14.7882,\n",
       "                       10.8837,  7.7072,  8.7823, 14.0688, 11.8872, 14.3936,  9.7891, 13.1332,\n",
       "                       22.6213,  6.3628, 14.6721, 14.4389, 15.3946, 16.4688, 10.7773,  6.6466,\n",
       "                       21.1301, 10.7116,  6.1879,  8.1472,  7.0374, 16.1513, 11.5553,  6.8429,\n",
       "                       12.0741, 11.5021, 10.7611, 12.5017, 14.9984, 15.8575, 19.4742,  8.1398],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block3.bn2.weight',\n",
       "               tensor([0.9051, 0.9394, 0.3467, 1.0366, 1.0479, 1.1572, 1.6049, 1.1137, 0.9935,\n",
       "                       1.1752, 0.8874, 1.0937, 0.6876, 1.1102, 1.4864, 1.3248, 0.9897, 1.4706,\n",
       "                       1.4177, 0.2613, 1.1516, 0.9729, 1.2617, 0.2820, 1.0827, 0.2616, 1.4487,\n",
       "                       1.0664, 1.4253, 1.3209, 1.0332, 1.2626, 0.9325, 1.1220, 0.8981, 1.0424,\n",
       "                       0.9619, 1.2507, 1.3945, 1.1734, 0.9084, 0.8654, 1.2673, 1.0337, 1.0987,\n",
       "                       1.3766, 1.6624, 0.8357, 1.0707, 0.9537, 0.2633, 0.9885, 0.9755, 1.3231,\n",
       "                       1.2518, 1.4758, 1.3703, 1.1539, 1.1889, 1.1905, 1.4671, 1.0795, 0.8962,\n",
       "                       0.8735, 1.1473, 1.0061, 0.9262, 0.9056, 0.9279, 1.1607, 1.1400, 1.3418,\n",
       "                       0.2692, 1.0091, 1.3077, 0.5176, 0.9112, 0.9307, 1.0229, 0.8897, 1.0297,\n",
       "                       0.9391, 1.0971, 0.4626, 0.9116, 1.4098, 1.0808, 1.0182, 1.5772, 1.0186,\n",
       "                       1.0702, 0.9926, 1.3717, 0.9138, 1.1040, 1.0963, 0.8279, 1.0532, 1.3980,\n",
       "                       1.2943, 1.0913, 0.8435, 1.0859, 0.9802, 1.0216, 0.2935, 1.1645, 0.9617,\n",
       "                       1.4009, 1.1233, 0.9578, 0.6571, 1.0725, 0.7002, 1.0372, 1.1292, 1.2509,\n",
       "                       0.9716, 1.5299, 1.2976, 1.0172, 1.2507, 1.0353, 1.0831, 0.9625, 0.9419,\n",
       "                       1.1977, 1.0909, 1.2755, 0.8902, 1.2145, 1.3266, 0.8319, 0.9505, 0.9411,\n",
       "                       1.1432, 0.9254, 1.1651, 1.1642, 0.2505, 1.2972, 1.1613, 0.9954, 1.1288,\n",
       "                       1.1554, 1.1024, 1.4579, 0.8870, 1.1077, 1.3331, 1.1827, 1.0637, 0.9267,\n",
       "                       1.1762, 1.0574, 1.2458, 1.3292, 0.9216, 1.0776, 1.2446, 1.3153, 1.2265,\n",
       "                       1.1726, 1.0782, 0.2623, 0.8875, 0.2963, 1.2376, 1.4084, 1.0460, 1.2456,\n",
       "                       1.2219, 1.0095, 1.0642, 0.9782, 1.2341, 1.0097, 1.0705, 0.8490, 0.9098,\n",
       "                       1.0768, 1.0270, 1.1807, 1.2606, 1.3560, 1.4065, 1.1395, 1.1043, 1.0956,\n",
       "                       0.9400, 0.9232, 0.9482, 1.0033, 0.7078, 1.1307, 1.1774, 0.9191, 1.1546,\n",
       "                       0.9854, 0.8554, 1.0341, 0.8977, 0.8860, 0.9033, 1.0850, 1.0711, 1.1451,\n",
       "                       0.9898, 1.1208, 1.0563, 1.3754, 0.8993, 1.0484, 0.8753, 0.9922, 1.2163,\n",
       "                       1.0892, 1.1947, 0.7565, 0.9142, 1.3299, 0.9942, 1.0805, 1.3669, 0.8534,\n",
       "                       1.3016, 1.4345, 1.2004, 1.1323, 0.7956, 0.9888, 1.0292, 1.1574, 1.1866,\n",
       "                       1.1543, 1.0344, 1.4174, 0.3030, 1.4229, 1.2801, 0.2937, 0.9351, 0.9618,\n",
       "                       1.1582, 1.2652, 0.9315, 1.1234, 1.0876, 1.0357, 1.2522, 0.9250, 1.1716,\n",
       "                       1.2080, 1.2942, 1.3198, 1.2777], device='cuda:0')),\n",
       "              ('conv_block3.bn2.bias',\n",
       "               tensor([-0.6634, -0.5544, -0.0422, -0.6581, -0.8572, -0.9712, -1.6261, -0.5950,\n",
       "                       -0.7201, -1.2496, -0.5318, -0.7978, -0.1393, -0.6118, -1.3631, -1.3863,\n",
       "                       -0.6188, -1.2326, -1.6330, -0.1872, -0.8443, -0.7549, -1.2820, -0.0505,\n",
       "                       -1.1499, -0.0781, -1.2581, -1.0880, -1.3273, -1.2754, -0.6035, -0.7674,\n",
       "                       -0.4481, -1.0971, -0.9998, -0.6411, -0.5971, -1.3235, -1.3134, -0.8110,\n",
       "                       -0.5895, -0.6744, -0.8855, -1.1614, -1.0477, -1.3588, -1.3315, -0.6502,\n",
       "                       -1.0932, -0.7254, -0.3861, -0.5992, -1.0614, -1.1524, -1.2114, -1.0342,\n",
       "                       -1.3392, -0.7853, -0.7540, -0.9350, -1.7840, -0.9019, -0.7942, -0.5565,\n",
       "                       -1.1643, -0.6610, -0.6357, -0.4942, -0.7252, -1.0780, -0.9504, -1.2680,\n",
       "                       -0.0283, -0.9093, -1.0604,  0.0534, -0.5707, -0.8475, -0.7689, -0.7964,\n",
       "                       -1.0437, -0.7244, -0.6308, -0.0799, -0.6952, -1.1794, -0.9914, -0.9248,\n",
       "                       -1.2379, -0.8964, -1.0408, -0.6191, -1.2270, -0.5548, -0.9034, -1.1669,\n",
       "                       -0.6484, -0.8183, -1.1430, -1.5660, -0.9298, -0.2687, -0.6611, -0.5908,\n",
       "                       -0.7479, -0.0536, -1.2109, -0.8190, -1.3240, -0.9726, -0.5736, -0.2446,\n",
       "                       -0.9323, -0.2670, -0.8135, -0.9782, -1.0693, -0.8946, -1.2197, -1.2017,\n",
       "                       -0.8493, -1.0271, -0.7801, -0.9973, -0.5407, -0.5843, -0.8183, -0.9339,\n",
       "                       -1.1637, -0.6353, -0.8803, -1.1417, -0.6053, -0.5750, -0.9905, -1.1236,\n",
       "                       -0.7335, -0.7768, -1.1079, -0.0484, -1.5820, -1.2682, -0.9510, -0.8856,\n",
       "                       -1.1036, -1.2498, -1.1422, -0.8046, -0.9191, -1.1010, -0.9548, -0.9208,\n",
       "                       -0.7223, -0.7993, -0.9130, -0.6914, -1.4146, -0.8214, -0.7783, -0.7009,\n",
       "                       -1.1782, -0.8517, -0.7981, -1.0004, -0.0658, -0.6777,  0.1841, -0.9849,\n",
       "                       -1.3402, -0.8736, -0.5267, -0.7914, -0.9291, -1.1181, -0.5579, -0.9340,\n",
       "                       -1.1616, -1.0515, -0.6710, -0.8138, -0.8020, -0.6899, -1.1364, -1.0139,\n",
       "                       -0.7805, -1.3099, -0.3936, -0.8767, -0.4665, -0.8453, -0.6968, -0.5989,\n",
       "                       -0.8351, -0.6806, -0.9338, -1.0715, -0.7662, -1.4438, -0.6182, -0.7659,\n",
       "                       -1.0537, -0.5319, -0.5135, -0.9045, -0.5828, -0.8373, -0.9134, -0.7420,\n",
       "                       -1.1932, -0.9939, -0.7015, -0.5463, -1.0515, -0.5218, -0.5948, -0.8505,\n",
       "                       -1.0803, -0.9453, -0.5138, -0.3713, -1.3711, -0.6823, -0.7744, -1.3687,\n",
       "                       -0.5889, -0.9297, -1.4539, -0.9427, -0.8768, -0.5206, -1.0093, -0.6510,\n",
       "                       -0.8140, -1.1389, -1.1334, -0.8144, -1.4738,  0.0231, -1.1460, -1.0632,\n",
       "                       -0.0401, -0.7883, -0.5025, -0.6524, -1.0350, -0.7857, -0.7549, -0.8493,\n",
       "                       -0.7969, -0.8876, -0.9356, -0.6092, -1.0583, -1.3752, -1.4297, -1.2696],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn2.running_mean',\n",
       "               tensor([-3.4911e+00, -9.6107e+00, -5.3826e+00, -1.6101e+01, -5.5888e+00,\n",
       "                       -8.8130e+00, -9.5321e+00, -6.3366e+00, -8.2244e+00, -8.4098e+00,\n",
       "                       -3.3756e+00, -7.0694e+00, -4.1885e+00, -8.6844e+00, -7.0230e+00,\n",
       "                       -1.5198e+01, -1.1964e+01, -7.8929e+00, -3.9568e+00, -3.9354e+00,\n",
       "                       -1.1699e+01,  2.0371e+00, -9.2795e+00,  5.9330e-02, -5.3359e+00,\n",
       "                        1.4149e-02, -6.5833e+00, -4.7250e-01, -1.2001e+01, -5.9918e+00,\n",
       "                       -1.3095e+01, -6.4204e+00, -2.2617e+00, -1.1366e+01, -6.1231e+00,\n",
       "                       -9.6574e+00, -1.2655e+01, -3.6809e+00, -6.0819e+00, -2.5524e+00,\n",
       "                        4.1935e+00, -3.6395e+00, -4.0330e+00, -4.5607e+00, -5.9919e+00,\n",
       "                       -1.3055e+01, -4.4051e+00, -4.5932e+00, -7.9964e+00, -6.3563e+00,\n",
       "                        7.8042e-02, -8.5461e+00, -4.2503e+00, -7.0154e+00, -8.0652e+00,\n",
       "                       -7.5181e+00, -9.9843e+00, -1.2088e+01, -8.2631e+00, -1.6709e+01,\n",
       "                       -8.9786e+00, -3.2740e+00, -3.0352e+00, -5.7816e+00, -1.0367e+00,\n",
       "                       -9.6153e+00, -1.2270e+00, -6.9112e+00, -5.0506e+00, -1.1475e+01,\n",
       "                       -7.0857e+00, -9.1037e+00, -2.5610e-02, -6.9558e+00, -8.9153e+00,\n",
       "                       -1.1920e+00, -9.7330e+00, -1.3303e+01, -1.0187e+01, -3.5070e+00,\n",
       "                       -3.8751e+00, -6.2426e+00, -7.3738e+00, -7.2214e+00, -7.7449e+00,\n",
       "                       -1.9124e+00, -4.3638e+00, -2.4460e+00, -8.4248e+00, -7.2303e+00,\n",
       "                       -5.0449e+00, -6.1708e+00, -6.7142e+00, -8.7842e+00, -1.4931e+01,\n",
       "                       -8.3758e+00,  4.8030e+00, -1.2311e+01, -5.9956e+00, -2.1967e+00,\n",
       "                       -2.2356e+00, -3.7703e+00, -5.8839e+00, -1.1787e+01, -1.0484e+01,\n",
       "                        9.5356e-02, -6.3985e+00, -6.5360e+00, -9.0980e+00, -9.6880e+00,\n",
       "                       -1.0938e+01, -8.2971e+00, -8.1249e+00, -3.1658e+00, -3.9382e+00,\n",
       "                       -5.5435e+00, -1.3640e+01, -1.0127e+01, -5.9742e+00, -9.9183e+00,\n",
       "                       -5.7110e+00, -2.7085e+00, -3.4386e+00, -9.2171e+00, -7.6556e+00,\n",
       "                       -8.4008e+00, -7.3623e+00, -9.9678e+00, -6.5990e+00, -1.0719e+01,\n",
       "                       -8.8565e+00, -2.6989e+00, -8.4863e+00, -4.6265e+00, -1.0382e+01,\n",
       "                       -9.7883e+00, -1.2193e+01, -6.3949e+00, -4.8447e+00,  5.8276e-03,\n",
       "                       -6.2136e+00, -1.0262e+01, -8.1288e+00, -2.5930e+00, -1.1328e+01,\n",
       "                       -3.8169e+00, -5.9234e+00, -1.1199e+01, -7.7389e+00, -8.8508e+00,\n",
       "                       -9.2099e+00, -1.2340e+01, -7.9534e+00, -7.4613e+00, -3.8052e+00,\n",
       "                       -6.5691e+00, -9.9729e+00, -1.3705e+00, -5.1512e+00, -1.0458e+00,\n",
       "                       -4.5330e+00, -1.1094e+01, -9.7869e+00, -5.6063e+00,  7.8726e-02,\n",
       "                       -2.8889e+00, -1.3183e+00, -3.8979e+00, -8.7061e+00, -9.4747e+00,\n",
       "                       -7.4667e+00, -6.6214e+00, -1.0910e+01, -4.1701e+00, -4.1629e+00,\n",
       "                       -7.0732e+00, -6.9208e+00, -6.2487e+00, -5.0185e+00, -5.0112e+00,\n",
       "                       -1.0220e+01, -1.0323e+01, -6.2955e+00, -5.8233e+00, -1.1548e+01,\n",
       "                       -6.7834e+00, -4.5839e+00, -1.3402e+01, -4.6271e+00, -1.2829e+01,\n",
       "                       -6.7772e+00, -6.7742e+00, -8.2506e+00,  4.2465e-01, -1.3567e+01,\n",
       "                       -3.2647e+00, -6.7446e+00,  3.3160e-01, -6.1321e+00, -6.4997e+00,\n",
       "                       -8.8729e+00, -5.6220e+00, -3.4813e+00, -5.9370e+00, -1.0709e+01,\n",
       "                       -6.4628e+00, -1.1719e+01, -3.9484e+00,  3.1026e+00, -6.6003e+00,\n",
       "                       -9.4827e+00, -8.4693e+00, -9.2676e+00, -1.1096e+01, -5.9350e+00,\n",
       "                       -9.8378e+00,  2.6526e+00, -9.2605e+00, -3.1468e+00, -9.9574e+00,\n",
       "                        2.6649e+00, -1.0790e+01, -7.9090e+00, -1.0677e+01, -7.9327e+00,\n",
       "                       -7.8905e+00, -6.0571e+00, -7.4595e+00, -1.0302e+01, -1.7779e+00,\n",
       "                       -6.6011e+00, -4.6557e+00, -1.1171e+01, -6.7969e+00, -3.7002e+00,\n",
       "                       -1.0312e+01, -1.0197e+01,  2.4224e+00, -5.5731e+00, -6.1909e+00,\n",
       "                        2.6746e-02, -1.0855e+01, -1.0937e+01, -1.0483e+01, -6.3921e+00,\n",
       "                       -7.5746e+00, -2.4169e+00, -1.0476e+01, -7.3055e-01, -4.6117e+00,\n",
       "                       -7.9135e+00, -6.3495e+00, -5.4649e+00, -9.6260e+00, -6.5566e+00,\n",
       "                       -9.5391e+00], device='cuda:0')),\n",
       "              ('conv_block3.bn2.running_var',\n",
       "               tensor([32.6233, 51.5683, 12.6306, 65.5238, 32.6754, 44.7554, 64.5536, 27.7206,\n",
       "                       39.5589, 38.3092, 26.6532, 33.9899, 30.0790, 54.5678, 51.9654, 59.6498,\n",
       "                       30.5240, 46.6019, 27.9788,  6.7656, 67.2831, 29.2543, 63.4173,  4.0350,\n",
       "                       27.5978,  2.7838, 46.1793, 22.1832, 76.4300, 27.9449, 36.9475, 48.0723,\n",
       "                       45.7297, 53.8783, 28.5872, 56.5120, 47.0346, 60.6090, 60.9651, 25.6091,\n",
       "                       42.1833, 48.8448, 35.1397, 50.1726, 56.0075, 34.9519, 36.2864, 35.8140,\n",
       "                       37.3637, 29.9512,  2.6348, 26.1510, 42.6052, 53.2502, 25.8395, 35.5810,\n",
       "                       40.8477, 38.8935, 45.3449, 51.7833, 39.9969, 43.2109, 25.6505, 36.0094,\n",
       "                       33.2648, 62.1977, 39.1122, 57.3670, 33.4389, 38.1868, 52.7368, 54.3924,\n",
       "                        3.6088, 64.9561, 36.4023, 15.0502, 40.6238, 54.7768, 29.0203, 38.0345,\n",
       "                       65.5473, 53.0213, 29.6840, 11.6785, 36.9148, 31.7697, 59.0567, 56.0098,\n",
       "                       53.6699, 58.3168, 48.9750, 37.4606, 42.3741, 51.5572, 94.3404, 24.0388,\n",
       "                       25.0426, 38.1994, 50.9014, 22.3653, 39.0551, 24.0783, 40.2843, 49.7629,\n",
       "                       37.6483,  3.2578, 38.6164, 40.2132, 63.3210, 47.4026, 42.1460, 22.7260,\n",
       "                       44.6575, 34.8594, 43.7083, 44.9351, 45.3688, 48.0210, 33.4751, 45.1288,\n",
       "                       53.3950, 32.8214, 57.7978, 36.8290, 41.1461, 38.3068, 33.7378, 57.2282,\n",
       "                       33.2330, 48.1275, 42.6299, 27.8076, 46.1160, 46.7283, 42.1512, 28.0513,\n",
       "                       57.9283, 39.8380, 43.2196,  3.5073, 28.0107, 46.1415, 68.1599, 48.5282,\n",
       "                       56.3766, 35.8305, 39.1425, 44.9112, 59.0459, 36.1491, 35.4118, 41.4488,\n",
       "                       45.1702, 27.1920, 49.6938, 47.7060, 31.0848, 15.4609, 26.2254, 29.7920,\n",
       "                       23.0079, 73.6208, 41.7077, 37.2194,  2.4906, 26.4361,  8.6566, 37.1917,\n",
       "                       42.9030, 79.9636, 34.5892, 25.0802, 57.8477, 48.7814, 38.4691, 44.0872,\n",
       "                       38.7179, 67.8061, 36.7731, 20.4657, 46.1175, 40.5765, 36.2589, 49.1754,\n",
       "                       39.0490, 35.3677, 44.1855, 75.3239, 30.7163, 40.1691, 43.4779, 36.5468,\n",
       "                       39.9022, 23.8207, 47.7200, 35.6861, 49.6604, 36.0345, 42.3438, 26.6729,\n",
       "                       38.3238, 25.3345, 33.1475, 36.2977, 30.7630, 33.7805, 52.9490, 27.6904,\n",
       "                       37.3234, 65.8518, 69.2531, 35.1666, 37.9871, 40.7733, 24.8778, 32.4508,\n",
       "                       39.5215, 46.5822, 29.6104, 39.9276, 35.4048, 68.5465, 58.7924, 26.3959,\n",
       "                       44.8660, 41.4652, 37.1311, 36.3811, 38.8422, 38.1316, 46.0219, 37.1965,\n",
       "                       53.9513, 32.3594, 31.7732, 46.6417, 45.2628,  7.0563, 49.5439, 32.8643,\n",
       "                        3.0042, 29.8262, 41.4070, 42.1796, 28.3282, 47.5921, 33.2856, 51.8637,\n",
       "                       34.3875, 31.0627, 32.7539, 48.3618, 42.0343, 42.5362, 42.4494, 46.9895],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block4.conv1.weight',\n",
       "               tensor([[[[-2.8117e-01, -1.9448e-01, -3.2072e-01],\n",
       "                         [ 1.6667e-01,  7.5469e-03, -1.2761e-01],\n",
       "                         [ 1.5804e-01,  1.4452e-01,  5.4735e-03]],\n",
       "               \n",
       "                        [[ 5.7425e-03, -1.6190e-02, -4.9775e-01],\n",
       "                         [ 6.9577e-02,  3.7016e-02, -2.2179e-01],\n",
       "                         [-2.1399e-01, -1.8292e-01, -2.7259e-01]],\n",
       "               \n",
       "                        [[-3.2275e-02,  6.3697e-02,  3.6232e-02],\n",
       "                         [-1.0834e-02,  2.3389e-01, -1.6246e-02],\n",
       "                         [ 1.3494e-01,  1.3342e-01, -1.4910e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.0493e-01,  6.6150e-03,  9.4810e-02],\n",
       "                         [ 7.5323e-02, -8.4515e-02, -2.6031e-01],\n",
       "                         [-4.4923e-02,  1.3767e-01, -1.3903e-02]],\n",
       "               \n",
       "                        [[ 5.8768e-02,  3.0249e-03,  1.2129e-01],\n",
       "                         [-1.4058e-02, -1.4894e-02,  1.1285e-01],\n",
       "                         [ 7.8302e-02, -5.2702e-03,  1.2461e-01]],\n",
       "               \n",
       "                        [[-2.8437e-02, -1.5080e-01, -1.7280e-02],\n",
       "                         [ 2.3192e-01, -1.1718e-02, -4.4942e-02],\n",
       "                         [ 6.1271e-01,  2.4129e-01,  1.4843e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8397e-01,  1.0231e-01, -3.6553e-04],\n",
       "                         [ 3.4619e-01,  2.6139e-01,  2.4499e-01],\n",
       "                         [ 3.5390e-01,  2.8168e-01,  3.8342e-01]],\n",
       "               \n",
       "                        [[ 8.4976e-02,  2.6384e-01,  9.5468e-02],\n",
       "                         [-2.7714e-02, -2.2332e-02, -4.8102e-02],\n",
       "                         [-1.7257e-01,  6.8492e-02,  1.0205e-01]],\n",
       "               \n",
       "                        [[-2.5342e-02, -1.5528e-02, -6.1688e-02],\n",
       "                         [-2.7608e-02, -2.5081e-02, -6.0266e-02],\n",
       "                         [ 6.7514e-04, -1.2479e-03, -4.8764e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2393e-01, -9.4306e-02, -1.9476e-01],\n",
       "                         [ 5.8398e-03, -7.9925e-02, -4.1517e-01],\n",
       "                         [-5.0327e-02, -1.9655e-01, -1.1735e-01]],\n",
       "               \n",
       "                        [[ 2.7297e-01, -4.6044e-02,  2.8592e-02],\n",
       "                         [ 7.4112e-01, -5.0212e-02, -1.0976e-01],\n",
       "                         [ 6.0514e-01, -6.1636e-02,  1.5829e-01]],\n",
       "               \n",
       "                        [[-8.9858e-02, -1.4299e-01, -8.8171e-02],\n",
       "                         [-2.7729e-02, -5.3546e-02,  1.1596e-03],\n",
       "                         [ 1.9970e-01,  5.9318e-02,  1.9625e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.5145e-02, -7.8992e-02, -2.5136e-02],\n",
       "                         [-4.0007e-02, -3.4993e-02, -4.9632e-02],\n",
       "                         [ 2.2835e-02, -8.2773e-02, -1.4480e-01]],\n",
       "               \n",
       "                        [[ 8.8546e-02, -1.3631e-03,  7.4954e-05],\n",
       "                         [ 2.7300e-02, -2.4629e-02, -6.8863e-02],\n",
       "                         [ 9.9173e-02,  2.9239e-02, -1.0297e-02]],\n",
       "               \n",
       "                        [[ 1.6983e-02,  3.6542e-03, -6.4787e-02],\n",
       "                         [ 9.0322e-02,  2.4170e-02, -5.2050e-02],\n",
       "                         [ 6.6579e-02,  4.9823e-02, -2.5309e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.4695e-02,  4.1721e-02, -5.1636e-02],\n",
       "                         [-6.5091e-02, -4.3530e-02, -1.4238e-01],\n",
       "                         [-5.6960e-02, -3.9052e-02, -1.4414e-01]],\n",
       "               \n",
       "                        [[ 1.1531e-02,  5.8840e-02,  4.7447e-02],\n",
       "                         [ 6.2048e-02,  1.1637e-01,  5.8397e-02],\n",
       "                         [ 5.2231e-03, -4.5418e-03, -3.0628e-02]],\n",
       "               \n",
       "                        [[ 5.5873e-03,  3.9302e-02, -1.9303e-02],\n",
       "                         [-8.0556e-02,  4.2154e-03, -8.2461e-02],\n",
       "                         [-1.3790e-01, -1.9746e-02, -1.8784e-01]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-1.5198e-01, -3.6075e-02, -1.4837e-01],\n",
       "                         [-2.3885e-01, -2.8460e-02, -1.0875e-01],\n",
       "                         [-1.4545e-01, -7.0426e-02, -6.8133e-02]],\n",
       "               \n",
       "                        [[-5.5952e-02, -4.0911e-02, -3.3310e-02],\n",
       "                         [-1.7451e-01, -8.7108e-02,  1.2693e-02],\n",
       "                         [-7.0759e-02, -4.8385e-02, -3.3718e-03]],\n",
       "               \n",
       "                        [[ 2.9875e-02,  6.5026e-03, -1.0522e-01],\n",
       "                         [ 9.7180e-02,  5.2470e-02, -5.8483e-02],\n",
       "                         [ 1.0137e-02,  2.4127e-02, -2.8789e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.7989e-02,  1.1075e-01,  9.5427e-02],\n",
       "                         [ 2.2058e-02,  4.7560e-02,  4.7533e-02],\n",
       "                         [-1.4979e-02, -4.1187e-02, -8.4268e-03]],\n",
       "               \n",
       "                        [[-5.8950e-03, -4.3256e-02, -1.0115e-01],\n",
       "                         [-4.2977e-02,  7.3435e-04, -1.7013e-02],\n",
       "                         [-1.0561e-01, -1.1956e-01, -4.2652e-02]],\n",
       "               \n",
       "                        [[-3.0934e-02, -1.9715e-02, -4.4373e-02],\n",
       "                         [ 1.9279e-01,  1.6256e-01,  1.3915e-01],\n",
       "                         [ 4.7260e-02,  1.3291e-01, -8.4166e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.3602e-02,  2.0539e-02,  1.2633e-01],\n",
       "                         [-2.9732e-02,  6.9290e-02,  1.5418e-01],\n",
       "                         [ 7.1638e-02,  9.3394e-02,  1.5287e-01]],\n",
       "               \n",
       "                        [[-1.8831e-02,  1.6386e-02, -3.7939e-02],\n",
       "                         [-5.5418e-02,  3.2672e-03, -3.0469e-02],\n",
       "                         [ 1.9739e-03,  4.9307e-02, -2.8697e-02]],\n",
       "               \n",
       "                        [[ 1.1110e-02, -9.3922e-03, -1.0620e-01],\n",
       "                         [ 5.1250e-02,  4.8479e-02, -1.5916e-01],\n",
       "                         [ 2.6691e-02,  6.9313e-02, -1.7979e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.3847e-02, -1.4713e-02, -1.0052e-01],\n",
       "                         [ 1.9321e-02,  8.7875e-03, -5.4893e-02],\n",
       "                         [ 3.4401e-02,  1.7562e-02,  1.9163e-02]],\n",
       "               \n",
       "                        [[-1.8030e-04,  7.7708e-02,  1.5777e-01],\n",
       "                         [ 1.7430e-02,  5.9972e-02,  1.0575e-01],\n",
       "                         [-6.3385e-03,  6.1964e-02,  2.0596e-01]],\n",
       "               \n",
       "                        [[ 4.0382e-02,  1.6917e-01,  1.4179e-01],\n",
       "                         [ 6.5023e-02,  7.9723e-02,  1.8729e-01],\n",
       "                         [ 4.7586e-02,  1.4556e-01,  8.0061e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9561e-02,  1.6063e-02,  4.5139e-02],\n",
       "                         [-1.0781e-01, -1.5374e-02,  8.8728e-05],\n",
       "                         [-4.4376e-02,  5.6114e-03,  6.6437e-02]],\n",
       "               \n",
       "                        [[-2.1091e-02,  1.9502e-03, -5.8937e-02],\n",
       "                         [-4.3717e-02, -4.9178e-03, -1.5190e-01],\n",
       "                         [ 6.7578e-02,  5.1915e-02,  2.1604e-02]],\n",
       "               \n",
       "                        [[ 2.7038e-03, -4.4696e-02, -8.6027e-02],\n",
       "                         [ 8.1351e-02,  3.4863e-02, -1.7840e-01],\n",
       "                         [ 3.4614e-02,  3.6288e-02, -1.2641e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.3675e-03,  1.8449e-02, -4.5892e-02],\n",
       "                         [ 3.9285e-02,  1.1169e-02, -4.6597e-02],\n",
       "                         [ 1.1016e-02, -1.7599e-02, -4.0958e-02]],\n",
       "               \n",
       "                        [[ 1.7124e-02,  4.0852e-02,  7.1878e-02],\n",
       "                         [ 1.9256e-02,  2.0039e-02,  6.9166e-02],\n",
       "                         [ 8.0109e-02,  1.0178e-01,  1.2642e-01]],\n",
       "               \n",
       "                        [[-1.3671e-02,  2.6154e-02, -1.1227e-03],\n",
       "                         [-5.0951e-02,  1.0144e-02, -8.1067e-02],\n",
       "                         [-4.0022e-02, -1.2864e-02, -1.0272e-01]]]], device='cuda:0')),\n",
       "              ('conv_block4.conv2.weight',\n",
       "               tensor([[[[-1.3141e-01, -1.7014e-01, -3.1536e-01],\n",
       "                         [ 1.4788e-04, -1.2086e-01, -3.0856e-01],\n",
       "                         [-5.1835e-02, -1.7605e-01, -3.0941e-01]],\n",
       "               \n",
       "                        [[-1.5246e-01, -1.2831e-01, -4.4812e-02],\n",
       "                         [-1.6314e-01, -1.2917e-01, -7.5320e-02],\n",
       "                         [-1.5122e-01, -1.1717e-01, -1.5710e-01]],\n",
       "               \n",
       "                        [[-5.3818e-02, -5.1342e-02, -1.5757e-01],\n",
       "                         [-7.5635e-02, -9.9171e-02, -2.1828e-01],\n",
       "                         [-1.0729e-03, -1.0431e-01, -2.2602e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.4321e-02, -2.2552e-02, -8.8848e-02],\n",
       "                         [-2.5956e-02, -3.5327e-02, -1.3773e-01],\n",
       "                         [ 8.9133e-03,  3.0740e-03, -1.0050e-01]],\n",
       "               \n",
       "                        [[ 6.3828e-02,  1.4987e-05, -3.2330e-02],\n",
       "                         [ 1.6951e-03, -2.7668e-02, -1.7322e-01],\n",
       "                         [-6.9142e-03, -5.0586e-02, -1.9127e-01]],\n",
       "               \n",
       "                        [[-3.0931e-02, -6.4165e-02, -1.4262e-01],\n",
       "                         [-5.3583e-02, -1.3207e-01, -2.6642e-01],\n",
       "                         [-4.2838e-02, -6.4026e-02, -2.8391e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 9.9623e-02, -6.3867e-02,  2.5452e-02],\n",
       "                         [ 1.1098e-01, -3.8810e-02,  1.3309e-01],\n",
       "                         [ 1.2145e-01, -2.1395e-02,  1.1927e-01]],\n",
       "               \n",
       "                        [[ 2.8668e-01,  1.7305e-02,  8.8408e-02],\n",
       "                         [ 2.5384e-01, -1.9117e-01, -2.0238e-01],\n",
       "                         [ 2.4004e-01, -2.0833e-01, -1.6091e-01]],\n",
       "               \n",
       "                        [[-2.6671e-02, -1.1001e-01,  3.0393e-02],\n",
       "                         [ 4.0007e-04, -1.1037e-01,  4.0861e-03],\n",
       "                         [-1.8974e-02, -1.4899e-01,  2.3437e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.5335e-02, -6.9298e-02, -4.2384e-03],\n",
       "                         [-3.2748e-02, -7.9837e-02, -3.2012e-02],\n",
       "                         [-9.6534e-02, -1.6497e-01, -8.8456e-02]],\n",
       "               \n",
       "                        [[-1.4191e-02, -5.7730e-02,  7.7663e-02],\n",
       "                         [-1.6944e-02, -1.2329e-01,  6.6457e-02],\n",
       "                         [-3.9793e-02, -5.5077e-02,  1.8633e-02]],\n",
       "               \n",
       "                        [[-4.3596e-02, -1.3971e-01,  1.0534e-02],\n",
       "                         [-4.4777e-02, -1.0370e-01,  2.5256e-02],\n",
       "                         [-2.9126e-02, -1.2420e-01,  1.6884e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2084e-01, -6.4760e-02,  1.3030e-01],\n",
       "                         [-1.3044e-01, -2.5075e-02,  1.6151e-02],\n",
       "                         [-8.7644e-02,  1.5531e-03,  1.7084e-02]],\n",
       "               \n",
       "                        [[ 1.0630e-01,  6.8825e-02,  1.0841e-01],\n",
       "                         [ 6.3294e-02,  5.6313e-02,  9.1738e-02],\n",
       "                         [-8.5978e-02,  4.0142e-03,  4.2442e-02]],\n",
       "               \n",
       "                        [[-7.9506e-02, -5.3952e-01, -4.3850e-02],\n",
       "                         [-1.0070e-01, -6.0278e-01, -6.0825e-02],\n",
       "                         [-4.1294e-02, -4.5038e-01, -5.5793e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.0779e-02, -9.0226e-03,  3.3375e-03],\n",
       "                         [ 8.1960e-04, -7.6463e-02, -3.6247e-02],\n",
       "                         [ 1.9942e-02, -4.3963e-02, -3.7640e-02]],\n",
       "               \n",
       "                        [[-4.5117e-02, -9.3657e-02, -1.9836e-03],\n",
       "                         [-5.8529e-02, -8.0018e-02, -3.1515e-02],\n",
       "                         [-1.2475e-02, -7.1371e-02, -4.3010e-03]],\n",
       "               \n",
       "                        [[-5.3049e-02, -1.5731e-01, -2.5275e-02],\n",
       "                         [-5.1301e-02, -2.0356e-01, -2.3456e-02],\n",
       "                         [-2.6011e-02, -1.6314e-01, -5.0286e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.3632e-03, -1.2925e-02,  6.8488e-04],\n",
       "                         [-9.8775e-02, -8.1714e-02, -3.4547e-02],\n",
       "                         [-1.1710e-02, -7.6958e-02, -6.0914e-02]],\n",
       "               \n",
       "                        [[-1.0509e-01, -1.0036e-01, -3.5899e-02],\n",
       "                         [-1.3978e-01, -1.4804e-01, -3.0534e-02],\n",
       "                         [-1.9116e-01, -1.2482e-01, -7.7175e-02]],\n",
       "               \n",
       "                        [[ 1.0296e-02, -6.9565e-02,  7.9738e-02],\n",
       "                         [ 2.8699e-02, -1.6072e-01,  6.3567e-02],\n",
       "                         [ 1.6107e-02, -1.5727e-01,  4.8203e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.1035e-02, -1.2945e-01,  1.2868e-02],\n",
       "                         [-1.6226e-01, -2.2084e-01, -4.9709e-03],\n",
       "                         [-2.6686e-02, -8.8472e-02,  4.4570e-02]],\n",
       "               \n",
       "                        [[-5.2616e-03, -5.7111e-02,  5.4005e-02],\n",
       "                         [-2.7419e-02, -9.5018e-02,  4.9039e-02],\n",
       "                         [-2.7858e-04, -2.4506e-02,  3.1993e-02]],\n",
       "               \n",
       "                        [[-3.8276e-02, -7.3607e-02, -9.0714e-03],\n",
       "                         [-5.5761e-02, -1.2196e-01,  4.7025e-03],\n",
       "                         [-1.7847e-02, -1.2619e-01,  4.5440e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.4819e-02, -1.4828e-01, -1.0668e-01],\n",
       "                         [ 4.5886e-02,  2.8900e-02,  4.0922e-02],\n",
       "                         [ 1.8913e-03,  2.3505e-02,  1.6824e-01]],\n",
       "               \n",
       "                        [[ 1.5831e-01,  1.1025e-01,  3.2725e-01],\n",
       "                         [ 3.3227e-01,  2.0414e-01,  3.9934e-01],\n",
       "                         [ 3.2118e-01,  2.7469e-01,  3.1816e-01]],\n",
       "               \n",
       "                        [[ 4.3839e-03, -1.8127e-01,  3.0586e-02],\n",
       "                         [-5.1334e-02, -2.2614e-01,  6.0986e-02],\n",
       "                         [-9.7718e-03, -2.2800e-01,  7.6102e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.9273e-02, -9.4798e-02, -1.8765e-02],\n",
       "                         [ 2.7452e-02, -1.2884e-01, -6.5547e-03],\n",
       "                         [-1.1060e-01, -2.2181e-01, -8.4998e-02]],\n",
       "               \n",
       "                        [[-1.2539e-02, -9.0758e-02,  3.2262e-02],\n",
       "                         [-2.7983e-02, -1.2655e-01,  1.7510e-03],\n",
       "                         [-7.8804e-03, -1.0630e-01,  3.6500e-02]],\n",
       "               \n",
       "                        [[-4.5780e-02, -1.7082e-01,  3.4723e-02],\n",
       "                         [-4.5897e-02, -2.2459e-01, -1.2138e-02],\n",
       "                         [-5.9276e-02, -1.9904e-01, -7.6359e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 6.4527e-02,  2.3626e-03,  3.5323e-02],\n",
       "                         [ 5.2964e-02,  8.6002e-03,  9.5076e-02],\n",
       "                         [ 2.5534e-01,  2.2776e-01,  6.3691e-01]],\n",
       "               \n",
       "                        [[-3.1473e-01, -1.5584e-01, -2.4066e-01],\n",
       "                         [-5.6614e-01, -2.5919e-01, -4.8721e-01],\n",
       "                         [-4.7625e-01, -4.3592e-01, -5.6699e-01]],\n",
       "               \n",
       "                        [[-8.0138e-02, -2.7227e-01, -3.8287e-03],\n",
       "                         [-8.9857e-02, -3.3922e-01, -7.3446e-03],\n",
       "                         [-8.2277e-02, -2.2914e-01, -2.5482e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.4436e-02, -1.6535e-01, -6.6169e-02],\n",
       "                         [-1.0076e-01, -1.9541e-01, -2.1543e-02],\n",
       "                         [-4.8573e-02, -2.3831e-01, -7.6474e-02]],\n",
       "               \n",
       "                        [[-6.5030e-02, -1.0340e-01, -1.7654e-02],\n",
       "                         [-4.2388e-02, -9.1843e-02, -4.4946e-02],\n",
       "                         [-5.0771e-02, -9.4325e-02, -3.5689e-02]],\n",
       "               \n",
       "                        [[-1.0607e-01, -1.3761e-01, -1.6891e-01],\n",
       "                         [-7.1688e-02, -1.0667e-01, -9.9844e-02],\n",
       "                         [-6.6565e-02, -1.0376e-01, -2.3241e-02]]]], device='cuda:0')),\n",
       "              ('conv_block4.bn1.weight',\n",
       "               tensor([1.0171, 0.5798, 0.5005, 0.9467, 0.4131, 0.9769, 0.4462, 1.0130, 0.9361,\n",
       "                       1.1435, 1.0755, 0.8172, 1.2160, 1.1708, 0.8326, 1.0605, 1.3565, 1.1408,\n",
       "                       0.9933, 1.1301, 1.0148, 1.1272, 0.9770, 0.5058, 0.8135, 0.6770, 1.1596,\n",
       "                       1.0459, 1.0975, 1.0943, 1.0097, 0.8133, 1.1153, 0.8899, 1.0428, 1.2536,\n",
       "                       0.9832, 0.6203, 0.9139, 0.8731, 0.6918, 1.1260, 0.2733, 1.0130, 1.0926,\n",
       "                       1.0720, 1.1631, 1.1839, 0.5973, 1.1405, 1.1763, 0.9800, 1.0225, 1.0436,\n",
       "                       0.8502, 1.1530, 0.9835, 1.3239, 0.6362, 0.9547, 0.8648, 0.7036, 0.9891,\n",
       "                       0.8956, 0.6684, 1.0972, 0.9076, 0.6384, 0.8603, 1.0418, 0.8226, 0.9889,\n",
       "                       0.4692, 0.4991, 0.8975, 0.8536, 1.2099, 0.9635, 1.1211, 1.0741, 1.1748,\n",
       "                       1.0328, 0.9639, 0.8464, 0.9222, 0.8646, 0.9812, 1.0259, 0.9026, 1.0985,\n",
       "                       1.3200, 1.3520, 0.8091, 0.8493, 1.0194, 0.5287, 0.9658, 0.9977, 0.9788,\n",
       "                       1.3655, 0.4898, 0.7785, 0.9938, 0.4714, 0.3356, 0.9735, 0.8762, 0.8690,\n",
       "                       1.3053, 0.7439, 0.7643, 0.6878, 1.0019, 1.0641, 1.0696, 1.1539, 1.1049,\n",
       "                       0.8718, 1.3012, 0.9538, 0.9531, 0.5643, 1.0746, 0.9723, 0.8656, 1.3475,\n",
       "                       0.9380, 0.8953, 1.3727, 0.4535, 1.1457, 0.6542, 1.0409, 1.0981, 0.9023,\n",
       "                       1.1144, 1.0815, 1.2134, 0.8978, 0.9925, 0.8624, 1.0421, 1.3380, 1.1504,\n",
       "                       0.9870, 0.4670, 1.0330, 1.1302, 1.1419, 1.2744, 1.2785, 1.2513, 1.0941,\n",
       "                       1.1802, 1.2290, 1.3752, 0.9396, 0.9662, 0.9707, 1.0778, 0.3860, 0.9183,\n",
       "                       1.1586, 0.8619, 0.6188, 1.1147, 1.3675, 1.0019, 1.1476, 1.0775, 1.0792,\n",
       "                       1.1930, 0.9706, 0.9071, 0.9174, 0.9868, 0.7037, 0.7321, 0.8768, 1.0496,\n",
       "                       0.9915, 1.0660, 0.8966, 0.9964, 0.8852, 1.2159, 1.1580, 0.7111, 0.4730,\n",
       "                       1.0353, 1.0192, 0.8928, 1.2706, 1.4263, 0.9980, 0.3532, 0.4918, 0.9829,\n",
       "                       0.7474, 1.0839, 0.5446, 1.0956, 1.0380, 1.0943, 1.0517, 0.7094, 1.0557,\n",
       "                       0.6625, 1.1248, 1.0023, 1.5281, 1.3572, 1.0759, 0.7746, 1.2011, 1.1546,\n",
       "                       0.5964, 0.9852, 0.8495, 0.9046, 0.9232, 1.2807, 0.5028, 0.9053, 1.1093,\n",
       "                       1.2315, 1.0267, 1.0194, 1.2623, 0.9689, 1.0482, 1.0786, 0.8586, 0.4864,\n",
       "                       1.2161, 1.0685, 1.0953, 0.9853, 0.8778, 1.0397, 1.2730, 0.9377, 1.2230,\n",
       "                       0.9753, 1.0981, 0.5209, 0.9376, 0.6086, 0.4151, 0.7702, 0.9797, 1.2388,\n",
       "                       1.0349, 0.9509, 0.8632, 1.2876, 1.6126, 1.1258, 0.4149, 1.0089, 1.0519,\n",
       "                       0.8221, 1.2245, 1.0256, 1.0461, 0.9651, 0.8645, 1.0192, 1.0774, 1.0158,\n",
       "                       1.1035, 0.9729, 1.2657, 1.1162, 1.0492, 0.8497, 1.1300, 1.0705, 0.9149,\n",
       "                       0.5904, 0.9442, 1.1462, 0.9009, 1.3760, 0.4095, 1.0837, 1.2117, 0.5813,\n",
       "                       1.1220, 1.3137, 0.5588, 1.1104, 0.7647, 0.8270, 1.7138, 1.0442, 0.9528,\n",
       "                       1.1511, 0.8160, 1.0942, 1.2062, 1.0723, 0.9839, 1.4398, 1.0917, 1.1048,\n",
       "                       1.0294, 1.0739, 1.1939, 1.0529, 1.0129, 1.0052, 1.4338, 1.0208, 0.9004,\n",
       "                       1.1145, 0.8237, 1.2433, 0.9026, 1.0068, 1.1364, 0.9539, 0.7693, 1.0401,\n",
       "                       1.3652, 0.4287, 1.0163, 0.9942, 1.1042, 0.4577, 0.9942, 0.9551, 0.9146,\n",
       "                       1.0011, 1.1516, 0.9862, 0.7260, 1.1630, 1.0532, 0.9281, 0.9433, 0.6011,\n",
       "                       0.6257, 1.1354, 0.9504, 0.9805, 0.9760, 0.9792, 0.4477, 0.7953, 0.9629,\n",
       "                       0.8023, 1.1022, 1.1797, 0.8836, 1.0323, 0.5699, 1.0605, 1.1273, 1.0621,\n",
       "                       0.7290, 0.9571, 0.8671, 0.6478, 0.3853, 0.9439, 0.8821, 0.8617, 0.4659,\n",
       "                       1.0389, 0.3590, 1.1582, 0.9726, 1.0988, 1.0964, 0.8692, 1.2900, 0.8554,\n",
       "                       1.1174, 0.9015, 0.9937, 1.2691, 0.9923, 0.9630, 1.0504, 0.7922, 0.5388,\n",
       "                       1.0412, 1.0914, 0.9493, 1.1033, 0.9571, 0.9168, 0.9361, 1.1429, 0.4560,\n",
       "                       1.0962, 1.0570, 0.6944, 1.0913, 1.0084, 0.9310, 0.8042, 0.9676, 1.1645,\n",
       "                       1.0108, 0.9704, 0.8509, 0.8505, 0.9832, 0.9930, 1.0751, 0.9806, 1.0307,\n",
       "                       1.1843, 1.0450, 0.8979, 0.8262, 0.7724, 0.8858, 0.9827, 1.0757, 1.1863,\n",
       "                       0.9124, 0.8604, 1.0140, 1.1726, 0.8133, 0.9450, 0.7757, 0.9359, 0.8902,\n",
       "                       0.4347, 0.8054, 0.9967, 0.8918, 1.1201, 0.8330, 1.3714, 0.6347, 0.6996,\n",
       "                       0.9285, 0.9511, 1.2236, 1.0164, 0.8717, 1.0107, 1.2076, 0.9399, 1.1091,\n",
       "                       0.9706, 1.1365, 1.0346, 1.1798, 1.2603, 1.0090, 0.9313, 0.8644, 1.0968,\n",
       "                       0.7437, 1.1048, 1.1171, 0.9892, 0.9939, 1.4142, 1.0721, 1.1209, 1.0621,\n",
       "                       1.1425, 0.8798, 1.1274, 0.9831, 1.0430, 0.9428, 0.3956, 0.9816, 1.0278,\n",
       "                       0.9393, 0.9891, 1.3775, 1.0050, 0.8539, 0.9556, 1.1961, 1.1283, 1.0901,\n",
       "                       0.9547, 1.0527, 1.6421, 1.0322, 1.0283, 0.7542, 0.9550, 1.1278, 0.9013,\n",
       "                       1.0847, 1.1320, 0.8843, 1.1033, 1.0025, 1.0018, 1.0766, 0.2731, 1.0976,\n",
       "                       1.3175, 1.2517, 1.0063, 1.2144, 1.1150, 0.8921, 0.4834, 0.4870],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.bias',\n",
       "               tensor([-0.9268, -0.6266, -0.5309, -0.6357, -0.5046, -1.1536, -0.5173, -1.4939,\n",
       "                       -0.7832, -1.5075, -0.6342, -0.5730, -1.1893, -1.1652, -0.7942, -1.0887,\n",
       "                       -1.3104, -1.3070, -0.8438, -1.5253, -0.9678, -1.0071, -0.9260, -0.5962,\n",
       "                       -1.2304, -0.2258, -0.6201, -0.8741, -0.9973, -0.2882, -1.0181, -0.0473,\n",
       "                       -1.2342, -0.8188, -0.9273, -1.0032, -1.1131, -0.5810, -0.9244, -0.8191,\n",
       "                       -0.4738, -0.7664, -0.1053, -1.1785, -1.2238, -1.2519, -1.0774, -1.7462,\n",
       "                       -1.2521, -1.0098, -1.3732, -1.0013, -0.9384, -0.9089, -0.7262, -1.2270,\n",
       "                       -1.0483, -1.5191, -0.4390, -1.0361, -0.8670, -0.8597, -1.4813, -0.6777,\n",
       "                       -0.4823, -1.1131, -0.8683, -0.1681, -0.6160, -1.1000, -0.6691, -0.6610,\n",
       "                        0.1074, -0.4299, -0.8592, -0.8151, -1.7040, -1.0895, -0.9872, -1.5288,\n",
       "                       -1.1496, -0.6807, -0.8016, -0.7891, -0.9479, -0.6210, -1.0759, -1.1950,\n",
       "                       -0.9956, -1.2665, -1.5158, -1.7583, -0.7382, -0.5999, -0.9451, -0.5500,\n",
       "                       -1.0278, -0.6882, -1.0760, -1.4877, -0.7106, -0.9699, -1.1468, -0.5725,\n",
       "                       -0.2269, -1.4250, -0.7481, -0.9016, -1.3545, -0.4090, -0.5920, -0.7844,\n",
       "                       -1.2422, -1.0947, -1.3283, -1.2184, -1.1426, -0.8193, -1.3204, -0.8605,\n",
       "                       -0.7378, -0.5170, -1.3469, -1.0916, -0.9371, -1.4747, -1.0785, -1.3800,\n",
       "                       -1.3396, -0.4237, -1.3274, -0.8327, -0.8605, -1.2755, -0.9883, -1.0643,\n",
       "                       -1.1332, -1.2407, -1.0683, -0.9353, -0.8443, -1.0549, -1.1899, -1.0002,\n",
       "                       -1.4368, -0.4605, -0.8931, -1.3795, -1.1537, -1.2295, -1.5573, -1.3294,\n",
       "                       -1.2111, -1.4382, -1.0037, -1.4445, -0.7545, -1.1937, -1.0555, -0.8604,\n",
       "                       -0.3483, -0.8547, -1.4832, -0.9992, -0.6245, -1.1271, -1.8393, -0.8570,\n",
       "                       -1.1873, -0.9002, -1.1650, -1.4616, -1.0966, -1.0338, -0.8798, -1.0539,\n",
       "                       -0.5295, -0.5991, -0.5281, -1.1401, -1.3800, -1.1607, -1.0025, -0.7102,\n",
       "                       -0.9779, -1.1512, -1.1975, -0.7246, -0.4748, -0.9941, -0.7571, -0.8653,\n",
       "                       -1.4647, -1.8294, -0.6385, -0.2421, -0.4240, -0.7561, -0.7323, -1.0429,\n",
       "                       -0.5567, -0.7589, -0.8982, -1.1422, -1.3670, -0.8966, -0.7570, -0.8501,\n",
       "                       -1.4752, -1.3566, -1.5417, -1.3120, -1.4789, -0.8098, -1.1903, -1.1919,\n",
       "                       -0.5641, -1.0068, -0.6368, -1.1082, -0.6602, -1.2209, -0.5706, -0.8450,\n",
       "                       -1.4457, -1.1181, -0.5517, -1.0157, -1.0188, -1.3320, -1.1227, -0.8480,\n",
       "                       -0.9637, -0.3996, -1.1952, -1.4615, -1.0471, -0.8518, -1.3566, -1.1436,\n",
       "                       -1.2017, -0.7486, -1.5245, -0.9609, -1.2642, -0.4812, -1.1266, -0.8732,\n",
       "                       -0.4258, -0.7096, -0.8881, -1.1568, -1.1495, -1.0584, -0.5065, -2.0450,\n",
       "                       -1.8439, -1.0001, -0.4478, -1.3064, -1.2587, -0.7340, -0.7342, -0.9460,\n",
       "                       -1.0269, -0.9412, -0.7271, -0.9116, -0.7955, -1.3599, -1.3335, -1.3596,\n",
       "                       -2.0832, -1.4160, -0.9864, -0.7417, -0.7941, -1.4409, -0.8184, -0.5528,\n",
       "                       -0.7167, -1.1789, -0.8158, -1.4325, -0.2628, -1.1581, -1.9050, -0.4080,\n",
       "                       -1.2944, -1.1235, -0.6202, -1.1652, -0.9671, -1.1774, -1.8213, -0.8847,\n",
       "                       -0.6611, -1.5906, -0.7409, -1.0386, -1.0712, -1.1633, -1.0001, -1.3512,\n",
       "                       -0.9485, -1.2225, -1.0768, -1.1959, -1.0779, -1.0752, -1.1522, -0.9081,\n",
       "                       -1.0947, -0.8541, -0.9721, -1.3169, -0.8332, -1.1959, -0.8614, -1.2096,\n",
       "                       -1.2910, -1.3517, -0.7324, -0.7874, -1.2204, -0.3987, -1.2808, -1.0477,\n",
       "                       -1.0734, -0.4106, -0.8290, -0.8418, -1.1694, -1.0074, -1.2381, -1.2645,\n",
       "                       -0.4686, -0.9527, -0.7772, -0.9946, -0.5623, -0.7630, -0.8910, -1.0892,\n",
       "                       -0.8300, -0.9807, -0.9775, -1.3635, -0.4377, -0.6563, -1.3178, -0.7624,\n",
       "                       -1.1922, -1.3888, -1.3011, -0.8241, -0.6315, -1.0948, -1.0740, -1.1862,\n",
       "                       -1.2401, -0.8922, -0.8188, -0.4529, -0.3196, -0.9116, -0.5977, -0.7753,\n",
       "                       -0.3463, -0.9359, -0.2351, -1.1351, -0.8505, -1.2622, -0.8808, -0.8275,\n",
       "                       -1.4604, -0.6374, -0.9875, -0.5543, -0.9385, -1.4324, -1.0252, -0.7666,\n",
       "                       -1.3167, -0.6675, -0.3785, -0.6188, -1.1109, -0.7665, -0.6459, -1.3750,\n",
       "                       -0.9565, -0.8162, -1.1617, -0.2942, -1.1032, -0.9313, -0.6704, -0.9382,\n",
       "                       -1.4996, -0.6677, -0.9241, -0.9116, -1.5874, -1.2366, -0.9990, -0.7313,\n",
       "                       -0.6550, -0.9268, -0.9094, -1.2075, -0.7507, -1.5805, -1.3963, -1.1001,\n",
       "                       -0.8197, -0.6291, -0.5572, -0.6652, -1.0816, -1.0449, -1.2613, -0.6382,\n",
       "                       -0.4380, -1.4386, -1.2137, -0.5551, -1.0229, -0.9086, -0.8036, -0.8823,\n",
       "                       -0.4433, -0.5666, -1.3386, -0.8249, -1.0241, -0.9359, -1.3669, -0.1792,\n",
       "                       -0.4910, -0.6613, -0.6006, -1.2904, -1.2362, -0.9800, -0.7748, -0.8731,\n",
       "                       -0.9160, -1.3455, -0.6145, -1.3676, -0.9559, -0.8511, -1.0169, -1.0877,\n",
       "                       -0.6715, -0.8468, -0.9053, -0.6382, -0.7508, -1.1323, -1.2330, -1.0002,\n",
       "                       -1.0657, -1.0172, -1.3319, -1.0393, -1.2256, -0.7244, -1.3001, -1.1020,\n",
       "                       -1.2895, -0.6108, -0.4768, -1.4196, -1.3897, -0.7835, -1.0923, -1.2570,\n",
       "                       -0.9177, -0.8924, -0.9494, -0.8150, -1.1034, -1.1010, -0.7710, -1.2923,\n",
       "                       -1.7607, -0.8246, -1.0299, -0.7357, -0.8449, -1.3700, -0.9031, -1.1970,\n",
       "                       -1.0119, -0.7387, -1.1051, -1.0061, -1.1059, -0.8715, -0.2503, -0.7411,\n",
       "                       -1.5400, -1.4532, -0.8578, -1.6902, -1.4873, -0.8968, -0.5279, -0.5539],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.running_mean',\n",
       "               tensor([-10.9466,  -4.7064,   0.4896, -13.0394,   1.0596,  -5.1966,   2.5946,\n",
       "                        -6.1204,  -4.9037,  -9.0592,  -4.7538,  -7.4809, -10.2353,  -4.2202,\n",
       "                       -11.6675,  -6.0336,  -7.8942,  -5.2304,  -5.9133,  -4.6640,  -6.5091,\n",
       "                        -8.8374,  -5.8615,  -0.1198,  -3.0118,  -5.2285,   3.0720,  -9.0669,\n",
       "                        -8.2644,  -2.2407, -16.7493,  -3.2580,  -6.2603,  -3.2431,  -8.6461,\n",
       "                        -5.1161,  -6.8665,   1.6716,  -2.8061,  -2.2973,  -6.4704,   0.0351,\n",
       "                         1.7752, -12.2334,  -7.8868,  -4.4822,  -6.7287,  -1.5001,  -1.8367,\n",
       "                        -9.2483,  -5.0554,  -7.2483,  -5.0116,  -2.3397,  -5.7115,  -7.1529,\n",
       "                        -4.5376,  -8.3607,  -3.2629,  -4.0760,  -8.0348,  -4.2006,  -6.1257,\n",
       "                        -3.2869,  -1.5678,  -5.3736,  -4.9567,  -0.0239,  -8.7057,  -6.1706,\n",
       "                        -9.4158,  -1.2394,  -0.2976,   2.0511,  -2.4322,  -7.2357,  -5.7281,\n",
       "                        -3.8909,  -6.6181,  -6.5762,  -6.2335,  -7.7848,  -3.6213,  -4.4694,\n",
       "                        -6.5564,  -1.7735,  -6.3409,  -3.5482,  -4.7265,  -9.7434,  -5.2787,\n",
       "                        -4.4089,  -8.5867,  -8.9784,  -8.3622,  -1.1242,  -1.6125,  -6.1353,\n",
       "                        -1.8334,  -6.4470,   1.9517,  -4.0501,  -7.9616,  -0.0614,   1.8526,\n",
       "                        -8.1184,  -7.6924,  -3.5090, -13.9613,  -1.8541,  -6.5741,  -1.1032,\n",
       "                        -7.2868,  -5.5170, -13.6198,  -8.7831,  -6.9043,  -9.8543,  -8.1938,\n",
       "                       -10.9025,  -1.5706,   0.2536,  -6.2698,  -4.7969,  -2.5400,  -6.6330,\n",
       "                        -8.2245,  -8.3690,  -3.3294,   1.4847,  -5.6580,  -0.6512,  -2.6138,\n",
       "                        -5.4812,  -8.3086,  -6.6517,  -0.9511,  -6.5308,  -0.4880, -10.0147,\n",
       "                       -10.0530,  -8.8695,  -8.9923,  -9.2739,  -5.5759,   1.4889,  -5.5971,\n",
       "                        -6.5623,  -6.1954,  -6.9607,  -4.3671, -10.0267,  -6.3242,  -1.5743,\n",
       "                        -5.8862,  -8.4250,  -9.6883,  -0.3161,  -6.0573,  -0.9220,   2.8667,\n",
       "                        -3.4738,  -5.6987,  -4.2769,  -1.2995,  -6.1807, -10.4538, -10.6439,\n",
       "                        -6.4368,  -7.6672,  -6.1779,  -6.6622, -12.6275,  -5.0543, -13.3042,\n",
       "                        -9.2222,  -2.8990,  -1.0521, -10.5863, -12.6526,  -5.7583,  -6.1315,\n",
       "                        -4.1107,  -7.5637,  -8.3993,  -3.6659,  -1.5571,  -5.7016,   0.4822,\n",
       "                        -4.1579,  -4.2678,  -3.1378,  -7.7058,  -5.8783,  -6.5717,   1.4404,\n",
       "                         0.1798,  -6.9300,  -2.0510,  -6.2335,   0.7833,  -5.9191,  -9.1841,\n",
       "                        -3.7911,  -7.2584,  -3.9278,  -5.4451,  -1.0859,  -8.4004,  -4.5896,\n",
       "                        -3.7839,  -2.1272,  -0.8305,  -3.9474,  -5.0292,  -4.3324,   1.6887,\n",
       "                        -5.2468,  -9.3235, -12.2824,  -5.9639,  -6.0610,   1.1145,  -4.4179,\n",
       "                        -6.1781,  -7.4969,  -6.3649,  -8.0785,  -5.8291,  -7.1095,   0.0293,\n",
       "                        -7.3850,  -5.0077,  -4.7580,  -2.4646,  -4.9892,  -6.5832,  -8.1314,\n",
       "                        -3.3271,  -6.9148,  -5.1012,  -6.6263,  -6.5491,  -5.4777,  -4.7112,\n",
       "                        -1.7681,  -2.9845,  -0.6280,   0.6161,  -4.8205,  -5.8634,  -3.7613,\n",
       "                       -12.9779,  -4.8706,  -3.6795,  -3.5789,  -7.1662,  -6.3291,   2.0748,\n",
       "                        -6.3364,  -5.2135,  -5.4410,  -3.6490,  -1.8804,  -6.5819,  -6.4984,\n",
       "                       -11.3954,  -9.8010, -11.5818,  -5.1824,  -4.9084,  -6.3417,  -7.3625,\n",
       "                       -11.8305, -11.8492,  -5.2052,  -3.5223,  -1.8082,  -4.9645,  -1.7844,\n",
       "                        -6.9489,  -7.0825,  -2.0701,  -4.3015,   0.9403,  -7.6335,  -8.7052,\n",
       "                        -0.3232,  -8.0548,  -6.3594,   0.0384, -10.3239,  -5.7635,   1.2717,\n",
       "                       -10.4732,  -6.6686,  -1.0650,  -2.5657,  -9.0322,  -6.0299,  -7.6969,\n",
       "                        -8.4339,  -5.6820,  -6.2278,  -6.9537,  -7.1906,  -9.3338,  -3.2026,\n",
       "                        -0.8080,  -8.3156,  -3.4238,  -6.3102,  -6.0365,  -7.9017,  -6.0254,\n",
       "                        -3.1737,  -3.8924,  -1.3887,  -7.4180,  -8.3821,  -6.3889,   0.2771,\n",
       "                       -13.0124,  -7.0043,  -6.5420,   0.5211, -10.5753,  -4.8199,  -8.8597,\n",
       "                         0.7271,  -6.9438,  -5.8706,  -6.6012, -11.7251,  -9.9602,  -3.5897,\n",
       "                        -3.7250,   1.3409,  -6.2583,  -8.7168,  -4.7366,   0.7047,   0.6778,\n",
       "                        -3.3599,  -5.2760,  -7.6540,  -7.4514,  -5.3712,   0.7601,  -9.1521,\n",
       "                        -4.2634,  -8.8234,  -7.7530,  -2.1752,  -6.7177,  -7.7468,   1.3792,\n",
       "                        -7.6447,  -4.8029, -10.1590,   0.7072,  -6.5925,  -4.7821,  -6.2494,\n",
       "                         2.2727,  -4.8053,  -7.1708,  -1.1976,  -0.4371,  -7.4698,   2.2801,\n",
       "                       -10.9002,  -7.5096,  -6.9487,  -6.1443,  -0.9438, -11.0681,  -5.3732,\n",
       "                        -6.2433,  -3.4355,  -7.4783,  -2.8342,  -2.9182,  -2.5896,  -2.3832,\n",
       "                        -3.8353,   1.1935,  -5.2662,  -8.6400,  -2.4046,  -4.8689,  -6.6092,\n",
       "                        -0.7686,  -5.4240,  -6.4915,  -0.1485,  -7.4101,  -5.3624,  -3.9568,\n",
       "                        -8.2369,  -6.2680,  -7.4459,  -1.5998, -12.1062,  -6.4252,  -4.5093,\n",
       "                        -9.1467,  -1.7616,  -4.1337,  -7.5233, -11.9482,  -9.0477,  -0.1674,\n",
       "                        -6.2516,  -5.3855, -13.4576,  -7.5187,  -8.5937,  -8.9846,  -7.8837,\n",
       "                        -7.2620,  -8.1858, -10.8179,   0.6603,  -8.9839,  -6.2542, -10.4111,\n",
       "                        -7.0609,  -5.5050,  -0.5491,  -4.2341,  -4.2832,   1.9065,  -6.6364,\n",
       "                        -9.1535,  -7.1616,  -5.9491,  -4.5903,  -6.4505,  -3.0236,  -6.1423,\n",
       "                        -2.2690,  -3.9202,  -6.1200, -10.3187, -10.1729,  -6.7391,  -7.7427,\n",
       "                        -8.7977, -11.9383,  -5.3453,  -5.8036,  -6.7242,   0.4427,  -9.2209,\n",
       "                        -3.7368,  -4.7518,  -9.7832,  -4.4224,   1.3990,  -2.4374,  -4.9322,\n",
       "                        -3.9685,  -8.2084,  -5.6697,  -4.8616,  -7.2400,  -9.3516,  -6.3486,\n",
       "                        -4.4132,  -8.5907,  -7.9852,  -3.4281,  -7.5983,   0.6316,  -4.0236,\n",
       "                        -4.1680,  -6.6564,  -7.3984,  -5.0515,  -9.8773,  -5.5165,  -3.4083,\n",
       "                        -4.0908,  -5.4502,  -7.5116,  -4.7940,  -6.8727,  -6.4855,  -3.8047,\n",
       "                        -4.6048,   2.2831,  -0.6845,  -9.2537,   2.3546,  -7.3868,  -6.5038,\n",
       "                        -8.1104,  -4.6953,  -6.2870,  -5.7926,  -7.7083,   1.6947,  -6.8570,\n",
       "                        -4.1531,  -4.1234,  -9.3761,  -7.1345,  -5.3935,  -2.3333,   1.9098,\n",
       "                         1.1853], device='cuda:0')),\n",
       "              ('conv_block4.bn1.running_var',\n",
       "               tensor([30.5615, 19.5194,  6.8431, 33.2307,  7.7484, 19.5720,  5.7041, 16.7709,\n",
       "                       20.6506, 32.5822, 12.8072, 25.8494, 28.5697,  9.8946, 38.2908, 12.4467,\n",
       "                       22.7973, 15.6550, 30.3211, 15.4183, 13.8769, 20.1674, 13.4068,  5.2064,\n",
       "                        9.3205, 19.1652, 13.3040, 28.8858, 23.1700, 17.6359, 36.8522, 17.2134,\n",
       "                       22.6639, 14.3213, 17.0298, 16.1659, 17.5653,  5.6243,  8.1378, 23.6647,\n",
       "                       17.6713, 10.8439,  6.3442, 18.7229, 28.5044, 15.1650, 16.8111, 27.2365,\n",
       "                       13.7515, 18.3758, 15.7615, 18.0450, 18.5931, 15.1795, 30.1187, 16.0600,\n",
       "                       18.4562, 15.7618,  6.0597,  9.8101, 25.0701, 10.5290, 20.8149,  8.2874,\n",
       "                       10.5557, 36.5706, 20.3083, 10.9105, 26.9362, 24.1466, 27.5407,  7.9009,\n",
       "                       10.2477,  7.5243,  7.9346, 31.0490, 16.5714, 16.9582, 15.1790, 15.1728,\n",
       "                       11.0975, 17.7968,  9.3774, 17.2617, 18.0170, 11.2026, 10.0479, 21.4738,\n",
       "                       12.8184, 27.9929, 34.9499,  8.7972, 20.2416, 38.6349, 35.8775, 26.6058,\n",
       "                        8.6860, 16.5672,  8.6107,  9.6205,  4.9644, 12.9083, 37.8021,  5.3654,\n",
       "                        4.3570, 33.3336, 28.2035,  9.7090, 34.4627, 10.1998, 32.1513,  6.2575,\n",
       "                       17.9305, 12.3358, 35.8649, 17.6484, 13.4068, 34.7466, 20.6096, 24.9320,\n",
       "                       12.1647,  5.1258, 15.6527, 36.4144, 13.6576, 15.8207, 12.5088, 21.6173,\n",
       "                       13.0574,  5.9408, 17.3958,  8.3152,  6.9040, 11.4219, 22.0784, 15.1430,\n",
       "                       15.8226, 26.2072, 13.5272, 31.2710, 25.6707, 19.4369, 19.3787, 27.3696,\n",
       "                       16.0319,  5.6787, 22.4620, 22.5795, 10.0631, 19.1722, 10.5147, 28.1664,\n",
       "                       12.4213, 25.4380, 12.6300, 23.6269, 41.7899, 11.3836, 18.0569,  8.7249,\n",
       "                        8.8377,  7.6490, 19.9988, 36.8825,  8.3112, 10.9120, 29.6565, 20.1334,\n",
       "                       13.5106, 28.7123, 16.1448, 27.9076, 31.5709, 19.4292, 30.4554, 25.3627,\n",
       "                       10.2696, 13.9052, 40.8040, 32.9910, 15.3921, 17.6103, 13.1719, 29.6313,\n",
       "                       18.9846, 22.1142, 12.7236, 18.7990,  5.8783, 13.0427, 12.2896,  5.8145,\n",
       "                       23.3267, 19.1351, 14.7191,  8.4226,  4.0103, 14.8062, 13.1337, 12.5089,\n",
       "                        5.3677, 21.5225, 24.8644, 17.3675, 13.8637, 14.5169, 15.1201,  6.6010,\n",
       "                       18.9283, 18.7039, 15.5907, 11.7995, 15.9959,  7.8538, 13.7008, 10.5229,\n",
       "                        4.6169, 13.7895, 36.4701, 28.8091, 16.2106, 11.9121,  4.6951, 12.1054,\n",
       "                       11.0117, 34.8793, 11.1683, 17.6856, 20.5549, 19.9955,  8.9615, 20.1625,\n",
       "                        9.6848, 19.9802, 14.8742, 17.6910, 19.3254, 24.4685, 21.4280, 29.3899,\n",
       "                       15.4179, 10.9351, 24.2829,  9.6252, 12.0946,  5.1307, 13.8964,  7.6012,\n",
       "                        6.3450, 14.6780, 14.1869, 24.8011, 26.2712, 22.6321, 14.2291, 18.8901,\n",
       "                       17.4181, 16.2870,  5.9781, 14.9376, 11.4820, 22.6166, 19.5444, 14.1481,\n",
       "                       14.4549, 16.9543, 19.7434, 27.3365, 32.2359, 20.6217, 26.1336, 24.1979,\n",
       "                       10.0762, 37.4724, 41.0546, 13.7372, 14.8969, 14.4313, 13.2454,  5.9549,\n",
       "                       14.9837, 19.6615, 10.9641, 12.4789,  4.1697, 20.6397, 20.3398,  4.9947,\n",
       "                       18.0992, 15.6661,  6.3609, 21.8676, 10.3437,  7.0835, 31.1422, 18.8504,\n",
       "                       12.8874, 12.5800, 25.5613, 21.8090, 15.6999, 21.7496, 22.0028, 15.8032,\n",
       "                       14.4817, 13.5646, 36.0756, 19.3523, 14.9007, 20.0335,  8.7787, 20.0837,\n",
       "                       17.5363, 12.9350, 13.9228, 12.1984,  7.4850, 18.1529, 15.2906, 15.3669,\n",
       "                       15.1041, 10.5410, 34.7928, 16.7722, 37.1760,  5.0407, 41.1197, 15.3174,\n",
       "                       27.7526,  2.9424, 16.8891, 20.1124, 14.4424, 34.8773, 22.7271, 20.1915,\n",
       "                        9.4582, 13.8497, 14.3264, 23.0631, 10.5649,  4.2221,  6.9832,  8.8682,\n",
       "                       18.3566, 20.9455, 20.9889, 22.7778,  7.7765, 26.7661,  7.1429, 13.2231,\n",
       "                       21.4396, 12.0353, 22.3188, 13.8094,  8.5693, 17.9074, 11.7283, 24.9059,\n",
       "                        8.4410, 11.4587, 16.0788, 37.7887,  6.3968, 15.5928, 10.7083,  7.3945,\n",
       "                        7.8200, 13.3485,  3.1345, 23.7982, 25.3734, 10.9349, 13.1362, 13.6335,\n",
       "                       24.6937, 23.0011, 18.5087, 23.0593, 15.7291, 13.5202, 15.2368, 10.1596,\n",
       "                       13.8289,  8.0219,  6.9101, 17.6363, 23.8544, 13.7632, 21.9881, 19.5875,\n",
       "                        7.7525, 13.8248, 12.9938,  5.0650, 14.1804, 29.8344, 12.4386, 20.9369,\n",
       "                        9.7813, 22.8497,  6.1871, 34.4481, 28.4984, 15.5763, 32.3126, 27.9873,\n",
       "                       28.5361, 21.9034, 29.6870, 19.2119, 15.0388, 12.2173, 16.7385, 36.1602,\n",
       "                       24.9092, 24.9316, 30.5120, 24.6249, 19.2227, 11.0939, 26.7466,  6.8273,\n",
       "                       12.3371, 20.9441, 39.4448, 14.4986, 11.7440,  6.7282, 15.6753, 23.5683,\n",
       "                        5.7090, 18.3468, 18.0073, 23.0290, 16.6334, 19.7900, 15.3393, 21.3345,\n",
       "                       11.5967, 10.6765, 24.2350, 16.5404, 35.5970, 35.3758, 10.5018, 15.7377,\n",
       "                       24.5646, 25.9001, 15.3133, 19.3552, 21.6175,  9.0542, 22.2412, 15.1988,\n",
       "                        6.7641, 17.1693, 23.0440,  5.8231,  6.8925, 10.3310, 16.7413, 15.4752,\n",
       "                       15.6510, 16.4781, 20.7925, 35.9258, 13.2031, 10.9192, 23.5391, 19.5459,\n",
       "                       17.7848, 12.5372,  3.6360, 11.2511, 10.7330, 14.0641,  9.4343, 13.3173,\n",
       "                       31.3042, 20.5273, 27.5875, 12.0333, 20.2981, 13.8537, 11.4676, 14.6925,\n",
       "                       16.4561, 14.0791, 15.1365,  6.3850,  7.7605, 27.7311, 18.7079, 18.9606,\n",
       "                       37.4239, 24.0474, 12.9374, 19.4589, 20.7373, 21.8877,  7.4155, 18.6823,\n",
       "                       22.3549, 14.1555, 25.8358, 15.2212, 22.2576,  8.2511,  6.0334,  4.6805],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block4.bn2.weight',\n",
       "               tensor([0.8692, 1.0196, 0.9362, 0.9131, 1.0375, 1.0444, 1.0132, 1.0092, 1.0608,\n",
       "                       1.0743, 1.0304, 1.1891, 1.0405, 1.0412, 1.0269, 0.9653, 1.0626, 1.0576,\n",
       "                       1.0416, 1.0394, 1.0032, 0.9530, 1.0887, 1.1196, 1.2284, 1.1845, 1.2006,\n",
       "                       1.0038, 0.9120, 0.9737, 1.0074, 1.0234, 0.9587, 0.9566, 1.1203, 1.0380,\n",
       "                       1.2199, 1.0974, 1.0536, 0.7612, 0.9293, 1.2127, 1.0957, 1.0487, 1.0060,\n",
       "                       0.9303, 1.1301, 0.9962, 0.9253, 0.9390, 1.0552, 1.0215, 0.6022, 1.1631,\n",
       "                       1.0075, 0.9166, 1.1436, 1.1242, 0.9639, 0.8867, 0.8757, 1.0242, 1.0773,\n",
       "                       1.0337, 1.0872, 0.9788, 0.9669, 0.9332, 0.7769, 1.0834, 1.1052, 1.0670,\n",
       "                       1.2093, 1.0479, 0.8535, 1.0409, 1.0113, 0.8261, 0.9043, 1.0220, 1.0291,\n",
       "                       1.0649, 0.9358, 1.2345, 0.9310, 0.9950, 1.1893, 1.0115, 0.7559, 1.0712,\n",
       "                       1.0209, 0.9954, 0.8501, 1.0186, 1.1557, 0.9994, 0.9954, 1.0819, 1.0597,\n",
       "                       1.0474, 1.0162, 0.9761, 0.9244, 0.9922, 0.9519, 1.1067, 0.9372, 0.9337,\n",
       "                       1.1715, 1.0161, 1.0217, 1.0195, 1.1220, 1.0149, 1.1270, 1.1602, 0.9379,\n",
       "                       1.0706, 1.1358, 1.0445, 0.9419, 1.0347, 0.9873, 1.0045, 0.9723, 1.0441,\n",
       "                       0.8574, 1.0103, 1.0524, 0.9981, 0.9770, 1.0063, 1.0351, 1.0704, 1.0712,\n",
       "                       1.1775, 1.0923, 1.0152, 1.0871, 1.0963, 0.9691, 1.0647, 0.6194, 1.0080,\n",
       "                       1.0311, 1.1069, 0.9379, 1.0183, 1.0397, 0.9723, 1.0926, 0.9570, 1.1201,\n",
       "                       0.6124, 1.0335, 1.0131, 1.0401, 1.0126, 0.9381, 1.0591, 1.0451, 0.6448,\n",
       "                       1.2713, 0.8568, 1.0401, 0.9968, 0.9266, 0.9932, 1.0042, 1.0146, 0.9523,\n",
       "                       1.0785, 1.0504, 1.0440, 0.8292, 1.0258, 0.8946, 1.0836, 0.9695, 1.1255,\n",
       "                       1.0539, 1.0798, 1.0433, 0.9571, 1.0015, 1.0899, 0.9283, 1.0606, 0.9519,\n",
       "                       0.7614, 0.7617, 0.9541, 1.1838, 0.9471, 1.0733, 1.1440, 1.0788, 1.0504,\n",
       "                       0.9725, 0.7654, 1.0277, 0.7071, 0.9312, 1.0306, 1.0887, 1.1121, 0.9629,\n",
       "                       1.0552, 1.0747, 1.1719, 0.8791, 1.0809, 1.0920, 0.8258, 1.0560, 0.9856,\n",
       "                       1.0623, 0.8904, 0.9770, 0.9496, 1.1909, 0.8231, 0.9825, 0.9999, 1.0781,\n",
       "                       1.0322, 0.9479, 0.6987, 1.0529, 0.9777, 1.0731, 1.0085, 1.0309, 0.9760,\n",
       "                       1.1300, 1.0308, 0.9500, 0.8970, 1.0981, 0.9828, 1.0356, 1.0897, 1.0457,\n",
       "                       1.1373, 1.0823, 1.0683, 1.1204, 1.0674, 1.1082, 1.0366, 1.0477, 0.7976,\n",
       "                       1.0946, 1.0202, 0.9869, 0.9141, 0.9358, 1.0071, 1.0090, 0.9882, 1.2007,\n",
       "                       0.9805, 0.9280, 0.9648, 1.1031, 1.0952, 1.0682, 0.9051, 0.9703, 0.9847,\n",
       "                       1.0507, 1.0302, 1.0373, 1.0126, 1.1133, 0.9373, 1.0751, 1.0259, 0.8999,\n",
       "                       0.9758, 1.0634, 0.9822, 0.9974, 1.1841, 1.0385, 0.9460, 1.0757, 1.0571,\n",
       "                       0.8684, 0.7430, 1.0869, 1.0043, 0.8735, 0.9567, 1.0572, 1.0317, 1.0294,\n",
       "                       1.0523, 1.0352, 1.0453, 1.1801, 1.1518, 1.0357, 1.0031, 1.0059, 1.0505,\n",
       "                       0.8497, 0.8277, 0.7445, 1.0762, 1.0021, 1.1202, 1.0641, 0.9924, 1.1110,\n",
       "                       1.0767, 0.9756, 1.0253, 1.1018, 0.9259, 0.9461, 1.0254, 1.0322, 0.9632,\n",
       "                       1.0843, 0.8916, 0.8301, 1.1465, 0.9954, 0.9512, 0.9322, 0.9779, 0.9065,\n",
       "                       0.9694, 0.5169, 1.1076, 1.0327, 0.9517, 1.1000, 0.9666, 0.9286, 0.9862,\n",
       "                       1.1279, 0.9118, 0.9248, 0.8618, 0.8209, 0.7729, 0.9371, 0.8842, 0.9992,\n",
       "                       1.0429, 1.0914, 0.8012, 1.0192, 1.0117, 1.0623, 1.0231, 1.0377, 1.1539,\n",
       "                       0.8518, 0.6366, 1.0854, 0.9593, 0.9821, 0.8839, 1.2614, 0.9315, 0.8245,\n",
       "                       0.9191, 1.0720, 0.9815, 0.7630, 1.0368, 1.0000, 1.0597, 0.9025, 1.0035,\n",
       "                       1.1145, 0.9382, 1.0012, 0.9382, 0.9492, 1.0129, 0.7285, 1.0805, 0.9569,\n",
       "                       1.0730, 1.0464, 0.8662, 0.5841, 0.9371, 0.7384, 0.9628, 1.1045, 0.9737,\n",
       "                       1.0557, 1.1154, 1.1908, 0.9917, 0.9906, 0.7624, 1.0398, 0.9751, 1.0418,\n",
       "                       1.0149, 0.8918, 0.9710, 0.9319, 0.9814, 0.9381, 0.9196, 1.1777, 1.0211,\n",
       "                       1.0665, 0.9604, 1.0621, 1.0200, 0.8991, 0.9888, 0.8206, 1.0428, 1.0212,\n",
       "                       1.0214, 1.0759, 1.0050, 0.9450, 0.9638, 1.0861, 1.0789, 0.9607, 0.7226,\n",
       "                       0.8935, 1.0180, 0.9566, 1.1027, 0.9531, 0.9753, 1.1532, 1.0002, 0.9920,\n",
       "                       1.0342, 0.9385, 0.8641, 0.9388, 0.9327, 1.0506, 1.0106, 1.0389, 0.9956,\n",
       "                       1.0707, 1.0160, 1.1350, 1.1605, 0.9819, 0.9502, 1.0184, 1.0517, 1.0610,\n",
       "                       1.0803, 0.9218, 0.9971, 1.0046, 1.0675, 0.9909, 1.1060, 0.7715, 1.0106,\n",
       "                       0.9804, 1.0199, 1.0249, 1.0042, 1.0969, 0.8566, 1.0517, 0.6326, 1.0388,\n",
       "                       1.0691, 1.0669, 0.9527, 1.0403, 1.0416, 0.7403, 1.1037, 1.0038, 1.0177,\n",
       "                       0.5930, 0.9599, 1.0896, 0.9358, 0.9490, 0.9979, 1.0591, 0.9622, 0.9875,\n",
       "                       0.9553, 1.0062, 1.0119, 1.1283, 1.0414, 1.0745, 1.0687, 0.8101, 1.0115,\n",
       "                       1.1221, 1.0903, 0.9864, 1.1624, 1.0129, 1.0907, 0.9775, 0.7475],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn2.bias',\n",
       "               tensor([-0.6357, -0.8527, -0.7240, -0.7183, -0.9574, -0.9813, -0.7130, -0.8558,\n",
       "                       -0.8158, -0.8945, -0.7349, -0.9749, -1.0785, -0.7781, -0.8201, -0.7343,\n",
       "                       -1.2163, -0.9349, -0.9170, -0.7448, -0.8741, -0.8969, -1.0082, -0.9573,\n",
       "                       -1.1156, -1.2825, -1.2379, -0.9295, -0.6968, -1.0297, -0.9719, -0.8778,\n",
       "                       -0.6440, -0.7050, -1.0121, -1.0072, -1.1827, -0.8992, -0.8494, -0.6630,\n",
       "                       -0.6907, -1.1151, -0.9045, -1.0034, -0.8512, -0.8988, -1.0106, -0.6670,\n",
       "                       -0.6949, -0.8435, -1.0474, -0.8233, -0.4661, -1.0223, -0.9171, -0.9080,\n",
       "                       -1.1544, -1.0028, -1.1745, -0.8494, -0.5735, -1.0519, -0.8442, -0.8575,\n",
       "                       -1.1057, -0.8953, -0.8886, -0.8457, -0.5678, -1.0093, -0.9063, -0.9730,\n",
       "                       -1.3149, -0.9343, -0.6227, -0.9176, -0.9047, -0.6808, -0.7603, -0.9709,\n",
       "                       -0.9282, -1.0250, -0.7901, -1.1732, -0.9183, -0.8938, -1.0894, -0.7654,\n",
       "                       -0.7095, -1.1964, -0.8708, -0.8142, -0.8661, -0.9949, -1.1258, -0.9737,\n",
       "                       -0.7671, -0.9461, -0.8957, -0.9559, -0.8173, -0.8774, -0.8777, -0.9807,\n",
       "                       -0.6896, -0.9080, -0.7666, -0.7901, -0.9920, -1.0560, -0.9186, -0.8876,\n",
       "                       -0.9487, -0.8476, -0.9140, -1.0839, -0.7586, -1.0032, -1.0627, -0.9870,\n",
       "                       -0.6890, -0.7998, -0.8275, -0.7153, -0.7468, -0.9308, -0.5439, -0.7082,\n",
       "                       -0.9491, -0.8077, -0.7686, -0.8005, -1.1216, -1.0302, -0.8449, -1.2532,\n",
       "                       -1.0404, -0.8978, -0.8028, -1.0356, -0.8640, -0.9739, -0.3478, -0.7908,\n",
       "                       -1.0078, -1.0894, -0.6264, -0.9284, -0.8441, -0.6705, -0.9099, -0.6895,\n",
       "                       -1.0781, -0.4041, -0.9598, -0.9002, -0.8591, -0.8593, -0.9035, -0.9717,\n",
       "                       -0.8061, -0.4209, -1.1186, -0.6594, -0.9079, -0.8793, -0.6905, -0.7890,\n",
       "                       -0.7763, -0.8181, -0.7768, -0.9247, -1.1757, -0.9052, -0.6392, -0.9119,\n",
       "                       -0.8816, -1.1514, -0.6032, -1.1121, -1.0446, -0.9701, -0.9160, -0.7903,\n",
       "                       -0.9031, -0.9186, -0.8806, -0.9007, -0.8075, -0.5293, -0.7690, -0.7966,\n",
       "                       -1.0551, -0.7402, -0.9771, -1.1216, -1.0144, -0.7270, -0.8152, -0.4969,\n",
       "                       -0.9188, -0.5080, -0.6954, -0.8943, -0.9111, -0.9846, -0.7691, -0.7996,\n",
       "                       -0.9310, -0.9318, -0.7881, -1.0120, -1.1179, -0.6427, -0.8588, -0.8852,\n",
       "                       -0.9369, -0.6432, -0.8372, -0.7708, -1.0399, -0.5446, -0.8622, -1.0342,\n",
       "                       -1.0385, -0.9053, -0.7958, -0.5640, -1.0736, -0.7351, -0.9306, -0.7655,\n",
       "                       -0.9475, -0.9423, -1.0223, -0.8780, -0.8575, -0.8953, -1.0348, -0.9474,\n",
       "                       -1.0599, -0.8597, -0.9905, -0.8517, -0.8602, -1.0753, -0.9481, -1.0397,\n",
       "                       -0.9873, -0.9807, -0.9107, -0.8368, -0.9407, -0.9491, -0.9919, -0.6827,\n",
       "                       -1.0033, -0.8495, -0.9439, -0.7659, -0.9812, -0.7008, -0.6716, -0.7872,\n",
       "                       -0.7998, -0.9925, -0.7968, -0.6551, -0.9045, -0.9280, -1.0423, -0.9507,\n",
       "                       -0.8546, -0.7400, -1.2037, -0.9359, -0.8926, -0.8114, -0.8905, -0.9073,\n",
       "                       -0.9369, -0.8521, -0.9964, -0.9729, -0.9072, -0.6744, -0.9125, -0.8992,\n",
       "                       -0.6318, -0.5347, -0.9464, -1.0394, -0.8523, -0.7701, -0.8907, -0.9499,\n",
       "                       -1.0483, -0.9705, -0.9066, -0.9237, -1.2272, -1.3275, -0.8460, -0.7763,\n",
       "                       -0.6645, -0.9437, -0.4811, -0.6286, -0.5974, -0.9572, -0.8808, -0.9409,\n",
       "                       -0.9350, -0.8788, -0.9325, -0.9302, -0.9094, -0.8218, -1.0726, -0.7214,\n",
       "                       -0.9896, -0.8111, -1.0361, -0.7955, -0.7910, -0.7099, -0.6057, -0.9668,\n",
       "                       -0.8110, -0.9454, -0.8162, -0.7066, -0.6406, -0.9381, -0.2838, -1.2096,\n",
       "                       -0.8564, -0.9551, -1.0171, -0.8412, -0.7527, -0.7537, -0.9505, -0.7497,\n",
       "                       -0.8901, -0.6481, -0.7140, -0.4668, -0.8714, -0.9210, -1.0737, -0.9736,\n",
       "                       -0.9253, -0.8462, -0.9520, -0.7971, -1.1652, -0.9690, -0.9288, -0.8844,\n",
       "                       -0.7713, -0.4085, -0.9273, -0.7709, -0.9965, -0.7296, -1.0591, -0.8909,\n",
       "                       -0.6816, -0.7582, -0.8895, -1.0022, -0.4112, -0.9052, -0.8330, -0.7699,\n",
       "                       -0.6271, -0.7419, -0.9814, -0.8401, -0.8756, -0.7851, -0.8853, -0.9722,\n",
       "                       -0.4361, -1.0040, -0.8905, -0.9258, -0.8468, -0.6977, -0.3273, -0.7692,\n",
       "                       -0.5724, -0.7710, -0.9961, -0.9429, -1.0810, -1.0256, -1.0846, -0.8732,\n",
       "                       -0.8395, -0.6623, -0.7299, -0.7672, -1.0518, -0.8442, -0.7411, -1.0576,\n",
       "                       -1.0265, -0.9971, -0.9094, -0.6428, -1.1716, -0.7394, -0.8364, -0.8228,\n",
       "                       -0.9271, -0.7503, -0.7941, -0.9165, -0.6003, -0.7904, -0.8405, -1.0136,\n",
       "                       -0.8585, -0.9383, -0.6179, -0.9837, -1.0112, -0.8642, -0.8000, -0.4619,\n",
       "                       -0.7208, -0.9207, -0.8988, -0.8371, -0.9391, -0.8320, -0.9519, -0.8000,\n",
       "                       -0.8909, -0.9169, -0.8799, -0.7483, -0.7430, -0.9219, -0.8550, -0.8171,\n",
       "                       -0.7724, -0.8056, -0.8571, -0.8749, -1.1316, -1.0753, -1.0479, -0.9392,\n",
       "                       -0.8136, -0.8701, -0.9236, -0.9709, -0.8798, -0.6883, -0.9078, -0.9579,\n",
       "                       -0.9275, -1.1071, -0.5766, -0.9774, -0.8089, -0.9832, -1.1391, -0.9514,\n",
       "                       -0.9571, -0.8613, -0.9184, -0.5020, -1.0454, -0.9861, -0.8187, -0.9366,\n",
       "                       -0.9146, -0.9690, -0.4672, -1.0258, -0.9856, -0.9362, -0.3431, -0.7617,\n",
       "                       -0.8894, -0.7865, -0.8302, -0.9095, -0.8643, -0.8991, -0.9230, -0.7429,\n",
       "                       -0.7601, -0.8827, -1.0443, -0.8199, -0.9924, -0.9508, -0.6007, -0.8046,\n",
       "                       -0.9269, -0.9579, -0.7895, -0.9726, -0.8318, -1.0327, -0.9359, -0.5078],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn2.running_mean',\n",
       "               tensor([ -7.0704,  -9.1402,  -7.7512, -11.1341,  -9.7865, -10.2807,  -9.2352,\n",
       "                       -11.5114, -11.2539, -11.2583, -10.6623, -12.7442,  -9.5280, -10.9777,\n",
       "                        -9.3166,  -9.5266, -10.3923,  -9.1503, -11.8856, -12.7874,  -9.3444,\n",
       "                        -8.8380, -11.3720, -10.5587, -14.1978,  -8.0652, -12.6958, -13.7487,\n",
       "                        -5.7113,  -6.2154, -13.2550, -13.7632,  -7.7563,  -8.4884, -15.6846,\n",
       "                       -12.8679, -12.5408, -10.1373, -11.0303,  -8.8317,  -8.6962, -11.2265,\n",
       "                       -13.3940, -12.6671, -10.5173, -11.1147,  -9.7191,  -9.3235, -10.5189,\n",
       "                        -9.2362,  -9.7928, -11.5436,  -5.3139, -11.4657,  -8.1820,  -9.7276,\n",
       "                       -12.8487, -12.4356, -11.3890,  -8.5416,  -7.0600, -12.1388,  -9.2885,\n",
       "                       -10.2390,  -8.3354,  -8.1266,  -7.4188,  -9.0289,  -6.1786, -13.6227,\n",
       "                       -11.5395,  -8.3719, -11.4114,  -9.3470, -10.4304, -11.7534,  -6.6131,\n",
       "                        -6.4860,  -7.7830, -14.2819,  -9.1729,  -9.4956,  -8.8200, -14.3914,\n",
       "                        -9.2733,  -9.3520, -13.5086,  -8.6649,  -7.7513, -12.5135, -13.1946,\n",
       "                       -12.8133,  -7.7209, -10.5792, -14.4326, -11.0646,  -9.8393, -13.3821,\n",
       "                       -10.0047, -10.6789, -11.1940,  -8.6306, -14.4514, -11.5956,  -9.7265,\n",
       "                       -15.0767, -12.2830, -10.7356,  -9.0361,  -6.8977,  -8.7512,  -9.1303,\n",
       "                        -8.6288,  -8.0765, -10.9246, -12.0117, -10.5883,  -8.1081, -12.3401,\n",
       "                       -12.3190, -12.3612, -11.6358,  -8.5028,  -9.4126, -12.0485,  -6.3837,\n",
       "                       -11.4244, -10.0863, -15.5683,  -9.1223, -12.6953, -11.5748,  -8.9412,\n",
       "                       -11.3644,  -8.8625, -12.2167, -11.1881,  -7.3360,  -8.7879, -10.7554,\n",
       "                        -7.0423, -11.7585,  -8.4510,  -9.6842, -10.4855,  -7.7066,  -6.3143,\n",
       "                        -9.5375,  -8.0087,  -9.2176, -12.3142,  -7.4595, -11.3879,  -4.9095,\n",
       "                        -7.0090, -10.2986, -12.8484,  -7.3264, -10.5119, -10.7336, -10.8010,\n",
       "                        -8.6696, -17.8151,  -9.2606,  -9.9283, -11.1807,  -7.9112,  -6.7784,\n",
       "                       -10.9137,  -8.0106,  -6.9620, -11.6688,  -9.5805,  -8.5959,  -9.7636,\n",
       "                        -8.5198, -12.2389,  -9.1478,  -8.1453, -12.4756,  -9.4083,  -7.3629,\n",
       "                       -13.1045,  -9.6270,  -9.6665,  -9.8933,  -7.9381, -10.6922,  -9.2425,\n",
       "                        -7.8954,  -9.3268, -11.8413, -13.3432, -10.3631, -10.5183, -10.0359,\n",
       "                        -9.9202,  -7.8625,  -8.1335,  -8.9402, -11.4192,  -5.9625,  -9.5392,\n",
       "                        -7.0874,  -8.0605,  -9.4473, -11.1855, -12.7950, -10.7949, -12.3419,\n",
       "                        -7.6562, -14.0854, -10.3612,  -9.8623, -10.4224,  -9.1409, -14.9591,\n",
       "                       -11.8854,  -8.6520, -10.1927, -11.4755, -10.1710,  -9.4750,  -7.7925,\n",
       "                       -10.2812, -12.2564,  -7.7537,  -6.6620, -10.8340, -10.4059, -11.9272,\n",
       "                       -11.0039, -12.3004, -10.3599,  -8.9955, -12.5240, -11.8692,  -9.8073,\n",
       "                       -10.7393, -10.6546, -12.2049, -10.8643, -10.2018, -11.6912, -11.3565,\n",
       "                        -9.4278, -12.8465,  -9.0102, -13.0422, -11.7360, -11.8573,  -9.6732,\n",
       "                       -13.5239, -11.4994, -11.8104,  -8.9863,  -9.1722,  -9.2032,  -9.9717,\n",
       "                       -11.1541,  -9.3149, -10.5394,  -9.8313,  -7.8685, -14.3521, -11.8711,\n",
       "                        -8.4968,  -6.1572, -12.4332,  -7.9072,  -9.5356,  -8.9708,  -7.0380,\n",
       "                       -14.7917, -13.4908,  -7.9742, -10.2905, -10.6549,  -9.9388,  -9.2936,\n",
       "                       -13.1623, -11.8600, -10.0409, -10.6516,  -7.1750,  -8.7823,  -9.1282,\n",
       "                       -11.7259, -12.0622,  -8.9568,  -8.7477, -12.5159,  -8.3625,  -9.3127,\n",
       "                       -10.3506,  -8.5225,  -8.0484, -11.9778,  -7.7152, -12.3258, -11.5251,\n",
       "                       -10.6074,  -9.3330, -11.6243,  -7.4509, -12.0330,  -8.5127,  -9.2744,\n",
       "                        -8.0115,  -8.7962, -11.2252,  -7.7782, -10.5103, -10.7580, -14.4433,\n",
       "                       -12.4094, -12.7848, -11.1887, -11.2455,  -8.8453,  -8.7306, -10.3607,\n",
       "                       -10.7794,  -7.5537, -10.0302, -12.2000,  -8.8585, -13.6904, -10.2506,\n",
       "                       -12.8044, -11.9870,  -8.5768, -10.6659, -11.1175,  -5.8667, -11.2665,\n",
       "                        -9.6447, -12.2697,  -7.1850, -11.4209,  -4.9475, -11.3445, -11.0180,\n",
       "                       -10.6976, -12.0633,  -9.4174, -10.2803,  -9.7666,  -8.6389, -12.2479,\n",
       "                        -8.8226, -16.4966, -12.9197, -10.8278, -10.5766,  -8.5228, -10.4537,\n",
       "                       -14.5190, -12.3608, -10.0704,  -7.2365,  -8.9748,  -8.5510, -13.3488,\n",
       "                        -6.3004,  -4.8657,  -9.5620, -11.1047, -10.6984, -12.2717,  -8.1002,\n",
       "                       -12.3814,  -6.1011, -10.1579, -11.3373,  -8.9346,  -7.1032, -10.6421,\n",
       "                        -8.5353,  -8.8176,  -8.6552, -10.7790, -11.1876,  -8.9152,  -8.6046,\n",
       "                       -10.1903, -13.3491, -10.9219, -11.4192,  -8.0122,  -5.0803,  -7.1907,\n",
       "                        -9.2910,  -6.4443, -11.2285, -11.1397, -11.4683,  -9.4067,  -9.7184,\n",
       "                        -8.4264,  -9.8142,  -5.1804, -14.5606, -12.8593, -11.3980,  -9.0743,\n",
       "                       -13.2523,  -9.1607, -11.2102,  -7.6098,  -9.4769,  -9.2939,  -9.0630,\n",
       "                       -10.9464, -12.5919, -11.1671,  -8.9951,  -8.9873, -10.7743,  -9.5763,\n",
       "                        -8.8532,  -6.3426, -11.5980,  -9.5338, -11.9581, -10.1507,  -7.6085,\n",
       "                        -7.8964, -16.3195,  -7.9698, -11.2983,  -6.1035, -10.8961, -14.8799,\n",
       "                        -8.5117,  -9.6699,  -6.9834,  -9.0393, -10.1701, -11.1316, -10.9523,\n",
       "                        -8.6811, -11.9509, -12.3365,  -8.9529,  -8.8247, -11.8243, -13.2038,\n",
       "                       -10.8081,  -7.0179, -11.2472, -10.8153, -11.1608, -14.5949, -10.3344,\n",
       "                        -9.6759, -10.2307,  -9.8480, -15.7847, -10.8683,  -5.9520, -10.4720,\n",
       "                        -8.1118,  -8.9037,  -9.4431, -11.0172, -11.3063, -10.3130, -10.1860,\n",
       "                       -14.6933,  -9.0615, -10.6036, -11.3590,  -8.2459,  -7.5740,  -5.9723,\n",
       "                       -12.3277, -11.0075, -14.9161,  -9.8716,  -8.6900,  -9.5916,  -5.1327,\n",
       "                        -9.1199, -12.2774, -10.8230,  -6.6812,  -8.3982,  -9.7224,  -8.3312,\n",
       "                        -6.6135, -11.8535, -12.5668,  -9.0417,  -7.1228, -10.2076,  -8.1796,\n",
       "                        -8.7434, -15.6028, -10.1699, -12.5138,  -9.8046, -11.9482,  -9.7467,\n",
       "                       -11.5575, -10.9710,  -5.8092, -10.2086, -11.6999, -10.3494, -15.2646,\n",
       "                        -7.8103], device='cuda:0')),\n",
       "              ('conv_block4.bn2.running_var',\n",
       "               tensor([119.5330, 111.5851, 105.8014, 194.3960, 145.1584, 151.1561, 170.7872,\n",
       "                       168.1288, 169.7325, 246.5773, 183.6257, 201.1760,  90.3726, 235.3835,\n",
       "                       136.1833, 151.5590, 101.7934,  94.6865, 159.6302, 232.4375,  98.5792,\n",
       "                        93.2172, 166.5209, 154.0410, 183.5350,  73.4258, 103.5562, 228.6407,\n",
       "                        65.5826,  34.5725, 184.1561, 244.0851, 165.4411, 139.0002, 209.6452,\n",
       "                       160.1482, 166.1909, 149.4473, 197.4758,  98.0435, 122.8118, 115.8345,\n",
       "                       191.0247, 147.4830, 144.7492, 102.1568, 111.2490, 178.6992, 177.2030,\n",
       "                        91.5468,  92.0047, 178.1482, 100.3087, 138.4312,  77.9875,  88.8078,\n",
       "                       142.7540, 176.0923,  75.0477, 113.5099, 117.4905,  93.1809, 104.7753,\n",
       "                       177.5880,  54.8149, 112.3250,  53.3386, 124.4382,  84.0634, 165.6850,\n",
       "                       164.8729, 100.4674, 109.0026, 107.4236, 151.6819, 193.3995,  55.3059,\n",
       "                       106.1447,  84.0162, 209.6905, 126.8873, 106.6894, 127.1495, 166.2238,\n",
       "                        64.3243, 171.6260, 167.2073, 121.4679,  67.4339, 137.6332, 173.0528,\n",
       "                       252.8767, 100.0092, 127.1863, 139.5112,  84.4245, 186.3425, 247.4683,\n",
       "                       146.9553, 155.3842, 137.5345,  75.3665, 207.3246, 126.8592, 214.1089,\n",
       "                       209.7989, 148.8357, 182.2472, 100.6449,  49.5003, 100.7825,  93.1085,\n",
       "                        71.4692,  83.5189, 136.7704, 158.8071, 147.4560,  93.2384, 131.4757,\n",
       "                       137.1293, 202.9832, 152.5964, 108.1116, 216.2217, 239.0280,  76.2350,\n",
       "                       140.5914, 153.3451, 260.5764, 172.4119, 169.4218, 197.7206,  80.6323,\n",
       "                       101.7465, 104.0214, 106.3632, 113.2930,  57.2918, 113.4499, 126.2890,\n",
       "                        72.6041, 137.7473, 211.8665,  87.2345,  82.5531,  80.0018, 108.3961,\n",
       "                        97.3852, 104.7040, 240.5546, 190.8302, 114.5864, 130.0359,  90.7443,\n",
       "                        64.4102, 139.4491, 165.0707,  84.4786,  95.4657, 101.3506, 175.5658,\n",
       "                       131.7360, 281.9009, 146.9190, 150.1954, 161.3970, 109.4073,  95.7615,\n",
       "                       182.3277,  96.4348,  73.4839, 115.9752,  99.4877, 137.9911, 166.9402,\n",
       "                        91.8582, 125.5850,  95.9300, 185.0470, 132.8921,  63.0050,  94.5155,\n",
       "                       174.8960, 150.6762,  76.0643, 121.6214,  64.4462, 157.4700, 121.1129,\n",
       "                       109.1967,  90.4049, 124.2251, 240.2950, 145.4362, 115.4441,  83.2565,\n",
       "                        92.3168, 167.5009,  89.1367, 160.1980, 179.0705, 108.8378, 124.8380,\n",
       "                        62.1686,  86.0124, 159.5369, 188.2807, 239.6436, 194.1266, 152.7062,\n",
       "                        91.3488, 181.7483, 103.0574, 125.0780, 102.0396,  76.1436, 230.8262,\n",
       "                       159.3068, 131.1642, 183.1092, 154.2262, 284.9601, 109.3947,  50.4844,\n",
       "                        77.8616, 153.9754,  98.7566, 124.5419,  93.7722, 167.6795, 185.0094,\n",
       "                       200.0618, 179.7574,  87.7052,  76.7539, 136.9572, 161.2445,  76.2044,\n",
       "                       123.4741,  98.5624, 123.3278, 201.6077, 105.0393, 207.5891, 177.8371,\n",
       "                        79.6234, 183.8452,  76.3404, 190.6858, 128.7299, 186.1456,  79.0408,\n",
       "                       194.2552, 167.2675, 143.1439, 208.0128,  93.1392, 134.3249,  97.7061,\n",
       "                       131.9269, 134.8008, 234.3669, 289.1217,  83.8410, 243.2776, 166.5899,\n",
       "                       138.5753,  93.8360, 135.3104, 102.1121, 130.6812,  88.0845,  87.4273,\n",
       "                       354.1793, 120.9376,  49.8033, 108.2608, 191.9858,  83.2218, 124.6435,\n",
       "                       198.9207, 151.3005, 114.5484, 187.6745,  80.2599, 128.1988, 115.1032,\n",
       "                       290.1814, 238.4541, 149.8992, 125.2472, 111.4082,  72.5357, 121.9289,\n",
       "                       138.8316, 105.3264,  81.6092, 150.1974,  96.3888, 165.7158, 101.1007,\n",
       "                        66.8240, 127.8578, 161.8440, 107.5237, 163.1043, 186.2200, 122.2260,\n",
       "                       129.0678,  98.6127, 102.1676,  73.6693, 138.8832, 144.4659, 208.6830,\n",
       "                       176.8513, 120.0968, 162.8605, 143.4462, 162.6996,  69.2330, 128.3018,\n",
       "                       133.2198, 112.4777, 174.3360, 258.6885, 207.6651, 204.3252, 165.8202,\n",
       "                       132.7782, 156.4254, 125.7472, 294.2368, 126.8540, 155.4616,  79.2299,\n",
       "                       123.1838, 105.4637,  66.7107, 156.1684,  70.9858, 182.2789, 158.8055,\n",
       "                       186.7225, 146.6785, 152.9809,  99.1145, 168.4443,  83.2520, 137.6243,\n",
       "                        68.5944, 237.3921, 201.5072, 105.9986, 118.1479, 134.5408,  87.5844,\n",
       "                       242.6606, 172.6103, 138.2726,  75.9145, 133.1461,  86.2201, 310.4858,\n",
       "                        45.1279,  77.7772, 123.9231, 114.0875, 139.8184, 162.8016, 140.3397,\n",
       "                        96.5330, 167.8691, 138.7544, 171.2143, 135.1889, 125.9986, 175.9455,\n",
       "                        81.4727,  89.3942,  81.5546, 122.4892, 134.6115,  83.5224,  94.3160,\n",
       "                       121.9861, 168.8695, 144.2761, 198.3965,  89.1466, 237.1340,  98.3379,\n",
       "                       186.9334,  59.1445, 144.5183, 105.5614, 113.5008, 122.7501, 101.8751,\n",
       "                        83.4345, 160.4523,  88.1170, 319.9019, 152.8835, 123.0919,  91.8793,\n",
       "                       199.7066,  96.4695,  98.2488,  60.2616,  92.5484, 172.1201,  80.0252,\n",
       "                       211.5920, 169.3102, 206.1817, 120.4552, 144.4899, 123.4716,  79.5671,\n",
       "                       113.1695,  83.3126, 222.6195,  83.9858, 176.4949, 132.8481, 148.8628,\n",
       "                        52.2881, 246.3003,  96.7397, 203.4213, 119.4787, 223.7660, 277.8627,\n",
       "                       124.3682, 131.0021,  59.6992, 108.7543, 137.5425, 206.7273, 142.7591,\n",
       "                        88.6648, 104.4339, 207.0668, 119.0594,  67.7863, 203.4793, 217.6955,\n",
       "                       184.5082,  83.2572, 108.5184, 182.4813, 112.8087, 159.0301, 109.1860,\n",
       "                        99.9105, 148.3253, 132.4963, 237.3271, 184.7216,  54.4456, 222.5535,\n",
       "                        95.5209,  95.9788,  83.0696, 104.1740, 256.7545, 112.8713, 214.7532,\n",
       "                       224.7012,  56.6445,  99.2389, 126.1396,  78.9249,  87.1820,  76.5859,\n",
       "                       144.2391, 131.5220, 268.1415,  70.4655, 139.8484,  78.6657,  99.4189,\n",
       "                       124.7197, 115.7797,  92.5335, 174.9718, 168.3002, 117.1443, 112.4444,\n",
       "                        84.0920, 159.9541, 203.4507,  80.1847,  81.9829, 186.1985, 118.6786,\n",
       "                       106.9935, 172.8516, 150.0677, 230.2883, 186.6628, 200.1913, 131.3280,\n",
       "                       185.2038, 122.9916, 113.0203, 149.2874, 144.6691, 110.0487, 158.8798,\n",
       "                       158.9126], device='cuda:0')),\n",
       "              ('conv_block4.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('fc1.weight',\n",
       "               tensor([[-0.0162,  0.2051,  0.1045,  ..., -0.0675,  0.0420,  0.0474],\n",
       "                       [-0.1089, -0.0935, -0.1332,  ...,  0.1064,  0.1283,  0.1095],\n",
       "                       [-0.0769,  0.1070, -0.0794,  ..., -0.1325, -0.1202, -0.0031],\n",
       "                       ...,\n",
       "                       [-0.2049,  0.0241, -0.2252,  ..., -0.5683,  0.1057,  0.0919],\n",
       "                       [-0.1168, -0.1704,  0.0327,  ..., -0.0705, -0.1603,  0.0641],\n",
       "                       [ 0.0408, -0.0130, -0.0847,  ..., -0.0846,  0.0335,  0.0355]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc1.bias',\n",
       "               tensor([ 0.5390,  0.5386,  0.0718, -0.2857,  0.0245, -0.0327,  0.7104,  0.5407,\n",
       "                       -0.0533, -0.3832, -0.0618,  0.0038,  0.7356, -0.0791, -0.0786,  0.4660,\n",
       "                       -0.0875,  0.3958,  0.8654,  0.0343,  1.0210,  0.1983,  0.5465,  0.6340,\n",
       "                       -0.2606, -0.1079,  0.5308,  0.7250,  0.8561,  0.0458, -0.0163,  1.4613,\n",
       "                        0.1459,  0.5657,  0.0974, -0.3957,  0.4825,  0.0538, -0.2921,  0.6931,\n",
       "                        0.3894,  0.0033,  0.6783, -0.0054, -0.4779, -0.1824,  0.5314, -0.4128,\n",
       "                        0.3976,  0.6597, -0.3526,  0.4103,  0.6220, -0.0259, -0.2060,  0.2368,\n",
       "                       -0.0545,  0.0995,  0.1890,  0.7222, -0.0065,  0.9948,  0.0051, -0.0179,\n",
       "                       -0.2542, -0.0503,  0.2423,  0.0585,  0.7288, -0.2077,  1.3685, -0.0125,\n",
       "                        0.0168,  0.5329,  0.5047, -0.3545,  0.8285,  0.9625,  0.4309,  0.0344,\n",
       "                        0.6676, -0.1120, -0.0795,  0.2257, -0.1322,  0.7685, -0.2873, -0.1637,\n",
       "                        0.7472, -0.2636, -0.6023,  0.1480, -0.2895,  0.3800,  0.3542,  0.0336,\n",
       "                       -0.1534, -0.0077, -0.2535,  0.7723,  0.7742,  0.0843,  0.4135,  0.5900,\n",
       "                        0.7188,  0.5165,  0.5607,  1.4848, -0.2240,  0.7909, -0.0338,  0.8326,\n",
       "                        0.0656,  0.0045,  0.2118, -0.0539,  0.0855,  0.6208,  0.0530, -0.1141,\n",
       "                        0.2065,  0.2361,  1.0296,  0.0438,  0.4333,  0.3641, -0.0523,  0.7411,\n",
       "                        0.6331,  0.6274,  0.6925, -1.2867,  0.8086,  0.0173, -0.1901, -0.3369,\n",
       "                       -0.0032,  0.1064,  0.5409,  0.0720,  0.2645, -0.0785,  0.0313, -0.2220,\n",
       "                        0.2901,  0.5120, -0.0407,  0.4435, -0.4844,  0.0249,  0.7821,  0.6862,\n",
       "                       -0.7986, -0.0193,  0.8213,  1.0957, -0.3831,  0.6909, -0.0031, -0.0315,\n",
       "                        0.3736,  0.5035, -0.3834,  0.0250, -0.4908,  0.6797,  0.2503,  0.0392,\n",
       "                        0.0334,  0.0328,  0.7076,  0.6202,  0.6192, -0.0043,  0.5458, -0.2643,\n",
       "                       -0.7342, -0.0907,  0.7569,  0.0824,  0.0046, -0.1082,  0.0774, -0.0584,\n",
       "                       -0.0353,  0.0615,  0.5795, -0.2930,  0.6952,  0.2286,  0.4080,  0.6492,\n",
       "                       -0.1935,  0.8778,  0.5847,  0.0619,  0.7006,  1.0230,  0.6471,  0.6449,\n",
       "                        0.0760,  0.0229, -0.0660,  0.1966,  0.0250,  0.9624, -1.0504,  0.0090,\n",
       "                        0.5280,  0.8886, -0.3967,  0.3304,  0.3099, -0.0214,  1.0731,  0.7956,\n",
       "                        0.8134,  0.2016,  0.6136, -0.2428,  0.1177,  0.4334,  0.0131,  0.8510,\n",
       "                        0.0610,  0.7948,  0.5155, -0.0663,  0.4911, -0.8763,  0.8510,  0.7228,\n",
       "                        0.8229, -0.0220,  0.0983,  0.0610,  0.6902,  0.1753,  0.7661,  0.0874,\n",
       "                       -0.0046,  0.4422,  0.0411,  1.0061, -0.2448,  0.2282,  0.4859, -0.0152,\n",
       "                       -0.8320,  0.3044,  0.3033,  0.2701,  0.6300,  0.2581,  0.9366, -0.3989,\n",
       "                       -0.0423, -0.0848,  0.7038,  0.3513,  0.8420, -0.0679,  0.0851,  0.1601,\n",
       "                        0.8619,  0.9919, -0.0899,  0.6976, -0.0237,  1.0497,  0.4629, -0.0838,\n",
       "                        0.8751,  0.1089,  0.0120,  0.4143, -0.0554,  0.4155,  0.1813,  0.3214,\n",
       "                       -0.0190,  0.9575, -0.6662,  0.0173,  0.8417,  1.0557,  0.6580,  1.0432,\n",
       "                        0.1036,  0.5181, -0.3942,  0.4714, -0.6981,  0.5184,  0.0654,  0.5405,\n",
       "                        0.5567,  0.0060, -0.0396, -0.5671,  0.0902,  0.5639, -0.6331,  0.1842,\n",
       "                        0.0451, -0.1490, -0.2121,  0.8105,  0.0405,  0.0342,  0.5684,  0.3533,\n",
       "                        0.0036,  0.4902,  0.1283,  0.4577, -0.0264, -0.2958,  0.6845,  1.0332,\n",
       "                        0.6011,  0.6495,  0.8831,  0.0350,  0.7828,  0.9590, -0.0278,  0.9186,\n",
       "                        0.6269, -0.0297,  0.1410,  0.7537,  0.0240,  0.0256,  0.4615,  0.7308,\n",
       "                        0.1071, -0.9078,  0.1964,  0.4996,  0.5870, -0.0044, -0.1103,  0.1263,\n",
       "                        1.8711,  0.6102,  0.1896,  0.5381, -0.6056,  0.0078,  0.6531, -0.2677,\n",
       "                        0.0208,  0.5778,  0.0198,  0.2121,  0.0217,  0.1653, -0.0612,  0.0035,\n",
       "                       -1.0666, -0.0879, -0.0541, -0.1329,  0.6626,  0.7638,  0.2922,  0.0853,\n",
       "                        0.5237,  0.2026, -0.0352, -0.1551,  0.0853,  0.6013,  0.9664, -0.2932,\n",
       "                       -0.0207,  0.1017,  0.3746,  0.6826, -0.0119,  0.5998,  0.0069,  0.7347,\n",
       "                        0.3851, -0.0292, -0.6627,  0.7156,  0.9222,  0.1129,  0.8253, -0.0920,\n",
       "                        1.9585,  0.2107,  0.7375,  0.6403,  0.0144,  0.0324, -0.0371,  1.0825,\n",
       "                        0.1428,  0.7617,  0.2419,  0.3425,  0.7588, -0.0280,  0.8388,  0.0687,\n",
       "                        0.6463,  0.2129,  1.0098, -0.0627,  0.7320,  0.6724, -0.5646,  0.6478,\n",
       "                        0.9435,  0.7642, -0.5676, -0.0020,  0.4888,  0.5415,  0.0286, -0.0444,\n",
       "                        0.3874,  1.0348,  0.8692, -0.1861, -0.4097, -0.4449, -0.0587,  0.1921,\n",
       "                        0.1430,  0.1148, -0.0817,  0.2384,  0.1298,  0.5131,  0.4706,  0.2027,\n",
       "                        0.5833,  0.4381,  0.6469,  0.8394,  0.4661,  0.2742,  0.0402,  0.5458,\n",
       "                        0.0116,  0.1196,  0.9895, -0.3875,  0.7393, -0.0311,  0.3565,  0.0899,\n",
       "                       -0.0582,  0.3803, -0.0535,  0.4975,  0.3216, -0.4744,  0.2178,  0.6991,\n",
       "                       -0.1516,  0.1003,  0.6228,  0.1111,  0.7130,  0.8505,  0.5158,  0.7247,\n",
       "                        0.3823, -0.0385,  0.8897, -0.0693,  0.1624,  0.7634,  0.7517,  0.0310,\n",
       "                       -0.1659, -0.0226,  0.1614, -0.0026,  0.5967,  0.6866, -0.0344, -0.0937,\n",
       "                        0.9474,  0.6435,  0.5628, -0.1668,  0.1525,  0.6969,  0.5165, -0.0336,\n",
       "                        0.9038,  0.1055,  0.7125,  0.6618,  0.8524,  0.0132, -0.0358,  0.5847,\n",
       "                        0.5924,  0.0588,  0.0119, -0.1043, -0.5310,  0.3961,  0.5049,  0.0200],\n",
       "                      device='cuda:0')),\n",
       "              ('fc_audioset.weight',\n",
       "               tensor([[-0.0073,  0.0060, -0.0283,  ...,  0.1203,  0.0217,  0.0070],\n",
       "                       [-0.0506, -0.0685, -0.0697,  ..., -0.4943, -0.0545, -0.0633],\n",
       "                       [-0.0703,  0.0848, -0.0423,  ..., -0.3457, -0.1200, -0.0484],\n",
       "                       ...,\n",
       "                       [-0.2180,  0.1204, -0.0582,  ..., -0.4413, -0.1044,  0.0347],\n",
       "                       [-0.1677, -0.0202,  0.0103,  ..., -0.2483, -0.0535,  0.0531],\n",
       "                       [ 0.0720, -0.0735, -0.0046,  ..., -0.1864, -0.0848, -0.0013]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc_audioset.bias',\n",
       "               tensor([-0.3537, -0.2475, -0.4678, -0.3557, -0.2614, -0.1378, -0.2048, -0.1257,\n",
       "                       -0.1749, -0.2945, -0.3129, -0.2637, -0.1914, -0.1700, -0.3302, -0.1657,\n",
       "                       -0.2608, -0.2377, -0.1867, -0.2388, -0.1955, -0.2924, -0.2105, -0.3577,\n",
       "                       -0.2468, -0.1999, -0.1309, -0.5515, -0.3622, -0.1173, -0.2123, -0.1828,\n",
       "                       -0.2515, -0.1763, -0.3372, -0.1570, -0.0807, -0.1679, -0.2259, -0.1356,\n",
       "                       -0.1636, -0.2332, -0.1912, -0.0908, -0.1744, -0.2277, -0.3101, -0.2606,\n",
       "                       -0.3547, -0.3004, -0.1540, -0.2947, -0.3089, -0.2579, -0.2052, -0.2061,\n",
       "                       -0.1698, -0.1022, -0.1111, -0.3086, -0.1498, -0.2120, -0.1458, -0.1753,\n",
       "                       -0.2398, -0.3907, -0.2612, -0.0982, -0.1615, -0.3293, -0.1837, -0.1444,\n",
       "                       -0.3892, -0.4273, -0.3540, -0.3073, -0.4383, -0.1952, -0.2886, -0.3588,\n",
       "                       -0.3360, -0.2398, -0.1421, -0.1347, -0.3262, -0.1405, -0.4570, -0.2578,\n",
       "                       -0.1269, -0.1527, -0.4155, -0.2492, -0.1334, -0.4670, -0.1903, -0.2552,\n",
       "                       -0.2842, -0.2360, -0.4018, -0.2526, -0.2655, -0.2518, -0.2827, -0.3671,\n",
       "                       -0.3984, -0.3830, -0.3744, -0.3047, -0.1646, -0.1996, -0.2509, -0.3250,\n",
       "                       -0.5594, -0.5244, -0.1877, -0.2838, -0.2151, -0.1936, -0.2393, -0.1575,\n",
       "                       -0.1752, -0.2057, -0.2905, -0.1186, -0.2225, -0.1959, -0.4943, -0.1772,\n",
       "                       -0.2159, -0.3115, -0.3668, -0.3608, -0.2743, -0.3169, -0.1906, -0.2425,\n",
       "                       -0.3258, -0.0824, -0.3836, -0.4122, -0.4331, -0.2660, -0.2795, -0.3327,\n",
       "                       -0.1466, -0.2250, -0.2795, -0.3054, -0.1550, -0.1840, -0.1815, -0.1592,\n",
       "                       -0.4298, -0.4890, -0.2363, -0.1592, -0.1590, -0.2616, -0.3309, -0.3767,\n",
       "                       -0.2094, -0.3770, -0.3146, -0.2613, -0.3801, -0.3506, -0.3313, -0.2533,\n",
       "                       -0.2320, -0.2512, -0.1647, -0.3419, -0.2479, -0.1421, -0.1017, -0.2116,\n",
       "                       -0.1598, -0.1726, -0.2312, -0.3537, -0.3291, -0.2786, -0.1483, -0.1008,\n",
       "                       -0.4618, -0.2376, -0.2810, -0.3911, -0.2135, -0.4936, -0.2967, -0.1877,\n",
       "                       -0.2395, -0.4240, -0.3124, -0.2018, -0.1087, -0.1425, -0.1351, -0.1676,\n",
       "                       -0.1632, -0.1270, -0.2043, -0.2486, -0.1300, -0.2162, -0.1435, -0.2751,\n",
       "                       -0.3062, -0.1338, -0.0713, -0.0956, -0.1972, -0.1580, -0.0643, -0.1403,\n",
       "                       -0.4107, -0.2211, -0.1588, -0.4987, -0.2738, -0.2291, -0.2731, -0.2987,\n",
       "                       -0.1822, -0.1467, -0.2558, -0.1972, -0.2504, -0.4129, -0.1368, -0.2726,\n",
       "                       -0.3382, -0.4004, -0.2259, -0.2899, -0.4035, -0.3396, -0.1842, -0.3142,\n",
       "                       -0.3869, -0.1684, -0.2231, -0.2617, -0.2228, -0.3131, -0.1719, -0.2044,\n",
       "                       -0.2608, -0.1847, -0.2231, -0.5349, -0.2338, -0.2676, -0.2062, -0.1604,\n",
       "                       -0.2111, -0.3981, -0.5671, -0.2596, -0.2773, -0.2150, -0.1242, -0.1820,\n",
       "                       -0.2427, -0.2429, -0.3614, -0.4391, -0.2054, -0.3485, -0.4412, -0.1954,\n",
       "                       -0.0835, -0.4123, -0.5304, -0.1837, -0.2821, -0.2137, -0.4026, -0.4592,\n",
       "                       -0.2952, -0.1925, -0.1274, -0.4139, -0.2321, -0.2406, -0.1972, -0.1861,\n",
       "                       -0.3665, -0.2442, -0.3615, -0.2871, -0.2453, -0.1878, -0.3397, -0.3027,\n",
       "                       -0.2172, -0.4743, -0.3484, -0.3001, -0.2101, -0.2944, -0.3144, -0.1834,\n",
       "                       -0.2437, -0.2355, -0.3975, -0.3203, -0.1148, -0.2099, -0.2535, -0.2963,\n",
       "                       -0.1439, -0.2473, -0.1720, -0.1529, -0.5164, -0.2371, -0.1876, -0.1773,\n",
       "                       -0.1149, -0.2334, -0.2916, -0.2899, -0.2943, -0.2745, -0.1975, -0.2519,\n",
       "                       -0.4191, -0.3885, -0.2116, -0.2630, -0.3070, -0.2339, -0.4336, -0.3425,\n",
       "                       -0.2274, -0.2695, -0.2546, -0.2056, -0.3684, -0.2268, -0.1964, -0.3175,\n",
       "                       -0.1842, -0.1835, -0.1965, -0.2230, -0.1884, -0.2829, -0.1854, -0.3985,\n",
       "                       -0.1619, -0.1548, -0.3096, -0.1665, -0.4278, -0.2216, -0.2344, -0.2738,\n",
       "                       -0.2025, -0.1480, -0.1634, -0.1746, -0.4287, -0.2180, -0.1856, -0.3711,\n",
       "                       -0.2545, -0.3254, -0.2575, -0.3963, -0.2103, -0.2107, -0.3120, -0.2376,\n",
       "                       -0.2510, -0.4727, -0.1735, -0.1642, -0.1472, -0.1427, -0.1937, -0.1302,\n",
       "                       -0.2861, -0.2194, -0.1853, -0.1560, -0.1799, -0.2459, -0.2076, -0.4442,\n",
       "                       -0.2122, -0.1669, -0.1696, -0.1358, -0.3067, -0.1089, -0.2226, -0.2297,\n",
       "                       -0.1976, -0.1133, -0.1483, -0.1591, -0.2220, -0.2332, -0.2406, -0.2138,\n",
       "                       -0.2284, -0.2109, -0.1738, -0.2394, -0.2299, -0.2842, -0.1720, -0.1865,\n",
       "                       -0.3023, -0.2254, -0.3218, -0.4740, -0.4103, -0.1863, -0.2450, -0.3028,\n",
       "                       -0.4664, -0.2292, -0.2503, -0.3617, -0.2133, -0.0949, -0.2192, -0.1527,\n",
       "                       -0.1928, -0.2296, -0.2942, -0.3051, -0.1859, -0.4133, -0.2166, -0.3207,\n",
       "                       -0.2160, -0.2232, -0.3179, -0.1327, -0.2912, -0.1611, -0.1601, -0.3654,\n",
       "                       -0.1933, -0.2057, -0.3190, -0.1902, -0.2419, -0.1603, -0.2589, -0.1674,\n",
       "                       -0.2111, -0.1031, -0.2695, -0.4614, -0.2496, -0.2255, -0.3635, -0.4138,\n",
       "                       -0.2433, -0.1642, -0.3051, -0.1986, -0.1814, -0.1407, -0.1998, -0.2335,\n",
       "                       -0.1610, -0.2577, -0.2172, -0.3175, -0.2816, -0.2251, -0.2851, -0.1637,\n",
       "                       -0.1873, -0.3904, -0.3235, -0.3839, -0.1854, -0.1589, -0.1304, -0.2944,\n",
       "                       -0.2398, -0.2792, -0.2389, -0.0767, -0.2468, -0.1448, -0.2242, -0.2961,\n",
       "                       -0.2477, -0.2238, -0.1844, -0.4480, -0.2059, -0.2270, -0.2432, -0.3335,\n",
       "                       -0.3057, -0.2527, -0.8537, -0.7422, -0.2719, -0.7250, -0.8501, -0.1985,\n",
       "                       -0.2027, -0.2493, -0.2233, -0.3995, -0.1986, -0.2389, -0.1356, -0.1837,\n",
       "                       -0.2550, -0.2296, -0.2841, -0.2581, -0.2493, -0.0848, -0.2910],\n",
       "                      device='cuda:0'))])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85049d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Transfer_Cnn10(freeze_base=True,pretrain_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d589a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:base.bn0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.bn0.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 1, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block4.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 256, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "#model parameter 확인\n",
    "for name, param in cnn.named_parameters(): \n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str = 'Hello world, Python!'\n",
    "if str.startswith('Hello'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6db15c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea5aab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer , fc 풀기\n",
    "for name, param in cnn.named_parameters():\n",
    "    if name.startswith('base.conv_block4'):\n",
    "        param.requires_grad=True\n",
    "    \n",
    "    #elif name.startswith('base.conv_block_after1'):\n",
    "    #    param.requires_grad=True\n",
    "   # \n",
    "    #elif name.startswith('base.fc'):\n",
    "    #    param.requires_grad=True\n",
    "    else:\n",
    "        param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1274d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_base=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70808b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn14,Transfer_Cnn14,init_layer\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, batch_size, dropout=0.5,pretrain_cnn=None,\n",
    "                 pretrain_emb=None,freeze_cnn=True):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.model_type = 'cnn10+transformer'\n",
    "        decoder_layers = TransformerDecoderLayer(d_model=nhid, nhead=nhead, dropout=dropout)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "        self.word_emb = nn.Embedding(ntoken, nhid)\n",
    "        self.ninp = ninp\n",
    "        self.nhid = nhid\n",
    "        self.fc = nn.Linear(512, 512, bias=True)\n",
    "        self.fc1 = nn.Linear(512, nhid, bias=True)\n",
    "        self.dec_fc = nn.Linear(nhid, ntoken)\n",
    "        self.batch_size = batch_size\n",
    "        self.ntoken = ntoken\n",
    "\n",
    "        #def __init__(self, freeze_base, pretrain_checkpoint=None):\n",
    "        pretrain_cnn=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\"\n",
    "        \n",
    "        #self.encoder = Transfer_ResNet54(freeze_base=freeze_cnn, pretrain_checkpoint=pretrain_cnn)\n",
    "        self.encoder = Cnn10()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pos_encoder = PositionalEncoding(nhid, dropout)\n",
    "        self.generator = nn.Softmax(dim=-1)\n",
    "        self.init_weights()\n",
    "\n",
    "        '''\n",
    "        if pretrain_cnn is not None:\n",
    "            dict_trained = pretrain_cnn\n",
    "            dict_new = self.encoder.state_dict().copy()\n",
    "            new_list = list(self.encoder.state_dict().keys())\n",
    "            trained_list = list(dict_trained.keys())\n",
    "            for i in range(len(new_list)):\n",
    "                dict_new[new_list[i]] = dict_trained[trained_list[i]]\n",
    "            self.encoder.load_state_dict(dict_new)\n",
    "        \n",
    "        if freeze_cnn:\n",
    "            self.freeze_cnn()\n",
    "        '''\n",
    "\n",
    "        if pretrain_emb is not None:\n",
    "            self.word_emb.weight.data = pretrain_emb\n",
    "\n",
    "    '''\n",
    "    def freeze_cnn(self):\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "    '''\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc)\n",
    "        self.word_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dec_fc.bias.data.zero_()\n",
    "        self.dec_fc.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def encode(self, src, input_mask=None):\n",
    "        global x \n",
    "        x = self.encoder(src)  # (batch_size, 2048, T/16, mel_bins/16) ,mixup\n",
    "        x = torch.mean(x, dim=3)  # (batch_size, 2048, T/16)\n",
    "        x = x.permute(2, 0, 1)  # (T/16,batch_size,2048)\n",
    "        x = F.relu_(self.fc(x))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "    def decode(self, mem, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # tgt:(batch_size,T_out)\n",
    "        # mem:(T_mem,batch_size,nhid)\n",
    "\n",
    "        tgt = tgt.transpose(0, 1)  # (T_out,batch_size)\n",
    "        if target_mask is None or target_mask.size(0) != len(tgt):\n",
    "            device = tgt.device\n",
    "            target_mask = self.generate_square_subsequent_mask(len(tgt)).to(device)\n",
    "\n",
    "        tgt = self.dropout(self.word_emb(tgt)) * math.sqrt(self.nhid)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        # mem = self.pos_encoder(mem)\n",
    "        output = self.transformer_decoder(tgt, mem, memory_mask=input_mask, tgt_mask=target_mask,\n",
    "                                          tgt_key_padding_mask=target_padding_mask)\n",
    "        output = self.dec_fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, src, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # src:(batch_size,T_in,feature_dim)\n",
    "        # tgt:(batch_size,T_out)\n",
    "        mem = self.encode(src)\n",
    "        output = self.decode(mem, tgt, input_mask=input_mask, target_mask=target_mask,\n",
    "                             target_padding_mask=target_padding_mask)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e0614a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3234085990>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "from data_handling import get_clotho_loader, get_test_data_loader\n",
    "#from model import TransformerModel  # , RNNModel, RNNModelSmall\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "from util import get_file_list, get_padding, print_hparams, greedy_decode, \\\n",
    "    calculate_bleu, calculate_spider, LabelSmoothingLoss, beam_search, align_word_embedding, gen_str\n",
    "from hparams import hparams\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "\n",
    "hp = hparams()\n",
    "parser = argparse.ArgumentParser(description='hparams for model')\n",
    "\n",
    "device = torch.device('cuda')\n",
    "np.random.seed(hp.seed)\n",
    "torch.manual_seed(hp.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23445b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "import inspect\n",
    "import copy\n",
    "from hparams import hparams as hp\n",
    "from eval_metrics import evaluate_metrics\n",
    "from eval_metrics import evaluate_metrics_from_lists\n",
    "from eval_metrics import combine_single_and_per_file_metrics\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import heapq\n",
    "from gensim.models.word2vec import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e6875d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_word_embedding(word_dict_pickle_path, w2v_model_path, ntoken, nhid):\n",
    "    word_dict = get_word_dict(word_dict_pickle_path)\n",
    "    model = Word2Vec.load(w2v_model_path)\n",
    "    word_emb = torch.zeros((ntoken, nhid)).float()\n",
    "    word_emb.uniform_(-0.1, 0.1)\n",
    "    w2v_vocab = [k for k in model.wv.key_to_index]\n",
    "    for i in range(len(word_dict)):\n",
    "        word = word_dict[i]\n",
    "        if word in w2v_vocab:\n",
    "            w2v_vector = model.wv[word]\n",
    "            word_emb[i] = torch.tensor(w2v_vector).float()\n",
    "    return word_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cefefd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_dict(word_dict_pickle_path, offset=0, reverse=False):\n",
    "    word_dict_pickle = pickle.load(open(word_dict_pickle_path, 'rb'))\n",
    "    word_dict = {}\n",
    "    for i in range(0 + offset, len(word_dict_pickle) + offset):\n",
    "        if reverse:\n",
    "            word_dict[word_dict_pickle[i]] = i\n",
    "        else:\n",
    "            word_dict[i] = word_dict_pickle[i]\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfb66a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_emb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f07e8879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0079, -0.0830,  0.0602,  ...,  0.0524, -0.0397,  0.0941],\n",
       "        [-0.2732,  0.0631, -0.3576,  ..., -0.2753, -0.3043,  0.0347],\n",
       "        [ 0.8280,  1.2189,  0.5615,  ...,  1.5523, -0.5715, -1.0595],\n",
       "        ...,\n",
       "        [ 0.0958, -0.0421, -0.0526,  ..., -0.0146, -0.0179, -0.0086],\n",
       "        [-0.0361,  0.0161,  0.0099,  ...,  0.0549, -0.0467,  0.0753],\n",
       "        [-0.0778,  0.0700, -0.0579,  ...,  0.0339, -0.0293,  0.0069]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3166e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_emb = align_word_embedding(hp.word_dict_pickle_path, hp.pretrain_emb_path, hp.ntoken,\n",
    "                                        hp.nhid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476ccfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(hp.ntoken, hp.ninp, hp.nhead, hp.nhid, hp.nlayers, hp.batch_size, dropout=0.2,\n",
    "                             pretrain_cnn=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\", pretrain_emb=pretrain_emb, freeze_cnn=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3e6cadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_emb): Embedding(4371, 192)\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=512, out_features=192, bias=True)\n",
       "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
       "  (encoder): Cnn10(\n",
       "    (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_block1): ConvBlock(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block2): ConvBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block3): ConvBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block4): ConvBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (generator): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14ee54d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:transformer_decoder.layers.0.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:word_emb.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.bn0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.bn0.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 1, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 2048, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 2048, 1, 1])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc_audioset.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([527, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc_audioset.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([527])\n",
      "param.requries_grad:True\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "#model parameter 확인\n",
    "for name, param in model.named_parameters(): \n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3255704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swa\n",
    "from torchcontrib.optim import SWA\n",
    "import torchcontrib\n",
    "\n",
    "base_opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=hp.lr, weight_decay=1e-6)\n",
    "optimizer = torchcontrib.optim.SWA(base_opt, swa_start=10, swa_freq=5, swa_lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, hp.scheduler_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "77b5da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swa 안할때\n",
    "optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=hp.lr, weight_decay=1e-6)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, hp.scheduler_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1809dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = hp.data_dir\n",
    "eval_data_dir = hp.eval_data_dir\n",
    "train_data_dir = hp.train_data_dir\n",
    "word_dict_pickle_path = hp.word_dict_pickle_path\n",
    "word_freq_pickle_path = hp.word_freq_pickle_path\n",
    "test_data_dir = hp.test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "570a7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir= '/home/hj20/dcase_2020_T6/data/test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e14809e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hj20/dcase_2020_T6/data/test_data'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4fa72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixup\n",
    "#data_dir = hp.data_dir\n",
    "#eval_data_dir = hp.eval_data_dir\n",
    "#train_data_dir = hp.train_data_dir\n",
    "word_dict_pickle_path = hp.word_dict_pickle_path\n",
    "word_freq_pickle_path = hp.word_freq_pickle_path\n",
    "#test_data_dir = hp.test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cc2cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = get_clotho_loader(data_dir=data_dir, split='development',\n",
    "                                      input_field_name='features',\n",
    "                                      output_field_name='words_ind',\n",
    "                                      load_into_memory=False,\n",
    "                                      batch_size=hp.batch_size,\n",
    "                                      nb_t_steps_pad='max',\n",
    "                                      num_workers=4, return_reference=True, augment=hp.spec_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29c2b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3051 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3051 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전체 데이터 \n",
    "from tqdm import tqdm\n",
    "tqdm(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2304b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24420,\n",
       " 24739,\n",
       " 1,\n",
       " 718,\n",
       " 4808,\n",
       " 46,\n",
       " 16,\n",
       " 13138,\n",
       " 17,\n",
       " 24420,\n",
       " 45,\n",
       " 28,\n",
       " 71,\n",
       " 329,\n",
       " 873,\n",
       " 5,\n",
       " 7333,\n",
       " 12184,\n",
       " 768,\n",
       " 1,\n",
       " 97,\n",
       " 149,\n",
       " 45,\n",
       " 168,\n",
       " 132,\n",
       " 555,\n",
       " 1,\n",
       " 49,\n",
       " 3225,\n",
       " 1,\n",
       " 241,\n",
       " 1844,\n",
       " 9147,\n",
       " 81,\n",
       " 1,\n",
       " 991,\n",
       " 455,\n",
       " 14,\n",
       " 7,\n",
       " 3,\n",
       " 330,\n",
       " 1935,\n",
       " 36,\n",
       " 12,\n",
       " 62,\n",
       " 2,\n",
       " 3654,\n",
       " 258,\n",
       " 90,\n",
       " 84,\n",
       " 79,\n",
       " 2134,\n",
       " 1,\n",
       " 5,\n",
       " 75,\n",
       " 4060,\n",
       " 1703,\n",
       " 40,\n",
       " 2369,\n",
       " 468,\n",
       " 67,\n",
       " 630,\n",
       " 2,\n",
       " 114,\n",
       " 15,\n",
       " 5,\n",
       " 2986,\n",
       " 1905,\n",
       " 52,\n",
       " 481,\n",
       " 2,\n",
       " 5,\n",
       " 315,\n",
       " 3003,\n",
       " 121,\n",
       " 811,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 31,\n",
       " 2541,\n",
       " 15,\n",
       " 13,\n",
       " 172,\n",
       " 502,\n",
       " 567,\n",
       " 301,\n",
       " 844,\n",
       " 1,\n",
       " 2748,\n",
       " 2229,\n",
       " 28,\n",
       " 60,\n",
       " 133,\n",
       " 2,\n",
       " 423,\n",
       " 262,\n",
       " 88,\n",
       " 52,\n",
       " 1,\n",
       " 806,\n",
       " 282,\n",
       " 22,\n",
       " 211,\n",
       " 41,\n",
       " 759,\n",
       " 447,\n",
       " 338,\n",
       " 142,\n",
       " 454,\n",
       " 2337,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 22,\n",
       " 1,\n",
       " 129,\n",
       " 23,\n",
       " 268,\n",
       " 809,\n",
       " 692,\n",
       " 630,\n",
       " 417,\n",
       " 3,\n",
       " 148,\n",
       " 20,\n",
       " 55,\n",
       " 91,\n",
       " 38,\n",
       " 241,\n",
       " 2309,\n",
       " 783,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 52,\n",
       " 2,\n",
       " 134,\n",
       " 428,\n",
       " 107,\n",
       " 25,\n",
       " 1,\n",
       " 461,\n",
       " 11,\n",
       " 129,\n",
       " 36,\n",
       " 87,\n",
       " 492,\n",
       " 508,\n",
       " 7,\n",
       " 16,\n",
       " 28,\n",
       " 61,\n",
       " 27,\n",
       " 397,\n",
       " 40,\n",
       " 15,\n",
       " 25,\n",
       " 117,\n",
       " 22,\n",
       " 77,\n",
       " 873,\n",
       " 68,\n",
       " 21,\n",
       " 5,\n",
       " 1,\n",
       " 10,\n",
       " 44,\n",
       " 298,\n",
       " 428,\n",
       " 29,\n",
       " 103,\n",
       " 1259,\n",
       " 128,\n",
       " 1404,\n",
       " 1,\n",
       " 1149,\n",
       " 271,\n",
       " 1,\n",
       " 1,\n",
       " 274,\n",
       " 123,\n",
       " 59,\n",
       " 933,\n",
       " 404,\n",
       " 650,\n",
       " 446,\n",
       " 18,\n",
       " 600,\n",
       " 120,\n",
       " 1608,\n",
       " 11,\n",
       " 372,\n",
       " 209,\n",
       " 2,\n",
       " 900,\n",
       " 97,\n",
       " 46,\n",
       " 240,\n",
       " 60,\n",
       " 57,\n",
       " 9,\n",
       " 31,\n",
       " 175,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 526,\n",
       " 260,\n",
       " 44,\n",
       " 35,\n",
       " 319,\n",
       " 446,\n",
       " 87,\n",
       " 17,\n",
       " 5,\n",
       " 1,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 26,\n",
       " 15,\n",
       " 13,\n",
       " 1,\n",
       " 46,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 398,\n",
       " 8,\n",
       " 27,\n",
       " 6,\n",
       " 2,\n",
       " 10,\n",
       " 94,\n",
       " 241,\n",
       " 125,\n",
       " 2,\n",
       " 44,\n",
       " 77,\n",
       " 13,\n",
       " 29,\n",
       " 13,\n",
       " 538,\n",
       " 524,\n",
       " 410,\n",
       " 293,\n",
       " 209,\n",
       " 164,\n",
       " 107,\n",
       " 142,\n",
       " 137,\n",
       " 679,\n",
       " 104,\n",
       " 708,\n",
       " 323,\n",
       " 903,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 22,\n",
       " 32,\n",
       " 23,\n",
       " 3,\n",
       " 3,\n",
       " 298,\n",
       " 91,\n",
       " 1,\n",
       " 173,\n",
       " 9,\n",
       " 18,\n",
       " 115,\n",
       " 17,\n",
       " 1,\n",
       " 43,\n",
       " 2,\n",
       " 5,\n",
       " 299,\n",
       " 1325,\n",
       " 119,\n",
       " 423,\n",
       " 112,\n",
       " 30,\n",
       " 46,\n",
       " 423,\n",
       " 3,\n",
       " 174,\n",
       " 4,\n",
       " 1,\n",
       " 122,\n",
       " 65,\n",
       " 2,\n",
       " 206,\n",
       " 423,\n",
       " 17,\n",
       " 2216,\n",
       " 163,\n",
       " 14,\n",
       " 864,\n",
       " 273,\n",
       " 55,\n",
       " 61,\n",
       " 387,\n",
       " 15,\n",
       " 61,\n",
       " 4,\n",
       " 111,\n",
       " 136,\n",
       " 121,\n",
       " 372,\n",
       " 23,\n",
       " 238,\n",
       " 220,\n",
       " 20,\n",
       " 4,\n",
       " 124,\n",
       " 2,\n",
       " 16,\n",
       " 3,\n",
       " 12,\n",
       " 133,\n",
       " 967,\n",
       " 28,\n",
       " 1,\n",
       " 1,\n",
       " 191,\n",
       " 548,\n",
       " 189,\n",
       " 34,\n",
       " 4,\n",
       " 19,\n",
       " 5,\n",
       " 3,\n",
       " 10,\n",
       " 64,\n",
       " 468,\n",
       " 92,\n",
       " 146,\n",
       " 52,\n",
       " 160,\n",
       " 144,\n",
       " 180,\n",
       " 3,\n",
       " 342,\n",
       " 127,\n",
       " 430,\n",
       " 3,\n",
       " 1,\n",
       " 119,\n",
       " 4,\n",
       " 70,\n",
       " 5,\n",
       " 35,\n",
       " 1,\n",
       " 63,\n",
       " 73,\n",
       " 22,\n",
       " 5,\n",
       " 28,\n",
       " 1,\n",
       " 3,\n",
       " 158,\n",
       " 21,\n",
       " 25,\n",
       " 176,\n",
       " 4,\n",
       " 12,\n",
       " 181,\n",
       " 431,\n",
       " 81,\n",
       " 96,\n",
       " 8,\n",
       " 34,\n",
       " 522,\n",
       " 127,\n",
       " 1,\n",
       " 11,\n",
       " 8,\n",
       " 17,\n",
       " 3,\n",
       " 3,\n",
       " 30,\n",
       " 32,\n",
       " 899,\n",
       " 250,\n",
       " 50,\n",
       " 13,\n",
       " 1,\n",
       " 27,\n",
       " 10,\n",
       " 2,\n",
       " 15,\n",
       " 97,\n",
       " 4,\n",
       " 85,\n",
       " 5,\n",
       " 21,\n",
       " 12,\n",
       " 523,\n",
       " 537,\n",
       " 72,\n",
       " 12,\n",
       " 20,\n",
       " 128,\n",
       " 17,\n",
       " 44,\n",
       " 3,\n",
       " 9,\n",
       " 61,\n",
       " 3,\n",
       " 2,\n",
       " 20,\n",
       " 31,\n",
       " 160,\n",
       " 103,\n",
       " 47,\n",
       " 24,\n",
       " 126,\n",
       " 18,\n",
       " 124,\n",
       " 1,\n",
       " 8,\n",
       " 35,\n",
       " 76,\n",
       " 13,\n",
       " 13,\n",
       " 56,\n",
       " 1,\n",
       " 30,\n",
       " 17,\n",
       " 56,\n",
       " 990,\n",
       " 64,\n",
       " 4,\n",
       " 55,\n",
       " 64,\n",
       " 20,\n",
       " 39,\n",
       " 33,\n",
       " 633,\n",
       " 5,\n",
       " 137,\n",
       " 19,\n",
       " 3,\n",
       " 1170,\n",
       " 180,\n",
       " 1,\n",
       " 43,\n",
       " 629,\n",
       " 1,\n",
       " 4,\n",
       " 47,\n",
       " 373,\n",
       " 314,\n",
       " 47,\n",
       " 337,\n",
       " 217,\n",
       " 76,\n",
       " 335,\n",
       " 1011,\n",
       " 549,\n",
       " 75,\n",
       " 196,\n",
       " 224,\n",
       " 196,\n",
       " 22,\n",
       " 9,\n",
       " 227,\n",
       " 11,\n",
       " 9,\n",
       " 1,\n",
       " 87,\n",
       " 57,\n",
       " 1,\n",
       " 41,\n",
       " 1,\n",
       " 44,\n",
       " 150,\n",
       " 72,\n",
       " 33,\n",
       " 65,\n",
       " 10,\n",
       " 1,\n",
       " 4,\n",
       " 306,\n",
       " 39,\n",
       " 24,\n",
       " 6,\n",
       " 600,\n",
       " 149,\n",
       " 36,\n",
       " 19,\n",
       " 5,\n",
       " 11,\n",
       " 263,\n",
       " 39,\n",
       " 2,\n",
       " 926,\n",
       " 4,\n",
       " 79,\n",
       " 34,\n",
       " 1,\n",
       " 65,\n",
       " 61,\n",
       " 3,\n",
       " 37,\n",
       " 157,\n",
       " 25,\n",
       " 15,\n",
       " 193,\n",
       " 17,\n",
       " 4,\n",
       " 29,\n",
       " 67,\n",
       " 12,\n",
       " 759,\n",
       " 56,\n",
       " 16,\n",
       " 92,\n",
       " 20,\n",
       " 18,\n",
       " 95,\n",
       " 11,\n",
       " 5,\n",
       " 3,\n",
       " 29,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 103,\n",
       " 171,\n",
       " 411,\n",
       " 170,\n",
       " 100,\n",
       " 10,\n",
       " 142,\n",
       " 132,\n",
       " 4,\n",
       " 47,\n",
       " 4,\n",
       " 2,\n",
       " 127,\n",
       " 6,\n",
       " 2,\n",
       " 86,\n",
       " 106,\n",
       " 26,\n",
       " 40,\n",
       " 15,\n",
       " 32,\n",
       " 3,\n",
       " 4,\n",
       " 14,\n",
       " 68,\n",
       " 8,\n",
       " 13,\n",
       " 10,\n",
       " 672,\n",
       " 69,\n",
       " 36,\n",
       " 5,\n",
       " 15,\n",
       " 19,\n",
       " 50,\n",
       " 11,\n",
       " 313,\n",
       " 13,\n",
       " 21,\n",
       " 40,\n",
       " 33,\n",
       " 25,\n",
       " 41,\n",
       " 79,\n",
       " 111,\n",
       " 42,\n",
       " 75,\n",
       " 2,\n",
       " 1,\n",
       " 12,\n",
       " 23,\n",
       " 20,\n",
       " 124,\n",
       " 9,\n",
       " 7,\n",
       " 66,\n",
       " 43,\n",
       " 155,\n",
       " 85,\n",
       " 2,\n",
       " 7,\n",
       " 17,\n",
       " 145,\n",
       " 305,\n",
       " 51,\n",
       " 2,\n",
       " 441,\n",
       " 1,\n",
       " 34,\n",
       " 3,\n",
       " 24,\n",
       " 42,\n",
       " 47,\n",
       " 58,\n",
       " 2,\n",
       " 48,\n",
       " 7,\n",
       " 69,\n",
       " 126,\n",
       " 16,\n",
       " 169,\n",
       " 79,\n",
       " 17,\n",
       " 667,\n",
       " 232,\n",
       " 353,\n",
       " 38,\n",
       " 3,\n",
       " 3,\n",
       " 590,\n",
       " 399,\n",
       " 63,\n",
       " 82,\n",
       " 4,\n",
       " 3,\n",
       " 131,\n",
       " 9,\n",
       " 47,\n",
       " 288,\n",
       " 195,\n",
       " 8,\n",
       " 56,\n",
       " 1,\n",
       " 346,\n",
       " 6,\n",
       " 17,\n",
       " 60,\n",
       " 28,\n",
       " 47,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 41,\n",
       " 53,\n",
       " 32,\n",
       " 107,\n",
       " 50,\n",
       " 69,\n",
       " 97,\n",
       " 35,\n",
       " 22,\n",
       " 99,\n",
       " 107,\n",
       " 54,\n",
       " 849,\n",
       " 360,\n",
       " 115,\n",
       " 1,\n",
       " 43,\n",
       " 4,\n",
       " 1,\n",
       " 19,\n",
       " 170,\n",
       " 1,\n",
       " 3,\n",
       " 18,\n",
       " 38,\n",
       " 59,\n",
       " 112,\n",
       " 17,\n",
       " 140,\n",
       " 1,\n",
       " 130,\n",
       " 24,\n",
       " 7,\n",
       " 66,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 70,\n",
       " 6,\n",
       " 4,\n",
       " 23,\n",
       " 104,\n",
       " 25,\n",
       " 156,\n",
       " 28,\n",
       " 15,\n",
       " 5,\n",
       " 425,\n",
       " 86,\n",
       " 237,\n",
       " 92,\n",
       " 2,\n",
       " 10,\n",
       " 30,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 11,\n",
       " 6,\n",
       " 1,\n",
       " 52,\n",
       " 268,\n",
       " 176,\n",
       " 11,\n",
       " 7,\n",
       " 159,\n",
       " 33,\n",
       " 79,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 48,\n",
       " 2,\n",
       " 15,\n",
       " 139,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 131,\n",
       " 263,\n",
       " 12,\n",
       " 376,\n",
       " 9,\n",
       " 238,\n",
       " 21,\n",
       " 5,\n",
       " 128,\n",
       " 9,\n",
       " 107,\n",
       " 69,\n",
       " 129,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 116,\n",
       " 29,\n",
       " 43,\n",
       " 84,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 26,\n",
       " 279,\n",
       " 1,\n",
       " 157,\n",
       " 136,\n",
       " 48,\n",
       " 20,\n",
       " 16,\n",
       " 34,\n",
       " 223,\n",
       " 34,\n",
       " 16,\n",
       " 50,\n",
       " 5,\n",
       " 221,\n",
       " 55,\n",
       " 73,\n",
       " 43,\n",
       " 2,\n",
       " 80,\n",
       " 10,\n",
       " 89,\n",
       " 94,\n",
       " 3,\n",
       " 55,\n",
       " 57,\n",
       " 1,\n",
       " 51,\n",
       " 28,\n",
       " 115,\n",
       " 306,\n",
       " 12,\n",
       " 25,\n",
       " 275,\n",
       " 157,\n",
       " 8,\n",
       " 240,\n",
       " 8,\n",
       " 13,\n",
       " 43,\n",
       " 9,\n",
       " 31,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 22,\n",
       " 11,\n",
       " 5,\n",
       " 39,\n",
       " 17,\n",
       " 8,\n",
       " 14,\n",
       " 2,\n",
       " 39,\n",
       " 63,\n",
       " 6,\n",
       " 15,\n",
       " 8,\n",
       " 8,\n",
       " 14,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 24,\n",
       " 4,\n",
       " 10,\n",
       " 113,\n",
       " 3,\n",
       " 15,\n",
       " 20,\n",
       " 27,\n",
       " 21,\n",
       " 2,\n",
       " 48,\n",
       " 102,\n",
       " 75,\n",
       " 52,\n",
       " 314,\n",
       " 26,\n",
       " 26,\n",
       " 150,\n",
       " 6,\n",
       " 379,\n",
       " 9,\n",
       " 10,\n",
       " 2,\n",
       " 9,\n",
       " 91,\n",
       " 5,\n",
       " 195,\n",
       " 2,\n",
       " 27,\n",
       " 32,\n",
       " 51,\n",
       " 3,\n",
       " 35,\n",
       " 135,\n",
       " 60,\n",
       " 19,\n",
       " 1,\n",
       " 251,\n",
       " 33,\n",
       " 266,\n",
       " 28,\n",
       " 1,\n",
       " 13,\n",
       " 72,\n",
       " 25,\n",
       " 2,\n",
       " 79,\n",
       " 13,\n",
       " 41,\n",
       " 2,\n",
       " 5,\n",
       " 15,\n",
       " 101,\n",
       " 12,\n",
       " 56,\n",
       " 4,\n",
       " 27,\n",
       " 61,\n",
       " 61,\n",
       " 3,\n",
       " 4,\n",
       " 41,\n",
       " 9,\n",
       " 26,\n",
       " 188,\n",
       " 73,\n",
       " 36,\n",
       " 31,\n",
       " 17,\n",
       " 4,\n",
       " 10,\n",
       " 94,\n",
       " 23,\n",
       " 1,\n",
       " 16,\n",
       " 38,\n",
       " 131,\n",
       " 202,\n",
       " 27,\n",
       " 1,\n",
       " 180,\n",
       " 30,\n",
       " 3,\n",
       " 3,\n",
       " 84,\n",
       " 1,\n",
       " 147,\n",
       " 41,\n",
       " 3,\n",
       " 60,\n",
       " 1,\n",
       " 4,\n",
       " 21,\n",
       " 45,\n",
       " 175,\n",
       " 2,\n",
       " 104,\n",
       " 7,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 18,\n",
       " 8,\n",
       " 130,\n",
       " 2,\n",
       " 133,\n",
       " 9,\n",
       " 58,\n",
       " 20,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 133,\n",
       " 61,\n",
       " 8,\n",
       " 5,\n",
       " 103,\n",
       " 63,\n",
       " 5,\n",
       " 5,\n",
       " 251,\n",
       " 44,\n",
       " 3,\n",
       " 109,\n",
       " 2,\n",
       " 15,\n",
       " 7,\n",
       " 17,\n",
       " 76,\n",
       " 233,\n",
       " 282,\n",
       " 2,\n",
       " 29,\n",
       " 202,\n",
       " 50,\n",
       " 2,\n",
       " 56,\n",
       " 56,\n",
       " 73,\n",
       " 30,\n",
       " 89,\n",
       " 1,\n",
       " 5,\n",
       " 32,\n",
       " 2,\n",
       " 134,\n",
       " 2,\n",
       " 2,\n",
       " 179,\n",
       " 28,\n",
       " 87,\n",
       " 160,\n",
       " 12,\n",
       " 7,\n",
       " 4,\n",
       " 35,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 13,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 115,\n",
       " 2,\n",
       " 11,\n",
       " 39,\n",
       " 22,\n",
       " 62,\n",
       " 57,\n",
       " 3,\n",
       " 36,\n",
       " 1,\n",
       " 18,\n",
       " 1,\n",
       " 41,\n",
       " 34,\n",
       " 5,\n",
       " 17,\n",
       " 12,\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "#워드 개수 확인\n",
    "with open('./create_dataset/data/pickles/words_frequencies.p','rb') as f:\n",
    "    words_freq=pickle.load(f)\n",
    "words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85ae9cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4371"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f1f1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_beam = get_clotho_loader(data_dir=data_dir, split='evaluation',\n",
    "                                        input_field_name='features',\n",
    "                                        output_field_name='words_ind',\n",
    "                                        load_into_memory=False,\n",
    "                                        batch_size=32,\n",
    "                                        nb_t_steps_pad='max',\n",
    "                                        shuffle=False,\n",
    "                                        return_reference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c6defba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hj20/dcase_2020_T6/data/test_data'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cf2eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = get_test_data_loader(data_dir=test_data_dir,\n",
    "                                     batch_size=1,\n",
    "                                     nb_t_steps_pad='max',\n",
    "                                     shuffle=False,\n",
    "                                     drop_last=False,\n",
    "                                     input_pad_at='start',\n",
    "                                     num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d41555f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17559"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a1287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e61a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4a14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "475347a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss_text = 0.\n",
    "    start_time = time.time()\n",
    "    batch = 0\n",
    "    for src, tgt, tgt_len,ref in training_data:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        tgt_pad_mask = get_padding(tgt, tgt_len)\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        tgt_pad_mask = tgt_pad_mask[:, :-1]\n",
    "        tgt_y = tgt[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, tgt_in, target_padding_mask=tgt_pad_mask)\n",
    "\n",
    "        loss_text = criterion(output.contiguous().view(-1, hp.ntoken), tgt_y.transpose(0, 1).contiguous().view(-1))\n",
    "        loss = loss_text\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), hp.clip_grad)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "        total_loss_text += loss_text.item()\n",
    "\n",
    "        writer.add_scalar('Loss/train-text', loss_text.item(), (epoch - 1) * len(training_data) + batch)\n",
    "        \n",
    "        \n",
    "        batch += 1\n",
    "        \n",
    "        if batch % hp.log_interval == 0 and batch > 0:\n",
    "            mean_text_loss = total_loss_text / hp.log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            current_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\n",
    "            logging.info('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2e} | ms/batch {:5.2f} | '\n",
    "                         'loss-text {:5.4f}'.format(\n",
    "                epoch, batch, len(training_data), current_lr,\n",
    "                elapsed * 1000 / hp.log_interval, mean_text_loss))\n",
    "            total_loss_text = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "            optimizer.swap_swa_sgd()\n",
    "\n",
    "def eval_all(evaluation_data, max_len=30, eos_ind=9, word_dict_pickle_path=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_sentence_all = []\n",
    "        ref_all = []\n",
    "        for src, tgt, _, ref in evaluation_data:\n",
    "            src = src.to(device)\n",
    "            output = greedy_decode(model, src, max_len=max_len)\n",
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for i in range(output.size()[0]):\n",
    "                output_sentence_ind = []\n",
    "                for j in range(1, output.size(1)):\n",
    "                    sym = output[i, j]\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n",
    "\n",
    "        loss_mean = score\n",
    "        writer.add_scalar(f'Loss/eval_greddy', loss_mean, epoch)\n",
    "        msg = f'eval_greddy SPIDEr: {loss_mean:2.4f}'\n",
    "        logging.info(msg)\n",
    "\n",
    "\n",
    "def eval_with_beam(evaluation_data, max_len=30, eos_ind=9, word_dict_pickle_path=None, beam_size=3):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_sentence_all = []\n",
    "        ref_all = []\n",
    "        for src, tgt, _, ref in evaluation_data:\n",
    "            src = src.to(device)\n",
    "            output = beam_search(model, src, max_len, start_symbol_ind=0, beam_size=beam_size)\n",
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for single_sample in output:\n",
    "                output_sentence_ind = []\n",
    "                for sym in single_sample:\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n",
    "\n",
    "        loss_mean = score\n",
    "        writer.add_scalar(f'Loss/eval_beam', loss_mean, epoch)\n",
    "        msg = f'eval_beam_{beam_size} SPIDEr: {loss_mean:2.4f}'\n",
    "        logging.info(msg)\n",
    "\n",
    "\n",
    "def test_with_beam(test_data, max_len=30, eos_ind=9, beam_size=3):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with open(\"test_out.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['file_name', 'caption_predicted'])\n",
    "            for src, filename in test_data:\n",
    "                src = src.to(device)\n",
    "                output = beam_search(model, src, max_len, start_symbol_ind=0, beam_size=beam_size)\n",
    "\n",
    "                output_sentence_ind_batch = []\n",
    "                for single_sample in output:\n",
    "                    output_sentence_ind = []\n",
    "                    for sym in single_sample:\n",
    "                        if sym == eos_ind: break\n",
    "                        output_sentence_ind.append(sym.item())\n",
    "                    output_sentence_ind_batch.append(output_sentence_ind)\n",
    "                out_str = gen_str(output_sentence_ind_batch, hp.word_dict_pickle_path)\n",
    "                for caption, fn in zip(out_str, filename):\n",
    "                    writer.writerow(['{}.wav'.format(fn), caption])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d583cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hp.label_smoothing:\n",
    "    criterion = LabelSmoothingLoss(hp.ntoken, smoothing=0.1)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=hp.ntoken - 1)\n",
    "\n",
    "now_time = str(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(time.time())))\n",
    "log_dir = 'models/{name}'.format(name=hp.name)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "log_path = os.path.join(log_dir, 'train.log')\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                        format=\n",
    "                        '%(asctime)s - %(levelname)s: %(message)s',\n",
    "                        handlers=[\n",
    "                            logging.FileHandler(log_path),\n",
    "                            logging.StreamHandler(sys.stdout)]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0708d0f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-09 09:39:49,651 - INFO: TransformerModel(\n",
      "  (transformer_decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (dropout3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (dropout3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_emb): Embedding(4371, 192)\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc1): Linear(in_features=512, out_features=192, bias=True)\n",
      "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
      "  (encoder): Cnn10(\n",
      "    (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_block1): ConvBlock(\n",
      "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_block2): ConvBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_block3): ConvBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_block4): ConvBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (generator): Softmax(dim=-1)\n",
      ")\n",
      "2022-04-09 09:39:49,652 - INFO: {'batch_size': 8, 'beam_width': 3, 'checkpoint_save_interval': 5, 'clip_grad': 2.5, 'data_dir': PosixPath('/media/hj20/disc2/create_dataset/data/data_splits'), 'device': 'cuda', 'eval_data_dir': '/media/hj20/disc2/create_dataset/data/data_splits/evaluation', 'freeze_cnn': True, 'label_smoothing': True, 'load_pretrain_cnn': True, 'load_pretrain_emb': False, 'load_pretrain_model': True, 'log_interval': 100, 'lr': 1e-05, 'mode': 'train', 'name': '0101_vgg_pretrain', 'nhead': 4, 'nhid': 192, 'ninp': 64, 'nkeyword': 4979, 'nlayers': 2, 'ntoken': 4371, 'pretrain_cnn_path': '/media/hj20/disc2/models/tag_models/TagModel_45.pt', 'pretrain_emb_path': '/media/hj20/disc2/models/w2v_192.mod', 'pretrain_model_path': '/media/hj20/disc2/models/base/46.pt', 'scheduler_decay': 0.98, 'seed': 1111, 'spec_augmentation': True, 'test_data_dir': '/media/hj20/disc2/create_dataset/data/test_data', 'train_data_dir': '/media/hj20/disc2/create_dataset/data/data_splits/development', 'training_epochs': 50, 'word_dict_pickle_path': '/media/hj20/disc2/create_dataset/data/pickles/words_list.p', 'word_freq_pickle_path': '/media/hj20/disc2/create_dataset/data/pickles/words_frequencies.p'}\n",
      "2022-04-09 09:39:49,653 - INFO: Data loaded!\n",
      "2022-04-09 09:39:49,654 - INFO: Data size: 3051\n",
      "2022-04-09 09:39:49,654 - INFO: Total Model parameters: 8902803\n"
     ]
    }
   ],
   "source": [
    "    logging.info(str(model))\n",
    "\n",
    "    logging.info(str(print_hparams(hp)))\n",
    "\n",
    "    logging.info('Data loaded!')\n",
    "    logging.info('Data size: ' + str(len(training_data)))\n",
    "\n",
    "    logging.info('Total Model parameters: ' + str(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2accc11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-09 09:40:16,209 - INFO: | epoch   1 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 161.96 | loss-text 6.5318\n",
      "2022-04-09 09:40:31,936 - INFO: | epoch   1 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 157.26 | loss-text 5.6197\n",
      "2022-04-09 09:40:47,959 - INFO: | epoch   1 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 160.23 | loss-text 5.3156\n",
      "2022-04-09 09:41:03,995 - INFO: | epoch   1 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 160.35 | loss-text 5.1574\n",
      "2022-04-09 09:41:20,066 - INFO: | epoch   1 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 160.70 | loss-text 4.9984\n",
      "2022-04-09 09:41:36,177 - INFO: | epoch   1 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 161.11 | loss-text 4.8311\n",
      "2022-04-09 09:41:52,120 - INFO: | epoch   1 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 159.42 | loss-text 4.7957\n",
      "2022-04-09 09:42:08,232 - INFO: | epoch   1 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 161.12 | loss-text 4.6976\n",
      "2022-04-09 09:42:24,344 - INFO: | epoch   1 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 161.11 | loss-text 4.7107\n",
      "2022-04-09 09:42:40,450 - INFO: | epoch   1 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 161.05 | loss-text 4.6916\n",
      "2022-04-09 09:42:56,574 - INFO: | epoch   1 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 161.24 | loss-text 4.6363\n",
      "2022-04-09 09:43:12,674 - INFO: | epoch   1 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 160.99 | loss-text 4.5617\n",
      "2022-04-09 09:43:28,870 - INFO: | epoch   1 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 161.95 | loss-text 4.5970\n",
      "2022-04-09 09:43:45,174 - INFO: | epoch   1 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.02 | loss-text 4.5278\n",
      "2022-04-09 09:44:01,482 - INFO: | epoch   1 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.08 | loss-text 4.5494\n",
      "2022-04-09 09:44:17,754 - INFO: | epoch   1 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 162.71 | loss-text 4.4613\n",
      "2022-04-09 09:44:33,984 - INFO: | epoch   1 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 162.29 | loss-text 4.5275\n",
      "2022-04-09 09:44:50,116 - INFO: | epoch   1 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 161.32 | loss-text 4.5010\n",
      "2022-04-09 09:45:06,280 - INFO: | epoch   1 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 161.63 | loss-text 4.4521\n",
      "2022-04-09 09:45:22,478 - INFO: | epoch   1 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 161.97 | loss-text 4.3823\n",
      "2022-04-09 09:45:38,718 - INFO: | epoch   1 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 162.39 | loss-text 4.3527\n",
      "2022-04-09 09:45:55,015 - INFO: | epoch   1 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 162.96 | loss-text 4.4512\n",
      "2022-04-09 09:46:11,212 - INFO: | epoch   1 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 161.97 | loss-text 4.4220\n",
      "2022-04-09 09:46:27,556 - INFO: | epoch   1 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.43 | loss-text 4.3759\n",
      "2022-04-09 09:46:43,640 - INFO: | epoch   1 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 160.83 | loss-text 4.3996\n",
      "2022-04-09 09:46:59,933 - INFO: | epoch   1 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 162.92 | loss-text 4.3933\n",
      "2022-04-09 09:47:16,183 - INFO: | epoch   1 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 162.49 | loss-text 4.3048\n",
      "2022-04-09 09:47:32,597 - INFO: | epoch   1 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.14 | loss-text 4.3406\n",
      "2022-04-09 09:47:48,915 - INFO: | epoch   1 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.16 | loss-text 4.2503\n",
      "2022-04-09 09:48:05,304 - INFO: | epoch   1 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.89 | loss-text 4.3249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004049\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 24742, 'reflen': 14512, 'guess': [24742, 23718, 22694, 21670], 'correct': [4398, 861, 199, 51]}\n",
      "ratio: 1.7049338478499376\n",
      "Bleu_1: 0.178\n",
      "Bleu_2: 0.080\n",
      "Bleu_3: 0.038\n",
      "Bleu_4: 0.019\n",
      "computing METEOR score...\n",
      "METEOR: 0.089\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.199\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.005\n",
      "computing SPICE score...\n",
      "SPICE: 0.035\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.020\n",
      "2022-04-09 09:49:01,526 - INFO: eval_greddy SPIDEr: 0.0201\n",
      "loading annotations into memory...\n",
      "0:00:00.003969\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7173, 'reflen': 9183, 'guess': [7173, 6149, 5125, 4101], 'correct': [3712, 843, 161, 40]}\n",
      "ratio: 0.7811172819339234\n",
      "Bleu_1: 0.391\n",
      "Bleu_2: 0.201\n",
      "Bleu_3: 0.099\n",
      "Bleu_4: 0.052\n",
      "computing METEOR score...\n",
      "METEOR: 0.098\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.281\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.063\n",
      "computing SPICE score...\n",
      "SPICE: 0.059\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.061\n",
      "2022-04-09 09:49:28,313 - INFO: eval_beam_2 SPIDEr: 0.0611\n",
      "loading annotations into memory...\n",
      "0:00:00.003915\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7169, 'reflen': 9182, 'guess': [7169, 6145, 5121, 4097], 'correct': [3712, 843, 161, 40]}\n",
      "ratio: 0.7807667174906577\n",
      "Bleu_1: 0.391\n",
      "Bleu_2: 0.201\n",
      "Bleu_3: 0.099\n",
      "Bleu_4: 0.052\n",
      "computing METEOR score...\n",
      "METEOR: 0.098\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.281\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.063\n",
      "computing SPICE score...\n",
      "SPICE: 0.059\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.061\n",
      "2022-04-09 09:49:57,510 - INFO: eval_beam_3 SPIDEr: 0.0611\n",
      "loading annotations into memory...\n",
      "0:00:00.003912\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7169, 'reflen': 9182, 'guess': [7169, 6145, 5121, 4097], 'correct': [3788, 926, 218, 42]}\n",
      "ratio: 0.7807667174906577\n",
      "Bleu_1: 0.399\n",
      "Bleu_2: 0.213\n",
      "Bleu_3: 0.113\n",
      "Bleu_4: 0.058\n",
      "computing METEOR score...\n",
      "METEOR: 0.102\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.288\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.068\n",
      "computing SPICE score...\n",
      "SPICE: 0.059\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.064\n",
      "2022-04-09 09:50:30,311 - INFO: eval_beam_4 SPIDEr: 0.0638\n",
      "2022-04-09 09:50:46,912 - INFO: | epoch   2 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.98 | loss-text 4.3288\n",
      "2022-04-09 09:51:03,167 - INFO: | epoch   2 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.54 | loss-text 4.2959\n",
      "2022-04-09 09:51:19,321 - INFO: | epoch   2 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 161.53 | loss-text 4.2787\n",
      "2022-04-09 09:51:35,579 - INFO: | epoch   2 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.58 | loss-text 4.2192\n",
      "2022-04-09 09:51:51,833 - INFO: | epoch   2 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.53 | loss-text 4.2638\n",
      "2022-04-09 09:52:08,118 - INFO: | epoch   2 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.84 | loss-text 4.2211\n",
      "2022-04-09 09:52:24,320 - INFO: | epoch   2 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 162.01 | loss-text 4.1972\n",
      "2022-04-09 09:52:40,585 - INFO: | epoch   2 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 162.64 | loss-text 4.1673\n",
      "2022-04-09 09:52:56,905 - INFO: | epoch   2 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.20 | loss-text 4.1549\n",
      "2022-04-09 09:53:13,340 - INFO: | epoch   2 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.33 | loss-text 4.1755\n",
      "2022-04-09 09:53:29,590 - INFO: | epoch   2 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 162.49 | loss-text 4.1865\n",
      "2022-04-09 09:53:45,866 - INFO: | epoch   2 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 162.76 | loss-text 4.1983\n",
      "2022-04-09 09:54:02,271 - INFO: | epoch   2 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.04 | loss-text 4.1607\n",
      "2022-04-09 09:54:18,627 - INFO: | epoch   2 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.56 | loss-text 4.2197\n",
      "2022-04-09 09:54:34,879 - INFO: | epoch   2 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 162.51 | loss-text 4.1765\n",
      "2022-04-09 09:54:51,272 - INFO: | epoch   2 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.92 | loss-text 4.1148\n",
      "2022-04-09 09:55:07,710 - INFO: | epoch   2 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.37 | loss-text 4.0488\n",
      "2022-04-09 09:55:24,112 - INFO: | epoch   2 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.02 | loss-text 4.2037\n",
      "2022-04-09 09:55:40,525 - INFO: | epoch   2 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.12 | loss-text 4.1271\n",
      "2022-04-09 09:55:57,044 - INFO: | epoch   2 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 165.19 | loss-text 4.1103\n",
      "2022-04-09 09:56:13,360 - INFO: | epoch   2 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 163.15 | loss-text 4.1632\n",
      "2022-04-09 09:56:29,574 - INFO: | epoch   2 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 162.13 | loss-text 4.1674\n",
      "2022-04-09 09:56:46,017 - INFO: | epoch   2 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.43 | loss-text 4.1565\n",
      "2022-04-09 09:57:02,429 - INFO: | epoch   2 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.11 | loss-text 4.1623\n",
      "2022-04-09 09:57:18,872 - INFO: | epoch   2 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.43 | loss-text 4.1295\n",
      "2022-04-09 09:57:35,154 - INFO: | epoch   2 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 162.81 | loss-text 4.1154\n",
      "2022-04-09 09:57:51,546 - INFO: | epoch   2 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.92 | loss-text 4.0685\n",
      "2022-04-09 09:58:07,883 - INFO: | epoch   2 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.36 | loss-text 4.0725\n",
      "2022-04-09 09:58:24,306 - INFO: | epoch   2 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.22 | loss-text 4.0759\n",
      "2022-04-09 09:58:40,600 - INFO: | epoch   2 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 162.92 | loss-text 4.1057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003839\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 21024, 'reflen': 13908, 'guess': [21024, 20000, 18976, 17952], 'correct': [4177, 880, 204, 52]}\n",
      "ratio: 1.5116479723898826\n",
      "Bleu_1: 0.199\n",
      "Bleu_2: 0.093\n",
      "Bleu_3: 0.045\n",
      "Bleu_4: 0.023\n",
      "computing METEOR score...\n",
      "METEOR: 0.091\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.211\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.031\n",
      "computing SPICE score...\n",
      "SPICE: 0.040\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.035\n",
      "2022-04-09 09:59:34,730 - INFO: eval_greddy SPIDEr: 0.0354\n",
      "loading annotations into memory...\n",
      "0:00:00.003911\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 14301, 'reflen': 12043, 'guess': [14301, 13277, 12253, 11229], 'correct': [4188, 950, 193, 50]}\n",
      "ratio: 1.1874948102631249\n",
      "Bleu_1: 0.293\n",
      "Bleu_2: 0.145\n",
      "Bleu_3: 0.069\n",
      "Bleu_4: 0.035\n",
      "computing METEOR score...\n",
      "METEOR: 0.100\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.249\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.056\n",
      "computing SPICE score...\n",
      "SPICE: 0.055\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.056\n",
      "2022-04-09 10:00:18,119 - INFO: eval_beam_2 SPIDEr: 0.0557\n",
      "loading annotations into memory...\n",
      "0:00:00.004072\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7282, 'reflen': 9209, 'guess': [7282, 6258, 5234, 4210], 'correct': [3550, 923, 235, 49]}\n",
      "ratio: 0.7907481811270723\n",
      "Bleu_1: 0.374\n",
      "Bleu_2: 0.206\n",
      "Bleu_3: 0.113\n",
      "Bleu_4: 0.060\n",
      "computing METEOR score...\n",
      "METEOR: 0.100\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.281\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.079\n",
      "computing SPICE score...\n",
      "SPICE: 0.063\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.071\n",
      "2022-04-09 10:00:46,627 - INFO: eval_beam_3 SPIDEr: 0.0712\n",
      "loading annotations into memory...\n",
      "0:00:00.003951\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7038, 'reflen': 9182, 'guess': [7038, 6014, 4990, 3966], 'correct': [3447, 1027, 315, 60]}\n",
      "ratio: 0.766499673273713\n",
      "Bleu_1: 0.361\n",
      "Bleu_2: 0.213\n",
      "Bleu_3: 0.128\n",
      "Bleu_4: 0.070\n",
      "computing METEOR score...\n",
      "METEOR: 0.100\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.280\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.091\n",
      "computing SPICE score...\n",
      "SPICE: 0.063\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.077\n",
      "2022-04-09 10:01:16,402 - INFO: eval_beam_4 SPIDEr: 0.0769\n",
      "2022-04-09 10:01:32,791 - INFO: | epoch   3 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 163.87 | loss-text 4.0222\n",
      "2022-04-09 10:01:48,920 - INFO: | epoch   3 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.28 | loss-text 4.1023\n",
      "2022-04-09 10:02:05,061 - INFO: | epoch   3 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 161.40 | loss-text 4.0271\n",
      "2022-04-09 10:02:21,309 - INFO: | epoch   3 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.47 | loss-text 4.1047\n",
      "2022-04-09 10:02:37,615 - INFO: | epoch   3 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.05 | loss-text 3.9619\n",
      "2022-04-09 10:02:54,056 - INFO: | epoch   3 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 164.40 | loss-text 4.0442\n",
      "2022-04-09 10:03:10,324 - INFO: | epoch   3 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 162.68 | loss-text 4.0529\n",
      "2022-04-09 10:03:26,695 - INFO: | epoch   3 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.70 | loss-text 4.0114\n",
      "2022-04-09 10:03:42,938 - INFO: | epoch   3 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 162.43 | loss-text 4.0105\n",
      "2022-04-09 10:03:59,249 - INFO: | epoch   3 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.10 | loss-text 4.0165\n",
      "2022-04-09 10:04:15,576 - INFO: | epoch   3 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.27 | loss-text 4.0403\n",
      "2022-04-09 10:04:31,908 - INFO: | epoch   3 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.31 | loss-text 4.0783\n",
      "2022-04-09 10:04:48,196 - INFO: | epoch   3 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 162.86 | loss-text 4.0031\n",
      "2022-04-09 10:05:04,465 - INFO: | epoch   3 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 162.69 | loss-text 4.0678\n",
      "2022-04-09 10:05:20,945 - INFO: | epoch   3 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.79 | loss-text 4.0422\n",
      "2022-04-09 10:05:37,394 - INFO: | epoch   3 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.49 | loss-text 4.0277\n",
      "2022-04-09 10:05:53,866 - INFO: | epoch   3 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.71 | loss-text 4.0686\n",
      "2022-04-09 10:06:10,320 - INFO: | epoch   3 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.53 | loss-text 3.9801\n",
      "2022-04-09 10:06:26,716 - INFO: | epoch   3 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.95 | loss-text 3.8910\n",
      "2022-04-09 10:06:43,206 - INFO: | epoch   3 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.89 | loss-text 4.0078\n",
      "2022-04-09 10:06:59,553 - INFO: | epoch   3 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 163.47 | loss-text 3.9672\n",
      "2022-04-09 10:07:15,929 - INFO: | epoch   3 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.75 | loss-text 3.9935\n",
      "2022-04-09 10:07:32,451 - INFO: | epoch   3 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 165.21 | loss-text 3.9905\n",
      "2022-04-09 10:07:48,825 - INFO: | epoch   3 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.73 | loss-text 3.9949\n",
      "2022-04-09 10:08:05,265 - INFO: | epoch   3 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.40 | loss-text 3.9197\n",
      "2022-04-09 10:08:21,497 - INFO: | epoch   3 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 162.31 | loss-text 3.9777\n",
      "2022-04-09 10:08:37,938 - INFO: | epoch   3 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.40 | loss-text 3.9767\n",
      "2022-04-09 10:08:54,348 - INFO: | epoch   3 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.09 | loss-text 3.9878\n",
      "2022-04-09 10:09:10,660 - INFO: | epoch   3 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.12 | loss-text 3.9975\n",
      "2022-04-09 10:09:27,051 - INFO: | epoch   3 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.91 | loss-text 3.9963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004010\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 17011, 'reflen': 13259, 'guess': [17011, 15987, 14963, 13939], 'correct': [3840, 768, 217, 61]}\n",
      "ratio: 1.282977600120576\n",
      "Bleu_1: 0.226\n",
      "Bleu_2: 0.104\n",
      "Bleu_3: 0.054\n",
      "Bleu_4: 0.029\n",
      "computing METEOR score...\n",
      "METEOR: 0.090\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.222\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.037\n",
      "computing SPICE score...\n",
      "SPICE: 0.047\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.042\n",
      "2022-04-09 10:10:12,591 - INFO: eval_greddy SPIDEr: 0.0421\n",
      "loading annotations into memory...\n",
      "0:00:00.004017\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 13415, 'reflen': 11924, 'guess': [13415, 12391, 11367, 10343], 'correct': [3754, 760, 215, 64]}\n",
      "ratio: 1.12504193223741\n",
      "Bleu_1: 0.280\n",
      "Bleu_2: 0.131\n",
      "Bleu_3: 0.069\n",
      "Bleu_4: 0.038\n",
      "computing METEOR score...\n",
      "METEOR: 0.092\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.240\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.048\n",
      "computing SPICE score...\n",
      "SPICE: 0.047\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.048\n",
      "2022-04-09 10:10:48,173 - INFO: eval_beam_2 SPIDEr: 0.0479\n",
      "loading annotations into memory...\n",
      "0:00:00.004002\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7439, 'reflen': 9182, 'guess': [7439, 6415, 5391, 4367], 'correct': [3537, 720, 210, 55]}\n",
      "ratio: 0.810172075800391\n",
      "Bleu_1: 0.376\n",
      "Bleu_2: 0.183\n",
      "Bleu_3: 0.101\n",
      "Bleu_4: 0.057\n",
      "computing METEOR score...\n",
      "METEOR: 0.101\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.274\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.067\n",
      "computing SPICE score...\n",
      "SPICE: 0.062\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.064\n",
      "2022-04-09 10:11:21,328 - INFO: eval_beam_3 SPIDEr: 0.0644\n",
      "loading annotations into memory...\n",
      "0:00:00.003693\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7350, 'reflen': 9182, 'guess': [7350, 6326, 5302, 4278], 'correct': [3599, 821, 223, 55]}\n",
      "ratio: 0.800479198431627\n",
      "Bleu_1: 0.382\n",
      "Bleu_2: 0.196\n",
      "Bleu_3: 0.108\n",
      "Bleu_4: 0.060\n",
      "computing METEOR score...\n",
      "METEOR: 0.102\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.280\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.075\n",
      "computing SPICE score...\n",
      "SPICE: 0.062\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.069\n",
      "2022-04-09 10:11:51,560 - INFO: eval_beam_4 SPIDEr: 0.0686\n",
      "2022-04-09 10:12:08,029 - INFO: | epoch   4 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.66 | loss-text 3.9475\n",
      "2022-04-09 10:12:24,222 - INFO: | epoch   4 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.92 | loss-text 3.9298\n",
      "2022-04-09 10:12:40,449 - INFO: | epoch   4 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.27 | loss-text 3.9565\n",
      "2022-04-09 10:12:56,671 - INFO: | epoch   4 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.21 | loss-text 3.9376\n",
      "2022-04-09 10:13:12,967 - INFO: | epoch   4 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.96 | loss-text 3.8674\n",
      "2022-04-09 10:13:29,267 - INFO: | epoch   4 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.99 | loss-text 3.9180\n",
      "2022-04-09 10:13:45,512 - INFO: | epoch   4 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 162.45 | loss-text 3.8877\n",
      "2022-04-09 10:14:01,836 - INFO: | epoch   4 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.23 | loss-text 3.8935\n",
      "2022-04-09 10:14:18,213 - INFO: | epoch   4 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.76 | loss-text 3.9787\n",
      "2022-04-09 10:14:34,448 - INFO: | epoch   4 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 162.35 | loss-text 3.9178\n",
      "2022-04-09 10:14:50,793 - INFO: | epoch   4 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.43 | loss-text 3.8974\n",
      "2022-04-09 10:15:07,296 - INFO: | epoch   4 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 165.03 | loss-text 3.9134\n",
      "2022-04-09 10:15:23,621 - INFO: | epoch   4 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.24 | loss-text 3.8951\n",
      "2022-04-09 10:15:40,122 - INFO: | epoch   4 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 165.01 | loss-text 3.8982\n",
      "2022-04-09 10:15:56,421 - INFO: | epoch   4 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 162.98 | loss-text 3.8985\n",
      "2022-04-09 10:16:12,843 - INFO: | epoch   4 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.21 | loss-text 3.9181\n",
      "2022-04-09 10:16:29,246 - INFO: | epoch   4 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.03 | loss-text 3.8818\n",
      "2022-04-09 10:16:45,721 - INFO: | epoch   4 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.74 | loss-text 3.8511\n",
      "2022-04-09 10:17:02,188 - INFO: | epoch   4 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.67 | loss-text 3.9276\n",
      "2022-04-09 10:17:18,645 - INFO: | epoch   4 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.56 | loss-text 3.8872\n",
      "2022-04-09 10:17:35,002 - INFO: | epoch   4 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 163.57 | loss-text 3.9222\n",
      "2022-04-09 10:17:51,402 - INFO: | epoch   4 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.99 | loss-text 3.8505\n",
      "2022-04-09 10:18:07,850 - INFO: | epoch   4 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.47 | loss-text 3.9135\n",
      "2022-04-09 10:18:24,311 - INFO: | epoch   4 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.60 | loss-text 3.8471\n",
      "2022-04-09 10:18:40,697 - INFO: | epoch   4 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.85 | loss-text 3.8822\n",
      "2022-04-09 10:18:57,016 - INFO: | epoch   4 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.19 | loss-text 3.9309\n",
      "2022-04-09 10:19:13,323 - INFO: | epoch   4 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.06 | loss-text 3.8582\n",
      "2022-04-09 10:19:29,747 - INFO: | epoch   4 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.23 | loss-text 3.9079\n",
      "2022-04-09 10:19:46,141 - INFO: | epoch   4 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.93 | loss-text 3.8719\n",
      "2022-04-09 10:20:02,578 - INFO: | epoch   4 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.36 | loss-text 3.8874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003819\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9671, 'reflen': 10017, 'guess': [9671, 8647, 7623, 6599], 'correct': [4249, 1106, 368, 86]}\n",
      "ratio: 0.9654587201756049\n",
      "Bleu_1: 0.424\n",
      "Bleu_2: 0.229\n",
      "Bleu_3: 0.135\n",
      "Bleu_4: 0.074\n",
      "computing METEOR score...\n",
      "METEOR: 0.115\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.296\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.119\n",
      "computing SPICE score...\n",
      "SPICE: 0.057\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.088\n",
      "2022-04-09 10:20:39,373 - INFO: eval_greddy SPIDEr: 0.0884\n",
      "loading annotations into memory...\n",
      "0:00:00.003984\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8424, 'reflen': 9517, 'guess': [8424, 7400, 6376, 5352], 'correct': [3667, 1016, 376, 95]}\n",
      "ratio: 0.8851528843121902\n",
      "Bleu_1: 0.382\n",
      "Bleu_2: 0.215\n",
      "Bleu_3: 0.134\n",
      "Bleu_4: 0.078\n",
      "computing METEOR score...\n",
      "METEOR: 0.097\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.276\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.109\n",
      "computing SPICE score...\n",
      "SPICE: 0.059\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.084\n",
      "2022-04-09 10:21:06,493 - INFO: eval_beam_2 SPIDEr: 0.0838\n",
      "loading annotations into memory...\n",
      "0:00:00.004001\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7686, 'reflen': 9244, 'guess': [7686, 6662, 5638, 4614], 'correct': [3500, 987, 356, 87]}\n",
      "ratio: 0.8314582431846785\n",
      "Bleu_1: 0.372\n",
      "Bleu_2: 0.212\n",
      "Bleu_3: 0.132\n",
      "Bleu_4: 0.077\n",
      "computing METEOR score...\n",
      "METEOR: 0.097\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.278\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.106\n",
      "computing SPICE score...\n",
      "SPICE: 0.057\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.082\n",
      "2022-04-09 10:21:33,690 - INFO: eval_beam_3 SPIDEr: 0.0818\n",
      "loading annotations into memory...\n",
      "0:00:00.003981\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7431, 'reflen': 9216, 'guess': [7431, 6407, 5383, 4359], 'correct': [3583, 1068, 415, 93]}\n",
      "ratio: 0.8063151041665791\n",
      "Bleu_1: 0.379\n",
      "Bleu_2: 0.223\n",
      "Bleu_3: 0.144\n",
      "Bleu_4: 0.084\n",
      "computing METEOR score...\n",
      "METEOR: 0.100\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.286\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.114\n",
      "computing SPICE score...\n",
      "SPICE: 0.058\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.086\n",
      "2022-04-09 10:22:07,735 - INFO: eval_beam_4 SPIDEr: 0.0859\n",
      "2022-04-09 10:22:24,291 - INFO: | epoch   5 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.53 | loss-text 3.8552\n",
      "2022-04-09 10:22:40,512 - INFO: | epoch   5 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.20 | loss-text 3.8349\n",
      "2022-04-09 10:22:56,936 - INFO: | epoch   5 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 164.23 | loss-text 3.8623\n",
      "2022-04-09 10:23:13,189 - INFO: | epoch   5 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.52 | loss-text 3.8455\n",
      "2022-04-09 10:23:29,499 - INFO: | epoch   5 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.10 | loss-text 3.8508\n",
      "2022-04-09 10:23:45,756 - INFO: | epoch   5 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.56 | loss-text 3.8132\n",
      "2022-04-09 10:24:02,078 - INFO: | epoch   5 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.21 | loss-text 3.8358\n",
      "2022-04-09 10:24:18,425 - INFO: | epoch   5 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.46 | loss-text 3.8029\n",
      "2022-04-09 10:24:34,710 - INFO: | epoch   5 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 162.84 | loss-text 3.8594\n",
      "2022-04-09 10:24:51,099 - INFO: | epoch   5 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.89 | loss-text 3.8228\n",
      "2022-04-09 10:25:07,542 - INFO: | epoch   5 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.42 | loss-text 3.8345\n",
      "2022-04-09 10:25:23,853 - INFO: | epoch   5 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.11 | loss-text 3.8163\n",
      "2022-04-09 10:25:40,165 - INFO: | epoch   5 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.11 | loss-text 3.8525\n",
      "2022-04-09 10:25:56,527 - INFO: | epoch   5 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.61 | loss-text 3.8471\n",
      "2022-04-09 10:26:12,987 - INFO: | epoch   5 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.60 | loss-text 3.7918\n",
      "2022-04-09 10:26:29,292 - INFO: | epoch   5 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.04 | loss-text 3.8707\n",
      "2022-04-09 10:26:45,713 - INFO: | epoch   5 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.20 | loss-text 3.8309\n",
      "2022-04-09 10:27:02,158 - INFO: | epoch   5 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.44 | loss-text 3.8081\n",
      "2022-04-09 10:27:18,512 - INFO: | epoch   5 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.53 | loss-text 3.8043\n",
      "2022-04-09 10:27:34,802 - INFO: | epoch   5 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 162.90 | loss-text 3.8312\n",
      "2022-04-09 10:27:51,348 - INFO: | epoch   5 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 165.45 | loss-text 3.8074\n",
      "2022-04-09 10:28:07,717 - INFO: | epoch   5 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.69 | loss-text 3.8050\n",
      "2022-04-09 10:28:24,200 - INFO: | epoch   5 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.82 | loss-text 3.8245\n",
      "2022-04-09 10:28:40,602 - INFO: | epoch   5 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.01 | loss-text 3.7845\n",
      "2022-04-09 10:28:56,942 - INFO: | epoch   5 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.39 | loss-text 3.8632\n",
      "2022-04-09 10:29:13,411 - INFO: | epoch   5 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.69 | loss-text 3.8025\n",
      "2022-04-09 10:29:29,771 - INFO: | epoch   5 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.59 | loss-text 3.7754\n",
      "2022-04-09 10:29:46,094 - INFO: | epoch   5 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.23 | loss-text 3.8390\n",
      "2022-04-09 10:30:02,395 - INFO: | epoch   5 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.00 | loss-text 3.8169\n",
      "2022-04-09 10:30:18,800 - INFO: | epoch   5 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.04 | loss-text 3.7539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003927\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 13300, 'reflen': 11493, 'guess': [13300, 12276, 11252, 10228], 'correct': [4673, 1316, 454, 109]}\n",
      "ratio: 1.157226137648903\n",
      "Bleu_1: 0.351\n",
      "Bleu_2: 0.194\n",
      "Bleu_3: 0.115\n",
      "Bleu_4: 0.063\n",
      "computing METEOR score...\n",
      "METEOR: 0.118\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.289\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.111\n",
      "computing SPICE score...\n",
      "SPICE: 0.069\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.090\n",
      "2022-04-09 10:30:56,574 - INFO: eval_greddy SPIDEr: 0.0898\n",
      "loading annotations into memory...\n",
      "0:00:00.004000\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8001, 'reflen': 9478, 'guess': [8001, 6977, 5953, 4929], 'correct': [4060, 1223, 463, 126]}\n",
      "ratio: 0.8441654357458489\n",
      "Bleu_1: 0.422\n",
      "Bleu_2: 0.248\n",
      "Bleu_3: 0.158\n",
      "Bleu_4: 0.096\n",
      "computing METEOR score...\n",
      "METEOR: 0.115\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.307\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.148\n",
      "computing SPICE score...\n",
      "SPICE: 0.069\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.109\n",
      "2022-04-09 10:31:27,201 - INFO: eval_beam_2 SPIDEr: 0.1086\n",
      "loading annotations into memory...\n",
      "0:00:00.003995\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7299, 'reflen': 9244, 'guess': [7299, 6275, 5251, 4227], 'correct': [3891, 1374, 539, 137]}\n",
      "ratio: 0.7895932496753797\n",
      "Bleu_1: 0.408\n",
      "Bleu_2: 0.262\n",
      "Bleu_3: 0.175\n",
      "Bleu_4: 0.108\n",
      "computing METEOR score...\n",
      "METEOR: 0.115\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.315\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.166\n",
      "computing SPICE score...\n",
      "SPICE: 0.073\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.120\n",
      "2022-04-09 10:31:53,006 - INFO: eval_beam_3 SPIDEr: 0.1197\n",
      "loading annotations into memory...\n",
      "0:00:00.003933\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7119, 'reflen': 9221, 'guess': [7119, 6095, 5071, 4047], 'correct': [3832, 1404, 574, 141]}\n",
      "ratio: 0.7720420778656575\n",
      "Bleu_1: 0.401\n",
      "Bleu_2: 0.262\n",
      "Bleu_3: 0.180\n",
      "Bleu_4: 0.111\n",
      "computing METEOR score...\n",
      "METEOR: 0.115\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.315\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.170\n",
      "computing SPICE score...\n",
      "SPICE: 0.073\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.121\n",
      "2022-04-09 10:32:21,407 - INFO: eval_beam_4 SPIDEr: 0.1212\n",
      "2022-04-09 10:32:37,970 - INFO: | epoch   6 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.60 | loss-text 3.8136\n",
      "2022-04-09 10:32:54,296 - INFO: | epoch   6 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 163.25 | loss-text 3.7929\n",
      "2022-04-09 10:33:10,672 - INFO: | epoch   6 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 163.76 | loss-text 3.7928\n",
      "2022-04-09 10:33:26,910 - INFO: | epoch   6 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.37 | loss-text 3.7421\n",
      "2022-04-09 10:33:43,092 - INFO: | epoch   6 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 161.81 | loss-text 3.7871\n",
      "2022-04-09 10:33:59,242 - INFO: | epoch   6 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 161.49 | loss-text 3.7938\n",
      "2022-04-09 10:34:15,741 - INFO: | epoch   6 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 164.99 | loss-text 3.7537\n",
      "2022-04-09 10:34:32,088 - INFO: | epoch   6 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.46 | loss-text 3.8217\n",
      "2022-04-09 10:34:48,593 - INFO: | epoch   6 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 165.04 | loss-text 3.7937\n",
      "2022-04-09 10:35:05,094 - INFO: | epoch   6 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 165.00 | loss-text 3.7586\n",
      "2022-04-09 10:35:21,545 - INFO: | epoch   6 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.50 | loss-text 3.7508\n",
      "2022-04-09 10:35:37,966 - INFO: | epoch   6 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.21 | loss-text 3.7562\n",
      "2022-04-09 10:35:54,397 - INFO: | epoch   6 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.30 | loss-text 3.7781\n",
      "2022-04-09 10:36:10,773 - INFO: | epoch   6 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.75 | loss-text 3.7804\n",
      "2022-04-09 10:36:27,153 - INFO: | epoch   6 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.80 | loss-text 3.7495\n",
      "2022-04-09 10:36:43,487 - INFO: | epoch   6 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.33 | loss-text 3.7654\n",
      "2022-04-09 10:36:59,913 - INFO: | epoch   6 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.25 | loss-text 3.8192\n",
      "2022-04-09 10:37:16,383 - INFO: | epoch   6 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.69 | loss-text 3.7665\n",
      "2022-04-09 10:37:32,802 - INFO: | epoch   6 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.19 | loss-text 3.7288\n",
      "2022-04-09 10:37:49,193 - INFO: | epoch   6 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.90 | loss-text 3.7427\n",
      "2022-04-09 10:38:05,578 - INFO: | epoch   6 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 163.84 | loss-text 3.7273\n",
      "2022-04-09 10:38:21,874 - INFO: | epoch   6 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 162.95 | loss-text 3.7339\n",
      "2022-04-09 10:38:38,246 - INFO: | epoch   6 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.72 | loss-text 3.7011\n",
      "2022-04-09 10:38:54,634 - INFO: | epoch   6 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.87 | loss-text 3.7826\n",
      "2022-04-09 10:39:11,035 - INFO: | epoch   6 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.01 | loss-text 3.7359\n",
      "2022-04-09 10:39:27,301 - INFO: | epoch   6 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 162.65 | loss-text 3.7384\n",
      "2022-04-09 10:39:43,605 - INFO: | epoch   6 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.04 | loss-text 3.7436\n",
      "2022-04-09 10:39:59,972 - INFO: | epoch   6 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.66 | loss-text 3.7744\n",
      "2022-04-09 10:40:16,458 - INFO: | epoch   6 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.85 | loss-text 3.7209\n",
      "2022-04-09 10:40:32,996 - INFO: | epoch   6 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 165.37 | loss-text 3.8060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003833\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11521, 'reflen': 11060, 'guess': [11521, 10497, 9473, 8449], 'correct': [4573, 1268, 431, 112]}\n",
      "ratio: 1.0416817359854391\n",
      "Bleu_1: 0.397\n",
      "Bleu_2: 0.219\n",
      "Bleu_3: 0.130\n",
      "Bleu_4: 0.073\n",
      "computing METEOR score...\n",
      "METEOR: 0.118\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.295\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.120\n",
      "computing SPICE score...\n",
      "SPICE: 0.071\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.096\n",
      "2022-04-09 10:41:13,169 - INFO: eval_greddy SPIDEr: 0.0956\n",
      "loading annotations into memory...\n",
      "0:00:00.004149\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8206, 'reflen': 9422, 'guess': [8206, 7182, 6158, 5134], 'correct': [3944, 1206, 448, 128]}\n",
      "ratio: 0.8709403523667086\n",
      "Bleu_1: 0.414\n",
      "Bleu_2: 0.245\n",
      "Bleu_3: 0.156\n",
      "Bleu_4: 0.095\n",
      "computing METEOR score...\n",
      "METEOR: 0.113\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.305\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.153\n",
      "computing SPICE score...\n",
      "SPICE: 0.071\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.112\n",
      "2022-04-09 10:41:37,627 - INFO: eval_beam_2 SPIDEr: 0.1121\n",
      "loading annotations into memory...\n",
      "0:00:00.003667\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7752, 'reflen': 9268, 'guess': [7752, 6728, 5704, 4680], 'correct': [3781, 1162, 422, 120]}\n",
      "ratio: 0.8364264134655981\n",
      "Bleu_1: 0.401\n",
      "Bleu_2: 0.239\n",
      "Bleu_3: 0.151\n",
      "Bleu_4: 0.092\n",
      "computing METEOR score...\n",
      "METEOR: 0.113\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.302\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.157\n",
      "computing SPICE score...\n",
      "SPICE: 0.073\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.115\n",
      "2022-04-09 10:42:05,362 - INFO: eval_beam_3 SPIDEr: 0.1150\n",
      "loading annotations into memory...\n",
      "0:00:00.004041\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7502, 'reflen': 9238, 'guess': [7502, 6478, 5454, 4430], 'correct': [3614, 1106, 406, 126]}\n",
      "ratio: 0.8120805369126637\n",
      "Bleu_1: 0.382\n",
      "Bleu_2: 0.228\n",
      "Bleu_3: 0.145\n",
      "Bleu_4: 0.091\n",
      "computing METEOR score...\n",
      "METEOR: 0.110\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.297\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.157\n",
      "computing SPICE score...\n",
      "SPICE: 0.070\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.114\n",
      "2022-04-09 10:42:37,065 - INFO: eval_beam_4 SPIDEr: 0.1138\n",
      "2022-04-09 10:42:53,566 - INFO: | epoch   7 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.98 | loss-text 3.7170\n",
      "2022-04-09 10:43:09,782 - INFO: | epoch   7 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.15 | loss-text 3.7497\n",
      "2022-04-09 10:43:25,999 - INFO: | epoch   7 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.16 | loss-text 3.7134\n",
      "2022-04-09 10:43:42,179 - INFO: | epoch   7 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 161.80 | loss-text 3.6706\n",
      "2022-04-09 10:43:58,425 - INFO: | epoch   7 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.45 | loss-text 3.7076\n",
      "2022-04-09 10:44:14,647 - INFO: | epoch   7 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.21 | loss-text 3.7912\n",
      "2022-04-09 10:44:31,034 - INFO: | epoch   7 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.86 | loss-text 3.7195\n",
      "2022-04-09 10:44:47,482 - INFO: | epoch   7 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.48 | loss-text 3.7481\n",
      "2022-04-09 10:45:03,830 - INFO: | epoch   7 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.47 | loss-text 3.7352\n",
      "2022-04-09 10:45:20,375 - INFO: | epoch   7 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 165.44 | loss-text 3.6956\n",
      "2022-04-09 10:45:36,929 - INFO: | epoch   7 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 165.53 | loss-text 3.6729\n",
      "2022-04-09 10:45:53,252 - INFO: | epoch   7 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.22 | loss-text 3.6723\n",
      "2022-04-09 10:46:09,481 - INFO: | epoch   7 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 162.29 | loss-text 3.7056\n",
      "2022-04-09 10:46:25,810 - INFO: | epoch   7 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.28 | loss-text 3.7625\n",
      "2022-04-09 10:46:42,110 - INFO: | epoch   7 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.00 | loss-text 3.6916\n",
      "2022-04-09 10:46:58,655 - INFO: | epoch   7 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 165.44 | loss-text 3.7219\n",
      "2022-04-09 10:47:15,095 - INFO: | epoch   7 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.40 | loss-text 3.7027\n",
      "2022-04-09 10:47:31,431 - INFO: | epoch   7 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.35 | loss-text 3.7211\n",
      "2022-04-09 10:47:47,879 - INFO: | epoch   7 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.47 | loss-text 3.6956\n",
      "2022-04-09 10:48:04,384 - INFO: | epoch   7 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 165.04 | loss-text 3.7786\n",
      "2022-04-09 10:48:20,917 - INFO: | epoch   7 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 165.32 | loss-text 3.6498\n",
      "2022-04-09 10:48:37,437 - INFO: | epoch   7 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 165.20 | loss-text 3.7432\n",
      "2022-04-09 10:48:53,950 - INFO: | epoch   7 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 165.13 | loss-text 3.6995\n",
      "2022-04-09 10:49:10,266 - INFO: | epoch   7 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.14 | loss-text 3.6837\n",
      "2022-04-09 10:49:26,646 - INFO: | epoch   7 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.80 | loss-text 3.6902\n",
      "2022-04-09 10:49:43,010 - INFO: | epoch   7 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.63 | loss-text 3.6790\n",
      "2022-04-09 10:49:59,333 - INFO: | epoch   7 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.23 | loss-text 3.7410\n",
      "2022-04-09 10:50:15,711 - INFO: | epoch   7 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.77 | loss-text 3.6655\n",
      "2022-04-09 10:50:32,057 - INFO: | epoch   7 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.46 | loss-text 3.7231\n",
      "2022-04-09 10:50:48,435 - INFO: | epoch   7 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.77 | loss-text 3.6580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003965\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 12346, 'reflen': 11261, 'guess': [12346, 11322, 10298, 9274], 'correct': [4709, 1337, 448, 116]}\n",
      "ratio: 1.0963502353253622\n",
      "Bleu_1: 0.381\n",
      "Bleu_2: 0.212\n",
      "Bleu_3: 0.125\n",
      "Bleu_4: 0.070\n",
      "computing METEOR score...\n",
      "METEOR: 0.119\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.292\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.135\n",
      "computing SPICE score...\n",
      "SPICE: 0.069\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.102\n",
      "2022-04-09 10:51:30,951 - INFO: eval_greddy SPIDEr: 0.1019\n",
      "loading annotations into memory...\n",
      "0:00:00.003933\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9295, 'reflen': 9983, 'guess': [9295, 8271, 7247, 6223], 'correct': [4409, 1458, 569, 163]}\n",
      "ratio: 0.9310828408293167\n",
      "Bleu_1: 0.440\n",
      "Bleu_2: 0.269\n",
      "Bleu_3: 0.174\n",
      "Bleu_4: 0.106\n",
      "computing METEOR score...\n",
      "METEOR: 0.125\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.314\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.183\n",
      "computing SPICE score...\n",
      "SPICE: 0.078\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.130\n",
      "2022-04-09 10:52:01,770 - INFO: eval_beam_2 SPIDEr: 0.1304\n",
      "loading annotations into memory...\n",
      "0:00:00.003900\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7899, 'reflen': 9329, 'guess': [7899, 6875, 5851, 4827], 'correct': [4062, 1400, 543, 145]}\n",
      "ratio: 0.8467145460391416\n",
      "Bleu_1: 0.429\n",
      "Bleu_2: 0.270\n",
      "Bleu_3: 0.178\n",
      "Bleu_4: 0.109\n",
      "computing METEOR score...\n",
      "METEOR: 0.121\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.318\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.183\n",
      "computing SPICE score...\n",
      "SPICE: 0.076\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.130\n",
      "2022-04-09 10:52:34,159 - INFO: eval_beam_3 SPIDEr: 0.1295\n",
      "loading annotations into memory...\n",
      "0:00:00.003976\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7424, 'reflen': 9263, 'guess': [7424, 6400, 5376, 4352], 'correct': [3808, 1341, 543, 149]}\n",
      "ratio: 0.8014682068443483\n",
      "Bleu_1: 0.400\n",
      "Bleu_2: 0.256\n",
      "Bleu_3: 0.173\n",
      "Bleu_4: 0.108\n",
      "computing METEOR score...\n",
      "METEOR: 0.118\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.312\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.191\n",
      "computing SPICE score...\n",
      "SPICE: 0.071\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.131\n",
      "2022-04-09 10:53:07,323 - INFO: eval_beam_4 SPIDEr: 0.1309\n",
      "2022-04-09 10:53:23,854 - INFO: | epoch   8 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.28 | loss-text 3.6636\n",
      "2022-04-09 10:53:40,112 - INFO: | epoch   8 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.56 | loss-text 3.6514\n",
      "2022-04-09 10:53:56,354 - INFO: | epoch   8 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.42 | loss-text 3.6641\n",
      "2022-04-09 10:54:12,656 - INFO: | epoch   8 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.01 | loss-text 3.6788\n",
      "2022-04-09 10:54:28,888 - INFO: | epoch   8 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.32 | loss-text 3.6384\n",
      "2022-04-09 10:54:45,292 - INFO: | epoch   8 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 164.03 | loss-text 3.7300\n",
      "2022-04-09 10:55:01,761 - INFO: | epoch   8 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 164.68 | loss-text 3.6521\n",
      "2022-04-09 10:55:18,070 - INFO: | epoch   8 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.08 | loss-text 3.6418\n",
      "2022-04-09 10:55:34,481 - INFO: | epoch   8 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.10 | loss-text 3.6296\n",
      "2022-04-09 10:55:50,769 - INFO: | epoch   8 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 162.87 | loss-text 3.7098\n",
      "2022-04-09 10:56:07,137 - INFO: | epoch   8 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.67 | loss-text 3.6367\n",
      "2022-04-09 10:56:23,470 - INFO: | epoch   8 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.33 | loss-text 3.6765\n",
      "2022-04-09 10:56:39,851 - INFO: | epoch   8 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.80 | loss-text 3.6866\n",
      "2022-04-09 10:56:56,293 - INFO: | epoch   8 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.42 | loss-text 3.6703\n",
      "2022-04-09 10:57:12,593 - INFO: | epoch   8 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 162.99 | loss-text 3.6353\n",
      "2022-04-09 10:57:28,994 - INFO: | epoch   8 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.00 | loss-text 3.7544\n",
      "2022-04-09 10:57:45,392 - INFO: | epoch   8 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.97 | loss-text 3.6605\n",
      "2022-04-09 10:58:01,854 - INFO: | epoch   8 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.62 | loss-text 3.6990\n",
      "2022-04-09 10:58:18,341 - INFO: | epoch   8 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.86 | loss-text 3.6854\n",
      "2022-04-09 10:58:34,710 - INFO: | epoch   8 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.68 | loss-text 3.6793\n",
      "2022-04-09 10:58:51,124 - INFO: | epoch   8 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.13 | loss-text 3.6186\n",
      "2022-04-09 10:59:07,404 - INFO: | epoch   8 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 162.80 | loss-text 3.6907\n",
      "2022-04-09 10:59:23,793 - INFO: | epoch   8 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.88 | loss-text 3.6521\n",
      "2022-04-09 10:59:40,267 - INFO: | epoch   8 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.74 | loss-text 3.7063\n",
      "2022-04-09 10:59:56,553 - INFO: | epoch   8 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 162.85 | loss-text 3.7441\n",
      "2022-04-09 11:00:12,911 - INFO: | epoch   8 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.57 | loss-text 3.7057\n",
      "2022-04-09 11:00:29,303 - INFO: | epoch   8 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.92 | loss-text 3.7180\n",
      "2022-04-09 11:00:45,644 - INFO: | epoch   8 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.40 | loss-text 3.6279\n",
      "2022-04-09 11:01:02,054 - INFO: | epoch   8 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.09 | loss-text 3.7128\n",
      "2022-04-09 11:01:18,560 - INFO: | epoch   8 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 165.05 | loss-text 3.6273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003843\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10077, 'reflen': 10183, 'guess': [10077, 9053, 8029, 7005], 'correct': [4624, 1359, 466, 123]}\n",
      "ratio: 0.9895904939604252\n",
      "Bleu_1: 0.454\n",
      "Bleu_2: 0.260\n",
      "Bleu_3: 0.157\n",
      "Bleu_4: 0.091\n",
      "computing METEOR score...\n",
      "METEOR: 0.121\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.311\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.143\n",
      "computing SPICE score...\n",
      "SPICE: 0.067\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.105\n",
      "2022-04-09 11:01:58,198 - INFO: eval_greddy SPIDEr: 0.1050\n",
      "loading annotations into memory...\n",
      "0:00:00.003980\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8285, 'reflen': 9410, 'guess': [8285, 7261, 6237, 5213], 'correct': [4266, 1417, 530, 144]}\n",
      "ratio: 0.8804463336874728\n",
      "Bleu_1: 0.450\n",
      "Bleu_2: 0.277\n",
      "Bleu_3: 0.178\n",
      "Bleu_4: 0.108\n",
      "computing METEOR score...\n",
      "METEOR: 0.120\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.319\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.179\n",
      "computing SPICE score...\n",
      "SPICE: 0.076\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.128\n",
      "2022-04-09 11:02:25,789 - INFO: eval_beam_2 SPIDEr: 0.1275\n",
      "loading annotations into memory...\n",
      "0:00:00.003990\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7788, 'reflen': 9248, 'guess': [7788, 6764, 5740, 4716], 'correct': [4090, 1371, 533, 151]}\n",
      "ratio: 0.8421280276815698\n",
      "Bleu_1: 0.435\n",
      "Bleu_2: 0.270\n",
      "Bleu_3: 0.178\n",
      "Bleu_4: 0.111\n",
      "computing METEOR score...\n",
      "METEOR: 0.122\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.323\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.188\n",
      "computing SPICE score...\n",
      "SPICE: 0.077\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.132\n",
      "2022-04-09 11:02:55,773 - INFO: eval_beam_3 SPIDEr: 0.1322\n",
      "loading annotations into memory...\n",
      "0:00:00.003887\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7699, 'reflen': 9234, 'guess': [7699, 6675, 5651, 4627], 'correct': [3979, 1329, 522, 155]}\n",
      "ratio: 0.8337665150529744\n",
      "Bleu_1: 0.423\n",
      "Bleu_2: 0.263\n",
      "Bleu_3: 0.174\n",
      "Bleu_4: 0.109\n",
      "computing METEOR score...\n",
      "METEOR: 0.121\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.318\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.191\n",
      "computing SPICE score...\n",
      "SPICE: 0.074\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.133\n",
      "2022-04-09 11:03:26,454 - INFO: eval_beam_4 SPIDEr: 0.1328\n",
      "2022-04-09 11:03:42,888 - INFO: | epoch   9 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.31 | loss-text 3.6456\n",
      "2022-04-09 11:03:58,946 - INFO: | epoch   9 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 160.56 | loss-text 3.6485\n",
      "2022-04-09 11:04:15,192 - INFO: | epoch   9 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.46 | loss-text 3.6320\n",
      "2022-04-09 11:04:31,491 - INFO: | epoch   9 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.98 | loss-text 3.6218\n",
      "2022-04-09 11:04:47,744 - INFO: | epoch   9 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.53 | loss-text 3.6540\n",
      "2022-04-09 11:05:04,069 - INFO: | epoch   9 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.24 | loss-text 3.6125\n",
      "2022-04-09 11:05:20,444 - INFO: | epoch   9 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.74 | loss-text 3.6350\n",
      "2022-04-09 11:05:36,873 - INFO: | epoch   9 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.27 | loss-text 3.6577\n",
      "2022-04-09 11:05:53,072 - INFO: | epoch   9 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 161.99 | loss-text 3.6709\n",
      "2022-04-09 11:06:09,392 - INFO: | epoch   9 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.19 | loss-text 3.6268\n",
      "2022-04-09 11:06:25,913 - INFO: | epoch   9 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 165.20 | loss-text 3.6651\n",
      "2022-04-09 11:06:42,409 - INFO: | epoch   9 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.96 | loss-text 3.6385\n",
      "2022-04-09 11:06:58,791 - INFO: | epoch   9 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.81 | loss-text 3.6251\n",
      "2022-04-09 11:07:15,317 - INFO: | epoch   9 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 165.26 | loss-text 3.5779\n",
      "2022-04-09 11:07:31,756 - INFO: | epoch   9 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.37 | loss-text 3.6241\n",
      "2022-04-09 11:07:48,281 - INFO: | epoch   9 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 165.25 | loss-text 3.5736\n",
      "2022-04-09 11:08:04,616 - INFO: | epoch   9 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.34 | loss-text 3.6281\n",
      "2022-04-09 11:08:20,881 - INFO: | epoch   9 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 162.64 | loss-text 3.6862\n",
      "2022-04-09 11:08:37,104 - INFO: | epoch   9 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 162.23 | loss-text 3.6388\n",
      "2022-04-09 11:08:53,397 - INFO: | epoch   9 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 162.92 | loss-text 3.6919\n",
      "2022-04-09 11:09:09,847 - INFO: | epoch   9 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.49 | loss-text 3.6123\n",
      "2022-04-09 11:09:26,170 - INFO: | epoch   9 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.22 | loss-text 3.6116\n",
      "2022-04-09 11:09:42,511 - INFO: | epoch   9 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.41 | loss-text 3.5974\n",
      "2022-04-09 11:09:59,032 - INFO: | epoch   9 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 165.20 | loss-text 3.6085\n",
      "2022-04-09 11:10:15,498 - INFO: | epoch   9 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.66 | loss-text 3.5881\n",
      "2022-04-09 11:10:31,960 - INFO: | epoch   9 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.61 | loss-text 3.6422\n",
      "2022-04-09 11:10:48,454 - INFO: | epoch   9 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.93 | loss-text 3.6504\n",
      "2022-04-09 11:11:04,967 - INFO: | epoch   9 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 165.13 | loss-text 3.6307\n",
      "2022-04-09 11:11:21,426 - INFO: | epoch   9 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.58 | loss-text 3.6661\n",
      "2022-04-09 11:11:37,766 - INFO: | epoch   9 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.39 | loss-text 3.6124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003903\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 12081, 'reflen': 11435, 'guess': [12081, 11057, 10033, 9009], 'correct': [5278, 1539, 536, 132]}\n",
      "ratio: 1.0564932225622163\n",
      "Bleu_1: 0.437\n",
      "Bleu_2: 0.247\n",
      "Bleu_3: 0.148\n",
      "Bleu_4: 0.083\n",
      "computing METEOR score...\n",
      "METEOR: 0.136\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.320\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.158\n",
      "computing SPICE score...\n",
      "SPICE: 0.078\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.118\n",
      "2022-04-09 11:12:17,142 - INFO: eval_greddy SPIDEr: 0.1180\n",
      "loading annotations into memory...\n",
      "0:00:00.004191\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9420, 'reflen': 9995, 'guess': [9420, 8396, 7372, 6348], 'correct': [4730, 1560, 602, 177]}\n",
      "ratio: 0.9424712356177146\n",
      "Bleu_1: 0.472\n",
      "Bleu_2: 0.287\n",
      "Bleu_3: 0.185\n",
      "Bleu_4: 0.114\n",
      "computing METEOR score...\n",
      "METEOR: 0.133\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.325\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.198\n",
      "computing SPICE score...\n",
      "SPICE: 0.083\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.140\n",
      "2022-04-09 11:12:45,694 - INFO: eval_beam_2 SPIDEr: 0.1404\n",
      "loading annotations into memory...\n",
      "0:00:00.003673\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7962, 'reflen': 9343, 'guess': [7962, 6938, 5914, 4890], 'correct': [4159, 1338, 526, 168]}\n",
      "ratio: 0.85218880445244\n",
      "Bleu_1: 0.439\n",
      "Bleu_2: 0.267\n",
      "Bleu_3: 0.175\n",
      "Bleu_4: 0.111\n",
      "computing METEOR score...\n",
      "METEOR: 0.126\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.322\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.195\n",
      "computing SPICE score...\n",
      "SPICE: 0.079\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.137\n",
      "2022-04-09 11:13:18,871 - INFO: eval_beam_3 SPIDEr: 0.1370\n",
      "loading annotations into memory...\n",
      "0:00:00.004058\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7602, 'reflen': 9279, 'guess': [7602, 6578, 5554, 4530], 'correct': [3996, 1276, 505, 161]}\n",
      "ratio: 0.8192693178143313\n",
      "Bleu_1: 0.422\n",
      "Bleu_2: 0.256\n",
      "Bleu_3: 0.168\n",
      "Bleu_4: 0.108\n",
      "computing METEOR score...\n",
      "METEOR: 0.122\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.317\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.193\n",
      "computing SPICE score...\n",
      "SPICE: 0.077\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.135\n",
      "2022-04-09 11:13:56,675 - INFO: eval_beam_4 SPIDEr: 0.1349\n",
      "2022-04-09 11:14:13,133 - INFO: | epoch  10 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.55 | loss-text 3.6429\n",
      "2022-04-09 11:14:29,222 - INFO: | epoch  10 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 160.88 | loss-text 3.5997\n",
      "2022-04-09 11:14:45,358 - INFO: | epoch  10 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 161.35 | loss-text 3.5649\n",
      "2022-04-09 11:15:01,546 - INFO: | epoch  10 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 161.87 | loss-text 3.6350\n",
      "2022-04-09 11:15:17,904 - INFO: | epoch  10 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.57 | loss-text 3.5826\n",
      "2022-04-09 11:15:34,256 - INFO: | epoch  10 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.51 | loss-text 3.5924\n",
      "2022-04-09 11:15:50,592 - INFO: | epoch  10 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.35 | loss-text 3.6506\n",
      "2022-04-09 11:16:06,833 - INFO: | epoch  10 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 162.40 | loss-text 3.6115\n",
      "2022-04-09 11:16:23,265 - INFO: | epoch  10 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.31 | loss-text 3.5673\n",
      "2022-04-09 11:16:39,673 - INFO: | epoch  10 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.07 | loss-text 3.6220\n",
      "2022-04-09 11:16:56,165 - INFO: | epoch  10 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.92 | loss-text 3.5563\n",
      "2022-04-09 11:17:12,449 - INFO: | epoch  10 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 162.83 | loss-text 3.6181\n",
      "2022-04-09 11:17:28,853 - INFO: | epoch  10 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.03 | loss-text 3.6723\n",
      "2022-04-09 11:17:45,253 - INFO: | epoch  10 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.00 | loss-text 3.5805\n",
      "2022-04-09 11:18:01,619 - INFO: | epoch  10 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.64 | loss-text 3.6013\n",
      "2022-04-09 11:18:17,954 - INFO: | epoch  10 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.35 | loss-text 3.6390\n",
      "2022-04-09 11:18:34,497 - INFO: | epoch  10 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 165.42 | loss-text 3.5638\n",
      "2022-04-09 11:18:51,018 - INFO: | epoch  10 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 165.19 | loss-text 3.5804\n",
      "2022-04-09 11:19:07,477 - INFO: | epoch  10 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.59 | loss-text 3.6258\n",
      "2022-04-09 11:19:23,825 - INFO: | epoch  10 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.47 | loss-text 3.5832\n",
      "2022-04-09 11:19:40,244 - INFO: | epoch  10 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.18 | loss-text 3.5955\n",
      "2022-04-09 11:19:56,510 - INFO: | epoch  10 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 162.66 | loss-text 3.5168\n",
      "2022-04-09 11:20:13,021 - INFO: | epoch  10 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 165.10 | loss-text 3.6042\n",
      "2022-04-09 11:20:29,456 - INFO: | epoch  10 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.34 | loss-text 3.5661\n",
      "2022-04-09 11:20:45,908 - INFO: | epoch  10 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.51 | loss-text 3.6036\n",
      "2022-04-09 11:21:02,217 - INFO: | epoch  10 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.09 | loss-text 3.6078\n",
      "2022-04-09 11:21:18,646 - INFO: | epoch  10 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.28 | loss-text 3.6884\n",
      "2022-04-09 11:21:34,990 - INFO: | epoch  10 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.43 | loss-text 3.5883\n",
      "2022-04-09 11:21:51,383 - INFO: | epoch  10 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.92 | loss-text 3.6284\n",
      "2022-04-09 11:22:07,847 - INFO: | epoch  10 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.64 | loss-text 3.6033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004091\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 12481, 'reflen': 11689, 'guess': [12481, 11457, 10433, 9409], 'correct': [5508, 1656, 569, 146]}\n",
      "ratio: 1.0677560099237686\n",
      "Bleu_1: 0.441\n",
      "Bleu_2: 0.253\n",
      "Bleu_3: 0.152\n",
      "Bleu_4: 0.086\n",
      "computing METEOR score...\n",
      "METEOR: 0.133\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.324\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.153\n",
      "computing SPICE score...\n",
      "SPICE: 0.079\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.116\n",
      "2022-04-09 11:22:51,422 - INFO: eval_greddy SPIDEr: 0.1157\n",
      "loading annotations into memory...\n",
      "0:00:00.003954\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10042, 'reflen': 10390, 'guess': [10042, 9018, 7994, 6970], 'correct': [5052, 1689, 645, 195]}\n",
      "ratio: 0.9665062560153064\n",
      "Bleu_1: 0.486\n",
      "Bleu_2: 0.297\n",
      "Bleu_3: 0.190\n",
      "Bleu_4: 0.117\n",
      "computing METEOR score...\n",
      "METEOR: 0.137\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.333\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.214\n",
      "computing SPICE score...\n",
      "SPICE: 0.085\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.150\n",
      "2022-04-09 11:23:22,770 - INFO: eval_beam_2 SPIDEr: 0.1497\n",
      "loading annotations into memory...\n",
      "0:00:00.003869\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8450, 'reflen': 9487, 'guess': [8450, 7426, 6402, 5378], 'correct': [4475, 1522, 607, 188]}\n",
      "ratio: 0.8906925266152744\n",
      "Bleu_1: 0.468\n",
      "Bleu_2: 0.291\n",
      "Bleu_3: 0.192\n",
      "Bleu_4: 0.122\n",
      "computing METEOR score...\n",
      "METEOR: 0.129\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.332\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.216\n",
      "computing SPICE score...\n",
      "SPICE: 0.081\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.148\n",
      "2022-04-09 11:23:52,978 - INFO: eval_beam_3 SPIDEr: 0.1482\n",
      "loading annotations into memory...\n",
      "0:00:00.003958\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7851, 'reflen': 9267, 'guess': [7851, 6827, 5803, 4779], 'correct': [4222, 1422, 588, 179]}\n",
      "ratio: 0.8471997410164187\n",
      "Bleu_1: 0.449\n",
      "Bleu_2: 0.279\n",
      "Bleu_3: 0.188\n",
      "Bleu_4: 0.120\n",
      "computing METEOR score...\n",
      "METEOR: 0.127\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.327\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.215\n",
      "computing SPICE score...\n",
      "SPICE: 0.079\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.147\n",
      "2022-04-09 11:24:26,798 - INFO: eval_beam_4 SPIDEr: 0.1470\n",
      "2022-04-09 11:24:43,326 - INFO: | epoch  11 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.24 | loss-text 3.5646\n",
      "2022-04-09 11:24:59,403 - INFO: | epoch  11 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 160.77 | loss-text 3.5340\n",
      "2022-04-09 11:25:15,660 - INFO: | epoch  11 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.55 | loss-text 3.5874\n",
      "2022-04-09 11:25:31,863 - INFO: | epoch  11 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.02 | loss-text 3.6430\n",
      "2022-04-09 11:25:48,061 - INFO: | epoch  11 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 161.97 | loss-text 3.5637\n",
      "2022-04-09 11:26:04,371 - INFO: | epoch  11 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.09 | loss-text 3.5692\n",
      "2022-04-09 11:26:20,643 - INFO: | epoch  11 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 162.72 | loss-text 3.5534\n",
      "2022-04-09 11:26:36,808 - INFO: | epoch  11 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 161.64 | loss-text 3.5695\n",
      "2022-04-09 11:26:53,168 - INFO: | epoch  11 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.59 | loss-text 3.6131\n",
      "2022-04-09 11:27:09,559 - INFO: | epoch  11 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.90 | loss-text 3.5695\n",
      "2022-04-09 11:27:26,066 - INFO: | epoch  11 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 165.06 | loss-text 3.6526\n",
      "2022-04-09 11:27:42,534 - INFO: | epoch  11 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.68 | loss-text 3.5447\n",
      "2022-04-09 11:27:58,894 - INFO: | epoch  11 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.60 | loss-text 3.5720\n",
      "2022-04-09 11:28:15,416 - INFO: | epoch  11 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 165.21 | loss-text 3.5998\n",
      "2022-04-09 11:28:31,867 - INFO: | epoch  11 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.50 | loss-text 3.5770\n",
      "2022-04-09 11:28:48,302 - INFO: | epoch  11 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.34 | loss-text 3.5673\n",
      "2022-04-09 11:29:04,631 - INFO: | epoch  11 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.29 | loss-text 3.5444\n",
      "2022-04-09 11:29:20,987 - INFO: | epoch  11 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.55 | loss-text 3.5768\n",
      "2022-04-09 11:29:37,510 - INFO: | epoch  11 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 165.23 | loss-text 3.5731\n",
      "2022-04-09 11:29:54,014 - INFO: | epoch  11 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 165.03 | loss-text 3.5200\n",
      "2022-04-09 11:30:10,440 - INFO: | epoch  11 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.26 | loss-text 3.5732\n",
      "2022-04-09 11:30:26,914 - INFO: | epoch  11 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.74 | loss-text 3.5727\n",
      "2022-04-09 11:30:43,390 - INFO: | epoch  11 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.75 | loss-text 3.5834\n",
      "2022-04-09 11:30:59,787 - INFO: | epoch  11 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.96 | loss-text 3.5782\n",
      "2022-04-09 11:31:16,088 - INFO: | epoch  11 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.00 | loss-text 3.5944\n",
      "2022-04-09 11:31:32,560 - INFO: | epoch  11 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.72 | loss-text 3.6120\n",
      "2022-04-09 11:31:48,842 - INFO: | epoch  11 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 162.81 | loss-text 3.5230\n",
      "2022-04-09 11:32:05,287 - INFO: | epoch  11 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.44 | loss-text 3.5705\n",
      "2022-04-09 11:32:21,693 - INFO: | epoch  11 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.05 | loss-text 3.5064\n",
      "2022-04-09 11:32:38,181 - INFO: | epoch  11 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.88 | loss-text 3.5725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003962\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10942, 'reflen': 10782, 'guess': [10942, 9918, 8894, 7870], 'correct': [4932, 1389, 465, 105]}\n",
      "ratio: 1.0148395473937104\n",
      "Bleu_1: 0.451\n",
      "Bleu_2: 0.251\n",
      "Bleu_3: 0.149\n",
      "Bleu_4: 0.081\n",
      "computing METEOR score...\n",
      "METEOR: 0.128\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.317\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.153\n",
      "computing SPICE score...\n",
      "SPICE: 0.073\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.113\n",
      "2022-04-09 11:33:16,644 - INFO: eval_greddy SPIDEr: 0.1131\n",
      "loading annotations into memory...\n",
      "0:00:00.003809\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8351, 'reflen': 9556, 'guess': [8351, 7327, 6303, 5279], 'correct': [4259, 1342, 488, 128]}\n",
      "ratio: 0.8739012138969365\n",
      "Bleu_1: 0.441\n",
      "Bleu_2: 0.265\n",
      "Bleu_3: 0.167\n",
      "Bleu_4: 0.100\n",
      "computing METEOR score...\n",
      "METEOR: 0.126\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.317\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.184\n",
      "computing SPICE score...\n",
      "SPICE: 0.077\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.131\n",
      "2022-04-09 11:33:45,481 - INFO: eval_beam_2 SPIDEr: 0.1306\n",
      "loading annotations into memory...\n",
      "0:00:00.004144\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7746, 'reflen': 9277, 'guess': [7746, 6722, 5698, 4674], 'correct': [4076, 1345, 515, 152]}\n",
      "ratio: 0.8349682009269338\n",
      "Bleu_1: 0.432\n",
      "Bleu_2: 0.266\n",
      "Bleu_3: 0.174\n",
      "Bleu_4: 0.109\n",
      "computing METEOR score...\n",
      "METEOR: 0.126\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.319\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.203\n",
      "computing SPICE score...\n",
      "SPICE: 0.078\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.140\n",
      "2022-04-09 11:34:14,829 - INFO: eval_beam_3 SPIDEr: 0.1405\n",
      "loading annotations into memory...\n",
      "0:00:00.003905\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7569, 'reflen': 9246, 'guess': [7569, 6545, 5521, 4497], 'correct': [3978, 1294, 504, 150]}\n",
      "ratio: 0.8186242699544863\n",
      "Bleu_1: 0.421\n",
      "Bleu_2: 0.258\n",
      "Bleu_3: 0.170\n",
      "Bleu_4: 0.107\n",
      "computing METEOR score...\n",
      "METEOR: 0.122\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.318\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.198\n",
      "computing SPICE score...\n",
      "SPICE: 0.074\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.136\n",
      "2022-04-09 11:34:46,878 - INFO: eval_beam_4 SPIDEr: 0.1359\n",
      "2022-04-09 11:35:03,442 - INFO: | epoch  12 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.61 | loss-text 3.5308\n",
      "2022-04-09 11:35:19,657 - INFO: | epoch  12 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.14 | loss-text 3.4987\n",
      "2022-04-09 11:35:35,908 - INFO: | epoch  12 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.50 | loss-text 3.5382\n",
      "2022-04-09 11:35:52,271 - INFO: | epoch  12 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.63 | loss-text 3.5576\n",
      "2022-04-09 11:36:08,531 - INFO: | epoch  12 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.59 | loss-text 3.5410\n",
      "2022-04-09 11:36:24,825 - INFO: | epoch  12 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.93 | loss-text 3.5259\n",
      "2022-04-09 11:36:41,135 - INFO: | epoch  12 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.10 | loss-text 3.5193\n",
      "2022-04-09 11:36:57,681 - INFO: | epoch  12 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 165.44 | loss-text 3.5794\n",
      "2022-04-09 11:37:14,066 - INFO: | epoch  12 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.85 | loss-text 3.5952\n",
      "2022-04-09 11:37:30,492 - INFO: | epoch  12 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.25 | loss-text 3.5673\n",
      "2022-04-09 11:37:46,918 - INFO: | epoch  12 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.25 | loss-text 3.4853\n",
      "2022-04-09 11:38:03,300 - INFO: | epoch  12 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.82 | loss-text 3.6008\n",
      "2022-04-09 11:38:19,669 - INFO: | epoch  12 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.68 | loss-text 3.5650\n",
      "2022-04-09 11:38:35,973 - INFO: | epoch  12 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.03 | loss-text 3.5144\n",
      "2022-04-09 11:38:52,432 - INFO: | epoch  12 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.59 | loss-text 3.5506\n",
      "2022-04-09 11:39:08,729 - INFO: | epoch  12 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 162.96 | loss-text 3.5429\n",
      "2022-04-09 11:39:25,088 - INFO: | epoch  12 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.58 | loss-text 3.5325\n",
      "2022-04-09 11:39:41,484 - INFO: | epoch  12 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.95 | loss-text 3.4990\n",
      "2022-04-09 11:39:57,890 - INFO: | epoch  12 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.05 | loss-text 3.5676\n",
      "2022-04-09 11:40:14,396 - INFO: | epoch  12 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 165.05 | loss-text 3.5600\n",
      "2022-04-09 11:40:30,763 - INFO: | epoch  12 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 163.67 | loss-text 3.5721\n",
      "2022-04-09 11:40:47,105 - INFO: | epoch  12 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.41 | loss-text 3.5204\n",
      "2022-04-09 11:41:03,469 - INFO: | epoch  12 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.64 | loss-text 3.5451\n",
      "2022-04-09 11:41:19,960 - INFO: | epoch  12 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.90 | loss-text 3.5758\n",
      "2022-04-09 11:41:36,357 - INFO: | epoch  12 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.97 | loss-text 3.5869\n",
      "2022-04-09 11:41:52,780 - INFO: | epoch  12 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.22 | loss-text 3.5593\n",
      "2022-04-09 11:42:09,222 - INFO: | epoch  12 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.42 | loss-text 3.5368\n",
      "2022-04-09 11:42:25,769 - INFO: | epoch  12 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 165.46 | loss-text 3.5888\n",
      "2022-04-09 11:42:42,223 - INFO: | epoch  12 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.53 | loss-text 3.5457\n",
      "2022-04-09 11:42:58,532 - INFO: | epoch  12 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.09 | loss-text 3.5526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004011\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11145, 'reflen': 10945, 'guess': [11145, 10121, 9097, 8073], 'correct': [5316, 1634, 599, 166]}\n",
      "ratio: 1.0182731841022368\n",
      "Bleu_1: 0.477\n",
      "Bleu_2: 0.278\n",
      "Bleu_3: 0.172\n",
      "Bleu_4: 0.101\n",
      "computing METEOR score...\n",
      "METEOR: 0.134\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.333\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.186\n",
      "computing SPICE score...\n",
      "SPICE: 0.081\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.133\n",
      "2022-04-09 11:43:37,081 - INFO: eval_greddy SPIDEr: 0.1334\n",
      "loading annotations into memory...\n",
      "0:00:00.004038\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9555, 'reflen': 10023, 'guess': [9555, 8531, 7507, 6483], 'correct': [4959, 1676, 649, 197]}\n",
      "ratio: 0.9533073929960137\n",
      "Bleu_1: 0.494\n",
      "Bleu_2: 0.304\n",
      "Bleu_3: 0.197\n",
      "Bleu_4: 0.122\n",
      "computing METEOR score...\n",
      "METEOR: 0.139\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.339\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.214\n",
      "computing SPICE score...\n",
      "SPICE: 0.087\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.150\n",
      "2022-04-09 11:44:05,995 - INFO: eval_beam_2 SPIDEr: 0.1504\n",
      "loading annotations into memory...\n",
      "0:00:00.004071\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8508, 'reflen': 9573, 'guess': [8508, 7484, 6460, 5436], 'correct': [4545, 1590, 648, 194]}\n",
      "ratio: 0.8887496082731757\n",
      "Bleu_1: 0.471\n",
      "Bleu_2: 0.297\n",
      "Bleu_3: 0.198\n",
      "Bleu_4: 0.125\n",
      "computing METEOR score...\n",
      "METEOR: 0.135\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.339\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.220\n",
      "computing SPICE score...\n",
      "SPICE: 0.087\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.153\n",
      "2022-04-09 11:44:38,773 - INFO: eval_beam_3 SPIDEr: 0.1532\n",
      "loading annotations into memory...\n",
      "0:00:00.004077\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7814, 'reflen': 9323, 'guess': [7814, 6790, 5766, 4742], 'correct': [4277, 1474, 601, 181]}\n",
      "ratio: 0.8381422288961881\n",
      "Bleu_1: 0.451\n",
      "Bleu_2: 0.284\n",
      "Bleu_3: 0.191\n",
      "Bleu_4: 0.122\n",
      "computing METEOR score...\n",
      "METEOR: 0.131\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.336\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.217\n",
      "computing SPICE score...\n",
      "SPICE: 0.082\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.150\n",
      "2022-04-09 11:45:12,370 - INFO: eval_beam_4 SPIDEr: 0.1498\n",
      "2022-04-09 11:45:28,872 - INFO: | epoch  13 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.98 | loss-text 3.4805\n",
      "2022-04-09 11:45:45,171 - INFO: | epoch  13 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.97 | loss-text 3.5400\n",
      "2022-04-09 11:46:01,607 - INFO: | epoch  13 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 164.36 | loss-text 3.5456\n",
      "2022-04-09 11:46:17,798 - INFO: | epoch  13 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 161.90 | loss-text 3.5548\n",
      "2022-04-09 11:46:34,092 - INFO: | epoch  13 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.93 | loss-text 3.5237\n",
      "2022-04-09 11:46:50,309 - INFO: | epoch  13 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.16 | loss-text 3.5607\n",
      "2022-04-09 11:47:06,740 - INFO: | epoch  13 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 164.31 | loss-text 3.5456\n",
      "2022-04-09 11:47:23,197 - INFO: | epoch  13 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.56 | loss-text 3.4789\n",
      "2022-04-09 11:47:39,565 - INFO: | epoch  13 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.67 | loss-text 3.4993\n",
      "2022-04-09 11:47:55,905 - INFO: | epoch  13 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.39 | loss-text 3.5496\n",
      "2022-04-09 11:48:12,232 - INFO: | epoch  13 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.27 | loss-text 3.5411\n",
      "2022-04-09 11:48:28,704 - INFO: | epoch  13 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.71 | loss-text 3.4898\n",
      "2022-04-09 11:48:45,283 - INFO: | epoch  13 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 165.78 | loss-text 3.5319\n",
      "2022-04-09 11:49:01,766 - INFO: | epoch  13 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.82 | loss-text 3.4905\n",
      "2022-04-09 11:49:18,234 - INFO: | epoch  13 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.67 | loss-text 3.5187\n",
      "2022-04-09 11:49:34,747 - INFO: | epoch  13 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 165.12 | loss-text 3.5288\n",
      "2022-04-09 11:49:51,059 - INFO: | epoch  13 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.11 | loss-text 3.5490\n",
      "2022-04-09 11:50:07,461 - INFO: | epoch  13 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.01 | loss-text 3.4915\n",
      "2022-04-09 11:50:23,813 - INFO: | epoch  13 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.52 | loss-text 3.4685\n",
      "2022-04-09 11:50:40,078 - INFO: | epoch  13 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 162.64 | loss-text 3.5470\n",
      "2022-04-09 11:50:56,328 - INFO: | epoch  13 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 162.49 | loss-text 3.4634\n",
      "2022-04-09 11:51:12,800 - INFO: | epoch  13 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.71 | loss-text 3.5633\n",
      "2022-04-09 11:51:29,354 - INFO: | epoch  13 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 165.54 | loss-text 3.5406\n",
      "2022-04-09 11:51:45,761 - INFO: | epoch  13 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.06 | loss-text 3.5399\n",
      "2022-04-09 11:52:02,152 - INFO: | epoch  13 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.90 | loss-text 3.4921\n",
      "2022-04-09 11:52:18,596 - INFO: | epoch  13 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.42 | loss-text 3.5071\n",
      "2022-04-09 11:52:35,207 - INFO: | epoch  13 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 166.11 | loss-text 3.5402\n",
      "2022-04-09 11:52:51,581 - INFO: | epoch  13 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.73 | loss-text 3.5261\n",
      "2022-04-09 11:53:08,015 - INFO: | epoch  13 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.34 | loss-text 3.4805\n",
      "2022-04-09 11:53:24,330 - INFO: | epoch  13 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.14 | loss-text 3.5299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004033\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10667, 'reflen': 10616, 'guess': [10667, 9643, 8619, 7595], 'correct': [5101, 1516, 521, 150]}\n",
      "ratio: 1.0048040693292195\n",
      "Bleu_1: 0.478\n",
      "Bleu_2: 0.274\n",
      "Bleu_3: 0.166\n",
      "Bleu_4: 0.097\n",
      "computing METEOR score...\n",
      "METEOR: 0.135\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.327\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.185\n",
      "computing SPICE score...\n",
      "SPICE: 0.082\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.133\n",
      "2022-04-09 11:54:03,068 - INFO: eval_greddy SPIDEr: 0.1335\n",
      "loading annotations into memory...\n",
      "0:00:00.003905\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8524, 'reflen': 9558, 'guess': [8524, 7500, 6476, 5452], 'correct': [4521, 1496, 579, 184]}\n",
      "ratio: 0.8918183720442674\n",
      "Bleu_1: 0.470\n",
      "Bleu_2: 0.288\n",
      "Bleu_3: 0.187\n",
      "Bleu_4: 0.118\n",
      "computing METEOR score...\n",
      "METEOR: 0.137\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.331\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.222\n",
      "computing SPICE score...\n",
      "SPICE: 0.086\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.154\n",
      "2022-04-09 11:54:31,072 - INFO: eval_beam_2 SPIDEr: 0.1539\n",
      "loading annotations into memory...\n",
      "0:00:00.004079\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7809, 'reflen': 9319, 'guess': [7809, 6785, 5761, 4737], 'correct': [4191, 1397, 546, 173]}\n",
      "ratio: 0.8379654469362766\n",
      "Bleu_1: 0.442\n",
      "Bleu_2: 0.274\n",
      "Bleu_3: 0.180\n",
      "Bleu_4: 0.115\n",
      "computing METEOR score...\n",
      "METEOR: 0.130\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.326\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.217\n",
      "computing SPICE score...\n",
      "SPICE: 0.080\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.148\n",
      "2022-04-09 11:54:59,120 - INFO: eval_beam_3 SPIDEr: 0.1483\n",
      "loading annotations into memory...\n",
      "0:00:00.004186\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7505, 'reflen': 9239, 'guess': [7505, 6481, 5457, 4433], 'correct': [4070, 1368, 547, 175]}\n",
      "ratio: 0.8123173503625054\n",
      "Bleu_1: 0.430\n",
      "Bleu_2: 0.269\n",
      "Bleu_3: 0.179\n",
      "Bleu_4: 0.116\n",
      "computing METEOR score...\n",
      "METEOR: 0.128\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.327\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.213\n",
      "computing SPICE score...\n",
      "SPICE: 0.078\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.146\n",
      "2022-04-09 11:55:30,512 - INFO: eval_beam_4 SPIDEr: 0.1455\n",
      "2022-04-09 11:55:47,039 - INFO: | epoch  14 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.23 | loss-text 3.4330\n",
      "2022-04-09 11:56:03,198 - INFO: | epoch  14 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.58 | loss-text 3.5153\n",
      "2022-04-09 11:56:19,450 - INFO: | epoch  14 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.52 | loss-text 3.5522\n",
      "2022-04-09 11:56:35,729 - INFO: | epoch  14 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.78 | loss-text 3.4998\n",
      "2022-04-09 11:56:51,995 - INFO: | epoch  14 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.65 | loss-text 3.4535\n",
      "2022-04-09 11:57:08,327 - INFO: | epoch  14 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.32 | loss-text 3.5220\n",
      "2022-04-09 11:57:24,544 - INFO: | epoch  14 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 162.16 | loss-text 3.5301\n",
      "2022-04-09 11:57:40,929 - INFO: | epoch  14 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.84 | loss-text 3.5031\n",
      "2022-04-09 11:57:57,337 - INFO: | epoch  14 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.08 | loss-text 3.4853\n",
      "2022-04-09 11:58:13,659 - INFO: | epoch  14 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.21 | loss-text 3.5369\n",
      "2022-04-09 11:58:30,072 - INFO: | epoch  14 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.12 | loss-text 3.4936\n",
      "2022-04-09 11:58:46,537 - INFO: | epoch  14 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.64 | loss-text 3.4852\n",
      "2022-04-09 11:59:03,115 - INFO: | epoch  14 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 165.78 | loss-text 3.5020\n",
      "2022-04-09 11:59:19,604 - INFO: | epoch  14 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.88 | loss-text 3.5615\n",
      "2022-04-09 11:59:36,125 - INFO: | epoch  14 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 165.21 | loss-text 3.5158\n",
      "2022-04-09 11:59:52,565 - INFO: | epoch  14 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.40 | loss-text 3.5063\n",
      "2022-04-09 12:00:08,953 - INFO: | epoch  14 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.87 | loss-text 3.4723\n",
      "2022-04-09 12:00:25,292 - INFO: | epoch  14 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.38 | loss-text 3.5288\n",
      "2022-04-09 12:00:41,775 - INFO: | epoch  14 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.83 | loss-text 3.5346\n",
      "2022-04-09 12:00:58,335 - INFO: | epoch  14 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 165.59 | loss-text 3.4965\n",
      "2022-04-09 12:01:14,707 - INFO: | epoch  14 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 163.71 | loss-text 3.4475\n",
      "2022-04-09 12:01:31,168 - INFO: | epoch  14 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.61 | loss-text 3.5016\n",
      "2022-04-09 12:01:47,600 - INFO: | epoch  14 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.32 | loss-text 3.4816\n",
      "2022-04-09 12:02:04,173 - INFO: | epoch  14 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 165.72 | loss-text 3.4830\n",
      "2022-04-09 12:02:20,595 - INFO: | epoch  14 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.20 | loss-text 3.5904\n",
      "2022-04-09 12:02:37,101 - INFO: | epoch  14 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 165.06 | loss-text 3.4985\n",
      "2022-04-09 12:02:53,491 - INFO: | epoch  14 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.89 | loss-text 3.4911\n",
      "2022-04-09 12:03:09,911 - INFO: | epoch  14 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.19 | loss-text 3.4875\n",
      "2022-04-09 12:03:26,182 - INFO: | epoch  14 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 162.71 | loss-text 3.4993\n",
      "2022-04-09 12:03:42,647 - INFO: | epoch  14 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.63 | loss-text 3.4683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003835\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9624, 'reflen': 10013, 'guess': [9624, 8600, 7576, 6552], 'correct': [4705, 1400, 476, 146]}\n",
      "ratio: 0.9611505043442563\n",
      "Bleu_1: 0.470\n",
      "Bleu_2: 0.271\n",
      "Bleu_3: 0.164\n",
      "Bleu_4: 0.099\n",
      "computing METEOR score...\n",
      "METEOR: 0.130\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.325\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.188\n",
      "computing SPICE score...\n",
      "SPICE: 0.079\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.133\n",
      "2022-04-09 12:04:20,733 - INFO: eval_greddy SPIDEr: 0.1335\n",
      "loading annotations into memory...\n",
      "0:00:00.003995\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8098, 'reflen': 9327, 'guess': [8098, 7074, 6050, 5026], 'correct': [4249, 1384, 541, 175]}\n",
      "ratio: 0.8682320145812299\n",
      "Bleu_1: 0.451\n",
      "Bleu_2: 0.275\n",
      "Bleu_3: 0.180\n",
      "Bleu_4: 0.115\n",
      "computing METEOR score...\n",
      "METEOR: 0.127\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.324\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.213\n",
      "computing SPICE score...\n",
      "SPICE: 0.081\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.147\n",
      "2022-04-09 12:04:46,782 - INFO: eval_beam_2 SPIDEr: 0.1465\n",
      "loading annotations into memory...\n",
      "0:00:00.003880\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7661, 'reflen': 9256, 'guess': [7661, 6637, 5613, 4589], 'correct': [4003, 1291, 537, 188]}\n",
      "ratio: 0.8276793431286918\n",
      "Bleu_1: 0.424\n",
      "Bleu_2: 0.259\n",
      "Bleu_3: 0.173\n",
      "Bleu_4: 0.115\n",
      "computing METEOR score...\n",
      "METEOR: 0.123\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.320\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.214\n",
      "computing SPICE score...\n",
      "SPICE: 0.074\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.144\n",
      "2022-04-09 12:05:13,904 - INFO: eval_beam_3 SPIDEr: 0.1440\n",
      "loading annotations into memory...\n",
      "0:00:00.003845\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7494, 'reflen': 9222, 'guess': [7494, 6470, 5446, 4422], 'correct': [3901, 1272, 524, 176]}\n",
      "ratio: 0.8126219908912586\n",
      "Bleu_1: 0.413\n",
      "Bleu_2: 0.254\n",
      "Bleu_3: 0.170\n",
      "Bleu_4: 0.112\n",
      "computing METEOR score...\n",
      "METEOR: 0.122\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.319\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.211\n",
      "computing SPICE score...\n",
      "SPICE: 0.071\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.141\n",
      "2022-04-09 12:05:43,657 - INFO: eval_beam_4 SPIDEr: 0.1412\n",
      "2022-04-09 12:06:00,206 - INFO: | epoch  15 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.46 | loss-text 3.4763\n",
      "2022-04-09 12:06:16,287 - INFO: | epoch  15 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 160.80 | loss-text 3.4471\n",
      "2022-04-09 12:06:32,443 - INFO: | epoch  15 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 161.55 | loss-text 3.4922\n",
      "2022-04-09 12:06:48,634 - INFO: | epoch  15 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 161.90 | loss-text 3.4998\n",
      "2022-04-09 12:07:05,050 - INFO: | epoch  15 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 164.15 | loss-text 3.4396\n",
      "2022-04-09 12:07:21,409 - INFO: | epoch  15 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.58 | loss-text 3.4952\n",
      "2022-04-09 12:07:37,761 - INFO: | epoch  15 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.52 | loss-text 3.4633\n",
      "2022-04-09 12:07:54,050 - INFO: | epoch  15 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 162.88 | loss-text 3.4782\n",
      "2022-04-09 12:08:10,491 - INFO: | epoch  15 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.40 | loss-text 3.4618\n",
      "2022-04-09 12:08:26,990 - INFO: | epoch  15 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.99 | loss-text 3.4656\n",
      "2022-04-09 12:08:43,486 - INFO: | epoch  15 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.95 | loss-text 3.5008\n",
      "2022-04-09 12:08:59,995 - INFO: | epoch  15 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 165.08 | loss-text 3.4504\n",
      "2022-04-09 12:09:16,352 - INFO: | epoch  15 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.56 | loss-text 3.4763\n",
      "2022-04-09 12:09:32,829 - INFO: | epoch  15 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.77 | loss-text 3.5043\n",
      "2022-04-09 12:09:49,314 - INFO: | epoch  15 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.84 | loss-text 3.4822\n",
      "2022-04-09 12:10:05,732 - INFO: | epoch  15 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.17 | loss-text 3.4735\n",
      "2022-04-09 12:10:22,130 - INFO: | epoch  15 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.98 | loss-text 3.5339\n",
      "2022-04-09 12:10:38,534 - INFO: | epoch  15 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.03 | loss-text 3.5079\n",
      "2022-04-09 12:10:54,915 - INFO: | epoch  15 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.81 | loss-text 3.5003\n",
      "2022-04-09 12:11:11,323 - INFO: | epoch  15 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.07 | loss-text 3.5279\n",
      "2022-04-09 12:11:27,665 - INFO: | epoch  15 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 163.41 | loss-text 3.5007\n",
      "2022-04-09 12:11:44,185 - INFO: | epoch  15 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 165.19 | loss-text 3.4951\n",
      "2022-04-09 12:12:00,729 - INFO: | epoch  15 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 165.43 | loss-text 3.4523\n",
      "2022-04-09 12:12:17,022 - INFO: | epoch  15 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 162.93 | loss-text 3.4831\n",
      "2022-04-09 12:12:33,480 - INFO: | epoch  15 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.57 | loss-text 3.4726\n",
      "2022-04-09 12:12:49,955 - INFO: | epoch  15 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.74 | loss-text 3.4831\n",
      "2022-04-09 12:13:06,412 - INFO: | epoch  15 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.57 | loss-text 3.4855\n",
      "2022-04-09 12:13:22,850 - INFO: | epoch  15 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.38 | loss-text 3.4803\n",
      "2022-04-09 12:13:39,210 - INFO: | epoch  15 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.60 | loss-text 3.4539\n",
      "2022-04-09 12:13:55,763 - INFO: | epoch  15 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 165.52 | loss-text 3.4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003994\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11927, 'reflen': 11292, 'guess': [11927, 10903, 9879, 8855], 'correct': [5316, 1607, 539, 154]}\n",
      "ratio: 1.0562345023024216\n",
      "Bleu_1: 0.446\n",
      "Bleu_2: 0.256\n",
      "Bleu_3: 0.153\n",
      "Bleu_4: 0.089\n",
      "computing METEOR score...\n",
      "METEOR: 0.135\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.320\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.184\n",
      "computing SPICE score...\n",
      "SPICE: 0.082\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.133\n",
      "2022-04-09 12:14:37,398 - INFO: eval_greddy SPIDEr: 0.1332\n",
      "loading annotations into memory...\n",
      "0:00:00.003960\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9607, 'reflen': 10049, 'guess': [9607, 8583, 7559, 6535], 'correct': [4737, 1598, 618, 178]}\n",
      "ratio: 0.9560155239326344\n",
      "Bleu_1: 0.471\n",
      "Bleu_2: 0.289\n",
      "Bleu_3: 0.187\n",
      "Bleu_4: 0.114\n",
      "computing METEOR score...\n",
      "METEOR: 0.134\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.330\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.226\n",
      "computing SPICE score...\n",
      "SPICE: 0.088\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.157\n",
      "2022-04-09 12:15:08,580 - INFO: eval_beam_2 SPIDEr: 0.1568\n",
      "loading annotations into memory...\n",
      "0:00:00.003979\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8696, 'reflen': 9603, 'guess': [8696, 7672, 6648, 5624], 'correct': [4487, 1565, 638, 200]}\n",
      "ratio: 0.9055503488492236\n",
      "Bleu_1: 0.465\n",
      "Bleu_2: 0.292\n",
      "Bleu_3: 0.195\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.134\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.331\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.227\n",
      "computing SPICE score...\n",
      "SPICE: 0.083\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.155\n",
      "2022-04-09 12:15:43,669 - INFO: eval_beam_3 SPIDEr: 0.1553\n",
      "loading annotations into memory...\n",
      "0:00:00.003685\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8062, 'reflen': 9325, 'guess': [8062, 7038, 6014, 4990], 'correct': [4263, 1476, 593, 191]}\n",
      "ratio: 0.8645576407505775\n",
      "Bleu_1: 0.452\n",
      "Bleu_2: 0.285\n",
      "Bleu_3: 0.190\n",
      "Bleu_4: 0.122\n",
      "computing METEOR score...\n",
      "METEOR: 0.131\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.328\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.223\n",
      "computing SPICE score...\n",
      "SPICE: 0.083\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.153\n",
      "2022-04-09 12:16:23,410 - INFO: eval_beam_4 SPIDEr: 0.1526\n",
      "2022-04-09 12:16:39,880 - INFO: | epoch  16 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.67 | loss-text 3.4409\n",
      "2022-04-09 12:16:56,123 - INFO: | epoch  16 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.42 | loss-text 3.4298\n",
      "2022-04-09 12:17:12,306 - INFO: | epoch  16 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 161.82 | loss-text 3.4540\n",
      "2022-04-09 12:17:28,682 - INFO: | epoch  16 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.75 | loss-text 3.3896\n",
      "2022-04-09 12:17:44,834 - INFO: | epoch  16 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 161.51 | loss-text 3.4906\n",
      "2022-04-09 12:18:01,069 - INFO: | epoch  16 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.35 | loss-text 3.4797\n",
      "2022-04-09 12:18:17,385 - INFO: | epoch  16 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.15 | loss-text 3.4900\n",
      "2022-04-09 12:18:33,814 - INFO: | epoch  16 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.28 | loss-text 3.4295\n",
      "2022-04-09 12:18:50,157 - INFO: | epoch  16 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.43 | loss-text 3.4894\n",
      "2022-04-09 12:19:06,514 - INFO: | epoch  16 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.56 | loss-text 3.4477\n",
      "2022-04-09 12:19:22,911 - INFO: | epoch  16 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.96 | loss-text 3.4752\n",
      "2022-04-09 12:19:39,238 - INFO: | epoch  16 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.27 | loss-text 3.5060\n",
      "2022-04-09 12:19:55,687 - INFO: | epoch  16 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.48 | loss-text 3.4019\n",
      "2022-04-09 12:20:12,118 - INFO: | epoch  16 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.31 | loss-text 3.4649\n",
      "2022-04-09 12:20:28,446 - INFO: | epoch  16 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.27 | loss-text 3.4389\n",
      "2022-04-09 12:20:44,928 - INFO: | epoch  16 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.81 | loss-text 3.4571\n",
      "2022-04-09 12:21:01,566 - INFO: | epoch  16 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 166.37 | loss-text 3.4689\n",
      "2022-04-09 12:21:18,080 - INFO: | epoch  16 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 165.13 | loss-text 3.4892\n",
      "2022-04-09 12:21:34,425 - INFO: | epoch  16 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.44 | loss-text 3.4926\n",
      "2022-04-09 12:21:50,860 - INFO: | epoch  16 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.35 | loss-text 3.4757\n",
      "2022-04-09 12:22:07,276 - INFO: | epoch  16 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.15 | loss-text 3.4778\n",
      "2022-04-09 12:22:23,675 - INFO: | epoch  16 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.98 | loss-text 3.4471\n",
      "2022-04-09 12:22:40,239 - INFO: | epoch  16 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 165.63 | loss-text 3.4961\n",
      "2022-04-09 12:22:56,519 - INFO: | epoch  16 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 162.79 | loss-text 3.4034\n",
      "2022-04-09 12:23:12,835 - INFO: | epoch  16 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.15 | loss-text 3.4890\n",
      "2022-04-09 12:23:29,284 - INFO: | epoch  16 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.49 | loss-text 3.4559\n",
      "2022-04-09 12:23:45,643 - INFO: | epoch  16 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.59 | loss-text 3.4725\n",
      "2022-04-09 12:24:02,142 - INFO: | epoch  16 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.98 | loss-text 3.4375\n",
      "2022-04-09 12:24:18,519 - INFO: | epoch  16 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.76 | loss-text 3.4444\n",
      "2022-04-09 12:24:34,949 - INFO: | epoch  16 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.30 | loss-text 3.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003919\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 12454, 'reflen': 11455, 'guess': [12454, 11430, 10406, 9382], 'correct': [5404, 1612, 539, 149]}\n",
      "ratio: 1.0872108249671681\n",
      "Bleu_1: 0.434\n",
      "Bleu_2: 0.247\n",
      "Bleu_3: 0.147\n",
      "Bleu_4: 0.084\n",
      "computing METEOR score...\n",
      "METEOR: 0.138\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.323\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.172\n",
      "computing SPICE score...\n",
      "SPICE: 0.088\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.130\n",
      "2022-04-09 12:25:18,586 - INFO: eval_greddy SPIDEr: 0.1300\n",
      "loading annotations into memory...\n",
      "0:00:00.003840\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9027, 'reflen': 9747, 'guess': [9027, 8003, 6979, 5955], 'correct': [4790, 1562, 591, 182]}\n",
      "ratio: 0.9261311172667562\n",
      "Bleu_1: 0.490\n",
      "Bleu_2: 0.297\n",
      "Bleu_3: 0.190\n",
      "Bleu_4: 0.118\n",
      "computing METEOR score...\n",
      "METEOR: 0.138\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.336\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.235\n",
      "computing SPICE score...\n",
      "SPICE: 0.087\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.161\n",
      "2022-04-09 12:25:51,752 - INFO: eval_beam_2 SPIDEr: 0.1609\n",
      "loading annotations into memory...\n",
      "0:00:00.003947\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8395, 'reflen': 9417, 'guess': [8395, 7371, 6347, 5323], 'correct': [4485, 1490, 588, 198]}\n",
      "ratio: 0.8914728682169596\n",
      "Bleu_1: 0.473\n",
      "Bleu_2: 0.291\n",
      "Bleu_3: 0.191\n",
      "Bleu_4: 0.123\n",
      "computing METEOR score...\n",
      "METEOR: 0.133\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.333\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.239\n",
      "computing SPICE score...\n",
      "SPICE: 0.082\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.160\n",
      "2022-04-09 12:26:29,737 - INFO: eval_beam_3 SPIDEr: 0.1604\n",
      "loading annotations into memory...\n",
      "0:00:00.003907\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7907, 'reflen': 9257, 'guess': [7907, 6883, 5859, 4835], 'correct': [4243, 1433, 575, 190]}\n",
      "ratio: 0.8541644161174403\n",
      "Bleu_1: 0.452\n",
      "Bleu_2: 0.282\n",
      "Bleu_3: 0.187\n",
      "Bleu_4: 0.121\n",
      "computing METEOR score...\n",
      "METEOR: 0.131\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.330\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.235\n",
      "computing SPICE score...\n",
      "SPICE: 0.080\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.158\n",
      "2022-04-09 12:27:08,613 - INFO: eval_beam_4 SPIDEr: 0.1579\n",
      "2022-04-09 12:27:25,214 - INFO: | epoch  17 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.97 | loss-text 3.4832\n",
      "2022-04-09 12:27:41,379 - INFO: | epoch  17 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.64 | loss-text 3.4266\n",
      "2022-04-09 12:27:57,530 - INFO: | epoch  17 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 161.50 | loss-text 3.4312\n",
      "2022-04-09 12:28:13,715 - INFO: | epoch  17 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 161.85 | loss-text 3.4374\n",
      "2022-04-09 12:28:30,102 - INFO: | epoch  17 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.86 | loss-text 3.4624\n",
      "2022-04-09 12:28:46,387 - INFO: | epoch  17 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.85 | loss-text 3.4044\n",
      "2022-04-09 12:29:02,725 - INFO: | epoch  17 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.37 | loss-text 3.3894\n",
      "2022-04-09 12:29:19,206 - INFO: | epoch  17 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.80 | loss-text 3.4114\n",
      "2022-04-09 12:29:35,695 - INFO: | epoch  17 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.89 | loss-text 3.4324\n",
      "2022-04-09 12:29:52,263 - INFO: | epoch  17 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 165.67 | loss-text 3.4456\n",
      "2022-04-09 12:30:08,547 - INFO: | epoch  17 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 162.83 | loss-text 3.4558\n",
      "2022-04-09 12:30:24,981 - INFO: | epoch  17 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.33 | loss-text 3.4999\n",
      "2022-04-09 12:30:41,368 - INFO: | epoch  17 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.86 | loss-text 3.4183\n",
      "2022-04-09 12:30:57,665 - INFO: | epoch  17 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 162.97 | loss-text 3.3959\n",
      "2022-04-09 12:31:14,008 - INFO: | epoch  17 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.42 | loss-text 3.4184\n",
      "2022-04-09 12:31:30,596 - INFO: | epoch  17 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 165.87 | loss-text 3.4589\n",
      "2022-04-09 12:31:47,036 - INFO: | epoch  17 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.40 | loss-text 3.4234\n",
      "2022-04-09 12:32:03,534 - INFO: | epoch  17 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.97 | loss-text 3.4327\n",
      "2022-04-09 12:32:19,933 - INFO: | epoch  17 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.97 | loss-text 3.4368\n",
      "2022-04-09 12:32:36,292 - INFO: | epoch  17 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.59 | loss-text 3.3975\n",
      "2022-04-09 12:32:52,612 - INFO: | epoch  17 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 163.19 | loss-text 3.4447\n",
      "2022-04-09 12:33:09,006 - INFO: | epoch  17 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.93 | loss-text 3.4429\n",
      "2022-04-09 12:33:25,478 - INFO: | epoch  17 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.71 | loss-text 3.4833\n",
      "2022-04-09 12:33:41,909 - INFO: | epoch  17 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.31 | loss-text 3.4706\n",
      "2022-04-09 12:33:58,266 - INFO: | epoch  17 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.56 | loss-text 3.4382\n",
      "2022-04-09 12:34:14,726 - INFO: | epoch  17 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.59 | loss-text 3.4254\n",
      "2022-04-09 12:34:31,100 - INFO: | epoch  17 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.74 | loss-text 3.4615\n",
      "2022-04-09 12:34:47,658 - INFO: | epoch  17 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 165.57 | loss-text 3.4578\n",
      "2022-04-09 12:35:03,899 - INFO: | epoch  17 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 162.40 | loss-text 3.4156\n",
      "2022-04-09 12:35:20,279 - INFO: | epoch  17 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.79 | loss-text 3.4611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004013\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9990, 'reflen': 10272, 'guess': [9990, 8966, 7942, 6918], 'correct': [4857, 1419, 482, 130]}\n",
      "ratio: 0.9725467289718679\n",
      "Bleu_1: 0.473\n",
      "Bleu_2: 0.270\n",
      "Bleu_3: 0.162\n",
      "Bleu_4: 0.094\n",
      "computing METEOR score...\n",
      "METEOR: 0.136\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.319\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.199\n",
      "computing SPICE score...\n",
      "SPICE: 0.087\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.143\n",
      "2022-04-09 12:36:00,469 - INFO: eval_greddy SPIDEr: 0.1432\n",
      "loading annotations into memory...\n",
      "0:00:00.004166\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8263, 'reflen': 9439, 'guess': [8263, 7239, 6215, 5191], 'correct': [4300, 1372, 525, 172]}\n",
      "ratio: 0.8754105307764726\n",
      "Bleu_1: 0.451\n",
      "Bleu_2: 0.272\n",
      "Bleu_3: 0.176\n",
      "Bleu_4: 0.112\n",
      "computing METEOR score...\n",
      "METEOR: 0.131\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.320\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.218\n",
      "computing SPICE score...\n",
      "SPICE: 0.083\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.151\n",
      "2022-04-09 12:36:27,750 - INFO: eval_beam_2 SPIDEr: 0.1506\n",
      "loading annotations into memory...\n",
      "0:00:00.004055\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7808, 'reflen': 9299, 'guess': [7808, 6784, 5760, 4736], 'correct': [4137, 1347, 550, 189]}\n",
      "ratio: 0.8396601785137283\n",
      "Bleu_1: 0.438\n",
      "Bleu_2: 0.268\n",
      "Bleu_3: 0.178\n",
      "Bleu_4: 0.117\n",
      "computing METEOR score...\n",
      "METEOR: 0.129\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.322\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.230\n",
      "computing SPICE score...\n",
      "SPICE: 0.078\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.154\n",
      "2022-04-09 12:36:58,416 - INFO: eval_beam_3 SPIDEr: 0.1540\n",
      "loading annotations into memory...\n",
      "0:00:00.003976\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7456, 'reflen': 9245, 'guess': [7456, 6432, 5408, 4384], 'correct': [4064, 1379, 583, 203]}\n",
      "ratio: 0.8064899945915839\n",
      "Bleu_1: 0.429\n",
      "Bleu_2: 0.269\n",
      "Bleu_3: 0.183\n",
      "Bleu_4: 0.122\n",
      "computing METEOR score...\n",
      "METEOR: 0.129\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.326\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.231\n",
      "computing SPICE score...\n",
      "SPICE: 0.078\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.155\n",
      "2022-04-09 12:37:29,171 - INFO: eval_beam_4 SPIDEr: 0.1548\n",
      "2022-04-09 12:37:45,809 - INFO: | epoch  18 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 166.36 | loss-text 3.4085\n",
      "2022-04-09 12:38:02,038 - INFO: | epoch  18 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.27 | loss-text 3.4355\n",
      "2022-04-09 12:38:18,285 - INFO: | epoch  18 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.47 | loss-text 3.4141\n",
      "2022-04-09 12:38:34,554 - INFO: | epoch  18 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.68 | loss-text 3.4066\n",
      "2022-04-09 12:38:50,880 - INFO: | epoch  18 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.26 | loss-text 3.4231\n",
      "2022-04-09 12:39:07,380 - INFO: | epoch  18 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 164.99 | loss-text 3.4102\n",
      "2022-04-09 12:39:23,844 - INFO: | epoch  18 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 164.63 | loss-text 3.4392\n",
      "2022-04-09 12:39:40,278 - INFO: | epoch  18 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.34 | loss-text 3.4026\n",
      "2022-04-09 12:39:56,679 - INFO: | epoch  18 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.00 | loss-text 3.3825\n",
      "2022-04-09 12:40:13,023 - INFO: | epoch  18 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.43 | loss-text 3.4195\n",
      "2022-04-09 12:40:29,344 - INFO: | epoch  18 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.20 | loss-text 3.4071\n",
      "2022-04-09 12:40:45,920 - INFO: | epoch  18 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 165.75 | loss-text 3.4509\n",
      "2022-04-09 12:41:02,308 - INFO: | epoch  18 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.87 | loss-text 3.4605\n",
      "2022-04-09 12:41:18,615 - INFO: | epoch  18 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.07 | loss-text 3.4432\n",
      "2022-04-09 12:41:34,842 - INFO: | epoch  18 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 162.26 | loss-text 3.3798\n",
      "2022-04-09 12:41:51,170 - INFO: | epoch  18 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.27 | loss-text 3.4753\n",
      "2022-04-09 12:42:07,658 - INFO: | epoch  18 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.87 | loss-text 3.3745\n",
      "2022-04-09 12:42:24,009 - INFO: | epoch  18 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.51 | loss-text 3.4104\n",
      "2022-04-09 12:42:40,384 - INFO: | epoch  18 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.74 | loss-text 3.4197\n",
      "2022-04-09 12:42:56,728 - INFO: | epoch  18 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.43 | loss-text 3.4181\n",
      "2022-04-09 12:43:13,141 - INFO: | epoch  18 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.13 | loss-text 3.4253\n",
      "2022-04-09 12:43:29,530 - INFO: | epoch  18 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.88 | loss-text 3.4298\n",
      "2022-04-09 12:43:45,974 - INFO: | epoch  18 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.43 | loss-text 3.4604\n",
      "2022-04-09 12:44:02,436 - INFO: | epoch  18 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.62 | loss-text 3.4450\n",
      "2022-04-09 12:44:18,757 - INFO: | epoch  18 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.20 | loss-text 3.3953\n",
      "2022-04-09 12:44:35,191 - INFO: | epoch  18 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.34 | loss-text 3.4354\n",
      "2022-04-09 12:44:51,567 - INFO: | epoch  18 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.75 | loss-text 3.4455\n",
      "2022-04-09 12:45:07,932 - INFO: | epoch  18 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.65 | loss-text 3.4756\n",
      "2022-04-09 12:45:24,380 - INFO: | epoch  18 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.47 | loss-text 3.4036\n",
      "2022-04-09 12:45:40,792 - INFO: | epoch  18 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.11 | loss-text 3.3929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003839\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9777, 'reflen': 10108, 'guess': [9777, 8753, 7729, 6705], 'correct': [5007, 1577, 587, 172]}\n",
      "ratio: 0.9672536604668611\n",
      "Bleu_1: 0.495\n",
      "Bleu_2: 0.294\n",
      "Bleu_3: 0.185\n",
      "Bleu_4: 0.112\n",
      "computing METEOR score...\n",
      "METEOR: 0.142\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.339\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.222\n",
      "computing SPICE score...\n",
      "SPICE: 0.090\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.156\n",
      "2022-04-09 12:46:20,174 - INFO: eval_greddy SPIDEr: 0.1558\n",
      "loading annotations into memory...\n",
      "0:00:00.003993\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8053, 'reflen': 9359, 'guess': [8053, 7029, 6005, 4981], 'correct': [4357, 1447, 560, 175]}\n",
      "ratio: 0.86045517683504\n",
      "Bleu_1: 0.460\n",
      "Bleu_2: 0.284\n",
      "Bleu_3: 0.186\n",
      "Bleu_4: 0.118\n",
      "computing METEOR score...\n",
      "METEOR: 0.136\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.332\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.227\n",
      "computing SPICE score...\n",
      "SPICE: 0.087\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.157\n",
      "2022-04-09 12:46:47,177 - INFO: eval_beam_2 SPIDEr: 0.1574\n",
      "loading annotations into memory...\n",
      "0:00:00.004112\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7780, 'reflen': 9286, 'guess': [7780, 6756, 5732, 4708], 'correct': [4136, 1343, 529, 177]}\n",
      "ratio: 0.8378203747576095\n",
      "Bleu_1: 0.438\n",
      "Bleu_2: 0.268\n",
      "Bleu_3: 0.176\n",
      "Bleu_4: 0.114\n",
      "computing METEOR score...\n",
      "METEOR: 0.130\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.323\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.218\n",
      "computing SPICE score...\n",
      "SPICE: 0.083\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.151\n",
      "2022-04-09 12:47:17,013 - INFO: eval_beam_3 SPIDEr: 0.1506\n",
      "loading annotations into memory...\n",
      "0:00:00.003895\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7478, 'reflen': 9240, 'guess': [7478, 6454, 5430, 4406], 'correct': [3988, 1302, 506, 167]}\n",
      "ratio: 0.8093073593072717\n",
      "Bleu_1: 0.421\n",
      "Bleu_2: 0.259\n",
      "Bleu_3: 0.170\n",
      "Bleu_4: 0.110\n",
      "computing METEOR score...\n",
      "METEOR: 0.128\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.322\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.213\n",
      "computing SPICE score...\n",
      "SPICE: 0.080\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.147\n",
      "2022-04-09 12:47:46,971 - INFO: eval_beam_4 SPIDEr: 0.1467\n",
      "2022-04-09 12:48:03,473 - INFO: | epoch  19 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.00 | loss-text 3.4051\n",
      "2022-04-09 12:48:19,701 - INFO: | epoch  19 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.26 | loss-text 3.3824\n",
      "2022-04-09 12:48:36,041 - INFO: | epoch  19 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 163.39 | loss-text 3.4053\n",
      "2022-04-09 12:48:52,379 - INFO: | epoch  19 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.37 | loss-text 3.4429\n",
      "2022-04-09 12:49:08,826 - INFO: | epoch  19 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 164.46 | loss-text 3.3786\n",
      "2022-04-09 12:49:25,156 - INFO: | epoch  19 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.30 | loss-text 3.4523\n",
      "2022-04-09 12:49:41,372 - INFO: | epoch  19 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 162.15 | loss-text 3.4391\n",
      "2022-04-09 12:49:57,746 - INFO: | epoch  19 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.73 | loss-text 3.4309\n",
      "2022-04-09 12:50:14,138 - INFO: | epoch  19 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.91 | loss-text 3.3759\n",
      "2022-04-09 12:50:30,438 - INFO: | epoch  19 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.00 | loss-text 3.3826\n",
      "2022-04-09 12:50:46,837 - INFO: | epoch  19 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.98 | loss-text 3.4045\n",
      "2022-04-09 12:51:03,333 - INFO: | epoch  19 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.95 | loss-text 3.4406\n",
      "2022-04-09 12:51:19,872 - INFO: | epoch  19 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 165.39 | loss-text 3.3860\n",
      "2022-04-09 12:51:36,392 - INFO: | epoch  19 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 165.20 | loss-text 3.4343\n",
      "2022-04-09 12:51:52,981 - INFO: | epoch  19 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 165.88 | loss-text 3.4312\n",
      "2022-04-09 12:52:09,535 - INFO: | epoch  19 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 165.54 | loss-text 3.4211\n",
      "2022-04-09 12:52:25,809 - INFO: | epoch  19 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 162.73 | loss-text 3.3629\n",
      "2022-04-09 12:52:42,163 - INFO: | epoch  19 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.53 | loss-text 3.4133\n",
      "2022-04-09 12:52:58,529 - INFO: | epoch  19 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.65 | loss-text 3.4402\n",
      "2022-04-09 12:53:14,906 - INFO: | epoch  19 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.76 | loss-text 3.3827\n",
      "2022-04-09 12:53:31,467 - INFO: | epoch  19 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 165.61 | loss-text 3.3937\n",
      "2022-04-09 12:53:47,913 - INFO: | epoch  19 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.45 | loss-text 3.4029\n",
      "2022-04-09 12:54:04,309 - INFO: | epoch  19 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.95 | loss-text 3.4611\n",
      "2022-04-09 12:54:20,770 - INFO: | epoch  19 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.60 | loss-text 3.4576\n",
      "2022-04-09 12:54:37,249 - INFO: | epoch  19 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.78 | loss-text 3.4251\n",
      "2022-04-09 12:54:53,785 - INFO: | epoch  19 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 165.36 | loss-text 3.4316\n",
      "2022-04-09 12:55:10,289 - INFO: | epoch  19 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 165.02 | loss-text 3.4292\n",
      "2022-04-09 12:55:26,727 - INFO: | epoch  19 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.38 | loss-text 3.3295\n",
      "2022-04-09 12:55:43,238 - INFO: | epoch  19 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 165.10 | loss-text 3.4386\n",
      "2022-04-09 12:55:59,572 - INFO: | epoch  19 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.34 | loss-text 3.3873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004059\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9976, 'reflen': 10295, 'guess': [9976, 8952, 7928, 6904], 'correct': [4966, 1517, 534, 142]}\n",
      "ratio: 0.969014084506948\n",
      "Bleu_1: 0.482\n",
      "Bleu_2: 0.281\n",
      "Bleu_3: 0.173\n",
      "Bleu_4: 0.101\n",
      "computing METEOR score...\n",
      "METEOR: 0.140\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.330\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.207\n",
      "computing SPICE score...\n",
      "SPICE: 0.089\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.148\n",
      "2022-04-09 12:56:38,841 - INFO: eval_greddy SPIDEr: 0.1477\n",
      "loading annotations into memory...\n",
      "0:00:00.004189\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8000, 'reflen': 9321, 'guess': [8000, 6976, 5952, 4928], 'correct': [4275, 1344, 505, 163]}\n",
      "ratio: 0.8582770089045318\n",
      "Bleu_1: 0.453\n",
      "Bleu_2: 0.272\n",
      "Bleu_3: 0.175\n",
      "Bleu_4: 0.111\n",
      "computing METEOR score...\n",
      "METEOR: 0.131\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.325\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.217\n",
      "computing SPICE score...\n",
      "SPICE: 0.085\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.151\n",
      "2022-04-09 12:57:04,841 - INFO: eval_beam_2 SPIDEr: 0.1511\n",
      "loading annotations into memory...\n",
      "0:00:00.003927\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7591, 'reflen': 9243, 'guess': [7591, 6567, 5543, 4519], 'correct': [4150, 1350, 535, 181]}\n",
      "ratio: 0.8212701503839855\n",
      "Bleu_1: 0.440\n",
      "Bleu_2: 0.270\n",
      "Bleu_3: 0.178\n",
      "Bleu_4: 0.116\n",
      "computing METEOR score...\n",
      "METEOR: 0.131\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.327\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.229\n",
      "computing SPICE score...\n",
      "SPICE: 0.083\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.156\n",
      "2022-04-09 12:57:31,954 - INFO: eval_beam_3 SPIDEr: 0.1561\n",
      "loading annotations into memory...\n",
      "0:00:00.004168\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7357, 'reflen': 9219, 'guess': [7357, 6333, 5309, 4285], 'correct': [3996, 1332, 538, 181]}\n",
      "ratio: 0.7980258162489643\n",
      "Bleu_1: 0.422\n",
      "Bleu_2: 0.262\n",
      "Bleu_3: 0.176\n",
      "Bleu_4: 0.115\n",
      "computing METEOR score...\n",
      "METEOR: 0.128\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.325\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.228\n",
      "computing SPICE score...\n",
      "SPICE: 0.080\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.154\n",
      "2022-04-09 12:58:02,254 - INFO: eval_beam_4 SPIDEr: 0.1540\n",
      "2022-04-09 12:58:18,802 - INFO: | epoch  20 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.45 | loss-text 3.3954\n",
      "2022-04-09 12:58:34,999 - INFO: | epoch  20 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.95 | loss-text 3.3739\n",
      "2022-04-09 12:58:51,244 - INFO: | epoch  20 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.45 | loss-text 3.4035\n",
      "2022-04-09 12:59:07,621 - INFO: | epoch  20 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.76 | loss-text 3.3780\n",
      "2022-04-09 12:59:23,882 - INFO: | epoch  20 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.59 | loss-text 3.3677\n",
      "2022-04-09 12:59:40,260 - INFO: | epoch  20 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.77 | loss-text 3.4163\n",
      "2022-04-09 12:59:56,560 - INFO: | epoch  20 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 162.99 | loss-text 3.3813\n",
      "2022-04-09 13:00:12,940 - INFO: | epoch  20 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.80 | loss-text 3.4517\n",
      "2022-04-09 13:00:29,433 - INFO: | epoch  20 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.92 | loss-text 3.4506\n",
      "2022-04-09 13:00:45,738 - INFO: | epoch  20 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.04 | loss-text 3.4281\n",
      "2022-04-09 13:01:02,379 - INFO: | epoch  20 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 166.40 | loss-text 3.4042\n",
      "2022-04-09 13:01:18,759 - INFO: | epoch  20 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.80 | loss-text 3.3840\n",
      "2022-04-09 13:01:35,205 - INFO: | epoch  20 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.45 | loss-text 3.4224\n",
      "2022-04-09 13:01:51,610 - INFO: | epoch  20 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.04 | loss-text 3.3915\n",
      "2022-04-09 13:02:08,083 - INFO: | epoch  20 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.72 | loss-text 3.4303\n",
      "2022-04-09 13:02:24,542 - INFO: | epoch  20 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.58 | loss-text 3.3957\n",
      "2022-04-09 13:02:40,909 - INFO: | epoch  20 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.66 | loss-text 3.4127\n",
      "2022-04-09 13:02:57,286 - INFO: | epoch  20 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.77 | loss-text 3.3525\n",
      "2022-04-09 13:03:13,734 - INFO: | epoch  20 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.47 | loss-text 3.3555\n",
      "2022-04-09 13:03:30,280 - INFO: | epoch  20 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 165.45 | loss-text 3.3967\n",
      "2022-04-09 13:03:46,521 - INFO: | epoch  20 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 162.40 | loss-text 3.3886\n",
      "2022-04-09 13:04:03,015 - INFO: | epoch  20 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.94 | loss-text 3.4020\n",
      "2022-04-09 13:04:19,340 - INFO: | epoch  20 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.24 | loss-text 3.3516\n",
      "2022-04-09 13:04:35,834 - INFO: | epoch  20 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.94 | loss-text 3.3474\n",
      "2022-04-09 13:04:52,394 - INFO: | epoch  20 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 165.60 | loss-text 3.4357\n",
      "2022-04-09 13:05:08,845 - INFO: | epoch  20 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.50 | loss-text 3.4484\n",
      "2022-04-09 13:05:25,204 - INFO: | epoch  20 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.58 | loss-text 3.3599\n",
      "2022-04-09 13:05:41,685 - INFO: | epoch  20 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.81 | loss-text 3.3936\n",
      "2022-04-09 13:05:57,970 - INFO: | epoch  20 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 162.84 | loss-text 3.4196\n",
      "2022-04-09 13:06:14,400 - INFO: | epoch  20 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.29 | loss-text 3.3536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003997\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11526, 'reflen': 11151, 'guess': [11526, 10502, 9478, 8454], 'correct': [5693, 1825, 643, 174]}\n",
      "ratio: 1.0336292709173138\n",
      "Bleu_1: 0.494\n",
      "Bleu_2: 0.293\n",
      "Bleu_3: 0.180\n",
      "Bleu_4: 0.105\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.344\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.230\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.161\n",
      "2022-04-09 13:06:55,019 - INFO: eval_greddy SPIDEr: 0.1609\n",
      "loading annotations into memory...\n",
      "0:00:00.003957\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9408, 'reflen': 9955, 'guess': [9408, 8384, 7360, 6336], 'correct': [5074, 1796, 712, 206]}\n",
      "ratio: 0.9450527373178357\n",
      "Bleu_1: 0.509\n",
      "Bleu_2: 0.321\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.145\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.262\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.178\n",
      "2022-04-09 13:07:23,463 - INFO: eval_beam_2 SPIDEr: 0.1781\n",
      "loading annotations into memory...\n",
      "0:00:00.004227\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8332, 'reflen': 9463, 'guess': [8332, 7308, 6284, 5260], 'correct': [4623, 1680, 701, 225]}\n",
      "ratio: 0.880481876783168\n",
      "Bleu_1: 0.484\n",
      "Bleu_2: 0.312\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.342\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.268\n",
      "computing SPICE score...\n",
      "SPICE: 0.091\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.179\n",
      "2022-04-09 13:07:57,610 - INFO: eval_beam_3 SPIDEr: 0.1791\n",
      "loading annotations into memory...\n",
      "0:00:00.004060\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7753, 'reflen': 9283, 'guess': [7753, 6729, 5705, 4681], 'correct': [4297, 1568, 656, 218]}\n",
      "ratio: 0.8351825918344462\n",
      "Bleu_1: 0.455\n",
      "Bleu_2: 0.295\n",
      "Bleu_3: 0.202\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.134\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.336\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.254\n",
      "computing SPICE score...\n",
      "SPICE: 0.085\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.170\n",
      "2022-04-09 13:08:33,607 - INFO: eval_beam_4 SPIDEr: 0.1697\n",
      "2022-04-09 13:08:50,292 - INFO: | epoch  21 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 166.82 | loss-text 3.3504\n",
      "2022-04-09 13:09:06,328 - INFO: | epoch  21 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 160.35 | loss-text 3.3960\n",
      "2022-04-09 13:09:22,483 - INFO: | epoch  21 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 161.55 | loss-text 3.3651\n",
      "2022-04-09 13:09:38,764 - INFO: | epoch  21 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.80 | loss-text 3.3626\n",
      "2022-04-09 13:09:54,975 - INFO: | epoch  21 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.11 | loss-text 3.3726\n",
      "2022-04-09 13:10:11,302 - INFO: | epoch  21 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.27 | loss-text 3.3985\n",
      "2022-04-09 13:10:27,641 - INFO: | epoch  21 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.38 | loss-text 3.3840\n",
      "2022-04-09 13:10:43,808 - INFO: | epoch  21 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 161.67 | loss-text 3.4023\n",
      "2022-04-09 13:11:00,288 - INFO: | epoch  21 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.80 | loss-text 3.3625\n",
      "2022-04-09 13:11:16,682 - INFO: | epoch  21 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.93 | loss-text 3.4381\n",
      "2022-04-09 13:11:33,146 - INFO: | epoch  21 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.63 | loss-text 3.4059\n",
      "2022-04-09 13:11:49,700 - INFO: | epoch  21 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 165.54 | loss-text 3.3362\n",
      "2022-04-09 13:12:06,174 - INFO: | epoch  21 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.73 | loss-text 3.3924\n",
      "2022-04-09 13:12:22,636 - INFO: | epoch  21 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.61 | loss-text 3.3906\n",
      "2022-04-09 13:12:39,046 - INFO: | epoch  21 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.10 | loss-text 3.4024\n",
      "2022-04-09 13:12:55,497 - INFO: | epoch  21 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.50 | loss-text 3.4014\n",
      "2022-04-09 13:13:11,852 - INFO: | epoch  21 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.54 | loss-text 3.3164\n",
      "2022-04-09 13:13:28,305 - INFO: | epoch  21 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.53 | loss-text 3.4134\n",
      "2022-04-09 13:13:44,704 - INFO: | epoch  21 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.98 | loss-text 3.3682\n",
      "2022-04-09 13:14:01,152 - INFO: | epoch  21 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.47 | loss-text 3.3468\n",
      "2022-04-09 13:14:17,511 - INFO: | epoch  21 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 163.58 | loss-text 3.3892\n",
      "2022-04-09 13:14:33,990 - INFO: | epoch  21 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.79 | loss-text 3.4008\n",
      "2022-04-09 13:14:50,480 - INFO: | epoch  21 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.89 | loss-text 3.3523\n",
      "2022-04-09 13:15:06,912 - INFO: | epoch  21 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.32 | loss-text 3.3745\n",
      "2022-04-09 13:15:23,254 - INFO: | epoch  21 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.41 | loss-text 3.3626\n",
      "2022-04-09 13:15:39,634 - INFO: | epoch  21 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.80 | loss-text 3.3852\n",
      "2022-04-09 13:15:56,115 - INFO: | epoch  21 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.80 | loss-text 3.3822\n",
      "2022-04-09 13:16:12,418 - INFO: | epoch  21 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.03 | loss-text 3.3737\n",
      "2022-04-09 13:16:28,659 - INFO: | epoch  21 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 162.41 | loss-text 3.3773\n",
      "2022-04-09 13:16:45,062 - INFO: | epoch  21 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.02 | loss-text 3.3934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004018\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10395, 'reflen': 10431, 'guess': [10395, 9371, 8347, 7323], 'correct': [5336, 1632, 574, 173]}\n",
      "ratio: 0.9965487489213884\n",
      "Bleu_1: 0.512\n",
      "Bleu_2: 0.298\n",
      "Bleu_3: 0.183\n",
      "Bleu_4: 0.109\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.337\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.221\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.158\n",
      "2022-04-09 13:17:23,316 - INFO: eval_greddy SPIDEr: 0.1582\n",
      "loading annotations into memory...\n",
      "0:00:00.004000\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8856, 'reflen': 9612, 'guess': [8856, 7832, 6808, 5784], 'correct': [4865, 1649, 630, 185]}\n",
      "ratio: 0.9213483146066457\n",
      "Bleu_1: 0.504\n",
      "Bleu_2: 0.312\n",
      "Bleu_3: 0.202\n",
      "Bleu_4: 0.125\n",
      "computing METEOR score...\n",
      "METEOR: 0.143\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.341\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.248\n",
      "computing SPICE score...\n",
      "SPICE: 0.093\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.170\n",
      "2022-04-09 13:17:50,412 - INFO: eval_beam_2 SPIDEr: 0.1704\n",
      "loading annotations into memory...\n",
      "0:00:00.003965\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8208, 'reflen': 9406, 'guess': [8208, 7184, 6160, 5136], 'correct': [4560, 1593, 641, 208]}\n",
      "ratio: 0.8726344886241896\n",
      "Bleu_1: 0.480\n",
      "Bleu_2: 0.303\n",
      "Bleu_3: 0.202\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.139\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.341\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.262\n",
      "computing SPICE score...\n",
      "SPICE: 0.086\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.174\n",
      "2022-04-09 13:18:18,131 - INFO: eval_beam_3 SPIDEr: 0.1741\n",
      "loading annotations into memory...\n",
      "0:00:00.004017\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7749, 'reflen': 9278, 'guess': [7749, 6725, 5701, 4677], 'correct': [4342, 1584, 669, 226]}\n",
      "ratio: 0.8352015520585433\n",
      "Bleu_1: 0.460\n",
      "Bleu_2: 0.298\n",
      "Bleu_3: 0.205\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.137\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.341\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.263\n",
      "computing SPICE score...\n",
      "SPICE: 0.085\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.174\n",
      "2022-04-09 13:18:54,132 - INFO: eval_beam_4 SPIDEr: 0.1742\n",
      "2022-04-09 13:19:10,672 - INFO: | epoch  22 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.37 | loss-text 3.3845\n",
      "2022-04-09 13:19:26,825 - INFO: | epoch  22 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.51 | loss-text 3.3301\n",
      "2022-04-09 13:19:43,096 - INFO: | epoch  22 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.70 | loss-text 3.3473\n",
      "2022-04-09 13:19:59,368 - INFO: | epoch  22 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.71 | loss-text 3.3716\n",
      "2022-04-09 13:20:15,706 - INFO: | epoch  22 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.38 | loss-text 3.3053\n",
      "2022-04-09 13:20:32,060 - INFO: | epoch  22 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.53 | loss-text 3.3652\n",
      "2022-04-09 13:20:48,407 - INFO: | epoch  22 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.47 | loss-text 3.3435\n",
      "2022-04-09 13:21:04,721 - INFO: | epoch  22 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.14 | loss-text 3.3615\n",
      "2022-04-09 13:21:21,099 - INFO: | epoch  22 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.77 | loss-text 3.3410\n",
      "2022-04-09 13:21:37,454 - INFO: | epoch  22 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.55 | loss-text 3.3688\n",
      "2022-04-09 13:21:53,891 - INFO: | epoch  22 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.36 | loss-text 3.3840\n",
      "2022-04-09 13:22:10,256 - INFO: | epoch  22 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.64 | loss-text 3.3512\n",
      "2022-04-09 13:22:26,720 - INFO: | epoch  22 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.63 | loss-text 3.4439\n",
      "2022-04-09 13:22:43,213 - INFO: | epoch  22 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.92 | loss-text 3.3501\n",
      "2022-04-09 13:22:59,514 - INFO: | epoch  22 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.01 | loss-text 3.3471\n",
      "2022-04-09 13:23:15,989 - INFO: | epoch  22 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.74 | loss-text 3.4092\n",
      "2022-04-09 13:23:32,387 - INFO: | epoch  22 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.97 | loss-text 3.4046\n",
      "2022-04-09 13:23:48,791 - INFO: | epoch  22 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.03 | loss-text 3.3662\n",
      "2022-04-09 13:24:05,127 - INFO: | epoch  22 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.35 | loss-text 3.3838\n",
      "2022-04-09 13:24:21,648 - INFO: | epoch  22 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 165.20 | loss-text 3.3741\n",
      "2022-04-09 13:24:38,069 - INFO: | epoch  22 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.21 | loss-text 3.3767\n",
      "2022-04-09 13:24:54,600 - INFO: | epoch  22 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 165.30 | loss-text 3.3907\n",
      "2022-04-09 13:25:10,935 - INFO: | epoch  22 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.35 | loss-text 3.3893\n",
      "2022-04-09 13:25:27,413 - INFO: | epoch  22 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.77 | loss-text 3.3737\n",
      "2022-04-09 13:25:43,672 - INFO: | epoch  22 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 162.58 | loss-text 3.3983\n",
      "2022-04-09 13:26:00,044 - INFO: | epoch  22 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.71 | loss-text 3.3289\n",
      "2022-04-09 13:26:16,449 - INFO: | epoch  22 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.05 | loss-text 3.4000\n",
      "2022-04-09 13:26:32,973 - INFO: | epoch  22 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 165.24 | loss-text 3.4042\n",
      "2022-04-09 13:26:49,476 - INFO: | epoch  22 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 165.02 | loss-text 3.3490\n",
      "2022-04-09 13:27:06,012 - INFO: | epoch  22 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 165.35 | loss-text 3.3322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003909\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10067, 'reflen': 10313, 'guess': [10067, 9043, 8019, 6995], 'correct': [5058, 1612, 573, 143]}\n",
      "ratio: 0.9761466110733078\n",
      "Bleu_1: 0.490\n",
      "Bleu_2: 0.292\n",
      "Bleu_3: 0.181\n",
      "Bleu_4: 0.104\n",
      "computing METEOR score...\n",
      "METEOR: 0.140\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.336\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.225\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.158\n",
      "2022-04-09 13:27:44,906 - INFO: eval_greddy SPIDEr: 0.1583\n",
      "loading annotations into memory...\n",
      "0:00:00.003904\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8529, 'reflen': 9476, 'guess': [8529, 7505, 6481, 5457], 'correct': [4592, 1591, 643, 191]}\n",
      "ratio: 0.9000633178555403\n",
      "Bleu_1: 0.482\n",
      "Bleu_2: 0.302\n",
      "Bleu_3: 0.201\n",
      "Bleu_4: 0.126\n",
      "computing METEOR score...\n",
      "METEOR: 0.137\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.336\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.247\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.170\n",
      "2022-04-09 13:28:12,302 - INFO: eval_beam_2 SPIDEr: 0.1697\n",
      "loading annotations into memory...\n",
      "0:00:00.004023\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7951, 'reflen': 9317, 'guess': [7951, 6927, 5903, 4879], 'correct': [4267, 1475, 598, 177]}\n",
      "ratio: 0.8533862831382576\n",
      "Bleu_1: 0.452\n",
      "Bleu_2: 0.285\n",
      "Bleu_3: 0.191\n",
      "Bleu_4: 0.121\n",
      "computing METEOR score...\n",
      "METEOR: 0.133\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.324\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.239\n",
      "computing SPICE score...\n",
      "SPICE: 0.088\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.163\n",
      "2022-04-09 13:28:42,804 - INFO: eval_beam_3 SPIDEr: 0.1632\n",
      "loading annotations into memory...\n",
      "0:00:00.004005\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7314, 'reflen': 9234, 'guess': [7314, 6290, 5266, 4242], 'correct': [3942, 1415, 568, 168]}\n",
      "ratio: 0.7920727745288291\n",
      "Bleu_1: 0.415\n",
      "Bleu_2: 0.268\n",
      "Bleu_3: 0.181\n",
      "Bleu_4: 0.116\n",
      "computing METEOR score...\n",
      "METEOR: 0.127\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.317\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.235\n",
      "computing SPICE score...\n",
      "SPICE: 0.084\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.159\n",
      "2022-04-09 13:29:13,890 - INFO: eval_beam_4 SPIDEr: 0.1594\n",
      "2022-04-09 13:29:30,298 - INFO: | epoch  23 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.04 | loss-text 3.3621\n",
      "2022-04-09 13:29:46,539 - INFO: | epoch  23 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.40 | loss-text 3.3599\n",
      "2022-04-09 13:30:02,861 - INFO: | epoch  23 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 163.21 | loss-text 3.3570\n",
      "2022-04-09 13:30:19,019 - INFO: | epoch  23 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 161.58 | loss-text 3.3821\n",
      "2022-04-09 13:30:35,267 - INFO: | epoch  23 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.47 | loss-text 3.3518\n",
      "2022-04-09 13:30:51,550 - INFO: | epoch  23 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.82 | loss-text 3.3556\n",
      "2022-04-09 13:31:07,902 - INFO: | epoch  23 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.51 | loss-text 3.3441\n",
      "2022-04-09 13:31:24,312 - INFO: | epoch  23 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.10 | loss-text 3.3394\n",
      "2022-04-09 13:31:40,754 - INFO: | epoch  23 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.41 | loss-text 3.4091\n",
      "2022-04-09 13:31:57,184 - INFO: | epoch  23 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.29 | loss-text 3.3403\n",
      "2022-04-09 13:32:13,628 - INFO: | epoch  23 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.43 | loss-text 3.3653\n",
      "2022-04-09 13:32:30,000 - INFO: | epoch  23 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.71 | loss-text 3.3038\n",
      "2022-04-09 13:32:46,398 - INFO: | epoch  23 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.97 | loss-text 3.3658\n",
      "2022-04-09 13:33:02,738 - INFO: | epoch  23 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.40 | loss-text 3.3821\n",
      "2022-04-09 13:33:19,282 - INFO: | epoch  23 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 165.43 | loss-text 3.3853\n",
      "2022-04-09 13:33:35,833 - INFO: | epoch  23 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 165.50 | loss-text 3.3293\n",
      "2022-04-09 13:33:52,300 - INFO: | epoch  23 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.66 | loss-text 3.3651\n",
      "2022-04-09 13:34:08,894 - INFO: | epoch  23 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 165.93 | loss-text 3.3247\n",
      "2022-04-09 13:34:25,211 - INFO: | epoch  23 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.16 | loss-text 3.3623\n",
      "2022-04-09 13:34:41,568 - INFO: | epoch  23 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.56 | loss-text 3.3834\n",
      "2022-04-09 13:34:57,985 - INFO: | epoch  23 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.17 | loss-text 3.3700\n",
      "2022-04-09 13:35:14,373 - INFO: | epoch  23 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.87 | loss-text 3.3389\n",
      "2022-04-09 13:35:30,823 - INFO: | epoch  23 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.50 | loss-text 3.3363\n",
      "2022-04-09 13:35:47,213 - INFO: | epoch  23 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.90 | loss-text 3.3774\n",
      "2022-04-09 13:36:03,809 - INFO: | epoch  23 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 165.94 | loss-text 3.3242\n",
      "2022-04-09 13:36:20,207 - INFO: | epoch  23 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.97 | loss-text 3.3634\n",
      "2022-04-09 13:36:36,633 - INFO: | epoch  23 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.25 | loss-text 3.3435\n",
      "2022-04-09 13:36:53,021 - INFO: | epoch  23 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.87 | loss-text 3.3714\n",
      "2022-04-09 13:37:09,409 - INFO: | epoch  23 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.87 | loss-text 3.3480\n",
      "2022-04-09 13:37:25,814 - INFO: | epoch  23 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.04 | loss-text 3.3228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003901\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10256, 'reflen': 10433, 'guess': [10256, 9232, 8208, 7184], 'correct': [5056, 1570, 582, 188]}\n",
      "ratio: 0.9830346017443704\n",
      "Bleu_1: 0.485\n",
      "Bleu_2: 0.285\n",
      "Bleu_3: 0.178\n",
      "Bleu_4: 0.110\n",
      "computing METEOR score...\n",
      "METEOR: 0.140\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.334\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.236\n",
      "computing SPICE score...\n",
      "SPICE: 0.087\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.161\n",
      "2022-04-09 13:38:03,217 - INFO: eval_greddy SPIDEr: 0.1615\n",
      "loading annotations into memory...\n",
      "0:00:00.004063\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8414, 'reflen': 9451, 'guess': [8414, 7390, 6366, 5342], 'correct': [4474, 1469, 600, 208]}\n",
      "ratio: 0.8902761612526833\n",
      "Bleu_1: 0.470\n",
      "Bleu_2: 0.287\n",
      "Bleu_3: 0.190\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.134\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.333\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.252\n",
      "computing SPICE score...\n",
      "SPICE: 0.088\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.170\n",
      "2022-04-09 13:38:30,946 - INFO: eval_beam_2 SPIDEr: 0.1704\n",
      "loading annotations into memory...\n",
      "0:00:00.003912\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7686, 'reflen': 9270, 'guess': [7686, 6662, 5638, 4614], 'correct': [4144, 1379, 576, 212]}\n",
      "ratio: 0.8291262135921436\n",
      "Bleu_1: 0.439\n",
      "Bleu_2: 0.272\n",
      "Bleu_3: 0.183\n",
      "Bleu_4: 0.123\n",
      "computing METEOR score...\n",
      "METEOR: 0.131\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.328\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.246\n",
      "computing SPICE score...\n",
      "SPICE: 0.086\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.166\n",
      "2022-04-09 13:39:02,366 - INFO: eval_beam_3 SPIDEr: 0.1662\n",
      "loading annotations into memory...\n",
      "0:00:00.003947\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7328, 'reflen': 9220, 'guess': [7328, 6304, 5280, 4256], 'correct': [3938, 1300, 539, 195]}\n",
      "ratio: 0.7947939262472022\n",
      "Bleu_1: 0.415\n",
      "Bleu_2: 0.257\n",
      "Bleu_3: 0.173\n",
      "Bleu_4: 0.117\n",
      "computing METEOR score...\n",
      "METEOR: 0.127\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.320\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.236\n",
      "computing SPICE score...\n",
      "SPICE: 0.085\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.160\n",
      "2022-04-09 13:39:34,116 - INFO: eval_beam_4 SPIDEr: 0.1604\n",
      "2022-04-09 13:39:50,696 - INFO: | epoch  24 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.77 | loss-text 3.3317\n",
      "2022-04-09 13:40:06,946 - INFO: | epoch  24 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.49 | loss-text 3.3229\n",
      "2022-04-09 13:40:23,192 - INFO: | epoch  24 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.46 | loss-text 3.3420\n",
      "2022-04-09 13:40:39,384 - INFO: | epoch  24 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 161.91 | loss-text 3.3738\n",
      "2022-04-09 13:40:55,747 - INFO: | epoch  24 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.63 | loss-text 3.3142\n",
      "2022-04-09 13:41:12,044 - INFO: | epoch  24 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.96 | loss-text 3.3662\n",
      "2022-04-09 13:41:28,533 - INFO: | epoch  24 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 164.88 | loss-text 3.3013\n",
      "2022-04-09 13:41:44,961 - INFO: | epoch  24 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.27 | loss-text 3.3593\n",
      "2022-04-09 13:42:01,252 - INFO: | epoch  24 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 162.91 | loss-text 3.3094\n",
      "2022-04-09 13:42:17,729 - INFO: | epoch  24 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.77 | loss-text 3.3406\n",
      "2022-04-09 13:42:34,150 - INFO: | epoch  24 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.20 | loss-text 3.3635\n",
      "2022-04-09 13:42:50,577 - INFO: | epoch  24 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.27 | loss-text 3.3429\n",
      "2022-04-09 13:43:06,943 - INFO: | epoch  24 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.65 | loss-text 3.3657\n",
      "2022-04-09 13:43:23,312 - INFO: | epoch  24 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.69 | loss-text 3.3191\n",
      "2022-04-09 13:43:39,640 - INFO: | epoch  24 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.27 | loss-text 3.3524\n",
      "2022-04-09 13:43:56,031 - INFO: | epoch  24 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.91 | loss-text 3.3550\n",
      "2022-04-09 13:44:12,456 - INFO: | epoch  24 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.24 | loss-text 3.3463\n",
      "2022-04-09 13:44:28,953 - INFO: | epoch  24 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.96 | loss-text 3.3521\n",
      "2022-04-09 13:44:45,404 - INFO: | epoch  24 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.51 | loss-text 3.3321\n",
      "2022-04-09 13:45:01,841 - INFO: | epoch  24 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.36 | loss-text 3.3574\n",
      "2022-04-09 13:45:18,288 - INFO: | epoch  24 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.46 | loss-text 3.3600\n",
      "2022-04-09 13:45:34,784 - INFO: | epoch  24 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.96 | loss-text 3.3370\n",
      "2022-04-09 13:45:51,039 - INFO: | epoch  24 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 162.54 | loss-text 3.3623\n",
      "2022-04-09 13:46:07,441 - INFO: | epoch  24 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.02 | loss-text 3.3457\n",
      "2022-04-09 13:46:23,814 - INFO: | epoch  24 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.72 | loss-text 3.3266\n",
      "2022-04-09 13:46:40,256 - INFO: | epoch  24 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.41 | loss-text 3.3013\n",
      "2022-04-09 13:46:56,672 - INFO: | epoch  24 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.16 | loss-text 3.2468\n",
      "2022-04-09 13:47:13,085 - INFO: | epoch  24 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.13 | loss-text 3.3388\n",
      "2022-04-09 13:47:29,529 - INFO: | epoch  24 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.43 | loss-text 3.3685\n",
      "2022-04-09 13:47:45,951 - INFO: | epoch  24 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.22 | loss-text 3.3435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003972\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10352, 'reflen': 10432, 'guess': [10352, 9328, 8304, 7280], 'correct': [5325, 1758, 670, 213]}\n",
      "ratio: 0.9923312883434631\n",
      "Bleu_1: 0.510\n",
      "Bleu_2: 0.309\n",
      "Bleu_3: 0.197\n",
      "Bleu_4: 0.122\n",
      "computing METEOR score...\n",
      "METEOR: 0.145\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.249\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.172\n",
      "2022-04-09 13:48:25,074 - INFO: eval_greddy SPIDEr: 0.1721\n",
      "loading annotations into memory...\n",
      "0:00:00.004068\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8624, 'reflen': 9517, 'guess': [8624, 7600, 6576, 5552], 'correct': [4831, 1734, 710, 240]}\n",
      "ratio: 0.9061679100555946\n",
      "Bleu_1: 0.505\n",
      "Bleu_2: 0.322\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.144\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.276\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.185\n",
      "2022-04-09 13:48:52,364 - INFO: eval_beam_2 SPIDEr: 0.1853\n",
      "loading annotations into memory...\n",
      "0:00:00.003988\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8069, 'reflen': 9372, 'guess': [8069, 7045, 6021, 4997], 'correct': [4557, 1604, 661, 212]}\n",
      "ratio: 0.8609688433631176\n",
      "Bleu_1: 0.481\n",
      "Bleu_2: 0.305\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.139\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.345\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.268\n",
      "computing SPICE score...\n",
      "SPICE: 0.089\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.179\n",
      "2022-04-09 13:49:24,970 - INFO: eval_beam_3 SPIDEr: 0.1788\n",
      "loading annotations into memory...\n",
      "0:00:00.004173\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7562, 'reflen': 9254, 'guess': [7562, 6538, 5514, 4490], 'correct': [4290, 1538, 639, 207]}\n",
      "ratio: 0.8171601469633869\n",
      "Bleu_1: 0.454\n",
      "Bleu_2: 0.292\n",
      "Bleu_3: 0.199\n",
      "Bleu_4: 0.131\n",
      "computing METEOR score...\n",
      "METEOR: 0.136\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.343\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.261\n",
      "computing SPICE score...\n",
      "SPICE: 0.087\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.174\n",
      "2022-04-09 13:49:57,113 - INFO: eval_beam_4 SPIDEr: 0.1741\n",
      "2022-04-09 13:50:13,626 - INFO: | epoch  25 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.09 | loss-text 3.3860\n",
      "2022-04-09 13:50:29,849 - INFO: | epoch  25 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.22 | loss-text 3.3432\n",
      "2022-04-09 13:50:46,192 - INFO: | epoch  25 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 163.42 | loss-text 3.3664\n",
      "2022-04-09 13:51:02,520 - INFO: | epoch  25 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.27 | loss-text 3.3006\n",
      "2022-04-09 13:51:18,875 - INFO: | epoch  25 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.54 | loss-text 3.3379\n",
      "2022-04-09 13:51:35,120 - INFO: | epoch  25 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.45 | loss-text 3.3753\n",
      "2022-04-09 13:51:51,422 - INFO: | epoch  25 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.01 | loss-text 3.3364\n",
      "2022-04-09 13:52:07,884 - INFO: | epoch  25 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.61 | loss-text 3.3361\n",
      "2022-04-09 13:52:24,232 - INFO: | epoch  25 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.48 | loss-text 3.3220\n",
      "2022-04-09 13:52:40,668 - INFO: | epoch  25 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.36 | loss-text 3.3470\n",
      "2022-04-09 13:52:57,006 - INFO: | epoch  25 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.38 | loss-text 3.3137\n",
      "2022-04-09 13:53:13,499 - INFO: | epoch  25 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.92 | loss-text 3.3604\n",
      "2022-04-09 13:53:29,917 - INFO: | epoch  25 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.17 | loss-text 3.3293\n",
      "2022-04-09 13:53:46,339 - INFO: | epoch  25 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.22 | loss-text 3.2891\n",
      "2022-04-09 13:54:02,816 - INFO: | epoch  25 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.76 | loss-text 3.3011\n",
      "2022-04-09 13:54:19,108 - INFO: | epoch  25 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 162.91 | loss-text 3.2975\n",
      "2022-04-09 13:54:35,460 - INFO: | epoch  25 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.52 | loss-text 3.2835\n",
      "2022-04-09 13:54:51,888 - INFO: | epoch  25 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.27 | loss-text 3.3289\n",
      "2022-04-09 13:55:08,122 - INFO: | epoch  25 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 162.34 | loss-text 3.3339\n",
      "2022-04-09 13:55:24,604 - INFO: | epoch  25 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.81 | loss-text 3.3160\n",
      "2022-04-09 13:55:41,035 - INFO: | epoch  25 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.30 | loss-text 3.3367\n",
      "2022-04-09 13:55:57,532 - INFO: | epoch  25 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.96 | loss-text 3.3568\n",
      "2022-04-09 13:56:13,948 - INFO: | epoch  25 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.16 | loss-text 3.3451\n",
      "2022-04-09 13:56:30,329 - INFO: | epoch  25 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.80 | loss-text 3.2913\n",
      "2022-04-09 13:56:46,842 - INFO: | epoch  25 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 165.12 | loss-text 3.2975\n",
      "2022-04-09 13:57:03,180 - INFO: | epoch  25 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.37 | loss-text 3.3715\n",
      "2022-04-09 13:57:19,699 - INFO: | epoch  25 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 165.18 | loss-text 3.2831\n",
      "2022-04-09 13:57:36,056 - INFO: | epoch  25 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.55 | loss-text 3.3412\n",
      "2022-04-09 13:57:52,450 - INFO: | epoch  25 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.94 | loss-text 3.3582\n",
      "2022-04-09 13:58:08,720 - INFO: | epoch  25 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 162.69 | loss-text 3.3607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004006\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10868, 'reflen': 10768, 'guess': [10868, 9844, 8820, 7796], 'correct': [5469, 1794, 640, 178]}\n",
      "ratio: 1.009286775631407\n",
      "Bleu_1: 0.503\n",
      "Bleu_2: 0.303\n",
      "Bleu_3: 0.188\n",
      "Bleu_4: 0.111\n",
      "computing METEOR score...\n",
      "METEOR: 0.149\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.254\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.174\n",
      "2022-04-09 13:58:47,946 - INFO: eval_greddy SPIDEr: 0.1744\n",
      "loading annotations into memory...\n",
      "0:00:00.004071\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8976, 'reflen': 9843, 'guess': [8976, 7952, 6928, 5904], 'correct': [4707, 1582, 600, 203]}\n",
      "ratio: 0.9119170984455032\n",
      "Bleu_1: 0.476\n",
      "Bleu_2: 0.293\n",
      "Bleu_3: 0.189\n",
      "Bleu_4: 0.121\n",
      "computing METEOR score...\n",
      "METEOR: 0.142\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.333\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.260\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.176\n",
      "2022-04-09 13:59:16,589 - INFO: eval_beam_2 SPIDEr: 0.1759\n",
      "loading annotations into memory...\n",
      "0:00:00.003927\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8171, 'reflen': 9444, 'guess': [8171, 7147, 6123, 5099], 'correct': [4444, 1540, 621, 226]}\n",
      "ratio: 0.8652054214315051\n",
      "Bleu_1: 0.465\n",
      "Bleu_2: 0.293\n",
      "Bleu_3: 0.195\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.139\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.333\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.268\n",
      "computing SPICE score...\n",
      "SPICE: 0.089\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.179\n",
      "2022-04-09 13:59:48,580 - INFO: eval_beam_3 SPIDEr: 0.1785\n",
      "loading annotations into memory...\n",
      "0:00:00.003976\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7619, 'reflen': 9312, 'guess': [7619, 6595, 5571, 4547], 'correct': [4245, 1463, 609, 236]}\n",
      "ratio: 0.8181915807559258\n",
      "Bleu_1: 0.446\n",
      "Bleu_2: 0.282\n",
      "Bleu_3: 0.191\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.135\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.332\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.259\n",
      "computing SPICE score...\n",
      "SPICE: 0.089\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.174\n",
      "2022-04-09 14:00:25,957 - INFO: eval_beam_4 SPIDEr: 0.1742\n",
      "2022-04-09 14:00:42,253 - INFO: | epoch  26 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 162.93 | loss-text 3.3305\n",
      "2022-04-09 14:00:58,438 - INFO: | epoch  26 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.84 | loss-text 3.2700\n",
      "2022-04-09 14:01:14,622 - INFO: | epoch  26 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 161.83 | loss-text 3.3069\n",
      "2022-04-09 14:01:30,898 - INFO: | epoch  26 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.76 | loss-text 3.2853\n",
      "2022-04-09 14:01:47,259 - INFO: | epoch  26 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.61 | loss-text 3.3115\n",
      "2022-04-09 14:02:03,725 - INFO: | epoch  26 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 164.65 | loss-text 3.3547\n",
      "2022-04-09 14:02:20,134 - INFO: | epoch  26 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 164.08 | loss-text 3.3290\n",
      "2022-04-09 14:02:36,607 - INFO: | epoch  26 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.72 | loss-text 3.2912\n",
      "2022-04-09 14:02:52,931 - INFO: | epoch  26 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.23 | loss-text 3.3010\n",
      "2022-04-09 14:03:09,195 - INFO: | epoch  26 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 162.63 | loss-text 3.3078\n",
      "2022-04-09 14:03:25,575 - INFO: | epoch  26 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.79 | loss-text 3.3438\n",
      "2022-04-09 14:03:41,904 - INFO: | epoch  26 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.29 | loss-text 3.3598\n",
      "2022-04-09 14:03:58,328 - INFO: | epoch  26 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.23 | loss-text 3.2903\n",
      "2022-04-09 14:04:14,788 - INFO: | epoch  26 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.59 | loss-text 3.3614\n",
      "2022-04-09 14:04:31,305 - INFO: | epoch  26 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 165.16 | loss-text 3.3335\n",
      "2022-04-09 14:04:47,704 - INFO: | epoch  26 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.99 | loss-text 3.3188\n",
      "2022-04-09 14:05:04,169 - INFO: | epoch  26 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.64 | loss-text 3.3130\n",
      "2022-04-09 14:05:20,666 - INFO: | epoch  26 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.96 | loss-text 3.3119\n",
      "2022-04-09 14:05:37,235 - INFO: | epoch  26 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 165.68 | loss-text 3.2415\n",
      "2022-04-09 14:05:53,614 - INFO: | epoch  26 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.79 | loss-text 3.3198\n",
      "2022-04-09 14:06:10,051 - INFO: | epoch  26 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.35 | loss-text 3.3154\n",
      "2022-04-09 14:06:26,375 - INFO: | epoch  26 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.24 | loss-text 3.3210\n",
      "2022-04-09 14:06:42,827 - INFO: | epoch  26 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.51 | loss-text 3.2940\n",
      "2022-04-09 14:06:59,314 - INFO: | epoch  26 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.87 | loss-text 3.3711\n",
      "2022-04-09 14:07:15,713 - INFO: | epoch  26 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.98 | loss-text 3.2663\n",
      "2022-04-09 14:07:32,092 - INFO: | epoch  26 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.79 | loss-text 3.3197\n",
      "2022-04-09 14:07:48,482 - INFO: | epoch  26 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.89 | loss-text 3.3119\n",
      "2022-04-09 14:08:04,923 - INFO: | epoch  26 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.40 | loss-text 3.2961\n",
      "2022-04-09 14:08:21,316 - INFO: | epoch  26 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.93 | loss-text 3.3419\n",
      "2022-04-09 14:08:37,723 - INFO: | epoch  26 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.06 | loss-text 3.2892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003908\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10721, 'reflen': 10735, 'guess': [10721, 9697, 8673, 7649], 'correct': [5329, 1680, 603, 177]}\n",
      "ratio: 0.9986958546808571\n",
      "Bleu_1: 0.496\n",
      "Bleu_2: 0.293\n",
      "Bleu_3: 0.181\n",
      "Bleu_4: 0.108\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.337\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.241\n",
      "computing SPICE score...\n",
      "SPICE: 0.090\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.166\n",
      "2022-04-09 14:09:16,688 - INFO: eval_greddy SPIDEr: 0.1657\n",
      "loading annotations into memory...\n",
      "0:00:00.003998\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8845, 'reflen': 9621, 'guess': [8845, 7821, 6797, 5773], 'correct': [4735, 1539, 597, 196]}\n",
      "ratio: 0.9193431036273859\n",
      "Bleu_1: 0.490\n",
      "Bleu_2: 0.297\n",
      "Bleu_3: 0.192\n",
      "Bleu_4: 0.122\n",
      "computing METEOR score...\n",
      "METEOR: 0.142\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.338\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.264\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.178\n",
      "2022-04-09 14:09:44,280 - INFO: eval_beam_2 SPIDEr: 0.1779\n",
      "loading annotations into memory...\n",
      "0:00:00.003997\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8334, 'reflen': 9469, 'guess': [8334, 7310, 6286, 5262], 'correct': [4518, 1529, 623, 220]}\n",
      "ratio: 0.8801351779490041\n",
      "Bleu_1: 0.473\n",
      "Bleu_2: 0.294\n",
      "Bleu_3: 0.195\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.140\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.338\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.270\n",
      "computing SPICE score...\n",
      "SPICE: 0.090\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.180\n",
      "2022-04-09 14:10:15,852 - INFO: eval_beam_3 SPIDEr: 0.1801\n",
      "loading annotations into memory...\n",
      "0:00:00.004044\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7622, 'reflen': 9310, 'guess': [7622, 6598, 5574, 4550], 'correct': [4258, 1494, 610, 202]}\n",
      "ratio: 0.8186895810955082\n",
      "Bleu_1: 0.448\n",
      "Bleu_2: 0.285\n",
      "Bleu_3: 0.192\n",
      "Bleu_4: 0.126\n",
      "computing METEOR score...\n",
      "METEOR: 0.137\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.337\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.267\n",
      "computing SPICE score...\n",
      "SPICE: 0.089\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.178\n",
      "2022-04-09 14:10:51,526 - INFO: eval_beam_4 SPIDEr: 0.1777\n",
      "2022-04-09 14:11:08,064 - INFO: | epoch  27 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.35 | loss-text 3.3341\n",
      "2022-04-09 14:11:24,138 - INFO: | epoch  27 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 160.72 | loss-text 3.2826\n",
      "2022-04-09 14:11:40,590 - INFO: | epoch  27 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 164.51 | loss-text 3.3493\n",
      "2022-04-09 14:11:56,825 - INFO: | epoch  27 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.34 | loss-text 3.3005\n",
      "2022-04-09 14:12:13,019 - INFO: | epoch  27 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 161.93 | loss-text 3.3003\n",
      "2022-04-09 14:12:29,538 - INFO: | epoch  27 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 165.19 | loss-text 3.3091\n",
      "2022-04-09 14:12:45,787 - INFO: | epoch  27 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 162.48 | loss-text 3.2773\n",
      "2022-04-09 14:13:02,197 - INFO: | epoch  27 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.09 | loss-text 3.2510\n",
      "2022-04-09 14:13:18,525 - INFO: | epoch  27 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.27 | loss-text 3.2764\n",
      "2022-04-09 14:13:35,028 - INFO: | epoch  27 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 165.03 | loss-text 3.3255\n",
      "2022-04-09 14:13:51,466 - INFO: | epoch  27 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.37 | loss-text 3.2975\n",
      "2022-04-09 14:14:07,878 - INFO: | epoch  27 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.12 | loss-text 3.2698\n",
      "2022-04-09 14:14:24,313 - INFO: | epoch  27 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.34 | loss-text 3.3031\n",
      "2022-04-09 14:14:40,744 - INFO: | epoch  27 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.30 | loss-text 3.3093\n",
      "2022-04-09 14:14:57,108 - INFO: | epoch  27 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.64 | loss-text 3.3039\n",
      "2022-04-09 14:15:13,482 - INFO: | epoch  27 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.73 | loss-text 3.2929\n",
      "2022-04-09 14:15:29,961 - INFO: | epoch  27 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.79 | loss-text 3.3383\n",
      "2022-04-09 14:15:46,202 - INFO: | epoch  27 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 162.39 | loss-text 3.2965\n",
      "2022-04-09 14:16:02,714 - INFO: | epoch  27 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 165.12 | loss-text 3.3365\n",
      "2022-04-09 14:16:19,076 - INFO: | epoch  27 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.61 | loss-text 3.2775\n",
      "2022-04-09 14:16:35,515 - INFO: | epoch  27 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.39 | loss-text 3.3365\n",
      "2022-04-09 14:16:51,890 - INFO: | epoch  27 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.74 | loss-text 3.2953\n",
      "2022-04-09 14:17:08,202 - INFO: | epoch  27 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.11 | loss-text 3.2914\n",
      "2022-04-09 14:17:24,616 - INFO: | epoch  27 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.13 | loss-text 3.3612\n",
      "2022-04-09 14:17:41,037 - INFO: | epoch  27 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.20 | loss-text 3.3062\n",
      "2022-04-09 14:17:57,322 - INFO: | epoch  27 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 162.85 | loss-text 3.2831\n",
      "2022-04-09 14:18:13,704 - INFO: | epoch  27 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.81 | loss-text 3.3051\n",
      "2022-04-09 14:18:30,050 - INFO: | epoch  27 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.45 | loss-text 3.3858\n",
      "2022-04-09 14:18:46,584 - INFO: | epoch  27 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 165.33 | loss-text 3.3014\n",
      "2022-04-09 14:19:03,094 - INFO: | epoch  27 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 165.09 | loss-text 3.3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003994\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10257, 'reflen': 10417, 'guess': [10257, 9233, 8209, 7185], 'correct': [5287, 1758, 640, 204]}\n",
      "ratio: 0.9846404915041773\n",
      "Bleu_1: 0.507\n",
      "Bleu_2: 0.308\n",
      "Bleu_3: 0.194\n",
      "Bleu_4: 0.120\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.345\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.246\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.170\n",
      "2022-04-09 14:19:42,247 - INFO: eval_greddy SPIDEr: 0.1701\n",
      "loading annotations into memory...\n",
      "0:00:00.003822\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8490, 'reflen': 9564, 'guess': [8490, 7466, 6442, 5418], 'correct': [4758, 1693, 684, 230]}\n",
      "ratio: 0.8877038895858544\n",
      "Bleu_1: 0.494\n",
      "Bleu_2: 0.314\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.145\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.346\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.263\n",
      "computing SPICE score...\n",
      "SPICE: 0.093\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.178\n",
      "2022-04-09 14:20:09,732 - INFO: eval_beam_2 SPIDEr: 0.1776\n",
      "loading annotations into memory...\n",
      "0:00:00.003771\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8094, 'reflen': 9411, 'guess': [8094, 7070, 6046, 5022], 'correct': [4559, 1669, 676, 224]}\n",
      "ratio: 0.8600573796620061\n",
      "Bleu_1: 0.479\n",
      "Bleu_2: 0.310\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.143\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.344\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.275\n",
      "computing SPICE score...\n",
      "SPICE: 0.089\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.182\n",
      "2022-04-09 14:20:42,273 - INFO: eval_beam_3 SPIDEr: 0.1820\n",
      "loading annotations into memory...\n",
      "0:00:00.004087\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7394, 'reflen': 9263, 'guess': [7394, 6370, 5346, 4322], 'correct': [4241, 1567, 641, 206]}\n",
      "ratio: 0.7982295152757424\n",
      "Bleu_1: 0.445\n",
      "Bleu_2: 0.292\n",
      "Bleu_3: 0.199\n",
      "Bleu_4: 0.131\n",
      "computing METEOR score...\n",
      "METEOR: 0.137\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.341\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.264\n",
      "computing SPICE score...\n",
      "SPICE: 0.086\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.175\n",
      "2022-04-09 14:21:13,184 - INFO: eval_beam_4 SPIDEr: 0.1751\n",
      "2022-04-09 14:21:29,798 - INFO: | epoch  28 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 166.10 | loss-text 3.2688\n",
      "2022-04-09 14:21:45,895 - INFO: | epoch  28 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 160.96 | loss-text 3.2650\n",
      "2022-04-09 14:22:02,155 - INFO: | epoch  28 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.59 | loss-text 3.2900\n",
      "2022-04-09 14:22:18,407 - INFO: | epoch  28 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.51 | loss-text 3.2277\n",
      "2022-04-09 14:22:34,687 - INFO: | epoch  28 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.79 | loss-text 3.2503\n",
      "2022-04-09 14:22:51,109 - INFO: | epoch  28 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 164.22 | loss-text 3.2888\n",
      "2022-04-09 14:23:07,620 - INFO: | epoch  28 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 165.10 | loss-text 3.2611\n",
      "2022-04-09 14:23:23,957 - INFO: | epoch  28 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.36 | loss-text 3.2765\n",
      "2022-04-09 14:23:40,371 - INFO: | epoch  28 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.12 | loss-text 3.2814\n",
      "2022-04-09 14:23:56,755 - INFO: | epoch  28 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.84 | loss-text 3.2810\n",
      "2022-04-09 14:24:13,200 - INFO: | epoch  28 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.44 | loss-text 3.3078\n",
      "2022-04-09 14:24:29,749 - INFO: | epoch  28 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 165.49 | loss-text 3.3513\n",
      "2022-04-09 14:24:46,231 - INFO: | epoch  28 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.81 | loss-text 3.3270\n",
      "2022-04-09 14:25:02,674 - INFO: | epoch  28 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.42 | loss-text 3.2872\n",
      "2022-04-09 14:25:18,931 - INFO: | epoch  28 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 162.56 | loss-text 3.2582\n",
      "2022-04-09 14:25:35,420 - INFO: | epoch  28 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.88 | loss-text 3.2687\n",
      "2022-04-09 14:25:51,884 - INFO: | epoch  28 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.63 | loss-text 3.2855\n",
      "2022-04-09 14:26:08,276 - INFO: | epoch  28 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.91 | loss-text 3.3100\n",
      "2022-04-09 14:26:24,751 - INFO: | epoch  28 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.74 | loss-text 3.3115\n",
      "2022-04-09 14:26:41,145 - INFO: | epoch  28 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.93 | loss-text 3.2732\n",
      "2022-04-09 14:26:57,647 - INFO: | epoch  28 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 165.01 | loss-text 3.2574\n",
      "2022-04-09 14:27:14,152 - INFO: | epoch  28 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 165.05 | loss-text 3.3310\n",
      "2022-04-09 14:27:30,598 - INFO: | epoch  28 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.45 | loss-text 3.3007\n",
      "2022-04-09 14:27:47,039 - INFO: | epoch  28 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.40 | loss-text 3.2979\n",
      "2022-04-09 14:28:03,476 - INFO: | epoch  28 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.37 | loss-text 3.3041\n",
      "2022-04-09 14:28:20,013 - INFO: | epoch  28 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 165.37 | loss-text 3.3125\n",
      "2022-04-09 14:28:36,373 - INFO: | epoch  28 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.59 | loss-text 3.3299\n",
      "2022-04-09 14:28:52,890 - INFO: | epoch  28 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 165.16 | loss-text 3.3394\n",
      "2022-04-09 14:29:09,427 - INFO: | epoch  28 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 165.37 | loss-text 3.3059\n",
      "2022-04-09 14:29:25,917 - INFO: | epoch  28 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.89 | loss-text 3.3168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003943\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11521, 'reflen': 11160, 'guess': [11521, 10497, 9473, 8449], 'correct': [5571, 1809, 659, 210]}\n",
      "ratio: 1.0323476702508034\n",
      "Bleu_1: 0.484\n",
      "Bleu_2: 0.289\n",
      "Bleu_3: 0.180\n",
      "Bleu_4: 0.110\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.344\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.241\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.168\n",
      "2022-04-09 14:30:05,290 - INFO: eval_greddy SPIDEr: 0.1676\n",
      "loading annotations into memory...\n",
      "0:00:00.004136\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9517, 'reflen': 9985, 'guess': [9517, 8493, 7469, 6445], 'correct': [5014, 1717, 686, 226]}\n",
      "ratio: 0.9531296945417173\n",
      "Bleu_1: 0.502\n",
      "Bleu_2: 0.311\n",
      "Bleu_3: 0.204\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.342\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.278\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.186\n",
      "2022-04-09 14:30:34,504 - INFO: eval_beam_2 SPIDEr: 0.1861\n",
      "loading annotations into memory...\n",
      "0:00:00.004011\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8677, 'reflen': 9576, 'guess': [8677, 7653, 6629, 5605], 'correct': [4777, 1673, 683, 232]}\n",
      "ratio: 0.906119465329897\n",
      "Bleu_1: 0.496\n",
      "Bleu_2: 0.313\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.144\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.345\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.279\n",
      "computing SPICE score...\n",
      "SPICE: 0.091\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.185\n",
      "2022-04-09 14:31:07,197 - INFO: eval_beam_3 SPIDEr: 0.1854\n",
      "loading annotations into memory...\n",
      "0:00:00.004443\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8119, 'reflen': 9391, 'guess': [8119, 7095, 6071, 5047], 'correct': [4581, 1616, 683, 251]}\n",
      "ratio: 0.8645511660099174\n",
      "Bleu_1: 0.482\n",
      "Bleu_2: 0.307\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.346\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.284\n",
      "computing SPICE score...\n",
      "SPICE: 0.090\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.187\n",
      "2022-04-09 14:31:45,194 - INFO: eval_beam_4 SPIDEr: 0.1870\n",
      "2022-04-09 14:32:01,758 - INFO: | epoch  29 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.61 | loss-text 3.2153\n",
      "2022-04-09 14:32:17,926 - INFO: | epoch  29 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.68 | loss-text 3.2935\n",
      "2022-04-09 14:32:34,267 - INFO: | epoch  29 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 163.40 | loss-text 3.2394\n",
      "2022-04-09 14:32:50,582 - INFO: | epoch  29 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.14 | loss-text 3.2640\n",
      "2022-04-09 14:33:06,882 - INFO: | epoch  29 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.99 | loss-text 3.3115\n",
      "2022-04-09 14:33:23,263 - INFO: | epoch  29 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.80 | loss-text 3.3354\n",
      "2022-04-09 14:33:39,628 - INFO: | epoch  29 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.65 | loss-text 3.1989\n",
      "2022-04-09 14:33:55,957 - INFO: | epoch  29 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.28 | loss-text 3.2644\n",
      "2022-04-09 14:34:12,351 - INFO: | epoch  29 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.94 | loss-text 3.2393\n",
      "2022-04-09 14:34:28,815 - INFO: | epoch  29 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.63 | loss-text 3.2529\n",
      "2022-04-09 14:34:45,227 - INFO: | epoch  29 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.12 | loss-text 3.2747\n",
      "2022-04-09 14:35:01,657 - INFO: | epoch  29 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.28 | loss-text 3.2769\n",
      "2022-04-09 14:35:18,095 - INFO: | epoch  29 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.38 | loss-text 3.3272\n",
      "2022-04-09 14:35:34,598 - INFO: | epoch  29 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 165.02 | loss-text 3.2824\n",
      "2022-04-09 14:35:51,135 - INFO: | epoch  29 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 165.36 | loss-text 3.3068\n",
      "2022-04-09 14:36:07,611 - INFO: | epoch  29 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.75 | loss-text 3.2730\n",
      "2022-04-09 14:36:24,083 - INFO: | epoch  29 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.71 | loss-text 3.2478\n",
      "2022-04-09 14:36:40,414 - INFO: | epoch  29 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.31 | loss-text 3.2396\n",
      "2022-04-09 14:36:56,824 - INFO: | epoch  29 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.09 | loss-text 3.3024\n",
      "2022-04-09 14:37:13,335 - INFO: | epoch  29 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 165.11 | loss-text 3.3076\n",
      "2022-04-09 14:37:29,761 - INFO: | epoch  29 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.24 | loss-text 3.2787\n",
      "2022-04-09 14:37:46,189 - INFO: | epoch  29 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.28 | loss-text 3.3172\n",
      "2022-04-09 14:38:02,547 - INFO: | epoch  29 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.57 | loss-text 3.2763\n",
      "2022-04-09 14:38:18,982 - INFO: | epoch  29 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.35 | loss-text 3.3345\n",
      "2022-04-09 14:38:35,243 - INFO: | epoch  29 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 162.60 | loss-text 3.3393\n",
      "2022-04-09 14:38:51,560 - INFO: | epoch  29 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.16 | loss-text 3.3285\n",
      "2022-04-09 14:39:08,006 - INFO: | epoch  29 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.45 | loss-text 3.2770\n",
      "2022-04-09 14:39:24,403 - INFO: | epoch  29 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.96 | loss-text 3.3185\n",
      "2022-04-09 14:39:40,786 - INFO: | epoch  29 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.83 | loss-text 3.3165\n",
      "2022-04-09 14:39:57,177 - INFO: | epoch  29 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.90 | loss-text 3.3437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004043\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10469, 'reflen': 10493, 'guess': [10469, 9445, 8421, 7397], 'correct': [5380, 1700, 625, 198]}\n",
      "ratio: 0.9977127608881161\n",
      "Bleu_1: 0.513\n",
      "Bleu_2: 0.303\n",
      "Bleu_3: 0.190\n",
      "Bleu_4: 0.116\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.344\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.257\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.176\n",
      "2022-04-09 14:40:37,130 - INFO: eval_greddy SPIDEr: 0.1757\n",
      "loading annotations into memory...\n",
      "0:00:00.003908\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8735, 'reflen': 9559, 'guess': [8735, 7711, 6687, 5663], 'correct': [4811, 1695, 668, 217]}\n",
      "ratio: 0.9137985144888676\n",
      "Bleu_1: 0.501\n",
      "Bleu_2: 0.317\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.144\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.281\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.188\n",
      "2022-04-09 14:41:04,345 - INFO: eval_beam_2 SPIDEr: 0.1882\n",
      "loading annotations into memory...\n",
      "0:00:00.003972\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8384, 'reflen': 9402, 'guess': [8384, 7360, 6336, 5312], 'correct': [4705, 1696, 693, 246]}\n",
      "ratio: 0.8917251648584459\n",
      "Bleu_1: 0.497\n",
      "Bleu_2: 0.318\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.143\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.294\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.194\n",
      "2022-04-09 14:41:35,233 - INFO: eval_beam_3 SPIDEr: 0.1942\n",
      "loading annotations into memory...\n",
      "0:00:00.004193\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8014, 'reflen': 9332, 'guess': [8014, 6990, 5966, 4942], 'correct': [4493, 1637, 661, 235]}\n",
      "ratio: 0.8587655379338985\n",
      "Bleu_1: 0.476\n",
      "Bleu_2: 0.307\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.294\n",
      "computing SPICE score...\n",
      "SPICE: 0.091\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.192\n",
      "2022-04-09 14:42:06,957 - INFO: eval_beam_4 SPIDEr: 0.1925\n",
      "2022-04-09 14:42:23,423 - INFO: | epoch  30 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.61 | loss-text 3.1956\n",
      "2022-04-09 14:42:39,718 - INFO: | epoch  30 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.94 | loss-text 3.2888\n",
      "2022-04-09 14:42:56,006 - INFO: | epoch  30 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.87 | loss-text 3.2442\n",
      "2022-04-09 14:43:12,387 - INFO: | epoch  30 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.81 | loss-text 3.3306\n",
      "2022-04-09 14:43:28,789 - INFO: | epoch  30 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 164.01 | loss-text 3.2762\n",
      "2022-04-09 14:43:45,007 - INFO: | epoch  30 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.17 | loss-text 3.2261\n",
      "2022-04-09 14:44:01,285 - INFO: | epoch  30 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 162.77 | loss-text 3.2639\n",
      "2022-04-09 14:44:17,763 - INFO: | epoch  30 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.77 | loss-text 3.2769\n",
      "2022-04-09 14:44:34,357 - INFO: | epoch  30 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 165.94 | loss-text 3.2958\n",
      "2022-04-09 14:44:50,791 - INFO: | epoch  30 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.33 | loss-text 3.3141\n",
      "2022-04-09 14:45:07,099 - INFO: | epoch  30 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.07 | loss-text 3.2701\n",
      "2022-04-09 14:45:23,497 - INFO: | epoch  30 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.98 | loss-text 3.2780\n",
      "2022-04-09 14:45:39,997 - INFO: | epoch  30 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.99 | loss-text 3.2651\n",
      "2022-04-09 14:45:56,291 - INFO: | epoch  30 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 162.93 | loss-text 3.2645\n",
      "2022-04-09 14:46:12,775 - INFO: | epoch  30 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.83 | loss-text 3.2565\n",
      "2022-04-09 14:46:29,141 - INFO: | epoch  30 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.65 | loss-text 3.2791\n",
      "2022-04-09 14:46:45,715 - INFO: | epoch  30 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 165.74 | loss-text 3.2747\n",
      "2022-04-09 14:47:02,184 - INFO: | epoch  30 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.68 | loss-text 3.2863\n",
      "2022-04-09 14:47:18,698 - INFO: | epoch  30 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 165.13 | loss-text 3.2950\n",
      "2022-04-09 14:47:35,242 - INFO: | epoch  30 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 165.43 | loss-text 3.2467\n",
      "2022-04-09 14:47:51,820 - INFO: | epoch  30 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 165.78 | loss-text 3.2836\n",
      "2022-04-09 14:48:08,258 - INFO: | epoch  30 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.37 | loss-text 3.2435\n",
      "2022-04-09 14:48:24,755 - INFO: | epoch  30 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.96 | loss-text 3.2876\n",
      "2022-04-09 14:48:41,168 - INFO: | epoch  30 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.12 | loss-text 3.2814\n",
      "2022-04-09 14:48:57,541 - INFO: | epoch  30 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.73 | loss-text 3.2682\n",
      "2022-04-09 14:49:13,932 - INFO: | epoch  30 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.91 | loss-text 3.2730\n",
      "2022-04-09 14:49:30,383 - INFO: | epoch  30 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.51 | loss-text 3.2584\n",
      "2022-04-09 14:49:46,787 - INFO: | epoch  30 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.03 | loss-text 3.2245\n",
      "2022-04-09 14:50:03,197 - INFO: | epoch  30 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.09 | loss-text 3.2547\n",
      "2022-04-09 14:50:19,671 - INFO: | epoch  30 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.74 | loss-text 3.3043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003846\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10524, 'reflen': 10554, 'guess': [10524, 9500, 8476, 7452], 'correct': [5484, 1882, 717, 223]}\n",
      "ratio: 0.9971574758384502\n",
      "Bleu_1: 0.520\n",
      "Bleu_2: 0.320\n",
      "Bleu_3: 0.205\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.270\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.185\n",
      "2022-04-09 14:50:58,166 - INFO: eval_greddy SPIDEr: 0.1849\n",
      "loading annotations into memory...\n",
      "0:00:00.004248\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8921, 'reflen': 9583, 'guess': [8921, 7897, 6873, 5849], 'correct': [4960, 1798, 727, 241]}\n",
      "ratio: 0.9309193363246445\n",
      "Bleu_1: 0.516\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.353\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.295\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.197\n",
      "2022-04-09 14:51:25,512 - INFO: eval_beam_2 SPIDEr: 0.1967\n",
      "loading annotations into memory...\n",
      "0:00:00.003992\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8522, 'reflen': 9430, 'guess': [8522, 7498, 6474, 5450], 'correct': [4812, 1806, 770, 269]}\n",
      "ratio: 0.9037115588546231\n",
      "Bleu_1: 0.508\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.305\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.200\n",
      "2022-04-09 14:51:56,473 - INFO: eval_beam_3 SPIDEr: 0.2005\n",
      "loading annotations into memory...\n",
      "0:00:00.004030\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8140, 'reflen': 9359, 'guess': [8140, 7116, 6092, 5068], 'correct': [4578, 1690, 703, 224]}\n",
      "ratio: 0.8697510417778748\n",
      "Bleu_1: 0.484\n",
      "Bleu_2: 0.315\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.144\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.288\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.191\n",
      "2022-04-09 14:52:32,744 - INFO: eval_beam_4 SPIDEr: 0.1910\n",
      "2022-04-09 14:52:49,263 - INFO: | epoch  31 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.16 | loss-text 3.2516\n",
      "2022-04-09 14:53:05,538 - INFO: | epoch  31 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.74 | loss-text 3.2553\n",
      "2022-04-09 14:53:21,726 - INFO: | epoch  31 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 161.87 | loss-text 3.2715\n",
      "2022-04-09 14:53:38,119 - INFO: | epoch  31 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.92 | loss-text 3.2701\n",
      "2022-04-09 14:53:54,462 - INFO: | epoch  31 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.42 | loss-text 3.2487\n",
      "2022-04-09 14:54:10,838 - INFO: | epoch  31 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.75 | loss-text 3.2621\n",
      "2022-04-09 14:54:27,205 - INFO: | epoch  31 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.66 | loss-text 3.2632\n",
      "2022-04-09 14:54:43,634 - INFO: | epoch  31 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.29 | loss-text 3.2047\n",
      "2022-04-09 14:55:00,037 - INFO: | epoch  31 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.02 | loss-text 3.2214\n",
      "2022-04-09 14:55:16,358 - INFO: | epoch  31 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.21 | loss-text 3.2612\n",
      "2022-04-09 14:55:32,871 - INFO: | epoch  31 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 165.12 | loss-text 3.2771\n",
      "2022-04-09 14:55:49,194 - INFO: | epoch  31 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.23 | loss-text 3.2795\n",
      "2022-04-09 14:56:05,601 - INFO: | epoch  31 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.06 | loss-text 3.2511\n",
      "2022-04-09 14:56:22,054 - INFO: | epoch  31 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.52 | loss-text 3.2853\n",
      "2022-04-09 14:56:38,473 - INFO: | epoch  31 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.17 | loss-text 3.2759\n",
      "2022-04-09 14:56:55,024 - INFO: | epoch  31 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 165.51 | loss-text 3.2639\n",
      "2022-04-09 14:57:11,592 - INFO: | epoch  31 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 165.68 | loss-text 3.2783\n",
      "2022-04-09 14:57:28,047 - INFO: | epoch  31 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.54 | loss-text 3.2902\n",
      "2022-04-09 14:57:44,598 - INFO: | epoch  31 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 165.50 | loss-text 3.2852\n",
      "2022-04-09 14:58:01,083 - INFO: | epoch  31 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.84 | loss-text 3.2222\n",
      "2022-04-09 14:58:17,385 - INFO: | epoch  31 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 163.02 | loss-text 3.2642\n",
      "2022-04-09 14:58:33,754 - INFO: | epoch  31 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.68 | loss-text 3.2262\n",
      "2022-04-09 14:58:50,221 - INFO: | epoch  31 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.67 | loss-text 3.2549\n",
      "2022-04-09 14:59:06,579 - INFO: | epoch  31 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.57 | loss-text 3.2615\n",
      "2022-04-09 14:59:23,004 - INFO: | epoch  31 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.24 | loss-text 3.2864\n",
      "2022-04-09 14:59:39,361 - INFO: | epoch  31 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.55 | loss-text 3.2363\n",
      "2022-04-09 14:59:55,745 - INFO: | epoch  31 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.84 | loss-text 3.3140\n",
      "2022-04-09 15:00:12,240 - INFO: | epoch  31 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.94 | loss-text 3.2383\n",
      "2022-04-09 15:00:28,534 - INFO: | epoch  31 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 162.93 | loss-text 3.2559\n",
      "2022-04-09 15:00:45,054 - INFO: | epoch  31 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 165.20 | loss-text 3.2216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003958\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11237, 'reflen': 11024, 'guess': [11237, 10213, 9189, 8165], 'correct': [5626, 1861, 683, 216]}\n",
      "ratio: 1.0193214804062936\n",
      "Bleu_1: 0.501\n",
      "Bleu_2: 0.302\n",
      "Bleu_3: 0.189\n",
      "Bleu_4: 0.116\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.348\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.261\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.180\n",
      "2022-04-09 15:01:23,884 - INFO: eval_greddy SPIDEr: 0.1799\n",
      "loading annotations into memory...\n",
      "0:00:00.003948\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9545, 'reflen': 9982, 'guess': [9545, 8521, 7497, 6473], 'correct': [5189, 1852, 748, 236]}\n",
      "ratio: 0.9562211981565862\n",
      "Bleu_1: 0.519\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.293\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.197\n",
      "2022-04-09 15:01:52,499 - INFO: eval_beam_2 SPIDEr: 0.1974\n",
      "loading annotations into memory...\n",
      "0:00:00.003841\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8644, 'reflen': 9514, 'guess': [8644, 7620, 6596, 5572], 'correct': [4878, 1803, 759, 264]}\n",
      "ratio: 0.908555812486766\n",
      "Bleu_1: 0.510\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.307\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.203\n",
      "2022-04-09 15:02:24,571 - INFO: eval_beam_3 SPIDEr: 0.2032\n",
      "loading annotations into memory...\n",
      "0:00:00.003951\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8101, 'reflen': 9343, 'guess': [8101, 7077, 6053, 5029], 'correct': [4567, 1646, 679, 235]}\n",
      "ratio: 0.8670662528094972\n",
      "Bleu_1: 0.484\n",
      "Bleu_2: 0.311\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.145\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.348\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.286\n",
      "computing SPICE score...\n",
      "SPICE: 0.093\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.189\n",
      "2022-04-09 15:02:57,317 - INFO: eval_beam_4 SPIDEr: 0.1895\n",
      "2022-04-09 15:03:13,877 - INFO: | epoch  32 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.57 | loss-text 3.2352\n",
      "2022-04-09 15:03:30,180 - INFO: | epoch  32 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 163.02 | loss-text 3.2663\n",
      "2022-04-09 15:03:46,483 - INFO: | epoch  32 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 163.02 | loss-text 3.2470\n",
      "2022-04-09 15:04:02,807 - INFO: | epoch  32 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.23 | loss-text 3.2449\n",
      "2022-04-09 15:04:19,186 - INFO: | epoch  32 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.78 | loss-text 3.2174\n",
      "2022-04-09 15:04:35,541 - INFO: | epoch  32 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.55 | loss-text 3.2888\n",
      "2022-04-09 15:04:51,880 - INFO: | epoch  32 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.38 | loss-text 3.2298\n",
      "2022-04-09 15:05:08,301 - INFO: | epoch  32 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.21 | loss-text 3.2230\n",
      "2022-04-09 15:05:24,842 - INFO: | epoch  32 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 165.40 | loss-text 3.2205\n",
      "2022-04-09 15:05:41,377 - INFO: | epoch  32 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 165.35 | loss-text 3.2501\n",
      "2022-04-09 15:05:57,776 - INFO: | epoch  32 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.97 | loss-text 3.2581\n",
      "2022-04-09 15:06:14,203 - INFO: | epoch  32 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.27 | loss-text 3.2732\n",
      "2022-04-09 15:06:30,662 - INFO: | epoch  32 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.58 | loss-text 3.2434\n",
      "2022-04-09 15:06:46,998 - INFO: | epoch  32 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.35 | loss-text 3.2590\n",
      "2022-04-09 15:07:03,434 - INFO: | epoch  32 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.35 | loss-text 3.2358\n",
      "2022-04-09 15:07:19,862 - INFO: | epoch  32 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.27 | loss-text 3.2588\n",
      "2022-04-09 15:07:36,176 - INFO: | epoch  32 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.13 | loss-text 3.2835\n",
      "2022-04-09 15:07:52,496 - INFO: | epoch  32 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.19 | loss-text 3.2737\n",
      "2022-04-09 15:08:08,783 - INFO: | epoch  32 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 162.86 | loss-text 3.2345\n",
      "2022-04-09 15:08:25,177 - INFO: | epoch  32 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.94 | loss-text 3.2244\n",
      "2022-04-09 15:08:41,698 - INFO: | epoch  32 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 165.20 | loss-text 3.2384\n",
      "2022-04-09 15:08:58,205 - INFO: | epoch  32 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 165.06 | loss-text 3.2192\n",
      "2022-04-09 15:09:14,689 - INFO: | epoch  32 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.84 | loss-text 3.2646\n",
      "2022-04-09 15:09:31,047 - INFO: | epoch  32 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.57 | loss-text 3.2665\n",
      "2022-04-09 15:09:47,402 - INFO: | epoch  32 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.55 | loss-text 3.2341\n",
      "2022-04-09 15:10:03,766 - INFO: | epoch  32 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.63 | loss-text 3.2212\n",
      "2022-04-09 15:10:20,329 - INFO: | epoch  32 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 165.62 | loss-text 3.3428\n",
      "2022-04-09 15:10:36,845 - INFO: | epoch  32 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 165.15 | loss-text 3.2452\n",
      "2022-04-09 15:10:53,245 - INFO: | epoch  32 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.99 | loss-text 3.2833\n",
      "2022-04-09 15:11:09,573 - INFO: | epoch  32 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.28 | loss-text 3.2178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004139\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10402, 'reflen': 10525, 'guess': [10402, 9378, 8354, 7330], 'correct': [5285, 1761, 639, 191]}\n",
      "ratio: 0.9883135391923051\n",
      "Bleu_1: 0.502\n",
      "Bleu_2: 0.305\n",
      "Bleu_3: 0.192\n",
      "Bleu_4: 0.116\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.346\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.254\n",
      "computing SPICE score...\n",
      "SPICE: 0.093\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.173\n",
      "2022-04-09 15:11:50,480 - INFO: eval_greddy SPIDEr: 0.1733\n",
      "loading annotations into memory...\n",
      "0:00:00.004005\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9071, 'reflen': 9704, 'guess': [9071, 8047, 7023, 5999], 'correct': [4924, 1772, 703, 239]}\n",
      "ratio: 0.9347691673535722\n",
      "Bleu_1: 0.506\n",
      "Bleu_2: 0.322\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.144\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.292\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.193\n",
      "2022-04-09 15:12:19,283 - INFO: eval_beam_2 SPIDEr: 0.1932\n",
      "loading annotations into memory...\n",
      "0:00:00.004055\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8383, 'reflen': 9388, 'guess': [8383, 7359, 6335, 5311], 'correct': [4644, 1665, 667, 218]}\n",
      "ratio: 0.8929484448230833\n",
      "Bleu_1: 0.491\n",
      "Bleu_2: 0.314\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.283\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.188\n",
      "2022-04-09 15:12:50,406 - INFO: eval_beam_3 SPIDEr: 0.1877\n",
      "loading annotations into memory...\n",
      "0:00:00.003911\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8025, 'reflen': 9300, 'guess': [8025, 7001, 5977, 4953], 'correct': [4524, 1634, 637, 201]}\n",
      "ratio: 0.8629032258063588\n",
      "Bleu_1: 0.481\n",
      "Bleu_2: 0.309\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.140\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.283\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.188\n",
      "2022-04-09 15:13:26,467 - INFO: eval_beam_4 SPIDEr: 0.1877\n",
      "2022-04-09 15:13:42,975 - INFO: | epoch  33 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.04 | loss-text 3.2639\n",
      "2022-04-09 15:13:59,064 - INFO: | epoch  33 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 160.88 | loss-text 3.2429\n",
      "2022-04-09 15:14:15,402 - INFO: | epoch  33 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 163.37 | loss-text 3.2679\n",
      "2022-04-09 15:14:31,559 - INFO: | epoch  33 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 161.56 | loss-text 3.2200\n",
      "2022-04-09 15:14:48,002 - INFO: | epoch  33 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 164.43 | loss-text 3.2024\n",
      "2022-04-09 15:15:04,330 - INFO: | epoch  33 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.28 | loss-text 3.2733\n",
      "2022-04-09 15:15:20,652 - INFO: | epoch  33 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.21 | loss-text 3.2593\n",
      "2022-04-09 15:15:37,020 - INFO: | epoch  33 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.67 | loss-text 3.2753\n",
      "2022-04-09 15:15:53,455 - INFO: | epoch  33 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.34 | loss-text 3.2599\n",
      "2022-04-09 15:16:09,967 - INFO: | epoch  33 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 165.11 | loss-text 3.2569\n",
      "2022-04-09 15:16:26,283 - INFO: | epoch  33 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.15 | loss-text 3.2829\n",
      "2022-04-09 15:16:42,779 - INFO: | epoch  33 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.96 | loss-text 3.2784\n",
      "2022-04-09 15:16:59,153 - INFO: | epoch  33 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.73 | loss-text 3.2437\n",
      "2022-04-09 15:17:15,562 - INFO: | epoch  33 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.08 | loss-text 3.2822\n",
      "2022-04-09 15:17:32,025 - INFO: | epoch  33 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.62 | loss-text 3.2267\n",
      "2022-04-09 15:17:48,461 - INFO: | epoch  33 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.35 | loss-text 3.2873\n",
      "2022-04-09 15:18:04,972 - INFO: | epoch  33 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 165.11 | loss-text 3.2167\n",
      "2022-04-09 15:18:21,341 - INFO: | epoch  33 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.67 | loss-text 3.2404\n",
      "2022-04-09 15:18:37,778 - INFO: | epoch  33 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.36 | loss-text 3.2103\n",
      "2022-04-09 15:18:54,141 - INFO: | epoch  33 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.63 | loss-text 3.2157\n",
      "2022-04-09 15:19:10,689 - INFO: | epoch  33 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 165.47 | loss-text 3.2173\n",
      "2022-04-09 15:19:27,084 - INFO: | epoch  33 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.94 | loss-text 3.2357\n",
      "2022-04-09 15:19:43,601 - INFO: | epoch  33 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 165.16 | loss-text 3.2006\n",
      "2022-04-09 15:19:59,940 - INFO: | epoch  33 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.38 | loss-text 3.2246\n",
      "2022-04-09 15:20:16,387 - INFO: | epoch  33 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.46 | loss-text 3.2820\n",
      "2022-04-09 15:20:32,809 - INFO: | epoch  33 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.21 | loss-text 3.1999\n",
      "2022-04-09 15:20:49,181 - INFO: | epoch  33 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.71 | loss-text 3.2459\n",
      "2022-04-09 15:21:05,496 - INFO: | epoch  33 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.14 | loss-text 3.2455\n",
      "2022-04-09 15:21:21,973 - INFO: | epoch  33 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.76 | loss-text 3.2223\n",
      "2022-04-09 15:21:38,369 - INFO: | epoch  33 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.96 | loss-text 3.2426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003842\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10566, 'reflen': 10640, 'guess': [10566, 9542, 8518, 7494], 'correct': [5415, 1858, 688, 211]}\n",
      "ratio: 0.9930451127818615\n",
      "Bleu_1: 0.509\n",
      "Bleu_2: 0.314\n",
      "Bleu_3: 0.199\n",
      "Bleu_4: 0.122\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.265\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.182\n",
      "2022-04-09 15:22:17,568 - INFO: eval_greddy SPIDEr: 0.1819\n",
      "loading annotations into memory...\n",
      "0:00:00.004014\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8571, 'reflen': 9567, 'guess': [8571, 7547, 6523, 5499], 'correct': [4823, 1710, 675, 224]}\n",
      "ratio: 0.8958921291940111\n",
      "Bleu_1: 0.501\n",
      "Bleu_2: 0.318\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.284\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.189\n",
      "2022-04-09 15:22:45,938 - INFO: eval_beam_2 SPIDEr: 0.1894\n",
      "loading annotations into memory...\n",
      "0:00:00.003971\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8151, 'reflen': 9386, 'guess': [8151, 7127, 6103, 5079], 'correct': [4679, 1708, 682, 220]}\n",
      "ratio: 0.8684210526314864\n",
      "Bleu_1: 0.493\n",
      "Bleu_2: 0.319\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.300\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.197\n",
      "2022-04-09 15:23:17,017 - INFO: eval_beam_3 SPIDEr: 0.1973\n",
      "loading annotations into memory...\n",
      "0:00:00.004160\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7795, 'reflen': 9296, 'guess': [7795, 6771, 5747, 4723], 'correct': [4500, 1630, 658, 215]}\n",
      "ratio: 0.8385327022374313\n",
      "Bleu_1: 0.476\n",
      "Bleu_2: 0.307\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.144\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.348\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.295\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.195\n",
      "2022-04-09 15:23:52,180 - INFO: eval_beam_4 SPIDEr: 0.1947\n",
      "2022-04-09 15:24:08,611 - INFO: | epoch  34 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.28 | loss-text 3.2290\n",
      "2022-04-09 15:24:24,837 - INFO: | epoch  34 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.24 | loss-text 3.2441\n",
      "2022-04-09 15:24:41,082 - INFO: | epoch  34 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.44 | loss-text 3.2135\n",
      "2022-04-09 15:24:57,568 - INFO: | epoch  34 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 164.86 | loss-text 3.2434\n",
      "2022-04-09 15:25:13,962 - INFO: | epoch  34 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.93 | loss-text 3.1980\n",
      "2022-04-09 15:25:30,181 - INFO: | epoch  34 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.18 | loss-text 3.2749\n",
      "2022-04-09 15:25:46,682 - INFO: | epoch  34 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 165.01 | loss-text 3.2211\n",
      "2022-04-09 15:26:03,113 - INFO: | epoch  34 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.30 | loss-text 3.2712\n",
      "2022-04-09 15:26:19,512 - INFO: | epoch  34 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.98 | loss-text 3.2021\n",
      "2022-04-09 15:26:36,045 - INFO: | epoch  34 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 165.33 | loss-text 3.2179\n",
      "2022-04-09 15:26:52,536 - INFO: | epoch  34 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.90 | loss-text 3.1931\n",
      "2022-04-09 15:27:08,974 - INFO: | epoch  34 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.37 | loss-text 3.2114\n",
      "2022-04-09 15:27:25,345 - INFO: | epoch  34 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.71 | loss-text 3.2059\n",
      "2022-04-09 15:27:41,763 - INFO: | epoch  34 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.17 | loss-text 3.2145\n",
      "2022-04-09 15:27:58,159 - INFO: | epoch  34 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.95 | loss-text 3.2261\n",
      "2022-04-09 15:28:14,456 - INFO: | epoch  34 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 162.97 | loss-text 3.2591\n",
      "2022-04-09 15:28:30,927 - INFO: | epoch  34 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.70 | loss-text 3.2795\n",
      "2022-04-09 15:28:47,384 - INFO: | epoch  34 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.56 | loss-text 3.2673\n",
      "2022-04-09 15:29:03,859 - INFO: | epoch  34 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.74 | loss-text 3.2199\n",
      "2022-04-09 15:29:20,285 - INFO: | epoch  34 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.25 | loss-text 3.2612\n",
      "2022-04-09 15:29:36,793 - INFO: | epoch  34 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 165.08 | loss-text 3.1983\n",
      "2022-04-09 15:29:53,303 - INFO: | epoch  34 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 165.09 | loss-text 3.2316\n",
      "2022-04-09 15:30:09,647 - INFO: | epoch  34 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.44 | loss-text 3.1818\n",
      "2022-04-09 15:30:26,008 - INFO: | epoch  34 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.60 | loss-text 3.1692\n",
      "2022-04-09 15:30:42,415 - INFO: | epoch  34 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.07 | loss-text 3.2380\n",
      "2022-04-09 15:30:59,003 - INFO: | epoch  34 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 165.87 | loss-text 3.2336\n",
      "2022-04-09 15:31:15,393 - INFO: | epoch  34 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.89 | loss-text 3.2142\n",
      "2022-04-09 15:31:31,812 - INFO: | epoch  34 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.19 | loss-text 3.3012\n",
      "2022-04-09 15:31:48,325 - INFO: | epoch  34 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 165.12 | loss-text 3.2357\n",
      "2022-04-09 15:32:04,821 - INFO: | epoch  34 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.95 | loss-text 3.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003844\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10212, 'reflen': 10442, 'guess': [10212, 9188, 8164, 7140], 'correct': [5433, 1874, 722, 225]}\n",
      "ratio: 0.9779735682818447\n",
      "Bleu_1: 0.520\n",
      "Bleu_2: 0.322\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.290\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.196\n",
      "2022-04-09 15:32:44,031 - INFO: eval_greddy SPIDEr: 0.1956\n",
      "loading annotations into memory...\n",
      "0:00:00.004124\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8510, 'reflen': 9496, 'guess': [8510, 7486, 6462, 5438], 'correct': [4875, 1768, 721, 226]}\n",
      "ratio: 0.8961668070765695\n",
      "Bleu_1: 0.510\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.304\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.201\n",
      "2022-04-09 15:33:11,437 - INFO: eval_beam_2 SPIDEr: 0.2010\n",
      "loading annotations into memory...\n",
      "0:00:00.003934\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7926, 'reflen': 9348, 'guess': [7926, 6902, 5878, 4854], 'correct': [4625, 1686, 710, 248]}\n",
      "ratio: 0.8478818998715395\n",
      "Bleu_1: 0.488\n",
      "Bleu_2: 0.316\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.300\n",
      "computing SPICE score...\n",
      "SPICE: 0.093\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.197\n",
      "2022-04-09 15:33:42,344 - INFO: eval_beam_3 SPIDEr: 0.1967\n",
      "loading annotations into memory...\n",
      "0:00:00.004014\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7452, 'reflen': 9237, 'guess': [7452, 6428, 5404, 4380], 'correct': [4358, 1594, 673, 222]}\n",
      "ratio: 0.80675544007786\n",
      "Bleu_1: 0.460\n",
      "Bleu_2: 0.300\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.140\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.286\n",
      "computing SPICE score...\n",
      "SPICE: 0.089\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.187\n",
      "2022-04-09 15:34:14,085 - INFO: eval_beam_4 SPIDEr: 0.1874\n",
      "2022-04-09 15:34:30,534 - INFO: | epoch  35 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.46 | loss-text 3.1811\n",
      "2022-04-09 15:34:46,871 - INFO: | epoch  35 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 163.35 | loss-text 3.2056\n",
      "2022-04-09 15:35:03,130 - INFO: | epoch  35 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.58 | loss-text 3.2416\n",
      "2022-04-09 15:35:19,442 - INFO: | epoch  35 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.11 | loss-text 3.2029\n",
      "2022-04-09 15:35:35,834 - INFO: | epoch  35 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.92 | loss-text 3.2106\n",
      "2022-04-09 15:35:52,023 - INFO: | epoch  35 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 161.88 | loss-text 3.2113\n",
      "2022-04-09 15:36:08,220 - INFO: | epoch  35 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 161.97 | loss-text 3.2255\n",
      "2022-04-09 15:36:24,692 - INFO: | epoch  35 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.70 | loss-text 3.2207\n",
      "2022-04-09 15:36:41,199 - INFO: | epoch  35 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 165.07 | loss-text 3.2196\n",
      "2022-04-09 15:36:57,654 - INFO: | epoch  35 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.54 | loss-text 3.2363\n",
      "2022-04-09 15:37:14,163 - INFO: | epoch  35 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 165.09 | loss-text 3.2128\n",
      "2022-04-09 15:37:30,676 - INFO: | epoch  35 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 165.12 | loss-text 3.2219\n",
      "2022-04-09 15:37:47,119 - INFO: | epoch  35 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.43 | loss-text 3.1991\n",
      "2022-04-09 15:38:03,614 - INFO: | epoch  35 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.94 | loss-text 3.2072\n",
      "2022-04-09 15:38:20,110 - INFO: | epoch  35 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.95 | loss-text 3.2225\n",
      "2022-04-09 15:38:36,462 - INFO: | epoch  35 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.51 | loss-text 3.2410\n",
      "2022-04-09 15:38:52,742 - INFO: | epoch  35 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 162.79 | loss-text 3.2397\n",
      "2022-04-09 15:39:09,218 - INFO: | epoch  35 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.75 | loss-text 3.2358\n",
      "2022-04-09 15:39:25,539 - INFO: | epoch  35 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 163.20 | loss-text 3.1936\n",
      "2022-04-09 15:39:41,880 - INFO: | epoch  35 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.40 | loss-text 3.2337\n",
      "2022-04-09 15:39:58,331 - INFO: | epoch  35 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.51 | loss-text 3.2389\n",
      "2022-04-09 15:40:14,641 - INFO: | epoch  35 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.09 | loss-text 3.2599\n",
      "2022-04-09 15:40:30,983 - INFO: | epoch  35 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.42 | loss-text 3.2686\n",
      "2022-04-09 15:40:47,465 - INFO: | epoch  35 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.81 | loss-text 3.2340\n",
      "2022-04-09 15:41:03,820 - INFO: | epoch  35 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.54 | loss-text 3.2675\n",
      "2022-04-09 15:41:20,380 - INFO: | epoch  35 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 165.59 | loss-text 3.2126\n",
      "2022-04-09 15:41:36,885 - INFO: | epoch  35 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 165.04 | loss-text 3.2169\n",
      "2022-04-09 15:41:53,241 - INFO: | epoch  35 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.55 | loss-text 3.2159\n",
      "2022-04-09 15:42:09,601 - INFO: | epoch  35 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.59 | loss-text 3.2311\n",
      "2022-04-09 15:42:26,018 - INFO: | epoch  35 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.16 | loss-text 3.2431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003976\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10128, 'reflen': 10354, 'guess': [10128, 9104, 8080, 7056], 'correct': [5330, 1752, 665, 218]}\n",
      "ratio: 0.9781726868842014\n",
      "Bleu_1: 0.515\n",
      "Bleu_2: 0.311\n",
      "Bleu_3: 0.198\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.351\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.269\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.185\n",
      "2022-04-09 15:43:05,187 - INFO: eval_greddy SPIDEr: 0.1846\n",
      "loading annotations into memory...\n",
      "0:00:00.004043\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8501, 'reflen': 9492, 'guess': [8501, 7477, 6453, 5429], 'correct': [4841, 1722, 701, 253]}\n",
      "ratio: 0.8955962916138963\n",
      "Bleu_1: 0.507\n",
      "Bleu_2: 0.322\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.311\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.207\n",
      "2022-04-09 15:43:32,894 - INFO: eval_beam_2 SPIDEr: 0.2067\n",
      "loading annotations into memory...\n",
      "0:00:00.003942\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8045, 'reflen': 9323, 'guess': [8045, 7021, 5997, 4973], 'correct': [4607, 1616, 660, 235]}\n",
      "ratio: 0.8629196610532164\n",
      "Bleu_1: 0.489\n",
      "Bleu_2: 0.310\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.145\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.303\n",
      "computing SPICE score...\n",
      "SPICE: 0.097\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.200\n",
      "2022-04-09 15:44:04,459 - INFO: eval_beam_3 SPIDEr: 0.2000\n",
      "loading annotations into memory...\n",
      "0:00:00.004055\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7716, 'reflen': 9261, 'guess': [7716, 6692, 5668, 4644], 'correct': [4466, 1601, 667, 248]}\n",
      "ratio: 0.8331713637835186\n",
      "Bleu_1: 0.474\n",
      "Bleu_2: 0.305\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.144\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.306\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.201\n",
      "2022-04-09 15:44:40,139 - INFO: eval_beam_4 SPIDEr: 0.2012\n",
      "2022-04-09 15:44:56,630 - INFO: | epoch  36 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.88 | loss-text 3.1949\n",
      "2022-04-09 15:45:12,807 - INFO: | epoch  36 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.76 | loss-text 3.1934\n",
      "2022-04-09 15:45:29,154 - INFO: | epoch  36 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 163.46 | loss-text 3.2690\n",
      "2022-04-09 15:45:45,526 - INFO: | epoch  36 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.72 | loss-text 3.2164\n",
      "2022-04-09 15:46:01,790 - INFO: | epoch  36 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.63 | loss-text 3.1923\n",
      "2022-04-09 15:46:18,071 - INFO: | epoch  36 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 162.81 | loss-text 3.2094\n",
      "2022-04-09 15:46:34,447 - INFO: | epoch  36 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.75 | loss-text 3.2263\n",
      "2022-04-09 15:46:51,001 - INFO: | epoch  36 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 165.53 | loss-text 3.2015\n",
      "2022-04-09 15:47:07,510 - INFO: | epoch  36 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 165.08 | loss-text 3.2083\n",
      "2022-04-09 15:47:23,965 - INFO: | epoch  36 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.54 | loss-text 3.2070\n",
      "2022-04-09 15:47:40,439 - INFO: | epoch  36 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.74 | loss-text 3.1885\n",
      "2022-04-09 15:47:56,910 - INFO: | epoch  36 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.70 | loss-text 3.2446\n",
      "2022-04-09 15:48:13,243 - INFO: | epoch  36 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.33 | loss-text 3.1947\n",
      "2022-04-09 15:48:29,720 - INFO: | epoch  36 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.77 | loss-text 3.2324\n",
      "2022-04-09 15:48:46,160 - INFO: | epoch  36 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.37 | loss-text 3.1984\n",
      "2022-04-09 15:49:02,616 - INFO: | epoch  36 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.55 | loss-text 3.2066\n",
      "2022-04-09 15:49:18,993 - INFO: | epoch  36 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.77 | loss-text 3.2222\n",
      "2022-04-09 15:49:35,622 - INFO: | epoch  36 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 166.28 | loss-text 3.2269\n",
      "2022-04-09 15:49:52,030 - INFO: | epoch  36 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.07 | loss-text 3.1817\n",
      "2022-04-09 15:50:08,313 - INFO: | epoch  36 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 162.82 | loss-text 3.2436\n",
      "2022-04-09 15:50:24,727 - INFO: | epoch  36 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.13 | loss-text 3.2091\n",
      "2022-04-09 15:50:41,109 - INFO: | epoch  36 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.82 | loss-text 3.2135\n",
      "2022-04-09 15:50:57,667 - INFO: | epoch  36 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 165.57 | loss-text 3.1582\n",
      "2022-04-09 15:51:14,202 - INFO: | epoch  36 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 165.34 | loss-text 3.2378\n",
      "2022-04-09 15:51:30,478 - INFO: | epoch  36 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 162.75 | loss-text 3.1559\n",
      "2022-04-09 15:51:46,653 - INFO: | epoch  36 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 161.75 | loss-text 3.2706\n",
      "2022-04-09 15:52:03,054 - INFO: | epoch  36 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.00 | loss-text 3.2296\n",
      "2022-04-09 15:52:19,493 - INFO: | epoch  36 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.38 | loss-text 3.2154\n",
      "2022-04-09 15:52:35,818 - INFO: | epoch  36 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.24 | loss-text 3.2179\n",
      "2022-04-09 15:52:52,211 - INFO: | epoch  36 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.92 | loss-text 3.2354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003888\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10731, 'reflen': 10735, 'guess': [10731, 9707, 8683, 7659], 'correct': [5526, 1850, 711, 227]}\n",
      "ratio: 0.9996273870516069\n",
      "Bleu_1: 0.515\n",
      "Bleu_2: 0.313\n",
      "Bleu_3: 0.200\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.263\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.182\n",
      "2022-04-09 15:53:31,555 - INFO: eval_greddy SPIDEr: 0.1820\n",
      "loading annotations into memory...\n",
      "0:00:00.004060\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8945, 'reflen': 9665, 'guess': [8945, 7921, 6897, 5873], 'correct': [4926, 1707, 677, 219]}\n",
      "ratio: 0.9255043973097852\n",
      "Bleu_1: 0.508\n",
      "Bleu_2: 0.318\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.285\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.193\n",
      "2022-04-09 15:53:59,000 - INFO: eval_beam_2 SPIDEr: 0.1929\n",
      "loading annotations into memory...\n",
      "0:00:00.003952\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8469, 'reflen': 9482, 'guess': [8469, 7445, 6421, 5397], 'correct': [4781, 1706, 685, 237]}\n",
      "ratio: 0.89316599873435\n",
      "Bleu_1: 0.501\n",
      "Bleu_2: 0.319\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.149\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.291\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.193\n",
      "2022-04-09 15:54:31,498 - INFO: eval_beam_3 SPIDEr: 0.1934\n",
      "loading annotations into memory...\n",
      "0:00:00.004022\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8169, 'reflen': 9372, 'guess': [8169, 7145, 6121, 5097], 'correct': [4653, 1707, 703, 247]}\n",
      "ratio: 0.8716389244557328\n",
      "Bleu_1: 0.492\n",
      "Bleu_2: 0.318\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.300\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.197\n",
      "2022-04-09 15:55:04,664 - INFO: eval_beam_4 SPIDEr: 0.1972\n",
      "2022-04-09 15:55:21,249 - INFO: | epoch  37 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.82 | loss-text 3.1848\n",
      "2022-04-09 15:55:37,394 - INFO: | epoch  37 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.44 | loss-text 3.1451\n",
      "2022-04-09 15:55:53,549 - INFO: | epoch  37 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 161.55 | loss-text 3.2060\n",
      "2022-04-09 15:56:09,888 - INFO: | epoch  37 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.38 | loss-text 3.1932\n",
      "2022-04-09 15:56:26,313 - INFO: | epoch  37 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 164.24 | loss-text 3.2404\n",
      "2022-04-09 15:56:42,690 - INFO: | epoch  37 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.76 | loss-text 3.2001\n",
      "2022-04-09 15:56:58,994 - INFO: | epoch  37 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.03 | loss-text 3.1884\n",
      "2022-04-09 15:57:15,487 - INFO: | epoch  37 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.93 | loss-text 3.2006\n",
      "2022-04-09 15:57:31,861 - INFO: | epoch  37 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.74 | loss-text 3.1991\n",
      "2022-04-09 15:57:48,276 - INFO: | epoch  37 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.14 | loss-text 3.1399\n",
      "2022-04-09 15:58:04,836 - INFO: | epoch  37 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 165.59 | loss-text 3.2071\n",
      "2022-04-09 15:58:21,335 - INFO: | epoch  37 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.99 | loss-text 3.1604\n",
      "2022-04-09 15:58:37,809 - INFO: | epoch  37 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.73 | loss-text 3.1935\n",
      "2022-04-09 15:58:54,226 - INFO: | epoch  37 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.17 | loss-text 3.2383\n",
      "2022-04-09 15:59:10,607 - INFO: | epoch  37 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.79 | loss-text 3.1995\n",
      "2022-04-09 15:59:27,001 - INFO: | epoch  37 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.93 | loss-text 3.2562\n",
      "2022-04-09 15:59:43,510 - INFO: | epoch  37 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 165.08 | loss-text 3.1849\n",
      "2022-04-09 15:59:59,984 - INFO: | epoch  37 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.74 | loss-text 3.2148\n",
      "2022-04-09 16:00:16,506 - INFO: | epoch  37 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 165.21 | loss-text 3.1921\n",
      "2022-04-09 16:00:32,856 - INFO: | epoch  37 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.50 | loss-text 3.2129\n",
      "2022-04-09 16:00:49,275 - INFO: | epoch  37 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.19 | loss-text 3.2572\n",
      "2022-04-09 16:01:05,758 - INFO: | epoch  37 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.82 | loss-text 3.1714\n",
      "2022-04-09 16:01:22,188 - INFO: | epoch  37 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.29 | loss-text 3.2028\n",
      "2022-04-09 16:01:38,666 - INFO: | epoch  37 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.77 | loss-text 3.2195\n",
      "2022-04-09 16:01:55,208 - INFO: | epoch  37 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 165.41 | loss-text 3.2096\n",
      "2022-04-09 16:02:11,685 - INFO: | epoch  37 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.76 | loss-text 3.1991\n",
      "2022-04-09 16:02:28,122 - INFO: | epoch  37 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.36 | loss-text 3.2323\n",
      "2022-04-09 16:02:44,534 - INFO: | epoch  37 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.11 | loss-text 3.2291\n",
      "2022-04-09 16:03:00,991 - INFO: | epoch  37 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.57 | loss-text 3.2505\n",
      "2022-04-09 16:03:17,617 - INFO: | epoch  37 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 166.25 | loss-text 3.2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004037\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10346, 'reflen': 10420, 'guess': [10346, 9322, 8298, 7274], 'correct': [5288, 1711, 633, 203]}\n",
      "ratio: 0.9928982725526878\n",
      "Bleu_1: 0.507\n",
      "Bleu_2: 0.304\n",
      "Bleu_3: 0.191\n",
      "Bleu_4: 0.118\n",
      "computing METEOR score...\n",
      "METEOR: 0.149\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.348\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.270\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.185\n",
      "2022-04-09 16:03:58,856 - INFO: eval_greddy SPIDEr: 0.1847\n",
      "loading annotations into memory...\n",
      "0:00:00.003998\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8284, 'reflen': 9454, 'guess': [8284, 7260, 6236, 5212], 'correct': [4490, 1480, 581, 212]}\n",
      "ratio: 0.8762428601649168\n",
      "Bleu_1: 0.471\n",
      "Bleu_2: 0.289\n",
      "Bleu_3: 0.189\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.333\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.276\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.186\n",
      "2022-04-09 16:04:26,898 - INFO: eval_beam_2 SPIDEr: 0.1858\n",
      "loading annotations into memory...\n",
      "0:00:00.003961\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7869, 'reflen': 9338, 'guess': [7869, 6845, 5821, 4797], 'correct': [4314, 1449, 578, 207]}\n",
      "ratio: 0.842685799957074\n",
      "Bleu_1: 0.455\n",
      "Bleu_2: 0.283\n",
      "Bleu_3: 0.187\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.138\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.331\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.274\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.183\n",
      "2022-04-09 16:04:57,635 - INFO: eval_beam_3 SPIDEr: 0.1833\n",
      "loading annotations into memory...\n",
      "0:00:00.004181\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7493, 'reflen': 9285, 'guess': [7493, 6469, 5445, 4421], 'correct': [4119, 1398, 561, 201]}\n",
      "ratio: 0.8070005385028748\n",
      "Bleu_1: 0.433\n",
      "Bleu_2: 0.271\n",
      "Bleu_3: 0.181\n",
      "Bleu_4: 0.121\n",
      "computing METEOR score...\n",
      "METEOR: 0.134\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.327\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.269\n",
      "computing SPICE score...\n",
      "SPICE: 0.090\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.180\n",
      "2022-04-09 16:05:32,823 - INFO: eval_beam_4 SPIDEr: 0.1796\n",
      "2022-04-09 16:05:49,349 - INFO: | epoch  38 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.23 | loss-text 3.1559\n",
      "2022-04-09 16:06:05,565 - INFO: | epoch  38 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.14 | loss-text 3.1815\n",
      "2022-04-09 16:06:21,804 - INFO: | epoch  38 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.39 | loss-text 3.1967\n",
      "2022-04-09 16:06:38,141 - INFO: | epoch  38 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.36 | loss-text 3.1890\n",
      "2022-04-09 16:06:54,447 - INFO: | epoch  38 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.05 | loss-text 3.1732\n",
      "2022-04-09 16:07:10,840 - INFO: | epoch  38 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.93 | loss-text 3.2123\n",
      "2022-04-09 16:07:27,243 - INFO: | epoch  38 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 164.02 | loss-text 3.1122\n",
      "2022-04-09 16:07:43,601 - INFO: | epoch  38 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.58 | loss-text 3.2126\n",
      "2022-04-09 16:08:00,048 - INFO: | epoch  38 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.46 | loss-text 3.2473\n",
      "2022-04-09 16:08:16,573 - INFO: | epoch  38 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 165.25 | loss-text 3.1796\n",
      "2022-04-09 16:08:33,072 - INFO: | epoch  38 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.98 | loss-text 3.1986\n",
      "2022-04-09 16:08:49,449 - INFO: | epoch  38 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.76 | loss-text 3.2291\n",
      "2022-04-09 16:09:05,893 - INFO: | epoch  38 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.43 | loss-text 3.1705\n",
      "2022-04-09 16:09:22,242 - INFO: | epoch  38 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.47 | loss-text 3.2000\n",
      "2022-04-09 16:09:38,808 - INFO: | epoch  38 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 165.66 | loss-text 3.1778\n",
      "2022-04-09 16:09:55,271 - INFO: | epoch  38 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.62 | loss-text 3.2043\n",
      "2022-04-09 16:10:11,693 - INFO: | epoch  38 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.22 | loss-text 3.1892\n",
      "2022-04-09 16:10:28,189 - INFO: | epoch  38 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.95 | loss-text 3.1932\n",
      "2022-04-09 16:10:44,634 - INFO: | epoch  38 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.44 | loss-text 3.2292\n",
      "2022-04-09 16:11:01,048 - INFO: | epoch  38 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.13 | loss-text 3.1834\n",
      "2022-04-09 16:11:17,538 - INFO: | epoch  38 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.90 | loss-text 3.1712\n",
      "2022-04-09 16:11:33,995 - INFO: | epoch  38 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.56 | loss-text 3.2225\n",
      "2022-04-09 16:11:50,480 - INFO: | epoch  38 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.85 | loss-text 3.1845\n",
      "2022-04-09 16:12:06,933 - INFO: | epoch  38 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.52 | loss-text 3.2339\n",
      "2022-04-09 16:12:23,407 - INFO: | epoch  38 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.73 | loss-text 3.2016\n",
      "2022-04-09 16:12:39,765 - INFO: | epoch  38 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.57 | loss-text 3.2259\n",
      "2022-04-09 16:12:56,099 - INFO: | epoch  38 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.34 | loss-text 3.2154\n",
      "2022-04-09 16:13:12,493 - INFO: | epoch  38 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 163.93 | loss-text 3.1998\n",
      "2022-04-09 16:13:28,849 - INFO: | epoch  38 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.55 | loss-text 3.2140\n",
      "2022-04-09 16:13:45,234 - INFO: | epoch  38 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.84 | loss-text 3.2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003966\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10238, 'reflen': 10369, 'guess': [10238, 9214, 8190, 7166], 'correct': [5217, 1670, 617, 207]}\n",
      "ratio: 0.9873661876747046\n",
      "Bleu_1: 0.503\n",
      "Bleu_2: 0.300\n",
      "Bleu_3: 0.188\n",
      "Bleu_4: 0.118\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.343\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.258\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.179\n",
      "2022-04-09 16:14:24,690 - INFO: eval_greddy SPIDEr: 0.1785\n",
      "loading annotations into memory...\n",
      "0:00:00.003968\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8577, 'reflen': 9553, 'guess': [8577, 7553, 6529, 5505], 'correct': [4675, 1577, 622, 215]}\n",
      "ratio: 0.897833141421449\n",
      "Bleu_1: 0.486\n",
      "Bleu_2: 0.301\n",
      "Bleu_3: 0.198\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.143\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.340\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.273\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.183\n",
      "2022-04-09 16:14:52,313 - INFO: eval_beam_2 SPIDEr: 0.1833\n",
      "loading annotations into memory...\n",
      "0:00:00.004143\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8099, 'reflen': 9386, 'guess': [8099, 7075, 6051, 5027], 'correct': [4534, 1565, 633, 235]}\n",
      "ratio: 0.8628808864265008\n",
      "Bleu_1: 0.478\n",
      "Bleu_2: 0.300\n",
      "Bleu_3: 0.200\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.143\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.342\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.284\n",
      "computing SPICE score...\n",
      "SPICE: 0.091\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.188\n",
      "2022-04-09 16:15:23,745 - INFO: eval_beam_3 SPIDEr: 0.1879\n",
      "loading annotations into memory...\n",
      "0:00:00.003975\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7774, 'reflen': 9300, 'guess': [7774, 6750, 5726, 4702], 'correct': [4376, 1554, 650, 239]}\n",
      "ratio: 0.8359139784945337\n",
      "Bleu_1: 0.463\n",
      "Bleu_2: 0.296\n",
      "Bleu_3: 0.201\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.341\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.285\n",
      "computing SPICE score...\n",
      "SPICE: 0.090\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.188\n",
      "2022-04-09 16:15:55,573 - INFO: eval_beam_4 SPIDEr: 0.1876\n",
      "2022-04-09 16:16:12,171 - INFO: | epoch  39 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.95 | loss-text 3.1372\n",
      "2022-04-09 16:16:28,345 - INFO: | epoch  39 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.73 | loss-text 3.1635\n",
      "2022-04-09 16:16:44,714 - INFO: | epoch  39 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 163.69 | loss-text 3.1922\n",
      "2022-04-09 16:17:01,166 - INFO: | epoch  39 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 164.51 | loss-text 3.2306\n",
      "2022-04-09 16:17:17,501 - INFO: | epoch  39 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.34 | loss-text 3.1652\n",
      "2022-04-09 16:17:33,993 - INFO: | epoch  39 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 164.91 | loss-text 3.1596\n",
      "2022-04-09 16:17:50,321 - INFO: | epoch  39 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.27 | loss-text 3.1818\n",
      "2022-04-09 16:18:06,713 - INFO: | epoch  39 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.92 | loss-text 3.2051\n",
      "2022-04-09 16:18:23,128 - INFO: | epoch  39 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.14 | loss-text 3.2022\n",
      "2022-04-09 16:18:39,684 - INFO: | epoch  39 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 165.55 | loss-text 3.1884\n",
      "2022-04-09 16:18:56,199 - INFO: | epoch  39 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 165.15 | loss-text 3.1861\n",
      "2022-04-09 16:19:12,618 - INFO: | epoch  39 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.18 | loss-text 3.2356\n",
      "2022-04-09 16:19:28,921 - INFO: | epoch  39 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.02 | loss-text 3.2072\n",
      "2022-04-09 16:19:45,219 - INFO: | epoch  39 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 162.98 | loss-text 3.2164\n",
      "2022-04-09 16:20:01,654 - INFO: | epoch  39 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.33 | loss-text 3.1786\n",
      "2022-04-09 16:20:18,125 - INFO: | epoch  39 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.71 | loss-text 3.1662\n",
      "2022-04-09 16:20:34,592 - INFO: | epoch  39 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.66 | loss-text 3.1674\n",
      "2022-04-09 16:20:50,960 - INFO: | epoch  39 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.67 | loss-text 3.1686\n",
      "2022-04-09 16:21:07,461 - INFO: | epoch  39 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 165.00 | loss-text 3.2069\n",
      "2022-04-09 16:21:23,807 - INFO: | epoch  39 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.45 | loss-text 3.2256\n",
      "2022-04-09 16:21:40,295 - INFO: | epoch  39 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.87 | loss-text 3.2532\n",
      "2022-04-09 16:21:56,475 - INFO: | epoch  39 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 161.79 | loss-text 3.1772\n",
      "2022-04-09 16:22:12,920 - INFO: | epoch  39 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.44 | loss-text 3.1549\n",
      "2022-04-09 16:22:29,305 - INFO: | epoch  39 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.85 | loss-text 3.1754\n",
      "2022-04-09 16:22:45,737 - INFO: | epoch  39 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.31 | loss-text 3.1256\n",
      "2022-04-09 16:23:02,121 - INFO: | epoch  39 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.83 | loss-text 3.1867\n",
      "2022-04-09 16:23:18,577 - INFO: | epoch  39 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.56 | loss-text 3.1615\n",
      "2022-04-09 16:23:35,037 - INFO: | epoch  39 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.59 | loss-text 3.1911\n",
      "2022-04-09 16:23:51,428 - INFO: | epoch  39 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.90 | loss-text 3.2294\n",
      "2022-04-09 16:24:07,750 - INFO: | epoch  39 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.21 | loss-text 3.1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003962\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11120, 'reflen': 10922, 'guess': [11120, 10096, 9072, 8048], 'correct': [5753, 1960, 728, 238]}\n",
      "ratio: 1.0181285478849096\n",
      "Bleu_1: 0.517\n",
      "Bleu_2: 0.317\n",
      "Bleu_3: 0.200\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.283\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.192\n",
      "2022-04-09 16:24:46,816 - INFO: eval_greddy SPIDEr: 0.1921\n",
      "loading annotations into memory...\n",
      "0:00:00.004034\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9096, 'reflen': 9751, 'guess': [9096, 8072, 7048, 6024], 'correct': [5043, 1777, 717, 260]}\n",
      "ratio: 0.9328274023176153\n",
      "Bleu_1: 0.516\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.351\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.298\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.199\n",
      "2022-04-09 16:25:17,148 - INFO: eval_beam_2 SPIDEr: 0.1988\n",
      "loading annotations into memory...\n",
      "0:00:00.003927\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8518, 'reflen': 9502, 'guess': [8518, 7494, 6470, 5446], 'correct': [4825, 1735, 714, 262]}\n",
      "ratio: 0.896442854135877\n",
      "Bleu_1: 0.505\n",
      "Bleu_2: 0.323\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.308\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.204\n",
      "2022-04-09 16:25:50,709 - INFO: eval_beam_3 SPIDEr: 0.2036\n",
      "loading annotations into memory...\n",
      "0:00:00.003993\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8082, 'reflen': 9343, 'guess': [8082, 7058, 6034, 5010], 'correct': [4617, 1691, 689, 261]}\n",
      "ratio: 0.8650326447606909\n",
      "Bleu_1: 0.489\n",
      "Bleu_2: 0.317\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.308\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.202\n",
      "2022-04-09 16:26:27,279 - INFO: eval_beam_4 SPIDEr: 0.2021\n",
      "2022-04-09 16:26:43,709 - INFO: | epoch  40 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.27 | loss-text 3.1432\n",
      "2022-04-09 16:26:59,935 - INFO: | epoch  40 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.25 | loss-text 3.1937\n",
      "2022-04-09 16:27:16,218 - INFO: | epoch  40 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.83 | loss-text 3.1585\n",
      "2022-04-09 16:27:32,634 - INFO: | epoch  40 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 164.15 | loss-text 3.2108\n",
      "2022-04-09 16:27:48,836 - INFO: | epoch  40 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.01 | loss-text 3.1652\n",
      "2022-04-09 16:28:05,226 - INFO: | epoch  40 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.89 | loss-text 3.2186\n",
      "2022-04-09 16:28:21,488 - INFO: | epoch  40 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 162.61 | loss-text 3.1467\n",
      "2022-04-09 16:28:37,878 - INFO: | epoch  40 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.90 | loss-text 3.1787\n",
      "2022-04-09 16:28:54,251 - INFO: | epoch  40 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.72 | loss-text 3.1837\n",
      "2022-04-09 16:29:10,603 - INFO: | epoch  40 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.51 | loss-text 3.2169\n",
      "2022-04-09 16:29:27,064 - INFO: | epoch  40 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.61 | loss-text 3.2174\n",
      "2022-04-09 16:29:43,511 - INFO: | epoch  40 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.47 | loss-text 3.1873\n",
      "2022-04-09 16:29:59,803 - INFO: | epoch  40 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 162.90 | loss-text 3.1546\n",
      "2022-04-09 16:30:16,258 - INFO: | epoch  40 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.55 | loss-text 3.1828\n",
      "2022-04-09 16:30:32,677 - INFO: | epoch  40 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.18 | loss-text 3.1735\n",
      "2022-04-09 16:30:49,117 - INFO: | epoch  40 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.40 | loss-text 3.2221\n",
      "2022-04-09 16:31:05,645 - INFO: | epoch  40 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 165.27 | loss-text 3.1619\n",
      "2022-04-09 16:31:22,056 - INFO: | epoch  40 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.11 | loss-text 3.1961\n",
      "2022-04-09 16:31:38,541 - INFO: | epoch  40 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.84 | loss-text 3.1807\n",
      "2022-04-09 16:31:55,006 - INFO: | epoch  40 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.64 | loss-text 3.1657\n",
      "2022-04-09 16:32:11,384 - INFO: | epoch  40 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 163.78 | loss-text 3.1390\n",
      "2022-04-09 16:32:27,705 - INFO: | epoch  40 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.20 | loss-text 3.2121\n",
      "2022-04-09 16:32:44,242 - INFO: | epoch  40 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 165.37 | loss-text 3.1877\n",
      "2022-04-09 16:33:00,724 - INFO: | epoch  40 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.81 | loss-text 3.1872\n",
      "2022-04-09 16:33:17,157 - INFO: | epoch  40 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.33 | loss-text 3.1801\n",
      "2022-04-09 16:33:33,572 - INFO: | epoch  40 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.14 | loss-text 3.1872\n",
      "2022-04-09 16:33:49,949 - INFO: | epoch  40 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.76 | loss-text 3.1739\n",
      "2022-04-09 16:34:06,516 - INFO: | epoch  40 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 165.67 | loss-text 3.1549\n",
      "2022-04-09 16:34:22,848 - INFO: | epoch  40 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.31 | loss-text 3.1431\n",
      "2022-04-09 16:34:39,370 - INFO: | epoch  40 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 165.21 | loss-text 3.1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003901\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10359, 'reflen': 10516, 'guess': [10359, 9335, 8311, 7287], 'correct': [5404, 1824, 667, 204]}\n",
      "ratio: 0.9850703689614886\n",
      "Bleu_1: 0.514\n",
      "Bleu_2: 0.314\n",
      "Bleu_3: 0.198\n",
      "Bleu_4: 0.121\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.273\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.188\n",
      "2022-04-09 16:35:17,247 - INFO: eval_greddy SPIDEr: 0.1878\n",
      "loading annotations into memory...\n",
      "0:00:00.003994\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8966, 'reflen': 9774, 'guess': [8966, 7942, 6918, 5894], 'correct': [5015, 1749, 689, 216]}\n",
      "ratio: 0.9173316963371273\n",
      "Bleu_1: 0.511\n",
      "Bleu_2: 0.321\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.351\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.295\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.199\n",
      "2022-04-09 16:35:44,199 - INFO: eval_beam_2 SPIDEr: 0.1987\n",
      "loading annotations into memory...\n",
      "0:00:00.004096\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8406, 'reflen': 9542, 'guess': [8406, 7382, 6358, 5334], 'correct': [4816, 1740, 699, 233]}\n",
      "ratio: 0.8809473904840829\n",
      "Bleu_1: 0.501\n",
      "Bleu_2: 0.321\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.300\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.200\n",
      "2022-04-09 16:36:15,201 - INFO: eval_beam_3 SPIDEr: 0.1997\n",
      "loading annotations into memory...\n",
      "0:00:00.003965\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7654, 'reflen': 9340, 'guess': [7654, 6630, 5606, 4582], 'correct': [4458, 1638, 676, 234]}\n",
      "ratio: 0.8194860813703619\n",
      "Bleu_1: 0.467\n",
      "Bleu_2: 0.304\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.143\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.348\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.294\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.195\n",
      "2022-04-09 16:36:50,758 - INFO: eval_beam_4 SPIDEr: 0.1948\n",
      "2022-04-09 16:37:07,399 - INFO: | epoch  41 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 166.38 | loss-text 3.1440\n",
      "2022-04-09 16:37:23,672 - INFO: | epoch  41 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.72 | loss-text 3.0687\n",
      "2022-04-09 16:37:39,960 - INFO: | epoch  41 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.87 | loss-text 3.1809\n",
      "2022-04-09 16:37:56,347 - INFO: | epoch  41 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.86 | loss-text 3.1412\n",
      "2022-04-09 16:38:12,752 - INFO: | epoch  41 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 164.04 | loss-text 3.1289\n",
      "2022-04-09 16:38:29,138 - INFO: | epoch  41 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.85 | loss-text 3.1527\n",
      "2022-04-09 16:38:45,551 - INFO: | epoch  41 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 164.12 | loss-text 3.1310\n",
      "2022-04-09 16:39:01,898 - INFO: | epoch  41 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.46 | loss-text 3.1880\n",
      "2022-04-09 16:39:18,421 - INFO: | epoch  41 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 165.23 | loss-text 3.1834\n",
      "2022-04-09 16:39:34,755 - INFO: | epoch  41 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.33 | loss-text 3.1652\n",
      "2022-04-09 16:39:51,209 - INFO: | epoch  41 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.53 | loss-text 3.1509\n",
      "2022-04-09 16:40:07,759 - INFO: | epoch  41 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 165.50 | loss-text 3.1763\n",
      "2022-04-09 16:40:24,244 - INFO: | epoch  41 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.84 | loss-text 3.1715\n",
      "2022-04-09 16:40:40,639 - INFO: | epoch  41 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.94 | loss-text 3.1864\n",
      "2022-04-09 16:40:57,119 - INFO: | epoch  41 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.79 | loss-text 3.1638\n",
      "2022-04-09 16:41:13,448 - INFO: | epoch  41 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.28 | loss-text 3.1593\n",
      "2022-04-09 16:41:29,958 - INFO: | epoch  41 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 165.10 | loss-text 3.1508\n",
      "2022-04-09 16:41:46,412 - INFO: | epoch  41 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.53 | loss-text 3.2209\n",
      "2022-04-09 16:42:02,823 - INFO: | epoch  41 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.10 | loss-text 3.1424\n",
      "2022-04-09 16:42:19,174 - INFO: | epoch  41 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.51 | loss-text 3.2036\n",
      "2022-04-09 16:42:35,675 - INFO: | epoch  41 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 165.00 | loss-text 3.1287\n",
      "2022-04-09 16:42:52,124 - INFO: | epoch  41 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.48 | loss-text 3.1947\n",
      "2022-04-09 16:43:08,548 - INFO: | epoch  41 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.23 | loss-text 3.1970\n",
      "2022-04-09 16:43:24,897 - INFO: | epoch  41 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.49 | loss-text 3.1777\n",
      "2022-04-09 16:43:41,325 - INFO: | epoch  41 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.26 | loss-text 3.1683\n",
      "2022-04-09 16:43:57,610 - INFO: | epoch  41 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 162.85 | loss-text 3.1534\n",
      "2022-04-09 16:44:13,943 - INFO: | epoch  41 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.33 | loss-text 3.2151\n",
      "2022-04-09 16:44:30,238 - INFO: | epoch  41 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 162.94 | loss-text 3.1779\n",
      "2022-04-09 16:44:46,735 - INFO: | epoch  41 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.96 | loss-text 3.1533\n",
      "2022-04-09 16:45:03,233 - INFO: | epoch  41 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.98 | loss-text 3.1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004017\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10395, 'reflen': 10519, 'guess': [10395, 9371, 8347, 7323], 'correct': [5457, 1826, 665, 204]}\n",
      "ratio: 0.9882118072059142\n",
      "Bleu_1: 0.519\n",
      "Bleu_2: 0.316\n",
      "Bleu_3: 0.199\n",
      "Bleu_4: 0.121\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.281\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.191\n",
      "2022-04-09 16:45:42,791 - INFO: eval_greddy SPIDEr: 0.1910\n",
      "loading annotations into memory...\n",
      "0:00:00.004498\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9035, 'reflen': 9745, 'guess': [9035, 8011, 6987, 5963], 'correct': [5023, 1750, 691, 226]}\n",
      "ratio: 0.9271421241661439\n",
      "Bleu_1: 0.514\n",
      "Bleu_2: 0.322\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.301\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.201\n",
      "2022-04-09 16:46:10,109 - INFO: eval_beam_2 SPIDEr: 0.2007\n",
      "loading annotations into memory...\n",
      "0:00:00.003976\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8412, 'reflen': 9473, 'guess': [8412, 7388, 6364, 5340], 'correct': [4776, 1720, 700, 233]}\n",
      "ratio: 0.8879974664835967\n",
      "Bleu_1: 0.500\n",
      "Bleu_2: 0.320\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.149\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.314\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.206\n",
      "2022-04-09 16:46:41,032 - INFO: eval_beam_3 SPIDEr: 0.2062\n",
      "loading annotations into memory...\n",
      "0:00:00.004009\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8057, 'reflen': 9371, 'guess': [8057, 7033, 6009, 4985], 'correct': [4607, 1674, 685, 219]}\n",
      "ratio: 0.8597801728736677\n",
      "Bleu_1: 0.486\n",
      "Bleu_2: 0.313\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.310\n",
      "computing SPICE score...\n",
      "SPICE: 0.097\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.204\n",
      "2022-04-09 16:47:16,582 - INFO: eval_beam_4 SPIDEr: 0.2037\n",
      "2022-04-09 16:47:33,154 - INFO: | epoch  42 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.69 | loss-text 3.1503\n",
      "2022-04-09 16:47:49,463 - INFO: | epoch  42 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 163.08 | loss-text 3.1243\n",
      "2022-04-09 16:48:05,829 - INFO: | epoch  42 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 163.65 | loss-text 3.1489\n",
      "2022-04-09 16:48:22,175 - INFO: | epoch  42 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.45 | loss-text 3.1799\n",
      "2022-04-09 16:48:38,556 - INFO: | epoch  42 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.80 | loss-text 3.2045\n",
      "2022-04-09 16:48:54,923 - INFO: | epoch  42 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.67 | loss-text 3.1301\n",
      "2022-04-09 16:49:11,306 - INFO: | epoch  42 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.82 | loss-text 3.1170\n",
      "2022-04-09 16:49:27,689 - INFO: | epoch  42 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.82 | loss-text 3.1472\n",
      "2022-04-09 16:49:44,095 - INFO: | epoch  42 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.05 | loss-text 3.1368\n",
      "2022-04-09 16:50:00,493 - INFO: | epoch  42 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 163.97 | loss-text 3.1694\n",
      "2022-04-09 16:50:16,925 - INFO: | epoch  42 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.31 | loss-text 3.1727\n",
      "2022-04-09 16:50:33,277 - INFO: | epoch  42 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.52 | loss-text 3.1297\n",
      "2022-04-09 16:50:49,783 - INFO: | epoch  42 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 165.05 | loss-text 3.1959\n",
      "2022-04-09 16:51:06,128 - INFO: | epoch  42 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 163.45 | loss-text 3.1893\n",
      "2022-04-09 16:51:22,645 - INFO: | epoch  42 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 165.16 | loss-text 3.2055\n",
      "2022-04-09 16:51:39,040 - INFO: | epoch  42 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 163.94 | loss-text 3.1740\n",
      "2022-04-09 16:51:55,487 - INFO: | epoch  42 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 164.47 | loss-text 3.1862\n",
      "2022-04-09 16:52:11,766 - INFO: | epoch  42 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 162.78 | loss-text 3.1450\n",
      "2022-04-09 16:52:28,220 - INFO: | epoch  42 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.54 | loss-text 3.1766\n",
      "2022-04-09 16:52:44,610 - INFO: | epoch  42 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.89 | loss-text 3.1479\n",
      "2022-04-09 16:53:01,037 - INFO: | epoch  42 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.26 | loss-text 3.1564\n",
      "2022-04-09 16:53:17,430 - INFO: | epoch  42 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.92 | loss-text 3.1527\n",
      "2022-04-09 16:53:34,045 - INFO: | epoch  42 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 166.14 | loss-text 3.2050\n",
      "2022-04-09 16:53:50,616 - INFO: | epoch  42 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 165.71 | loss-text 3.1432\n",
      "2022-04-09 16:54:07,216 - INFO: | epoch  42 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 166.00 | loss-text 3.2087\n",
      "2022-04-09 16:54:23,735 - INFO: | epoch  42 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 165.18 | loss-text 3.1726\n",
      "2022-04-09 16:54:40,033 - INFO: | epoch  42 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 162.98 | loss-text 3.1445\n",
      "2022-04-09 16:54:56,517 - INFO: | epoch  42 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.83 | loss-text 3.1557\n",
      "2022-04-09 16:55:12,975 - INFO: | epoch  42 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.57 | loss-text 3.1330\n",
      "2022-04-09 16:55:29,292 - INFO: | epoch  42 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.16 | loss-text 3.1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003935\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10741, 'reflen': 10646, 'guess': [10741, 9717, 8693, 7669], 'correct': [5578, 1867, 665, 196]}\n",
      "ratio: 1.0089235393574103\n",
      "Bleu_1: 0.519\n",
      "Bleu_2: 0.316\n",
      "Bleu_3: 0.197\n",
      "Bleu_4: 0.118\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.277\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.190\n",
      "2022-04-09 16:56:08,526 - INFO: eval_greddy SPIDEr: 0.1896\n",
      "loading annotations into memory...\n",
      "0:00:00.004037\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9134, 'reflen': 9779, 'guess': [9134, 8110, 7086, 6062], 'correct': [5090, 1835, 723, 231]}\n",
      "ratio: 0.9340423356170432\n",
      "Bleu_1: 0.519\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.305\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.202\n",
      "2022-04-09 16:56:37,641 - INFO: eval_beam_2 SPIDEr: 0.2025\n",
      "loading annotations into memory...\n",
      "0:00:00.004047\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8517, 'reflen': 9522, 'guess': [8517, 7493, 6469, 5445], 'correct': [4818, 1726, 682, 218]}\n",
      "ratio: 0.8944549464397296\n",
      "Bleu_1: 0.503\n",
      "Bleu_2: 0.321\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.296\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.197\n",
      "2022-04-09 16:57:09,291 - INFO: eval_beam_3 SPIDEr: 0.1968\n",
      "loading annotations into memory...\n",
      "0:00:00.003869\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7891, 'reflen': 9362, 'guess': [7891, 6867, 5843, 4819], 'correct': [4559, 1668, 662, 221]}\n",
      "ratio: 0.8428754539627383\n",
      "Bleu_1: 0.479\n",
      "Bleu_2: 0.311\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.143\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.296\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.196\n",
      "2022-04-09 16:57:46,266 - INFO: eval_beam_4 SPIDEr: 0.1955\n",
      "2022-04-09 16:58:02,649 - INFO: | epoch  43 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 163.80 | loss-text 3.1668\n",
      "2022-04-09 16:58:18,776 - INFO: | epoch  43 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.26 | loss-text 3.1047\n",
      "2022-04-09 16:58:35,071 - INFO: | epoch  43 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.94 | loss-text 3.2027\n",
      "2022-04-09 16:58:51,361 - INFO: | epoch  43 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.89 | loss-text 3.1626\n",
      "2022-04-09 16:59:07,737 - INFO: | epoch  43 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.75 | loss-text 3.1472\n",
      "2022-04-09 16:59:24,152 - INFO: | epoch  43 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 164.14 | loss-text 3.2189\n",
      "2022-04-09 16:59:40,646 - INFO: | epoch  43 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 164.94 | loss-text 3.1139\n",
      "2022-04-09 16:59:57,157 - INFO: | epoch  43 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 165.10 | loss-text 3.1573\n",
      "2022-04-09 17:00:13,543 - INFO: | epoch  43 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.85 | loss-text 3.1542\n",
      "2022-04-09 17:00:29,989 - INFO: | epoch  43 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.45 | loss-text 3.1920\n",
      "2022-04-09 17:00:46,318 - INFO: | epoch  43 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 163.28 | loss-text 3.1504\n",
      "2022-04-09 17:01:02,762 - INFO: | epoch  43 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.43 | loss-text 3.1714\n",
      "2022-04-09 17:01:19,144 - INFO: | epoch  43 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.82 | loss-text 3.1920\n",
      "2022-04-09 17:01:35,618 - INFO: | epoch  43 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.73 | loss-text 3.1192\n",
      "2022-04-09 17:01:52,036 - INFO: | epoch  43 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.17 | loss-text 3.1949\n",
      "2022-04-09 17:02:08,253 - INFO: | epoch  43 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 162.16 | loss-text 3.1646\n",
      "2022-04-09 17:02:24,611 - INFO: | epoch  43 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.57 | loss-text 3.1214\n",
      "2022-04-09 17:02:41,029 - INFO: | epoch  43 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 164.17 | loss-text 3.1428\n",
      "2022-04-09 17:02:57,459 - INFO: | epoch  43 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.30 | loss-text 3.1582\n",
      "2022-04-09 17:03:13,889 - INFO: | epoch  43 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.29 | loss-text 3.1812\n",
      "2022-04-09 17:03:30,383 - INFO: | epoch  43 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.93 | loss-text 3.1116\n",
      "2022-04-09 17:03:46,924 - INFO: | epoch  43 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 165.40 | loss-text 3.1748\n",
      "2022-04-09 17:04:03,341 - INFO: | epoch  43 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.17 | loss-text 3.1799\n",
      "2022-04-09 17:04:19,726 - INFO: | epoch  43 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 163.84 | loss-text 3.1484\n",
      "2022-04-09 17:04:36,122 - INFO: | epoch  43 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.96 | loss-text 3.1120\n",
      "2022-04-09 17:04:52,471 - INFO: | epoch  43 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.48 | loss-text 3.1287\n",
      "2022-04-09 17:05:08,923 - INFO: | epoch  43 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.51 | loss-text 3.1729\n",
      "2022-04-09 17:05:25,401 - INFO: | epoch  43 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.77 | loss-text 3.1125\n",
      "2022-04-09 17:05:41,753 - INFO: | epoch  43 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.51 | loss-text 3.1386\n",
      "2022-04-09 17:05:58,294 - INFO: | epoch  43 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 165.41 | loss-text 3.2113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003925\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10899, 'reflen': 10797, 'guess': [10899, 9875, 8851, 7827], 'correct': [5617, 1831, 637, 188]}\n",
      "ratio: 1.0094470686300816\n",
      "Bleu_1: 0.515\n",
      "Bleu_2: 0.309\n",
      "Bleu_3: 0.190\n",
      "Bleu_4: 0.113\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.269\n",
      "computing SPICE score...\n",
      "SPICE: 0.097\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.183\n",
      "2022-04-09 17:06:37,654 - INFO: eval_greddy SPIDEr: 0.1826\n",
      "loading annotations into memory...\n",
      "0:00:00.004220\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9132, 'reflen': 9780, 'guess': [9132, 8108, 7084, 6060], 'correct': [5039, 1783, 703, 243]}\n",
      "ratio: 0.933742331288248\n",
      "Bleu_1: 0.514\n",
      "Bleu_2: 0.324\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.305\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.202\n",
      "2022-04-09 17:07:06,861 - INFO: eval_beam_2 SPIDEr: 0.2023\n",
      "loading annotations into memory...\n",
      "0:00:00.004084\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8619, 'reflen': 9531, 'guess': [8619, 7595, 6571, 5547], 'correct': [4803, 1705, 675, 225]}\n",
      "ratio: 0.9043122442554921\n",
      "Bleu_1: 0.501\n",
      "Bleu_2: 0.318\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.301\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.200\n",
      "2022-04-09 17:07:38,852 - INFO: eval_beam_3 SPIDEr: 0.2001\n",
      "loading annotations into memory...\n",
      "0:00:00.004152\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8176, 'reflen': 9363, 'guess': [8176, 7152, 6128, 5104], 'correct': [4593, 1628, 653, 218]}\n",
      "ratio: 0.8732243938907537\n",
      "Bleu_1: 0.486\n",
      "Bleu_2: 0.309\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.343\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.299\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.197\n",
      "2022-04-09 17:08:11,896 - INFO: eval_beam_4 SPIDEr: 0.1973\n",
      "2022-04-09 17:08:28,434 - INFO: | epoch  44 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.34 | loss-text 3.1698\n",
      "2022-04-09 17:08:44,657 - INFO: | epoch  44 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 162.22 | loss-text 3.1602\n",
      "2022-04-09 17:09:00,979 - INFO: | epoch  44 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 163.21 | loss-text 3.1306\n",
      "2022-04-09 17:09:17,213 - INFO: | epoch  44 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 162.33 | loss-text 3.1732\n",
      "2022-04-09 17:09:33,616 - INFO: | epoch  44 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 164.02 | loss-text 3.1243\n",
      "2022-04-09 17:09:49,956 - INFO: | epoch  44 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.39 | loss-text 3.1562\n",
      "2022-04-09 17:10:06,291 - INFO: | epoch  44 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.34 | loss-text 3.1349\n",
      "2022-04-09 17:10:22,678 - INFO: | epoch  44 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.87 | loss-text 3.1797\n",
      "2022-04-09 17:10:39,067 - INFO: | epoch  44 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.88 | loss-text 3.1516\n",
      "2022-04-09 17:10:55,602 - INFO: | epoch  44 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 165.34 | loss-text 3.1426\n",
      "2022-04-09 17:26:51,209 - INFO: | epoch  45 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.67 | loss-text 3.1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003887\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10942, 'reflen': 10819, 'guess': [10942, 9918, 8894, 7870], 'correct': [5603, 1874, 687, 217]}\n",
      "ratio: 1.0113688880671956\n",
      "Bleu_1: 0.512\n",
      "Bleu_2: 0.311\n",
      "Bleu_3: 0.196\n",
      "Bleu_4: 0.120\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.353\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.267\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.185\n",
      "2022-04-09 17:27:30,852 - INFO: eval_greddy SPIDEr: 0.1853\n",
      "loading annotations into memory...\n",
      "0:00:00.003961\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9207, 'reflen': 9810, 'guess': [9207, 8183, 7159, 6135], 'correct': [5127, 1802, 721, 255]}\n",
      "ratio: 0.9385321100916474\n",
      "Bleu_1: 0.522\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.307\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.204\n",
      "2022-04-09 17:28:01,023 - INFO: eval_beam_2 SPIDEr: 0.2036\n",
      "loading annotations into memory...\n",
      "0:00:00.003977\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8597, 'reflen': 9519, 'guess': [8597, 7573, 6549, 5525], 'correct': [4880, 1767, 720, 247]}\n",
      "ratio: 0.9031410862484606\n",
      "Bleu_1: 0.510\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.219\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.149\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.353\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.319\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.208\n",
      "2022-04-09 17:28:33,433 - INFO: eval_beam_3 SPIDEr: 0.2079\n",
      "loading annotations into memory...\n",
      "0:00:00.003909\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8111, 'reflen': 9386, 'guess': [8111, 7087, 6063, 5039], 'correct': [4603, 1670, 682, 220]}\n",
      "ratio: 0.864159386319959\n",
      "Bleu_1: 0.485\n",
      "Bleu_2: 0.312\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.145\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.302\n",
      "computing SPICE score...\n",
      "SPICE: 0.093\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.198\n",
      "2022-04-09 17:29:10,340 - INFO: eval_beam_4 SPIDEr: 0.1978\n",
      "2022-04-09 17:29:26,889 - INFO: | epoch  46 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 165.46 | loss-text 3.1039\n",
      "2022-04-09 17:29:43,023 - INFO: | epoch  46 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 161.33 | loss-text 3.0998\n",
      "2022-04-09 17:29:59,283 - INFO: | epoch  46 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.59 | loss-text 3.1257\n",
      "2022-04-09 17:30:15,603 - INFO: | epoch  46 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.20 | loss-text 3.1630\n",
      "2022-04-09 17:30:31,762 - INFO: | epoch  46 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 161.57 | loss-text 3.1130\n",
      "2022-04-09 17:30:48,113 - INFO: | epoch  46 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.50 | loss-text 3.1150\n",
      "2022-04-09 17:31:04,493 - INFO: | epoch  46 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 163.80 | loss-text 3.1490\n",
      "2022-04-09 17:31:20,826 - INFO: | epoch  46 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 163.33 | loss-text 3.1578\n",
      "2022-04-09 17:31:37,206 - INFO: | epoch  46 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.79 | loss-text 3.1778\n",
      "2022-04-09 17:31:53,609 - INFO: | epoch  46 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 164.01 | loss-text 3.1712\n",
      "2022-04-09 17:32:10,182 - INFO: | epoch  46 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 165.73 | loss-text 3.1399\n",
      "2022-04-09 17:32:26,666 - INFO: | epoch  46 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 164.84 | loss-text 3.1360\n",
      "2022-04-09 17:32:43,087 - INFO: | epoch  46 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 164.20 | loss-text 3.1138\n",
      "2022-04-09 17:32:59,544 - INFO: | epoch  46 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.56 | loss-text 3.1639\n",
      "2022-04-09 17:33:16,004 - INFO: | epoch  46 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 164.59 | loss-text 3.1516\n",
      "2022-04-09 17:33:32,435 - INFO: | epoch  46 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.30 | loss-text 3.0937\n",
      "2022-04-09 17:33:48,800 - INFO: | epoch  46 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.65 | loss-text 3.1210\n",
      "2022-04-09 17:34:05,302 - INFO: | epoch  46 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 165.01 | loss-text 3.1416\n",
      "2022-04-09 17:34:21,781 - INFO: | epoch  46 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.79 | loss-text 3.1202\n",
      "2022-04-09 17:34:38,195 - INFO: | epoch  46 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.13 | loss-text 3.1301\n",
      "2022-04-09 17:34:54,759 - INFO: | epoch  46 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 165.63 | loss-text 3.1328\n",
      "2022-04-09 17:35:11,291 - INFO: | epoch  46 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 165.31 | loss-text 3.1485\n",
      "2022-04-09 17:35:27,645 - INFO: | epoch  46 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 163.53 | loss-text 3.1567\n",
      "2022-04-09 17:35:44,055 - INFO: | epoch  46 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.09 | loss-text 3.1577\n",
      "2022-04-09 17:36:00,402 - INFO: | epoch  46 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.47 | loss-text 3.1436\n",
      "2022-04-09 17:36:16,792 - INFO: | epoch  46 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.88 | loss-text 3.1511\n",
      "2022-04-09 17:36:33,143 - INFO: | epoch  46 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 163.51 | loss-text 3.1144\n",
      "2022-04-09 17:36:49,561 - INFO: | epoch  46 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.18 | loss-text 3.1209\n",
      "2022-04-09 17:37:05,918 - INFO: | epoch  46 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 163.56 | loss-text 3.1077\n",
      "2022-04-09 17:37:22,306 - INFO: | epoch  46 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.88 | loss-text 3.1401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003926\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10659, 'reflen': 10626, 'guess': [10659, 9635, 8611, 7587], 'correct': [5643, 1968, 757, 243]}\n",
      "ratio: 1.0031055900620174\n",
      "Bleu_1: 0.529\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.287\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.195\n",
      "2022-04-09 17:38:03,194 - INFO: eval_greddy SPIDEr: 0.1947\n",
      "loading annotations into memory...\n",
      "0:00:00.003968\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9025, 'reflen': 9701, 'guess': [9025, 8001, 6977, 5953], 'correct': [5132, 1873, 769, 279]}\n",
      "ratio: 0.9303164622202937\n",
      "Bleu_1: 0.528\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.213\n",
      "2022-04-09 17:38:32,096 - INFO: eval_beam_2 SPIDEr: 0.2132\n",
      "loading annotations into memory...\n",
      "0:00:00.004024\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8542, 'reflen': 9480, 'guess': [8542, 7518, 6494, 5470], 'correct': [4953, 1835, 771, 287]}\n",
      "ratio: 0.90105485232058\n",
      "Bleu_1: 0.520\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.331\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2022-04-09 17:39:04,862 - INFO: eval_beam_3 SPIDEr: 0.2161\n",
      "loading annotations into memory...\n",
      "0:00:00.003893\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8039, 'reflen': 9369, 'guess': [8039, 7015, 5991, 4967], 'correct': [4784, 1774, 745, 264]}\n",
      "ratio: 0.858042480520775\n",
      "Bleu_1: 0.504\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.329\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2022-04-09 17:39:41,376 - INFO: eval_beam_4 SPIDEr: 0.2156\n",
      "2022-04-09 17:39:57,875 - INFO: | epoch  47 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 164.96 | loss-text 3.1276\n",
      "2022-04-09 17:40:13,851 - INFO: | epoch  47 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 159.74 | loss-text 3.1252\n",
      "2022-04-09 17:40:30,079 - INFO: | epoch  47 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.28 | loss-text 3.1228\n",
      "2022-04-09 17:40:46,404 - INFO: | epoch  47 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.24 | loss-text 3.1098\n",
      "2022-04-09 17:41:02,682 - INFO: | epoch  47 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 162.77 | loss-text 3.1234\n",
      "2022-04-09 17:41:19,027 - INFO: | epoch  47 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 163.45 | loss-text 3.1350\n",
      "2022-04-09 17:41:35,305 - INFO: | epoch  47 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 162.77 | loss-text 3.0807\n",
      "2022-04-09 17:41:51,732 - INFO: | epoch  47 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.26 | loss-text 3.1138\n",
      "2022-04-09 17:42:08,131 - INFO: | epoch  47 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 163.98 | loss-text 3.0915\n",
      "2022-04-09 17:42:24,689 - INFO: | epoch  47 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 165.57 | loss-text 3.1290\n",
      "2022-04-09 17:42:41,145 - INFO: | epoch  47 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.55 | loss-text 3.1188\n",
      "2022-04-09 17:42:57,677 - INFO: | epoch  47 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 165.32 | loss-text 3.0999\n",
      "2022-04-09 17:43:14,021 - INFO: | epoch  47 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 163.43 | loss-text 3.1316\n",
      "2022-04-09 17:43:30,493 - INFO: | epoch  47 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 164.72 | loss-text 3.1404\n",
      "2022-04-09 17:43:46,998 - INFO: | epoch  47 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 165.05 | loss-text 3.1481\n",
      "2022-04-09 17:44:03,462 - INFO: | epoch  47 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 164.64 | loss-text 3.1340\n",
      "2022-04-09 17:44:19,841 - INFO: | epoch  47 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 163.78 | loss-text 3.1031\n",
      "2022-04-09 17:44:36,170 - INFO: | epoch  47 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.28 | loss-text 3.1252\n",
      "2022-04-09 17:44:52,654 - INFO: | epoch  47 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 164.84 | loss-text 3.0956\n",
      "2022-04-09 17:45:09,036 - INFO: | epoch  47 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 163.82 | loss-text 3.1588\n",
      "2022-04-09 17:45:25,454 - INFO: | epoch  47 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.17 | loss-text 3.1621\n",
      "2022-04-09 17:45:41,959 - INFO: | epoch  47 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 165.04 | loss-text 3.0926\n",
      "2022-04-09 17:45:58,490 - INFO: | epoch  47 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 165.30 | loss-text 3.1233\n",
      "2022-04-09 17:46:14,962 - INFO: | epoch  47 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.71 | loss-text 3.1008\n",
      "2022-04-09 17:46:31,264 - INFO: | epoch  47 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.02 | loss-text 3.1384\n",
      "2022-04-09 17:46:47,838 - INFO: | epoch  47 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 165.72 | loss-text 3.1885\n",
      "2022-04-09 17:47:04,340 - INFO: | epoch  47 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 165.01 | loss-text 3.1323\n",
      "2022-04-09 17:47:20,805 - INFO: | epoch  47 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.64 | loss-text 3.1365\n",
      "2022-04-09 17:47:37,229 - INFO: | epoch  47 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.23 | loss-text 3.1479\n",
      "2022-04-09 17:47:53,589 - INFO: | epoch  47 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.60 | loss-text 3.1440\n",
      "2022-04-09 18:05:51,945 - INFO: | epoch  49 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 165.39 | loss-text 3.1486\n",
      "2022-04-09 18:06:08,212 - INFO: | epoch  49 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 162.66 | loss-text 3.1398\n",
      "2022-04-09 18:06:24,613 - INFO: | epoch  49 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 164.00 | loss-text 3.0987\n",
      "2022-04-09 18:06:41,087 - INFO: | epoch  49 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 164.74 | loss-text 3.1265\n",
      "2022-04-09 18:06:57,527 - INFO: | epoch  49 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.39 | loss-text 3.0848\n",
      "2022-04-09 18:07:13,994 - INFO: | epoch  49 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.66 | loss-text 3.1290\n",
      "2022-04-09 18:07:30,473 - INFO: | epoch  49 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 164.78 | loss-text 3.1450\n",
      "2022-04-09 18:07:46,945 - INFO: | epoch  49 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 164.72 | loss-text 3.1423\n",
      "2022-04-09 18:08:03,390 - INFO: | epoch  49 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 164.45 | loss-text 3.0975\n",
      "2022-04-09 18:08:20,008 - INFO: | epoch  49 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 166.17 | loss-text 3.1268\n",
      "2022-04-09 18:08:36,481 - INFO: | epoch  49 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.73 | loss-text 3.1065\n",
      "2022-04-09 18:08:52,954 - INFO: | epoch  49 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 164.72 | loss-text 3.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003904\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10980, 'reflen': 10859, 'guess': [10980, 9956, 8932, 7908], 'correct': [5742, 2001, 757, 244]}\n",
      "ratio: 1.0111428308314752\n",
      "Bleu_1: 0.523\n",
      "Bleu_2: 0.324\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.286\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.195\n",
      "2022-04-09 18:09:30,385 - INFO: eval_greddy SPIDEr: 0.1949\n",
      "loading annotations into memory...\n",
      "0:00:00.003919\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9010, 'reflen': 9716, 'guess': [9010, 7986, 6962, 5938], 'correct': [5203, 1945, 798, 288]}\n",
      "ratio: 0.927336352408303\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.341\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.224\n",
      "2022-04-09 18:09:58,502 - INFO: eval_beam_2 SPIDEr: 0.2239\n",
      "loading annotations into memory...\n",
      "0:00:00.004056\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8513, 'reflen': 9524, 'guess': [8513, 7489, 6465, 5441], 'correct': [4996, 1878, 793, 294]}\n",
      "ratio: 0.893847123057445\n",
      "Bleu_1: 0.521\n",
      "Bleu_2: 0.341\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.339\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.221\n",
      "2022-04-09 18:10:29,937 - INFO: eval_beam_3 SPIDEr: 0.2213\n",
      "loading annotations into memory...\n",
      "0:00:00.003941\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7753, 'reflen': 9330, 'guess': [7753, 6729, 5705, 4681], 'correct': [4626, 1760, 757, 270]}\n",
      "ratio: 0.8309753483386033\n",
      "Bleu_1: 0.487\n",
      "Bleu_2: 0.322\n",
      "Bleu_3: 0.224\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.323\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.211\n",
      "2022-04-09 18:11:06,326 - INFO: eval_beam_4 SPIDEr: 0.2111\n",
      "2022-04-09 18:11:22,706 - INFO: | epoch  50 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 163.77 | loss-text 3.0780\n",
      "2022-04-09 18:11:39,017 - INFO: | epoch  50 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 163.10 | loss-text 3.0729\n",
      "2022-04-09 18:11:55,278 - INFO: | epoch  50 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 162.60 | loss-text 3.1121\n",
      "2022-04-09 18:12:11,579 - INFO: | epoch  50 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 163.00 | loss-text 3.0771\n",
      "2022-04-09 18:12:27,895 - INFO: | epoch  50 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 163.16 | loss-text 3.0900\n",
      "2022-04-09 18:12:44,373 - INFO: | epoch  50 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 164.77 | loss-text 3.1068\n",
      "2022-04-09 18:13:00,785 - INFO: | epoch  50 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 164.11 | loss-text 3.1370\n",
      "2022-04-09 18:13:17,232 - INFO: | epoch  50 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 164.46 | loss-text 3.1183\n",
      "2022-04-09 18:13:33,639 - INFO: | epoch  50 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 164.06 | loss-text 3.0700\n",
      "2022-04-09 18:13:49,933 - INFO: | epoch  50 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 162.93 | loss-text 3.1080\n",
      "2022-04-09 18:14:06,344 - INFO: | epoch  50 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 164.11 | loss-text 3.1234\n",
      "2022-04-09 18:14:22,732 - INFO: | epoch  50 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 163.87 | loss-text 3.1037\n",
      "2022-04-09 18:14:39,252 - INFO: | epoch  50 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 165.20 | loss-text 3.1086\n",
      "2022-04-09 18:14:55,538 - INFO: | epoch  50 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 162.85 | loss-text 3.1330\n",
      "2022-04-09 18:15:11,875 - INFO: | epoch  50 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 163.36 | loss-text 3.1643\n",
      "2022-04-09 18:15:28,411 - INFO: | epoch  50 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 165.35 | loss-text 3.1401\n",
      "2022-04-09 18:15:44,686 - INFO: | epoch  50 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 162.75 | loss-text 3.0583\n",
      "2022-04-09 18:16:01,047 - INFO: | epoch  50 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 163.60 | loss-text 3.1096\n",
      "2022-04-09 18:16:17,573 - INFO: | epoch  50 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 165.25 | loss-text 3.1153\n",
      "2022-04-09 18:16:34,033 - INFO: | epoch  50 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 164.59 | loss-text 3.1150\n",
      "2022-04-09 18:16:50,549 - INFO: | epoch  50 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 165.16 | loss-text 3.0954\n",
      "2022-04-09 18:17:06,890 - INFO: | epoch  50 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 163.40 | loss-text 3.1132\n",
      "2022-04-09 18:17:23,358 - INFO: | epoch  50 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 164.67 | loss-text 3.1459\n",
      "2022-04-09 18:17:39,767 - INFO: | epoch  50 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 164.08 | loss-text 3.1290\n",
      "2022-04-09 18:17:56,131 - INFO: | epoch  50 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 163.63 | loss-text 3.0926\n",
      "2022-04-09 18:18:12,511 - INFO: | epoch  50 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 163.79 | loss-text 3.1107\n",
      "2022-04-09 18:18:29,046 - INFO: | epoch  50 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 165.35 | loss-text 3.1160\n",
      "2022-04-09 18:18:45,523 - INFO: | epoch  50 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 164.75 | loss-text 3.1402\n",
      "2022-04-09 18:19:02,022 - INFO: | epoch  50 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 164.99 | loss-text 3.0807\n",
      "2022-04-09 18:19:18,422 - INFO: | epoch  50 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 163.99 | loss-text 3.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004055\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10553, 'reflen': 10588, 'guess': [10553, 9529, 8505, 7481], 'correct': [5500, 1884, 698, 230]}\n",
      "ratio: 0.9966943709859277\n",
      "Bleu_1: 0.519\n",
      "Bleu_2: 0.320\n",
      "Bleu_3: 0.203\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.351\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.290\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.197\n",
      "2022-04-09 18:19:58,596 - INFO: eval_greddy SPIDEr: 0.1973\n",
      "loading annotations into memory...\n",
      "0:00:00.003951\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9060, 'reflen': 9721, 'guess': [9060, 8036, 7012, 5988], 'correct': [5147, 1843, 733, 250]}\n",
      "ratio: 0.9320028803620067\n",
      "Bleu_1: 0.528\n",
      "Bleu_2: 0.336\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2022-04-09 18:20:26,432 - INFO: eval_beam_2 SPIDEr: 0.2153\n",
      "loading annotations into memory...\n",
      "0:00:00.004053\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8609, 'reflen': 9509, 'guess': [8609, 7585, 6561, 5537], 'correct': [4959, 1838, 748, 259]}\n",
      "ratio: 0.9053528236406662\n",
      "Bleu_1: 0.519\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.333\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2022-04-09 18:20:58,571 - INFO: eval_beam_3 SPIDEr: 0.2172\n",
      "loading annotations into memory...\n",
      "0:00:00.004169\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8153, 'reflen': 9369, 'guess': [8153, 7129, 6105, 5081], 'correct': [4724, 1757, 727, 252]}\n",
      "ratio: 0.8702102679046995\n",
      "Bleu_1: 0.499\n",
      "Bleu_2: 0.326\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.149\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.211\n",
      "2022-04-09 18:21:35,697 - INFO: eval_beam_4 SPIDEr: 0.2114\n"
     ]
    }
   ],
   "source": [
    "#scratch 모델\n",
    "epoch = 1\n",
    "if hp.mode == 'train':\n",
    "    while epoch < hp.training_epochs + 1:\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        torch.save(model.state_dict(), '{log_dir}/{num_epoch}.pt'.format(log_dir=log_dir, num_epoch=epoch))\n",
    "        scheduler.step(epoch)\n",
    "        eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=2)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=3)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=4)\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbae9c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_emb): Embedding(4371, 192)\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=512, out_features=192, bias=True)\n",
       "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
       "  (encoder): Cnn10(\n",
       "    (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_block1): ConvBlock(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block2): ConvBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block3): ConvBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_block4): ConvBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (generator): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92893a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58110c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94cfc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9457c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949dd431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cefa21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78b6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a1cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3cc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc51859f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-23 18:40:55,771 - INFO: | epoch   1 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 1265.58 | loss-text 6.5403\n",
      "2022-02-23 18:42:27,550 - INFO: | epoch   1 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 917.78 | loss-text 5.6446\n",
      "2022-02-23 18:43:43,367 - INFO: | epoch   1 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 758.16 | loss-text 5.2348\n",
      "2022-02-23 18:44:47,889 - INFO: | epoch   1 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 645.21 | loss-text 5.1337\n",
      "2022-02-23 18:45:42,969 - INFO: | epoch   1 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 550.79 | loss-text 5.0125\n",
      "2022-02-23 18:46:26,145 - INFO: | epoch   1 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 431.73 | loss-text 4.9339\n",
      "2022-02-23 18:47:04,040 - INFO: | epoch   1 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 378.95 | loss-text 4.8790\n",
      "2022-02-23 18:47:36,368 - INFO: | epoch   1 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 323.26 | loss-text 4.6982\n",
      "2022-02-23 18:48:03,317 - INFO: | epoch   1 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 269.48 | loss-text 4.7313\n",
      "2022-02-23 18:48:28,095 - INFO: | epoch   1 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 247.77 | loss-text 4.6910\n",
      "2022-02-23 18:48:48,426 - INFO: | epoch   1 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 203.30 | loss-text 4.6127\n",
      "2022-02-23 18:49:06,884 - INFO: | epoch   1 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 184.57 | loss-text 4.6050\n",
      "2022-02-23 18:49:23,386 - INFO: | epoch   1 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 165.01 | loss-text 4.5450\n",
      "2022-02-23 18:49:37,625 - INFO: | epoch   1 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 142.38 | loss-text 4.5380\n",
      "2022-02-23 18:49:50,311 - INFO: | epoch   1 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 126.86 | loss-text 4.5353\n",
      "2022-02-23 18:50:01,806 - INFO: | epoch   1 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 114.92 | loss-text 4.5371\n",
      "2022-02-23 18:50:12,613 - INFO: | epoch   1 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 108.00 | loss-text 4.4776\n",
      "2022-02-23 18:50:22,591 - INFO: | epoch   1 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 99.77 | loss-text 4.3895\n",
      "2022-02-23 18:50:31,797 - INFO: | epoch   1 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 92.05 | loss-text 4.3764\n",
      "2022-02-23 18:50:40,179 - INFO: | epoch   1 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 83.80 | loss-text 4.4144\n",
      "2022-02-23 18:50:48,086 - INFO: | epoch   1 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 79.05 | loss-text 4.4055\n",
      "2022-02-23 18:50:56,001 - INFO: | epoch   1 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 79.14 | loss-text 4.3277\n",
      "2022-02-23 18:51:03,820 - INFO: | epoch   1 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 78.18 | loss-text 4.4100\n",
      "2022-02-23 18:51:11,747 - INFO: | epoch   1 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 79.26 | loss-text 4.3759\n",
      "2022-02-23 18:51:19,513 - INFO: | epoch   1 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 77.66 | loss-text 4.3059\n",
      "2022-02-23 18:51:27,341 - INFO: | epoch   1 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 78.27 | loss-text 4.3476\n",
      "2022-02-23 18:51:35,194 - INFO: | epoch   1 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 78.52 | loss-text 4.3018\n",
      "2022-02-23 18:51:43,100 - INFO: | epoch   1 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 79.05 | loss-text 4.2715\n",
      "2022-02-23 18:51:50,904 - INFO: | epoch   1 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 78.03 | loss-text 4.2884\n",
      "2022-02-23 18:51:58,749 - INFO: | epoch   1 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 78.45 | loss-text 4.2487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003964\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 22125, 'reflen': 13584, 'guess': [22125, 21101, 20077, 19053], 'correct': [4875, 1373, 406, 103]}\n",
      "ratio: 1.6287544169610109\n",
      "Bleu_1: 0.220\n",
      "Bleu_2: 0.120\n",
      "Bleu_3: 0.066\n",
      "Bleu_4: 0.035\n",
      "computing METEOR score...\n",
      "METEOR: 0.108\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.238\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.070\n",
      "computing SPICE score...\n",
      "SPICE: 0.073\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.072\n",
      "2022-02-23 18:54:50,858 - INFO: eval_greddy SPIDEr: 0.0715\n",
      "loading annotations into memory...\n",
      "0:00:00.004027\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9744, 'reflen': 10673, 'guess': [9744, 8720, 7696, 6672], 'correct': [4262, 1294, 421, 115]}\n",
      "ratio: 0.9129579312282476\n",
      "Bleu_1: 0.398\n",
      "Bleu_2: 0.232\n",
      "Bleu_3: 0.139\n",
      "Bleu_4: 0.080\n",
      "computing METEOR score...\n",
      "METEOR: 0.114\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.305\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.134\n",
      "computing SPICE score...\n",
      "SPICE: 0.077\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.105\n",
      "2022-02-23 18:55:32,547 - INFO: eval_beam_2 SPIDEr: 0.1054\n",
      "loading annotations into memory...\n",
      "0:00:00.003991\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 6897, 'reflen': 9271, 'guess': [6897, 5873, 4849, 3825], 'correct': [3892, 1179, 390, 107]}\n",
      "ratio: 0.7439326933447584\n",
      "Bleu_1: 0.400\n",
      "Bleu_2: 0.239\n",
      "Bleu_3: 0.148\n",
      "Bleu_4: 0.090\n",
      "computing METEOR score...\n",
      "METEOR: 0.110\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.312\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.132\n",
      "computing SPICE score...\n",
      "SPICE: 0.080\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.106\n",
      "2022-02-23 18:56:10,996 - INFO: eval_beam_3 SPIDEr: 0.1060\n",
      "loading annotations into memory...\n",
      "0:00:00.004177\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 6721, 'reflen': 9192, 'guess': [6721, 5697, 4673, 3649], 'correct': [3883, 1219, 417, 114]}\n",
      "ratio: 0.7311792863358647\n",
      "Bleu_1: 0.400\n",
      "Bleu_2: 0.243\n",
      "Bleu_3: 0.154\n",
      "Bleu_4: 0.094\n",
      "computing METEOR score...\n",
      "METEOR: 0.111\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.314\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.136\n",
      "computing SPICE score...\n",
      "SPICE: 0.081\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.108\n",
      "2022-02-23 18:56:51,246 - INFO: eval_beam_4 SPIDEr: 0.1084\n",
      "2022-02-23 18:56:59,375 - INFO: | epoch   2 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 81.26 | loss-text 4.2311\n",
      "2022-02-23 18:57:07,092 - INFO: | epoch   2 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 77.16 | loss-text 4.1605\n",
      "2022-02-23 18:57:14,740 - INFO: | epoch   2 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 76.48 | loss-text 4.2349\n",
      "2022-02-23 18:57:22,499 - INFO: | epoch   2 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 77.57 | loss-text 4.2271\n",
      "2022-02-23 18:57:30,235 - INFO: | epoch   2 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 77.35 | loss-text 4.2187\n",
      "2022-02-23 18:57:37,955 - INFO: | epoch   2 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 77.20 | loss-text 4.1973\n",
      "2022-02-23 18:57:45,805 - INFO: | epoch   2 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 78.49 | loss-text 4.2269\n",
      "2022-02-23 18:57:53,551 - INFO: | epoch   2 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 77.45 | loss-text 4.1410\n",
      "2022-02-23 18:58:01,344 - INFO: | epoch   2 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 77.92 | loss-text 4.1333\n",
      "2022-02-23 18:58:09,114 - INFO: | epoch   2 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 77.69 | loss-text 4.1978\n",
      "2022-02-23 18:58:16,899 - INFO: | epoch   2 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 77.85 | loss-text 4.1056\n",
      "2022-02-23 18:58:24,716 - INFO: | epoch   2 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 78.15 | loss-text 4.1297\n",
      "2022-02-23 18:58:32,474 - INFO: | epoch   2 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 77.57 | loss-text 4.1103\n",
      "2022-02-23 18:58:40,266 - INFO: | epoch   2 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 77.91 | loss-text 4.1511\n",
      "2022-02-23 18:58:48,010 - INFO: | epoch   2 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 77.43 | loss-text 4.2205\n",
      "2022-02-23 18:58:55,818 - INFO: | epoch   2 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 78.07 | loss-text 4.1017\n",
      "2022-02-23 18:59:03,690 - INFO: | epoch   2 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 78.72 | loss-text 4.1020\n",
      "2022-02-23 18:59:11,530 - INFO: | epoch   2 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 78.39 | loss-text 4.0719\n",
      "2022-02-23 18:59:19,368 - INFO: | epoch   2 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 78.37 | loss-text 4.0993\n",
      "2022-02-23 18:59:27,142 - INFO: | epoch   2 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 77.74 | loss-text 4.0783\n",
      "2022-02-23 18:59:34,947 - INFO: | epoch   2 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 78.04 | loss-text 4.1242\n",
      "2022-02-23 18:59:42,766 - INFO: | epoch   2 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 78.18 | loss-text 4.0518\n",
      "2022-02-23 18:59:50,542 - INFO: | epoch   2 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 77.75 | loss-text 4.0778\n",
      "2022-02-23 18:59:58,415 - INFO: | epoch   2 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 78.72 | loss-text 4.0934\n",
      "2022-02-23 19:00:06,187 - INFO: | epoch   2 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 77.71 | loss-text 3.9969\n",
      "2022-02-23 19:00:14,025 - INFO: | epoch   2 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 78.37 | loss-text 4.0652\n",
      "2022-02-23 19:00:23,540 - INFO: | epoch   2 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 95.14 | loss-text 3.9931\n",
      "2022-02-23 19:00:31,783 - INFO: | epoch   2 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 82.41 | loss-text 4.0782\n",
      "2022-02-23 19:00:39,596 - INFO: | epoch   2 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 78.13 | loss-text 4.0266\n",
      "2022-02-23 19:00:47,467 - INFO: | epoch   2 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 78.70 | loss-text 4.0638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004531\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 14670, 'reflen': 12187, 'guess': [14670, 13646, 12622, 11598], 'correct': [5302, 1591, 502, 99]}\n",
      "ratio: 1.2037416919667512\n",
      "Bleu_1: 0.361\n",
      "Bleu_2: 0.205\n",
      "Bleu_3: 0.119\n",
      "Bleu_4: 0.062\n",
      "computing METEOR score...\n",
      "METEOR: 0.126\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.301\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.117\n",
      "computing SPICE score...\n",
      "SPICE: 0.080\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.099\n",
      "2022-02-23 19:01:36,089 - INFO: eval_greddy SPIDEr: 0.0989\n",
      "loading annotations into memory...\n",
      "0:00:00.004174\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9909, 'reflen': 10345, 'guess': [9909, 8885, 7861, 6837], 'correct': [4412, 1498, 513, 108]}\n",
      "ratio: 0.9578540357659779\n",
      "Bleu_1: 0.426\n",
      "Bleu_2: 0.262\n",
      "Bleu_3: 0.163\n",
      "Bleu_4: 0.090\n",
      "computing METEOR score...\n",
      "METEOR: 0.127\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.318\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.166\n",
      "computing SPICE score...\n",
      "SPICE: 0.078\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.122\n",
      "2022-02-23 19:02:18,730 - INFO: eval_beam_2 SPIDEr: 0.1218\n",
      "loading annotations into memory...\n",
      "0:00:00.004109\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7342, 'reflen': 9349, 'guess': [7342, 6318, 5294, 4270], 'correct': [4206, 1514, 529, 110]}\n",
      "ratio: 0.7853246336505738\n",
      "Bleu_1: 0.436\n",
      "Bleu_2: 0.282\n",
      "Bleu_3: 0.182\n",
      "Bleu_4: 0.104\n",
      "computing METEOR score...\n",
      "METEOR: 0.130\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.338\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.192\n",
      "computing SPICE score...\n",
      "SPICE: 0.084\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.138\n",
      "2022-02-23 19:03:00,843 - INFO: eval_beam_3 SPIDEr: 0.1380\n",
      "loading annotations into memory...\n",
      "0:00:00.003819\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7003, 'reflen': 9204, 'guess': [7003, 5979, 4955, 3931], 'correct': [4155, 1534, 540, 116]}\n",
      "ratio: 0.7608648413732333\n",
      "Bleu_1: 0.433\n",
      "Bleu_2: 0.285\n",
      "Bleu_3: 0.186\n",
      "Bleu_4: 0.109\n",
      "computing METEOR score...\n",
      "METEOR: 0.129\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.338\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.200\n",
      "computing SPICE score...\n",
      "SPICE: 0.088\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.144\n",
      "2022-02-23 19:03:44,655 - INFO: eval_beam_4 SPIDEr: 0.1440\n",
      "2022-02-23 19:03:52,753 - INFO: | epoch   3 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 80.95 | loss-text 3.9907\n",
      "2022-02-23 19:04:00,524 - INFO: | epoch   3 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 77.69 | loss-text 3.9942\n",
      "2022-02-23 19:04:08,224 - INFO: | epoch   3 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 77.00 | loss-text 4.0094\n",
      "2022-02-23 19:04:15,968 - INFO: | epoch   3 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 77.43 | loss-text 3.9850\n",
      "2022-02-23 19:04:23,733 - INFO: | epoch   3 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 77.64 | loss-text 4.0236\n",
      "2022-02-23 19:04:31,503 - INFO: | epoch   3 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 77.70 | loss-text 3.9785\n",
      "2022-02-23 19:04:39,265 - INFO: | epoch   3 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 77.61 | loss-text 3.9641\n",
      "2022-02-23 19:04:47,028 - INFO: | epoch   3 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 77.61 | loss-text 4.0218\n",
      "2022-02-23 19:04:54,758 - INFO: | epoch   3 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 77.30 | loss-text 3.9289\n",
      "2022-02-23 19:05:02,784 - INFO: | epoch   3 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 80.25 | loss-text 3.9435\n",
      "2022-02-23 19:05:10,579 - INFO: | epoch   3 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 77.94 | loss-text 3.9875\n",
      "2022-02-23 19:05:18,346 - INFO: | epoch   3 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 77.66 | loss-text 3.9573\n",
      "2022-02-23 19:05:26,092 - INFO: | epoch   3 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 77.45 | loss-text 3.9410\n",
      "2022-02-23 19:05:33,892 - INFO: | epoch   3 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 77.99 | loss-text 3.8897\n",
      "2022-02-23 19:05:41,684 - INFO: | epoch   3 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 77.91 | loss-text 3.9108\n",
      "2022-02-23 19:05:49,497 - INFO: | epoch   3 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 78.12 | loss-text 3.9909\n",
      "2022-02-23 19:05:57,305 - INFO: | epoch   3 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 78.07 | loss-text 3.9522\n",
      "2022-02-23 19:06:05,172 - INFO: | epoch   3 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 78.65 | loss-text 3.9887\n",
      "2022-02-23 19:06:12,990 - INFO: | epoch   3 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 78.17 | loss-text 3.9290\n",
      "2022-02-23 19:06:20,814 - INFO: | epoch   3 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 78.23 | loss-text 3.8855\n",
      "2022-02-23 19:06:28,652 - INFO: | epoch   3 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 78.38 | loss-text 3.8660\n",
      "2022-02-23 19:06:36,475 - INFO: | epoch   3 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 78.22 | loss-text 3.9550\n",
      "2022-02-23 19:06:44,250 - INFO: | epoch   3 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 77.74 | loss-text 3.9506\n",
      "2022-02-23 19:06:51,999 - INFO: | epoch   3 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 77.48 | loss-text 3.8469\n",
      "2022-02-23 19:06:59,761 - INFO: | epoch   3 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 77.59 | loss-text 3.9244\n",
      "2022-02-23 19:07:07,626 - INFO: | epoch   3 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 78.63 | loss-text 3.9002\n",
      "2022-02-23 19:07:15,469 - INFO: | epoch   3 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 78.42 | loss-text 3.9213\n",
      "2022-02-23 19:07:23,313 - INFO: | epoch   3 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 78.43 | loss-text 3.9500\n",
      "2022-02-23 19:07:31,095 - INFO: | epoch   3 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 77.81 | loss-text 3.9134\n",
      "2022-02-23 19:07:38,888 - INFO: | epoch   3 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 77.92 | loss-text 3.8657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003994\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 13057, 'reflen': 11370, 'guess': [13057, 12033, 11009, 9985], 'correct': [5032, 1484, 490, 116]}\n",
      "ratio: 1.148372911169644\n",
      "Bleu_1: 0.385\n",
      "Bleu_2: 0.218\n",
      "Bleu_3: 0.128\n",
      "Bleu_4: 0.070\n",
      "computing METEOR score...\n",
      "METEOR: 0.128\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.299\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.148\n",
      "computing SPICE score...\n",
      "SPICE: 0.082\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.115\n",
      "2022-02-23 19:08:27,701 - INFO: eval_greddy SPIDEr: 0.1148\n",
      "loading annotations into memory...\n",
      "0:00:00.004001\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10584, 'reflen': 10331, 'guess': [10584, 9560, 8536, 7512], 'correct': [4776, 1605, 570, 151]}\n",
      "ratio: 1.0244894008323469\n",
      "Bleu_1: 0.451\n",
      "Bleu_2: 0.275\n",
      "Bleu_3: 0.172\n",
      "Bleu_4: 0.100\n",
      "computing METEOR score...\n",
      "METEOR: 0.133\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.318\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.197\n",
      "computing SPICE score...\n",
      "SPICE: 0.087\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.142\n",
      "2022-02-23 19:09:09,666 - INFO: eval_beam_2 SPIDEr: 0.1420\n",
      "loading annotations into memory...\n",
      "0:00:00.003878\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7936, 'reflen': 9480, 'guess': [7936, 6912, 5888, 4864], 'correct': [4284, 1541, 556, 133]}\n",
      "ratio: 0.8371308016876754\n",
      "Bleu_1: 0.444\n",
      "Bleu_2: 0.286\n",
      "Bleu_3: 0.185\n",
      "Bleu_4: 0.109\n",
      "computing METEOR score...\n",
      "METEOR: 0.131\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.332\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.213\n",
      "computing SPICE score...\n",
      "SPICE: 0.090\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.151\n",
      "2022-02-23 19:09:49,385 - INFO: eval_beam_3 SPIDEr: 0.1514\n",
      "loading annotations into memory...\n",
      "0:00:00.003816\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7207, 'reflen': 9258, 'guess': [7207, 6183, 5159, 4135], 'correct': [4175, 1566, 579, 138]}\n",
      "ratio: 0.7784618708143466\n",
      "Bleu_1: 0.436\n",
      "Bleu_2: 0.288\n",
      "Bleu_3: 0.191\n",
      "Bleu_4: 0.115\n",
      "computing METEOR score...\n",
      "METEOR: 0.132\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.339\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.222\n",
      "computing SPICE score...\n",
      "SPICE: 0.090\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.156\n",
      "2022-02-23 19:10:29,125 - INFO: eval_beam_4 SPIDEr: 0.1556\n",
      "2022-02-23 19:10:36,901 - INFO: | epoch   4 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.73 | loss-text 3.8135\n",
      "2022-02-23 19:10:44,346 - INFO: | epoch   4 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.43 | loss-text 3.9093\n",
      "2022-02-23 19:10:51,807 - INFO: | epoch   4 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.61 | loss-text 3.8407\n",
      "2022-02-23 19:10:59,336 - INFO: | epoch   4 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.28 | loss-text 3.8687\n",
      "2022-02-23 19:11:06,868 - INFO: | epoch   4 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.31 | loss-text 3.8160\n",
      "2022-02-23 19:11:14,465 - INFO: | epoch   4 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.8822\n",
      "2022-02-23 19:11:22,004 - INFO: | epoch   4 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.39 | loss-text 3.8921\n",
      "2022-02-23 19:11:29,514 - INFO: | epoch   4 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.09 | loss-text 3.8619\n",
      "2022-02-23 19:11:37,030 - INFO: | epoch   4 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.15 | loss-text 3.8593\n",
      "2022-02-23 19:11:44,621 - INFO: | epoch   4 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.9336\n",
      "2022-02-23 19:11:52,197 - INFO: | epoch   4 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.8574\n",
      "2022-02-23 19:11:59,777 - INFO: | epoch   4 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.79 | loss-text 3.8147\n",
      "2022-02-23 19:12:07,409 - INFO: | epoch   4 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.31 | loss-text 3.8176\n",
      "2022-02-23 19:12:14,978 - INFO: | epoch   4 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.8398\n",
      "2022-02-23 19:12:22,532 - INFO: | epoch   4 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.53 | loss-text 3.8528\n",
      "2022-02-23 19:12:30,108 - INFO: | epoch   4 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.76 | loss-text 3.8385\n",
      "2022-02-23 19:12:37,700 - INFO: | epoch   4 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.8292\n",
      "2022-02-23 19:12:45,295 - INFO: | epoch   4 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.7907\n",
      "2022-02-23 19:12:52,898 - INFO: | epoch   4 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.8175\n",
      "2022-02-23 19:13:00,484 - INFO: | epoch   4 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.85 | loss-text 3.8257\n",
      "2022-02-23 19:13:08,056 - INFO: | epoch   4 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.7714\n",
      "2022-02-23 19:13:15,653 - INFO: | epoch   4 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.8638\n",
      "2022-02-23 19:13:23,217 - INFO: | epoch   4 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.64 | loss-text 3.7823\n",
      "2022-02-23 19:13:30,748 - INFO: | epoch   4 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.30 | loss-text 3.7980\n",
      "2022-02-23 19:13:38,295 - INFO: | epoch   4 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.8348\n",
      "2022-02-23 19:13:45,882 - INFO: | epoch   4 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.8276\n",
      "2022-02-23 19:13:53,436 - INFO: | epoch   4 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.53 | loss-text 3.8217\n",
      "2022-02-23 19:14:00,992 - INFO: | epoch   4 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.55 | loss-text 3.7755\n",
      "2022-02-23 19:14:08,609 - INFO: | epoch   4 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.16 | loss-text 3.8591\n",
      "2022-02-23 19:14:16,182 - INFO: | epoch   4 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.73 | loss-text 3.8884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003770\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 13765, 'reflen': 11652, 'guess': [13765, 12741, 11717, 10693], 'correct': [5197, 1620, 540, 130]}\n",
      "ratio: 1.1813422588395828\n",
      "Bleu_1: 0.378\n",
      "Bleu_2: 0.219\n",
      "Bleu_3: 0.130\n",
      "Bleu_4: 0.072\n",
      "computing METEOR score...\n",
      "METEOR: 0.133\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.304\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.174\n",
      "computing SPICE score...\n",
      "SPICE: 0.089\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.131\n",
      "2022-02-23 19:15:03,546 - INFO: eval_greddy SPIDEr: 0.1315\n",
      "loading annotations into memory...\n",
      "0:00:00.003774\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9104, 'reflen': 9907, 'guess': [9104, 8080, 7056, 6032], 'correct': [4869, 1724, 645, 187]}\n",
      "ratio: 0.9189461996567155\n",
      "Bleu_1: 0.490\n",
      "Bleu_2: 0.309\n",
      "Bleu_3: 0.200\n",
      "Bleu_4: 0.123\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.341\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.239\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.167\n",
      "2022-02-23 19:15:37,863 - INFO: eval_beam_2 SPIDEr: 0.1665\n",
      "loading annotations into memory...\n",
      "0:00:00.004057\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7831, 'reflen': 9449, 'guess': [7831, 6807, 5783, 4759], 'correct': [4485, 1660, 645, 189]}\n",
      "ratio: 0.8287649486717293\n",
      "Bleu_1: 0.466\n",
      "Bleu_2: 0.304\n",
      "Bleu_3: 0.203\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.138\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.238\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.165\n",
      "2022-02-23 19:16:14,025 - INFO: eval_beam_3 SPIDEr: 0.1652\n",
      "loading annotations into memory...\n",
      "0:00:00.003845\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7149, 'reflen': 9243, 'guess': [7149, 6125, 5101, 4077], 'correct': [4287, 1594, 611, 155]}\n",
      "ratio: 0.7734501785133859\n",
      "Bleu_1: 0.447\n",
      "Bleu_2: 0.295\n",
      "Bleu_3: 0.198\n",
      "Bleu_4: 0.122\n",
      "computing METEOR score...\n",
      "METEOR: 0.135\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.348\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.231\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.162\n",
      "2022-02-23 19:16:54,622 - INFO: eval_beam_4 SPIDEr: 0.1616\n",
      "2022-02-23 19:17:02,424 - INFO: | epoch   5 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.99 | loss-text 3.7608\n",
      "2022-02-23 19:17:09,907 - INFO: | epoch   5 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.81 | loss-text 3.7963\n",
      "2022-02-23 19:17:17,397 - INFO: | epoch   5 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.90 | loss-text 3.7627\n",
      "2022-02-23 19:17:24,998 - INFO: | epoch   5 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.7922\n",
      "2022-02-23 19:17:32,520 - INFO: | epoch   5 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.21 | loss-text 3.7833\n",
      "2022-02-23 19:17:39,970 - INFO: | epoch   5 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 74.48 | loss-text 3.7403\n",
      "2022-02-23 19:17:47,478 - INFO: | epoch   5 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.08 | loss-text 3.7996\n",
      "2022-02-23 19:17:55,014 - INFO: | epoch   5 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.35 | loss-text 3.7816\n",
      "2022-02-23 19:18:02,565 - INFO: | epoch   5 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.51 | loss-text 3.8035\n",
      "2022-02-23 19:18:10,107 - INFO: | epoch   5 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.41 | loss-text 3.7920\n",
      "2022-02-23 19:18:17,717 - INFO: | epoch   5 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 76.09 | loss-text 3.7121\n",
      "2022-02-23 19:18:25,288 - INFO: | epoch   5 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.8150\n",
      "2022-02-23 19:18:32,936 - INFO: | epoch   5 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.47 | loss-text 3.7795\n",
      "2022-02-23 19:18:40,522 - INFO: | epoch   5 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.7638\n",
      "2022-02-23 19:18:48,113 - INFO: | epoch   5 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.7321\n",
      "2022-02-23 19:18:55,626 - INFO: | epoch   5 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.13 | loss-text 3.7227\n",
      "2022-02-23 19:19:03,227 - INFO: | epoch   5 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.7179\n",
      "2022-02-23 19:19:10,715 - INFO: | epoch   5 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 74.87 | loss-text 3.7434\n",
      "2022-02-23 19:19:18,311 - INFO: | epoch   5 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.7629\n",
      "2022-02-23 19:19:25,905 - INFO: | epoch   5 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.7445\n",
      "2022-02-23 19:19:33,478 - INFO: | epoch   5 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.7152\n",
      "2022-02-23 19:19:41,020 - INFO: | epoch   5 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.41 | loss-text 3.7490\n",
      "2022-02-23 19:19:48,654 - INFO: | epoch   5 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.34 | loss-text 3.7590\n",
      "2022-02-23 19:19:56,241 - INFO: | epoch   5 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.8370\n",
      "2022-02-23 19:20:03,788 - INFO: | epoch   5 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.7207\n",
      "2022-02-23 19:20:11,356 - INFO: | epoch   5 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.68 | loss-text 3.7222\n",
      "2022-02-23 19:20:18,932 - INFO: | epoch   5 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.7428\n",
      "2022-02-23 19:20:26,511 - INFO: | epoch   5 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.78 | loss-text 3.6707\n",
      "2022-02-23 19:20:34,052 - INFO: | epoch   5 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 75.41 | loss-text 3.7545\n",
      "2022-02-23 19:20:41,627 - INFO: | epoch   5 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.74 | loss-text 3.7179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003813\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 13707, 'reflen': 11662, 'guess': [13707, 12683, 11659, 10635], 'correct': [5563, 1820, 626, 155]}\n",
      "ratio: 1.1753558566282647\n",
      "Bleu_1: 0.406\n",
      "Bleu_2: 0.241\n",
      "Bleu_3: 0.146\n",
      "Bleu_4: 0.082\n",
      "computing METEOR score...\n",
      "METEOR: 0.139\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.322\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.182\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.139\n",
      "2022-02-23 19:21:28,421 - INFO: eval_greddy SPIDEr: 0.1390\n",
      "loading annotations into memory...\n",
      "0:00:00.003919\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10233, 'reflen': 10240, 'guess': [10233, 9209, 8185, 7161], 'correct': [5022, 1793, 651, 187]}\n",
      "ratio: 0.9993164062499024\n",
      "Bleu_1: 0.490\n",
      "Bleu_2: 0.309\n",
      "Bleu_3: 0.196\n",
      "Bleu_4: 0.119\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.336\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.246\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.173\n",
      "2022-02-23 19:22:07,494 - INFO: eval_beam_2 SPIDEr: 0.1730\n",
      "loading annotations into memory...\n",
      "0:00:00.003922\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8265, 'reflen': 9549, 'guess': [8265, 7241, 6217, 5193], 'correct': [4609, 1672, 623, 184]}\n",
      "ratio: 0.8655356581840123\n",
      "Bleu_1: 0.477\n",
      "Bleu_2: 0.307\n",
      "Bleu_3: 0.201\n",
      "Bleu_4: 0.125\n",
      "computing METEOR score...\n",
      "METEOR: 0.137\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.339\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.243\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.170\n",
      "2022-02-23 19:22:41,910 - INFO: eval_beam_3 SPIDEr: 0.1704\n",
      "loading annotations into memory...\n",
      "0:00:00.003891\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7601, 'reflen': 9319, 'guess': [7601, 6577, 5553, 4529], 'correct': [4364, 1602, 614, 175]}\n",
      "ratio: 0.8156454555208911\n",
      "Bleu_1: 0.458\n",
      "Bleu_2: 0.298\n",
      "Bleu_3: 0.199\n",
      "Bleu_4: 0.125\n",
      "computing METEOR score...\n",
      "METEOR: 0.132\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.334\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.233\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.164\n",
      "2022-02-23 19:23:20,744 - INFO: eval_beam_4 SPIDEr: 0.1644\n",
      "2022-02-23 19:23:28,537 - INFO: | epoch   6 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.90 | loss-text 3.7214\n",
      "2022-02-23 19:23:36,040 - INFO: | epoch   6 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.02 | loss-text 3.7648\n",
      "2022-02-23 19:23:43,635 - INFO: | epoch   6 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.93 | loss-text 3.6950\n",
      "2022-02-23 19:23:51,194 - INFO: | epoch   6 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.58 | loss-text 3.7081\n",
      "2022-02-23 19:23:58,730 - INFO: | epoch   6 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.36 | loss-text 3.7567\n",
      "2022-02-23 19:24:06,274 - INFO: | epoch   6 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.43 | loss-text 3.7301\n",
      "2022-02-23 19:24:13,799 - INFO: | epoch   6 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.25 | loss-text 3.6862\n",
      "2022-02-23 19:24:21,294 - INFO: | epoch   6 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 74.94 | loss-text 3.6808\n",
      "2022-02-23 19:24:28,864 - INFO: | epoch   6 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.7151\n",
      "2022-02-23 19:24:36,356 - INFO: | epoch   6 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 74.91 | loss-text 3.6864\n",
      "2022-02-23 19:24:43,934 - INFO: | epoch   6 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.78 | loss-text 3.6933\n",
      "2022-02-23 19:24:51,451 - INFO: | epoch   6 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.17 | loss-text 3.7617\n",
      "2022-02-23 19:24:59,067 - INFO: | epoch   6 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.15 | loss-text 3.7826\n",
      "2022-02-23 19:25:06,646 - INFO: | epoch   6 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.78 | loss-text 3.6895\n",
      "2022-02-23 19:25:14,221 - INFO: | epoch   6 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.6828\n",
      "2022-02-23 19:25:21,841 - INFO: | epoch   6 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.19 | loss-text 3.6615\n",
      "2022-02-23 19:25:29,411 - INFO: | epoch   6 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.6742\n",
      "2022-02-23 19:25:37,003 - INFO: | epoch   6 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.6632\n",
      "2022-02-23 19:25:44,587 - INFO: | epoch   6 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.6607\n",
      "2022-02-23 19:25:52,195 - INFO: | epoch   6 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.6932\n",
      "2022-02-23 19:25:59,780 - INFO: | epoch   6 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.6574\n",
      "2022-02-23 19:26:07,402 - INFO: | epoch   6 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.22 | loss-text 3.7160\n",
      "2022-02-23 19:26:14,984 - INFO: | epoch   6 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.81 | loss-text 3.7166\n",
      "2022-02-23 19:26:22,579 - INFO: | epoch   6 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.7047\n",
      "2022-02-23 19:26:30,213 - INFO: | epoch   6 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.33 | loss-text 3.6850\n",
      "2022-02-23 19:26:37,807 - INFO: | epoch   6 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.93 | loss-text 3.7064\n",
      "2022-02-23 19:26:45,381 - INFO: | epoch   6 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.73 | loss-text 3.6915\n",
      "2022-02-23 19:26:52,993 - INFO: | epoch   6 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.12 | loss-text 3.6666\n",
      "2022-02-23 19:27:00,632 - INFO: | epoch   6 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.38 | loss-text 3.6852\n",
      "2022-02-23 19:27:08,203 - INFO: | epoch   6 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003737\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11997, 'reflen': 11161, 'guess': [11997, 10973, 9949, 8925], 'correct': [5408, 1772, 612, 174]}\n",
      "ratio: 1.0749036824656326\n",
      "Bleu_1: 0.451\n",
      "Bleu_2: 0.270\n",
      "Bleu_3: 0.165\n",
      "Bleu_4: 0.097\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.329\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.211\n",
      "computing SPICE score...\n",
      "SPICE: 0.093\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.152\n",
      "2022-02-23 19:27:51,675 - INFO: eval_greddy SPIDEr: 0.1520\n",
      "loading annotations into memory...\n",
      "0:00:00.004059\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9277, 'reflen': 10025, 'guess': [9277, 8253, 7229, 6205], 'correct': [4966, 1793, 713, 224]}\n",
      "ratio: 0.9253865336657431\n",
      "Bleu_1: 0.494\n",
      "Bleu_2: 0.315\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.267\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.183\n",
      "2022-02-23 19:28:22,126 - INFO: eval_beam_2 SPIDEr: 0.1827\n",
      "loading annotations into memory...\n",
      "0:00:00.003999\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8074, 'reflen': 9432, 'guess': [8074, 7050, 6026, 5002], 'correct': [4689, 1765, 692, 218]}\n",
      "ratio: 0.8560220525868473\n",
      "Bleu_1: 0.491\n",
      "Bleu_2: 0.322\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.145\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.351\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.273\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.184\n",
      "2022-02-23 19:28:54,727 - INFO: eval_beam_3 SPIDEr: 0.1845\n",
      "loading annotations into memory...\n",
      "0:00:00.003641\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7495, 'reflen': 9271, 'guess': [7495, 6471, 5447, 4423], 'correct': [4387, 1636, 630, 192]}\n",
      "ratio: 0.8084349045409547\n",
      "Bleu_1: 0.462\n",
      "Bleu_2: 0.304\n",
      "Bleu_3: 0.203\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.142\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.346\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.262\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.178\n",
      "2022-02-23 19:29:30,037 - INFO: eval_beam_4 SPIDEr: 0.1782\n",
      "2022-02-23 19:29:37,836 - INFO: | epoch   7 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.96 | loss-text 3.6592\n",
      "2022-02-23 19:29:45,369 - INFO: | epoch   7 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.32 | loss-text 3.6817\n",
      "2022-02-23 19:29:52,827 - INFO: | epoch   7 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.57 | loss-text 3.6909\n",
      "2022-02-23 19:30:00,407 - INFO: | epoch   7 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.79 | loss-text 3.6935\n",
      "2022-02-23 19:30:07,970 - INFO: | epoch   7 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.6921\n",
      "2022-02-23 19:30:15,471 - INFO: | epoch   7 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.01 | loss-text 3.6275\n",
      "2022-02-23 19:30:23,032 - INFO: | epoch   7 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.61 | loss-text 3.6505\n",
      "2022-02-23 19:30:30,563 - INFO: | epoch   7 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.30 | loss-text 3.6071\n",
      "2022-02-23 19:30:38,147 - INFO: | epoch   7 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.6230\n",
      "2022-02-23 19:30:45,710 - INFO: | epoch   7 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.63 | loss-text 3.6472\n",
      "2022-02-23 19:30:53,312 - INFO: | epoch   7 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.6341\n",
      "2022-02-23 19:31:00,897 - INFO: | epoch   7 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.6775\n",
      "2022-02-23 19:31:08,474 - INFO: | epoch   7 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.77 | loss-text 3.6461\n",
      "2022-02-23 19:31:16,065 - INFO: | epoch   7 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.6730\n",
      "2022-02-23 19:31:23,700 - INFO: | epoch   7 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.33 | loss-text 3.6790\n",
      "2022-02-23 19:31:31,267 - INFO: | epoch   7 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.6630\n",
      "2022-02-23 19:31:38,850 - INFO: | epoch   7 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.82 | loss-text 3.6952\n",
      "2022-02-23 19:31:46,473 - INFO: | epoch   7 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.23 | loss-text 3.6491\n",
      "2022-02-23 19:31:54,042 - INFO: | epoch   7 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.6311\n",
      "2022-02-23 19:32:01,665 - INFO: | epoch   7 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.22 | loss-text 3.6389\n",
      "2022-02-23 19:32:09,282 - INFO: | epoch   7 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.5952\n",
      "2022-02-23 19:32:16,857 - INFO: | epoch   7 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.74 | loss-text 3.6054\n",
      "2022-02-23 19:32:24,492 - INFO: | epoch   7 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.34 | loss-text 3.6106\n",
      "2022-02-23 19:32:32,050 - INFO: | epoch   7 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.58 | loss-text 3.7036\n",
      "2022-02-23 19:32:39,646 - INFO: | epoch   7 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.6491\n",
      "2022-02-23 19:32:47,229 - INFO: | epoch   7 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.82 | loss-text 3.6749\n",
      "2022-02-23 19:32:54,809 - INFO: | epoch   7 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.79 | loss-text 3.5851\n",
      "2022-02-23 19:33:02,412 - INFO: | epoch   7 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.02 | loss-text 3.6010\n",
      "2022-02-23 19:33:10,070 - INFO: | epoch   7 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.57 | loss-text 3.6714\n",
      "2022-02-23 19:33:17,644 - INFO: | epoch   7 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.73 | loss-text 3.5965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003851\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 12476, 'reflen': 11566, 'guess': [12476, 11452, 10428, 9404], 'correct': [5822, 1958, 708, 215]}\n",
      "ratio: 1.0786788863910532\n",
      "Bleu_1: 0.467\n",
      "Bleu_2: 0.282\n",
      "Bleu_3: 0.176\n",
      "Bleu_4: 0.105\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.345\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.229\n",
      "computing SPICE score...\n",
      "SPICE: 0.097\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.163\n",
      "2022-02-23 19:34:02,829 - INFO: eval_greddy SPIDEr: 0.1628\n",
      "loading annotations into memory...\n",
      "0:00:00.003935\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9929, 'reflen': 10336, 'guess': [9929, 8905, 7881, 6857], 'correct': [5232, 1908, 757, 247]}\n",
      "ratio: 0.9606230650153869\n",
      "Bleu_1: 0.506\n",
      "Bleu_2: 0.323\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.265\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.182\n",
      "2022-02-23 19:34:33,335 - INFO: eval_beam_2 SPIDEr: 0.1822\n",
      "loading annotations into memory...\n",
      "0:00:00.003901\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8775, 'reflen': 9751, 'guess': [8775, 7751, 6727, 5703], 'correct': [4862, 1788, 713, 238]}\n",
      "ratio: 0.8999077017740846\n",
      "Bleu_1: 0.496\n",
      "Bleu_2: 0.320\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.267\n",
      "computing SPICE score...\n",
      "SPICE: 0.097\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.182\n",
      "2022-02-23 19:35:07,057 - INFO: eval_beam_3 SPIDEr: 0.1821\n",
      "loading annotations into memory...\n",
      "0:00:00.003928\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7484, 'reflen': 9316, 'guess': [7484, 6460, 5436, 4412], 'correct': [4346, 1633, 629, 196]}\n",
      "ratio: 0.8033490768569339\n",
      "Bleu_1: 0.455\n",
      "Bleu_2: 0.300\n",
      "Bleu_3: 0.201\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.140\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.346\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.262\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.177\n",
      "2022-02-23 19:35:44,768 - INFO: eval_beam_4 SPIDEr: 0.1771\n",
      "2022-02-23 19:35:52,585 - INFO: | epoch   8 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.14 | loss-text 3.6544\n",
      "2022-02-23 19:36:00,085 - INFO: | epoch   8 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.00 | loss-text 3.6132\n",
      "2022-02-23 19:36:07,557 - INFO: | epoch   8 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.71 | loss-text 3.6512\n",
      "2022-02-23 19:36:15,097 - INFO: | epoch   8 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.5537\n",
      "2022-02-23 19:36:22,631 - INFO: | epoch   8 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.33 | loss-text 3.5789\n",
      "2022-02-23 19:36:30,110 - INFO: | epoch   8 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 74.77 | loss-text 3.5773\n",
      "2022-02-23 19:36:37,709 - INFO: | epoch   8 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.5851\n",
      "2022-02-23 19:36:45,236 - INFO: | epoch   8 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.27 | loss-text 3.6422\n",
      "2022-02-23 19:36:52,818 - INFO: | epoch   8 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.82 | loss-text 3.5787\n",
      "2022-02-23 19:37:01,450 - INFO: | epoch   8 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 86.31 | loss-text 3.6260\n",
      "2022-02-23 19:37:09,007 - INFO: | epoch   8 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.56 | loss-text 3.6307\n",
      "2022-02-23 19:37:16,626 - INFO: | epoch   8 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 76.19 | loss-text 3.6047\n",
      "2022-02-23 19:37:24,126 - INFO: | epoch   8 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 74.99 | loss-text 3.6055\n",
      "2022-02-23 19:37:31,717 - INFO: | epoch   8 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.6452\n",
      "2022-02-23 19:37:39,285 - INFO: | epoch   8 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.5798\n",
      "2022-02-23 19:37:46,822 - INFO: | epoch   8 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.37 | loss-text 3.6050\n",
      "2022-02-23 19:37:54,399 - INFO: | epoch   8 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.76 | loss-text 3.5983\n",
      "2022-02-23 19:38:01,915 - INFO: | epoch   8 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.15 | loss-text 3.6174\n",
      "2022-02-23 19:38:09,537 - INFO: | epoch   8 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.22 | loss-text 3.6313\n",
      "2022-02-23 19:38:17,169 - INFO: | epoch   8 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.32 | loss-text 3.6282\n",
      "2022-02-23 19:38:24,826 - INFO: | epoch   8 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.56 | loss-text 3.6000\n",
      "2022-02-23 19:38:32,387 - INFO: | epoch   8 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.60 | loss-text 3.6606\n",
      "2022-02-23 19:38:40,007 - INFO: | epoch   8 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.19 | loss-text 3.6168\n",
      "2022-02-23 19:38:47,643 - INFO: | epoch   8 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.35 | loss-text 3.5740\n",
      "2022-02-23 19:38:55,226 - INFO: | epoch   8 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.6095\n",
      "2022-02-23 19:39:02,856 - INFO: | epoch   8 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.29 | loss-text 3.6053\n",
      "2022-02-23 19:39:10,486 - INFO: | epoch   8 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.29 | loss-text 3.5382\n",
      "2022-02-23 19:39:18,122 - INFO: | epoch   8 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.35 | loss-text 3.6111\n",
      "2022-02-23 19:39:25,672 - INFO: | epoch   8 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 75.50 | loss-text 3.6113\n",
      "2022-02-23 19:39:33,309 - INFO: | epoch   8 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.36 | loss-text 3.5656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003895\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11895, 'reflen': 11200, 'guess': [11895, 10871, 9847, 8823], 'correct': [5604, 1841, 630, 167]}\n",
      "ratio: 1.0620535714284765\n",
      "Bleu_1: 0.471\n",
      "Bleu_2: 0.282\n",
      "Bleu_3: 0.172\n",
      "Bleu_4: 0.099\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.343\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.231\n",
      "computing SPICE score...\n",
      "SPICE: 0.093\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.162\n",
      "2022-02-23 19:40:16,354 - INFO: eval_greddy SPIDEr: 0.1623\n",
      "loading annotations into memory...\n",
      "0:00:00.003981\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9384, 'reflen': 10027, 'guess': [9384, 8360, 7336, 6312], 'correct': [5161, 1882, 745, 240]}\n",
      "ratio: 0.9358731425151156\n",
      "Bleu_1: 0.514\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.285\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.194\n",
      "2022-02-23 19:40:46,515 - INFO: eval_beam_2 SPIDEr: 0.1943\n",
      "loading annotations into memory...\n",
      "0:00:00.003889\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8461, 'reflen': 9639, 'guess': [8461, 7437, 6413, 5389], 'correct': [4725, 1785, 722, 237]}\n",
      "ratio: 0.8777881522978651\n",
      "Bleu_1: 0.486\n",
      "Bleu_2: 0.319\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.351\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.289\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.194\n",
      "2022-02-23 19:41:19,991 - INFO: eval_beam_3 SPIDEr: 0.1938\n",
      "loading annotations into memory...\n",
      "0:00:00.003817\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7270, 'reflen': 9270, 'guess': [7270, 6246, 5222, 4198], 'correct': [4255, 1628, 652, 200]}\n",
      "ratio: 0.7842502696870782\n",
      "Bleu_1: 0.445\n",
      "Bleu_2: 0.297\n",
      "Bleu_3: 0.203\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.351\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.282\n",
      "computing SPICE score...\n",
      "SPICE: 0.093\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.188\n",
      "2022-02-23 19:41:56,398 - INFO: eval_beam_4 SPIDEr: 0.1875\n",
      "2022-02-23 19:42:04,100 - INFO: | epoch   9 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 76.99 | loss-text 3.5126\n",
      "2022-02-23 19:42:11,623 - INFO: | epoch   9 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.21 | loss-text 3.5824\n",
      "2022-02-23 19:42:19,127 - INFO: | epoch   9 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.04 | loss-text 3.5558\n",
      "2022-02-23 19:42:26,631 - INFO: | epoch   9 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.03 | loss-text 3.5587\n",
      "2022-02-23 19:42:34,191 - INFO: | epoch   9 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.59 | loss-text 3.5353\n",
      "2022-02-23 19:42:41,691 - INFO: | epoch   9 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 74.99 | loss-text 3.5472\n",
      "2022-02-23 19:42:49,301 - INFO: | epoch   9 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 76.10 | loss-text 3.5814\n",
      "2022-02-23 19:42:56,874 - INFO: | epoch   9 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.5420\n",
      "2022-02-23 19:43:04,379 - INFO: | epoch   9 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.04 | loss-text 3.5748\n",
      "2022-02-23 19:43:11,907 - INFO: | epoch   9 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.27 | loss-text 3.6356\n",
      "2022-02-23 19:43:19,494 - INFO: | epoch   9 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.6403\n",
      "2022-02-23 19:43:27,068 - INFO: | epoch   9 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.74 | loss-text 3.5658\n",
      "2022-02-23 19:43:34,663 - INFO: | epoch   9 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.5764\n",
      "2022-02-23 19:43:42,208 - INFO: | epoch   9 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.5204\n",
      "2022-02-23 19:43:49,780 - INFO: | epoch   9 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.5763\n",
      "2022-02-23 19:43:57,382 - INFO: | epoch   9 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.5958\n",
      "2022-02-23 19:44:04,943 - INFO: | epoch   9 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.61 | loss-text 3.5994\n",
      "2022-02-23 19:44:12,529 - INFO: | epoch   9 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.85 | loss-text 3.6333\n",
      "2022-02-23 19:44:20,104 - INFO: | epoch   9 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.5408\n",
      "2022-02-23 19:44:27,713 - INFO: | epoch   9 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.08 | loss-text 3.5662\n",
      "2022-02-23 19:44:35,343 - INFO: | epoch   9 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.30 | loss-text 3.5789\n",
      "2022-02-23 19:44:42,940 - INFO: | epoch   9 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.5365\n",
      "2022-02-23 19:44:50,481 - INFO: | epoch   9 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.6099\n",
      "2022-02-23 19:44:58,065 - INFO: | epoch   9 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.5686\n",
      "2022-02-23 19:45:05,645 - INFO: | epoch   9 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.79 | loss-text 3.5634\n",
      "2022-02-23 19:45:13,298 - INFO: | epoch   9 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.52 | loss-text 3.5772\n",
      "2022-02-23 19:45:20,917 - INFO: | epoch   9 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.18 | loss-text 3.5417\n",
      "2022-02-23 19:45:28,552 - INFO: | epoch   9 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.34 | loss-text 3.5465\n",
      "2022-02-23 19:45:36,205 - INFO: | epoch   9 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.52 | loss-text 3.6438\n",
      "2022-02-23 19:45:43,844 - INFO: | epoch   9 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.39 | loss-text 3.4724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004079\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11413, 'reflen': 10964, 'guess': [11413, 10389, 9365, 8341], 'correct': [5480, 1795, 626, 195]}\n",
      "ratio: 1.040952207223546\n",
      "Bleu_1: 0.480\n",
      "Bleu_2: 0.288\n",
      "Bleu_3: 0.177\n",
      "Bleu_4: 0.107\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.344\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.246\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.171\n",
      "2022-02-23 19:46:27,136 - INFO: eval_greddy SPIDEr: 0.1707\n",
      "loading annotations into memory...\n",
      "0:00:00.003905\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8492, 'reflen': 9637, 'guess': [8492, 7468, 6444, 5420], 'correct': [4796, 1753, 679, 210]}\n",
      "ratio: 0.8811870914183998\n",
      "Bleu_1: 0.494\n",
      "Bleu_2: 0.318\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.298\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.199\n",
      "2022-02-23 19:46:56,293 - INFO: eval_beam_2 SPIDEr: 0.1990\n",
      "loading annotations into memory...\n",
      "0:00:00.003834\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7629, 'reflen': 9336, 'guess': [7629, 6605, 5581, 4557], 'correct': [4457, 1693, 706, 231]}\n",
      "ratio: 0.8171593830333315\n",
      "Bleu_1: 0.467\n",
      "Bleu_2: 0.309\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.302\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.199\n",
      "2022-02-23 19:47:27,157 - INFO: eval_beam_3 SPIDEr: 0.1993\n",
      "loading annotations into memory...\n",
      "0:00:00.003753\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7043, 'reflen': 9236, 'guess': [7043, 6019, 4995, 3971], 'correct': [4145, 1572, 642, 200]}\n",
      "ratio: 0.7625595495884839\n",
      "Bleu_1: 0.431\n",
      "Bleu_2: 0.287\n",
      "Bleu_3: 0.198\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.140\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.348\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.283\n",
      "computing SPICE score...\n",
      "SPICE: 0.091\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.187\n",
      "2022-02-23 19:48:03,843 - INFO: eval_beam_4 SPIDEr: 0.1868\n",
      "2022-02-23 19:48:11,674 - INFO: | epoch  10 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.28 | loss-text 3.5396\n",
      "2022-02-23 19:48:19,136 - INFO: | epoch  10 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.61 | loss-text 3.5569\n",
      "2022-02-23 19:48:26,622 - INFO: | epoch  10 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.86 | loss-text 3.5527\n",
      "2022-02-23 19:48:34,142 - INFO: | epoch  10 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.20 | loss-text 3.5426\n",
      "2022-02-23 19:48:41,709 - INFO: | epoch  10 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.5206\n",
      "2022-02-23 19:48:49,223 - INFO: | epoch  10 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.13 | loss-text 3.5260\n",
      "2022-02-23 19:48:56,751 - INFO: | epoch  10 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.28 | loss-text 3.5481\n",
      "2022-02-23 19:49:04,275 - INFO: | epoch  10 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.22 | loss-text 3.5597\n",
      "2022-02-23 19:49:11,833 - INFO: | epoch  10 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.58 | loss-text 3.5487\n",
      "2022-02-23 19:49:19,382 - INFO: | epoch  10 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.47 | loss-text 3.5334\n",
      "2022-02-23 19:49:26,950 - INFO: | epoch  10 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.68 | loss-text 3.4902\n",
      "2022-02-23 19:49:34,509 - INFO: | epoch  10 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.5650\n",
      "2022-02-23 19:49:42,135 - INFO: | epoch  10 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.26 | loss-text 3.5442\n",
      "2022-02-23 19:49:49,682 - INFO: | epoch  10 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.47 | loss-text 3.5623\n",
      "2022-02-23 19:49:57,273 - INFO: | epoch  10 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.5520\n",
      "2022-02-23 19:50:04,835 - INFO: | epoch  10 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.61 | loss-text 3.5299\n",
      "2022-02-23 19:50:12,391 - INFO: | epoch  10 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.55 | loss-text 3.5259\n",
      "2022-02-23 19:50:19,988 - INFO: | epoch  10 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.5214\n",
      "2022-02-23 19:50:27,632 - INFO: | epoch  10 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.44 | loss-text 3.5218\n",
      "2022-02-23 19:50:35,223 - INFO: | epoch  10 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.5264\n",
      "2022-02-23 19:50:42,793 - INFO: | epoch  10 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.5806\n",
      "2022-02-23 19:50:50,392 - INFO: | epoch  10 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.5338\n",
      "2022-02-23 19:50:57,989 - INFO: | epoch  10 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.5117\n",
      "2022-02-23 19:51:05,572 - INFO: | epoch  10 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.81 | loss-text 3.5993\n",
      "2022-02-23 19:51:13,176 - INFO: | epoch  10 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.5080\n",
      "2022-02-23 19:51:20,819 - INFO: | epoch  10 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.42 | loss-text 3.4982\n",
      "2022-02-23 19:51:28,395 - INFO: | epoch  10 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.4745\n",
      "2022-02-23 19:51:35,981 - INFO: | epoch  10 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.85 | loss-text 3.5087\n",
      "2022-02-23 19:51:43,567 - INFO: | epoch  10 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.4655\n",
      "2022-02-23 19:51:51,191 - INFO: | epoch  10 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.23 | loss-text 3.5552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003966\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11472, 'reflen': 11031, 'guess': [11472, 10448, 9424, 8400], 'correct': [5475, 1782, 638, 170]}\n",
      "ratio: 1.0399782431328946\n",
      "Bleu_1: 0.477\n",
      "Bleu_2: 0.285\n",
      "Bleu_3: 0.177\n",
      "Bleu_4: 0.103\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.341\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.229\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.164\n",
      "2022-02-23 19:52:34,648 - INFO: eval_greddy SPIDEr: 0.1645\n",
      "loading annotations into memory...\n",
      "0:00:00.004113\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8798, 'reflen': 9760, 'guess': [8798, 7774, 6750, 5726], 'correct': [4961, 1820, 706, 219]}\n",
      "ratio: 0.9014344262294158\n",
      "Bleu_1: 0.505\n",
      "Bleu_2: 0.326\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.296\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.199\n",
      "2022-02-23 19:53:04,196 - INFO: eval_beam_2 SPIDEr: 0.1990\n",
      "loading annotations into memory...\n",
      "0:00:00.003927\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7814, 'reflen': 9374, 'guess': [7814, 6790, 5766, 4742], 'correct': [4571, 1702, 672, 207]}\n",
      "ratio: 0.8335822487731135\n",
      "Bleu_1: 0.479\n",
      "Bleu_2: 0.314\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.295\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.195\n",
      "2022-02-23 19:53:36,291 - INFO: eval_beam_3 SPIDEr: 0.1954\n",
      "loading annotations into memory...\n",
      "0:00:00.003666\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7399, 'reflen': 9243, 'guess': [7399, 6375, 5351, 4327], 'correct': [4431, 1705, 698, 225]}\n",
      "ratio: 0.8004976739153088\n",
      "Bleu_1: 0.467\n",
      "Bleu_2: 0.312\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.306\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.201\n",
      "2022-02-23 19:54:12,052 - INFO: eval_beam_4 SPIDEr: 0.2010\n",
      "2022-02-23 19:54:19,909 - INFO: | epoch  11 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.55 | loss-text 3.4742\n",
      "2022-02-23 19:54:27,373 - INFO: | epoch  11 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.62 | loss-text 3.5568\n",
      "2022-02-23 19:54:34,901 - INFO: | epoch  11 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.27 | loss-text 3.4710\n",
      "2022-02-23 19:54:42,395 - INFO: | epoch  11 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 74.93 | loss-text 3.5322\n",
      "2022-02-23 19:54:49,950 - INFO: | epoch  11 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.54 | loss-text 3.5009\n",
      "2022-02-23 19:54:57,493 - INFO: | epoch  11 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.42 | loss-text 3.4941\n",
      "2022-02-23 19:55:04,980 - INFO: | epoch  11 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 74.87 | loss-text 3.4763\n",
      "2022-02-23 19:55:12,476 - INFO: | epoch  11 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 74.95 | loss-text 3.5035\n",
      "2022-02-23 19:55:19,985 - INFO: | epoch  11 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.09 | loss-text 3.4685\n",
      "2022-02-23 19:55:27,559 - INFO: | epoch  11 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.73 | loss-text 3.5098\n",
      "2022-02-23 19:55:35,091 - INFO: | epoch  11 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.31 | loss-text 3.5024\n",
      "2022-02-23 19:55:42,651 - INFO: | epoch  11 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.60 | loss-text 3.5229\n",
      "2022-02-23 19:55:50,242 - INFO: | epoch  11 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.4912\n",
      "2022-02-23 19:55:57,791 - INFO: | epoch  11 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.48 | loss-text 3.4926\n",
      "2022-02-23 19:56:05,395 - INFO: | epoch  11 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.5000\n",
      "2022-02-23 19:56:12,981 - INFO: | epoch  11 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.85 | loss-text 3.4514\n",
      "2022-02-23 19:56:20,592 - INFO: | epoch  11 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.4555\n",
      "2022-02-23 19:56:28,196 - INFO: | epoch  11 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.5473\n",
      "2022-02-23 19:56:35,798 - INFO: | epoch  11 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.02 | loss-text 3.4707\n",
      "2022-02-23 19:56:43,352 - INFO: | epoch  11 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.54 | loss-text 3.5240\n",
      "2022-02-23 19:56:50,920 - INFO: | epoch  11 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.4862\n",
      "2022-02-23 19:56:58,510 - INFO: | epoch  11 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.5484\n",
      "2022-02-23 19:57:06,075 - INFO: | epoch  11 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.64 | loss-text 3.4905\n",
      "2022-02-23 19:57:13,689 - INFO: | epoch  11 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.13 | loss-text 3.5137\n",
      "2022-02-23 19:57:21,290 - INFO: | epoch  11 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.5038\n",
      "2022-02-23 19:57:28,910 - INFO: | epoch  11 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.19 | loss-text 3.5684\n",
      "2022-02-23 19:57:36,470 - INFO: | epoch  11 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.59 | loss-text 3.5275\n",
      "2022-02-23 19:57:44,066 - INFO: | epoch  11 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.4937\n",
      "2022-02-23 19:57:51,692 - INFO: | epoch  11 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.26 | loss-text 3.5216\n",
      "2022-02-23 19:57:59,317 - INFO: | epoch  11 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.23 | loss-text 3.5480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003887\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10284, 'reflen': 10434, 'guess': [10284, 9260, 8236, 7212], 'correct': [5327, 1815, 671, 195]}\n",
      "ratio: 0.98562392179404\n",
      "Bleu_1: 0.510\n",
      "Bleu_2: 0.314\n",
      "Bleu_3: 0.199\n",
      "Bleu_4: 0.121\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.267\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.184\n",
      "2022-02-23 19:58:40,104 - INFO: eval_greddy SPIDEr: 0.1843\n",
      "loading annotations into memory...\n",
      "0:00:00.003683\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8572, 'reflen': 9632, 'guess': [8572, 7548, 6524, 5500], 'correct': [4866, 1824, 739, 248]}\n",
      "ratio: 0.8899501661128644\n",
      "Bleu_1: 0.502\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.303\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.204\n",
      "2022-02-23 19:59:08,374 - INFO: eval_beam_2 SPIDEr: 0.2037\n",
      "loading annotations into memory...\n",
      "0:00:00.003904\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7759, 'reflen': 9353, 'guess': [7759, 6735, 5711, 4687], 'correct': [4481, 1711, 704, 236]}\n",
      "ratio: 0.8295733989093521\n",
      "Bleu_1: 0.470\n",
      "Bleu_2: 0.312\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.145\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.294\n",
      "computing SPICE score...\n",
      "SPICE: 0.097\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.195\n",
      "2022-02-23 19:59:39,794 - INFO: eval_beam_3 SPIDEr: 0.1952\n",
      "loading annotations into memory...\n",
      "0:00:00.003788\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7333, 'reflen': 9239, 'guess': [7333, 6309, 5285, 4261], 'correct': [4297, 1668, 687, 216]}\n",
      "ratio: 0.7937006169498004\n",
      "Bleu_1: 0.452\n",
      "Bleu_2: 0.304\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.142\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.353\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.289\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.192\n",
      "2022-02-23 20:00:14,433 - INFO: eval_beam_4 SPIDEr: 0.1924\n",
      "2022-02-23 20:00:22,241 - INFO: | epoch  12 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.05 | loss-text 3.4570\n",
      "2022-02-23 20:00:29,733 - INFO: | epoch  12 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.90 | loss-text 3.4979\n",
      "2022-02-23 20:00:37,225 - INFO: | epoch  12 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.92 | loss-text 3.4831\n",
      "2022-02-23 20:00:44,764 - INFO: | epoch  12 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.38 | loss-text 3.5500\n",
      "2022-02-23 20:00:52,241 - INFO: | epoch  12 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 74.76 | loss-text 3.5386\n",
      "2022-02-23 20:00:59,849 - INFO: | epoch  12 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 76.08 | loss-text 3.4860\n",
      "2022-02-23 20:01:07,370 - INFO: | epoch  12 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.20 | loss-text 3.4694\n",
      "2022-02-23 20:01:14,955 - INFO: | epoch  12 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.5089\n",
      "2022-02-23 20:01:22,483 - INFO: | epoch  12 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.27 | loss-text 3.4397\n",
      "2022-02-23 20:01:30,004 - INFO: | epoch  12 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.21 | loss-text 3.4494\n",
      "2022-02-23 20:01:37,586 - INFO: | epoch  12 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.81 | loss-text 3.4337\n",
      "2022-02-23 20:01:45,216 - INFO: | epoch  12 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 76.30 | loss-text 3.5176\n",
      "2022-02-23 20:01:52,782 - INFO: | epoch  12 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.4855\n",
      "2022-02-23 20:02:00,363 - INFO: | epoch  12 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.80 | loss-text 3.4921\n",
      "2022-02-23 20:02:07,942 - INFO: | epoch  12 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.78 | loss-text 3.4558\n",
      "2022-02-23 20:02:15,517 - INFO: | epoch  12 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.74 | loss-text 3.5098\n",
      "2022-02-23 20:02:23,061 - INFO: | epoch  12 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.43 | loss-text 3.4896\n",
      "2022-02-23 20:02:30,712 - INFO: | epoch  12 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.51 | loss-text 3.4601\n",
      "2022-02-23 20:02:38,354 - INFO: | epoch  12 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.41 | loss-text 3.4816\n",
      "2022-02-23 20:02:46,005 - INFO: | epoch  12 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.51 | loss-text 3.4734\n",
      "2022-02-23 20:02:53,619 - INFO: | epoch  12 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.13 | loss-text 3.5068\n",
      "2022-02-23 20:03:01,202 - INFO: | epoch  12 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.82 | loss-text 3.4957\n",
      "2022-02-23 20:03:08,831 - INFO: | epoch  12 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.29 | loss-text 3.4591\n",
      "2022-02-23 20:03:16,416 - INFO: | epoch  12 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.5141\n",
      "2022-02-23 20:03:24,025 - INFO: | epoch  12 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.4859\n",
      "2022-02-23 20:03:31,639 - INFO: | epoch  12 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.14 | loss-text 3.4338\n",
      "2022-02-23 20:03:39,245 - INFO: | epoch  12 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.4412\n",
      "2022-02-23 20:03:46,810 - INFO: | epoch  12 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.64 | loss-text 3.4595\n",
      "2022-02-23 20:03:54,418 - INFO: | epoch  12 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.4901\n",
      "2022-02-23 20:04:02,021 - INFO: | epoch  12 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.02 | loss-text 3.4719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003849\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10928, 'reflen': 10785, 'guess': [10928, 9904, 8880, 7856], 'correct': [5817, 2023, 733, 208]}\n",
      "ratio: 1.0132591562354183\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.288\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.199\n",
      "2022-02-23 20:04:43,215 - INFO: eval_greddy SPIDEr: 0.1986\n",
      "loading annotations into memory...\n",
      "0:00:00.003687\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8904, 'reflen': 9805, 'guess': [8904, 7880, 6856, 5832], 'correct': [5151, 1928, 766, 233]}\n",
      "ratio: 0.9081081081080155\n",
      "Bleu_1: 0.523\n",
      "Bleu_2: 0.340\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.322\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2022-02-23 20:05:12,502 - INFO: eval_beam_2 SPIDEr: 0.2156\n",
      "loading annotations into memory...\n",
      "0:00:00.003897\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8121, 'reflen': 9470, 'guess': [8121, 7097, 6073, 5049], 'correct': [4759, 1811, 739, 241]}\n",
      "ratio: 0.8575501583948407\n",
      "Bleu_1: 0.496\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.223\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.310\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.206\n",
      "2022-02-23 20:05:44,260 - INFO: eval_beam_3 SPIDEr: 0.2057\n",
      "loading annotations into memory...\n",
      "0:00:00.003906\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7283, 'reflen': 9252, 'guess': [7283, 6259, 5235, 4211], 'correct': [4426, 1753, 729, 228]}\n",
      "ratio: 0.7871811500215318\n",
      "Bleu_1: 0.464\n",
      "Bleu_2: 0.315\n",
      "Bleu_3: 0.219\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.308\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.204\n",
      "2022-02-23 20:06:20,019 - INFO: eval_beam_4 SPIDEr: 0.2036\n",
      "2022-02-23 20:06:27,799 - INFO: | epoch  13 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.77 | loss-text 3.4024\n",
      "2022-02-23 20:06:35,344 - INFO: | epoch  13 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.4799\n",
      "2022-02-23 20:06:42,894 - INFO: | epoch  13 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.50 | loss-text 3.4574\n",
      "2022-02-23 20:06:50,465 - INFO: | epoch  13 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.4640\n",
      "2022-02-23 20:06:58,049 - INFO: | epoch  13 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.4706\n",
      "2022-02-23 20:07:05,637 - INFO: | epoch  13 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.88 | loss-text 3.4880\n",
      "2022-02-23 20:07:13,255 - INFO: | epoch  13 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.4518\n",
      "2022-02-23 20:07:20,813 - INFO: | epoch  13 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.4326\n",
      "2022-02-23 20:07:28,372 - INFO: | epoch  13 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.59 | loss-text 3.4576\n",
      "2022-02-23 20:07:35,924 - INFO: | epoch  13 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.51 | loss-text 3.4394\n",
      "2022-02-23 20:07:43,456 - INFO: | epoch  13 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.31 | loss-text 3.4234\n",
      "2022-02-23 20:07:50,922 - INFO: | epoch  13 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 74.65 | loss-text 3.4483\n",
      "2022-02-23 20:07:58,449 - INFO: | epoch  13 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.26 | loss-text 3.4565\n",
      "2022-02-23 20:08:05,998 - INFO: | epoch  13 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.48 | loss-text 3.4393\n",
      "2022-02-23 20:08:13,593 - INFO: | epoch  13 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.4582\n",
      "2022-02-23 20:08:21,237 - INFO: | epoch  13 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.43 | loss-text 3.4280\n",
      "2022-02-23 20:08:28,786 - INFO: | epoch  13 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.48 | loss-text 3.4751\n",
      "2022-02-23 20:08:36,401 - INFO: | epoch  13 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.15 | loss-text 3.4729\n",
      "2022-02-23 20:08:44,003 - INFO: | epoch  13 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.4800\n",
      "2022-02-23 20:08:51,592 - INFO: | epoch  13 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.4843\n",
      "2022-02-23 20:08:59,144 - INFO: | epoch  13 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.51 | loss-text 3.4375\n",
      "2022-02-23 20:09:06,739 - INFO: | epoch  13 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.4514\n",
      "2022-02-23 20:09:14,369 - INFO: | epoch  13 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.28 | loss-text 3.4584\n",
      "2022-02-23 20:09:21,948 - INFO: | epoch  13 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.78 | loss-text 3.4094\n",
      "2022-02-23 20:09:29,482 - INFO: | epoch  13 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.33 | loss-text 3.4887\n",
      "2022-02-23 20:09:37,125 - INFO: | epoch  13 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.42 | loss-text 3.4114\n",
      "2022-02-23 20:09:44,752 - INFO: | epoch  13 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.27 | loss-text 3.4584\n",
      "2022-02-23 20:09:52,406 - INFO: | epoch  13 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.53 | loss-text 3.4843\n",
      "2022-02-23 20:10:00,014 - INFO: | epoch  13 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.4172\n",
      "2022-02-23 20:10:07,648 - INFO: | epoch  13 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.33 | loss-text 3.4284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003902\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10465, 'reflen': 10484, 'guess': [10465, 9441, 8417, 7393], 'correct': [5565, 1901, 685, 199]}\n",
      "ratio: 0.998187714612648\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.205\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.277\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.189\n",
      "2022-02-23 20:10:48,339 - INFO: eval_greddy SPIDEr: 0.1886\n",
      "loading annotations into memory...\n",
      "0:00:00.003766\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8907, 'reflen': 9770, 'guess': [8907, 7883, 6859, 5835], 'correct': [5035, 1798, 692, 216]}\n",
      "ratio: 0.9116683725689957\n",
      "Bleu_1: 0.513\n",
      "Bleu_2: 0.326\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.306\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.203\n",
      "2022-02-23 20:11:17,789 - INFO: eval_beam_2 SPIDEr: 0.2028\n",
      "loading annotations into memory...\n",
      "0:00:00.003620\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8278, 'reflen': 9516, 'guess': [8278, 7254, 6230, 5206], 'correct': [4734, 1733, 694, 233]}\n",
      "ratio: 0.8699033207229014\n",
      "Bleu_1: 0.492\n",
      "Bleu_2: 0.318\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.310\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.204\n",
      "2022-02-23 20:11:49,872 - INFO: eval_beam_3 SPIDEr: 0.2038\n",
      "loading annotations into memory...\n",
      "0:00:00.003898\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7653, 'reflen': 9335, 'guess': [7653, 6629, 5605, 4581], 'correct': [4470, 1646, 662, 222]}\n",
      "ratio: 0.8198178896624724\n",
      "Bleu_1: 0.469\n",
      "Bleu_2: 0.306\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.309\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.203\n",
      "2022-02-23 20:12:27,028 - INFO: eval_beam_4 SPIDEr: 0.2035\n",
      "2022-02-23 20:12:34,742 - INFO: | epoch  14 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.11 | loss-text 3.4774\n",
      "2022-02-23 20:12:42,145 - INFO: | epoch  14 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.02 | loss-text 3.3859\n",
      "2022-02-23 20:12:49,710 - INFO: | epoch  14 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.64 | loss-text 3.3872\n",
      "2022-02-23 20:12:57,252 - INFO: | epoch  14 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.41 | loss-text 3.4513\n",
      "2022-02-23 20:13:04,753 - INFO: | epoch  14 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.01 | loss-text 3.3788\n",
      "2022-02-23 20:13:12,256 - INFO: | epoch  14 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.03 | loss-text 3.4289\n",
      "2022-02-23 20:13:19,782 - INFO: | epoch  14 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.24 | loss-text 3.4792\n",
      "2022-02-23 20:13:27,363 - INFO: | epoch  14 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.80 | loss-text 3.4024\n",
      "2022-02-23 20:13:34,943 - INFO: | epoch  14 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.80 | loss-text 3.4905\n",
      "2022-02-23 20:13:42,524 - INFO: | epoch  14 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.80 | loss-text 3.4316\n",
      "2022-02-23 20:13:50,097 - INFO: | epoch  14 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.4082\n",
      "2022-02-23 20:13:57,668 - INFO: | epoch  14 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.4014\n",
      "2022-02-23 20:14:05,237 - INFO: | epoch  14 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.68 | loss-text 3.4523\n",
      "2022-02-23 20:14:12,865 - INFO: | epoch  14 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.28 | loss-text 3.4362\n",
      "2022-02-23 20:14:20,453 - INFO: | epoch  14 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.4393\n",
      "2022-02-23 20:14:27,989 - INFO: | epoch  14 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.35 | loss-text 3.4060\n",
      "2022-02-23 20:14:35,603 - INFO: | epoch  14 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.14 | loss-text 3.3919\n",
      "2022-02-23 20:14:43,252 - INFO: | epoch  14 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.48 | loss-text 3.4535\n",
      "2022-02-23 20:14:50,856 - INFO: | epoch  14 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.4513\n",
      "2022-02-23 20:14:58,503 - INFO: | epoch  14 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.47 | loss-text 3.4592\n",
      "2022-02-23 20:15:06,070 - INFO: | epoch  14 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.4013\n",
      "2022-02-23 20:15:13,600 - INFO: | epoch  14 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.30 | loss-text 3.4566\n",
      "2022-02-23 20:15:21,161 - INFO: | epoch  14 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.60 | loss-text 3.4734\n",
      "2022-02-23 20:15:28,780 - INFO: | epoch  14 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.18 | loss-text 3.3993\n",
      "2022-02-23 20:15:36,413 - INFO: | epoch  14 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.32 | loss-text 3.4016\n",
      "2022-02-23 20:15:43,992 - INFO: | epoch  14 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.79 | loss-text 3.4788\n",
      "2022-02-23 20:15:51,599 - INFO: | epoch  14 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.4076\n",
      "2022-02-23 20:15:59,219 - INFO: | epoch  14 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.19 | loss-text 3.4518\n",
      "2022-02-23 20:16:06,830 - INFO: | epoch  14 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.4537\n",
      "2022-02-23 20:16:14,413 - INFO: | epoch  14 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.78 | loss-text 3.4602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003691\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10149, 'reflen': 10325, 'guess': [10149, 9125, 8101, 7077], 'correct': [5536, 1903, 701, 214]}\n",
      "ratio: 0.9829539951572898\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.293\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.198\n",
      "2022-02-23 20:16:55,540 - INFO: eval_greddy SPIDEr: 0.1983\n",
      "loading annotations into memory...\n",
      "0:00:00.003935\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8420, 'reflen': 9495, 'guess': [8420, 7396, 6372, 5348], 'correct': [4949, 1809, 712, 239]}\n",
      "ratio: 0.8867825171141772\n",
      "Bleu_1: 0.517\n",
      "Bleu_2: 0.334\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.311\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.207\n",
      "2022-02-23 20:17:23,530 - INFO: eval_beam_2 SPIDEr: 0.2070\n",
      "loading annotations into memory...\n",
      "0:00:00.003660\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7816, 'reflen': 9307, 'guess': [7816, 6792, 5768, 4744], 'correct': [4663, 1792, 727, 248]}\n",
      "ratio: 0.8397980015041538\n",
      "Bleu_1: 0.493\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.224\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.149\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.316\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.209\n",
      "2022-02-23 20:17:55,154 - INFO: eval_beam_3 SPIDEr: 0.2089\n",
      "loading annotations into memory...\n",
      "0:00:00.004032\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7339, 'reflen': 9228, 'guess': [7339, 6315, 5291, 4267], 'correct': [4441, 1734, 699, 225]}\n",
      "ratio: 0.7952969224099701\n",
      "Bleu_1: 0.468\n",
      "Bleu_2: 0.315\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.308\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.204\n",
      "2022-02-23 20:18:31,105 - INFO: eval_beam_4 SPIDEr: 0.2036\n",
      "2022-02-23 20:18:38,863 - INFO: | epoch  15 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.55 | loss-text 3.4195\n",
      "2022-02-23 20:18:46,352 - INFO: | epoch  15 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.88 | loss-text 3.3626\n",
      "2022-02-23 20:18:53,922 - INFO: | epoch  15 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.3922\n",
      "2022-02-23 20:19:01,436 - INFO: | epoch  15 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.14 | loss-text 3.4291\n",
      "2022-02-23 20:19:08,944 - INFO: | epoch  15 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.06 | loss-text 3.3896\n",
      "2022-02-23 20:19:16,456 - INFO: | epoch  15 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.11 | loss-text 3.3656\n",
      "2022-02-23 20:19:24,027 - INFO: | epoch  15 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.3832\n",
      "2022-02-23 20:19:31,651 - INFO: | epoch  15 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.4098\n",
      "2022-02-23 20:19:39,209 - INFO: | epoch  15 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.4124\n",
      "2022-02-23 20:19:46,800 - INFO: | epoch  15 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.4522\n",
      "2022-02-23 20:19:54,395 - INFO: | epoch  15 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.3961\n",
      "2022-02-23 20:20:01,906 - INFO: | epoch  15 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.10 | loss-text 3.4332\n",
      "2022-02-23 20:20:09,463 - INFO: | epoch  15 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.4389\n",
      "2022-02-23 20:20:17,045 - INFO: | epoch  15 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.81 | loss-text 3.4241\n",
      "2022-02-23 20:20:24,648 - INFO: | epoch  15 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.02 | loss-text 3.4038\n",
      "2022-02-23 20:20:32,162 - INFO: | epoch  15 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.13 | loss-text 3.4200\n",
      "2022-02-23 20:20:39,702 - INFO: | epoch  15 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.4434\n",
      "2022-02-23 20:20:47,290 - INFO: | epoch  15 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.4051\n",
      "2022-02-23 20:20:54,880 - INFO: | epoch  15 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.4232\n",
      "2022-02-23 20:21:02,572 - INFO: | epoch  15 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.91 | loss-text 3.4494\n",
      "2022-02-23 20:21:10,133 - INFO: | epoch  15 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.60 | loss-text 3.4239\n",
      "2022-02-23 20:21:17,716 - INFO: | epoch  15 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.3543\n",
      "2022-02-23 20:21:25,344 - INFO: | epoch  15 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.27 | loss-text 3.3826\n",
      "2022-02-23 20:21:32,913 - INFO: | epoch  15 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.4056\n",
      "2022-02-23 20:21:40,476 - INFO: | epoch  15 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.4094\n",
      "2022-02-23 20:21:48,090 - INFO: | epoch  15 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.13 | loss-text 3.4206\n",
      "2022-02-23 20:21:55,692 - INFO: | epoch  15 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.02 | loss-text 3.4204\n",
      "2022-02-23 20:22:03,314 - INFO: | epoch  15 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.21 | loss-text 3.4539\n",
      "2022-02-23 20:22:10,911 - INFO: | epoch  15 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.4488\n",
      "2022-02-23 20:22:18,529 - INFO: | epoch  15 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.3751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003861\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10176, 'reflen': 10385, 'guess': [10176, 9152, 8128, 7104], 'correct': [5603, 2007, 781, 255]}\n",
      "ratio: 0.979874819451037\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.340\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.317\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.211\n",
      "2022-02-23 20:23:00,053 - INFO: eval_greddy SPIDEr: 0.2109\n",
      "loading annotations into memory...\n",
      "0:00:00.003770\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8175, 'reflen': 9429, 'guess': [8175, 7151, 6127, 5103], 'correct': [4871, 1813, 734, 247]}\n",
      "ratio: 0.8670060451796726\n",
      "Bleu_1: 0.511\n",
      "Bleu_2: 0.333\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.213\n",
      "2022-02-23 20:23:27,882 - INFO: eval_beam_2 SPIDEr: 0.2132\n",
      "loading annotations into memory...\n",
      "0:00:00.003911\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7461, 'reflen': 9294, 'guess': [7461, 6437, 5413, 4389], 'correct': [4497, 1673, 681, 229]}\n",
      "ratio: 0.8027759845060466\n",
      "Bleu_1: 0.471\n",
      "Bleu_2: 0.310\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.145\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.309\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.202\n",
      "2022-02-23 20:23:59,388 - INFO: eval_beam_3 SPIDEr: 0.2020\n",
      "loading annotations into memory...\n",
      "0:00:00.003937\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7151, 'reflen': 9220, 'guess': [7151, 6127, 5103, 4079], 'correct': [4342, 1656, 674, 230]}\n",
      "ratio: 0.7755965292840807\n",
      "Bleu_1: 0.455\n",
      "Bleu_2: 0.303\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.144\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.308\n",
      "computing SPICE score...\n",
      "SPICE: 0.093\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.200\n",
      "2022-02-23 20:24:33,416 - INFO: eval_beam_4 SPIDEr: 0.2002\n",
      "2022-02-23 20:24:41,191 - INFO: | epoch  16 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.72 | loss-text 3.4509\n",
      "2022-02-23 20:24:48,752 - INFO: | epoch  16 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.60 | loss-text 3.3510\n",
      "2022-02-23 20:24:56,306 - INFO: | epoch  16 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.54 | loss-text 3.3385\n",
      "2022-02-23 20:25:03,889 - INFO: | epoch  16 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.80 | loss-text 3.3979\n",
      "2022-02-23 20:25:11,335 - INFO: | epoch  16 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 74.45 | loss-text 3.3220\n",
      "2022-02-23 20:25:18,980 - INFO: | epoch  16 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 76.45 | loss-text 3.3697\n",
      "2022-02-23 20:25:26,496 - INFO: | epoch  16 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.15 | loss-text 3.3930\n",
      "2022-02-23 20:25:34,037 - INFO: | epoch  16 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.4121\n",
      "2022-02-23 20:25:41,564 - INFO: | epoch  16 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.26 | loss-text 3.4372\n",
      "2022-02-23 20:25:49,186 - INFO: | epoch  16 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 76.22 | loss-text 3.3721\n",
      "2022-02-23 20:25:56,755 - INFO: | epoch  16 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.4044\n",
      "2022-02-23 20:26:04,313 - INFO: | epoch  16 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.3659\n",
      "2022-02-23 20:26:11,879 - INFO: | epoch  16 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.3998\n",
      "2022-02-23 20:26:19,449 - INFO: | epoch  16 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.4442\n",
      "2022-02-23 20:26:27,036 - INFO: | epoch  16 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.4005\n",
      "2022-02-23 20:26:34,634 - INFO: | epoch  16 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.3627\n",
      "2022-02-23 20:26:42,214 - INFO: | epoch  16 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.79 | loss-text 3.3483\n",
      "2022-02-23 20:26:49,826 - INFO: | epoch  16 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.3990\n",
      "2022-02-23 20:26:57,437 - INFO: | epoch  16 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.10 | loss-text 3.4660\n",
      "2022-02-23 20:27:05,012 - INFO: | epoch  16 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.4116\n",
      "2022-02-23 20:27:12,598 - INFO: | epoch  16 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.4203\n",
      "2022-02-23 20:27:20,217 - INFO: | epoch  16 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.18 | loss-text 3.4147\n",
      "2022-02-23 20:27:27,846 - INFO: | epoch  16 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.28 | loss-text 3.3797\n",
      "2022-02-23 20:27:35,434 - INFO: | epoch  16 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.88 | loss-text 3.4370\n",
      "2022-02-23 20:27:43,047 - INFO: | epoch  16 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.12 | loss-text 3.4405\n",
      "2022-02-23 20:27:50,625 - INFO: | epoch  16 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.77 | loss-text 3.4225\n",
      "2022-02-23 20:27:58,284 - INFO: | epoch  16 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.59 | loss-text 3.3668\n",
      "2022-02-23 20:28:05,876 - INFO: | epoch  16 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.3204\n",
      "2022-02-23 20:28:13,465 - INFO: | epoch  16 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 75.88 | loss-text 3.4034\n",
      "2022-02-23 20:28:21,027 - INFO: | epoch  16 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.3588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003812\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9867, 'reflen': 10173, 'guess': [9867, 8843, 7819, 6795], 'correct': [5257, 1846, 684, 215]}\n",
      "ratio: 0.9699203774696775\n",
      "Bleu_1: 0.517\n",
      "Bleu_2: 0.323\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.351\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.291\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.197\n",
      "2022-02-23 20:29:02,235 - INFO: eval_greddy SPIDEr: 0.1973\n",
      "loading annotations into memory...\n",
      "0:00:00.003707\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8279, 'reflen': 9446, 'guess': [8279, 7255, 6231, 5207], 'correct': [4758, 1712, 677, 229]}\n",
      "ratio: 0.8764556425999496\n",
      "Bleu_1: 0.499\n",
      "Bleu_2: 0.320\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.313\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.207\n",
      "2022-02-23 20:29:29,359 - INFO: eval_beam_2 SPIDEr: 0.2069\n",
      "loading annotations into memory...\n",
      "0:00:00.003970\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7650, 'reflen': 9303, 'guess': [7650, 6626, 5602, 4578], 'correct': [4473, 1674, 677, 236]}\n",
      "ratio: 0.8223153821347068\n",
      "Bleu_1: 0.471\n",
      "Bleu_2: 0.310\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.318\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.209\n",
      "2022-02-23 20:30:01,476 - INFO: eval_beam_3 SPIDEr: 0.2093\n",
      "loading annotations into memory...\n",
      "0:00:00.003907\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7301, 'reflen': 9234, 'guess': [7301, 6277, 5253, 4229], 'correct': [4292, 1628, 654, 222]}\n",
      "ratio: 0.790664933939702\n",
      "Bleu_1: 0.451\n",
      "Bleu_2: 0.300\n",
      "Bleu_3: 0.205\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.313\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.205\n",
      "2022-02-23 20:30:36,018 - INFO: eval_beam_4 SPIDEr: 0.2054\n",
      "2022-02-23 20:30:43,853 - INFO: | epoch  17 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.32 | loss-text 3.3687\n",
      "2022-02-23 20:30:51,364 - INFO: | epoch  17 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.10 | loss-text 3.3188\n",
      "2022-02-23 20:30:58,837 - INFO: | epoch  17 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.73 | loss-text 3.4094\n",
      "2022-02-23 20:31:06,383 - INFO: | epoch  17 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.45 | loss-text 3.3388\n",
      "2022-02-23 20:31:13,913 - INFO: | epoch  17 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.29 | loss-text 3.3795\n",
      "2022-02-23 20:31:21,438 - INFO: | epoch  17 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.24 | loss-text 3.3904\n",
      "2022-02-23 20:31:28,925 - INFO: | epoch  17 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 74.87 | loss-text 3.3779\n",
      "2022-02-23 20:31:36,459 - INFO: | epoch  17 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.34 | loss-text 3.3666\n",
      "2022-02-23 20:31:43,987 - INFO: | epoch  17 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.28 | loss-text 3.3493\n",
      "2022-02-23 20:31:51,517 - INFO: | epoch  17 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.29 | loss-text 3.4036\n",
      "2022-02-23 20:31:59,029 - INFO: | epoch  17 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.11 | loss-text 3.4094\n",
      "2022-02-23 20:32:06,548 - INFO: | epoch  17 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.18 | loss-text 3.3791\n",
      "2022-02-23 20:32:14,112 - INFO: | epoch  17 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.64 | loss-text 3.3926\n",
      "2022-02-23 20:32:21,730 - INFO: | epoch  17 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.4086\n",
      "2022-02-23 20:32:29,275 - INFO: | epoch  17 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.3115\n",
      "2022-02-23 20:32:36,832 - INFO: | epoch  17 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.3952\n",
      "2022-02-23 20:32:44,371 - INFO: | epoch  17 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.38 | loss-text 3.3627\n",
      "2022-02-23 20:32:51,965 - INFO: | epoch  17 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.3804\n",
      "2022-02-23 20:32:59,602 - INFO: | epoch  17 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.36 | loss-text 3.3331\n",
      "2022-02-23 20:33:07,236 - INFO: | epoch  17 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.34 | loss-text 3.3746\n",
      "2022-02-23 20:33:14,861 - INFO: | epoch  17 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.25 | loss-text 3.3436\n",
      "2022-02-23 20:33:22,507 - INFO: | epoch  17 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.45 | loss-text 3.3918\n",
      "2022-02-23 20:33:30,091 - INFO: | epoch  17 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.3570\n",
      "2022-02-23 20:33:37,697 - INFO: | epoch  17 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.05 | loss-text 3.3871\n",
      "2022-02-23 20:33:45,335 - INFO: | epoch  17 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.37 | loss-text 3.3799\n",
      "2022-02-23 20:33:52,970 - INFO: | epoch  17 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.34 | loss-text 3.4206\n",
      "2022-02-23 20:34:00,563 - INFO: | epoch  17 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.93 | loss-text 3.3650\n",
      "2022-02-23 20:34:08,167 - INFO: | epoch  17 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.4084\n",
      "2022-02-23 20:34:15,775 - INFO: | epoch  17 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.3978\n",
      "2022-02-23 20:34:23,395 - INFO: | epoch  17 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.19 | loss-text 3.3656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003740\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10006, 'reflen': 10302, 'guess': [10006, 8982, 7958, 6934], 'correct': [5411, 1902, 695, 219]}\n",
      "ratio: 0.9712677150067005\n",
      "Bleu_1: 0.525\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.302\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.203\n",
      "2022-02-23 20:35:03,504 - INFO: eval_greddy SPIDEr: 0.2034\n",
      "loading annotations into memory...\n",
      "0:00:00.003685\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8411, 'reflen': 9537, 'guess': [8411, 7387, 6363, 5339], 'correct': [4929, 1808, 720, 247]}\n",
      "ratio: 0.8819335220718378\n",
      "Bleu_1: 0.513\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.333\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2022-02-23 20:35:31,438 - INFO: eval_beam_2 SPIDEr: 0.2174\n",
      "loading annotations into memory...\n",
      "0:00:00.003954\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7904, 'reflen': 9373, 'guess': [7904, 6880, 5856, 4832], 'correct': [4684, 1765, 728, 265]}\n",
      "ratio: 0.8432732316226562\n",
      "Bleu_1: 0.492\n",
      "Bleu_2: 0.324\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.328\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2022-02-23 20:36:03,059 - INFO: eval_beam_3 SPIDEr: 0.2139\n",
      "loading annotations into memory...\n",
      "0:00:00.003885\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7378, 'reflen': 9268, 'guess': [7378, 6354, 5330, 4306], 'correct': [4433, 1685, 697, 242]}\n",
      "ratio: 0.7960725075527841\n",
      "Bleu_1: 0.465\n",
      "Bleu_2: 0.309\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.319\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.207\n",
      "2022-02-23 20:36:37,967 - INFO: eval_beam_4 SPIDEr: 0.2071\n",
      "2022-02-23 20:36:45,699 - INFO: | epoch  18 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.29 | loss-text 3.3666\n",
      "2022-02-23 20:36:53,204 - INFO: | epoch  18 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.04 | loss-text 3.3374\n",
      "2022-02-23 20:37:00,721 - INFO: | epoch  18 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.16 | loss-text 3.3433\n",
      "2022-02-23 20:37:08,223 - INFO: | epoch  18 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.01 | loss-text 3.4060\n",
      "2022-02-23 20:37:15,747 - INFO: | epoch  18 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.24 | loss-text 3.3390\n",
      "2022-02-23 20:37:23,321 - INFO: | epoch  18 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.3708\n",
      "2022-02-23 20:37:30,856 - INFO: | epoch  18 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.35 | loss-text 3.3797\n",
      "2022-02-23 20:37:38,437 - INFO: | epoch  18 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.80 | loss-text 3.3978\n",
      "2022-02-23 20:37:45,970 - INFO: | epoch  18 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.32 | loss-text 3.3274\n",
      "2022-02-23 20:37:53,571 - INFO: | epoch  18 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.3074\n",
      "2022-02-23 20:38:01,148 - INFO: | epoch  18 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.77 | loss-text 3.3605\n",
      "2022-02-23 20:38:08,736 - INFO: | epoch  18 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.3656\n",
      "2022-02-23 20:38:16,369 - INFO: | epoch  18 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.32 | loss-text 3.2966\n",
      "2022-02-23 20:38:23,913 - INFO: | epoch  18 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.3652\n",
      "2022-02-23 20:38:31,481 - INFO: | epoch  18 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.3905\n",
      "2022-02-23 20:38:39,049 - INFO: | epoch  18 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.68 | loss-text 3.4001\n",
      "2022-02-23 20:38:46,664 - INFO: | epoch  18 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.14 | loss-text 3.3693\n",
      "2022-02-23 20:38:54,263 - INFO: | epoch  18 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.3266\n",
      "2022-02-23 20:39:01,834 - INFO: | epoch  18 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.3690\n",
      "2022-02-23 20:39:09,378 - INFO: | epoch  18 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.43 | loss-text 3.3703\n",
      "2022-02-23 20:39:16,989 - INFO: | epoch  18 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.10 | loss-text 3.3299\n",
      "2022-02-23 20:39:24,634 - INFO: | epoch  18 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.45 | loss-text 3.3566\n",
      "2022-02-23 20:39:32,239 - INFO: | epoch  18 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.3351\n",
      "2022-02-23 20:39:39,789 - INFO: | epoch  18 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.49 | loss-text 3.4541\n",
      "2022-02-23 20:39:47,385 - INFO: | epoch  18 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.3649\n",
      "2022-02-23 20:39:55,024 - INFO: | epoch  18 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.38 | loss-text 3.3321\n",
      "2022-02-23 20:40:02,689 - INFO: | epoch  18 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.64 | loss-text 3.3336\n",
      "2022-02-23 20:40:10,297 - INFO: | epoch  18 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.08 | loss-text 3.4035\n",
      "2022-02-23 20:40:17,912 - INFO: | epoch  18 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.14 | loss-text 3.3272\n",
      "2022-02-23 20:40:25,547 - INFO: | epoch  18 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.34 | loss-text 3.3517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003760\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10543, 'reflen': 10620, 'guess': [10543, 9519, 8495, 7471], 'correct': [5423, 1818, 629, 190]}\n",
      "ratio: 0.9927495291901136\n",
      "Bleu_1: 0.511\n",
      "Bleu_2: 0.311\n",
      "Bleu_3: 0.192\n",
      "Bleu_4: 0.116\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.348\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.281\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.191\n",
      "2022-02-23 20:41:07,688 - INFO: eval_greddy SPIDEr: 0.1912\n",
      "loading annotations into memory...\n",
      "0:00:00.003798\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8907, 'reflen': 9718, 'guess': [8907, 7883, 6859, 5835], 'correct': [5012, 1798, 684, 232]}\n",
      "ratio: 0.9165466145296443\n",
      "Bleu_1: 0.514\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.321\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.212\n",
      "2022-02-23 20:41:37,422 - INFO: eval_beam_2 SPIDEr: 0.2120\n",
      "loading annotations into memory...\n",
      "0:00:00.003674\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8187, 'reflen': 9447, 'guess': [8187, 7163, 6139, 5115], 'correct': [4762, 1773, 717, 269]}\n",
      "ratio: 0.8666243251825059\n",
      "Bleu_1: 0.499\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.331\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2022-02-23 20:42:09,983 - INFO: eval_beam_3 SPIDEr: 0.2154\n",
      "loading annotations into memory...\n",
      "0:00:00.003886\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7669, 'reflen': 9289, 'guess': [7669, 6645, 5621, 4597], 'correct': [4521, 1701, 703, 263]}\n",
      "ratio: 0.8256001722466545\n",
      "Bleu_1: 0.477\n",
      "Bleu_2: 0.314\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.323\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.210\n",
      "2022-02-23 20:42:46,335 - INFO: eval_beam_4 SPIDEr: 0.2101\n",
      "2022-02-23 20:42:54,096 - INFO: | epoch  19 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.58 | loss-text 3.4086\n",
      "2022-02-23 20:43:01,610 - INFO: | epoch  19 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.13 | loss-text 3.3515\n",
      "2022-02-23 20:43:09,134 - INFO: | epoch  19 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.23 | loss-text 3.3758\n",
      "2022-02-23 20:43:16,696 - INFO: | epoch  19 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.2924\n",
      "2022-02-23 20:43:24,251 - INFO: | epoch  19 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.54 | loss-text 3.2895\n",
      "2022-02-23 20:43:31,784 - INFO: | epoch  19 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.32 | loss-text 3.3095\n",
      "2022-02-23 20:43:39,324 - INFO: | epoch  19 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.3381\n",
      "2022-02-23 20:43:46,912 - INFO: | epoch  19 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.3710\n",
      "2022-02-23 20:43:54,498 - INFO: | epoch  19 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.3696\n",
      "2022-02-23 20:44:02,079 - INFO: | epoch  19 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.80 | loss-text 3.3348\n",
      "2022-02-23 20:44:09,636 - INFO: | epoch  19 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.56 | loss-text 3.3232\n",
      "2022-02-23 20:44:17,218 - INFO: | epoch  19 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.82 | loss-text 3.3192\n",
      "2022-02-23 20:44:24,786 - INFO: | epoch  19 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.2778\n",
      "2022-02-23 20:44:32,352 - INFO: | epoch  19 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.3672\n",
      "2022-02-23 20:44:39,908 - INFO: | epoch  19 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.55 | loss-text 3.3041\n",
      "2022-02-23 20:44:47,509 - INFO: | epoch  19 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.3616\n",
      "2022-02-23 20:44:55,111 - INFO: | epoch  19 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.3170\n",
      "2022-02-23 20:45:02,735 - INFO: | epoch  19 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.3508\n",
      "2022-02-23 20:45:10,310 - INFO: | epoch  19 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.74 | loss-text 3.3065\n",
      "2022-02-23 20:45:17,874 - INFO: | epoch  19 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.63 | loss-text 3.2857\n",
      "2022-02-23 20:45:25,469 - INFO: | epoch  19 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.3423\n",
      "2022-02-23 20:45:33,057 - INFO: | epoch  19 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.3651\n",
      "2022-02-23 20:45:40,637 - INFO: | epoch  19 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.79 | loss-text 3.4243\n",
      "2022-02-23 20:45:48,262 - INFO: | epoch  19 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.2964\n",
      "2022-02-23 20:45:55,865 - INFO: | epoch  19 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.3144\n",
      "2022-02-23 20:46:03,465 - INFO: | epoch  19 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.99 | loss-text 3.3333\n",
      "2022-02-23 20:46:11,035 - INFO: | epoch  19 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.3124\n",
      "2022-02-23 20:46:18,626 - INFO: | epoch  19 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.3273\n",
      "2022-02-23 20:46:26,242 - INFO: | epoch  19 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.16 | loss-text 3.3576\n",
      "2022-02-23 20:46:33,751 - INFO: | epoch  19 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.09 | loss-text 3.3953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003694\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9735, 'reflen': 10164, 'guess': [9735, 8711, 7687, 6663], 'correct': [5310, 1830, 668, 209]}\n",
      "ratio: 0.9577922077921135\n",
      "Bleu_1: 0.522\n",
      "Bleu_2: 0.324\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.301\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.200\n",
      "2022-02-23 20:47:15,177 - INFO: eval_greddy SPIDEr: 0.2004\n",
      "loading annotations into memory...\n",
      "0:00:00.003940\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8325, 'reflen': 9482, 'guess': [8325, 7301, 6277, 5253], 'correct': [4813, 1759, 698, 240]}\n",
      "ratio: 0.8779793292553387\n",
      "Bleu_1: 0.503\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.325\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.212\n",
      "2022-02-23 20:47:42,868 - INFO: eval_beam_2 SPIDEr: 0.2117\n",
      "loading annotations into memory...\n",
      "0:00:00.004134\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7789, 'reflen': 9328, 'guess': [7789, 6765, 5741, 4717], 'correct': [4582, 1724, 692, 239]}\n",
      "ratio: 0.835012864493907\n",
      "Bleu_1: 0.483\n",
      "Bleu_2: 0.318\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.149\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.329\n",
      "computing SPICE score...\n",
      "SPICE: 0.097\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.213\n",
      "2022-02-23 20:48:13,886 - INFO: eval_beam_3 SPIDEr: 0.2130\n",
      "loading annotations into memory...\n",
      "0:00:00.004066\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7343, 'reflen': 9231, 'guess': [7343, 6319, 5295, 4271], 'correct': [4352, 1641, 661, 217]}\n",
      "ratio: 0.7954717798720836\n",
      "Bleu_1: 0.458\n",
      "Bleu_2: 0.303\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.318\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.206\n",
      "2022-02-23 20:48:49,254 - INFO: eval_beam_4 SPIDEr: 0.2064\n",
      "2022-02-23 20:48:57,057 - INFO: | epoch  20 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.99 | loss-text 3.2693\n",
      "2022-02-23 20:49:04,576 - INFO: | epoch  20 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.18 | loss-text 3.3350\n",
      "2022-02-23 20:49:12,097 - INFO: | epoch  20 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.21 | loss-text 3.3559\n",
      "2022-02-23 20:49:19,625 - INFO: | epoch  20 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.27 | loss-text 3.2991\n",
      "2022-02-23 20:49:27,138 - INFO: | epoch  20 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.12 | loss-text 3.3642\n",
      "2022-02-23 20:49:34,645 - INFO: | epoch  20 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.07 | loss-text 3.3815\n",
      "2022-02-23 20:49:42,202 - INFO: | epoch  20 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.56 | loss-text 3.3082\n",
      "2022-02-23 20:49:49,731 - INFO: | epoch  20 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.29 | loss-text 3.3339\n",
      "2022-02-23 20:49:57,364 - INFO: | epoch  20 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 76.32 | loss-text 3.2794\n",
      "2022-02-23 20:50:04,947 - INFO: | epoch  20 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.82 | loss-text 3.3927\n",
      "2022-02-23 20:50:12,520 - INFO: | epoch  20 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.3164\n",
      "2022-02-23 20:50:20,093 - INFO: | epoch  20 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.3077\n",
      "2022-02-23 20:50:27,731 - INFO: | epoch  20 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.38 | loss-text 3.3674\n",
      "2022-02-23 20:50:35,376 - INFO: | epoch  20 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.44 | loss-text 3.2987\n",
      "2022-02-23 20:50:42,939 - INFO: | epoch  20 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.3076\n",
      "2022-02-23 20:50:50,578 - INFO: | epoch  20 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.38 | loss-text 3.3459\n",
      "2022-02-23 20:50:58,201 - INFO: | epoch  20 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.22 | loss-text 3.3192\n",
      "2022-02-23 20:51:05,831 - INFO: | epoch  20 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.29 | loss-text 3.3443\n",
      "2022-02-23 20:51:13,403 - INFO: | epoch  20 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.3457\n",
      "2022-02-23 20:51:20,945 - INFO: | epoch  20 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.3529\n",
      "2022-02-23 20:51:28,559 - INFO: | epoch  20 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.13 | loss-text 3.3217\n",
      "2022-02-23 20:51:36,155 - INFO: | epoch  20 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.3712\n",
      "2022-02-23 20:51:43,746 - INFO: | epoch  20 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.2985\n",
      "2022-02-23 20:51:51,347 - INFO: | epoch  20 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.3470\n",
      "2022-02-23 20:51:58,910 - INFO: | epoch  20 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.63 | loss-text 3.3236\n",
      "2022-02-23 20:52:06,540 - INFO: | epoch  20 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.29 | loss-text 3.3265\n",
      "2022-02-23 20:52:14,182 - INFO: | epoch  20 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.41 | loss-text 3.3401\n",
      "2022-02-23 20:52:21,786 - INFO: | epoch  20 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.3627\n",
      "2022-02-23 20:52:29,393 - INFO: | epoch  20 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.2668\n",
      "2022-02-23 20:52:37,062 - INFO: | epoch  20 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.68 | loss-text 3.3542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004058\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10639, 'reflen': 10621, 'guess': [10639, 9615, 8591, 7567], 'correct': [5624, 1939, 703, 224]}\n",
      "ratio: 1.0016947556726294\n",
      "Bleu_1: 0.529\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.303\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.205\n",
      "2022-02-23 20:53:18,500 - INFO: eval_greddy SPIDEr: 0.2047\n",
      "loading annotations into memory...\n",
      "0:00:00.003754\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8444, 'reflen': 9554, 'guess': [8444, 7420, 6396, 5372], 'correct': [4929, 1816, 720, 243]}\n",
      "ratio: 0.8838182960015821\n",
      "Bleu_1: 0.512\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.333\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.218\n",
      "2022-02-23 20:53:48,355 - INFO: eval_beam_2 SPIDEr: 0.2184\n",
      "loading annotations into memory...\n",
      "0:00:00.003891\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7875, 'reflen': 9356, 'guess': [7875, 6851, 5827, 4803], 'correct': [4747, 1843, 758, 250]}\n",
      "ratio: 0.8417058572038433\n",
      "Bleu_1: 0.499\n",
      "Bleu_2: 0.334\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.340\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.222\n",
      "2022-02-23 20:54:21,534 - INFO: eval_beam_3 SPIDEr: 0.2218\n",
      "loading annotations into memory...\n",
      "0:00:00.003954\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7450, 'reflen': 9269, 'guess': [7450, 6426, 5402, 4378], 'correct': [4492, 1742, 711, 230]}\n",
      "ratio: 0.8037544503181784\n",
      "Bleu_1: 0.472\n",
      "Bleu_2: 0.317\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.213\n",
      "2022-02-23 20:54:58,262 - INFO: eval_beam_4 SPIDEr: 0.2128\n",
      "2022-02-23 20:55:06,065 - INFO: | epoch  21 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.00 | loss-text 3.3198\n",
      "2022-02-23 20:55:13,535 - INFO: | epoch  21 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.69 | loss-text 3.3682\n",
      "2022-02-23 20:55:21,039 - INFO: | epoch  21 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.03 | loss-text 3.2714\n",
      "2022-02-23 20:55:28,511 - INFO: | epoch  21 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 74.72 | loss-text 3.2842\n",
      "2022-02-23 20:55:36,041 - INFO: | epoch  21 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.29 | loss-text 3.3487\n",
      "2022-02-23 20:55:43,583 - INFO: | epoch  21 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.41 | loss-text 3.3112\n",
      "2022-02-23 20:55:51,134 - INFO: | epoch  21 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.51 | loss-text 3.2923\n",
      "2022-02-23 20:55:58,711 - INFO: | epoch  21 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.77 | loss-text 3.3190\n",
      "2022-02-23 20:56:06,279 - INFO: | epoch  21 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.2862\n",
      "2022-02-23 20:56:13,894 - INFO: | epoch  21 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 76.15 | loss-text 3.3194\n",
      "2022-02-23 20:56:21,435 - INFO: | epoch  21 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.3551\n",
      "2022-02-23 20:56:28,972 - INFO: | epoch  21 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.36 | loss-text 3.3493\n",
      "2022-02-23 20:56:36,560 - INFO: | epoch  21 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.3204\n",
      "2022-02-23 20:56:44,132 - INFO: | epoch  21 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.3100\n",
      "2022-02-23 20:56:51,720 - INFO: | epoch  21 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.3026\n",
      "2022-02-23 20:56:59,312 - INFO: | epoch  21 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.2685\n",
      "2022-02-23 20:57:06,937 - INFO: | epoch  21 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.2816\n",
      "2022-02-23 20:57:14,465 - INFO: | epoch  21 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.27 | loss-text 3.3118\n",
      "2022-02-23 20:57:22,069 - INFO: | epoch  21 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.2811\n",
      "2022-02-23 20:57:29,659 - INFO: | epoch  21 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.3073\n",
      "2022-02-23 20:57:37,258 - INFO: | epoch  21 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.3303\n",
      "2022-02-23 20:57:44,868 - INFO: | epoch  21 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.10 | loss-text 3.3110\n",
      "2022-02-23 20:57:52,458 - INFO: | epoch  21 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.3485\n",
      "2022-02-23 20:57:59,992 - INFO: | epoch  21 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.33 | loss-text 3.3349\n",
      "2022-02-23 20:58:07,578 - INFO: | epoch  21 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.85 | loss-text 3.2928\n",
      "2022-02-23 20:58:15,139 - INFO: | epoch  21 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.61 | loss-text 3.3040\n",
      "2022-02-23 20:58:22,739 - INFO: | epoch  21 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.99 | loss-text 3.3030\n",
      "2022-02-23 20:58:30,372 - INFO: | epoch  21 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.32 | loss-text 3.3033\n",
      "2022-02-23 20:58:37,961 - INFO: | epoch  21 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 75.88 | loss-text 3.3085\n",
      "2022-02-23 20:58:45,568 - INFO: | epoch  21 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.2824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003930\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10508, 'reflen': 10567, 'guess': [10508, 9484, 8460, 7436], 'correct': [5472, 1833, 650, 195]}\n",
      "ratio: 0.9944165799185204\n",
      "Bleu_1: 0.518\n",
      "Bleu_2: 0.315\n",
      "Bleu_3: 0.197\n",
      "Bleu_4: 0.119\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.353\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.286\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.196\n",
      "2022-02-23 20:59:27,226 - INFO: eval_greddy SPIDEr: 0.1961\n",
      "loading annotations into memory...\n",
      "0:00:00.003771\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8807, 'reflen': 9668, 'guess': [8807, 7783, 6759, 5735], 'correct': [5102, 1870, 714, 228]}\n",
      "ratio: 0.9109433181629177\n",
      "Bleu_1: 0.525\n",
      "Bleu_2: 0.338\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.332\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.220\n",
      "2022-02-23 20:59:55,940 - INFO: eval_beam_2 SPIDEr: 0.2201\n",
      "loading annotations into memory...\n",
      "0:00:00.003900\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8038, 'reflen': 9418, 'guess': [8038, 7014, 5990, 4966], 'correct': [4720, 1763, 700, 229]}\n",
      "ratio: 0.8534720747503871\n",
      "Bleu_1: 0.495\n",
      "Bleu_2: 0.324\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.322\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2022-02-23 21:00:28,963 - INFO: eval_beam_3 SPIDEr: 0.2138\n",
      "loading annotations into memory...\n",
      "0:00:00.003953\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7369, 'reflen': 9240, 'guess': [7369, 6345, 5321, 4297], 'correct': [4500, 1771, 713, 222]}\n",
      "ratio: 0.7975108225107361\n",
      "Bleu_1: 0.474\n",
      "Bleu_2: 0.320\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.325\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2022-02-23 21:01:06,080 - INFO: eval_beam_4 SPIDEr: 0.2141\n",
      "2022-02-23 21:01:13,838 - INFO: | epoch  22 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.55 | loss-text 3.2850\n",
      "2022-02-23 21:01:21,337 - INFO: | epoch  22 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.98 | loss-text 3.3359\n",
      "2022-02-23 21:01:28,856 - INFO: | epoch  22 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.17 | loss-text 3.3066\n",
      "2022-02-23 21:01:36,369 - INFO: | epoch  22 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.13 | loss-text 3.2986\n",
      "2022-02-23 21:01:43,907 - INFO: | epoch  22 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.38 | loss-text 3.2726\n",
      "2022-02-23 21:01:51,447 - INFO: | epoch  22 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.39 | loss-text 3.3342\n",
      "2022-02-23 21:01:58,955 - INFO: | epoch  22 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.08 | loss-text 3.3114\n",
      "2022-02-23 21:02:06,473 - INFO: | epoch  22 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.17 | loss-text 3.3201\n",
      "2022-02-23 21:02:13,984 - INFO: | epoch  22 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.10 | loss-text 3.2863\n",
      "2022-02-23 21:02:21,508 - INFO: | epoch  22 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.23 | loss-text 3.3326\n",
      "2022-02-23 21:02:29,127 - INFO: | epoch  22 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 76.18 | loss-text 3.3004\n",
      "2022-02-23 21:02:36,671 - INFO: | epoch  22 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.2816\n",
      "2022-02-23 21:02:44,299 - INFO: | epoch  22 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.27 | loss-text 3.3183\n",
      "2022-02-23 21:02:51,848 - INFO: | epoch  22 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.48 | loss-text 3.3304\n",
      "2022-02-23 21:02:59,420 - INFO: | epoch  22 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.2506\n",
      "2022-02-23 21:03:07,012 - INFO: | epoch  22 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.3311\n",
      "2022-02-23 21:03:14,612 - INFO: | epoch  22 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.2864\n",
      "2022-02-23 21:03:22,196 - INFO: | epoch  22 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.2701\n",
      "2022-02-23 21:03:29,774 - INFO: | epoch  22 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.77 | loss-text 3.3588\n",
      "2022-02-23 21:03:37,346 - INFO: | epoch  22 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.3174\n",
      "2022-02-23 21:03:44,952 - INFO: | epoch  22 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.05 | loss-text 3.3235\n",
      "2022-02-23 21:03:52,542 - INFO: | epoch  22 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.2610\n",
      "2022-02-23 21:04:00,174 - INFO: | epoch  22 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.31 | loss-text 3.3337\n",
      "2022-02-23 21:04:07,716 - INFO: | epoch  22 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.42 | loss-text 3.2552\n",
      "2022-02-23 21:04:15,276 - INFO: | epoch  22 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.58 | loss-text 3.2867\n",
      "2022-02-23 21:04:22,831 - INFO: | epoch  22 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.55 | loss-text 3.2962\n",
      "2022-02-23 21:04:30,407 - INFO: | epoch  22 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.76 | loss-text 3.3054\n",
      "2022-02-23 21:04:38,031 - INFO: | epoch  22 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.23 | loss-text 3.2972\n",
      "2022-02-23 21:04:45,667 - INFO: | epoch  22 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.35 | loss-text 3.3197\n",
      "2022-02-23 21:04:53,284 - INFO: | epoch  22 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.3063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003780\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10161, 'reflen': 10334, 'guess': [10161, 9137, 8113, 7089], 'correct': [5452, 1885, 685, 209]}\n",
      "ratio: 0.9832591445712228\n",
      "Bleu_1: 0.528\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.314\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.209\n",
      "2022-02-23 21:05:34,585 - INFO: eval_greddy SPIDEr: 0.2092\n",
      "loading annotations into memory...\n",
      "0:00:00.003969\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8290, 'reflen': 9458, 'guess': [8290, 7266, 6242, 5218], 'correct': [4851, 1817, 716, 256]}\n",
      "ratio: 0.8765066610276087\n",
      "Bleu_1: 0.508\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.338\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.219\n",
      "2022-02-23 21:06:04,295 - INFO: eval_beam_2 SPIDEr: 0.2194\n",
      "loading annotations into memory...\n",
      "0:00:00.003907\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7768, 'reflen': 9308, 'guess': [7768, 6744, 5720, 4696], 'correct': [4558, 1681, 665, 236]}\n",
      "ratio: 0.8345509239363091\n",
      "Bleu_1: 0.481\n",
      "Bleu_2: 0.314\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.149\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.327\n",
      "computing SPICE score...\n",
      "SPICE: 0.097\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.212\n",
      "2022-02-23 21:06:35,895 - INFO: eval_beam_3 SPIDEr: 0.2123\n",
      "loading annotations into memory...\n",
      "0:00:00.003904\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7374, 'reflen': 9224, 'guess': [7374, 6350, 5326, 4302], 'correct': [4387, 1645, 655, 225]}\n",
      "ratio: 0.7994362532522984\n",
      "Bleu_1: 0.463\n",
      "Bleu_2: 0.305\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.320\n",
      "computing SPICE score...\n",
      "SPICE: 0.094\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.207\n",
      "2022-02-23 21:07:10,699 - INFO: eval_beam_4 SPIDEr: 0.2072\n",
      "2022-02-23 21:07:18,506 - INFO: | epoch  23 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.04 | loss-text 3.2684\n",
      "2022-02-23 21:07:26,015 - INFO: | epoch  23 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.08 | loss-text 3.2197\n",
      "2022-02-23 21:07:33,511 - INFO: | epoch  23 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.95 | loss-text 3.2624\n",
      "2022-02-23 21:07:41,039 - INFO: | epoch  23 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.28 | loss-text 3.3213\n",
      "2022-02-23 21:07:48,597 - INFO: | epoch  23 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.2730\n",
      "2022-02-23 21:07:56,143 - INFO: | epoch  23 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.2937\n",
      "2022-02-23 21:08:03,685 - INFO: | epoch  23 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.41 | loss-text 3.2667\n",
      "2022-02-23 21:08:11,257 - INFO: | epoch  23 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.2875\n",
      "2022-02-23 21:08:18,765 - INFO: | epoch  23 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.08 | loss-text 3.2311\n",
      "2022-02-23 21:08:26,376 - INFO: | epoch  23 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 76.10 | loss-text 3.2881\n",
      "2022-02-23 21:08:33,914 - INFO: | epoch  23 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.37 | loss-text 3.2691\n",
      "2022-02-23 21:08:41,469 - INFO: | epoch  23 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.55 | loss-text 3.2835\n",
      "2022-02-23 21:08:49,035 - INFO: | epoch  23 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.2411\n",
      "2022-02-23 21:08:56,607 - INFO: | epoch  23 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.2916\n",
      "2022-02-23 21:09:04,180 - INFO: | epoch  23 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.2926\n",
      "2022-02-23 21:09:11,716 - INFO: | epoch  23 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.35 | loss-text 3.3149\n",
      "2022-02-23 21:09:19,342 - INFO: | epoch  23 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.25 | loss-text 3.2902\n",
      "2022-02-23 21:09:26,985 - INFO: | epoch  23 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.42 | loss-text 3.3545\n",
      "2022-02-23 21:09:34,624 - INFO: | epoch  23 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.38 | loss-text 3.2898\n",
      "2022-02-23 21:09:42,256 - INFO: | epoch  23 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.32 | loss-text 3.2635\n",
      "2022-02-23 21:09:49,808 - INFO: | epoch  23 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.52 | loss-text 3.2926\n",
      "2022-02-23 21:09:57,411 - INFO: | epoch  23 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.02 | loss-text 3.2669\n",
      "2022-02-23 21:10:05,041 - INFO: | epoch  23 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.30 | loss-text 3.2727\n",
      "2022-02-23 21:10:12,591 - INFO: | epoch  23 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.49 | loss-text 3.2588\n",
      "2022-02-23 21:10:20,183 - INFO: | epoch  23 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.2783\n",
      "2022-02-23 21:10:27,776 - INFO: | epoch  23 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.92 | loss-text 3.2915\n",
      "2022-02-23 21:10:35,386 - INFO: | epoch  23 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.09 | loss-text 3.2737\n",
      "2022-02-23 21:10:42,915 - INFO: | epoch  23 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.29 | loss-text 3.2665\n",
      "2022-02-23 21:10:50,543 - INFO: | epoch  23 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.27 | loss-text 3.3198\n",
      "2022-02-23 21:10:58,113 - INFO: | epoch  23 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.2883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003822\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10573, 'reflen': 10593, 'guess': [10573, 9549, 8525, 7501], 'correct': [5750, 2071, 784, 250]}\n",
      "ratio: 0.9981119607286889\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.325\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2022-02-23 21:11:40,015 - INFO: eval_greddy SPIDEr: 0.2151\n",
      "loading annotations into memory...\n",
      "0:00:00.003949\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8788, 'reflen': 9673, 'guess': [8788, 7764, 6740, 5716], 'correct': [5244, 1984, 829, 276]}\n",
      "ratio: 0.9085082187531367\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.372\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.356\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2022-02-23 21:12:09,243 - INFO: eval_beam_2 SPIDEr: 0.2333\n",
      "loading annotations into memory...\n",
      "0:00:00.003834\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8224, 'reflen': 9430, 'guess': [8224, 7200, 6176, 5152], 'correct': [4970, 1928, 804, 261]}\n",
      "ratio: 0.872110286320162\n",
      "Bleu_1: 0.522\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.353\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2022-02-23 21:12:41,181 - INFO: eval_beam_3 SPIDEr: 0.2292\n",
      "loading annotations into memory...\n",
      "0:00:00.003659\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7620, 'reflen': 9283, 'guess': [7620, 6596, 5572, 4548], 'correct': [4716, 1890, 792, 248]}\n",
      "ratio: 0.820855326941633\n",
      "Bleu_1: 0.498\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.345\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.224\n",
      "2022-02-23 21:13:17,289 - INFO: eval_beam_4 SPIDEr: 0.2242\n",
      "2022-02-23 21:13:25,039 - INFO: | epoch  24 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.48 | loss-text 3.2476\n",
      "2022-02-23 21:13:32,564 - INFO: | epoch  24 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.23 | loss-text 3.2567\n",
      "2022-02-23 21:13:40,077 - INFO: | epoch  24 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.13 | loss-text 3.3005\n",
      "2022-02-23 21:13:47,622 - INFO: | epoch  24 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.2950\n",
      "2022-02-23 21:13:55,183 - INFO: | epoch  24 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.61 | loss-text 3.2622\n",
      "2022-02-23 21:14:02,757 - INFO: | epoch  24 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.73 | loss-text 3.3277\n",
      "2022-02-23 21:14:10,337 - INFO: | epoch  24 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.79 | loss-text 3.2388\n",
      "2022-02-23 21:14:17,938 - INFO: | epoch  24 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.2965\n",
      "2022-02-23 21:14:25,506 - INFO: | epoch  24 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.2773\n",
      "2022-02-23 21:14:33,034 - INFO: | epoch  24 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.28 | loss-text 3.2962\n",
      "2022-02-23 21:14:40,674 - INFO: | epoch  24 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 76.39 | loss-text 3.2908\n",
      "2022-02-23 21:14:48,237 - INFO: | epoch  24 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.63 | loss-text 3.2700\n",
      "2022-02-23 21:14:55,728 - INFO: | epoch  24 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 74.90 | loss-text 3.2635\n",
      "2022-02-23 21:15:03,293 - INFO: | epoch  24 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.64 | loss-text 3.2409\n",
      "2022-02-23 21:15:10,884 - INFO: | epoch  24 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.2565\n",
      "2022-02-23 21:15:18,467 - INFO: | epoch  24 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.82 | loss-text 3.2799\n",
      "2022-02-23 21:15:26,032 - INFO: | epoch  24 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.2292\n",
      "2022-02-23 21:15:33,626 - INFO: | epoch  24 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.93 | loss-text 3.2803\n",
      "2022-02-23 21:15:41,209 - INFO: | epoch  24 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.82 | loss-text 3.3578\n",
      "2022-02-23 21:15:48,821 - INFO: | epoch  24 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.2746\n",
      "2022-02-23 21:15:56,361 - INFO: | epoch  24 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.39 | loss-text 3.2782\n",
      "2022-02-23 21:16:03,995 - INFO: | epoch  24 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.33 | loss-text 3.2986\n",
      "2022-02-23 21:16:11,582 - INFO: | epoch  24 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.2455\n",
      "2022-02-23 21:16:19,249 - INFO: | epoch  24 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.65 | loss-text 3.2988\n",
      "2022-02-23 21:16:26,881 - INFO: | epoch  24 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.31 | loss-text 3.2746\n",
      "2022-02-23 21:16:34,456 - INFO: | epoch  24 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.74 | loss-text 3.2639\n",
      "2022-02-23 21:16:42,119 - INFO: | epoch  24 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.62 | loss-text 3.2673\n",
      "2022-02-23 21:16:49,732 - INFO: | epoch  24 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.12 | loss-text 3.2828\n",
      "2022-02-23 21:16:57,277 - INFO: | epoch  24 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.2656\n",
      "2022-02-23 21:17:04,910 - INFO: | epoch  24 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.32 | loss-text 3.2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003842\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10101, 'reflen': 10391, 'guess': [10101, 9077, 8053, 7029], 'correct': [5474, 1944, 749, 240]}\n",
      "ratio: 0.9720912327975197\n",
      "Bleu_1: 0.527\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.328\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.218\n",
      "2022-02-23 21:17:45,697 - INFO: eval_greddy SPIDEr: 0.2178\n",
      "loading annotations into memory...\n",
      "0:00:00.003902\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8368, 'reflen': 9481, 'guess': [8368, 7344, 6320, 5296], 'correct': [4970, 1846, 740, 242]}\n",
      "ratio: 0.8826073199028707\n",
      "Bleu_1: 0.520\n",
      "Bleu_2: 0.338\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.350\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2022-02-23 21:18:14,840 - INFO: eval_beam_2 SPIDEr: 0.2274\n",
      "loading annotations into memory...\n",
      "0:00:00.003869\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7823, 'reflen': 9352, 'guess': [7823, 6799, 5775, 4751], 'correct': [4677, 1778, 708, 232]}\n",
      "ratio: 0.836505560307866\n",
      "Bleu_1: 0.492\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.341\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.222\n",
      "2022-02-23 21:18:45,959 - INFO: eval_beam_3 SPIDEr: 0.2222\n",
      "loading annotations into memory...\n",
      "0:00:00.003876\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7459, 'reflen': 9265, 'guess': [7459, 6435, 5411, 4387], 'correct': [4436, 1696, 684, 227]}\n",
      "ratio: 0.8050728548299184\n",
      "Bleu_1: 0.467\n",
      "Bleu_2: 0.311\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.327\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.212\n",
      "2022-02-23 21:19:21,224 - INFO: eval_beam_4 SPIDEr: 0.2124\n",
      "2022-02-23 21:19:29,013 - INFO: | epoch  25 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.86 | loss-text 3.2639\n",
      "2022-02-23 21:19:36,547 - INFO: | epoch  25 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.33 | loss-text 3.2361\n",
      "2022-02-23 21:19:44,023 - INFO: | epoch  25 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.76 | loss-text 3.2899\n",
      "2022-02-23 21:19:51,517 - INFO: | epoch  25 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 74.93 | loss-text 3.1733\n",
      "2022-02-23 21:19:59,107 - INFO: | epoch  25 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.2847\n",
      "2022-02-23 21:20:06,683 - INFO: | epoch  25 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.2881\n",
      "2022-02-23 21:20:14,259 - INFO: | epoch  25 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.76 | loss-text 3.2344\n",
      "2022-02-23 21:20:21,808 - INFO: | epoch  25 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.48 | loss-text 3.2421\n",
      "2022-02-23 21:20:29,424 - INFO: | epoch  25 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 76.15 | loss-text 3.2647\n",
      "2022-02-23 21:20:36,993 - INFO: | epoch  25 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.68 | loss-text 3.2805\n",
      "2022-02-23 21:20:44,526 - INFO: | epoch  25 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.33 | loss-text 3.2730\n",
      "2022-02-23 21:20:52,097 - INFO: | epoch  25 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.2886\n",
      "2022-02-23 21:20:59,648 - INFO: | epoch  25 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.50 | loss-text 3.2478\n",
      "2022-02-23 21:21:07,216 - INFO: | epoch  25 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.2443\n",
      "2022-02-23 21:21:14,797 - INFO: | epoch  25 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.80 | loss-text 3.2412\n",
      "2022-02-23 21:21:22,404 - INFO: | epoch  25 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.2791\n",
      "2022-02-23 21:21:30,036 - INFO: | epoch  25 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.32 | loss-text 3.3111\n",
      "2022-02-23 21:21:37,652 - INFO: | epoch  25 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.15 | loss-text 3.2629\n",
      "2022-02-23 21:21:45,269 - INFO: | epoch  25 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.2626\n",
      "2022-02-23 21:21:52,828 - INFO: | epoch  25 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.58 | loss-text 3.2620\n",
      "2022-02-23 21:22:00,427 - INFO: | epoch  25 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.99 | loss-text 3.2570\n",
      "2022-02-23 21:22:08,062 - INFO: | epoch  25 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.34 | loss-text 3.2452\n",
      "2022-02-23 21:22:15,698 - INFO: | epoch  25 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.35 | loss-text 3.2801\n",
      "2022-02-23 21:22:23,265 - INFO: | epoch  25 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.2457\n",
      "2022-02-23 21:22:30,921 - INFO: | epoch  25 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.56 | loss-text 3.3048\n",
      "2022-02-23 21:22:38,505 - INFO: | epoch  25 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.2740\n",
      "2022-02-23 21:22:46,108 - INFO: | epoch  25 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.2513\n",
      "2022-02-23 21:22:53,729 - INFO: | epoch  25 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.20 | loss-text 3.2434\n",
      "2022-02-23 21:23:01,351 - INFO: | epoch  25 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.21 | loss-text 3.2835\n",
      "2022-02-23 21:23:08,935 - INFO: | epoch  25 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.2762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003651\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10766, 'reflen': 10692, 'guess': [10766, 9742, 8718, 7694], 'correct': [5901, 2119, 811, 252]}\n",
      "ratio: 1.006921062476524\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.223\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.331\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.221\n",
      "2022-02-23 21:23:50,978 - INFO: eval_greddy SPIDEr: 0.2214\n",
      "loading annotations into memory...\n",
      "0:00:00.003708\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8868, 'reflen': 9711, 'guess': [8868, 7844, 6820, 5796], 'correct': [5213, 1970, 805, 272]}\n",
      "ratio: 0.9131912264441444\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.351\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2022-02-23 21:24:20,155 - INFO: eval_beam_2 SPIDEr: 0.2292\n",
      "loading annotations into memory...\n",
      "0:00:00.003932\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8253, 'reflen': 9467, 'guess': [8253, 7229, 6205, 5181], 'correct': [4964, 1895, 768, 255]}\n",
      "ratio: 0.8717650786943201\n",
      "Bleu_1: 0.519\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.342\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2022-02-23 21:24:52,615 - INFO: eval_beam_3 SPIDEr: 0.2246\n",
      "loading annotations into memory...\n",
      "0:00:00.003927\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7716, 'reflen': 9336, 'guess': [7716, 6692, 5668, 4644], 'correct': [4695, 1814, 738, 239]}\n",
      "ratio: 0.8264781491001685\n",
      "Bleu_1: 0.493\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.331\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.218\n",
      "2022-02-23 21:25:29,478 - INFO: eval_beam_4 SPIDEr: 0.2177\n",
      "2022-02-23 21:25:37,269 - INFO: | epoch  26 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.88 | loss-text 3.2435\n",
      "2022-02-23 21:25:44,815 - INFO: | epoch  26 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.2262\n",
      "2022-02-23 21:25:52,289 - INFO: | epoch  26 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.73 | loss-text 3.2623\n",
      "2022-02-23 21:25:59,767 - INFO: | epoch  26 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 74.76 | loss-text 3.2625\n",
      "2022-02-23 21:26:07,239 - INFO: | epoch  26 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 74.71 | loss-text 3.2651\n",
      "2022-02-23 21:26:14,755 - INFO: | epoch  26 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.15 | loss-text 3.1984\n",
      "2022-02-23 21:26:22,286 - INFO: | epoch  26 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.31 | loss-text 3.2373\n",
      "2022-02-23 21:26:29,836 - INFO: | epoch  26 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.49 | loss-text 3.2662\n",
      "2022-02-23 21:26:37,377 - INFO: | epoch  26 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.2472\n",
      "2022-02-23 21:26:44,920 - INFO: | epoch  26 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.43 | loss-text 3.2488\n",
      "2022-02-23 21:26:52,471 - INFO: | epoch  26 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.50 | loss-text 3.2140\n",
      "2022-02-23 21:27:00,025 - INFO: | epoch  26 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.53 | loss-text 3.2551\n",
      "2022-02-23 21:27:07,663 - INFO: | epoch  26 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.38 | loss-text 3.2234\n",
      "2022-02-23 21:27:15,264 - INFO: | epoch  26 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.2183\n",
      "2022-02-23 21:27:22,889 - INFO: | epoch  26 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.2442\n",
      "2022-02-23 21:27:30,474 - INFO: | epoch  26 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.2702\n",
      "2022-02-23 21:27:38,029 - INFO: | epoch  26 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.54 | loss-text 3.2555\n",
      "2022-02-23 21:27:45,697 - INFO: | epoch  26 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.67 | loss-text 3.2898\n",
      "2022-02-23 21:27:53,329 - INFO: | epoch  26 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.31 | loss-text 3.2695\n",
      "2022-02-23 21:28:00,970 - INFO: | epoch  26 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.41 | loss-text 3.2252\n",
      "2022-02-23 21:28:08,597 - INFO: | epoch  26 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.26 | loss-text 3.2489\n",
      "2022-02-23 21:28:16,274 - INFO: | epoch  26 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.76 | loss-text 3.2429\n",
      "2022-02-23 21:28:23,935 - INFO: | epoch  26 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.60 | loss-text 3.3046\n",
      "2022-02-23 21:28:31,505 - INFO: | epoch  26 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.2304\n",
      "2022-02-23 21:28:39,118 - INFO: | epoch  26 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.13 | loss-text 3.2197\n",
      "2022-02-23 21:28:46,716 - INFO: | epoch  26 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.2158\n",
      "2022-02-23 21:28:54,286 - INFO: | epoch  26 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.2452\n",
      "2022-02-23 21:29:01,898 - INFO: | epoch  26 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.2552\n",
      "2022-02-23 21:29:09,555 - INFO: | epoch  26 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.57 | loss-text 3.2361\n",
      "2022-02-23 21:29:17,191 - INFO: | epoch  26 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.35 | loss-text 3.2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003852\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10310, 'reflen': 10496, 'guess': [10310, 9286, 8262, 7238], 'correct': [5567, 1945, 729, 225]}\n",
      "ratio: 0.9822789634145406\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2022-02-23 21:29:58,608 - INFO: eval_greddy SPIDEr: 0.2163\n",
      "loading annotations into memory...\n",
      "0:00:00.003845\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8546, 'reflen': 9567, 'guess': [8546, 7522, 6498, 5474], 'correct': [5067, 1866, 740, 245]}\n",
      "ratio: 0.8932789798263935\n",
      "Bleu_1: 0.526\n",
      "Bleu_2: 0.340\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.348\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2022-02-23 21:30:27,983 - INFO: eval_beam_2 SPIDEr: 0.2279\n",
      "loading annotations into memory...\n",
      "0:00:00.003888\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7942, 'reflen': 9367, 'guess': [7942, 6918, 5894, 4870], 'correct': [4762, 1767, 716, 243]}\n",
      "ratio: 0.8478701825556904\n",
      "Bleu_1: 0.501\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.344\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2022-02-23 21:31:00,433 - INFO: eval_beam_3 SPIDEr: 0.2246\n",
      "loading annotations into memory...\n",
      "0:00:00.003879\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7497, 'reflen': 9252, 'guess': [7497, 6473, 5449, 4425], 'correct': [4568, 1718, 696, 222]}\n",
      "ratio: 0.810311284046605\n",
      "Bleu_1: 0.482\n",
      "Bleu_2: 0.318\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.336\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.219\n",
      "2022-02-23 21:31:35,731 - INFO: eval_beam_4 SPIDEr: 0.2195\n",
      "2022-02-23 21:31:43,538 - INFO: | epoch  27 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.03 | loss-text 3.1971\n",
      "2022-02-23 21:31:51,051 - INFO: | epoch  27 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.13 | loss-text 3.2584\n",
      "2022-02-23 21:31:58,522 - INFO: | epoch  27 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.70 | loss-text 3.2261\n",
      "2022-02-23 21:32:06,017 - INFO: | epoch  27 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 74.95 | loss-text 3.2065\n",
      "2022-02-23 21:32:13,520 - INFO: | epoch  27 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.02 | loss-text 3.1895\n",
      "2022-02-23 21:32:21,080 - INFO: | epoch  27 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.59 | loss-text 3.2532\n",
      "2022-02-23 21:32:28,629 - INFO: | epoch  27 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.48 | loss-text 3.2232\n",
      "2022-02-23 21:32:36,158 - INFO: | epoch  27 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.29 | loss-text 3.2694\n",
      "2022-02-23 21:32:43,759 - INFO: | epoch  27 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.1994\n",
      "2022-02-23 21:32:51,329 - INFO: | epoch  27 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.2384\n",
      "2022-02-23 21:32:58,861 - INFO: | epoch  27 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.31 | loss-text 3.2430\n",
      "2022-02-23 21:33:06,423 - INFO: | epoch  27 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.2381\n",
      "2022-02-23 21:33:14,060 - INFO: | epoch  27 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.35 | loss-text 3.2212\n",
      "2022-02-23 21:33:21,627 - INFO: | epoch  27 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.2092\n",
      "2022-02-23 21:33:29,219 - INFO: | epoch  27 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.2615\n",
      "2022-02-23 21:33:36,815 - INFO: | epoch  27 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.2147\n",
      "2022-02-23 21:33:44,409 - INFO: | epoch  27 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.2278\n",
      "2022-02-23 21:33:51,997 - INFO: | epoch  27 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.2406\n",
      "2022-02-23 21:33:59,608 - INFO: | epoch  27 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.2605\n",
      "2022-02-23 21:34:07,203 - INFO: | epoch  27 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.2359\n",
      "2022-02-23 21:34:14,775 - INFO: | epoch  27 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.2223\n",
      "2022-02-23 21:34:22,371 - INFO: | epoch  27 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.2592\n",
      "2022-02-23 21:34:29,977 - INFO: | epoch  27 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.05 | loss-text 3.2334\n",
      "2022-02-23 21:34:37,667 - INFO: | epoch  27 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.89 | loss-text 3.2524\n",
      "2022-02-23 21:34:45,266 - INFO: | epoch  27 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.99 | loss-text 3.2822\n",
      "2022-02-23 21:34:52,874 - INFO: | epoch  27 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.2832\n",
      "2022-02-23 21:35:00,545 - INFO: | epoch  27 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.71 | loss-text 3.2512\n",
      "2022-02-23 21:35:08,175 - INFO: | epoch  27 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.29 | loss-text 3.1862\n",
      "2022-02-23 21:35:15,846 - INFO: | epoch  27 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.70 | loss-text 3.2323\n",
      "2022-02-23 21:35:23,502 - INFO: | epoch  27 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.55 | loss-text 3.2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003871\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10084, 'reflen': 10322, 'guess': [10084, 9060, 8036, 7012], 'correct': [5726, 2067, 772, 215]}\n",
      "ratio: 0.9769424530128873\n",
      "Bleu_1: 0.555\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.373\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.339\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2022-02-23 21:36:05,495 - INFO: eval_greddy SPIDEr: 0.2253\n",
      "loading annotations into memory...\n",
      "0:00:00.003899\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8609, 'reflen': 9612, 'guess': [8609, 7585, 6561, 5537], 'correct': [5124, 1924, 776, 255]}\n",
      "ratio: 0.8956512692466816\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.348\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2022-02-23 21:36:33,101 - INFO: eval_beam_2 SPIDEr: 0.2282\n",
      "loading annotations into memory...\n",
      "0:00:00.003677\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7973, 'reflen': 9396, 'guess': [7973, 6949, 5925, 4901], 'correct': [4842, 1860, 760, 242]}\n",
      "ratio: 0.8485525755639794\n",
      "Bleu_1: 0.508\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.351\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2022-02-23 21:37:04,323 - INFO: eval_beam_3 SPIDEr: 0.2294\n",
      "loading annotations into memory...\n",
      "0:00:00.004006\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7532, 'reflen': 9306, 'guess': [7532, 6508, 5484, 4460], 'correct': [4628, 1813, 756, 241]}\n",
      "ratio: 0.8093702987319138\n",
      "Bleu_1: 0.486\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.346\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.226\n",
      "2022-02-23 21:37:39,432 - INFO: eval_beam_4 SPIDEr: 0.2260\n",
      "2022-02-23 21:37:47,283 - INFO: | epoch  28 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.48 | loss-text 3.1757\n",
      "2022-02-23 21:37:54,764 - INFO: | epoch  28 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.80 | loss-text 3.1958\n",
      "2022-02-23 21:38:02,337 - INFO: | epoch  28 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.2433\n",
      "2022-02-23 21:38:09,874 - INFO: | epoch  28 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.37 | loss-text 3.2753\n",
      "2022-02-23 21:38:17,402 - INFO: | epoch  28 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.27 | loss-text 3.2081\n",
      "2022-02-23 21:38:24,976 - INFO: | epoch  28 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.74 | loss-text 3.2144\n",
      "2022-02-23 21:38:32,494 - INFO: | epoch  28 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.18 | loss-text 3.2114\n",
      "2022-02-23 21:38:40,056 - INFO: | epoch  28 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.61 | loss-text 3.1952\n",
      "2022-02-23 21:38:47,640 - INFO: | epoch  28 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.2620\n",
      "2022-02-23 21:38:55,203 - INFO: | epoch  28 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.1734\n",
      "2022-02-23 21:39:02,771 - INFO: | epoch  28 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.2217\n",
      "2022-02-23 21:39:10,316 - INFO: | epoch  28 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.2480\n",
      "2022-02-23 21:39:17,917 - INFO: | epoch  28 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.2273\n",
      "2022-02-23 21:39:25,474 - INFO: | epoch  28 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.56 | loss-text 3.2345\n",
      "2022-02-23 21:39:33,024 - INFO: | epoch  28 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.49 | loss-text 3.2043\n",
      "2022-02-23 21:39:40,628 - INFO: | epoch  28 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.1754\n",
      "2022-02-23 21:39:48,187 - INFO: | epoch  28 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.59 | loss-text 3.2545\n",
      "2022-02-23 21:39:55,757 - INFO: | epoch  28 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.2198\n",
      "2022-02-23 21:40:03,347 - INFO: | epoch  28 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.2597\n",
      "2022-02-23 21:40:10,927 - INFO: | epoch  28 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.79 | loss-text 3.2515\n",
      "2022-02-23 21:40:18,544 - INFO: | epoch  28 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.2865\n",
      "2022-02-23 21:40:26,192 - INFO: | epoch  28 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.47 | loss-text 3.2086\n",
      "2022-02-23 21:40:33,758 - INFO: | epoch  28 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.2417\n",
      "2022-02-23 21:40:41,387 - INFO: | epoch  28 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.29 | loss-text 3.2140\n",
      "2022-02-23 21:40:49,009 - INFO: | epoch  28 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.22 | loss-text 3.1763\n",
      "2022-02-23 21:40:56,536 - INFO: | epoch  28 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.26 | loss-text 3.2344\n",
      "2022-02-23 21:41:04,144 - INFO: | epoch  28 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.2296\n",
      "2022-02-23 21:41:11,734 - INFO: | epoch  28 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.2751\n",
      "2022-02-23 21:41:19,343 - INFO: | epoch  28 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.09 | loss-text 3.2149\n",
      "2022-02-23 21:41:26,947 - INFO: | epoch  28 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003883\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10256, 'reflen': 10436, 'guess': [10256, 9232, 8208, 7184], 'correct': [5588, 1955, 739, 226]}\n",
      "ratio: 0.9827520122651415\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.334\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.336\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.223\n",
      "2022-02-23 21:42:08,022 - INFO: eval_greddy SPIDEr: 0.2235\n",
      "loading annotations into memory...\n",
      "0:00:00.003908\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8746, 'reflen': 9640, 'guess': [8746, 7722, 6698, 5674], 'correct': [5184, 1947, 780, 259]}\n",
      "ratio: 0.9072614107882876\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2022-02-23 21:42:36,303 - INFO: eval_beam_2 SPIDEr: 0.2395\n",
      "loading annotations into memory...\n",
      "0:00:00.003863\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8113, 'reflen': 9416, 'guess': [8113, 7089, 6065, 5041], 'correct': [4897, 1878, 760, 250]}\n",
      "ratio: 0.8616185216651591\n",
      "Bleu_1: 0.514\n",
      "Bleu_2: 0.341\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2022-02-23 21:43:08,340 - INFO: eval_beam_3 SPIDEr: 0.2375\n",
      "loading annotations into memory...\n",
      "0:00:00.003901\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7611, 'reflen': 9310, 'guess': [7611, 6587, 5563, 4539], 'correct': [4637, 1757, 700, 232]}\n",
      "ratio: 0.8175080558538327\n",
      "Bleu_1: 0.487\n",
      "Bleu_2: 0.322\n",
      "Bleu_3: 0.219\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.350\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2022-02-23 21:43:44,394 - INFO: eval_beam_4 SPIDEr: 0.2275\n",
      "2022-02-23 21:43:52,138 - INFO: | epoch  29 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.41 | loss-text 3.2104\n",
      "2022-02-23 21:43:59,634 - INFO: | epoch  29 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.95 | loss-text 3.2480\n",
      "2022-02-23 21:44:07,168 - INFO: | epoch  29 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.33 | loss-text 3.1743\n",
      "2022-02-23 21:44:14,745 - INFO: | epoch  29 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.76 | loss-text 3.2212\n",
      "2022-02-23 21:44:22,246 - INFO: | epoch  29 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.01 | loss-text 3.2304\n",
      "2022-02-23 21:44:29,771 - INFO: | epoch  29 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.25 | loss-text 3.2335\n",
      "2022-02-23 21:44:37,383 - INFO: | epoch  29 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.2017\n",
      "2022-02-23 21:44:44,979 - INFO: | epoch  29 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.1961\n",
      "2022-02-23 21:44:52,492 - INFO: | epoch  29 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.12 | loss-text 3.2180\n",
      "2022-02-23 21:45:00,078 - INFO: | epoch  29 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.85 | loss-text 3.1976\n",
      "2022-02-23 21:45:07,668 - INFO: | epoch  29 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.2417\n",
      "2022-02-23 21:45:15,265 - INFO: | epoch  29 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.2286\n",
      "2022-02-23 21:45:22,839 - INFO: | epoch  29 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.73 | loss-text 3.2613\n",
      "2022-02-23 21:45:30,363 - INFO: | epoch  29 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.24 | loss-text 3.2229\n",
      "2022-02-23 21:45:37,959 - INFO: | epoch  29 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.1797\n",
      "2022-02-23 21:45:45,550 - INFO: | epoch  29 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.2371\n",
      "2022-02-23 21:45:53,149 - INFO: | epoch  29 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.2111\n",
      "2022-02-23 21:46:00,734 - INFO: | epoch  29 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.1890\n",
      "2022-02-23 21:46:08,353 - INFO: | epoch  29 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.19 | loss-text 3.2319\n",
      "2022-02-23 21:46:15,968 - INFO: | epoch  29 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.14 | loss-text 3.2657\n",
      "2022-02-23 21:46:23,572 - INFO: | epoch  29 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.1872\n",
      "2022-02-23 21:46:31,174 - INFO: | epoch  29 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.2194\n",
      "2022-02-23 21:46:38,772 - INFO: | epoch  29 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.1960\n",
      "2022-02-23 21:46:46,341 - INFO: | epoch  29 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.68 | loss-text 3.2496\n",
      "2022-02-23 21:46:53,933 - INFO: | epoch  29 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.2263\n",
      "2022-02-23 21:47:01,539 - INFO: | epoch  29 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.2248\n",
      "2022-02-23 21:47:09,110 - INFO: | epoch  29 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.2249\n",
      "2022-02-23 21:47:16,786 - INFO: | epoch  29 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.75 | loss-text 3.2404\n",
      "2022-02-23 21:47:24,372 - INFO: | epoch  29 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.2007\n",
      "2022-02-23 21:47:31,965 - INFO: | epoch  29 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.92 | loss-text 3.1820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003827\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10488, 'reflen': 10544, 'guess': [10488, 9464, 8440, 7416], 'correct': [5553, 1907, 682, 207]}\n",
      "ratio: 0.9946889226099208\n",
      "Bleu_1: 0.527\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.204\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.313\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.210\n",
      "2022-02-23 21:48:13,913 - INFO: eval_greddy SPIDEr: 0.2100\n",
      "loading annotations into memory...\n",
      "0:00:00.003844\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8912, 'reflen': 9730, 'guess': [8912, 7888, 6864, 5840], 'correct': [5114, 1852, 726, 231]}\n",
      "ratio: 0.9159301130523211\n",
      "Bleu_1: 0.524\n",
      "Bleu_2: 0.335\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.346\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2022-02-23 21:48:43,549 - INFO: eval_beam_2 SPIDEr: 0.2274\n",
      "loading annotations into memory...\n",
      "0:00:00.004065\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8283, 'reflen': 9480, 'guess': [8283, 7259, 6235, 5211], 'correct': [4845, 1792, 729, 257]}\n",
      "ratio: 0.8737341772150977\n",
      "Bleu_1: 0.506\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.352\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2022-02-23 21:49:16,335 - INFO: eval_beam_3 SPIDEr: 0.2287\n",
      "loading annotations into memory...\n",
      "0:00:00.003862\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7721, 'reflen': 9335, 'guess': [7721, 6697, 5673, 4649], 'correct': [4617, 1736, 696, 235]}\n",
      "ratio: 0.8271023031600613\n",
      "Bleu_1: 0.485\n",
      "Bleu_2: 0.319\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.347\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2022-02-23 21:49:52,777 - INFO: eval_beam_4 SPIDEr: 0.2245\n",
      "2022-02-23 21:50:00,591 - INFO: | epoch  30 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.10 | loss-text 3.1476\n",
      "2022-02-23 21:50:08,074 - INFO: | epoch  30 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.82 | loss-text 3.2391\n",
      "2022-02-23 21:50:15,630 - INFO: | epoch  30 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.55 | loss-text 3.2351\n",
      "2022-02-23 21:50:23,160 - INFO: | epoch  30 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.30 | loss-text 3.2231\n",
      "2022-02-23 21:50:30,734 - INFO: | epoch  30 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.73 | loss-text 3.1760\n",
      "2022-02-23 21:50:38,303 - INFO: | epoch  30 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.68 | loss-text 3.1885\n",
      "2022-02-23 21:50:45,812 - INFO: | epoch  30 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.09 | loss-text 3.1935\n",
      "2022-02-23 21:50:53,343 - INFO: | epoch  30 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.29 | loss-text 3.1981\n",
      "2022-02-23 21:51:00,916 - INFO: | epoch  30 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.2068\n",
      "2022-02-23 21:51:08,465 - INFO: | epoch  30 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.49 | loss-text 3.1766\n",
      "2022-02-23 21:51:16,029 - INFO: | epoch  30 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.63 | loss-text 3.1438\n",
      "2022-02-23 21:51:23,601 - INFO: | epoch  30 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.2169\n",
      "2022-02-23 21:51:31,182 - INFO: | epoch  30 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.81 | loss-text 3.1996\n",
      "2022-02-23 21:51:38,747 - INFO: | epoch  30 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.64 | loss-text 3.1806\n",
      "2022-02-23 21:51:46,372 - INFO: | epoch  30 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.25 | loss-text 3.2209\n",
      "2022-02-23 21:51:54,031 - INFO: | epoch  30 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.58 | loss-text 3.2035\n",
      "2022-02-23 21:52:01,629 - INFO: | epoch  30 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.2014\n",
      "2022-02-23 21:52:09,314 - INFO: | epoch  30 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.84 | loss-text 3.2238\n",
      "2022-02-23 21:52:16,892 - INFO: | epoch  30 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.78 | loss-text 3.1663\n",
      "2022-02-23 21:52:24,438 - INFO: | epoch  30 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.45 | loss-text 3.2081\n",
      "2022-02-23 21:52:32,065 - INFO: | epoch  30 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.26 | loss-text 3.1761\n",
      "2022-02-23 21:52:39,701 - INFO: | epoch  30 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.36 | loss-text 3.1836\n",
      "2022-02-23 21:52:47,266 - INFO: | epoch  30 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.64 | loss-text 3.2057\n",
      "2022-02-23 21:52:54,841 - INFO: | epoch  30 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.2160\n",
      "2022-02-23 21:53:02,452 - INFO: | epoch  30 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.10 | loss-text 3.1903\n",
      "2022-02-23 21:53:10,069 - INFO: | epoch  30 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.16 | loss-text 3.2136\n",
      "2022-02-23 21:53:17,661 - INFO: | epoch  30 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.2329\n",
      "2022-02-23 21:53:25,279 - INFO: | epoch  30 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.18 | loss-text 3.2186\n",
      "2022-02-23 21:53:32,929 - INFO: | epoch  30 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.50 | loss-text 3.2454\n",
      "2022-02-23 21:53:40,572 - INFO: | epoch  30 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.42 | loss-text 3.2475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003889\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10076, 'reflen': 10288, 'guess': [10076, 9052, 8028, 7004], 'correct': [5496, 1913, 700, 227]}\n",
      "ratio: 0.9793934681181007\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2022-02-23 21:54:22,362 - INFO: eval_greddy SPIDEr: 0.2158\n",
      "loading annotations into memory...\n",
      "0:00:00.003931\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8273, 'reflen': 9468, 'guess': [8273, 7249, 6225, 5201], 'correct': [4897, 1782, 704, 253]}\n",
      "ratio: 0.8737853823404231\n",
      "Bleu_1: 0.512\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.342\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.223\n",
      "2022-02-23 21:54:50,932 - INFO: eval_beam_2 SPIDEr: 0.2233\n",
      "loading annotations into memory...\n",
      "0:00:00.003805\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7813, 'reflen': 9358, 'guess': [7813, 6789, 5765, 4741], 'correct': [4702, 1738, 697, 251]}\n",
      "ratio: 0.8349006197904643\n",
      "Bleu_1: 0.494\n",
      "Bleu_2: 0.322\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.338\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.221\n",
      "2022-02-23 21:55:22,560 - INFO: eval_beam_3 SPIDEr: 0.2207\n",
      "loading annotations into memory...\n",
      "0:00:00.003874\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7362, 'reflen': 9266, 'guess': [7362, 6338, 5314, 4290], 'correct': [4492, 1680, 684, 245]}\n",
      "ratio: 0.7945175911935253\n",
      "Bleu_1: 0.471\n",
      "Bleu_2: 0.311\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.147\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.331\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2022-02-23 21:55:58,421 - INFO: eval_beam_4 SPIDEr: 0.2151\n",
      "2022-02-23 21:56:06,188 - INFO: | epoch  31 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.64 | loss-text 3.1764\n",
      "2022-02-23 21:56:13,715 - INFO: | epoch  31 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.25 | loss-text 3.1901\n",
      "2022-02-23 21:56:21,309 - INFO: | epoch  31 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.1607\n",
      "2022-02-23 21:56:28,854 - INFO: | epoch  31 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.1587\n",
      "2022-02-23 21:56:36,443 - INFO: | epoch  31 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.88 | loss-text 3.1844\n",
      "2022-02-23 21:56:43,999 - INFO: | epoch  31 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.55 | loss-text 3.2353\n",
      "2022-02-23 21:56:51,586 - INFO: | epoch  31 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.2027\n",
      "2022-02-23 21:56:59,109 - INFO: | epoch  31 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.22 | loss-text 3.1527\n",
      "2022-02-23 21:57:06,653 - INFO: | epoch  31 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.43 | loss-text 3.1602\n",
      "2022-02-23 21:57:14,223 - INFO: | epoch  31 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.2180\n",
      "2022-02-23 21:57:21,769 - INFO: | epoch  31 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.2133\n",
      "2022-02-23 21:57:29,374 - INFO: | epoch  31 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.1931\n",
      "2022-02-23 21:57:36,928 - INFO: | epoch  31 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.54 | loss-text 3.1995\n",
      "2022-02-23 21:57:44,540 - INFO: | epoch  31 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.1724\n",
      "2022-02-23 21:57:52,129 - INFO: | epoch  31 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.88 | loss-text 3.1804\n",
      "2022-02-23 21:57:59,698 - INFO: | epoch  31 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.68 | loss-text 3.1965\n",
      "2022-02-23 21:58:07,290 - INFO: | epoch  31 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.2344\n",
      "2022-02-23 21:58:14,817 - INFO: | epoch  31 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.27 | loss-text 3.2090\n",
      "2022-02-23 21:58:22,364 - INFO: | epoch  31 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.1627\n",
      "2022-02-23 21:58:29,978 - INFO: | epoch  31 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.13 | loss-text 3.2284\n",
      "2022-02-23 21:58:37,581 - INFO: | epoch  31 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.1466\n",
      "2022-02-23 21:58:45,223 - INFO: | epoch  31 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.42 | loss-text 3.2042\n",
      "2022-02-23 21:58:52,818 - INFO: | epoch  31 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.1811\n",
      "2022-02-23 21:59:00,498 - INFO: | epoch  31 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.79 | loss-text 3.1861\n",
      "2022-02-23 21:59:08,109 - INFO: | epoch  31 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.10 | loss-text 3.1857\n",
      "2022-02-23 21:59:15,673 - INFO: | epoch  31 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.63 | loss-text 3.1883\n",
      "2022-02-23 21:59:23,240 - INFO: | epoch  31 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.1815\n",
      "2022-02-23 21:59:30,837 - INFO: | epoch  31 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.2430\n",
      "2022-02-23 21:59:38,428 - INFO: | epoch  31 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.2178\n",
      "2022-02-23 21:59:46,012 - INFO: | epoch  31 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003671\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9869, 'reflen': 10171, 'guess': [9869, 8845, 7821, 6797], 'correct': [5450, 1944, 740, 240]}\n",
      "ratio: 0.9703077376854812\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.338\n",
      "Bleu_3: 0.219\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.335\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.223\n",
      "2022-02-23 22:00:26,709 - INFO: eval_greddy SPIDEr: 0.2231\n",
      "loading annotations into memory...\n",
      "0:00:00.003928\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8343, 'reflen': 9449, 'guess': [8343, 7319, 6295, 5271], 'correct': [4963, 1843, 720, 233]}\n",
      "ratio: 0.8829505767805182\n",
      "Bleu_1: 0.521\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.350\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2022-02-23 22:00:55,013 - INFO: eval_beam_2 SPIDEr: 0.2300\n",
      "loading annotations into memory...\n",
      "0:00:00.003959\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7912, 'reflen': 9376, 'guess': [7912, 6888, 5864, 4840], 'correct': [4805, 1852, 772, 278]}\n",
      "ratio: 0.8438566552900123\n",
      "Bleu_1: 0.505\n",
      "Bleu_2: 0.336\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2022-02-23 22:01:26,563 - INFO: eval_beam_3 SPIDEr: 0.2399\n",
      "loading annotations into memory...\n",
      "0:00:00.004006\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7507, 'reflen': 9278, 'guess': [7507, 6483, 5459, 4435], 'correct': [4598, 1800, 731, 239]}\n",
      "ratio: 0.8091183444707039\n",
      "Bleu_1: 0.484\n",
      "Bleu_2: 0.326\n",
      "Bleu_3: 0.224\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.356\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2022-02-23 22:02:01,319 - INFO: eval_beam_4 SPIDEr: 0.2307\n",
      "2022-02-23 22:02:09,091 - INFO: | epoch  32 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.69 | loss-text 3.1837\n",
      "2022-02-23 22:02:16,585 - INFO: | epoch  32 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.93 | loss-text 3.1605\n",
      "2022-02-23 22:02:24,126 - INFO: | epoch  32 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.1186\n",
      "2022-02-23 22:02:31,713 - INFO: | epoch  32 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.2293\n",
      "2022-02-23 22:02:39,252 - INFO: | epoch  32 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.38 | loss-text 3.1581\n",
      "2022-02-23 22:02:46,804 - INFO: | epoch  32 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.51 | loss-text 3.1583\n",
      "2022-02-23 22:02:54,333 - INFO: | epoch  32 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.28 | loss-text 3.1870\n",
      "2022-02-23 22:03:01,910 - INFO: | epoch  32 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.77 | loss-text 3.2146\n",
      "2022-02-23 22:03:09,457 - INFO: | epoch  32 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.1942\n",
      "2022-02-23 22:03:17,004 - INFO: | epoch  32 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.47 | loss-text 3.2386\n",
      "2022-02-23 22:03:24,568 - INFO: | epoch  32 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.1922\n",
      "2022-02-23 22:03:32,123 - INFO: | epoch  32 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.54 | loss-text 3.1763\n",
      "2022-02-23 22:03:39,725 - INFO: | epoch  32 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.1878\n",
      "2022-02-23 22:03:47,338 - INFO: | epoch  32 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.12 | loss-text 3.1819\n",
      "2022-02-23 22:03:54,949 - INFO: | epoch  32 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.10 | loss-text 3.1915\n",
      "2022-02-23 22:04:02,541 - INFO: | epoch  32 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.92 | loss-text 3.1801\n",
      "2022-02-23 22:04:10,152 - INFO: | epoch  32 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.1744\n",
      "2022-02-23 22:04:17,719 - INFO: | epoch  32 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.1586\n",
      "2022-02-23 22:04:25,250 - INFO: | epoch  32 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.30 | loss-text 3.1710\n",
      "2022-02-23 22:04:32,858 - INFO: | epoch  32 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.1814\n",
      "2022-02-23 22:04:40,493 - INFO: | epoch  32 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.34 | loss-text 3.1883\n",
      "2022-02-23 22:04:48,058 - INFO: | epoch  32 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.1308\n",
      "2022-02-23 22:04:55,705 - INFO: | epoch  32 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.46 | loss-text 3.1700\n",
      "2022-02-23 22:05:03,280 - INFO: | epoch  32 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.74 | loss-text 3.2033\n",
      "2022-02-23 22:05:10,961 - INFO: | epoch  32 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.80 | loss-text 3.1811\n",
      "2022-02-23 22:05:18,565 - INFO: | epoch  32 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.1662\n",
      "2022-02-23 22:05:26,190 - INFO: | epoch  32 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.1954\n",
      "2022-02-23 22:05:33,831 - INFO: | epoch  32 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.40 | loss-text 3.1680\n",
      "2022-02-23 22:05:41,451 - INFO: | epoch  32 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.20 | loss-text 3.1691\n",
      "2022-02-23 22:05:49,064 - INFO: | epoch  32 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.12 | loss-text 3.2266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003885\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10791, 'reflen': 10693, 'guess': [10791, 9767, 8743, 7719], 'correct': [5714, 2005, 724, 214]}\n",
      "ratio: 1.009164874216683\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.126\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.316\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.212\n",
      "2022-02-23 22:06:33,498 - INFO: eval_greddy SPIDEr: 0.2123\n",
      "loading annotations into memory...\n",
      "0:00:00.003768\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9244, 'reflen': 9883, 'guess': [9244, 8220, 7196, 6172], 'correct': [5374, 1962, 772, 268]}\n",
      "ratio: 0.9353435191742451\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.358\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2022-02-23 22:07:02,463 - INFO: eval_beam_2 SPIDEr: 0.2353\n",
      "loading annotations into memory...\n",
      "0:00:00.003867\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8652, 'reflen': 9632, 'guess': [8652, 7628, 6604, 5580], 'correct': [5171, 1896, 771, 273]}\n",
      "ratio: 0.898255813953395\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.356\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2022-02-23 22:07:35,702 - INFO: eval_beam_3 SPIDEr: 0.2328\n",
      "loading annotations into memory...\n",
      "0:00:00.003939\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8048, 'reflen': 9419, 'guess': [8048, 7024, 6000, 4976], 'correct': [4861, 1822, 735, 240]}\n",
      "ratio: 0.854443146830783\n",
      "Bleu_1: 0.509\n",
      "Bleu_2: 0.334\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.350\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2022-02-23 22:08:13,469 - INFO: eval_beam_4 SPIDEr: 0.2277\n",
      "2022-02-23 22:08:21,197 - INFO: | epoch  33 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.25 | loss-text 3.1967\n",
      "2022-02-23 22:08:28,670 - INFO: | epoch  33 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.72 | loss-text 3.1945\n",
      "2022-02-23 22:08:36,199 - INFO: | epoch  33 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.28 | loss-text 3.1300\n",
      "2022-02-23 22:08:43,679 - INFO: | epoch  33 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 74.80 | loss-text 3.1888\n",
      "2022-02-23 22:08:51,158 - INFO: | epoch  33 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 74.78 | loss-text 3.1266\n",
      "2022-02-23 22:08:58,724 - INFO: | epoch  33 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.1316\n",
      "2022-02-23 22:09:06,233 - INFO: | epoch  33 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.09 | loss-text 3.1902\n",
      "2022-02-23 22:09:13,799 - INFO: | epoch  33 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.1910\n",
      "2022-02-23 22:09:21,403 - INFO: | epoch  33 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.1574\n",
      "2022-02-23 22:09:29,003 - INFO: | epoch  33 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.99 | loss-text 3.1532\n",
      "2022-02-23 22:09:36,551 - INFO: | epoch  33 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.47 | loss-text 3.1955\n",
      "2022-02-23 22:09:44,133 - INFO: | epoch  33 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.82 | loss-text 3.1760\n",
      "2022-02-23 22:09:51,658 - INFO: | epoch  33 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.24 | loss-text 3.1203\n",
      "2022-02-23 22:09:59,210 - INFO: | epoch  33 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.51 | loss-text 3.2257\n",
      "2022-02-23 22:10:06,815 - INFO: | epoch  33 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.05 | loss-text 3.1478\n",
      "2022-02-23 22:10:14,372 - INFO: | epoch  33 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.56 | loss-text 3.1844\n",
      "2022-02-23 22:10:21,968 - INFO: | epoch  33 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.2124\n",
      "2022-02-23 22:10:29,504 - INFO: | epoch  33 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.35 | loss-text 3.2270\n",
      "2022-02-23 22:10:37,072 - INFO: | epoch  33 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.1566\n",
      "2022-02-23 22:10:44,639 - INFO: | epoch  33 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.2020\n",
      "2022-02-23 22:10:52,228 - INFO: | epoch  33 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.1499\n",
      "2022-02-23 22:10:59,871 - INFO: | epoch  33 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.42 | loss-text 3.2145\n",
      "2022-02-23 22:11:07,442 - INFO: | epoch  33 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.1834\n",
      "2022-02-23 22:11:15,070 - INFO: | epoch  33 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.27 | loss-text 3.1292\n",
      "2022-02-23 22:11:22,698 - INFO: | epoch  33 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.27 | loss-text 3.2074\n",
      "2022-02-23 22:11:30,288 - INFO: | epoch  33 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.1758\n",
      "2022-02-23 22:11:37,841 - INFO: | epoch  33 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.52 | loss-text 3.1978\n",
      "2022-02-23 22:11:45,457 - INFO: | epoch  33 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.16 | loss-text 3.1790\n",
      "2022-02-23 22:11:53,032 - INFO: | epoch  33 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.1765\n",
      "2022-02-23 22:12:00,648 - INFO: | epoch  33 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.16 | loss-text 3.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003935\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10350, 'reflen': 10383, 'guess': [10350, 9326, 8302, 7278], 'correct': [5529, 1925, 681, 199]}\n",
      "ratio: 0.9968217278242322\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.125\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.314\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.211\n",
      "2022-02-23 22:12:41,125 - INFO: eval_greddy SPIDEr: 0.2110\n",
      "loading annotations into memory...\n",
      "0:00:00.003865\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8898, 'reflen': 9622, 'guess': [8898, 7874, 6850, 5826], 'correct': [5153, 1868, 732, 247]}\n",
      "ratio: 0.9247557680314981\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.342\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.354\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2022-02-23 22:13:08,971 - INFO: eval_beam_2 SPIDEr: 0.2312\n",
      "loading annotations into memory...\n",
      "0:00:00.003641\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8237, 'reflen': 9403, 'guess': [8237, 7213, 6189, 5165], 'correct': [4879, 1804, 727, 260]}\n",
      "ratio: 0.8759970222268556\n",
      "Bleu_1: 0.514\n",
      "Bleu_2: 0.334\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.357\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2022-02-23 22:13:42,303 - INFO: eval_beam_3 SPIDEr: 0.2315\n",
      "loading annotations into memory...\n",
      "0:00:00.004159\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7756, 'reflen': 9304, 'guess': [7756, 6732, 5708, 4684], 'correct': [4697, 1756, 722, 254]}\n",
      "ratio: 0.8336199484091967\n",
      "Bleu_1: 0.496\n",
      "Bleu_2: 0.326\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.355\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2022-02-23 22:14:19,770 - INFO: eval_beam_4 SPIDEr: 0.2294\n",
      "2022-02-23 22:14:27,572 - INFO: | epoch  34 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.00 | loss-text 3.1749\n",
      "2022-02-23 22:14:35,054 - INFO: | epoch  34 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.80 | loss-text 3.1339\n",
      "2022-02-23 22:14:42,611 - INFO: | epoch  34 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.56 | loss-text 3.1213\n",
      "2022-02-23 22:14:50,177 - INFO: | epoch  34 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.1883\n",
      "2022-02-23 22:14:57,775 - INFO: | epoch  34 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.97 | loss-text 3.1682\n",
      "2022-02-23 22:15:05,296 - INFO: | epoch  34 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.20 | loss-text 3.1513\n",
      "2022-02-23 22:15:12,840 - INFO: | epoch  34 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.1870\n",
      "2022-02-23 22:15:20,400 - INFO: | epoch  34 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.58 | loss-text 3.1733\n",
      "2022-02-23 22:15:27,984 - INFO: | epoch  34 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.1792\n",
      "2022-02-23 22:15:35,475 - INFO: | epoch  34 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 74.90 | loss-text 3.1833\n",
      "2022-02-23 22:15:43,060 - INFO: | epoch  34 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.1969\n",
      "2022-02-23 22:15:50,753 - INFO: | epoch  34 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 76.63 | loss-text 3.1351\n",
      "2022-02-23 22:15:58,349 - INFO: | epoch  34 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.95 | loss-text 3.2087\n",
      "2022-02-23 22:16:05,972 - INFO: | epoch  34 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.23 | loss-text 3.1264\n",
      "2022-02-23 22:16:13,563 - INFO: | epoch  34 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.1651\n",
      "2022-02-23 22:16:21,172 - INFO: | epoch  34 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.09 | loss-text 3.1515\n",
      "2022-02-23 22:16:28,732 - INFO: | epoch  34 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.59 | loss-text 3.1546\n",
      "2022-02-23 22:16:36,338 - INFO: | epoch  34 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.05 | loss-text 3.1886\n",
      "2022-02-23 22:16:43,890 - INFO: | epoch  34 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.51 | loss-text 3.1756\n",
      "2022-02-23 22:16:51,516 - INFO: | epoch  34 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.25 | loss-text 3.1491\n",
      "2022-02-23 22:16:59,103 - INFO: | epoch  34 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.1515\n",
      "2022-02-23 22:17:06,710 - INFO: | epoch  34 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.2336\n",
      "2022-02-23 22:17:14,361 - INFO: | epoch  34 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.50 | loss-text 3.1843\n",
      "2022-02-23 22:17:21,920 - INFO: | epoch  34 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.59 | loss-text 3.1636\n",
      "2022-02-23 22:17:29,596 - INFO: | epoch  34 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.75 | loss-text 3.1616\n",
      "2022-02-23 22:17:37,168 - INFO: | epoch  34 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.1550\n",
      "2022-02-23 22:17:44,798 - INFO: | epoch  34 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.30 | loss-text 3.1776\n",
      "2022-02-23 22:17:52,376 - INFO: | epoch  34 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.77 | loss-text 3.1580\n",
      "2022-02-23 22:18:00,019 - INFO: | epoch  34 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.42 | loss-text 3.1557\n",
      "2022-02-23 22:18:07,603 - INFO: | epoch  34 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.1855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003748\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10759, 'reflen': 10682, 'guess': [10759, 9735, 8711, 7687], 'correct': [5771, 2055, 757, 231]}\n",
      "ratio: 1.0072083879422387\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.336\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.131\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.325\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.218\n",
      "2022-02-23 22:18:49,269 - INFO: eval_greddy SPIDEr: 0.2181\n",
      "loading annotations into memory...\n",
      "0:00:00.004069\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8954, 'reflen': 9654, 'guess': [8954, 7930, 6906, 5882], 'correct': [5265, 1979, 783, 269]}\n",
      "ratio: 0.9274911953593404\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.374\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2022-02-23 22:19:19,071 - INFO: eval_beam_2 SPIDEr: 0.2384\n",
      "loading annotations into memory...\n",
      "0:00:00.003960\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8279, 'reflen': 9426, 'guess': [8279, 7255, 6231, 5207], 'correct': [4980, 1915, 797, 288]}\n",
      "ratio: 0.878315298111513\n",
      "Bleu_1: 0.524\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.373\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2022-02-23 22:19:51,546 - INFO: eval_beam_3 SPIDEr: 0.2369\n",
      "loading annotations into memory...\n",
      "0:00:00.003908\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7664, 'reflen': 9288, 'guess': [7664, 6640, 5616, 4592], 'correct': [4668, 1801, 762, 281]}\n",
      "ratio: 0.8251507321273874\n",
      "Bleu_1: 0.493\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.358\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2022-02-23 22:20:28,021 - INFO: eval_beam_4 SPIDEr: 0.2313\n",
      "2022-02-23 22:20:35,834 - INFO: | epoch  35 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.10 | loss-text 3.1556\n",
      "2022-02-23 22:20:43,397 - INFO: | epoch  35 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.1081\n",
      "2022-02-23 22:20:50,921 - INFO: | epoch  35 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.23 | loss-text 3.1468\n",
      "2022-02-23 22:20:58,357 - INFO: | epoch  35 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 74.36 | loss-text 3.1537\n",
      "2022-02-23 22:21:05,907 - INFO: | epoch  35 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.49 | loss-text 3.1180\n",
      "2022-02-23 22:21:13,444 - INFO: | epoch  35 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.37 | loss-text 3.1202\n",
      "2022-02-23 22:21:21,016 - INFO: | epoch  35 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.1538\n",
      "2022-02-23 22:21:28,562 - INFO: | epoch  35 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.1933\n",
      "2022-02-23 22:21:36,106 - INFO: | epoch  35 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.43 | loss-text 3.1537\n",
      "2022-02-23 22:21:43,693 - INFO: | epoch  35 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.1642\n",
      "2022-02-23 22:21:51,240 - INFO: | epoch  35 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.1556\n",
      "2022-02-23 22:21:58,853 - INFO: | epoch  35 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 76.13 | loss-text 3.1766\n",
      "2022-02-23 22:22:06,396 - INFO: | epoch  35 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.42 | loss-text 3.1986\n",
      "2022-02-23 22:22:14,008 - INFO: | epoch  35 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.1573\n",
      "2022-02-23 22:22:21,615 - INFO: | epoch  35 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.1201\n",
      "2022-02-23 22:22:29,240 - INFO: | epoch  35 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.1510\n",
      "2022-02-23 22:22:36,861 - INFO: | epoch  35 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.20 | loss-text 3.1608\n",
      "2022-02-23 22:22:44,455 - INFO: | epoch  35 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.1334\n",
      "2022-02-23 22:22:52,043 - INFO: | epoch  35 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.1533\n",
      "2022-02-23 22:22:59,668 - INFO: | epoch  35 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.25 | loss-text 3.1660\n",
      "2022-02-23 22:23:07,290 - INFO: | epoch  35 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.20 | loss-text 3.1625\n",
      "2022-02-23 22:23:14,876 - INFO: | epoch  35 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.85 | loss-text 3.1714\n",
      "2022-02-23 22:23:22,521 - INFO: | epoch  35 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.44 | loss-text 3.2108\n",
      "2022-02-23 22:23:30,099 - INFO: | epoch  35 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.78 | loss-text 3.1523\n",
      "2022-02-23 22:23:37,739 - INFO: | epoch  35 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.39 | loss-text 3.1579\n",
      "2022-02-23 22:23:45,322 - INFO: | epoch  35 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.1373\n",
      "2022-02-23 22:23:52,969 - INFO: | epoch  35 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.45 | loss-text 3.1557\n",
      "2022-02-23 22:24:00,545 - INFO: | epoch  35 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.76 | loss-text 3.1706\n",
      "2022-02-23 22:24:08,199 - INFO: | epoch  35 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.54 | loss-text 3.1479\n",
      "2022-02-23 22:24:15,830 - INFO: | epoch  35 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.30 | loss-text 3.2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003766\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10756, 'reflen': 10676, 'guess': [10756, 9732, 8708, 7684], 'correct': [5713, 2003, 772, 244]}\n",
      "ratio: 1.007493443237073\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.329\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.219\n",
      "2022-02-23 22:24:57,440 - INFO: eval_greddy SPIDEr: 0.2185\n",
      "loading annotations into memory...\n",
      "0:00:00.003911\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9084, 'reflen': 9761, 'guess': [9084, 8060, 7036, 6012], 'correct': [5269, 1941, 796, 273]}\n",
      "ratio: 0.930642352217915\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2022-02-23 22:25:27,778 - INFO: eval_beam_2 SPIDEr: 0.2340\n",
      "loading annotations into memory...\n",
      "0:00:00.004002\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8428, 'reflen': 9516, 'guess': [8428, 7404, 6380, 5356], 'correct': [5009, 1881, 773, 274]}\n",
      "ratio: 0.885666246321891\n",
      "Bleu_1: 0.522\n",
      "Bleu_2: 0.342\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.352\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2022-02-23 22:26:00,291 - INFO: eval_beam_3 SPIDEr: 0.2283\n",
      "loading annotations into memory...\n",
      "0:00:00.003889\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7813, 'reflen': 9340, 'guess': [7813, 6789, 5765, 4741], 'correct': [4749, 1836, 776, 267]}\n",
      "ratio: 0.8365096359742145\n",
      "Bleu_1: 0.500\n",
      "Bleu_2: 0.333\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.348\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2022-02-23 22:26:37,035 - INFO: eval_beam_4 SPIDEr: 0.2246\n",
      "2022-02-23 22:26:44,808 - INFO: | epoch  36 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.70 | loss-text 3.1150\n",
      "2022-02-23 22:26:52,355 - INFO: | epoch  36 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.1483\n",
      "2022-02-23 22:26:59,865 - INFO: | epoch  36 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.09 | loss-text 3.1149\n",
      "2022-02-23 22:27:07,460 - INFO: | epoch  36 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.1878\n",
      "2022-02-23 22:27:14,944 - INFO: | epoch  36 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 74.84 | loss-text 3.1308\n",
      "2022-02-23 22:27:22,517 - INFO: | epoch  36 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.73 | loss-text 3.1622\n",
      "2022-02-23 22:27:30,060 - INFO: | epoch  36 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.42 | loss-text 3.1756\n",
      "2022-02-23 22:27:37,648 - INFO: | epoch  36 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.1140\n",
      "2022-02-23 22:27:45,267 - INFO: | epoch  36 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.1950\n",
      "2022-02-23 22:27:52,848 - INFO: | epoch  36 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.81 | loss-text 3.1934\n",
      "2022-02-23 22:28:00,410 - INFO: | epoch  36 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.61 | loss-text 3.1407\n",
      "2022-02-23 22:28:08,025 - INFO: | epoch  36 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 76.14 | loss-text 3.1204\n",
      "2022-02-23 22:28:15,643 - INFO: | epoch  36 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.1330\n",
      "2022-02-23 22:28:23,252 - INFO: | epoch  36 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.09 | loss-text 3.2086\n",
      "2022-02-23 22:28:30,828 - INFO: | epoch  36 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.1192\n",
      "2022-02-23 22:28:38,401 - INFO: | epoch  36 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.73 | loss-text 3.1564\n",
      "2022-02-23 22:28:46,017 - INFO: | epoch  36 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.16 | loss-text 3.1401\n",
      "2022-02-23 22:28:53,609 - INFO: | epoch  36 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.1785\n",
      "2022-02-23 22:29:01,176 - INFO: | epoch  36 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.1285\n",
      "2022-02-23 22:29:08,816 - INFO: | epoch  36 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.39 | loss-text 3.1797\n",
      "2022-02-23 22:29:16,416 - INFO: | epoch  36 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.99 | loss-text 3.1062\n",
      "2022-02-23 22:29:24,050 - INFO: | epoch  36 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.33 | loss-text 3.1719\n",
      "2022-02-23 22:29:31,668 - INFO: | epoch  36 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.1419\n",
      "2022-02-23 22:29:39,247 - INFO: | epoch  36 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.79 | loss-text 3.1161\n",
      "2022-02-23 22:29:46,873 - INFO: | epoch  36 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.25 | loss-text 3.1127\n",
      "2022-02-23 22:29:54,502 - INFO: | epoch  36 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.29 | loss-text 3.1506\n",
      "2022-02-23 22:30:02,075 - INFO: | epoch  36 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.1475\n",
      "2022-02-23 22:30:09,702 - INFO: | epoch  36 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.26 | loss-text 3.1435\n",
      "2022-02-23 22:30:17,380 - INFO: | epoch  36 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.78 | loss-text 3.1858\n",
      "2022-02-23 22:30:24,953 - INFO: | epoch  36 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003929\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10133, 'reflen': 10343, 'guess': [10133, 9109, 8085, 7061], 'correct': [5517, 1909, 699, 209]}\n",
      "ratio: 0.9796964130328744\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2022-02-23 22:31:06,897 - INFO: eval_greddy SPIDEr: 0.2173\n",
      "loading annotations into memory...\n",
      "0:00:00.003928\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8545, 'reflen': 9547, 'guess': [8545, 7521, 6497, 5473], 'correct': [5029, 1857, 740, 254]}\n",
      "ratio: 0.8950455640514408\n",
      "Bleu_1: 0.523\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.360\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2022-02-23 22:31:34,963 - INFO: eval_beam_2 SPIDEr: 0.2353\n",
      "loading annotations into memory...\n",
      "0:00:00.003907\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7993, 'reflen': 9378, 'guess': [7993, 6969, 5945, 4921], 'correct': [4775, 1802, 743, 272]}\n",
      "ratio: 0.8523139262101884\n",
      "Bleu_1: 0.502\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2022-02-23 22:32:06,848 - INFO: eval_beam_3 SPIDEr: 0.2334\n",
      "loading annotations into memory...\n",
      "0:00:00.003813\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7596, 'reflen': 9310, 'guess': [7596, 6572, 5548, 4524], 'correct': [4558, 1725, 714, 262]}\n",
      "ratio: 0.8158968850697297\n",
      "Bleu_1: 0.479\n",
      "Bleu_2: 0.317\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.353\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2022-02-23 22:32:44,078 - INFO: eval_beam_4 SPIDEr: 0.2276\n",
      "2022-02-23 22:32:51,856 - INFO: | epoch  37 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.74 | loss-text 3.1426\n",
      "2022-02-23 22:32:59,357 - INFO: | epoch  37 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.00 | loss-text 3.1303\n",
      "2022-02-23 22:33:06,870 - INFO: | epoch  37 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.12 | loss-text 3.1642\n",
      "2022-02-23 22:33:14,440 - INFO: | epoch  37 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.69 | loss-text 3.1085\n",
      "2022-02-23 22:33:22,027 - INFO: | epoch  37 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.1555\n",
      "2022-02-23 22:33:29,583 - INFO: | epoch  37 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.56 | loss-text 3.1774\n",
      "2022-02-23 22:33:37,129 - INFO: | epoch  37 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.45 | loss-text 3.1078\n",
      "2022-02-23 22:33:44,627 - INFO: | epoch  37 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 74.98 | loss-text 3.0921\n",
      "2022-02-23 22:33:52,230 - INFO: | epoch  37 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.1252\n",
      "2022-02-23 22:33:59,779 - INFO: | epoch  37 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.47 | loss-text 3.1505\n",
      "2022-02-23 22:34:07,353 - INFO: | epoch  37 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.73 | loss-text 3.1413\n",
      "2022-02-23 22:34:14,913 - INFO: | epoch  37 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.59 | loss-text 3.1432\n",
      "2022-02-23 22:34:22,495 - INFO: | epoch  37 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.82 | loss-text 3.1446\n",
      "2022-02-23 22:34:30,119 - INFO: | epoch  37 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.23 | loss-text 3.1326\n",
      "2022-02-23 22:34:37,740 - INFO: | epoch  37 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.21 | loss-text 3.1165\n",
      "2022-02-23 22:34:45,332 - INFO: | epoch  37 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.1305\n",
      "2022-02-23 22:34:52,954 - INFO: | epoch  37 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.22 | loss-text 3.1340\n",
      "2022-02-23 22:35:00,608 - INFO: | epoch  37 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.54 | loss-text 3.1519\n",
      "2022-02-23 22:35:08,196 - INFO: | epoch  37 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.1698\n",
      "2022-02-23 22:35:15,801 - INFO: | epoch  37 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.1695\n",
      "2022-02-23 22:35:23,414 - INFO: | epoch  37 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.13 | loss-text 3.1390\n",
      "2022-02-23 22:35:31,082 - INFO: | epoch  37 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.67 | loss-text 3.1428\n",
      "2022-02-23 22:35:38,754 - INFO: | epoch  37 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.72 | loss-text 3.1289\n",
      "2022-02-23 22:35:46,385 - INFO: | epoch  37 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.30 | loss-text 3.1767\n",
      "2022-02-23 22:35:54,028 - INFO: | epoch  37 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.42 | loss-text 3.1359\n",
      "2022-02-23 22:36:01,673 - INFO: | epoch  37 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.44 | loss-text 3.1240\n",
      "2022-02-23 22:36:09,288 - INFO: | epoch  37 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.15 | loss-text 3.1705\n",
      "2022-02-23 22:36:16,916 - INFO: | epoch  37 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.27 | loss-text 3.1683\n",
      "2022-02-23 22:36:24,524 - INFO: | epoch  37 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.1257\n",
      "2022-02-23 22:36:32,128 - INFO: | epoch  37 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003837\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10625, 'reflen': 10672, 'guess': [10625, 9601, 8577, 7553], 'correct': [5668, 1989, 743, 228]}\n",
      "ratio: 0.9955959520238947\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.332\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.220\n",
      "2022-02-23 22:37:13,534 - INFO: eval_greddy SPIDEr: 0.2201\n",
      "loading annotations into memory...\n",
      "0:00:00.004041\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9005, 'reflen': 9758, 'guess': [9005, 7981, 6957, 5933], 'correct': [5208, 1946, 787, 262]}\n",
      "ratio: 0.922832547653113\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2022-02-23 22:37:43,111 - INFO: eval_beam_2 SPIDEr: 0.2393\n",
      "loading annotations into memory...\n",
      "0:00:00.003774\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8340, 'reflen': 9488, 'guess': [8340, 7316, 6292, 5268], 'correct': [4948, 1862, 769, 270]}\n",
      "ratio: 0.8790050590218298\n",
      "Bleu_1: 0.517\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2022-02-23 22:38:15,718 - INFO: eval_beam_3 SPIDEr: 0.2323\n",
      "loading annotations into memory...\n",
      "0:00:00.003859\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7770, 'reflen': 9339, 'guess': [7770, 6746, 5722, 4698], 'correct': [4659, 1764, 727, 245]}\n",
      "ratio: 0.8319948602633224\n",
      "Bleu_1: 0.490\n",
      "Bleu_2: 0.324\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.347\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2022-02-23 22:38:53,593 - INFO: eval_beam_4 SPIDEr: 0.2248\n",
      "2022-02-23 22:39:01,383 - INFO: | epoch  38 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.88 | loss-text 3.0942\n",
      "2022-02-23 22:39:08,869 - INFO: | epoch  38 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.85 | loss-text 3.1209\n",
      "2022-02-23 22:39:16,402 - INFO: | epoch  38 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.32 | loss-text 3.1119\n",
      "2022-02-23 22:39:23,914 - INFO: | epoch  38 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.11 | loss-text 3.1471\n",
      "2022-02-23 22:39:31,400 - INFO: | epoch  38 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 74.85 | loss-text 3.0798\n",
      "2022-02-23 22:39:38,983 - INFO: | epoch  38 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.1233\n",
      "2022-02-23 22:39:46,545 - INFO: | epoch  38 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.61 | loss-text 3.1498\n",
      "2022-02-23 22:39:54,103 - INFO: | epoch  38 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.58 | loss-text 3.1145\n",
      "2022-02-23 22:40:01,702 - INFO: | epoch  38 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.99 | loss-text 3.1742\n",
      "2022-02-23 22:40:09,268 - INFO: | epoch  38 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.1703\n",
      "2022-02-23 22:40:16,782 - INFO: | epoch  38 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.13 | loss-text 3.1267\n",
      "2022-02-23 22:40:24,298 - INFO: | epoch  38 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.16 | loss-text 3.1680\n",
      "2022-02-23 22:40:31,881 - INFO: | epoch  38 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.82 | loss-text 3.1352\n",
      "2022-02-23 22:40:39,431 - INFO: | epoch  38 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.49 | loss-text 3.1347\n",
      "2022-02-23 22:40:47,008 - INFO: | epoch  38 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.76 | loss-text 3.1592\n",
      "2022-02-23 22:40:54,576 - INFO: | epoch  38 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.1240\n",
      "2022-02-23 22:41:02,178 - INFO: | epoch  38 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.02 | loss-text 3.1375\n",
      "2022-02-23 22:41:09,783 - INFO: | epoch  38 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.1019\n",
      "2022-02-23 22:41:17,371 - INFO: | epoch  38 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.88 | loss-text 3.1279\n",
      "2022-02-23 22:41:24,994 - INFO: | epoch  38 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.22 | loss-text 3.1371\n",
      "2022-02-23 22:41:32,552 - INFO: | epoch  38 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.1064\n",
      "2022-02-23 22:41:40,151 - INFO: | epoch  38 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.1145\n",
      "2022-02-23 22:41:47,777 - INFO: | epoch  38 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.26 | loss-text 3.1242\n",
      "2022-02-23 22:41:55,342 - INFO: | epoch  38 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.1190\n",
      "2022-02-23 22:42:02,915 - INFO: | epoch  38 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.1220\n",
      "2022-02-23 22:42:10,529 - INFO: | epoch  38 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.14 | loss-text 3.1839\n",
      "2022-02-23 22:42:18,165 - INFO: | epoch  38 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.35 | loss-text 3.1390\n",
      "2022-02-23 22:42:25,799 - INFO: | epoch  38 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.33 | loss-text 3.1617\n",
      "2022-02-23 22:42:33,406 - INFO: | epoch  38 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.1716\n",
      "2022-02-23 22:42:41,046 - INFO: | epoch  38 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.39 | loss-text 3.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003942\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10691, 'reflen': 10619, 'guess': [10691, 9667, 8643, 7619], 'correct': [5587, 1905, 683, 212]}\n",
      "ratio: 1.0067802994631314\n",
      "Bleu_1: 0.523\n",
      "Bleu_2: 0.321\n",
      "Bleu_3: 0.201\n",
      "Bleu_4: 0.123\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.317\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.211\n",
      "2022-02-23 22:43:23,280 - INFO: eval_greddy SPIDEr: 0.2111\n",
      "loading annotations into memory...\n",
      "0:00:00.003973\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8671, 'reflen': 9620, 'guess': [8671, 7647, 6623, 5599], 'correct': [5125, 1857, 729, 254]}\n",
      "ratio: 0.9013513513512577\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.340\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2022-02-23 22:43:53,009 - INFO: eval_beam_2 SPIDEr: 0.2347\n",
      "loading annotations into memory...\n",
      "0:00:00.004167\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8127, 'reflen': 9436, 'guess': [8127, 7103, 6079, 5055], 'correct': [4837, 1758, 692, 240]}\n",
      "ratio: 0.8612759643916\n",
      "Bleu_1: 0.507\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.344\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2022-02-23 22:44:26,247 - INFO: eval_beam_3 SPIDEr: 0.2247\n",
      "loading annotations into memory...\n",
      "0:00:00.003732\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7603, 'reflen': 9302, 'guess': [7603, 6579, 5555, 4531], 'correct': [4611, 1752, 692, 244]}\n",
      "ratio: 0.8173511072886672\n",
      "Bleu_1: 0.485\n",
      "Bleu_2: 0.321\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.353\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2022-02-23 22:45:04,028 - INFO: eval_beam_4 SPIDEr: 0.2278\n",
      "2022-02-23 22:45:11,838 - INFO: | epoch  39 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.07 | loss-text 3.1223\n",
      "2022-02-23 22:45:19,355 - INFO: | epoch  39 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.15 | loss-text 3.0939\n",
      "2022-02-23 22:45:26,895 - INFO: | epoch  39 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.0951\n",
      "2022-02-23 22:45:34,411 - INFO: | epoch  39 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.15 | loss-text 3.0781\n",
      "2022-02-23 22:45:41,955 - INFO: | epoch  39 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.1092\n",
      "2022-02-23 22:45:49,514 - INFO: | epoch  39 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.58 | loss-text 3.1376\n",
      "2022-02-23 22:45:57,043 - INFO: | epoch  39 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.29 | loss-text 3.0912\n",
      "2022-02-23 22:46:04,595 - INFO: | epoch  39 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.51 | loss-text 3.1032\n",
      "2022-02-23 22:46:12,188 - INFO: | epoch  39 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.92 | loss-text 3.1263\n",
      "2022-02-23 22:46:19,765 - INFO: | epoch  39 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.76 | loss-text 3.1469\n",
      "2022-02-23 22:46:27,337 - INFO: | epoch  39 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.1271\n",
      "2022-02-23 22:46:34,940 - INFO: | epoch  39 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 76.02 | loss-text 3.1195\n",
      "2022-02-23 22:46:42,547 - INFO: | epoch  39 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.1402\n",
      "2022-02-23 22:46:50,144 - INFO: | epoch  39 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.97 | loss-text 3.1505\n",
      "2022-02-23 22:46:57,728 - INFO: | epoch  39 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.0847\n",
      "2022-02-23 22:47:05,335 - INFO: | epoch  39 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.1633\n",
      "2022-02-23 22:47:12,959 - INFO: | epoch  39 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.1232\n",
      "2022-02-23 22:47:20,538 - INFO: | epoch  39 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.79 | loss-text 3.1328\n",
      "2022-02-23 22:47:28,121 - INFO: | epoch  39 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.81 | loss-text 3.1039\n",
      "2022-02-23 22:47:35,727 - INFO: | epoch  39 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.1260\n",
      "2022-02-23 22:47:43,394 - INFO: | epoch  39 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.67 | loss-text 3.1694\n",
      "2022-02-23 22:47:50,954 - INFO: | epoch  39 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.59 | loss-text 3.1437\n",
      "2022-02-23 22:47:58,575 - INFO: | epoch  39 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.20 | loss-text 3.1074\n",
      "2022-02-23 22:48:06,184 - INFO: | epoch  39 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.08 | loss-text 3.1298\n",
      "2022-02-23 22:48:13,728 - INFO: | epoch  39 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.0951\n",
      "2022-02-23 22:48:21,344 - INFO: | epoch  39 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.16 | loss-text 3.1375\n",
      "2022-02-23 22:48:29,000 - INFO: | epoch  39 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.55 | loss-text 3.1104\n",
      "2022-02-23 22:48:36,615 - INFO: | epoch  39 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.14 | loss-text 3.1302\n",
      "2022-02-23 22:48:44,251 - INFO: | epoch  39 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.36 | loss-text 3.1676\n",
      "2022-02-23 22:48:51,855 - INFO: | epoch  39 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003880\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10397, 'reflen': 10508, 'guess': [10397, 9373, 8349, 7325], 'correct': [5739, 2068, 809, 263]}\n",
      "ratio: 0.9894366197182156\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.347\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2022-02-23 22:49:32,598 - INFO: eval_greddy SPIDEr: 0.2298\n",
      "loading annotations into memory...\n",
      "0:00:00.003680\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8797, 'reflen': 9709, 'guess': [8797, 7773, 6749, 5725], 'correct': [5180, 1959, 817, 285]}\n",
      "ratio: 0.9060665362034291\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.375\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2022-02-23 22:50:01,332 - INFO: eval_beam_2 SPIDEr: 0.2440\n",
      "loading annotations into memory...\n",
      "0:00:00.003619\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8283, 'reflen': 9506, 'guess': [8283, 7259, 6235, 5211], 'correct': [4943, 1895, 795, 283]}\n",
      "ratio: 0.8713444140541898\n",
      "Bleu_1: 0.515\n",
      "Bleu_2: 0.341\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2022-02-23 22:50:34,653 - INFO: eval_beam_3 SPIDEr: 0.2404\n",
      "loading annotations into memory...\n",
      "0:00:00.003945\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7743, 'reflen': 9346, 'guess': [7743, 6719, 5695, 4671], 'correct': [4664, 1781, 731, 246]}\n",
      "ratio: 0.828482773378897\n",
      "Bleu_1: 0.490\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.350\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2022-02-23 22:51:10,934 - INFO: eval_beam_4 SPIDEr: 0.2285\n",
      "2022-02-23 22:51:18,680 - INFO: | epoch  40 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.43 | loss-text 3.1166\n",
      "2022-02-23 22:51:26,222 - INFO: | epoch  40 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.41 | loss-text 3.1632\n",
      "2022-02-23 22:51:33,655 - INFO: | epoch  40 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.32 | loss-text 3.0388\n",
      "2022-02-23 22:51:41,178 - INFO: | epoch  40 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.23 | loss-text 3.1514\n",
      "2022-02-23 22:51:48,731 - INFO: | epoch  40 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.52 | loss-text 3.1104\n",
      "2022-02-23 22:51:56,246 - INFO: | epoch  40 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.14 | loss-text 3.0466\n",
      "2022-02-23 22:52:03,831 - INFO: | epoch  40 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.85 | loss-text 3.1191\n",
      "2022-02-23 22:52:11,393 - INFO: | epoch  40 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.61 | loss-text 3.1269\n",
      "2022-02-23 22:52:19,001 - INFO: | epoch  40 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 76.08 | loss-text 3.1083\n",
      "2022-02-23 22:52:26,555 - INFO: | epoch  40 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.53 | loss-text 3.0963\n",
      "2022-02-23 22:52:34,144 - INFO: | epoch  40 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.0982\n",
      "2022-02-23 22:52:41,735 - INFO: | epoch  40 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.0920\n",
      "2022-02-23 22:52:49,293 - INFO: | epoch  40 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.1457\n",
      "2022-02-23 22:52:56,837 - INFO: | epoch  40 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.1319\n",
      "2022-02-23 22:53:04,443 - INFO: | epoch  40 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.05 | loss-text 3.1045\n",
      "2022-02-23 22:53:12,022 - INFO: | epoch  40 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.78 | loss-text 3.1239\n",
      "2022-02-23 22:53:19,608 - INFO: | epoch  40 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.85 | loss-text 3.1273\n",
      "2022-02-23 22:53:27,205 - INFO: | epoch  40 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.0899\n",
      "2022-02-23 22:53:34,798 - INFO: | epoch  40 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.93 | loss-text 3.1626\n",
      "2022-02-23 22:53:42,385 - INFO: | epoch  40 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.1258\n",
      "2022-02-23 22:53:50,051 - INFO: | epoch  40 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.66 | loss-text 3.1207\n",
      "2022-02-23 22:53:57,727 - INFO: | epoch  40 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.75 | loss-text 3.1039\n",
      "2022-02-23 22:54:05,350 - INFO: | epoch  40 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.22 | loss-text 3.1455\n",
      "2022-02-23 22:54:12,954 - INFO: | epoch  40 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.1574\n",
      "2022-02-23 22:54:20,572 - INFO: | epoch  40 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.1108\n",
      "2022-02-23 22:54:28,105 - INFO: | epoch  40 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.33 | loss-text 3.1258\n",
      "2022-02-23 22:54:35,713 - INFO: | epoch  40 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.1108\n",
      "2022-02-23 22:54:43,355 - INFO: | epoch  40 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.41 | loss-text 3.1503\n",
      "2022-02-23 22:54:50,992 - INFO: | epoch  40 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.37 | loss-text 3.0996\n",
      "2022-02-23 22:54:58,624 - INFO: | epoch  40 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.31 | loss-text 3.1409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003769\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10735, 'reflen': 10638, 'guess': [10735, 9711, 8687, 7663], 'correct': [5850, 2106, 801, 239]}\n",
      "ratio: 1.0091182553110538\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.349\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2022-02-23 22:55:40,359 - INFO: eval_greddy SPIDEr: 0.2305\n",
      "loading annotations into memory...\n",
      "0:00:00.003928\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9151, 'reflen': 9807, 'guess': [9151, 8127, 7103, 6079], 'correct': [5432, 2082, 863, 297]}\n",
      "ratio: 0.9331090037727201\n",
      "Bleu_1: 0.553\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.246\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.377\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.384\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.248\n",
      "2022-02-23 22:56:09,428 - INFO: eval_beam_2 SPIDEr: 0.2484\n",
      "loading annotations into memory...\n",
      "0:00:00.003920\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8532, 'reflen': 9595, 'guess': [8532, 7508, 6484, 5460], 'correct': [5150, 1973, 814, 276]}\n",
      "ratio: 0.889213131839407\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.377\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2022-02-23 22:56:43,291 - INFO: eval_beam_3 SPIDEr: 0.2439\n",
      "loading annotations into memory...\n",
      "0:00:00.003850\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7941, 'reflen': 9401, 'guess': [7941, 6917, 5893, 4869], 'correct': [4889, 1925, 797, 264]}\n",
      "ratio: 0.8446973726198441\n",
      "Bleu_1: 0.512\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.377\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2022-02-23 22:57:20,903 - INFO: eval_beam_4 SPIDEr: 0.2427\n",
      "2022-02-23 22:57:28,676 - INFO: | epoch  41 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.70 | loss-text 3.1281\n",
      "2022-02-23 22:57:36,202 - INFO: | epoch  41 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.25 | loss-text 3.1324\n",
      "2022-02-23 22:57:43,748 - INFO: | epoch  41 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.45 | loss-text 3.0696\n",
      "2022-02-23 22:57:51,300 - INFO: | epoch  41 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.51 | loss-text 3.1641\n",
      "2022-02-23 22:57:58,820 - INFO: | epoch  41 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.19 | loss-text 3.0565\n",
      "2022-02-23 22:58:06,425 - INFO: | epoch  41 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 76.05 | loss-text 3.0572\n",
      "2022-02-23 22:58:13,996 - INFO: | epoch  41 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.70 | loss-text 3.0797\n",
      "2022-02-23 22:58:21,566 - INFO: | epoch  41 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.68 | loss-text 3.0646\n",
      "2022-02-23 22:58:29,104 - INFO: | epoch  41 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.38 | loss-text 3.0893\n",
      "2022-02-23 22:58:36,646 - INFO: | epoch  41 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.41 | loss-text 3.0928\n",
      "2022-02-23 22:58:44,250 - INFO: | epoch  41 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.0921\n",
      "2022-02-23 22:58:51,815 - INFO: | epoch  41 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.1416\n",
      "2022-02-23 22:58:59,419 - INFO: | epoch  41 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.0923\n",
      "2022-02-23 22:59:06,926 - INFO: | epoch  41 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.05 | loss-text 3.1244\n",
      "2022-02-23 22:59:14,502 - INFO: | epoch  41 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.1645\n",
      "2022-02-23 22:59:22,104 - INFO: | epoch  41 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.1000\n",
      "2022-02-23 22:59:29,624 - INFO: | epoch  41 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.20 | loss-text 3.1000\n",
      "2022-02-23 22:59:37,182 - INFO: | epoch  41 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.0945\n",
      "2022-02-23 22:59:44,782 - INFO: | epoch  41 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.0942\n",
      "2022-02-23 22:59:52,348 - INFO: | epoch  41 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.1446\n",
      "2022-02-23 22:59:59,973 - INFO: | epoch  41 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.1002\n",
      "2022-02-23 23:00:07,617 - INFO: | epoch  41 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.43 | loss-text 3.1624\n",
      "2022-02-23 23:00:15,229 - INFO: | epoch  41 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.0921\n",
      "2022-02-23 23:00:22,888 - INFO: | epoch  41 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.58 | loss-text 3.1352\n",
      "2022-02-23 23:00:30,474 - INFO: | epoch  41 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.1233\n",
      "2022-02-23 23:00:38,127 - INFO: | epoch  41 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.53 | loss-text 3.1549\n",
      "2022-02-23 23:00:45,756 - INFO: | epoch  41 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.28 | loss-text 3.1171\n",
      "2022-02-23 23:00:53,374 - INFO: | epoch  41 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.18 | loss-text 3.1112\n",
      "2022-02-23 23:01:00,980 - INFO: | epoch  41 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.05 | loss-text 3.0837\n",
      "2022-02-23 23:01:08,604 - INFO: | epoch  41 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.1386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003857\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10411, 'reflen': 10474, 'guess': [10411, 9387, 8363, 7339], 'correct': [5730, 2028, 743, 217]}\n",
      "ratio: 0.9939851059766093\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.342\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2022-02-23 23:01:51,162 - INFO: eval_greddy SPIDEr: 0.2267\n",
      "loading annotations into memory...\n",
      "0:00:00.003643\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8805, 'reflen': 9688, 'guess': [8805, 7781, 6757, 5733], 'correct': [5227, 1937, 782, 270]}\n",
      "ratio: 0.9088563170932175\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2022-02-23 23:02:20,953 - INFO: eval_beam_2 SPIDEr: 0.2397\n",
      "loading annotations into memory...\n",
      "0:00:00.003926\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8228, 'reflen': 9478, 'guess': [8228, 7204, 6180, 5156], 'correct': [4897, 1811, 741, 263]}\n",
      "ratio: 0.8681156362100793\n",
      "Bleu_1: 0.511\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.356\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2022-02-23 23:02:53,559 - INFO: eval_beam_3 SPIDEr: 0.2322\n",
      "loading annotations into memory...\n",
      "0:00:00.003930\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7782, 'reflen': 9355, 'guess': [7782, 6758, 5734, 4710], 'correct': [4636, 1745, 697, 230]}\n",
      "ratio: 0.8318546231960628\n",
      "Bleu_1: 0.487\n",
      "Bleu_2: 0.320\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.344\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2022-02-23 23:03:29,942 - INFO: eval_beam_4 SPIDEr: 0.2246\n",
      "2022-02-23 23:03:37,757 - INFO: | epoch  42 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.12 | loss-text 3.0937\n",
      "2022-02-23 23:03:45,297 - INFO: | epoch  42 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.39 | loss-text 3.0512\n",
      "2022-02-23 23:03:52,795 - INFO: | epoch  42 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.98 | loss-text 3.0563\n",
      "2022-02-23 23:04:00,324 - INFO: | epoch  42 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.28 | loss-text 3.0757\n",
      "2022-02-23 23:04:07,861 - INFO: | epoch  42 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.36 | loss-text 3.1189\n",
      "2022-02-23 23:04:15,419 - INFO: | epoch  42 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.1120\n",
      "2022-02-23 23:04:22,981 - INFO: | epoch  42 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.61 | loss-text 3.0497\n",
      "2022-02-23 23:04:30,521 - INFO: | epoch  42 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.1094\n",
      "2022-02-23 23:04:38,068 - INFO: | epoch  42 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.0670\n",
      "2022-02-23 23:04:45,688 - INFO: | epoch  42 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 76.19 | loss-text 3.0999\n",
      "2022-02-23 23:04:53,243 - INFO: | epoch  42 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.55 | loss-text 3.1262\n",
      "2022-02-23 23:05:00,859 - INFO: | epoch  42 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 76.15 | loss-text 3.1105\n",
      "2022-02-23 23:05:08,460 - INFO: | epoch  42 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.0930\n",
      "2022-02-23 23:05:16,093 - INFO: | epoch  42 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.32 | loss-text 3.1279\n",
      "2022-02-23 23:05:23,657 - INFO: | epoch  42 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.63 | loss-text 3.1073\n",
      "2022-02-23 23:05:31,259 - INFO: | epoch  42 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.0986\n",
      "2022-02-23 23:05:38,858 - INFO: | epoch  42 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.1211\n",
      "2022-02-23 23:05:46,450 - INFO: | epoch  42 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.92 | loss-text 3.1300\n",
      "2022-02-23 23:05:54,068 - INFO: | epoch  42 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.17 | loss-text 3.0923\n",
      "2022-02-23 23:06:01,725 - INFO: | epoch  42 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.56 | loss-text 3.1053\n",
      "2022-02-23 23:06:09,348 - INFO: | epoch  42 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.22 | loss-text 3.1194\n",
      "2022-02-23 23:06:16,911 - INFO: | epoch  42 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.63 | loss-text 3.1306\n",
      "2022-02-23 23:06:24,520 - INFO: | epoch  42 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.09 | loss-text 3.1056\n",
      "2022-02-23 23:06:32,134 - INFO: | epoch  42 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.14 | loss-text 3.0726\n",
      "2022-02-23 23:06:39,671 - INFO: | epoch  42 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 75.36 | loss-text 3.1130\n",
      "2022-02-23 23:06:47,327 - INFO: | epoch  42 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.55 | loss-text 3.1494\n",
      "2022-02-23 23:06:54,940 - INFO: | epoch  42 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.12 | loss-text 3.1064\n",
      "2022-02-23 23:07:02,575 - INFO: | epoch  42 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.34 | loss-text 3.1098\n",
      "2022-02-23 23:07:10,243 - INFO: | epoch  42 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.67 | loss-text 3.1043\n",
      "2022-02-23 23:07:17,844 - INFO: | epoch  42 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003943\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10099, 'reflen': 10279, 'guess': [10099, 9075, 8051, 7027], 'correct': [5614, 2045, 767, 247]}\n",
      "ratio: 0.9824885689268428\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.224\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.372\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.352\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2022-02-23 23:07:59,193 - INFO: eval_greddy SPIDEr: 0.2331\n",
      "loading annotations into memory...\n",
      "0:00:00.003887\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8656, 'reflen': 9647, 'guess': [8656, 7632, 6608, 5584], 'correct': [5183, 1946, 760, 254]}\n",
      "ratio: 0.8972737638643208\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2022-02-23 23:08:27,703 - INFO: eval_beam_2 SPIDEr: 0.2433\n",
      "loading annotations into memory...\n",
      "0:00:00.004048\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8079, 'reflen': 9471, 'guess': [8079, 7055, 6031, 5007], 'correct': [4884, 1818, 715, 246]}\n",
      "ratio: 0.853025023756641\n",
      "Bleu_1: 0.509\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2022-02-23 23:09:00,114 - INFO: eval_beam_3 SPIDEr: 0.2378\n",
      "loading annotations into memory...\n",
      "0:00:00.003864\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7636, 'reflen': 9338, 'guess': [7636, 6612, 5588, 4564], 'correct': [4669, 1758, 696, 240]}\n",
      "ratio: 0.8177339901476957\n",
      "Bleu_1: 0.489\n",
      "Bleu_2: 0.323\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.352\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2022-02-23 23:09:36,119 - INFO: eval_beam_4 SPIDEr: 0.2293\n",
      "2022-02-23 23:09:43,895 - INFO: | epoch  43 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.73 | loss-text 3.0857\n",
      "2022-02-23 23:09:51,415 - INFO: | epoch  43 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.19 | loss-text 3.0742\n",
      "2022-02-23 23:09:58,886 - INFO: | epoch  43 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 74.70 | loss-text 3.1362\n",
      "2022-02-23 23:10:06,415 - INFO: | epoch  43 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.28 | loss-text 3.0850\n",
      "2022-02-23 23:10:13,912 - INFO: | epoch  43 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 74.96 | loss-text 3.1085\n",
      "2022-02-23 23:10:21,467 - INFO: | epoch  43 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.55 | loss-text 3.0840\n",
      "2022-02-23 23:10:29,059 - INFO: | epoch  43 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.0828\n",
      "2022-02-23 23:10:36,575 - INFO: | epoch  43 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.16 | loss-text 3.0851\n",
      "2022-02-23 23:10:44,085 - INFO: | epoch  43 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.09 | loss-text 3.0761\n",
      "2022-02-23 23:10:51,623 - INFO: | epoch  43 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.38 | loss-text 3.0564\n",
      "2022-02-23 23:10:59,142 - INFO: | epoch  43 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.18 | loss-text 3.1454\n",
      "2022-02-23 23:11:06,737 - INFO: | epoch  43 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.94 | loss-text 3.0972\n",
      "2022-02-23 23:11:14,321 - INFO: | epoch  43 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.1119\n",
      "2022-02-23 23:11:21,924 - INFO: | epoch  43 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.0719\n",
      "2022-02-23 23:11:29,468 - INFO: | epoch  43 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.43 | loss-text 3.0715\n",
      "2022-02-23 23:11:37,018 - INFO: | epoch  43 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.49 | loss-text 3.0460\n",
      "2022-02-23 23:11:44,581 - INFO: | epoch  43 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.0909\n",
      "2022-02-23 23:11:52,189 - INFO: | epoch  43 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.0557\n",
      "2022-02-23 23:11:59,802 - INFO: | epoch  43 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.12 | loss-text 3.0968\n",
      "2022-02-23 23:12:07,424 - INFO: | epoch  43 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.21 | loss-text 3.1358\n",
      "2022-02-23 23:12:15,043 - INFO: | epoch  43 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.18 | loss-text 3.0841\n",
      "2022-02-23 23:12:22,658 - INFO: | epoch  43 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.15 | loss-text 3.1020\n",
      "2022-02-23 23:12:30,320 - INFO: | epoch  43 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.61 | loss-text 3.0681\n",
      "2022-02-23 23:12:37,964 - INFO: | epoch  43 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.44 | loss-text 3.0895\n",
      "2022-02-23 23:12:45,578 - INFO: | epoch  43 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.13 | loss-text 3.1113\n",
      "2022-02-23 23:12:53,226 - INFO: | epoch  43 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.47 | loss-text 3.0526\n",
      "2022-02-23 23:13:00,852 - INFO: | epoch  43 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.25 | loss-text 3.1182\n",
      "2022-02-23 23:13:08,508 - INFO: | epoch  43 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.55 | loss-text 3.1180\n",
      "2022-02-23 23:13:16,111 - INFO: | epoch  43 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.1160\n",
      "2022-02-23 23:13:23,744 - INFO: | epoch  43 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.33 | loss-text 3.1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003921\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10594, 'reflen': 10627, 'guess': [10594, 9570, 8546, 7522], 'correct': [5840, 2075, 783, 238]}\n",
      "ratio: 0.9968947021736146\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.339\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.226\n",
      "2022-02-23 23:14:06,141 - INFO: eval_greddy SPIDEr: 0.2265\n",
      "loading annotations into memory...\n",
      "0:00:00.004000\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8890, 'reflen': 9744, 'guess': [8890, 7866, 6842, 5818], 'correct': [5330, 2012, 806, 260]}\n",
      "ratio: 0.9123563218389867\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.376\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2022-02-23 23:14:35,712 - INFO: eval_beam_2 SPIDEr: 0.2416\n",
      "loading annotations into memory...\n",
      "0:00:00.004042\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8313, 'reflen': 9502, 'guess': [8313, 7289, 6265, 5241], 'correct': [5136, 1992, 820, 275]}\n",
      "ratio: 0.87486844874754\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.377\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.380\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.245\n",
      "2022-02-23 23:15:09,742 - INFO: eval_beam_3 SPIDEr: 0.2450\n",
      "loading annotations into memory...\n",
      "0:00:00.003903\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7711, 'reflen': 9322, 'guess': [7711, 6687, 5663, 4639], 'correct': [4826, 1922, 824, 270]}\n",
      "ratio: 0.8271830079381219\n",
      "Bleu_1: 0.508\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.376\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2022-02-23 23:15:47,886 - INFO: eval_beam_4 SPIDEr: 0.2395\n",
      "2022-02-23 23:15:55,719 - INFO: | epoch  44 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 78.29 | loss-text 3.0641\n",
      "2022-02-23 23:16:03,192 - INFO: | epoch  44 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.71 | loss-text 3.0732\n",
      "2022-02-23 23:16:10,717 - INFO: | epoch  44 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.25 | loss-text 3.1141\n",
      "2022-02-23 23:16:18,290 - INFO: | epoch  44 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.0537\n",
      "2022-02-23 23:16:25,815 - INFO: | epoch  44 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.24 | loss-text 3.0684\n",
      "2022-02-23 23:16:33,387 - INFO: | epoch  44 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.0623\n",
      "2022-02-23 23:16:40,934 - INFO: | epoch  44 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.0584\n",
      "2022-02-23 23:16:48,503 - INFO: | epoch  44 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.68 | loss-text 3.0887\n",
      "2022-02-23 23:16:56,102 - INFO: | epoch  44 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.97 | loss-text 3.1212\n",
      "2022-02-23 23:17:03,666 - INFO: | epoch  44 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.63 | loss-text 3.0362\n",
      "2022-02-23 23:17:11,207 - INFO: | epoch  44 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.0977\n",
      "2022-02-23 23:17:18,767 - INFO: | epoch  44 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.60 | loss-text 3.0689\n",
      "2022-02-23 23:17:26,312 - INFO: | epoch  44 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.43 | loss-text 3.0460\n",
      "2022-02-23 23:17:33,887 - INFO: | epoch  44 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.0782\n",
      "2022-02-23 23:17:41,504 - INFO: | epoch  44 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.16 | loss-text 3.1076\n",
      "2022-02-23 23:17:49,122 - INFO: | epoch  44 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.18 | loss-text 3.1114\n",
      "2022-02-23 23:17:56,699 - INFO: | epoch  44 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.76 | loss-text 3.0627\n",
      "2022-02-23 23:18:04,315 - INFO: | epoch  44 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 76.16 | loss-text 3.1000\n",
      "2022-02-23 23:18:11,943 - INFO: | epoch  44 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.27 | loss-text 3.0887\n",
      "2022-02-23 23:18:19,539 - INFO: | epoch  44 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.0603\n",
      "2022-02-23 23:18:27,143 - INFO: | epoch  44 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.1408\n",
      "2022-02-23 23:18:34,725 - INFO: | epoch  44 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.81 | loss-text 3.1565\n",
      "2022-02-23 23:18:42,331 - INFO: | epoch  44 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.05 | loss-text 3.0834\n",
      "2022-02-23 23:18:49,929 - INFO: | epoch  44 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.0846\n",
      "2022-02-23 23:18:57,570 - INFO: | epoch  44 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.40 | loss-text 3.1130\n",
      "2022-02-23 23:19:05,208 - INFO: | epoch  44 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.37 | loss-text 3.0727\n",
      "2022-02-23 23:19:12,813 - INFO: | epoch  44 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.0760\n",
      "2022-02-23 23:19:20,478 - INFO: | epoch  44 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.65 | loss-text 3.1357\n",
      "2022-02-23 23:19:28,141 - INFO: | epoch  44 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.62 | loss-text 3.0821\n",
      "2022-02-23 23:19:35,750 - INFO: | epoch  44 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.07 | loss-text 3.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003840\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10659, 'reflen': 10620, 'guess': [10659, 9635, 8611, 7587], 'correct': [5847, 2130, 827, 265]}\n",
      "ratio: 1.0036723163840862\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.169\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.353\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2022-02-23 23:20:17,982 - INFO: eval_greddy SPIDEr: 0.2332\n",
      "loading annotations into memory...\n",
      "0:00:00.004002\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9054, 'reflen': 9741, 'guess': [9054, 8030, 7006, 5982], 'correct': [5367, 2019, 818, 274]}\n",
      "ratio: 0.9294733600245426\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.374\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.377\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2022-02-23 23:20:47,433 - INFO: eval_beam_2 SPIDEr: 0.2460\n",
      "loading annotations into memory...\n",
      "0:00:00.003745\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8432, 'reflen': 9497, 'guess': [8432, 7408, 6384, 5360], 'correct': [5081, 1948, 801, 273]}\n",
      "ratio: 0.8878593239969582\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.373\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2022-02-23 23:21:20,457 - INFO: eval_beam_3 SPIDEr: 0.2432\n",
      "loading annotations into memory...\n",
      "0:00:00.003913\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8087, 'reflen': 9408, 'guess': [8087, 7063, 6039, 5015], 'correct': [4934, 1903, 794, 264]}\n",
      "ratio: 0.8595875850339222\n",
      "Bleu_1: 0.518\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2022-02-23 23:21:57,711 - INFO: eval_beam_4 SPIDEr: 0.2407\n",
      "2022-02-23 23:22:05,500 - INFO: | epoch  45 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.86 | loss-text 3.0784\n",
      "2022-02-23 23:22:12,994 - INFO: | epoch  45 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.93 | loss-text 3.0668\n",
      "2022-02-23 23:22:20,531 - INFO: | epoch  45 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.37 | loss-text 3.0630\n",
      "2022-02-23 23:22:28,078 - INFO: | epoch  45 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.0655\n",
      "2022-02-23 23:22:35,633 - INFO: | epoch  45 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.55 | loss-text 3.0752\n",
      "2022-02-23 23:22:43,198 - INFO: | epoch  45 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.64 | loss-text 3.0701\n",
      "2022-02-23 23:22:50,681 - INFO: | epoch  45 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 74.82 | loss-text 3.0802\n",
      "2022-02-23 23:22:58,225 - INFO: | epoch  45 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.43 | loss-text 3.1022\n",
      "2022-02-23 23:23:05,818 - INFO: | epoch  45 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.92 | loss-text 3.0761\n",
      "2022-02-23 23:23:13,359 - INFO: | epoch  45 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.40 | loss-text 3.0477\n",
      "2022-02-23 23:23:20,970 - INFO: | epoch  45 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 76.10 | loss-text 3.0523\n",
      "2022-02-23 23:23:28,558 - INFO: | epoch  45 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.88 | loss-text 3.0496\n",
      "2022-02-23 23:23:36,144 - INFO: | epoch  45 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.0668\n",
      "2022-02-23 23:23:43,785 - INFO: | epoch  45 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.40 | loss-text 3.0955\n",
      "2022-02-23 23:23:51,385 - INFO: | epoch  45 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.99 | loss-text 3.0737\n",
      "2022-02-23 23:23:58,942 - INFO: | epoch  45 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.57 | loss-text 3.0689\n",
      "2022-02-23 23:24:06,586 - INFO: | epoch  45 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.43 | loss-text 3.1103\n",
      "2022-02-23 23:24:14,162 - INFO: | epoch  45 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.76 | loss-text 3.1355\n",
      "2022-02-23 23:24:21,863 - INFO: | epoch  45 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 77.00 | loss-text 3.0981\n",
      "2022-02-23 23:24:29,468 - INFO: | epoch  45 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.1226\n",
      "2022-02-23 23:24:37,081 - INFO: | epoch  45 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.12 | loss-text 3.1152\n",
      "2022-02-23 23:24:44,692 - INFO: | epoch  45 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.10 | loss-text 3.0912\n",
      "2022-02-23 23:24:52,317 - INFO: | epoch  45 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.0789\n",
      "2022-02-23 23:24:59,973 - INFO: | epoch  45 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.56 | loss-text 3.1184\n",
      "2022-02-23 23:25:07,603 - INFO: | epoch  45 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.29 | loss-text 3.0370\n",
      "2022-02-23 23:25:15,229 - INFO: | epoch  45 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.25 | loss-text 3.0706\n",
      "2022-02-23 23:25:22,853 - INFO: | epoch  45 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.24 | loss-text 3.0547\n",
      "2022-02-23 23:25:30,463 - INFO: | epoch  45 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.09 | loss-text 3.0790\n",
      "2022-02-23 23:25:38,076 - INFO: | epoch  45 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.12 | loss-text 3.0994\n",
      "2022-02-23 23:25:45,717 - INFO: | epoch  45 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.41 | loss-text 3.0639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003886\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10701, 'reflen': 10654, 'guess': [10701, 9677, 8653, 7629], 'correct': [5672, 1980, 732, 228]}\n",
      "ratio: 1.004411488642669\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.341\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.226\n",
      "2022-02-23 23:26:28,757 - INFO: eval_greddy SPIDEr: 0.2255\n",
      "loading annotations into memory...\n",
      "0:00:00.003621\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9062, 'reflen': 9786, 'guess': [9062, 8038, 7014, 5990], 'correct': [5250, 1933, 751, 243]}\n",
      "ratio: 0.9260167586346897\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2022-02-23 23:26:58,665 - INFO: eval_beam_2 SPIDEr: 0.2428\n",
      "loading annotations into memory...\n",
      "0:00:00.003911\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8342, 'reflen': 9474, 'guess': [8342, 7318, 6294, 5270], 'correct': [4973, 1894, 765, 260]}\n",
      "ratio: 0.8805150939412201\n",
      "Bleu_1: 0.520\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2022-02-23 23:27:32,953 - INFO: eval_beam_3 SPIDEr: 0.2407\n",
      "loading annotations into memory...\n",
      "0:00:00.003815\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7836, 'reflen': 9331, 'guess': [7836, 6812, 5788, 4764], 'correct': [4672, 1767, 710, 238]}\n",
      "ratio: 0.8397813739148172\n",
      "Bleu_1: 0.493\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2022-02-23 23:28:10,974 - INFO: eval_beam_4 SPIDEr: 0.2336\n",
      "2022-02-23 23:28:18,743 - INFO: | epoch  46 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.66 | loss-text 3.1096\n",
      "2022-02-23 23:28:26,260 - INFO: | epoch  46 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.16 | loss-text 3.0710\n",
      "2022-02-23 23:28:33,778 - INFO: | epoch  46 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.17 | loss-text 3.0992\n",
      "2022-02-23 23:28:41,324 - INFO: | epoch  46 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.0951\n",
      "2022-02-23 23:28:48,857 - INFO: | epoch  46 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.32 | loss-text 3.0545\n",
      "2022-02-23 23:28:56,302 - INFO: | epoch  46 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 74.45 | loss-text 3.0501\n",
      "2022-02-23 23:29:03,857 - INFO: | epoch  46 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.54 | loss-text 3.0804\n",
      "2022-02-23 23:29:11,423 - INFO: | epoch  46 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.0815\n",
      "2022-02-23 23:29:18,986 - INFO: | epoch  46 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.0674\n",
      "2022-02-23 23:29:26,550 - INFO: | epoch  46 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.64 | loss-text 3.0529\n",
      "2022-02-23 23:29:34,173 - INFO: | epoch  46 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 76.22 | loss-text 3.1001\n",
      "2022-02-23 23:29:41,745 - INFO: | epoch  46 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.0668\n",
      "2022-02-23 23:29:49,338 - INFO: | epoch  46 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.92 | loss-text 3.0846\n",
      "2022-02-23 23:29:56,885 - INFO: | epoch  46 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.47 | loss-text 3.0176\n",
      "2022-02-23 23:30:04,475 - INFO: | epoch  46 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.0427\n",
      "2022-02-23 23:30:12,080 - INFO: | epoch  46 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.05 | loss-text 3.1137\n",
      "2022-02-23 23:30:19,648 - INFO: | epoch  46 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.67 | loss-text 3.0830\n",
      "2022-02-23 23:30:27,238 - INFO: | epoch  46 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.0720\n",
      "2022-02-23 23:30:34,845 - INFO: | epoch  46 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.0569\n",
      "2022-02-23 23:30:42,443 - INFO: | epoch  46 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.0514\n",
      "2022-02-23 23:30:50,075 - INFO: | epoch  46 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.31 | loss-text 3.0385\n",
      "2022-02-23 23:30:57,707 - INFO: | epoch  46 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.31 | loss-text 3.1155\n",
      "2022-02-23 23:31:05,341 - INFO: | epoch  46 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.33 | loss-text 3.0636\n",
      "2022-02-23 23:31:13,000 - INFO: | epoch  46 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.59 | loss-text 3.0750\n",
      "2022-02-23 23:31:20,605 - INFO: | epoch  46 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.1052\n",
      "2022-02-23 23:31:28,172 - INFO: | epoch  46 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.0415\n",
      "2022-02-23 23:31:35,813 - INFO: | epoch  46 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.40 | loss-text 3.1049\n",
      "2022-02-23 23:31:43,411 - INFO: | epoch  46 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.97 | loss-text 3.0668\n",
      "2022-02-23 23:31:50,907 - INFO: | epoch  46 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 74.96 | loss-text 3.0604\n",
      "2022-02-23 23:31:58,548 - INFO: | epoch  46 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.40 | loss-text 3.1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003767\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10806, 'reflen': 10764, 'guess': [10806, 9782, 8758, 7734], 'correct': [5700, 1952, 699, 204]}\n",
      "ratio: 1.0039018952061498\n",
      "Bleu_1: 0.527\n",
      "Bleu_2: 0.324\n",
      "Bleu_3: 0.203\n",
      "Bleu_4: 0.122\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.317\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.213\n",
      "2022-02-23 23:32:41,702 - INFO: eval_greddy SPIDEr: 0.2135\n",
      "loading annotations into memory...\n",
      "0:00:00.004118\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9041, 'reflen': 9701, 'guess': [9041, 8017, 6993, 5969], 'correct': [5304, 2023, 794, 253]}\n",
      "ratio: 0.931965776723953\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.372\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2022-02-23 23:33:11,718 - INFO: eval_beam_2 SPIDEr: 0.2400\n",
      "loading annotations into memory...\n",
      "0:00:00.004004\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8513, 'reflen': 9515, 'guess': [8513, 7489, 6465, 5441], 'correct': [5061, 1924, 774, 250]}\n",
      "ratio: 0.8946925906462538\n",
      "Bleu_1: 0.528\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2022-02-23 23:33:45,395 - INFO: eval_beam_3 SPIDEr: 0.2353\n",
      "loading annotations into memory...\n",
      "0:00:00.003910\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7843, 'reflen': 9344, 'guess': [7843, 6819, 5795, 4771], 'correct': [4769, 1845, 746, 242]}\n",
      "ratio: 0.8393621575341567\n",
      "Bleu_1: 0.502\n",
      "Bleu_2: 0.335\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2022-02-23 23:34:23,891 - INFO: eval_beam_4 SPIDEr: 0.2302\n",
      "2022-02-23 23:34:31,684 - INFO: | epoch  47 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.90 | loss-text 3.0656\n",
      "2022-02-23 23:34:39,224 - INFO: | epoch  47 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.38 | loss-text 3.0515\n",
      "2022-02-23 23:34:46,774 - INFO: | epoch  47 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.50 | loss-text 3.0595\n",
      "2022-02-23 23:34:54,297 - INFO: | epoch  47 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.22 | loss-text 3.0484\n",
      "2022-02-23 23:35:01,890 - INFO: | epoch  47 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.93 | loss-text 3.0389\n",
      "2022-02-23 23:35:09,441 - INFO: | epoch  47 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.50 | loss-text 3.0777\n",
      "2022-02-23 23:35:16,951 - INFO: | epoch  47 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.09 | loss-text 3.0876\n",
      "2022-02-23 23:35:24,504 - INFO: | epoch  47 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.53 | loss-text 3.0453\n",
      "2022-02-23 23:35:32,058 - INFO: | epoch  47 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.53 | loss-text 3.0927\n",
      "2022-02-23 23:35:39,652 - INFO: | epoch  47 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.93 | loss-text 3.0355\n",
      "2022-02-23 23:35:47,202 - INFO: | epoch  47 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.49 | loss-text 3.0714\n",
      "2022-02-23 23:35:54,806 - INFO: | epoch  47 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.0449\n",
      "2022-02-23 23:36:02,404 - INFO: | epoch  47 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.98 | loss-text 3.0604\n",
      "2022-02-23 23:36:10,015 - INFO: | epoch  47 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.10 | loss-text 3.0377\n",
      "2022-02-23 23:36:17,652 - INFO: | epoch  47 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.36 | loss-text 3.0454\n",
      "2022-02-23 23:36:25,242 - INFO: | epoch  47 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.0648\n",
      "2022-02-23 23:36:32,759 - INFO: | epoch  47 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.16 | loss-text 3.0528\n",
      "2022-02-23 23:36:40,322 - INFO: | epoch  47 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.62 | loss-text 3.0764\n",
      "2022-02-23 23:36:47,845 - INFO: | epoch  47 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.23 | loss-text 3.1013\n",
      "2022-02-23 23:36:55,429 - INFO: | epoch  47 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.83 | loss-text 3.1053\n",
      "2022-02-23 23:37:03,008 - INFO: | epoch  47 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.78 | loss-text 3.1133\n",
      "2022-02-23 23:37:10,582 - INFO: | epoch  47 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.73 | loss-text 3.0653\n",
      "2022-02-23 23:37:18,184 - INFO: | epoch  47 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.0730\n",
      "2022-02-23 23:37:25,822 - INFO: | epoch  47 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.37 | loss-text 3.0973\n",
      "2022-02-23 23:37:33,503 - INFO: | epoch  47 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.80 | loss-text 3.0750\n",
      "2022-02-23 23:37:41,110 - INFO: | epoch  47 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.0631\n",
      "2022-02-23 23:37:48,765 - INFO: | epoch  47 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.55 | loss-text 3.1018\n",
      "2022-02-23 23:37:56,341 - INFO: | epoch  47 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.0796\n",
      "2022-02-23 23:38:03,988 - INFO: | epoch  47 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.46 | loss-text 3.0790\n",
      "2022-02-23 23:38:11,667 - INFO: | epoch  47 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.79 | loss-text 3.0470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003829\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10778, 'reflen': 10702, 'guess': [10778, 9754, 8730, 7706], 'correct': [5858, 2110, 792, 243]}\n",
      "ratio: 1.0071014763594648\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.372\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.343\n",
      "computing SPICE score...\n",
      "SPICE: 0.118\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2022-02-23 23:38:54,220 - INFO: eval_greddy SPIDEr: 0.2304\n",
      "loading annotations into memory...\n",
      "0:00:00.004184\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8988, 'reflen': 9719, 'guess': [8988, 7964, 6940, 5916], 'correct': [5286, 2002, 826, 285]}\n",
      "ratio: 0.9247865006686979\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2022-02-23 23:39:24,462 - INFO: eval_beam_2 SPIDEr: 0.2427\n",
      "loading annotations into memory...\n",
      "0:00:00.003529\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8346, 'reflen': 9463, 'guess': [8346, 7322, 6298, 5274], 'correct': [5000, 1911, 797, 282]}\n",
      "ratio: 0.881961323047566\n",
      "Bleu_1: 0.524\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2022-02-23 23:39:57,574 - INFO: eval_beam_3 SPIDEr: 0.2431\n",
      "loading annotations into memory...\n",
      "0:00:00.003877\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7639, 'reflen': 9295, 'guess': [7639, 6615, 5591, 4567], 'correct': [4633, 1816, 774, 268]}\n",
      "ratio: 0.8218396987626873\n",
      "Bleu_1: 0.488\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.356\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2022-02-23 23:40:35,305 - INFO: eval_beam_4 SPIDEr: 0.2312\n",
      "2022-02-23 23:40:43,078 - INFO: | epoch  48 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.70 | loss-text 3.0221\n",
      "2022-02-23 23:40:50,628 - INFO: | epoch  48 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.49 | loss-text 3.0494\n",
      "2022-02-23 23:40:58,174 - INFO: | epoch  48 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.46 | loss-text 3.0242\n",
      "2022-02-23 23:41:05,782 - INFO: | epoch  48 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 76.06 | loss-text 3.0413\n",
      "2022-02-23 23:41:13,331 - INFO: | epoch  48 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.49 | loss-text 3.0280\n",
      "2022-02-23 23:41:20,933 - INFO: | epoch  48 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.0558\n",
      "2022-02-23 23:41:28,479 - INFO: | epoch  48 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.45 | loss-text 3.0113\n",
      "2022-02-23 23:41:36,007 - INFO: | epoch  48 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.28 | loss-text 3.0398\n",
      "2022-02-23 23:41:43,553 - INFO: | epoch  48 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.44 | loss-text 3.0562\n",
      "2022-02-23 23:41:51,075 - INFO: | epoch  48 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.22 | loss-text 3.1184\n",
      "2022-02-23 23:41:58,627 - INFO: | epoch  48 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.51 | loss-text 3.0626\n",
      "2022-02-23 23:42:06,191 - INFO: | epoch  48 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.63 | loss-text 3.1063\n",
      "2022-02-23 23:42:13,822 - INFO: | epoch  48 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.30 | loss-text 3.1057\n",
      "2022-02-23 23:42:21,398 - INFO: | epoch  48 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.0496\n",
      "2022-02-23 23:42:28,965 - INFO: | epoch  48 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.66 | loss-text 3.0692\n",
      "2022-02-23 23:42:36,566 - INFO: | epoch  48 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.0980\n",
      "2022-02-23 23:42:44,114 - INFO: | epoch  48 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 75.47 | loss-text 3.0295\n",
      "2022-02-23 23:42:51,680 - INFO: | epoch  48 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.65 | loss-text 3.0746\n",
      "2022-02-23 23:42:59,268 - INFO: | epoch  48 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.87 | loss-text 3.0537\n",
      "2022-02-23 23:43:06,853 - INFO: | epoch  48 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.0094\n",
      "2022-02-23 23:43:14,493 - INFO: | epoch  48 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.39 | loss-text 3.0298\n",
      "2022-02-23 23:43:22,082 - INFO: | epoch  48 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.88 | loss-text 3.0569\n",
      "2022-02-23 23:43:29,655 - INFO: | epoch  48 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.72 | loss-text 3.0647\n",
      "2022-02-23 23:43:37,302 - INFO: | epoch  48 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.47 | loss-text 3.1056\n",
      "2022-02-23 23:43:44,905 - INFO: | epoch  48 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.02 | loss-text 3.0035\n",
      "2022-02-23 23:43:52,552 - INFO: | epoch  48 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.47 | loss-text 3.0725\n",
      "2022-02-23 23:44:00,202 - INFO: | epoch  48 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 76.49 | loss-text 3.1028\n",
      "2022-02-23 23:44:07,795 - INFO: | epoch  48 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 75.92 | loss-text 3.0847\n",
      "2022-02-23 23:44:15,407 - INFO: | epoch  48 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.11 | loss-text 3.0624\n",
      "2022-02-23 23:44:23,047 - INFO: | epoch  48 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.39 | loss-text 3.0645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003991\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10559, 'reflen': 10559, 'guess': [10559, 9535, 8511, 7487], 'correct': [5617, 2014, 731, 219]}\n",
      "ratio: 0.9999999999999053\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.335\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.330\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.220\n",
      "2022-02-23 23:45:05,002 - INFO: eval_greddy SPIDEr: 0.2199\n",
      "loading annotations into memory...\n",
      "0:00:00.003942\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8947, 'reflen': 9746, 'guess': [8947, 7923, 6899, 5875], 'correct': [5218, 1964, 765, 261]}\n",
      "ratio: 0.9180176482658611\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2022-02-23 23:45:36,929 - INFO: eval_beam_2 SPIDEr: 0.2340\n",
      "loading annotations into memory...\n",
      "0:00:00.003989\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8413, 'reflen': 9516, 'guess': [8413, 7389, 6365, 5341], 'correct': [5014, 1910, 756, 251]}\n",
      "ratio: 0.884089953761992\n",
      "Bleu_1: 0.523\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2022-02-23 23:46:11,441 - INFO: eval_beam_3 SPIDEr: 0.2345\n",
      "loading annotations into memory...\n",
      "0:00:00.003987\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7795, 'reflen': 9357, 'guess': [7795, 6771, 5747, 4723], 'correct': [4729, 1831, 732, 246]}\n",
      "ratio: 0.8330661536816465\n",
      "Bleu_1: 0.497\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.358\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2022-02-23 23:46:49,424 - INFO: eval_beam_4 SPIDEr: 0.2312\n",
      "2022-02-23 23:46:57,145 - INFO: | epoch  49 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.17 | loss-text 3.0626\n",
      "2022-02-23 23:47:04,621 - INFO: | epoch  49 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 74.76 | loss-text 3.0392\n",
      "2022-02-23 23:47:12,149 - INFO: | epoch  49 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.27 | loss-text 3.0379\n",
      "2022-02-23 23:47:19,643 - INFO: | epoch  49 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 74.93 | loss-text 3.0320\n",
      "2022-02-23 23:47:27,203 - INFO: | epoch  49 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.59 | loss-text 3.0366\n",
      "2022-02-23 23:47:34,778 - INFO: | epoch  49 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.75 | loss-text 3.0107\n",
      "2022-02-23 23:47:42,296 - INFO: | epoch  49 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.17 | loss-text 3.0585\n",
      "2022-02-23 23:47:49,883 - INFO: | epoch  49 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.86 | loss-text 3.0498\n",
      "2022-02-23 23:47:57,433 - INFO: | epoch  49 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.50 | loss-text 3.0504\n",
      "2022-02-23 23:48:05,024 - INFO: | epoch  49 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.0125\n",
      "2022-02-23 23:48:12,577 - INFO: | epoch  49 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.53 | loss-text 3.0450\n",
      "2022-02-23 23:48:20,193 - INFO: | epoch  49 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 76.15 | loss-text 3.0267\n",
      "2022-02-23 23:48:27,796 - INFO: | epoch  49 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 76.02 | loss-text 3.0389\n",
      "2022-02-23 23:48:35,396 - INFO: | epoch  49 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.0469\n",
      "2022-02-23 23:48:42,974 - INFO: | epoch  49 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 75.77 | loss-text 3.0539\n",
      "2022-02-23 23:48:50,571 - INFO: | epoch  49 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 75.96 | loss-text 3.0629\n",
      "2022-02-23 23:48:58,233 - INFO: | epoch  49 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.62 | loss-text 3.0801\n",
      "2022-02-23 23:49:05,804 - INFO: | epoch  49 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.71 | loss-text 3.0643\n",
      "2022-02-23 23:49:13,435 - INFO: | epoch  49 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 76.30 | loss-text 3.0273\n",
      "2022-02-23 23:49:21,016 - INFO: | epoch  49 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 75.80 | loss-text 3.0456\n",
      "2022-02-23 23:49:28,645 - INFO: | epoch  49 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 76.28 | loss-text 3.0337\n",
      "2022-02-23 23:49:36,249 - INFO: | epoch  49 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 76.04 | loss-text 3.0570\n",
      "2022-02-23 23:49:43,798 - INFO: | epoch  49 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 75.48 | loss-text 3.0454\n",
      "2022-02-23 23:49:51,398 - INFO: | epoch  49 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.0150\n",
      "2022-02-23 23:49:59,054 - INFO: | epoch  49 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.55 | loss-text 3.0903\n",
      "2022-02-23 23:50:06,735 - INFO: | epoch  49 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.80 | loss-text 3.0570\n",
      "2022-02-23 23:50:14,327 - INFO: | epoch  49 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.91 | loss-text 3.0931\n",
      "2022-02-23 23:50:21,958 - INFO: | epoch  49 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.31 | loss-text 3.0968\n",
      "2022-02-23 23:50:29,519 - INFO: | epoch  49 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 75.60 | loss-text 3.0453\n",
      "2022-02-23 23:50:37,140 - INFO: | epoch  49 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.20 | loss-text 3.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003844\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10508, 'reflen': 10544, 'guess': [10508, 9484, 8460, 7436], 'correct': [5744, 2065, 789, 249]}\n",
      "ratio: 0.9965857359634867\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.349\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2022-02-23 23:51:19,020 - INFO: eval_greddy SPIDEr: 0.2307\n",
      "loading annotations into memory...\n",
      "0:00:00.003975\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9094, 'reflen': 9827, 'guess': [9094, 8070, 7046, 6022], 'correct': [5312, 2019, 814, 289]}\n",
      "ratio: 0.9254095858348503\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.373\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.383\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.247\n",
      "2022-02-23 23:51:49,515 - INFO: eval_beam_2 SPIDEr: 0.2474\n",
      "loading annotations into memory...\n",
      "0:00:00.003902\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8422, 'reflen': 9564, 'guess': [8422, 7398, 6374, 5350], 'correct': [5040, 1911, 783, 279]}\n",
      "ratio: 0.8805938937682056\n",
      "Bleu_1: 0.523\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2022-02-23 23:52:23,265 - INFO: eval_beam_3 SPIDEr: 0.2415\n",
      "loading annotations into memory...\n",
      "0:00:00.003974\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7894, 'reflen': 9398, 'guess': [7894, 6870, 5846, 4822], 'correct': [4817, 1859, 780, 272]}\n",
      "ratio: 0.8399659502020813\n",
      "Bleu_1: 0.504\n",
      "Bleu_2: 0.336\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2022-02-23 23:53:00,773 - INFO: eval_beam_4 SPIDEr: 0.2378\n",
      "2022-02-23 23:53:08,499 - INFO: | epoch  50 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 77.23 | loss-text 3.0131\n",
      "2022-02-23 23:53:16,084 - INFO: | epoch  50 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.0377\n",
      "2022-02-23 23:53:23,623 - INFO: | epoch  50 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 75.38 | loss-text 3.0580\n",
      "2022-02-23 23:53:31,133 - INFO: | epoch  50 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 75.09 | loss-text 3.0655\n",
      "2022-02-23 23:53:38,658 - INFO: | epoch  50 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 75.24 | loss-text 3.0179\n",
      "2022-02-23 23:53:46,196 - INFO: | epoch  50 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 75.37 | loss-text 3.0314\n",
      "2022-02-23 23:53:53,723 - INFO: | epoch  50 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 75.26 | loss-text 3.0250\n",
      "2022-02-23 23:54:01,272 - INFO: | epoch  50 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 75.48 | loss-text 3.0242\n",
      "2022-02-23 23:54:08,831 - INFO: | epoch  50 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 75.59 | loss-text 3.0157\n",
      "2022-02-23 23:54:16,395 - INFO: | epoch  50 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 75.64 | loss-text 3.0424\n",
      "2022-02-23 23:54:23,947 - INFO: | epoch  50 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 75.51 | loss-text 3.0436\n",
      "2022-02-23 23:54:31,532 - INFO: | epoch  50 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.0339\n",
      "2022-02-23 23:54:39,113 - INFO: | epoch  50 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 75.80 | loss-text 3.0329\n",
      "2022-02-23 23:54:46,698 - INFO: | epoch  50 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 75.85 | loss-text 3.0032\n",
      "2022-02-23 23:54:54,299 - INFO: | epoch  50 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 76.00 | loss-text 3.0389\n",
      "2022-02-23 23:55:01,935 - INFO: | epoch  50 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 76.35 | loss-text 3.0702\n",
      "2022-02-23 23:55:09,537 - INFO: | epoch  50 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 76.01 | loss-text 3.0652\n",
      "2022-02-23 23:55:17,098 - INFO: | epoch  50 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 75.61 | loss-text 3.0220\n",
      "2022-02-23 23:55:24,683 - INFO: | epoch  50 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 75.84 | loss-text 3.0541\n",
      "2022-02-23 23:55:32,307 - INFO: | epoch  50 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 76.23 | loss-text 3.0581\n",
      "2022-02-23 23:55:39,897 - INFO: | epoch  50 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.0339\n",
      "2022-02-23 23:55:47,486 - INFO: | epoch  50 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 75.89 | loss-text 3.0752\n",
      "2022-02-23 23:55:55,129 - INFO: | epoch  50 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 76.42 | loss-text 3.0644\n",
      "2022-02-23 23:56:02,771 - INFO: | epoch  50 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 76.41 | loss-text 3.0903\n",
      "2022-02-23 23:56:10,437 - INFO: | epoch  50 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 76.65 | loss-text 3.0285\n",
      "2022-02-23 23:56:18,061 - INFO: | epoch  50 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 76.23 | loss-text 3.0421\n",
      "2022-02-23 23:56:25,651 - INFO: | epoch  50 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 75.90 | loss-text 3.0384\n",
      "2022-02-23 23:56:33,261 - INFO: | epoch  50 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 76.09 | loss-text 3.0750\n",
      "2022-02-23 23:56:40,926 - INFO: | epoch  50 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 76.64 | loss-text 3.0210\n",
      "2022-02-23 23:56:48,530 - INFO: | epoch  50 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 76.03 | loss-text 3.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003913\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10554, 'reflen': 10595, 'guess': [10554, 9530, 8506, 7482], 'correct': [5840, 2122, 783, 234]}\n",
      "ratio: 0.9961302501178861\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.224\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.169\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.353\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2022-02-23 23:57:31,010 - INFO: eval_greddy SPIDEr: 0.2340\n",
      "loading annotations into memory...\n",
      "0:00:00.003817\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9144, 'reflen': 9817, 'guess': [9144, 8120, 7096, 6072], 'correct': [5449, 2065, 806, 279]}\n",
      "ratio: 0.9314454517672475\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.362\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.169\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.378\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.386\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.250\n",
      "2022-02-23 23:57:59,961 - INFO: eval_beam_2 SPIDEr: 0.2502\n",
      "loading annotations into memory...\n",
      "0:00:00.003641\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8571, 'reflen': 9608, 'guess': [8571, 7547, 6523, 5499], 'correct': [5228, 1999, 808, 274]}\n",
      "ratio: 0.8920691090756773\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.374\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.386\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.250\n",
      "2022-02-23 23:58:32,771 - INFO: eval_beam_3 SPIDEr: 0.2499\n",
      "loading annotations into memory...\n",
      "0:00:00.003909\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8060, 'reflen': 9433, 'guess': [8060, 7036, 6012, 4988], 'correct': [4922, 1877, 750, 251]}\n",
      "ratio: 0.8544471536095776\n",
      "Bleu_1: 0.515\n",
      "Bleu_2: 0.340\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2022-02-23 23:59:09,058 - INFO: eval_beam_4 SPIDEr: 0.2402\n"
     ]
    }
   ],
   "source": [
    "#일부 레이어 1131\n",
    "epoch = 1\n",
    "if hp.mode == 'train':\n",
    "    while epoch < hp.training_epochs + 1:\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        torch.save(model.state_dict(), '{log_dir}/{num_epoch}.pt'.format(log_dir=log_dir, num_epoch=epoch))\n",
    "        scheduler.step(epoch)\n",
    "        eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=2)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=3)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=4)\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad8fd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src, tgt,tgt_len, ref = next(iter(evaluation_beam)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9f9eb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2037, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c42acfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fe4d8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "905ebaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 629, 597, 1286, 4, 130, 1877, 17, 375, 16, 7, 3479, 9]]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25071d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83296eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a6a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb9cab91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f23e485a4e0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28c67129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.000412\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8, 'reflen': 11, 'guess': [8, 7, 6, 5], 'correct': [4, 1, 0, 0]}\n",
      "ratio: 0.7272727272066117\n",
      "Bleu_1: 0.344\n",
      "Bleu_2: 0.184\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.171\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.409\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.200\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.100\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e277fcfedcbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluation model score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/0101_vgg_pretrain/50.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_beam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n\u001b[1;32m      5\u001b[0m                        beam_size=2)\n",
      "\u001b[0;32m<ipython-input-16-94649549a569>\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(evaluation_data, max_len, eos_ind, word_dict_pickle_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mloss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss/eval_greddy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'eval_greddy SPIDEr: {loss_mean:2.4f}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "#1번째\n",
    "# Evaluation model score\n",
    "model.load_state_dict(torch.load(\"./models/0101_vgg_pretrain/50.pt\"))\n",
    "eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=2)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=3)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bffe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30357b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1887f5cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.000431\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10, 'reflen': 11, 'guess': [10, 9, 8, 7], 'correct': [3, 0, 0, 0]}\n",
      "ratio: 0.9090909090082646\n",
      "Bleu_1: 0.271\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.115\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.189\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.182\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.091\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-713b7c54e98e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Evaluation model score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/0101_vgg_pretrain/50.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_beam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n\u001b[1;32m      6\u001b[0m                        beam_size=2)\n",
      "\u001b[0;32m<ipython-input-13-94649549a569>\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(evaluation_data, max_len, eos_ind, word_dict_pickle_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mloss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss/eval_greddy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'eval_greddy SPIDEr: {loss_mean:2.4f}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "#2번째\n",
    "# Evaluation model score\n",
    "model.load_state_dict(torch.load(\"./models/0101_vgg_pretrain/50.pt\"))\n",
    "eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=2)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=3)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba0025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.000156\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11, 'reflen': 13, 'guess': [11, 10, 9, 8], 'correct': [6, 3, 2, 1]}\n",
      "ratio: 0.8461538460887575\n",
      "Bleu_1: 0.455\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.276\n",
      "Bleu_4: 0.216\n",
      "computing METEOR score...\n",
      "METEOR: 0.253\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.410\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.182\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.091\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'writer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c818b6825043>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Evaluation model score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/0101_vgg_pretrain/50.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_beam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n\u001b[1;32m      6\u001b[0m                        beam_size=2)\n",
      "\u001b[0;32m<ipython-input-14-94649549a569>\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(evaluation_data, max_len, eos_ind, word_dict_pickle_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mloss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss/eval_greddy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'eval_greddy SPIDEr: {loss_mean:2.4f}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'writer' is not defined"
     ]
    }
   ],
   "source": [
    "#3번째\n",
    "# Evaluation model score\n",
    "model.load_state_dict(torch.load(\"./models/0101_vgg_pretrain/50.pt\"))\n",
    "eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=2)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=3)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9174fd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.000372\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7, 'reflen': 12, 'guess': [7, 6, 5, 4], 'correct': [4, 3, 2, 1]}\n",
      "ratio: 0.5833333332847223\n",
      "Bleu_1: 0.280\n",
      "Bleu_2: 0.262\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.201\n",
      "computing METEOR score...\n",
      "METEOR: 0.181\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.402\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.500\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.250\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1282abd79518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Evaluation model score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/0101_vgg_pretrain/50.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_beam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n\u001b[1;32m      6\u001b[0m                        beam_size=2)\n",
      "\u001b[0;32m<ipython-input-15-94649549a569>\u001b[0m in \u001b[0;36meval_all\u001b[0;34m(evaluation_data, max_len, eos_ind, word_dict_pickle_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mloss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss/eval_greddy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'eval_greddy SPIDEr: {loss_mean:2.4f}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "#4번째\n",
    "# Evaluation model score\n",
    "model.load_state_dict(torch.load(\"./models/0101_vgg_pretrain/50.pt\"))\n",
    "eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=2)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=3)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "219278a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.000192\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11, 'reflen': 12, 'guess': [11, 10, 9, 8], 'correct': [0, 0, 0, 0]}\n",
      "ratio: 0.916666666590278\n",
      "Bleu_1: 0.000\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.059\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.000\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.250\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.125\n",
      "2022-03-07 15:49:41,176 - INFO: eval_greddy SPIDEr: 0.1250\n",
      "loading annotations into memory...\n",
      "0:00:00.000400\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8, 'reflen': 12, 'guess': [8, 7, 6, 5], 'correct': [0, 0, 0, 0]}\n",
      "ratio: 0.6666666666111113\n",
      "Bleu_1: 0.000\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.025\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.000\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.000\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.000\n",
      "2022-03-07 15:49:48,393 - INFO: eval_beam_2 SPIDEr: 0.0000\n",
      "loading annotations into memory...\n",
      "0:00:00.000442\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8, 'reflen': 12, 'guess': [8, 7, 6, 5], 'correct': [0, 0, 0, 0]}\n",
      "ratio: 0.6666666666111113\n",
      "Bleu_1: 0.000\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.076\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.000\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.667\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.333\n",
      "2022-03-07 15:49:55,852 - INFO: eval_beam_3 SPIDEr: 0.3333\n",
      "loading annotations into memory...\n",
      "0:00:00.000139\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8, 'reflen': 12, 'guess': [8, 7, 6, 5], 'correct': [0, 0, 0, 0]}\n",
      "ratio: 0.6666666666111113\n",
      "Bleu_1: 0.000\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.076\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.000\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.667\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.333\n",
      "2022-03-07 15:50:03,612 - INFO: eval_beam_4 SPIDEr: 0.3333\n"
     ]
    }
   ],
   "source": [
    "#5번째\n",
    "# Evaluation model score\n",
    "epoch = 1\n",
    "model.load_state_dict(torch.load(\"./models/0101_vgg_pretrain/50.pt\"))\n",
    "eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=2)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=3)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4eda45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "439e0cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_text:4.3942\n",
      "loading annotations into memory...\n",
      "0:00:00.000350\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11, 'reflen': 12, 'guess': [11, 10, 9, 8], 'correct': [0, 0, 0, 0]}\n",
      "ratio: 0.916666666590278\n",
      "Bleu_1: 0.000\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.059\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.000\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.250\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.125\n",
      "2022-03-11 13:30:30,097 - INFO: eval_greddy SPIDEr: 0.1250\n",
      "loading annotations into memory...\n",
      "0:00:00.000507\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8, 'reflen': 12, 'guess': [8, 7, 6, 5], 'correct': [0, 0, 0, 0]}\n",
      "ratio: 0.6666666666111113\n",
      "Bleu_1: 0.000\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.025\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.000\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.000\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.000\n",
      "2022-03-11 13:30:37,501 - INFO: eval_beam_2 SPIDEr: 0.0000\n",
      "loading annotations into memory...\n",
      "0:00:00.000292\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8, 'reflen': 12, 'guess': [8, 7, 6, 5], 'correct': [0, 0, 0, 0]}\n",
      "ratio: 0.6666666666111113\n",
      "Bleu_1: 0.000\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.076\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.000\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.667\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.333\n",
      "2022-03-11 13:30:44,545 - INFO: eval_beam_3 SPIDEr: 0.3333\n",
      "loading annotations into memory...\n",
      "0:00:00.000326\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8, 'reflen': 12, 'guess': [8, 7, 6, 5], 'correct': [0, 0, 0, 0]}\n",
      "ratio: 0.6666666666111113\n",
      "Bleu_1: 0.000\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.076\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.000\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.000\n",
      "computing SPICE score...\n",
      "SPICE: 0.667\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.333\n",
      "2022-03-11 13:30:52,029 - INFO: eval_beam_4 SPIDEr: 0.3333\n"
     ]
    }
   ],
   "source": [
    "#5번째\n",
    "# Evaluation model score\n",
    "epoch = 1\n",
    "model.load_state_dict(torch.load(\"./models/0101_vgg_pretrain/50.pt\"))\n",
    "eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=2)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=3)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c90b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07126d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5616de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all(evaluation_data, max_len=30, eos_ind=9, word_dict_pickle_path=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_sentence_all = []\n",
    "        ref_all = []\n",
    "        for src, tgt, tgt_len, ref in evaluation_data:\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            tgt_pad_mask = get_padding(tgt, tgt_len)\n",
    "            tgt_in = tgt[:, :-1]\n",
    "            tgt_pad_mask = tgt_pad_mask[:, :-1]\n",
    "            tgt_y = tgt[:, 1:]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            output_text = model(src, tgt_in, target_padding_mask=tgt_pad_mask)\n",
    "\n",
    "            loss_text = criterion(output_text.contiguous().view(-1, hp.ntoken), tgt_y.transpose(0, 1).contiguous().view(-1))\n",
    "            print(f'loss_text:{loss_text:2.4f}')\n",
    "            output = greedy_decode(model, src, max_len=max_len)\n",
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for i in range(output.size()[0]):\n",
    "                output_sentence_ind = []\n",
    "                for j in range(1, output.size(1)):\n",
    "                    sym = output[i, j]\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n",
    "\n",
    "        loss_mean = score\n",
    "        writer.add_scalar(f'Loss/eval_greddy', loss_mean, epoch)\n",
    "        msg = f'eval_greddy SPIDEr: {loss_mean:2.4f}'\n",
    "        logging.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d46a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29830c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd433a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        tgt_pad_mask = get_padding(tgt, tgt_len)\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        tgt_pad_mask = tgt_pad_mask[:, :-1]\n",
    "        tgt_y = tgt[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, tgt_in, target_padding_mask=tgt_pad_mask)\n",
    "\n",
    "        loss_text = criterion(output.contiguous().view(-1, hp.ntoken), tgt_y.transpose(0, 1).contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = tgt.to(device)\n",
    "                tgt_pad_mask = get_padding(tgt, tgt_len)\n",
    "                tgt_in = tgt[:, :-1]\n",
    "                tgt_pad_mask = tgt_pad_mask[:, :-1]\n",
    "                tgt_y = tgt[:, 1:]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                output_text = model(src, tgt_in, target_padding_mask=tgt_pad_mask)\n",
    "\n",
    "                loss_text = criterion(output_text.contiguous().view(-1, hp.ntoken), tgt_y.transpose(0, 1).contiguous().view(-1))\n",
    "                print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d08b8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_beam(test_data, max_len=30, eos_ind=9, beam_size=3):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with open(\"test_out.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['file_name', 'caption_predicted'])\n",
    "            for src, filename in test_data:\n",
    "                src = src.to(device)\n",
    "                \n",
    "                output = beam_search(model, src, max_len, start_symbol_ind=0, beam_size=beam_size)\n",
    "\n",
    "                output_sentence_ind_batch = []\n",
    "                for single_sample in output:\n",
    "                    output_sentence_ind = []\n",
    "                    for sym in single_sample:\n",
    "                        if sym == eos_ind: break\n",
    "                        output_sentence_ind.append(sym.item())\n",
    "                    output_sentence_ind_batch.append(output_sentence_ind)\n",
    "                out_str = gen_str(output_sentence_ind_batch, hp.word_dict_pickle_path)\n",
    "                for caption, fn in zip(out_str, filename):\n",
    "                    writer.writerow(['{}.wav'.format(fn), caption])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f3f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7585f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe88069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c9e5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdadbffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbceb6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_emb): Embedding(4371, 192)\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=512, out_features=192, bias=True)\n",
       "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
       "  (encoder): Transfer_Cnn10(\n",
       "    (base): Cnn10(\n",
       "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_block1): ConvBlock(\n",
       "        (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block2): ConvBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block3): ConvBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block4): ConvBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (generator): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "397e6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate caption(in test_out.csv)\n",
    "model.load_state_dict(torch.load(\"./models/0101_vgg_pretrain/50.pt\"))\n",
    "test_with_beam(test_data, beam_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d512643f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f08d98dffd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9f1d692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f07ffbe0d68>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4039bdcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce357d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa7461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d3a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50edcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734a884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f72a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd7657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6130a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c4628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17656e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20a20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c73b388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea2634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2883a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/hj20/disc2/create_dataset/data/data_splits')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96ba9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_beam = get_clotho_loader(data_dir=data_dir, split='evaluation5',\n",
    "                                        input_field_name='features',\n",
    "                                        output_field_name='words_ind',\n",
    "                                        load_into_memory=False,\n",
    "                                        batch_size=1,\n",
    "                                        nb_t_steps_pad='max',\n",
    "                                        shuffle=False,\n",
    "                                        return_reference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6c3cdc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355a559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389a573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c8f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5950aaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-04 14:04:22,352 - INFO: | epoch   1 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 59.65 | loss-text 5.8095\n",
      "2021-12-04 14:04:28,155 - INFO: | epoch   1 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 58.03 | loss-text 5.0831\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cb09f8526cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{log_dir}/{num_epoch}.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-94649549a569>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_pad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9d2cd804fa0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, input_mask, target_mask, target_padding_mask)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         output = self.decode(mem, tgt, input_mask=input_mask, target_mask=target_mask,\n\u001b[0;32m--> 126\u001b[0;31m                              target_padding_mask=target_padding_mask)\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9d2cd804fa0a>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, mem, tgt, input_mask, target_mask, target_padding_mask)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mtarget_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#mixup\n",
    "epoch = 1\n",
    "if hp.mode == 'train':\n",
    "    while epoch < hp.training_epochs + 1:\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        torch.save(model.state_dict(), '{log_dir}/{num_epoch}.pt'.format(log_dir=log_dir, num_epoch=epoch))\n",
    "        scheduler.step(epoch)\n",
    "        eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=2)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=3)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=4)\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b593960e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-85fdcc81b46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for src, tgt, tgt_len in training_data:\n",
    "    src = src.to(device)\n",
    "    tgt = tgt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3df15dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.training_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6fa65a",
   "metadata": {},
   "source": [
    "epoch=37 eval_beam_3 SPIDEr: 0.2344 # 2개 layer 만 trainable -06/9  \n",
    " SPIDEr: # 5개 layer 만 trainable -06/10 0.2252\n",
    "별 차이 없음 ;;;;;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19ee5c",
   "metadata": {},
   "source": [
    "model score check (eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3852d268",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/base/48.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2f0e4443ea7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#if hp.mode == 'eval':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Evaluation model score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/base/48.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_beam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/base/48.pt'"
     ]
    }
   ],
   "source": [
    "#if hp.mode == 'eval':\n",
    "# Evaluation model score\n",
    "model.load_state_dict(torch.load(\"./models/base/48.pt\"))\n",
    "eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=2)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=3)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1735c2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./models/base/49.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixup(object):\n",
    "    def __init__(self, mixup_alpha, random_seed=1234):\n",
    "        \"\"\"Mixup coefficient generator.\n",
    "        \"\"\"\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    def get_lambda(self, batch_size):\n",
    "        \"\"\"Get mixup random coefficients.\n",
    "        Args:\n",
    "          batch_size: int\n",
    "        Returns:\n",
    "          mixup_lambdas: (batch_size,)\n",
    "        \"\"\"\n",
    "        mixup_lambdas = []\n",
    "        for n in range(0, batch_size, 2):\n",
    "            lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "            mixup_lambdas.append(lam)\n",
    "            mixup_lambdas.append(1. - lam)\n",
    "\n",
    "        return np.array(mixup_lambdas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fecb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd36458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mixup(x, mixup_lambda):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes \n",
    "    (1, 3, 5, ...).\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0 :: 2].transpose(0, -1) * mixup_lambda[0 :: 2] + \\\n",
    "        x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d22dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.feature.inverse import mel_to_audio, mel_to_stft\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University, Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['feature_extraction']\n",
    "\n",
    "\n",
    "def feature_extraction(audio_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"Feature extraction function.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: Log mel-bands energies of shape=(t, nb_mels)\n",
    "    :rtype: numpy.ndarray, numpy.float\n",
    "    \"\"\"\n",
    "    y = audio_data/abs(audio_data).max()\n",
    "    mel_bands = melspectrogram(\n",
    "        y=y, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power, n_mels=nb_mels,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm).T\n",
    "\n",
    "    return np.log(mel_bands + np.finfo(float).eps)\n",
    "\n",
    "\n",
    "def from_mel_to_audio(mel_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"Feature extraction inverse function.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: audio data\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.exp(mel_data) - np.finfo(float).eps\n",
    "    audio_data = mel_to_audio(\n",
    "        M=y.T, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm)\n",
    "\n",
    "    return audio_data\n",
    "\n",
    "\n",
    "def from_mel_to_stft(mel_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"From logmelspectrogram to stft.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: audio data\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.exp(mel_data) - np.finfo(float).eps\n",
    "    stft = mel_to_stft(\n",
    "        M=y.T, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm)\n",
    "\n",
    "    return stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beae2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "#from tools.features_log_mel_bands import feature_extraction, from_mel_to_audio, from_mel_to_stft\n",
    "from pathlib import Path\n",
    "import pysndfx\n",
    "import gc\n",
    "\n",
    "import copy\n",
    "\n",
    "#from tools.file_io import load_audio_file\n",
    "import torch\n",
    "\n",
    "\n",
    "__author__ = 'Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "\n",
    "class MixUp:\n",
    "\n",
    "    def __init__(self, p, settings_features, simple_concat_captions=True,\n",
    "                 sample_audio=False):\n",
    "\n",
    "        self.p = p\n",
    "        self.sample_audio = sample_audio\n",
    "        self.settings_features = settings_features\n",
    "        self.simple_concat_captions = simple_concat_captions\n",
    "\n",
    "    def from_mel(self, mel):\n",
    "        return 700 * (10 ** (mel / 2595.0) - 1)\n",
    "\n",
    "    def to_mel(self, hertz):\n",
    "        return 2595.0 * np.log10(1 + hertz / 700.0)\n",
    "\n",
    "    def mix_audio(self, first_audio, second_audio):\n",
    "\n",
    "        a = np.random.uniform(0.4, 0.6)\n",
    "\n",
    "        shorter, longer = first_audio, second_audio\n",
    "\n",
    "        if shorter.shape[0] == longer.shape[0]:\n",
    "            if self.sample_audio:\n",
    "                return (longer + shorter) / 2.0\n",
    "            else:\n",
    "                longer = from_mel_to_audio(longer, **self.settings_features['process']) * a\n",
    "                shorter = from_mel_to_audio(shorter,\n",
    "                                            **self.settings_features['process'])\n",
    "                return feature_extraction((longer + shorter) / 2, **self.settings_features['process'])\n",
    "\n",
    "        if first_audio.shape[0] > second_audio.shape[0]:\n",
    "            shorter, longer = longer, shorter\n",
    "\n",
    "\n",
    "        if self.sample_audio:\n",
    "            start = random.randint(0, longer.shape[0] - 1 - shorter.shape[0])\n",
    "            end = start + shorter.shape[0]\n",
    "            longer *= a\n",
    "            longer[start:end] += shorter * (1 - a)\n",
    "        else:\n",
    "            longer = from_mel_to_audio(longer, **self.settings_features['process']) * a\n",
    "            shorter = from_mel_to_audio(shorter,\n",
    "                                        **self.settings_features['process'])\n",
    "            start = random.randint(0, longer.shape[0] - 1 - shorter.shape[0])\n",
    "            end = start + shorter.shape[0]\n",
    "            longer[start:end] += shorter * (1 - a)\n",
    "            longer = feature_extraction(longer,\n",
    "                                        **self.settings_features['process'])\n",
    "\n",
    "        return longer\n",
    "\n",
    "    def mix_labels(self, first_labels, second_labels):\n",
    "        if self.simple_concat_captions:\n",
    "            return np.hstack([first_labels[:-1], second_labels[1:]])\n",
    "        else:\n",
    "\n",
    "            first_token = first_labels[0]\n",
    "            last_token = first_labels[-1]\n",
    "            first_labels = first_labels[1:-1]\n",
    "            second_labels = second_labels[1:-1]\n",
    "            res = np.empty((first_labels.size + second_labels.size,),\n",
    "                           dtype=first_labels.dtype)\n",
    "            min_size = min(first_labels.size, second_labels.size)\n",
    "            res[0:2*min_size:2] = first_labels[:min_size]\n",
    "            res[1:2*min_size:2] = second_labels[:min_size]\n",
    "            if first_labels.size > second_labels.size:\n",
    "                res[min_size * 2:] = first_labels[min_size:]\n",
    "            elif second_labels.size > first_labels.size:\n",
    "                res[min_size*2:] = second_labels[min_size:]\n",
    "            res = np.concatenate(([first_token], res))\n",
    "            res = np.concatenate((res, [last_token]))\n",
    "            return res\n",
    "\n",
    "    def mix_audio_and_labels(self,\n",
    "                             first_audio, second_audio,\n",
    "                             first_labels, second_labels):\n",
    "        mixed_audio = self.mix_audio(first_audio, second_audio)\n",
    "        mixed_labels = self.mix_labels(first_labels, second_labels)\n",
    "\n",
    "        return mixed_audio, mixed_labels\n",
    "\n",
    "    def __call__(self, dataset, inputs):\n",
    "        resulted_audio, resulted_labels, filename = inputs[0], inputs[1], inputs[2]\n",
    "        if np.random.uniform() <= self.p:\n",
    "            random_sample = dataset.random_sample(sample_audio=self.sample_audio)\n",
    "            resulted_audio, resulted_labels = self.mix_audio_and_labels(\n",
    "                resulted_audio, random_sample[0],\n",
    "                resulted_labels, random_sample[1]\n",
    "            )\n",
    "        return resulted_audio, resulted_labels\n",
    "\n",
    "\n",
    "class AudioAugmentation:\n",
    "    # https://github.com/ex4sperans/freesound-classification\n",
    "    def __init__(self, p):\n",
    "\n",
    "        self.p = p\n",
    "        self.effects_chain = (\n",
    "            pysndfx.AudioEffectsChain()\n",
    "                .reverb(\n",
    "                reverberance=random.randrange(50),\n",
    "                room_scale=random.randrange(50),\n",
    "                stereo_depth=random.randrange(50)\n",
    "            )\n",
    "                .pitch(shift=random.randrange(-300, 300))\n",
    "                .overdrive(gain=random.randrange(2, 10))\n",
    "                .speed(random.uniform(0.9, 1.1))\n",
    "        )\n",
    "\n",
    "    def __call__(self, dataset, inputs):\n",
    "\n",
    "        resulted_audio = inputs[0]\n",
    "        captions = inputs[1]\n",
    "        del inputs\n",
    "        gc.collect()\n",
    "        if np.random.uniform() < self.p:\n",
    "            resulted_audio = torch.from_numpy(self.effects_chain(resulted_audio.numpy()))\n",
    "        return resulted_audio, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a5ddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysndfx in /home/hj20/anaconda3/lib/python3.7/site-packages (0.3.6)\r\n",
      "Requirement already satisfied: numpy in /home/hj20/anaconda3/lib/python3.7/site-packages (from pysndfx) (1.20.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pysndfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f78e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchaudio\n",
    "from numpy import load as np_load, ndarray\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pympler import muppy, summary\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University, Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['ClothoDataset']\n",
    "\n",
    "\n",
    "class ClothoDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_dir: Path,\n",
    "                 split: str,\n",
    "                 input_field_name: str,\n",
    "                 output_field_name: str,\n",
    "                 load_into_memory: bool,\n",
    "                 settings_audio,\n",
    "                 settings_features,\n",
    "                 online_preprocessing=True,\n",
    "                 transforms=None) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "        :param data_dir: Data directory with Clotho dataset files.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: The split to use (`development`, `validation`)\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name for the input values\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name for the output (target) values.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load the dataset into memory?\n",
    "        :type load_into_memory: bool\n",
    "        :param settings_audio: Settings about audio loading\n",
    "        :type dict\n",
    "        :param settings_features: Settings about audio processing\n",
    "        :type dict\n",
    "        :param indexes: Indexes of files, which depends on validation strategy\n",
    "        :type indexes: numpy array\n",
    "        :param transforms: List of transforms\n",
    "        :type transforms: list\n",
    "        \"\"\"\n",
    "\n",
    "        super(ClothoDataset, self).__init__()\n",
    "        self.online_preprocessing = online_preprocessing\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "        self.split = split\n",
    "\n",
    "        self.settings_audio = settings_audio\n",
    "        self.settings_features = settings_features\n",
    "\n",
    "        #if indexes is None:\n",
    "        self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        #else:\n",
    "        #    self.examples: List[Path] = list(np.array(sorted(the_dir.iterdir()))[indexes])\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.transforms = transforms\n",
    "        self.resampler = torchaudio.transforms.Resample(orig_freq=settings_features['process']['sr'],\n",
    "                                                        new_freq=settings_features['process']['sr_resample'])\n",
    "        if load_into_memory:\n",
    "            self.examples: List[ndarray] = [\n",
    "                np_load(str(f), allow_pickle=True)\n",
    "                for f in self.examples]\n",
    "        self.cnt = 0\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int) \\\n",
    "            -> Tuple[ndarray, ndarray, Path]:\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values, and the Path of the file.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray, Path\n",
    "        \"\"\"\n",
    "\n",
    "        ex = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex = np_load(str(ex), allow_pickle=True)\n",
    "        if self.online_preprocessing:\n",
    "            in_e = torchaudio.load(Path('data', 'clotho_audio_files', self.split, ex.file_name[0]))[0][0]\n",
    "            ou_e = ex[self.output_name].item()\n",
    "        else:\n",
    "            in_e, ou_e = [ex[i].item()\n",
    "                          for i in [self.input_name, self.output_name]]\n",
    "        filename = ex.file_name[0]\n",
    "        del ex\n",
    "        if self.transforms is not None:\n",
    "            for transform in self.transforms:\n",
    "                in_e, ou_e = transform(dataset=self, inputs=(in_e, ou_e, filename))\n",
    "        return in_e, ou_e, filename\n",
    "\n",
    "    def random_sample(self, sample_audio=False):\n",
    "        \"\"\"\n",
    "        Sampling audio or melspectrogram and encoded output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        item = random.randint(0, len(self.examples) - 1)\n",
    "        ex = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex = np_load(str(ex), allow_pickle=True)\n",
    "        if sample_audio:\n",
    "            thedir = Path('./data/clotho_audio_files/').joinpath(self.split)\n",
    "            filename = Path(thedir, ex.file_name[0])\n",
    "            in_e = torchaudio.load(filepath=filename)[0][0]\n",
    "            #in_e = self.resampler.forward(in_e)\n",
    "            ou_e = ex[self.output_name].item()\n",
    "        else:\n",
    "            in_e, ou_e = [ex[i].item()\n",
    "                          for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        return in_e, ou_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c764639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import MutableSequence, MutableMapping, Union,\\\n",
    "    Tuple, List\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import cat, zeros, from_numpy, ones, Tensor\n",
    "from numpy import ndarray\n",
    "\n",
    "#from data_handlers._clotho import ClothoDataset\n",
    "#from tools.augmentations import MixUp, AudioAugmentation\n",
    "\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University. Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['get_clotho_loader']\n",
    "\n",
    "\n",
    "def _clotho_collate_fn(batch: MutableSequence[ndarray]) \\\n",
    "        -> Tuple[Tensor, Tensor, List[str]]:\n",
    "    \"\"\"Pads data.\n",
    "    For each batch, the maximum input and output\\\n",
    "    time-steps are calculated. Then, then input and\\\n",
    "    output data are padded to match the maximum time-steps.\n",
    "    The input data are padded with zeros in front, and\\\n",
    "    the output with] <EOS> tokens at the end.\n",
    "    :param batch: Batch data of batch x time x features.\\\n",
    "                  First element in the list are the input\\\n",
    "                  data, second the output data.\n",
    "    :type batch: list[numpy.ndarray]\n",
    "    :return: Padded data. First tensor is the input data\\\n",
    "             and second the output.\n",
    "    :rtype: torch.Tensor, torch.Tensor, list[str]\n",
    "    \"\"\"\n",
    "    max_input_t_steps = max([i[0].shape[0] for i in batch])\n",
    "    max_output_t_steps = max([i[1].shape[0] for i in batch])\n",
    "\n",
    "    file_names = [i[2] for i in batch]\n",
    "\n",
    "    #input_features = batch[0][0].shape[-1]\n",
    "    eos_token = batch[0][1][-1]\n",
    "    input_tensor = cat([\n",
    "        cat([zeros(\n",
    "            max_input_t_steps - i[0].shape[0]).float(),\n",
    "             i[0].float()]).unsqueeze(0) for i in batch])\n",
    "    output_tensor = cat([\n",
    "        cat([\n",
    "            from_numpy(i[1]).long(),\n",
    "            ones(max_output_t_steps - len(i[1])).mul(eos_token).long()\n",
    "        ]).unsqueeze(0) for i in batch])\n",
    "    return [input_tensor, output_tensor, file_names]\n",
    "\n",
    "\n",
    "def get_clotho_loader(split: str,\n",
    "                      is_training: bool,\n",
    "                      settings_data: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      settings_io: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[\n",
    "                              str, Union[str, MutableMapping[str, str]]]]],\n",
    "                      settings_features: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      settings_dataset: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      ) \\\n",
    "        -> DataLoader:\n",
    "    \"\"\"Gets the data loader.\n",
    "    :param split: Split to be used.\n",
    "    :type split: str\n",
    "    :param is_training: Is training data?\n",
    "    :type is_training: bool\n",
    "    :param settings_data: Data loading and dataset settings.\n",
    "    :type settings_data: dict\n",
    "    :param settings_io: Files I/O settings.\n",
    "    :type settings_io: dict\n",
    "    :param settings_features: Audio preprocessing features.\n",
    "    :type settings_features: dict\n",
    "    :param settings_dataset: Dataset settings.\n",
    "    :type settings_dataset: dict\n",
    "    :param indexes: Indexes of audio files, which depends on validation_strategy.\n",
    "    :type indexes: numpy array\n",
    "    :type settings_training: dict\n",
    "    :return: Data loader.\n",
    "    :rtype: torch.utils.data.DataLoader\n",
    "    \"\"\"\n",
    "    data_dir = Path(\n",
    "        settings_io['root_dirs']['data'],\n",
    "        settings_io['dataset']['features_dirs']['output'])\n",
    "\n",
    "    transforms = []\n",
    "    if settings_data['transforms'] == 'None' or (not is_training):\n",
    "        transforms = None\n",
    "    else:\n",
    "        if 'MixUp' in settings_data['transforms']:\n",
    "            print(settings_features['simple_concat_captions'], 'lalalalalal')\n",
    "            transforms.append(MixUp(p=settings_data['MixUp_p'],\n",
    "                              settings_features=settings_features,\n",
    "                              simple_concat_captions=settings_features['simple_concat_captions'],\n",
    "                              sample_audio=True))\n",
    "        if 'another' in settings_data['transforms']:\n",
    "            transforms.append(AudioAugmentation(p=settings_data['MixUp_p']))\n",
    "\n",
    "    #if settings_training['validation_strategy']\n",
    "    dataset = ClothoDataset(\n",
    "        data_dir=data_dir,\n",
    "        split=split,\n",
    "        input_field_name=settings_data['input_field_name'],\n",
    "        output_field_name=settings_data['output_field_name'],\n",
    "        load_into_memory=settings_data['load_into_memory'],\n",
    "        settings_audio=settings_dataset['audio'],\n",
    "        settings_features=settings_features,\n",
    "        transforms=transforms)\n",
    "\n",
    "    shuffle = settings_data['shuffle'] if is_training else False\n",
    "    drop_last = settings_data['drop_last'] if is_training else False\n",
    "    if is_training:\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=settings_data['batch_size'],\n",
    "            shuffle=shuffle,\n",
    "            num_workers=settings_data['num_workers'],\n",
    "            drop_last=drop_last,\n",
    "            # pin_memory=True,\n",
    "            collate_fn=_clotho_collate_fn)\n",
    "    else:\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=40,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=2,\n",
    "            drop_last=drop_last,\n",
    "            # pin_memory=True,\n",
    "            collate_fn=_clotho_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bdc159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file='main_settings'\n",
    "file_ext='yaml'\n",
    "file_dir='settings' \n",
    "settings = file_io.load_yaml_file(Path(\n",
    "        file_dir, f'{config_file}.{file_ext}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282439e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.file_io import load_audio_file\n",
    "from tools import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba6d900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True lalalalalal\n"
     ]
    }
   ],
   "source": [
    "training_data = get_clotho_loader(\n",
    "            settings_io['dataset']['features_dirs']['development'],\n",
    "            is_training=True,\n",
    "            settings_data=settings_data,\n",
    "            settings_io=settings_io,\n",
    "            settings_features=settings_features,\n",
    "            settings_dataset=settings_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da33e988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fc96caf",
   "metadata": {},
   "outputs": [],
   "source": [
    " =  get_clotho_loader(\n",
    "            settings_io['dataset']['features_dirs']['evaluation'],\n",
    "            is_training=False,\n",
    "            settings_data=settings_data,\n",
    "            settings_io=settings_io,\n",
    "            settings_features=settings_features,\n",
    "            settings_dataset=settings_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2e22027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c197368",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_io=settings['dirs_and_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586cf61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MixUp']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_data['transforms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46972f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_dirs': {'outputs': 'outputs', 'data': 'data'},\n",
       " 'dataset': {'development': 'development',\n",
       "  'evaluation': 'evaluation',\n",
       "  'features_dirs': {'output': 'data_splits_mel',\n",
       "   'development': 'development',\n",
       "   'evaluation': 'evaluation'},\n",
       "  'audio_dirs': {'downloaded': 'clotho_audio_files',\n",
       "   'output': 'data_splits_audio_mel',\n",
       "   'development': 'development',\n",
       "   'evaluation': 'evaluation'},\n",
       "  'annotations_dir': 'clotho_csv_files',\n",
       "  'pickle_files_dir': 'pickles',\n",
       "  'files': {'np_file_name_template': 'clotho_file_{audio_file_name}_{caption_index}.npy',\n",
       "   'words_list_file_name': 'words_list.p',\n",
       "   'words_counter_file_name': 'words_frequencies.p',\n",
       "   'characters_list_file_name': 'characters_list.p',\n",
       "   'characters_frequencies_file_name': 'characters_frequencies.p'}},\n",
       " 'model': {'model_dir': 'models',\n",
       "  'checkpoint_model_name': 'dcase_model_baseline.pt',\n",
       "  'pre_trained_model_name': 'dcase_model_baseline_pre_trained.pt'},\n",
       " 'logging': {'logger_dir': 'logging',\n",
       "  'caption_logger_file': 'captions_baseline.txt'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201948df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'development'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_io['dataset']['features_dirs']['development']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc641b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_data=settings['dnn_training_settings']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa82501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_field_name': 'features',\n",
       " 'output_field_name': 'words_ind',\n",
       " 'load_into_memory': False,\n",
       " 'transforms': ['MixUp'],\n",
       " 'MixUp_p': 0.5,\n",
       " 'batch_size': 16,\n",
       " 'shuffle': True,\n",
       " 'num_workers': 4,\n",
       " 'drop_last': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0419e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_features=settings['feature_extraction_settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f7120db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keep_raw_audio_data': False,\n",
       " 'simple_concat_captions': True,\n",
       " 'process': {'sr': 44100,\n",
       "  'sr_resample': 16000,\n",
       "  'nb_fft': 1024,\n",
       "  'hop_size': 512,\n",
       "  'nb_mels': 64,\n",
       "  'window_function': 'hann',\n",
       "  'center': True,\n",
       "  'f_min': 0.0,\n",
       "  'f_max': None,\n",
       "  'htk': False,\n",
       "  'power': 1.0,\n",
       "  'norm': 1}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04521df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dataset=settings['dataset_creation_settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd805b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workflow': {'create_dataset': True, 'validate_dataset': False},\n",
       " 'annotations': {'development_file': 'clotho_captions_development.csv',\n",
       "  'evaluation_file': 'clotho_captions_evaluation.csv',\n",
       "  'audio_file_column': 'file_name',\n",
       "  'captions_fields_prefix': 'caption_{}',\n",
       "  'use_special_tokens': True,\n",
       "  'nb_captions': 5,\n",
       "  'keep_case': False,\n",
       "  'remove_punctuation_words': True,\n",
       "  'remove_punctuation_chars': True,\n",
       "  'use_unique_words_per_caption': False,\n",
       "  'use_unique_chars_per_caption': False},\n",
       " 'audio': {'sr': 44100, 'to_mono': True, 'max_abs_value': 1.0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from typing import Tuple, List, AnyStr, Union\n",
    "from pathlib import Path\n",
    "\n",
    "from numpy import ndarray, recarray\n",
    "from torch.utils.data import Dataset\n",
    "from numpy import load as np_load\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['ClothoDataset']\n",
    "\n",
    "\n",
    "class ClothoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir: Path,\n",
    "                 split: AnyStr,\n",
    "                 input_field_name: AnyStr,\n",
    "                 output_field_name: AnyStr,\n",
    "                 load_into_memory: bool,\n",
    "                 transforms=transforms) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "\n",
    "        :param data_dir: Directory with data.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name of the clotho data\\\n",
    "                                 to be used as input data to the\\\n",
    "                                 method.\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name of the clotho data\\\n",
    "                                 to be used as output data to the\\\n",
    "                                 method.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load all data into memory?\n",
    "        :type load_into_memory: bool\n",
    "        \"\"\"\n",
    "        super(ClothoDataset, self).__init__()\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "\n",
    "        self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.transforms=transforms\n",
    "        if load_into_memory:\n",
    "            self.examples: List[recarray] = [np_load(str(f), allow_pickle=True)\n",
    "                                             for f in self.examples]\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int) \\\n",
    "            -> Tuple[ndarray, ndarray]:\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray\n",
    "        \"\"\"\n",
    "        ex: Union[Path, recarray] = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex: recarray = np_load(str(ex), allow_pickle=True)\n",
    "\n",
    "        in_e, ou_e = [ex[i].item() for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        return in_e, ou_e\n",
    "\n",
    "\n",
    "class ClothoDatasetEval(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir: Path,\n",
    "                 split: AnyStr,\n",
    "                 input_field_name: AnyStr,\n",
    "                 output_field_name: AnyStr,\n",
    "                 load_into_memory: bool) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "\n",
    "        :param data_dir: Directory with data.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name of the clotho data\\\n",
    "                                 to be used as input data to the\\\n",
    "                                 method.\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name of the clotho data\\\n",
    "                                 to be used as output data to the\\\n",
    "                                 method.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load all data into memory?\n",
    "        :type load_into_memory: bool\n",
    "        \"\"\"\n",
    "        super(ClothoDatasetEval, self).__init__()\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "        if split == 'evaluation':\n",
    "            self.examples: List[Path] = sorted(the_dir.iterdir())[::5]  # changed\n",
    "        else:\n",
    "            self.examples: List[Path] = sorted(the_dir.iterdir())  # changed\n",
    "        # self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.data_dir = the_dir\n",
    "\n",
    "        if load_into_memory:\n",
    "            self.examples: List[recarray] = [np_load(str(f), allow_pickle=True)\n",
    "                                             for f in self.examples]\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int):\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray\n",
    "        \"\"\"\n",
    "        ex: Union[Path, recarray] = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex: recarray = np_load(str(ex), allow_pickle=True)\n",
    "\n",
    "        in_e, ou_e = [ex[i].item() for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        all_ref = get_all_ref(ex['file_name'].item(), self.data_dir)\n",
    "\n",
    "        filename = str(ex['file_name'].item())\n",
    "        out_len = len(ou_e)\n",
    "        return in_e, ou_e, all_ref, filename,out_len\n",
    "\n",
    "\n",
    "def get_all_ref(filename, data_dir):\n",
    "    filename = str(filename)\n",
    "    # tgt = [np.load(d, allow_pickle=True).words_ind.tolist()\n",
    "    tgt = [np.load(d, allow_pickle=True)['words_ind'].item().tolist()\n",
    "           for d in [os.path.join(data_dir, 'clotho_file_{filename}.wav_{i}.npy'.\n",
    "                                  format(filename=filename[:-4],  # 删除'.wav'\n",
    "                                         i=i)) for i in range(5)]  # wav_0-wav_4\n",
    "           ]\n",
    "    return tgt\n",
    "# EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa295a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff041f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from typing import Callable, Union, Tuple, AnyStr, Optional\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from .clotho_dataset import ClothoDataset, ClothoDatasetEval\n",
    "from .collate_fn import clotho_collate_fn, clotho_collate_fn_eval\n",
    "\n",
    "__author__ = 'Konstantinos Drossos'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['get_clotho_loader']\n",
    "\n",
    "\n",
    "def get_clotho_loader(data_dir: Path,\n",
    "                      split: str,\n",
    "                      input_field_name: str,\n",
    "                      output_field_name: str,\n",
    "                      load_into_memory: bool,\n",
    "                      batch_size: int,\n",
    "                      nb_t_steps_pad: Union[AnyStr, Tuple[int, int]],\n",
    "                      shuffle: Optional[bool] = True,\n",
    "                      drop_last: Optional[bool] = True,\n",
    "                      input_pad_at: Optional[str] = 'start',\n",
    "                      output_pad_at: Optional[str] = 'end',\n",
    "                      num_workers: Optional[int] = 1,\n",
    "                      return_reference: Optional[bool] = False,\n",
    "                      augment: Optional[bool] = False) \\\n",
    "        -> DataLoader:\n",
    "    \"\"\"Gets the clotho data loader.\n",
    "\n",
    "    :param return_reference:\n",
    "    :param data_dir: Directory with data.\n",
    "    :type data_dir: pathlib.Path\n",
    "    :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "    :type split: str\n",
    "    :param input_field_name: Field name of the clotho data\\\n",
    "                             to be used as input data to the\\\n",
    "                             method.\n",
    "    :type input_field_name: str\n",
    "    :param output_field_name: Field name of the clotho data\\\n",
    "                             to be used as output data to the\\\n",
    "                             method.\n",
    "    :type output_field_name: str\n",
    "    :param load_into_memory: Load all data into memory?\n",
    "    :type load_into_memory: bool\n",
    "    :param batch_size: Batch size to use.\n",
    "    :type batch_size: int\n",
    "    :param nb_t_steps_pad: Number of time steps to\\\n",
    "                           pad/truncate to. Cab use\\\n",
    "                           'max', 'min', or exact number\\\n",
    "                           e.g. (1024, 10).\n",
    "    :type nb_t_steps_pad: str|(int, int)\n",
    "    :param shuffle: Shuffle examples? Defaults to True.\n",
    "    :type shuffle: bool, optional\n",
    "    :param drop_last: Drop the last examples if not making\\\n",
    "                      a batch of `batch_size`? Defaults to True.\n",
    "    :type drop_last: bool, optional\n",
    "    :param input_pad_at: Pad input at the start or\\\n",
    "                         at the end?\n",
    "    :type input_pad_at: str\n",
    "    :param output_pad_at: Pad output at the start or\\\n",
    "                          at the end?\n",
    "    :type output_pad_at: str\n",
    "    :param num_workers: Amount of workers, defaults to 1.\n",
    "    :type num_workers: int, optional\n",
    "    :return: Dataloader for Clotho data.\n",
    "    :rtype: torch.utils.data.dataloader.DataLoader\n",
    "    \"\"\"\n",
    "    if return_reference:\n",
    "        dataset: ClothoDatasetEval = ClothoDatasetEval(\n",
    "            data_dir=data_dir, split=split,\n",
    "            input_field_name=input_field_name,\n",
    "            output_field_name=output_field_name,\n",
    "            load_into_memory=load_into_memory\n",
    "            transforms=trans)\n",
    "\n",
    "        collate_fn: Callable = partial(\n",
    "            clotho_collate_fn_eval,\n",
    "            nb_t_steps=nb_t_steps_pad,\n",
    "            input_pad_at=input_pad_at,\n",
    "            output_pad_at=output_pad_at, split=split, augment=augment)\n",
    "    else:\n",
    "        dataset: ClothoDataset = ClothoDataset(\n",
    "            data_dir=data_dir, split=split,\n",
    "            input_field_name=input_field_name,\n",
    "            output_field_name=output_field_name,\n",
    "            load_into_memory=load_into_memory)\n",
    "\n",
    "        collate_fn: Callable = partial(\n",
    "            clotho_collate_fn,\n",
    "            nb_t_steps=nb_t_steps_pad,\n",
    "            input_pad_at=input_pad_at,\n",
    "            output_pad_at=output_pad_at)\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset=dataset, batch_size=batch_size,\n",
    "        shuffle=shuffle, num_workers=num_workers,\n",
    "        drop_last=drop_last, collate_fn=collate_fn)\n",
    "\n",
    "# EOF\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcaset6",
   "language": "python",
   "name": "dcase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
