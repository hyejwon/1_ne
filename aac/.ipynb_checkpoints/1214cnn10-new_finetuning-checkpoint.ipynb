{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f52a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58059f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn14,Cnn10,init_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5214a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a900f95",
   "metadata": {},
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abbeed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transfer_Cnn10(nn.Module):\n",
    "    def __init__(self, freeze_base=True, pretrain_checkpoint=None):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_Cnn10, self).__init__()\n",
    "\n",
    "        audioset_classes_num = 527\n",
    "        self.base = Cnn10()\n",
    "\n",
    "        #self.init_weights()\n",
    "\n",
    "        if pretrain_checkpoint:\n",
    "            self.load_from_pretrain(pretrain_checkpoint)\n",
    "            \n",
    "        #self.base.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        # 안쓰이는이유는 multi-class clasification을 생략하기 때문,\n",
    "\n",
    "        if freeze_base:\n",
    "            # 2단계 freeze / 3단계 freeze X\n",
    "            # Freeze AudioSet pretrained layers\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    #def init_weights(self):\n",
    "        #init_layer(self.fc_transfer)\n",
    "\n",
    "    def load_from_pretrain(self, pretrained_checkpoint):\n",
    "        pretrained_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\"\n",
    "        checkpoint = torch.load(pretrained_checkpoint)\n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_imag.weight')#가중치 삭제  \n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_real.weight')#가중치 삭제\n",
    "        checkpoint['model'].pop('logmel_extractor.melW')#가중치 삭제\n",
    "        checkpoint['model'].pop('fc1.weight')\n",
    "        checkpoint['model'].pop('fc1.bias')\n",
    "        checkpoint['model'].pop('fc_audioset.weight')\n",
    "        checkpoint['model'].pop('fc_audioset.bias')\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        output = self.base(input)\n",
    "\n",
    "        #embedding = output_dict['embedding']\n",
    "        #clipwise_output = output_dict['clipwise_output']\n",
    "\n",
    "        return output #, clipwise_output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2840e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\"\n",
    "checkpoint = torch.load(pretrained_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4cfe7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iteration': 440000,\n",
       " 'model': OrderedDict([('spectrogram_extractor.stft.conv_real.weight',\n",
       "               tensor([[[ 0.0000e+00,  9.4124e-06,  3.7649e-05,  ...,  8.4709e-05,\n",
       "                          3.7649e-05,  9.4124e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00,  9.4122e-06,  3.7646e-05,  ...,  8.4695e-05,\n",
       "                          3.7646e-05,  9.4122e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00,  9.4117e-06,  3.7638e-05,  ...,  8.4652e-05,\n",
       "                          3.7638e-05,  9.4117e-06]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4117e-06,  3.7638e-05,  ..., -8.4652e-05,\n",
       "                          3.7638e-05, -9.4117e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4122e-06,  3.7646e-05,  ..., -8.4695e-05,\n",
       "                          3.7646e-05, -9.4122e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4124e-06,  3.7649e-05,  ..., -8.4709e-05,\n",
       "                          3.7649e-05, -9.4124e-06]]], device='cuda:0')),\n",
       "              ('spectrogram_extractor.stft.conv_imag.weight',\n",
       "               tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -5.7753e-08, -4.6201e-07,  ...,  1.5592e-06,\n",
       "                          4.6201e-07,  5.7753e-08]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1550e-07, -9.2395e-07,  ...,  3.1179e-06,\n",
       "                          9.2395e-07,  1.1550e-07]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1550e-07,  9.2395e-07,  ...,  3.1179e-06,\n",
       "                         -9.2395e-07,  1.1550e-07]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -5.7753e-08,  4.6201e-07,  ...,  1.5592e-06,\n",
       "                         -4.6201e-07,  5.7753e-08]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1527e-21,  9.2214e-21,  ..., -1.7514e-17,\n",
       "                          1.2470e-17, -8.8136e-21]]], device='cuda:0')),\n",
       "              ('logmel_extractor.melW',\n",
       "               tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0043, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       ...,\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "                      device='cuda:0')),\n",
       "              ('bn0.weight',\n",
       "               tensor([1.2579, 1.2287, 1.1752, 1.1472, 1.1341, 1.1017, 1.0914, 1.0787, 1.0651,\n",
       "                       1.0756, 1.0683, 1.0589, 1.0478, 1.0323, 1.0432, 1.0094, 1.0038, 1.0202,\n",
       "                       1.0210, 1.0268, 1.0409, 1.0565, 1.0200, 1.0603, 1.0618, 1.0505, 1.0631,\n",
       "                       1.0512, 1.0770, 1.0790, 1.0833, 1.0788, 1.0826, 1.0741, 1.0893, 1.0994,\n",
       "                       1.1181, 1.1037, 1.1052, 1.1233, 1.1174, 1.1264, 1.1512, 1.1866, 1.2267,\n",
       "                       1.2610, 1.2632, 1.3015, 1.2884, 1.3413, 1.3513, 1.3659, 1.3383, 1.3445,\n",
       "                       1.3790, 1.3468, 1.3447, 1.3394, 1.2890, 1.2610, 1.2722, 1.2695, 1.2540,\n",
       "                       1.2942], device='cuda:0')),\n",
       "              ('bn0.bias',\n",
       "               tensor([ 0.1418,  0.1614,  0.2051,  0.2250,  0.2054,  0.2128,  0.2234,  0.2539,\n",
       "                        0.2251,  0.2122,  0.2185,  0.2002,  0.2017,  0.1822,  0.1683,  0.1444,\n",
       "                        0.1269,  0.1714,  0.1422,  0.1387,  0.1513,  0.1419,  0.1510,  0.1334,\n",
       "                        0.1520,  0.1332,  0.1163,  0.1276,  0.1073,  0.1257,  0.1314,  0.1131,\n",
       "                        0.1414,  0.1328,  0.1064,  0.1035,  0.0991,  0.1022,  0.1113,  0.1031,\n",
       "                        0.0918,  0.0667,  0.0340,  0.0058, -0.0343, -0.0510, -0.0735, -0.0952,\n",
       "                       -0.1210, -0.1620, -0.1719, -0.1713, -0.1978, -0.1898, -0.2296, -0.2104,\n",
       "                       -0.2010, -0.2143, -0.1837, -0.2698, -0.2991, -0.3428, -0.3216, -0.2706],\n",
       "                      device='cuda:0')),\n",
       "              ('bn0.running_mean',\n",
       "               tensor([-14.7698, -13.6179, -13.6138, -13.7430, -14.3962, -14.5996, -15.4520,\n",
       "                       -15.8805, -16.5379, -17.0350, -17.5244, -18.0900, -18.3324, -19.0569,\n",
       "                       -19.5501, -20.2974, -20.4803, -21.0466, -21.3381, -21.5437, -22.0068,\n",
       "                       -22.1964, -22.6461, -23.1714, -23.2960, -23.5023, -23.8864, -24.1805,\n",
       "                       -24.8282, -24.9183, -25.4159, -25.7884, -26.1122, -26.6204, -27.0275,\n",
       "                       -27.5277, -28.0286, -28.3588, -28.8325, -29.3342, -30.0424, -30.7998,\n",
       "                       -31.6253, -32.8063, -33.9453, -34.8903, -35.8278, -36.8257, -37.9765,\n",
       "                       -39.4108, -40.4666, -41.2937, -42.2061, -43.2223, -44.2648, -45.2302,\n",
       "                       -46.2764, -47.3646, -48.5596, -50.5382, -52.2995, -53.9504, -55.6551,\n",
       "                       -57.6545], device='cuda:0')),\n",
       "              ('bn0.running_var',\n",
       "               tensor([596.6601, 575.9350, 560.0305, 552.3881, 547.5211, 543.4526, 540.1447,\n",
       "                       537.5850, 537.4604, 537.6881, 536.0203, 530.9358, 531.9637, 525.5637,\n",
       "                       517.0662, 513.1134, 512.5848, 509.0781, 503.4427, 505.8644, 502.7238,\n",
       "                       499.5360, 499.5542, 495.1674, 495.0078, 492.7249, 487.0581, 484.2194,\n",
       "                       479.8156, 480.9565, 476.3221, 475.1716, 477.7686, 474.1192, 475.2479,\n",
       "                       472.0588, 468.3824, 464.7163, 466.6536, 467.5047, 463.1785, 460.5492,\n",
       "                       459.6526, 470.3666, 489.5420, 499.5362, 507.8021, 513.4002, 517.6402,\n",
       "                       540.6107, 557.5811, 558.7811, 560.7786, 561.4371, 562.8868, 558.7776,\n",
       "                       555.0521, 546.9778, 535.2908, 534.0878, 539.0059, 537.0637, 529.1208,\n",
       "                       521.8989], device='cuda:0')),\n",
       "              ('bn0.num_batches_tracked', tensor(440000, device='cuda:0')),\n",
       "              ('conv_block1.conv1.weight',\n",
       "               tensor([[[[-3.7039e-02, -4.2758e-01,  4.6078e-01],\n",
       "                         [-9.8838e-02, -4.7424e-01,  3.5086e-01],\n",
       "                         [ 5.4757e-02, -2.9605e-01,  4.8484e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.3487e-01, -2.7748e-01, -2.2969e-01],\n",
       "                         [-2.5529e-03, -1.0134e-01, -9.9216e-02],\n",
       "                         [ 8.8498e-02,  4.3399e-01,  3.1902e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.8117e-01,  2.1679e-01,  8.6598e-03],\n",
       "                         [-3.0433e-01,  4.2776e-01, -2.8384e-02],\n",
       "                         [-3.1323e-01,  3.7712e-01, -8.6349e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.1328e-01, -4.7214e-01, -1.5421e-01],\n",
       "                         [-7.4739e-03,  1.5373e-01, -9.9434e-02],\n",
       "                         [ 5.1257e-01,  3.8470e-01,  2.0314e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2202e-01,  1.1475e-01,  1.7375e-01],\n",
       "                         [ 4.6711e-02, -2.4738e-01, -1.1763e-01],\n",
       "                         [-1.2941e-01, -1.4176e-01, -8.9102e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.6680e-01, -5.6923e-01, -3.8833e-01],\n",
       "                         [ 7.2493e-01, -2.7824e-01,  9.7279e-03],\n",
       "                         [ 2.4725e-01, -1.6016e-01,  9.7753e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.4617e-01,  1.1877e-01,  9.5465e-02],\n",
       "                         [ 5.3723e-02,  1.6259e-02,  3.4303e-02],\n",
       "                         [-2.3713e-01, -1.7044e-01, -7.7720e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.7280e-01,  5.4870e-01, -3.0124e-01],\n",
       "                         [-3.1358e-01,  4.4885e-01, -2.8404e-01],\n",
       "                         [-1.4353e-01,  5.0320e-01, -2.3500e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.4014e-04, -6.3007e-02, -2.5290e-01],\n",
       "                         [-1.3695e-02, -7.0924e-02, -1.0243e-01],\n",
       "                         [ 1.5860e-01,  2.4922e-01,  7.3565e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2324e-01, -2.8807e-01,  7.9693e-01],\n",
       "                         [-2.5401e-01, -1.1556e-01,  2.5972e-01],\n",
       "                         [-2.0476e-01, -4.7462e-01, -3.4198e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.0406e-01,  5.1279e-02, -3.6834e-01],\n",
       "                         [-2.3591e-01,  2.6704e-01,  1.5689e-01],\n",
       "                         [-2.8982e-01, -2.9980e-02,  1.7038e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.3808e-02, -2.1475e-01,  2.4791e-01],\n",
       "                         [-1.5626e-01, -2.8334e-01,  9.1087e-02],\n",
       "                         [-8.4360e-02, -1.1746e-01,  1.6794e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.2985e-01, -1.6245e-01, -3.5523e-01],\n",
       "                         [ 5.0251e-01, -1.0382e-01, -3.8975e-01],\n",
       "                         [ 2.4276e-01,  5.4808e-02, -2.7259e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.4744e-01,  2.3009e-01,  8.3530e-01],\n",
       "                         [-1.4976e-01, -2.8275e-01,  2.4763e-01],\n",
       "                         [-1.9248e-01, -3.3660e-01, -1.4239e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.4622e-02, -5.6861e-02, -4.1197e-01],\n",
       "                         [ 5.7208e-01, -5.0864e-02, -4.3210e-01],\n",
       "                         [ 5.4853e-01,  5.0650e-02, -3.2082e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6556e-01, -5.3412e-01, -2.3066e-01],\n",
       "                         [-2.8875e-02,  2.4764e-02, -1.6386e-01],\n",
       "                         [-3.9200e-03,  5.5788e-01,  2.6252e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.1720e-01, -4.7870e-01,  1.1784e-01],\n",
       "                         [-2.0684e-01,  6.2280e-02,  4.1311e-01],\n",
       "                         [ 5.6433e-02,  4.4781e-02,  4.6758e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1200e-01,  2.7321e-01, -3.9600e-02],\n",
       "                         [-3.1901e-01,  3.1452e-01, -2.7479e-03],\n",
       "                         [-3.3993e-01,  3.6536e-01,  5.1426e-04]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.2003e-01,  1.8998e-01,  1.2129e-01],\n",
       "                         [-2.7666e-01,  9.2499e-02, -4.6375e-02],\n",
       "                         [-1.4448e-01,  6.8090e-02,  7.0098e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.7226e-02, -1.2127e-01,  2.3658e-01],\n",
       "                         [-2.4300e-01, -1.9383e-01,  1.1952e-01],\n",
       "                         [ 2.2897e-02, -8.7058e-02,  3.2172e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.3028e-02, -2.3576e-01,  4.1035e-02],\n",
       "                         [ 1.6508e-01, -1.1036e-01,  9.5125e-02],\n",
       "                         [-2.9840e-03,  1.8085e-01,  2.6306e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.4316e-01,  1.1665e+00, -4.3412e-01],\n",
       "                         [ 6.2403e-02, -5.5574e-01,  1.2445e-01],\n",
       "                         [ 5.2582e-02, -3.2262e-01,  1.8072e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.5395e-01,  6.7191e-01, -4.2608e-01],\n",
       "                         [ 1.4435e-01,  7.4019e-01, -1.7308e-01],\n",
       "                         [-2.6455e-01, -1.5263e-02, -2.0942e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.5521e-01, -2.1611e-01,  7.1947e-02],\n",
       "                         [ 3.0966e-01, -3.0091e-01, -7.8164e-03],\n",
       "                         [ 3.0483e-01, -3.1466e-01,  1.5690e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9823e-01, -4.2168e-01,  6.0279e-02],\n",
       "                         [-3.2808e-01, -3.3818e-01,  3.4307e-01],\n",
       "                         [-9.1788e-02,  2.4978e-01,  6.2914e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0916e-01, -1.0632e-02,  4.5488e-01],\n",
       "                         [ 1.1837e-02, -5.0426e-01,  5.5825e-02],\n",
       "                         [ 1.8273e-01, -5.3850e-01,  8.3406e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.7359e-01, -1.8598e-01,  2.1945e-02],\n",
       "                         [ 2.8800e-01, -1.5747e-01, -1.0243e-01],\n",
       "                         [ 1.2883e-01, -3.4466e-01, -1.4244e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.6872e-01, -1.4464e-01,  2.2020e-01],\n",
       "                         [-2.9175e-01,  2.2592e-01,  2.0379e-01],\n",
       "                         [-1.6604e-01,  2.6496e-01, -8.3792e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.5360e-02,  3.8966e-01,  1.4031e-01],\n",
       "                         [ 1.2257e-02,  2.1597e-02, -4.7005e-02],\n",
       "                         [ 9.1067e-02, -1.6526e-01, -1.9378e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0163e-01, -4.5580e-01,  3.1707e-01],\n",
       "                         [ 1.8935e-01, -4.5179e-01,  2.3650e-01],\n",
       "                         [ 2.7485e-01, -4.0986e-01,  2.1443e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.7262e-01, -1.0266e-01, -4.1695e-01],\n",
       "                         [ 4.8492e-01, -2.3177e-03, -4.4562e-01],\n",
       "                         [ 3.3022e-01,  6.2551e-02, -3.2547e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2101e-01,  1.0126e-01, -3.6913e-02],\n",
       "                         [ 1.4700e-01,  6.9705e-02, -3.9404e-02],\n",
       "                         [-5.5072e-02, -1.1184e-01, -6.6921e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.8531e-01, -4.7569e-02, -2.3400e-01],\n",
       "                         [ 3.4791e-01, -7.7497e-02, -2.4477e-01],\n",
       "                         [ 3.7497e-01, -1.4277e-01, -3.4089e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1033e+00,  1.2753e-01, -6.2010e-03],\n",
       "                         [-7.2243e-01, -4.6420e-01, -5.2412e-03],\n",
       "                         [-3.7374e-01,  4.0990e-01, -7.4779e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.1552e-01,  5.3512e-01,  8.1034e-02],\n",
       "                         [-1.1637e-01,  3.2702e-02,  9.7668e-03],\n",
       "                         [ 7.4868e-01, -5.4375e-01, -1.1775e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.5149e-01,  1.8367e-01,  5.9942e-01],\n",
       "                         [ 6.4945e-02, -3.3298e-01,  4.7456e-02],\n",
       "                         [-7.2457e-02, -6.4503e-01, -2.3545e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.3996e-01, -4.6708e-01,  6.5029e-02],\n",
       "                         [ 4.1431e-01, -5.8810e-01, -1.2947e-01],\n",
       "                         [ 6.3620e-01, -4.6198e-01,  8.9512e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.8400e-01,  6.0769e-01,  3.9696e-01],\n",
       "                         [-1.0041e-01, -5.5067e-02, -6.5041e-02],\n",
       "                         [-4.0160e-01, -5.5484e-01, -4.9943e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.7577e-01,  9.2406e-02,  9.8464e-02],\n",
       "                         [-2.4153e-01, -1.5672e-02,  1.2420e-01],\n",
       "                         [-6.3149e-01, -2.6339e-02,  4.9605e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.2362e-01, -4.3782e-01, -5.7199e-01],\n",
       "                         [ 5.7036e-02,  1.7327e-01,  5.8640e-02],\n",
       "                         [ 3.2428e-01,  2.6780e-01,  1.1553e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.2817e-02,  2.5345e-01, -2.3407e-01],\n",
       "                         [ 6.5310e-02,  1.0996e-01, -1.5513e-01],\n",
       "                         [-2.7904e-02,  2.7827e-01, -2.4337e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1770e-01,  3.1490e-01, -9.0855e-01],\n",
       "                         [-1.3766e-01,  3.3192e-03,  7.7066e-01],\n",
       "                         [-5.3093e-02, -3.6863e-01,  2.3213e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.5213e-02, -4.4828e-01,  6.2535e-02],\n",
       "                         [ 5.3619e-02, -4.0840e-01,  4.2392e-03],\n",
       "                         [ 2.0112e-01, -2.2866e-01,  3.0056e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.9792e-01,  2.0081e-01,  1.9037e-01],\n",
       "                         [-2.4127e-01, -3.5608e-01, -2.4821e-01],\n",
       "                         [-3.8929e-02,  1.7353e-01, -4.8857e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.0018e-01,  1.3077e-03, -2.7321e-01],\n",
       "                         [ 2.7165e-02,  3.3843e-02, -7.1168e-02],\n",
       "                         [ 5.3553e-02,  2.3183e-01, -4.2740e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.8983e-01, -3.7882e-02,  7.5205e-01],\n",
       "                         [-4.3510e-01, -2.7665e-01,  5.3879e-01],\n",
       "                         [-3.7065e-01, -1.9793e-01,  3.8153e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0559e-01,  3.1273e-01,  1.5594e-01],\n",
       "                         [ 1.7393e-01, -6.1596e-02, -2.1482e-01],\n",
       "                         [ 1.0072e-01, -3.6248e-01, -2.6370e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0709e-01, -2.5422e-01,  5.1832e-02],\n",
       "                         [ 2.1006e-01, -1.3040e-01, -6.3120e-02],\n",
       "                         [ 6.7084e-02, -9.1186e-02,  8.9826e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.0937e-01,  3.9595e-01,  2.2122e-01],\n",
       "                         [-1.6386e-01,  2.8206e-02, -1.7149e-01],\n",
       "                         [-4.2785e-01, -1.2610e-01, -1.6499e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.4867e-01, -2.5180e-01, -3.5126e-01],\n",
       "                         [-1.1301e-01, -1.2536e-01, -8.0463e-02],\n",
       "                         [ 8.8822e-01,  3.9861e-01,  2.1695e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0753e-02,  4.4991e-02, -2.4421e-01],\n",
       "                         [ 9.5658e-03,  2.3654e-01, -2.5991e-01],\n",
       "                         [ 2.4366e-02,  3.8166e-01, -2.2451e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 8.7838e-01, -5.9983e-02,  1.4472e-01],\n",
       "                         [ 2.1890e-01, -8.2260e-02,  3.5236e-02],\n",
       "                         [-1.6305e-01, -5.5475e-01, -3.4149e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1640e-01,  7.8737e-02, -1.7762e-01],\n",
       "                         [-1.4516e-02,  1.3225e-01,  2.5413e-02],\n",
       "                         [-2.8115e-02,  1.8151e-01, -3.3639e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.3240e-01, -3.6960e-01, -1.5010e-01],\n",
       "                         [ 6.2620e-02,  2.2893e-02,  1.1247e-01],\n",
       "                         [ 2.6827e-01,  3.7458e-01, -8.5182e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0860e-01,  1.1462e+00, -4.2346e-02],\n",
       "                         [-1.4127e-01,  3.0784e-01, -4.1399e-02],\n",
       "                         [-3.6094e-01, -1.9679e-01, -2.6113e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.3481e-01, -2.5167e-01,  3.8530e-01],\n",
       "                         [-1.3977e-01, -3.6216e-01,  1.1309e-03],\n",
       "                         [ 2.0413e-01, -4.5980e-01,  2.9574e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.7680e-02,  2.6627e-01, -2.8784e-01],\n",
       "                         [-3.3592e-01,  2.4736e-01, -1.2399e-01],\n",
       "                         [-2.8255e-01,  8.0267e-01, -4.0267e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.3659e-01, -5.6885e-01, -5.8263e-02],\n",
       "                         [ 2.3202e-01, -3.7275e-01,  4.3137e-02],\n",
       "                         [ 2.3751e-01, -1.1991e-01,  2.6967e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.7833e-01,  6.2141e-01,  4.1701e-01],\n",
       "                         [-9.2735e-02, -3.6468e-02, -3.5021e-01],\n",
       "                         [-5.1336e-02,  1.1924e-01, -1.3558e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.9185e-01,  2.7757e-01,  1.5429e-01],\n",
       "                         [ 2.0638e-01, -9.3221e-02, -4.2492e-02],\n",
       "                         [-3.6869e-01, -2.5070e-01, -3.6196e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1912e-01, -3.4506e-01, -2.0505e-01],\n",
       "                         [-3.5524e-02,  5.3625e-02,  3.3577e-01],\n",
       "                         [ 1.5814e-01, -1.6911e-02,  5.5144e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-7.1422e-01, -9.4341e-02,  4.3752e-02],\n",
       "                         [ 1.3863e+00, -7.7188e-02,  1.9691e-02],\n",
       "                         [-3.5302e-01, -1.1650e-01, -4.4031e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.5821e-01,  1.7370e-01,  3.0065e-01],\n",
       "                         [-4.7475e-01, -6.5231e-01, -4.0496e-01],\n",
       "                         [ 1.6438e-01,  4.0722e-01,  1.4705e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6765e-01, -3.5122e-01, -3.0718e-01],\n",
       "                         [-3.7997e-02, -1.8845e-01,  5.6407e-02],\n",
       "                         [ 2.3948e-01,  2.0316e-01,  6.8780e-01]]]], device='cuda:0')),\n",
       "              ('conv_block1.conv2.weight',\n",
       "               tensor([[[[ 3.7716e-02,  3.8377e-01, -2.6829e-02],\n",
       "                         [ 1.4405e-02, -2.7071e-02, -1.1790e-01],\n",
       "                         [ 3.1483e-02, -1.2675e-01,  1.0402e-01]],\n",
       "               \n",
       "                        [[-1.3191e-01,  5.1577e-02,  9.3906e-02],\n",
       "                         [-1.0973e-01,  1.2606e-01,  6.9330e-02],\n",
       "                         [-7.9789e-02,  1.4824e-01, -2.2891e-01]],\n",
       "               \n",
       "                        [[ 8.4112e-02, -6.5050e-02,  2.2053e-02],\n",
       "                         [-1.6003e-02,  3.6255e-02, -1.0961e-01],\n",
       "                         [ 2.1383e-03,  1.7355e-01, -2.0730e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.2900e-01, -9.4333e-02, -4.8292e-01],\n",
       "                         [ 1.5381e-01, -8.5188e-03,  2.9697e-02],\n",
       "                         [ 1.7547e-01,  5.9568e-02,  4.1180e-01]],\n",
       "               \n",
       "                        [[-6.4412e-02,  2.3372e-02, -8.3541e-02],\n",
       "                         [-5.3537e-02, -8.9693e-02, -1.3112e-02],\n",
       "                         [-5.3418e-02, -4.0995e-02,  1.0250e-01]],\n",
       "               \n",
       "                        [[-2.1671e-01,  2.8036e-02, -1.3197e-04],\n",
       "                         [-3.4290e-02,  5.9299e-02, -1.8906e-02],\n",
       "                         [-5.3243e-02, -4.2178e-02,  2.6321e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0785e+00, -2.0748e-01,  7.5568e-02],\n",
       "                         [ 2.0621e-01, -5.9543e-02,  6.3722e-02],\n",
       "                         [-6.5188e-01, -1.2228e-02,  1.1816e-01]],\n",
       "               \n",
       "                        [[-1.2173e-01,  1.9149e-01,  8.3929e-02],\n",
       "                         [ 8.3358e-02, -2.0013e-01, -1.1041e-02],\n",
       "                         [ 2.7151e-01, -3.6403e-01, -4.3889e-02]],\n",
       "               \n",
       "                        [[-1.7432e-01,  1.5744e-01, -2.0128e-01],\n",
       "                         [ 2.6894e-02, -1.1746e-01, -5.5749e-03],\n",
       "                         [ 2.9326e-01, -4.2377e-01,  5.7002e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.5385e-01, -8.2642e-01,  3.3079e-01],\n",
       "                         [-4.6052e-02, -1.7915e-01,  1.1808e-01],\n",
       "                         [-5.4963e-01,  1.0333e+00, -2.4473e-01]],\n",
       "               \n",
       "                        [[-6.9922e-02,  1.3253e-01,  8.7043e-02],\n",
       "                         [ 1.5732e-01,  1.6859e-01, -2.4649e-02],\n",
       "                         [ 4.5574e-02, -1.4071e-01, -1.5539e-01]],\n",
       "               \n",
       "                        [[ 1.2706e-01,  3.1828e-02,  1.1200e-01],\n",
       "                         [ 9.8312e-02,  3.1909e-02,  8.6010e-02],\n",
       "                         [ 1.4542e-02, -3.4562e-04,  8.4735e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.7297e-02, -1.1035e-01, -1.1087e-01],\n",
       "                         [-7.3131e-02, -9.5376e-02, -9.5487e-02],\n",
       "                         [-8.0729e-02, -9.2381e-04,  2.4190e-02]],\n",
       "               \n",
       "                        [[-1.7203e-01, -4.6300e-01,  2.5281e-01],\n",
       "                         [-1.5188e-01, -4.7515e-01, -3.0280e-02],\n",
       "                         [ 6.9937e-02, -1.2466e-01,  4.5305e-01]],\n",
       "               \n",
       "                        [[ 8.2297e-02,  1.0682e-01,  2.8612e-02],\n",
       "                         [ 1.3627e-01,  4.2858e-02, -3.2870e-02],\n",
       "                         [-3.5023e-02, -7.2602e-02, -2.1970e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.8166e-02,  1.6987e-01,  2.3324e-01],\n",
       "                         [ 2.0293e-01, -1.0903e-02, -1.6093e-01],\n",
       "                         [ 1.5683e-01, -1.1523e-01, -3.9176e-01]],\n",
       "               \n",
       "                        [[ 2.7918e-02, -5.2651e-02, -3.0204e-02],\n",
       "                         [-6.0518e-02, -1.3612e-01, -2.5142e-01],\n",
       "                         [ 8.2353e-02, -6.1556e-02,  5.9971e-02]],\n",
       "               \n",
       "                        [[-7.5691e-02, -5.9457e-03, -4.2270e-02],\n",
       "                         [-4.8160e-02, -3.5608e-02, -2.8247e-02],\n",
       "                         [-1.7834e-02, -7.6805e-02,  2.5366e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-4.9454e-02, -5.7105e-03, -8.8107e-02],\n",
       "                         [-3.6103e-02,  2.0379e-01,  3.4189e-01],\n",
       "                         [-4.2215e-02, -2.1860e-01, -2.4045e-01]],\n",
       "               \n",
       "                        [[-3.0638e-01, -1.8374e-01, -3.8692e-01],\n",
       "                         [ 4.3731e-01,  6.7990e-01,  3.9994e-01],\n",
       "                         [-3.8064e-01, -3.3509e-01, -6.1751e-01]],\n",
       "               \n",
       "                        [[-1.5306e-02, -1.0777e-02, -4.1142e-02],\n",
       "                         [-8.7511e-02, -1.0601e-01, -1.5231e-01],\n",
       "                         [-1.8568e-02,  3.6170e-02, -7.9173e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.1569e-01,  2.8898e-01,  3.5592e-01],\n",
       "                         [-1.0991e+00, -7.5708e-01, -8.5644e-01],\n",
       "                         [ 6.9730e-01,  1.2808e-01,  4.9305e-01]],\n",
       "               \n",
       "                        [[-6.9309e-02, -2.3946e-02, -6.7120e-02],\n",
       "                         [ 7.7438e-02,  7.9852e-02, -2.2187e-02],\n",
       "                         [-5.7858e-02, -7.3175e-03, -4.6205e-02]],\n",
       "               \n",
       "                        [[ 2.4485e-01,  3.5203e-01,  1.8942e-01],\n",
       "                         [-2.1788e-01, -1.4184e-01, -1.8707e-01],\n",
       "                         [-1.7722e-01, -9.8066e-02, -2.2995e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2625e-02,  1.0379e-02, -8.0609e-02],\n",
       "                         [ 5.3149e-02, -9.3726e-02, -1.0543e-01],\n",
       "                         [ 4.8197e-02, -5.4563e-02, -4.1949e-02]],\n",
       "               \n",
       "                        [[ 1.4315e-02,  7.2706e-02, -6.4910e-02],\n",
       "                         [-3.9319e-02, -1.9981e-01, -9.3217e-02],\n",
       "                         [ 5.4948e-02,  7.2174e-02,  5.5379e-02]],\n",
       "               \n",
       "                        [[-2.6129e-02, -1.1373e-02, -1.9768e-02],\n",
       "                         [ 2.1967e-02,  6.3522e-02,  1.2756e-02],\n",
       "                         [ 9.7849e-02,  8.7106e-02,  4.9843e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.5595e-02, -1.5106e-01,  2.8897e-01],\n",
       "                         [ 9.5800e-02, -1.1059e-01,  1.5325e-01],\n",
       "                         [ 2.9394e-02, -2.9501e-02,  1.2501e-01]],\n",
       "               \n",
       "                        [[ 1.2613e-01,  6.3016e-02,  2.7176e-02],\n",
       "                         [-5.3751e-02, -8.8469e-02, -2.4307e-02],\n",
       "                         [ 7.0750e-02,  2.2604e-02,  1.4919e-02]],\n",
       "               \n",
       "                        [[ 2.6332e-02, -2.9871e-02,  7.3902e-02],\n",
       "                         [ 5.8938e-02,  8.6006e-02,  3.4223e-02],\n",
       "                         [-2.8744e-02,  8.2594e-03,  1.7609e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.7435e-01,  4.7874e-02,  7.0055e-02],\n",
       "                         [ 8.6948e-02,  3.3030e-01,  1.3110e-01],\n",
       "                         [ 1.5556e-01,  3.2963e-01,  1.5869e-01]],\n",
       "               \n",
       "                        [[-6.3539e-01, -6.0424e-01, -2.4252e-01],\n",
       "                         [-1.3502e-01, -1.3486e-01, -3.6140e-01],\n",
       "                         [-5.2280e-01, -4.7667e-01, -5.4187e-01]],\n",
       "               \n",
       "                        [[ 1.0034e-01, -3.9097e-01, -6.2816e-01],\n",
       "                         [-5.8587e-02, -3.5102e-01, -4.4382e-01],\n",
       "                         [-1.9356e-02, -2.9316e-01, -2.4458e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.3339e-01, -3.5807e-01, -7.3283e-03],\n",
       "                         [ 9.7241e-03, -1.2542e-01,  4.9291e-02],\n",
       "                         [ 2.5228e-01, -1.4051e-01, -8.6471e-02]],\n",
       "               \n",
       "                        [[-6.5190e-02, -1.7026e-01, -9.0556e-02],\n",
       "                         [ 1.3915e-01, -3.3030e-02, -7.1347e-02],\n",
       "                         [-2.2762e-05, -1.7184e-01, -1.6950e-02]],\n",
       "               \n",
       "                        [[ 7.2244e-02,  7.6516e-02, -2.7654e-03],\n",
       "                         [ 1.0507e-01, -4.3255e-04,  5.2007e-02],\n",
       "                         [ 2.0332e-02,  1.0466e-01,  5.0690e-02]]]], device='cuda:0')),\n",
       "              ('conv_block1.bn1.weight',\n",
       "               tensor([1.0147, 1.8317, 0.8301, 1.2968, 0.5953, 0.7233, 0.7475, 1.2259, 0.7721,\n",
       "                       1.0568, 1.3650, 0.3360, 0.4459, 0.6781, 0.6541, 0.3440, 0.5908, 1.0499,\n",
       "                       0.6292, 0.5092, 0.6707, 2.1327, 1.5605, 0.8525, 0.6335, 0.9048, 0.8897,\n",
       "                       0.6496, 1.0510, 1.3799, 0.9359, 0.6482, 0.5818, 1.7507, 2.3637, 0.6982,\n",
       "                       0.9968, 0.4719, 0.5994, 0.5357, 0.7040, 2.0022, 0.6293, 0.2890, 0.5688,\n",
       "                       0.9239, 0.6793, 0.5159, 0.4398, 0.5231, 0.6452, 0.8483, 0.5375, 1.9732,\n",
       "                       0.8341, 0.7305, 1.1377, 1.0964, 0.8403, 0.4709, 0.7815, 1.3541, 0.9502,\n",
       "                       1.0875], device='cuda:0')),\n",
       "              ('conv_block1.bn1.bias',\n",
       "               tensor([ 0.6754,  0.1345,  0.0220,  1.3368, -0.6749,  0.0839, -1.3812, -1.3433,\n",
       "                       -0.7652,  0.2082, -1.0769,  0.1627,  0.0673,  0.0511,  0.1200,  0.1681,\n",
       "                        0.0150,  0.0098, -0.7188, -0.5221, -0.8065,  0.4152,  0.2131, -1.1045,\n",
       "                        0.0147, -1.0571,  0.0904, -0.7248, -0.9289, -0.0724,  0.0621, -0.8089,\n",
       "                        0.0928,  0.1172,  0.0503,  0.1471,  0.6545,  0.1610, -0.4684,  0.0174,\n",
       "                       -0.8001,  0.3992, -0.6326,  0.1002, -0.7923,  0.0503, -0.4399, -0.1764,\n",
       "                       -1.0168,  0.0272, -0.1202,  0.1499, -0.9979,  0.2602, -0.7370,  0.1048,\n",
       "                        0.8390, -0.2476,  0.0871,  0.0680,  0.1174,  1.5486, -1.0039, -1.6553],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn1.running_mean',\n",
       "               tensor([-0.0030, -0.0002, -0.0097,  0.0008, -0.0108,  0.0094, -0.0018, -0.0032,\n",
       "                       -0.0002, -0.0022,  0.0009, -0.0213,  0.0035, -0.0077,  0.0031, -0.0275,\n",
       "                       -0.0161, -0.0078, -0.0127, -0.0061,  0.0220,  0.0024,  0.0018,  0.0035,\n",
       "                       -0.0123, -0.0039,  0.0027,  0.0010,  0.0109,  0.0010,  0.0048, -0.0150,\n",
       "                        0.0156,  0.0009,  0.0008,  0.0050,  0.0055, -0.0204, -0.0695, -0.0294,\n",
       "                        0.0018, -0.0023, -0.0279, -0.0122, -0.0161, -0.0047, -0.0007,  0.0002,\n",
       "                       -0.0074,  0.0328,  0.0009,  0.0095, -0.0117, -0.0013,  0.0422,  0.0078,\n",
       "                       -0.0017,  0.0020, -0.0008,  0.0251,  0.0097,  0.0051,  0.0014,  0.0013],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn1.running_var',\n",
       "               tensor([0.1543, 0.0237, 0.0862, 0.0526, 0.0313, 0.1704, 0.0081, 0.1066, 0.0159,\n",
       "                       0.1204, 0.0105, 0.0897, 0.2165, 0.1375, 0.2466, 0.1312, 0.1832, 0.0805,\n",
       "                       0.0449, 0.0544, 0.0787, 0.0197, 0.1028, 0.0528, 0.1611, 0.0675, 0.0803,\n",
       "                       0.0510, 0.0249, 0.0835, 0.2510, 0.1207, 0.1927, 0.0362, 0.0125, 0.0803,\n",
       "                       0.1997, 0.1383, 0.6347, 0.1720, 0.0371, 0.0157, 0.1682, 0.0286, 0.0476,\n",
       "                       0.3584, 0.0377, 0.0152, 0.0391, 0.1976, 0.0495, 0.1186, 0.0258, 0.0243,\n",
       "                       0.3662, 0.0665, 0.0868, 0.0709, 0.0456, 0.1456, 0.0848, 0.0315, 0.0196,\n",
       "                       0.0608], device='cuda:0')),\n",
       "              ('conv_block1.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block1.bn2.weight',\n",
       "               tensor([1.4841, 1.2917, 1.0752, 0.9392, 1.3012, 0.5648, 0.7395, 1.2967, 0.3735,\n",
       "                       1.2988, 1.5531, 1.1796, 1.5098, 0.8108, 0.5671, 1.0800, 1.0263, 1.2715,\n",
       "                       1.3641, 1.3163, 1.5201, 0.6631, 1.1183, 1.1883, 1.2024, 0.8789, 1.3421,\n",
       "                       0.3771, 1.0490, 1.4551, 1.1245, 1.5359, 0.6782, 1.5352, 0.9282, 1.1248,\n",
       "                       1.3073, 0.9236, 1.2908, 1.3024, 0.4935, 1.0720, 0.8583, 1.5085, 1.4076,\n",
       "                       1.4440, 0.6413, 0.6526, 1.0588, 0.5574, 0.6595, 1.0363, 0.7635, 1.3950,\n",
       "                       1.3622, 1.1709, 0.8593, 0.5827, 0.9331, 1.3578, 1.2215, 0.9420, 0.5712,\n",
       "                       0.5443], device='cuda:0')),\n",
       "              ('conv_block1.bn2.bias',\n",
       "               tensor([-0.8234, -0.8081, -0.4838, -0.5944, -0.8566, -0.2404, -0.5236, -0.9160,\n",
       "                       -0.0529, -0.3748, -0.7467, -0.8183, -1.0355, -0.2404, -0.3608, -0.5537,\n",
       "                       -0.6094, -0.5815, -0.5941, -0.8944, -0.6258, -0.1631, -0.5619, -0.8486,\n",
       "                       -0.4367, -0.3251, -0.8718, -0.0486, -0.5740, -0.9323, -0.6806, -0.7423,\n",
       "                       -0.9645, -1.0283, -0.6479, -0.5786, -0.9397, -0.1561, -0.6581, -0.7995,\n",
       "                       -0.1054, -0.5006, -0.2690, -0.9833, -0.6177, -1.0039, -0.5419, -0.7335,\n",
       "                       -0.4527, -0.3228, -0.2103, -0.3911, -0.2588, -0.8303, -0.6102, -0.4021,\n",
       "                       -0.2842, -0.4564, -0.4216, -0.6266, -0.8774, -0.5110, -0.9052, -0.2076],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn2.running_mean',\n",
       "               tensor([ -7.9719,  -3.7649,  -7.8810,  -7.6889, -10.5837,  -4.0918,  -5.6065,\n",
       "                        -6.6311,   2.5603,  -7.6045,  -5.1107,  -4.1815,  -5.9455,  -3.2822,\n",
       "                        -0.6395,  -6.0870,  -6.7635,  -9.0023, -10.2618,  -7.7644,  -7.4981,\n",
       "                       -10.6928,  -5.4010,  -5.7467,  -4.5544, -14.6207,  -9.4568,   0.4363,\n",
       "                        -6.0029,  -4.7520, -10.0777, -19.3728,   7.3312,  -3.9146,  -4.1213,\n",
       "                        -4.5376, -10.3372, -11.7089,  -8.8880,  -4.1784,  -8.7844, -13.1679,\n",
       "                        -5.4957,  -5.8013,  -6.2711,  -5.9831,  -0.4317,   2.0526, -11.5915,\n",
       "                         0.2059, -10.6473,  -4.9260,  -1.5417,  -6.0039,  -5.3137,  -8.6857,\n",
       "                        -5.8778,   0.5054,  -4.8357, -11.6665,  -6.8932,  -5.2246,   3.5649,\n",
       "                       -13.4528], device='cuda:0')),\n",
       "              ('conv_block1.bn2.running_var',\n",
       "               tensor([104.4665,  52.4385,  91.5131,  81.1477, 122.0083, 126.2023,  42.4414,\n",
       "                        56.1025,  49.7538, 172.0671,  49.8468,  42.4662,  61.2207,  86.6769,\n",
       "                        18.0178,  74.0177, 108.8776, 173.0154, 178.2723,  87.5935,  94.7047,\n",
       "                       169.9219, 103.4164,  34.5758,  53.0822, 284.2262, 160.3335,  48.1477,\n",
       "                        71.1743,  55.5738, 114.1072, 412.1122,  25.4355,  31.5929,  33.4811,\n",
       "                        55.7246, 103.4648, 273.7428, 177.9740,  32.0147,  52.4685, 176.6447,\n",
       "                        43.8073,  53.1339,  80.3319,  43.6741,  16.8771,  37.1667, 248.7390,\n",
       "                        23.0678, 106.6639,  45.7877,  36.2760,  64.4575, 116.5747, 174.5919,\n",
       "                       161.6967,  24.6345,  87.6809, 261.5728,  88.1909,  33.4879,  24.3092,\n",
       "                       194.4015], device='cuda:0')),\n",
       "              ('conv_block1.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block2.conv1.weight',\n",
       "               tensor([[[[-6.6612e-02, -5.9600e-02, -3.3646e-02],\n",
       "                         [-9.0082e-03, -3.4218e-02, -1.2638e-01],\n",
       "                         [-1.5268e-01, -5.2480e-02, -6.7372e-02]],\n",
       "               \n",
       "                        [[ 1.1773e-01,  1.3273e-01,  1.4331e-01],\n",
       "                         [ 1.5485e-02, -5.2641e-02,  6.5574e-02],\n",
       "                         [ 3.9865e-02,  6.6218e-02,  1.6867e-01]],\n",
       "               \n",
       "                        [[ 9.3612e-03, -3.2874e-03, -5.0931e-03],\n",
       "                         [ 1.0213e-02,  2.7881e-02,  5.9696e-02],\n",
       "                         [ 2.5336e-03,  5.3899e-02,  1.0334e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.3382e-02,  6.7181e-02,  6.3629e-02],\n",
       "                         [-8.2463e-03,  3.0971e-02,  3.6543e-02],\n",
       "                         [-3.2838e-02, -5.4525e-02, -1.0010e-01]],\n",
       "               \n",
       "                        [[ 5.8703e-03, -5.4488e-03, -7.4210e-03],\n",
       "                         [-8.8855e-03,  9.4491e-03, -2.4393e-02],\n",
       "                         [ 4.0046e-02,  2.7267e-02, -2.4605e-02]],\n",
       "               \n",
       "                        [[ 3.4274e-03, -1.7679e-02, -1.0506e-02],\n",
       "                         [-6.6787e-02, -2.9965e-02, -3.4468e-02],\n",
       "                         [-4.4432e-02, -1.3806e-02, -4.1295e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.9368e-02, -4.6169e-02, -3.1849e-02],\n",
       "                         [ 1.1523e-01,  1.7957e-01,  4.6607e-02],\n",
       "                         [ 5.8586e-03,  1.2307e-01,  1.4036e-02]],\n",
       "               \n",
       "                        [[-1.8446e-01, -2.0808e-01, -7.5956e-02],\n",
       "                         [-2.9685e-01, -2.9554e-01,  5.7040e-02],\n",
       "                         [-2.7504e-01,  6.5192e-02,  2.9643e-02]],\n",
       "               \n",
       "                        [[ 3.1143e-02,  5.7940e-02,  5.3295e-02],\n",
       "                         [-1.4687e-01, -2.6303e-01,  4.0375e-02],\n",
       "                         [ 8.0275e-02, -1.9773e-01,  7.4133e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.7884e-02, -6.6429e-02, -6.8187e-03],\n",
       "                         [-8.8455e-02, -2.1068e-01, -1.0393e-01],\n",
       "                         [ 4.0991e-02, -1.4381e-01, -1.1891e-01]],\n",
       "               \n",
       "                        [[ 3.8864e-02, -7.3408e-02, -1.0042e-01],\n",
       "                         [ 6.2543e-02, -1.5229e-02,  3.8400e-02],\n",
       "                         [-4.9299e-02, -1.4120e-01, -1.5871e-01]],\n",
       "               \n",
       "                        [[ 1.2304e-01,  1.6561e-01,  1.1603e-01],\n",
       "                         [-3.1976e-03,  1.5427e-01,  1.0683e-01],\n",
       "                         [ 1.0294e-01,  1.0579e-01,  1.8109e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.3461e-01,  3.3709e-01, -1.2679e-01],\n",
       "                         [-1.1710e-01, -1.9431e-01, -2.6899e-01],\n",
       "                         [ 1.2496e-01, -2.3303e-01, -3.0178e-01]],\n",
       "               \n",
       "                        [[-7.5645e-01, -1.8989e-02, -1.4834e-01],\n",
       "                         [-1.5400e+00, -1.4846e+00, -2.8898e-01],\n",
       "                         [-1.9606e+00, -1.8870e+00, -6.1143e-01]],\n",
       "               \n",
       "                        [[ 7.4252e-02, -3.6760e-02,  2.5229e-01],\n",
       "                         [-5.4651e-03, -4.8606e-01,  6.3125e-02],\n",
       "                         [ 1.1650e-01, -6.2473e-01,  9.7307e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.3681e-02,  1.0975e-01, -1.4098e-01],\n",
       "                         [-1.3643e-02, -1.8806e-02, -1.1949e-01],\n",
       "                         [-1.5424e-01,  2.1139e-02, -1.2501e-01]],\n",
       "               \n",
       "                        [[-2.0506e-01, -3.0328e-01, -7.0644e-03],\n",
       "                         [ 6.5120e-02, -1.5298e-02,  8.4776e-02],\n",
       "                         [ 9.8368e-02,  2.2104e-01,  4.7331e-02]],\n",
       "               \n",
       "                        [[ 1.0543e-02, -3.8799e-02,  1.2879e-01],\n",
       "                         [-1.4161e-03, -1.6089e-01, -1.1688e-01],\n",
       "                         [ 1.8923e-01,  2.9672e-02, -8.9577e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 2.5869e-01,  2.4997e-01,  1.0919e-01],\n",
       "                         [ 8.0202e-02, -7.0330e-02, -1.1587e-01],\n",
       "                         [-1.7754e-01, -9.0353e-02, -1.1497e-02]],\n",
       "               \n",
       "                        [[ 3.2115e-01,  2.9448e-01, -5.0417e-02],\n",
       "                         [ 1.6544e-01,  5.9469e-02,  1.6220e-02],\n",
       "                         [-3.3938e-02, -2.0441e-02,  2.2820e-01]],\n",
       "               \n",
       "                        [[-2.6324e-01, -2.1927e-01,  1.9276e-02],\n",
       "                         [-1.1829e-01, -9.9668e-02, -3.7246e-02],\n",
       "                         [-1.5414e-01, -3.0073e-01, -3.8076e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.8569e-01, -8.8609e-02, -2.7967e-01],\n",
       "                         [-1.7912e-01, -1.2283e-01, -1.4729e-01],\n",
       "                         [-1.1130e-01, -1.5198e-01, -4.9355e-02]],\n",
       "               \n",
       "                        [[-1.5297e-01, -6.4467e-02, -1.4488e-02],\n",
       "                         [ 8.3452e-02,  1.1420e-01,  1.4201e-01],\n",
       "                         [ 6.5947e-02,  7.5174e-02,  1.4104e-02]],\n",
       "               \n",
       "                        [[-3.9835e-01, -4.4832e-01,  4.2174e-02],\n",
       "                         [-4.3757e-02,  3.5249e-03,  1.9157e-01],\n",
       "                         [ 5.1002e-01,  2.7074e-01,  2.1804e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.0083e-01, -2.0754e-01, -1.2930e-01],\n",
       "                         [-4.3015e-02,  7.0285e-02,  3.9884e-02],\n",
       "                         [ 4.1164e-03, -1.0237e-02, -2.3977e-01]],\n",
       "               \n",
       "                        [[-2.5900e-01, -4.4998e-01,  1.5604e-01],\n",
       "                         [-1.7697e-01, -4.5872e-01,  2.1617e-01],\n",
       "                         [ 3.7660e-02, -7.4408e-01,  6.8443e-02]],\n",
       "               \n",
       "                        [[-1.1396e-01, -5.3961e-02, -3.6279e-01],\n",
       "                         [ 1.1854e-01, -1.2681e-01, -2.1725e-01],\n",
       "                         [ 2.6696e-01, -3.6346e-01, -9.5176e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.7260e-04, -6.8171e-02,  8.3130e-02],\n",
       "                         [-6.1544e-02, -1.0541e-01,  1.3370e-01],\n",
       "                         [-1.3495e-02, -3.3459e-01, -3.7672e-01]],\n",
       "               \n",
       "                        [[ 4.4782e-02, -4.8111e-02, -3.0118e-01],\n",
       "                         [ 7.5534e-02,  1.4195e-02, -9.2084e-02],\n",
       "                         [ 5.9530e-02,  2.4830e-01, -1.9449e-02]],\n",
       "               \n",
       "                        [[-5.6514e-02, -4.7786e-01, -5.4551e-01],\n",
       "                         [ 6.7129e-02, -1.0447e-01, -3.5393e-01],\n",
       "                         [ 2.0524e-01,  1.4802e-01, -1.2159e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1755e-01,  1.8948e-01, -8.5609e-02],\n",
       "                         [ 1.8041e-03,  9.2940e-02,  4.3612e-03],\n",
       "                         [-2.8400e-02,  8.6866e-02,  5.8296e-02]],\n",
       "               \n",
       "                        [[ 1.5267e-01,  9.4688e-02,  1.0845e-01],\n",
       "                         [ 1.2109e-02,  1.7323e-02,  7.2662e-02],\n",
       "                         [ 1.5045e-01,  6.3335e-02,  1.3530e-01]],\n",
       "               \n",
       "                        [[-1.1404e-02, -6.6846e-05,  3.2670e-02],\n",
       "                         [ 1.3148e-02, -9.1374e-03,  7.4029e-02],\n",
       "                         [ 7.1019e-02, -1.2960e-02,  2.3726e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.7098e-02,  6.7599e-02,  1.4238e-02],\n",
       "                         [ 4.8238e-02,  1.3659e-02, -1.2117e-01],\n",
       "                         [ 1.4043e-02, -4.1660e-02, -1.5624e-01]],\n",
       "               \n",
       "                        [[ 7.8119e-02,  5.5463e-02, -4.3440e-02],\n",
       "                         [ 4.9839e-02,  1.5844e-02,  6.5254e-03],\n",
       "                         [-1.8330e-03,  3.8192e-02, -6.3780e-02]],\n",
       "               \n",
       "                        [[ 1.2015e-03, -5.0034e-02, -4.7408e-03],\n",
       "                         [-9.7093e-02, -1.0198e-01, -1.2352e-01],\n",
       "                         [-4.9896e-02, -4.3457e-02, -1.8967e-02]]]], device='cuda:0')),\n",
       "              ('conv_block2.conv2.weight',\n",
       "               tensor([[[[-1.2165e-01, -3.4758e-02, -3.1801e-02],\n",
       "                         [-2.2202e-01, -4.2053e-02, -8.9334e-03],\n",
       "                         [-2.1968e-01,  1.4105e-02, -7.2417e-02]],\n",
       "               \n",
       "                        [[-1.8230e-02,  4.9553e-02,  2.1746e-03],\n",
       "                         [-5.1542e-03,  1.5157e-01, -5.8213e-02],\n",
       "                         [-6.2584e-02,  8.8796e-02, -9.7473e-02]],\n",
       "               \n",
       "                        [[-7.6419e-02,  2.6815e-01, -4.1798e-01],\n",
       "                         [ 1.1087e-01,  1.8604e-01, -4.2441e-01],\n",
       "                         [ 6.6051e-01,  6.7546e-02, -2.2249e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.7164e-01,  6.9644e-02, -1.1054e-01],\n",
       "                         [-1.9934e-01,  1.2364e-01, -1.8217e-01],\n",
       "                         [ 1.9870e-01, -2.1927e-01, -4.7338e-01]],\n",
       "               \n",
       "                        [[ 6.0575e-01,  1.9189e-01, -3.9298e-01],\n",
       "                         [ 3.8937e-01, -5.2282e-01, -3.3441e-01],\n",
       "                         [ 5.0963e-02, -8.0754e-01,  2.1472e-01]],\n",
       "               \n",
       "                        [[-5.4394e-02, -4.4702e-02, -4.1633e-02],\n",
       "                         [-7.9942e-02,  2.0425e-02, -1.1764e-01],\n",
       "                         [-6.7712e-02, -4.8692e-02, -8.1700e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.8303e-02, -1.1456e-01, -6.3068e-02],\n",
       "                         [-3.1676e-02, -7.5469e-02, -8.8714e-02],\n",
       "                         [ 1.6190e-02, -1.3691e-01, -1.2982e-02]],\n",
       "               \n",
       "                        [[ 1.3800e-02,  4.3082e-02,  1.2921e-01],\n",
       "                         [-6.6615e-02,  3.9583e-02,  5.1345e-02],\n",
       "                         [-9.0941e-02, -3.3695e-02, -1.6292e-01]],\n",
       "               \n",
       "                        [[-2.9417e-01, -2.7346e-01, -2.8625e-01],\n",
       "                         [-4.8340e-01, -3.0853e-01, -2.9241e-01],\n",
       "                         [-4.6969e-01, -4.4771e-01, -2.2531e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.3768e-01, -1.3367e-01,  6.3965e-02],\n",
       "                         [-1.8034e-01, -1.0056e-01,  4.9152e-02],\n",
       "                         [ 6.9681e-02,  4.4886e-02, -1.5970e-02]],\n",
       "               \n",
       "                        [[ 6.3910e-02,  5.0630e-02, -1.5643e-01],\n",
       "                         [-1.2564e-02,  8.7770e-02, -2.5424e-01],\n",
       "                         [-1.5242e-01,  3.2650e-02, -3.4847e-01]],\n",
       "               \n",
       "                        [[-1.0796e-02, -6.4269e-02, -5.0478e-03],\n",
       "                         [-9.9691e-02, -6.7211e-02, -5.9294e-02],\n",
       "                         [-5.5320e-02, -4.8565e-02, -8.5714e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.3092e-01,  9.5969e-02,  1.5641e-01],\n",
       "                         [ 1.9266e-01,  1.9806e-01,  3.0072e-01],\n",
       "                         [ 1.0866e-01,  6.0311e-02,  1.0739e-01]],\n",
       "               \n",
       "                        [[-4.7209e-02, -7.3073e-02, -1.1407e-01],\n",
       "                         [ 3.4073e-02, -6.4070e-02,  7.7815e-02],\n",
       "                         [ 2.4749e-02, -6.8775e-02,  7.9206e-02]],\n",
       "               \n",
       "                        [[-2.8662e-02, -6.8921e-03, -1.5398e-01],\n",
       "                         [ 1.1468e-01,  1.0031e-01, -2.7129e-02],\n",
       "                         [ 1.9977e-01,  1.8576e-01,  5.5038e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.7789e-01, -1.6586e-01, -5.8020e-02],\n",
       "                         [-1.0732e-01, -1.4870e-01, -1.8783e-01],\n",
       "                         [ 1.1411e-01,  1.8217e-03,  6.5047e-03]],\n",
       "               \n",
       "                        [[ 5.4595e-02,  7.4122e-02, -2.3456e-01],\n",
       "                         [-1.3140e-01, -1.0850e-02, -2.9233e-01],\n",
       "                         [-3.5969e-02,  2.3044e-01, -1.8797e-01]],\n",
       "               \n",
       "                        [[ 1.4259e-01,  7.6576e-02,  9.8668e-02],\n",
       "                         [ 2.4371e-01,  1.9889e-01,  1.1936e-01],\n",
       "                         [ 1.4846e-01,  1.9596e-01,  1.3475e-01]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-2.1735e-02, -1.3602e-03, -6.8345e-03],\n",
       "                         [-3.9126e-02, -2.0053e-02, -6.9146e-02],\n",
       "                         [-4.7897e-02, -3.2232e-02, -3.0127e-02]],\n",
       "               \n",
       "                        [[-1.1223e-01, -2.3186e-03,  1.0385e-01],\n",
       "                         [-1.8395e-02, -9.9355e-03,  2.3772e-02],\n",
       "                         [ 9.9456e-03,  3.8746e-02,  3.2703e-02]],\n",
       "               \n",
       "                        [[ 5.2624e-01,  3.0441e-01, -2.7560e-02],\n",
       "                         [ 3.8298e-01,  3.3152e-01,  3.2366e-01],\n",
       "                         [-1.7045e-01, -1.2247e-01, -6.2685e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.2901e-01,  1.6458e-01, -5.7356e-02],\n",
       "                         [ 1.9583e-01,  1.6779e-01,  2.3444e-02],\n",
       "                         [-1.3751e-01, -1.7650e-01, -3.1298e-01]],\n",
       "               \n",
       "                        [[ 1.4263e-01, -1.8176e-01, -1.3101e-01],\n",
       "                         [-3.3003e-01, -1.7546e-01, -1.4912e-01],\n",
       "                         [-4.1653e-01, -2.7350e-01, -2.3506e-01]],\n",
       "               \n",
       "                        [[-3.4305e-03, -1.1950e-02, -2.6996e-02],\n",
       "                         [-3.5794e-02, -1.4185e-02, -2.9764e-02],\n",
       "                         [ 2.7390e-02, -6.2543e-02, -3.8219e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0635e-02, -2.6808e-03, -9.0777e-02],\n",
       "                         [-3.8485e-02,  3.2833e-02, -1.6659e-02],\n",
       "                         [-1.8095e-02,  8.3388e-03,  1.3049e-02]],\n",
       "               \n",
       "                        [[-4.0688e-02, -2.1189e-01, -1.4189e-01],\n",
       "                         [-4.1159e-02, -1.1777e-01, -3.9503e-02],\n",
       "                         [ 4.0488e-02,  6.5073e-02, -1.2451e-01]],\n",
       "               \n",
       "                        [[-1.9807e-01, -1.4593e-01, -3.1981e-01],\n",
       "                         [-2.6858e-01, -9.8892e-02, -2.4597e-01],\n",
       "                         [-3.9285e-01, -2.7522e-02, -2.4347e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2200e-01, -2.3795e-01, -4.5053e-01],\n",
       "                         [-4.3874e-01, -2.1310e-02, -6.6127e-02],\n",
       "                         [ 1.4589e-01,  1.8029e-01, -2.1881e-01]],\n",
       "               \n",
       "                        [[ 1.2308e-02,  3.8618e-01,  4.7723e-02],\n",
       "                         [ 1.1494e-02,  2.0954e-01,  1.6211e-02],\n",
       "                         [-1.2337e-01, -1.7129e-01, -2.3508e-01]],\n",
       "               \n",
       "                        [[-2.2188e-03, -2.6811e-02, -4.6226e-03],\n",
       "                         [-7.3100e-02, -4.6282e-02, -5.9734e-02],\n",
       "                         [ 1.5354e-02, -7.1094e-02, -4.0344e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9619e-02, -1.3767e-02, -6.4492e-02],\n",
       "                         [ 7.0084e-02,  2.1040e-02, -1.6778e-02],\n",
       "                         [ 2.5448e-02, -2.0526e-02, -1.5553e-02]],\n",
       "               \n",
       "                        [[ 6.7199e-02,  5.4012e-02, -5.1086e-02],\n",
       "                         [-1.6294e-02,  2.6211e-03, -5.9751e-02],\n",
       "                         [ 1.1546e-01,  7.7307e-02, -3.1984e-02]],\n",
       "               \n",
       "                        [[-1.3045e-01,  4.2094e-01,  3.6570e-01],\n",
       "                         [ 5.6246e-02,  7.0460e-01,  5.7300e-01],\n",
       "                         [-8.8699e-02,  4.3950e-01,  6.2013e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.6621e-01, -1.4640e-01,  1.2067e-01],\n",
       "                         [ 3.1655e-02,  3.4726e-01,  4.2844e-01],\n",
       "                         [-4.9609e-02,  3.7723e-01,  2.6148e-01]],\n",
       "               \n",
       "                        [[ 1.0608e-02,  5.0214e-01,  1.0745e-01],\n",
       "                         [-1.9865e-01,  2.3390e-01,  7.7547e-03],\n",
       "                         [-1.2779e-01,  2.3408e-01, -2.2846e-02]],\n",
       "               \n",
       "                        [[ 2.3396e-02, -2.1005e-02, -6.9662e-03],\n",
       "                         [-2.6809e-02, -3.2222e-02, -9.1260e-03],\n",
       "                         [-5.6296e-04, -2.4745e-03, -5.7847e-02]]]], device='cuda:0')),\n",
       "              ('conv_block2.bn1.weight',\n",
       "               tensor([0.7172, 1.1233, 1.1306, 1.0778, 1.2900, 1.3358, 1.0254, 0.9637, 1.0924,\n",
       "                       1.9560, 1.1531, 1.0244, 0.9168, 0.9906, 1.3675, 1.0856, 1.0364, 1.4014,\n",
       "                       0.6489, 1.1420, 1.0177, 1.0153, 0.4829, 1.3125, 1.0182, 1.2070, 0.8518,\n",
       "                       1.1346, 1.0194, 1.0389, 0.6530, 1.6765, 1.3377, 1.0420, 1.1963, 1.4562,\n",
       "                       1.2257, 0.8529, 1.2123, 1.0886, 1.2572, 0.9541, 1.2606, 1.1860, 0.7690,\n",
       "                       1.0909, 0.8198, 1.6815, 1.5043, 0.9400, 0.9319, 1.2516, 1.2181, 0.7739,\n",
       "                       1.5223, 1.2250, 0.5551, 0.8316, 1.1723, 0.6180, 1.2489, 1.3083, 1.2504,\n",
       "                       1.1648, 0.9319, 0.8519, 1.1785, 1.1199, 1.0065, 1.0437, 0.8517, 0.9715,\n",
       "                       1.1117, 0.8660, 1.2616, 0.6270, 1.4886, 0.8508, 1.6452, 0.9375, 0.9837,\n",
       "                       0.9614, 0.9463, 0.9444, 1.3023, 0.9668, 0.9989, 0.8529, 1.2239, 1.2258,\n",
       "                       0.8677, 1.0991, 1.2224, 1.3239, 1.0160, 0.8423, 0.7899, 1.0761, 0.9532,\n",
       "                       1.1130, 1.0155, 1.4508, 0.9422, 0.4902, 1.3575, 1.2227, 0.6806, 1.0196,\n",
       "                       1.1379, 1.3348, 0.8498, 1.1620, 1.0342, 1.0171, 0.7932, 1.2207, 1.0058,\n",
       "                       1.1235, 0.9424, 0.7260, 1.1394, 1.4980, 0.9080, 1.0551, 0.7560, 1.6658,\n",
       "                       1.0238, 0.7015], device='cuda:0')),\n",
       "              ('conv_block2.bn1.bias',\n",
       "               tensor([-1.3539, -0.9176, -0.3358, -0.6793, -0.2511, -0.5147,  0.1780,  0.0788,\n",
       "                       -0.9521, -3.2531, -0.3384, -0.2269, -0.1342, -0.4940, -0.5501, -0.7990,\n",
       "                       -0.2480, -0.7214, -1.2223, -0.8328,  0.1423, -0.7698, -0.0695, -0.9567,\n",
       "                       -0.6748, -0.8609, -1.0909, -0.6635, -0.5919, -0.3254, -0.5232, -1.0573,\n",
       "                       -0.5956,  0.2500, -1.2381, -0.9972, -1.1012, -0.7308, -0.9487, -0.4341,\n",
       "                       -0.7429, -0.7259, -0.9874, -0.2327, -1.4147, -0.8253, -0.5465, -2.2435,\n",
       "                       -0.7619, -0.4607, -1.0012, -0.7680,  0.0576, -0.1711, -0.9545, -0.4789,\n",
       "                       -0.2734, -0.1463, -0.9236, -0.4300, -1.3015, -0.8899, -1.5931, -0.5611,\n",
       "                       -0.2354,  0.1681, -0.6901, -0.1235, -0.6812, -0.5706, -0.0539, -0.2259,\n",
       "                       -0.7704, -0.1603, -0.9158, -1.2511, -1.1759, -0.4254, -1.5772,  0.0548,\n",
       "                       -0.3023, -0.2560, -0.9098,  0.1258, -0.8445,  0.2932, -0.5789, -1.4806,\n",
       "                       -0.7398, -0.6939, -0.2297, -0.3205, -1.0558, -0.5916, -0.7359, -0.6250,\n",
       "                        0.0800, -0.9542, -0.1950, -0.3094, -0.5269, -0.8853, -0.4104, -0.0767,\n",
       "                       -0.9139, -0.6508, -0.2267, -0.5620, -0.0352, -0.6384,  0.3548, -0.7505,\n",
       "                       -0.5176, -0.8099, -0.5966, -0.7521, -1.1145, -0.2763, -0.7157, -0.2710,\n",
       "                       -0.5462, -0.9088, -0.2783, -0.7310,  0.0219, -0.8976, -0.0224, -1.1168],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.running_mean',\n",
       "               tensor([-2.4131, -0.8904, -4.9010, -1.7769, -2.2053, -2.7407, -1.1921, -3.0030,\n",
       "                       -0.4156, -0.3795, -2.3029, -1.2883, -0.4116, -0.1081, -3.7642, -1.0190,\n",
       "                       -2.0777, -3.3611, -0.0486, -3.1341, -2.4077, -1.1157, -0.8847, -2.7711,\n",
       "                       -1.7424, -3.3486,  2.1937, -2.5235, -1.8268, -2.8369,  0.6379, -2.1238,\n",
       "                       -3.7224, -0.4414, -1.3879, -3.3340, -3.3817,  0.3282, -2.7800, -1.5432,\n",
       "                       -2.6469, -1.0276, -3.0478, -2.0544, -3.2316, -2.2868, -1.4719, -1.4437,\n",
       "                       -1.1511, -3.5797, -2.7565, -2.2685, -1.4782, -2.8771, -2.0487, -1.7757,\n",
       "                       -0.8824, -1.3743, -1.8331, -1.9949, -0.8457, -2.1034, -0.5533, -1.3504,\n",
       "                       -1.4081, -2.1844, -1.0006, -2.2973, -2.6539, -2.2386, -1.4796, -1.1708,\n",
       "                       -2.5862, -0.4609, -3.5191, -1.9588, -0.6882, -1.3655, -1.3016, -1.3824,\n",
       "                       -1.6750, -0.4051, -1.0312, -2.7010, -2.5754, -1.1560, -0.3630,  0.7148,\n",
       "                       -1.6863, -2.2299, -0.1336, -2.4699, -2.1001, -1.5359, -1.5326,  0.7923,\n",
       "                       -1.0251,  0.2001, -2.3583, -1.4120, -0.1170, -1.8230, -2.2582,  1.4584,\n",
       "                       -3.3188, -0.8856,  0.3503, -1.2154, -2.1023, -1.5781, -3.0069, -1.1046,\n",
       "                       -1.3731, -1.0934,  1.5682, -2.0638, -0.9050, -3.8840, -1.0200, -1.9753,\n",
       "                       -4.2705, -4.1954, -3.8186, -2.5487, -0.3516, -1.8321, -2.5454, -1.9434],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.running_var',\n",
       "               tensor([ 0.9786,  1.5125,  9.5856,  1.8743,  8.2790,  4.4735,  7.8640, 10.5432,\n",
       "                        1.2490,  2.9350,  6.8486,  6.3948,  3.2540,  1.1393,  9.0964,  1.5334,\n",
       "                        8.2834,  4.2068,  0.9122,  3.0292,  8.1301,  1.0579,  6.6738,  4.5364,\n",
       "                        2.0355,  4.1773,  1.8325,  4.3999,  4.2481,  6.3098,  2.5068,  9.3283,\n",
       "                        6.4492,  3.0384,  1.8923,  5.8473,  3.0599,  0.8678,  2.7243,  5.1903,\n",
       "                        4.7960,  4.2547,  2.5376,  2.5142,  2.3388,  3.6344,  1.5592,  2.2303,\n",
       "                        4.9886,  6.1556,  2.0378,  2.1848,  3.8695,  7.8191,  6.6059,  3.8878,\n",
       "                        3.6203,  4.7165,  1.8168,  2.2955,  1.4972,  2.4463,  2.0767,  7.1414,\n",
       "                        3.5790,  7.7162,  1.4699, 15.7467,  2.9050,  5.4722,  4.5844,  3.5854,\n",
       "                        3.4569,  4.2376,  4.6873,  0.7987,  1.1326,  3.8485,  1.5644,  3.9909,\n",
       "                        5.1989,  2.9923,  1.4127,  3.8168,  3.5553,  3.1785,  3.8540,  0.9011,\n",
       "                        1.4663,  3.4107,  2.3478,  3.1561,  2.1672,  5.4370,  3.1052,  1.8797,\n",
       "                        5.6606,  1.1486,  5.1894,  4.4640,  2.9727,  1.8161,  7.0791,  5.8385,\n",
       "                        4.8354,  2.8537,  2.3023,  5.0950,  3.7036,  3.9769, 11.8580,  1.1699,\n",
       "                        6.9196,  2.8060,  3.8003,  5.5325,  1.3808,  5.8572,  1.1803,  5.3702,\n",
       "                        8.7443,  8.8479,  5.3295,  4.1233,  6.9519,  8.7936,  5.9418,  1.0971],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block2.bn2.weight',\n",
       "               tensor([1.3141, 0.9743, 0.9400, 0.9704, 1.1382, 1.0515, 0.7056, 0.8917, 1.2728,\n",
       "                       0.8739, 0.8869, 1.0483, 0.6003, 0.7180, 0.9838, 0.9419, 1.2941, 1.2745,\n",
       "                       1.1587, 1.3949, 0.7573, 0.7964, 1.2028, 1.1286, 0.5101, 1.5309, 1.7043,\n",
       "                       1.0253, 1.2643, 1.5136, 0.9687, 1.1254, 0.9008, 1.0613, 1.2545, 1.9371,\n",
       "                       1.0074, 1.1867, 0.6400, 0.8690, 1.2913, 1.1891, 1.5210, 1.2264, 1.1337,\n",
       "                       1.5098, 0.7860, 1.1929, 0.9391, 1.0299, 0.8509, 1.0739, 1.1180, 1.0300,\n",
       "                       1.1998, 0.9821, 0.9817, 1.3478, 0.9603, 0.9633, 0.6857, 0.6026, 0.7475,\n",
       "                       0.7358, 0.7933, 0.9335, 0.9808, 1.0397, 0.8151, 0.7391, 0.6320, 1.2441,\n",
       "                       1.0984, 1.2876, 0.8579, 1.6905, 0.7509, 0.7957, 0.7060, 1.0145, 0.9281,\n",
       "                       0.8951, 1.7811, 1.0739, 1.3654, 1.0729, 0.7540, 0.7065, 1.2138, 1.0745,\n",
       "                       0.9565, 0.9216, 1.0931, 0.6989, 1.1158, 0.9414, 0.7919, 1.2018, 1.0087,\n",
       "                       1.4503, 0.6382, 0.8017, 0.9373, 1.1921, 1.0555, 1.2000, 1.3124, 1.1891,\n",
       "                       0.8393, 1.0704, 0.7054, 1.2592, 0.7358, 0.9641, 1.1372, 0.8094, 1.0117,\n",
       "                       1.2514, 1.1951, 1.0004, 0.8262, 0.7046, 0.8043, 1.1598, 0.6865, 1.4700,\n",
       "                       0.8981, 0.9085], device='cuda:0')),\n",
       "              ('conv_block2.bn2.bias',\n",
       "               tensor([-1.3503, -0.4413, -0.6789, -0.9455, -1.0849, -0.4448, -0.5752, -0.7186,\n",
       "                       -0.8108, -0.2051, -0.4654, -0.7822, -0.4704, -0.3479, -0.7247, -0.6463,\n",
       "                       -1.1507, -0.8867, -0.7556, -0.8274, -0.4405, -0.4568, -0.9801, -0.6102,\n",
       "                       -1.2241, -1.2244, -1.5618, -0.8782, -0.5003, -0.9520, -0.5820, -1.1252,\n",
       "                       -0.9082, -0.9316, -1.0885, -1.7258, -0.9305, -0.9675, -0.2319, -0.6314,\n",
       "                       -0.8341, -1.1461, -0.9772, -0.9146, -0.7383, -1.1380, -0.6114, -0.9168,\n",
       "                       -1.1098, -0.8108, -0.2102, -0.8518, -0.5361, -0.4911, -0.9719, -0.7816,\n",
       "                       -0.7263, -1.1259, -0.3177, -0.4689, -0.2683, -0.5677, -0.5023, -0.3059,\n",
       "                       -0.5004, -0.7979, -0.7226, -0.8363, -0.3814, -0.5096, -2.4209, -1.0990,\n",
       "                       -0.7452, -1.0950, -0.4069, -1.6483, -0.4548, -0.4833, -0.4344, -0.7627,\n",
       "                       -0.5733, -0.4171, -1.7487, -1.0344, -0.9407, -0.8883, -0.0773, -0.2880,\n",
       "                       -1.0581, -0.7470, -0.6575, -0.5272, -0.7539, -0.3000, -0.6706, -0.6163,\n",
       "                       -0.3594, -0.7435, -2.1373, -1.4771, -0.2047, -0.3021, -0.4441, -0.8505,\n",
       "                       -0.7633, -1.0400, -0.6749, -0.8543, -0.2337, -0.7890, -0.1617, -0.7715,\n",
       "                       -0.4618, -0.8388, -0.8737, -0.8112, -0.6466, -0.8895, -0.7215, -0.9477,\n",
       "                       -0.6900, -0.5412, -0.4516, -1.3314, -0.2638, -1.1401, -0.6788, -0.7952],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn2.running_mean',\n",
       "               tensor([ -7.3961,  -4.5891,  -5.8213,  -1.0133,  -2.2580,  -1.8642,  -3.5694,\n",
       "                        -6.0996,  -5.6499,  -2.5031,  -5.9163,  -2.2057,  -0.3819,  -1.8356,\n",
       "                        -4.1744,  -2.8422, -10.6328,  -5.2309,  -5.7686,  -2.5634,  -3.7643,\n",
       "                        -3.3726,  -4.8321,  -2.0769,   0.1582,  -3.8061,  -2.4051,  -3.5277,\n",
       "                        -3.9691,  -9.3103,  -8.0612,  -8.9360,  -1.8765,  -2.2820,  -5.7356,\n",
       "                        -4.4611,  -4.0259,  -2.2542,  -3.3550,  -6.5327,  -2.8121,  -2.8097,\n",
       "                        -6.0242,  -4.6169,  -6.0128,  -5.0973,  -3.0608,  -5.6782,   3.8616,\n",
       "                        -6.4063,  -3.3098,  -3.8689,  -7.3669,  -8.6131,  -3.6852,  -1.7822,\n",
       "                        -0.8158,  -2.0991,  -3.4854,  -6.3265,  -0.7037,  -1.9551,  -3.9395,\n",
       "                        -8.3529,  -6.3534,  -5.0519,  -9.2046,  -5.9804,  -3.8782,  -6.5263,\n",
       "                        -5.4163,  -5.5368,  -4.0463,  -3.8354,  -5.0896,  -6.0110,  -7.0405,\n",
       "                        -3.0010,  -6.2386,  -4.0346,  -0.3754,  -7.8277,  -6.0818,  -7.8651,\n",
       "                        -6.4240,  -4.4329,  -5.6176, -10.5690,  -4.8338,  -7.8223,  -8.5971,\n",
       "                        -4.2706,  -1.2760,  -3.1160,  -5.2439,  -6.0792,  -2.8554,  -4.7671,\n",
       "                       -10.1972,  -5.3260,  -1.2649,  -6.3484,  -3.9511,  -3.6146,  -3.9128,\n",
       "                        -2.9004,  -4.7150,  -3.9410,  -6.3880,  -4.4866,  -2.6650,  -6.4564,\n",
       "                        -1.9117,  -7.6207,  -2.6397,  -1.2198,  -6.7517,  -3.4818,  -6.2508,\n",
       "                        -5.4821,  -5.1062,   0.5175,  -5.7855,  -2.5263,  -1.4931,  -2.2290,\n",
       "                        -8.5932,  -7.5575], device='cuda:0')),\n",
       "              ('conv_block2.bn2.running_var',\n",
       "               tensor([39.4738, 50.2512, 22.0735, 19.9018, 19.8698, 20.9728,  7.8593, 25.9285,\n",
       "                       26.7521, 35.7524, 28.5406, 15.7397, 21.2985, 16.1114, 29.1470, 16.3477,\n",
       "                       46.2311, 21.5170, 24.7272, 21.8895, 30.1096, 32.5887, 24.2733, 34.2261,\n",
       "                        2.8262, 31.3546, 27.2281, 20.9851, 38.9086, 58.9054, 41.3042, 36.1662,\n",
       "                       18.2157, 18.5176, 14.1306, 34.1359, 18.4572, 34.3251, 31.8396, 19.9072,\n",
       "                       38.5039, 25.1795, 49.3835, 22.4839, 21.6583, 44.9227, 16.7198, 26.6548,\n",
       "                       14.7740, 30.8616, 37.0285, 14.4538, 35.8281, 49.5567, 20.6141, 18.0857,\n",
       "                       14.2632, 17.1822, 18.9241, 24.8222, 26.1890, 18.4515, 18.8614, 24.9102,\n",
       "                       25.8328, 20.0000, 19.6624, 20.5221, 10.0361, 25.1925,  6.1014, 29.3661,\n",
       "                       23.9723, 16.6776, 31.6900, 38.0337, 37.4205, 19.9710, 23.4294, 23.7631,\n",
       "                       14.4114, 42.7463, 21.7828, 29.3276, 22.0355, 30.7823, 27.8870, 50.3067,\n",
       "                       46.6016, 24.0858, 23.1349, 26.0429, 17.0057, 16.8542, 30.9906, 31.5861,\n",
       "                       24.1196, 21.7915, 22.6303, 24.3610, 26.3884, 19.4191, 31.9319, 17.5472,\n",
       "                       32.2729, 14.9530, 39.7351, 40.5044, 42.4207, 27.4097, 28.9811, 23.9798,\n",
       "                       19.2014, 29.4878, 21.0382, 19.4690, 35.1844, 46.0242, 28.0500, 18.4765,\n",
       "                       14.6201, 15.6444, 29.0666, 13.7840, 45.7339, 16.2414, 32.2088, 29.5621],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block3.conv1.weight',\n",
       "               tensor([[[[ 0.1918,  0.2914,  0.2449],\n",
       "                         [ 0.1409,  0.4522,  0.5067],\n",
       "                         [-0.0884,  0.0737,  0.0301]],\n",
       "               \n",
       "                        [[ 0.1019,  0.0240,  0.1687],\n",
       "                         [ 0.1553,  0.1560,  0.1272],\n",
       "                         [ 0.3152,  0.1944,  0.5959]],\n",
       "               \n",
       "                        [[-0.0959,  0.0195, -0.0181],\n",
       "                         [ 0.1306,  0.3360,  0.2106],\n",
       "                         [ 0.0172,  0.2755,  0.1774]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0589, -0.0836, -0.0707],\n",
       "                         [-0.0466, -0.0364, -0.0165],\n",
       "                         [-0.1360, -0.1182, -0.2067]],\n",
       "               \n",
       "                        [[ 0.1215, -0.0398,  0.0103],\n",
       "                         [ 0.2076,  0.1056,  0.0358],\n",
       "                         [ 0.2488,  0.1140,  0.0059]],\n",
       "               \n",
       "                        [[-0.1999,  0.1547, -0.0563],\n",
       "                         [ 0.0262,  0.1187,  0.0150],\n",
       "                         [-0.0092,  0.0139, -0.0758]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2419,  0.0038,  0.0491],\n",
       "                         [ 0.1142,  0.1323,  0.0855],\n",
       "                         [ 0.0182,  0.1687,  0.1369]],\n",
       "               \n",
       "                        [[ 0.0632, -0.0132, -0.2317],\n",
       "                         [-0.0641,  0.1044, -0.1256],\n",
       "                         [-0.2285, -0.0290, -0.1301]],\n",
       "               \n",
       "                        [[ 0.1610,  0.1163, -0.5981],\n",
       "                         [-0.1550,  0.0303, -0.5493],\n",
       "                         [-0.0474,  0.0092, -0.9042]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0083,  0.0083,  0.0075],\n",
       "                         [ 0.0145,  0.0950,  0.0511],\n",
       "                         [ 0.0830,  0.1164,  0.0494]],\n",
       "               \n",
       "                        [[ 0.2263,  0.1090,  0.0101],\n",
       "                         [ 0.1972,  0.0947,  0.0223],\n",
       "                         [ 0.2290,  0.0657,  0.0559]],\n",
       "               \n",
       "                        [[ 0.0564,  0.0782, -0.1155],\n",
       "                         [-0.0289,  0.0121, -0.1669],\n",
       "                         [-0.1572, -0.0734, -0.2753]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1550,  0.0760, -0.0711],\n",
       "                         [ 0.0081,  0.0031,  0.2342],\n",
       "                         [-0.0559, -0.0469,  0.0951]],\n",
       "               \n",
       "                        [[-0.2200, -0.1018,  0.0902],\n",
       "                         [-0.0272, -0.0195, -0.0870],\n",
       "                         [-0.0746,  0.0177, -0.0156]],\n",
       "               \n",
       "                        [[ 0.1937,  0.1846, -0.1088],\n",
       "                         [-0.0464, -0.0803, -0.1807],\n",
       "                         [-0.2460, -0.4201, -0.2906]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.2961,  0.0428,  0.0576],\n",
       "                         [-0.0060, -0.0896, -0.0119],\n",
       "                         [-0.0070, -0.1107, -0.0374]],\n",
       "               \n",
       "                        [[ 0.0958, -0.1339, -0.5265],\n",
       "                         [ 0.2807, -0.0662, -0.3240],\n",
       "                         [ 0.1958, -0.0395,  0.0079]],\n",
       "               \n",
       "                        [[-0.1234, -0.1167,  0.0425],\n",
       "                         [-0.1760, -0.0356,  0.1057],\n",
       "                         [ 0.0918,  0.0630,  0.0935]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1052,  0.0447, -0.0383],\n",
       "                         [ 0.3132, -0.0677,  0.2181],\n",
       "                         [ 0.3347,  0.1222,  0.1651]],\n",
       "               \n",
       "                        [[-0.1390, -0.1263, -0.2003],\n",
       "                         [ 0.0697,  0.2888,  0.1418],\n",
       "                         [-0.1250,  0.1076, -0.2513]],\n",
       "               \n",
       "                        [[ 0.1868,  0.4712, -0.2973],\n",
       "                         [ 0.4597,  0.3130,  0.0224],\n",
       "                         [ 0.6202,  0.3876,  0.2023]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1832, -0.2164, -0.1429],\n",
       "                         [-1.0208, -0.7868, -0.6915],\n",
       "                         [ 0.0429, -0.0640,  0.0734]],\n",
       "               \n",
       "                        [[ 0.3000, -0.1256, -0.1552],\n",
       "                         [ 0.3883,  0.0413, -0.0672],\n",
       "                         [-0.0734, -0.2630, -0.1852]],\n",
       "               \n",
       "                        [[-0.0130, -0.1501, -0.0803],\n",
       "                         [-0.0735, -0.1439, -0.1835],\n",
       "                         [-0.0352, -0.1001, -0.0571]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1292, -0.0475, -0.2751],\n",
       "                         [-0.0806, -0.0832, -0.1058],\n",
       "                         [-0.2897, -0.2348, -0.2851]],\n",
       "               \n",
       "                        [[ 0.3081, -0.0171,  0.0433],\n",
       "                         [ 0.3938, -0.0264,  0.0846],\n",
       "                         [-0.0721, -0.1088,  0.0143]],\n",
       "               \n",
       "                        [[-0.2201, -0.1279,  0.0128],\n",
       "                         [-0.0203, -0.0936,  0.2572],\n",
       "                         [-0.0513,  0.0027,  0.2839]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1582,  0.0710, -0.0582],\n",
       "                         [-0.1213,  0.0654,  0.0037],\n",
       "                         [-0.0399,  0.0586, -0.0409]],\n",
       "               \n",
       "                        [[ 0.1604, -0.0942, -0.0826],\n",
       "                         [ 0.0975,  0.0810,  0.0280],\n",
       "                         [ 0.1393,  0.1117,  0.0537]],\n",
       "               \n",
       "                        [[-0.0604, -0.2456, -0.2025],\n",
       "                         [ 0.0392, -0.1012, -0.0784],\n",
       "                         [-0.0073, -0.2827, -0.0562]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0430,  0.2113,  0.5149],\n",
       "                         [-0.0677,  0.0607,  0.4389],\n",
       "                         [-0.2325, -0.0065,  0.1742]],\n",
       "               \n",
       "                        [[-0.3542, -0.1437,  0.3854],\n",
       "                         [-0.2052, -0.2274,  0.2500],\n",
       "                         [-0.4057, -0.3395, -0.0143]],\n",
       "               \n",
       "                        [[-0.1930, -0.0256, -0.0375],\n",
       "                         [ 0.0103, -0.0207, -0.0794],\n",
       "                         [ 0.3867,  0.2394,  0.1966]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.1049,  0.0724, -0.0165],\n",
       "                         [ 0.0512,  0.0242, -0.0029],\n",
       "                         [ 0.0762,  0.0376,  0.0533]],\n",
       "               \n",
       "                        [[-0.0143,  0.0353,  0.0516],\n",
       "                         [-0.0515,  0.0574,  0.0636],\n",
       "                         [ 0.1108,  0.1316,  0.1324]],\n",
       "               \n",
       "                        [[ 0.2118, -0.2252,  0.0978],\n",
       "                         [ 0.4146, -0.1564,  0.0487],\n",
       "                         [ 0.1328, -0.3897, -0.1263]]]], device='cuda:0')),\n",
       "              ('conv_block3.conv2.weight',\n",
       "               tensor([[[[ 1.3757e-01,  4.3896e-02,  7.7711e-02],\n",
       "                         [ 3.9155e-02, -1.6810e-02, -5.3194e-03],\n",
       "                         [-7.1487e-02, -8.9337e-02, -9.6639e-02]],\n",
       "               \n",
       "                        [[ 1.0051e-01,  5.4529e-02,  2.5286e-01],\n",
       "                         [ 2.2643e-01,  1.0918e-01,  2.1707e-01],\n",
       "                         [ 2.2286e-01,  1.7694e-01,  1.8261e-01]],\n",
       "               \n",
       "                        [[ 1.0463e-01,  4.7260e-02,  1.4341e-01],\n",
       "                         [ 6.8646e-03,  3.5136e-02, -1.8568e-01],\n",
       "                         [ 1.4691e-02,  2.7523e-02, -8.4363e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.6073e-02, -1.0391e-01, -5.4284e-01],\n",
       "                         [-1.1898e-01, -1.1015e-01, -2.7668e-01],\n",
       "                         [-1.6836e-01, -1.7446e-01, -4.8569e-01]],\n",
       "               \n",
       "                        [[-2.9016e-01, -1.0900e-01, -5.3641e-02],\n",
       "                         [-2.6679e-01, -1.2469e-01, -1.4308e-01],\n",
       "                         [-1.3673e-01, -1.5387e-02,  1.9499e-02]],\n",
       "               \n",
       "                        [[-3.0667e-02, -2.2987e-01, -2.8192e-01],\n",
       "                         [-1.4152e-01, -1.1759e-01, -1.8855e-01],\n",
       "                         [-1.6718e-01, -2.3168e-01, -2.6251e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8786e-01,  1.6873e-01,  1.3946e-01],\n",
       "                         [-1.7823e-01,  5.2950e-02,  1.0508e-01],\n",
       "                         [ 3.9748e-02,  1.1322e-01,  9.1565e-02]],\n",
       "               \n",
       "                        [[ 1.6513e-01,  7.0866e-02,  2.9959e-02],\n",
       "                         [ 1.8623e-01,  8.5402e-02,  1.0393e-01],\n",
       "                         [ 1.6429e-01,  6.0174e-02,  9.9975e-02]],\n",
       "               \n",
       "                        [[-2.9346e-02,  2.7225e-01,  4.5111e-03],\n",
       "                         [-1.6765e-01,  8.2408e-02, -6.9969e-02],\n",
       "                         [-3.3864e-01, -3.1999e-01, -4.8076e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 8.7067e-02,  3.7755e-02,  1.4875e-01],\n",
       "                         [ 1.3623e-01,  5.7685e-02,  1.2049e-01],\n",
       "                         [-4.3463e-02,  8.5667e-02,  2.6807e-01]],\n",
       "               \n",
       "                        [[ 3.3094e-02, -3.1364e-02, -9.8045e-02],\n",
       "                         [ 5.5394e-02,  1.4516e-01,  4.4614e-02],\n",
       "                         [ 1.2437e-01,  6.7197e-02,  2.6299e-01]],\n",
       "               \n",
       "                        [[ 1.3716e-02,  2.9617e-02, -8.5375e-03],\n",
       "                         [-5.4299e-02, -9.0567e-03, -3.2639e-02],\n",
       "                         [-3.9753e-02, -3.7975e-02,  1.0959e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2729e-02,  1.2983e-02, -1.1082e-03],\n",
       "                         [-1.0104e-02, -2.4775e-03, -1.8996e-03],\n",
       "                         [-6.1798e-02, -5.7441e-02, -7.8250e-02]],\n",
       "               \n",
       "                        [[-1.8100e-02, -8.1336e-02,  8.5607e-03],\n",
       "                         [ 2.4292e-02,  3.0190e-03,  6.1094e-03],\n",
       "                         [ 5.0470e-02, -2.3951e-03,  3.9983e-02]],\n",
       "               \n",
       "                        [[-1.2726e-02, -9.6699e-02, -1.3851e-01],\n",
       "                         [-2.9790e-02, -8.6112e-02, -1.5020e-01],\n",
       "                         [-7.4393e-02, -9.5068e-02, -1.3827e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.0869e-02, -7.1531e-02, -3.1412e-03],\n",
       "                         [-2.2586e-02, -4.4022e-03, -1.1555e-02],\n",
       "                         [-3.3323e-02, -7.2141e-02, -3.3744e-02]],\n",
       "               \n",
       "                        [[ 3.9286e-02,  2.1935e-02, -1.1812e-02],\n",
       "                         [ 8.7210e-02,  4.9117e-02,  3.8273e-02],\n",
       "                         [ 7.9813e-03,  2.1938e-02, -2.2139e-02]],\n",
       "               \n",
       "                        [[-1.0034e-01, -6.9140e-02, -9.8685e-02],\n",
       "                         [ 7.6026e-03,  5.4144e-04, -2.7368e-02],\n",
       "                         [ 2.0734e-02,  2.5915e-02, -4.8275e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-3.3179e-03, -1.0582e-01, -7.0599e-02],\n",
       "                         [ 3.1258e-02,  2.8049e-02,  2.0656e-03],\n",
       "                         [ 1.3279e-01,  4.2829e-02,  9.6902e-02]],\n",
       "               \n",
       "                        [[-2.8050e-01, -2.3010e-01, -2.8824e-01],\n",
       "                         [-3.2654e-02,  7.5081e-02, -1.0713e-01],\n",
       "                         [ 2.2023e-01,  1.2251e-01, -3.1004e-02]],\n",
       "               \n",
       "                        [[-2.2567e-02, -1.0412e-01, -2.9561e-01],\n",
       "                         [-6.5547e-02, -1.8374e-01, -2.1960e-01],\n",
       "                         [ 4.5878e-02, -5.6491e-02, -1.8567e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2591e-01, -2.1784e-02, -4.0365e-02],\n",
       "                         [-5.7017e-02,  8.3478e-02, -3.8980e-02],\n",
       "                         [ 7.2135e-02,  1.7239e-01,  1.7608e-01]],\n",
       "               \n",
       "                        [[-3.4503e-01, -3.1989e-01, -3.2226e-01],\n",
       "                         [-1.6589e-01, -1.6011e-01, -1.2297e-01],\n",
       "                         [-7.5813e-02, -5.2137e-02, -5.5259e-02]],\n",
       "               \n",
       "                        [[-1.4890e-01,  1.2244e-02,  3.4804e-03],\n",
       "                         [ 9.9097e-02,  1.0039e-01,  1.1039e-01],\n",
       "                         [ 2.7918e-01,  2.4813e-01,  2.0999e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2763e-02,  3.3710e-02,  9.8060e-02],\n",
       "                         [ 4.1523e-02,  1.0447e-01,  1.1888e-01],\n",
       "                         [ 9.0085e-02,  1.0030e-01,  1.2675e-01]],\n",
       "               \n",
       "                        [[-2.0796e-02,  1.4305e-01, -8.5851e-02],\n",
       "                         [ 9.9763e-02,  1.7328e-01,  1.0501e-01],\n",
       "                         [ 9.9091e-02,  1.1628e-01,  5.7350e-02]],\n",
       "               \n",
       "                        [[-1.8043e-01, -6.2085e-02, -4.5798e-02],\n",
       "                         [-8.4020e-02,  1.2727e-01,  9.6284e-02],\n",
       "                         [ 1.7993e-01,  1.3537e-01,  1.8061e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.6259e-02, -5.4515e-02,  1.0738e-01],\n",
       "                         [-1.6335e-01, -1.6188e-01, -4.7400e-02],\n",
       "                         [-4.4075e-01, -2.0570e-01, -2.3790e-01]],\n",
       "               \n",
       "                        [[ 6.3876e-02,  5.0798e-02,  3.0333e-02],\n",
       "                         [ 1.7889e-02,  1.8676e-02,  2.0114e-02],\n",
       "                         [ 3.7309e-03,  6.1642e-02,  1.0740e-01]],\n",
       "               \n",
       "                        [[ 7.5402e-02,  6.8505e-02,  1.2329e-02],\n",
       "                         [ 9.4484e-02,  1.3652e-01,  7.6856e-02],\n",
       "                         [ 2.4983e-01,  2.6860e-01,  1.3195e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.5039e-02,  3.9122e-02, -4.0369e-03],\n",
       "                         [-1.2478e-01, -5.6188e-02, -2.4111e-02],\n",
       "                         [-6.4421e-02, -1.1154e-02,  3.1546e-02]],\n",
       "               \n",
       "                        [[ 6.7863e-02, -1.7155e-02,  8.1381e-02],\n",
       "                         [-3.2866e-02, -1.4610e-01, -7.5981e-03],\n",
       "                         [-9.6189e-02, -1.5031e-01, -2.5742e-02]],\n",
       "               \n",
       "                        [[-6.0012e-02,  7.6986e-02,  5.3144e-01],\n",
       "                         [ 1.6253e-01,  2.6311e-02,  2.9028e-01],\n",
       "                         [ 2.8924e-01,  4.3638e-01,  9.5001e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.4443e-02,  8.4047e-02,  9.4683e-02],\n",
       "                         [ 7.5064e-02,  8.1519e-03,  9.3771e-02],\n",
       "                         [ 4.4937e-02,  1.1582e-02,  3.0661e-02]],\n",
       "               \n",
       "                        [[-4.2403e-02,  5.5279e-02,  7.3614e-02],\n",
       "                         [-1.4714e-01, -1.1489e-01, -1.1970e-01],\n",
       "                         [-2.2739e-01, -2.6858e-01, -2.7262e-01]],\n",
       "               \n",
       "                        [[ 5.3812e-02,  1.3348e-01,  9.6792e-02],\n",
       "                         [ 1.7793e-02,  9.1173e-02,  1.9585e-02],\n",
       "                         [ 7.9299e-03,  8.6664e-02,  1.0111e-02]]]], device='cuda:0')),\n",
       "              ('conv_block3.bn1.weight',\n",
       "               tensor([1.0210, 1.0682, 1.3787, 1.2665, 1.1524, 1.2183, 0.7760, 0.9235, 1.3536,\n",
       "                       1.1974, 1.3259, 1.0340, 0.7915, 1.4988, 1.3355, 1.0443, 1.5879, 1.0444,\n",
       "                       1.4216, 1.0978, 0.9139, 1.1532, 1.1720, 1.4551, 0.9114, 1.1548, 0.2007,\n",
       "                       0.9233, 0.9801, 1.4392, 1.2658, 1.2461, 1.2587, 0.9034, 1.2150, 0.9803,\n",
       "                       0.9793, 1.0596, 1.2942, 1.0567, 0.9321, 1.1342, 1.5601, 1.0315, 1.2391,\n",
       "                       1.0022, 0.9950, 1.2044, 1.0443, 1.0558, 1.0039, 1.3602, 1.1981, 1.2316,\n",
       "                       1.3122, 1.0064, 0.7829, 1.3809, 1.1030, 1.4282, 0.9289, 1.1313, 1.3792,\n",
       "                       0.9184, 1.0905, 1.0623, 1.2476, 1.4465, 1.1163, 1.2293, 1.0798, 1.3139,\n",
       "                       1.7250, 0.8172, 1.5012, 1.3231, 1.0144, 1.1767, 0.8729, 1.1869, 0.9012,\n",
       "                       1.0563, 0.7078, 1.3326, 1.0936, 1.0224, 1.3593, 0.9392, 1.0068, 0.9863,\n",
       "                       1.1849, 0.9958, 1.2248, 0.9927, 0.3141, 1.3952, 1.0526, 0.9720, 1.1495,\n",
       "                       1.1253, 0.9783, 1.0597, 1.0248, 1.4366, 1.3393, 1.2572, 0.9937, 1.1931,\n",
       "                       1.1437, 0.8957, 1.2098, 0.2566, 1.0649, 1.3017, 1.0800, 0.5224, 1.0450,\n",
       "                       1.1513, 1.1263, 0.8780, 1.3537, 1.1516, 1.5164, 1.1235, 0.9574, 0.9924,\n",
       "                       1.1335, 1.0409, 0.9817, 0.9195, 0.9063, 0.7173, 1.1560, 1.2215, 1.1700,\n",
       "                       1.4139, 1.2205, 0.9432, 1.0820, 1.4721, 1.3174, 1.0905, 1.2970, 0.8261,\n",
       "                       0.9812, 1.0475, 1.2826, 1.2452, 0.8185, 1.0462, 1.0750, 1.5156, 1.1132,\n",
       "                       1.3410, 1.1077, 1.1155, 1.2860, 0.9671, 0.5262, 1.1721, 0.9906, 1.1165,\n",
       "                       1.2943, 0.9292, 1.0349, 1.1765, 1.1188, 1.1820, 0.9491, 0.9734, 1.3175,\n",
       "                       1.2034, 1.2084, 0.9865, 1.2615, 0.8739, 0.7807, 1.1073, 0.7385, 0.9734,\n",
       "                       1.4519, 0.9854, 1.0787, 1.0790, 1.0758, 1.1872, 1.0594, 0.9354, 0.5785,\n",
       "                       1.2671, 0.6805, 1.1030, 1.2096, 1.1690, 0.8356, 0.8897, 1.0657, 1.2187,\n",
       "                       0.9070, 0.7119, 0.9653, 0.9849, 1.0520, 0.2849, 0.9442, 1.1167, 1.2524,\n",
       "                       1.0367, 1.4768, 1.2307, 1.2085, 0.8254, 1.2146, 1.1639, 0.2181, 1.2649,\n",
       "                       1.1123, 1.2077, 1.2347, 1.0788, 1.5626, 1.0067, 1.1525, 1.1592, 1.1814,\n",
       "                       1.2216, 1.1346, 0.6273, 1.3089, 1.5136, 1.1486, 0.7495, 1.3114, 0.9355,\n",
       "                       1.1059, 1.4022, 1.3204, 1.5235, 1.3346, 1.1735, 1.1633, 1.0751, 1.3056,\n",
       "                       1.0540, 1.0776, 0.9134, 0.7332, 1.1821, 0.9479, 0.8942, 1.1816, 1.1299,\n",
       "                       0.9147, 1.0555, 0.8702, 1.0005], device='cuda:0')),\n",
       "              ('conv_block3.bn1.bias',\n",
       "               tensor([-0.8982, -0.5593, -0.8299, -0.8870, -0.6938, -0.3829, -1.0505, -0.7719,\n",
       "                       -0.6779, -0.5489, -0.8549, -0.9675, -0.3858, -1.1915, -0.7939, -0.5287,\n",
       "                       -1.0818, -0.6826, -1.1990, -0.5504, -0.6985, -0.5265, -0.7031, -0.7221,\n",
       "                       -0.6240, -0.7923, -0.7477, -0.6211, -0.4847, -0.9305, -0.8672, -0.9640,\n",
       "                       -0.5970, -0.7963, -1.0095, -0.7041, -0.6201, -0.8272, -0.8642, -0.7149,\n",
       "                       -0.1486, -0.8913, -1.5533, -0.5700, -0.7954, -0.9663, -0.5202, -1.0395,\n",
       "                       -1.0383, -0.8046, -0.7002, -1.1470, -0.5868, -0.7367, -0.7754, -0.4929,\n",
       "                       -0.6644, -0.7077, -0.7026, -0.8174, -0.6611, -0.5234, -0.6234, -0.5961,\n",
       "                       -0.5143, -0.7454, -0.6751, -0.6286, -1.0052, -1.2545, -0.4291, -1.1618,\n",
       "                       -0.8726, -0.8077, -1.0296, -0.9257, -1.2397, -0.9032, -1.1586, -0.6834,\n",
       "                       -0.3203, -0.7832,  0.3590, -0.7680, -0.7617, -0.9250, -0.9485, -0.8702,\n",
       "                       -0.5869, -0.2732, -1.1147, -0.6329, -0.7087, -0.5849, -1.2142, -0.8736,\n",
       "                       -1.2073, -0.4033, -0.6485, -0.9067, -0.1779, -0.7485, -1.5761, -0.8470,\n",
       "                       -0.5936, -1.3240, -0.8528, -0.7504, -0.8944, -0.4018, -0.9139, -0.2481,\n",
       "                       -1.2777, -0.6512, -0.5649,  0.1888, -0.9627, -0.8056, -0.6371, -0.6132,\n",
       "                       -1.0691, -0.5870, -1.7209, -0.3129, -0.5256, -1.5523, -0.5553, -0.8495,\n",
       "                       -0.0422, -0.3014, -0.5068, -0.6025, -0.5146, -1.0281, -0.7575, -1.0009,\n",
       "                       -0.9620, -0.3392, -0.7340, -0.9131, -1.0636, -0.7621, -0.8121, -0.3924,\n",
       "                       -1.2843, -0.4223, -0.8621, -0.7582, -0.4664, -0.6746, -0.9525, -0.7069,\n",
       "                       -0.6494, -1.2329, -0.9510, -0.5987, -0.8122, -0.2585, -2.3511, -0.4336,\n",
       "                       -0.4982, -1.0574, -0.6793, -0.3944, -0.4837, -0.6630, -1.0718, -0.7356,\n",
       "                       -0.3307, -0.7226, -0.8178, -0.3179, -0.6890, -0.4605, -1.2686, -0.4719,\n",
       "                       -0.4427, -0.6833, -0.3259, -0.6951, -1.1053, -0.9664, -0.7898, -0.8774,\n",
       "                       -0.1740, -0.9885, -0.3770, -0.7380, -1.2202, -1.1224, -0.1347, -0.7182,\n",
       "                       -0.7212, -0.3407, -0.2000, -0.8056, -0.8408, -0.6210, -1.0593, -3.0333,\n",
       "                       -0.3586, -1.0164, -0.5091, -0.7474, -0.7502, -0.5594, -0.7063, -0.6198,\n",
       "                       -1.2757, -0.9516, -0.7334, -0.6935, -0.7772, -0.7707, -0.4082, -1.0337,\n",
       "                       -0.6719, -0.8486, -0.8674, -0.7073, -0.8083, -0.7788, -0.8789, -0.3953,\n",
       "                       -1.1115, -0.7206, -0.9332,  0.0890, -0.8098, -0.9703, -1.0459, -0.3908,\n",
       "                       -0.4484, -0.9225, -0.8505, -0.7879, -0.9284, -1.4579, -1.1448, -0.5124,\n",
       "                       -0.8017, -0.4046, -0.8617, -0.6982, -0.5067, -0.4861, -0.2880, -0.7619,\n",
       "                       -0.6610, -0.4801, -0.9662, -0.7079, -0.0607, -0.8820, -0.4338, -0.8083],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.running_mean',\n",
       "               tensor([-3.7360, -4.6233, -3.6557, -4.6322, -4.8712, -6.6473,  2.6305, -2.3720,\n",
       "                       -5.6320, -4.4953, -5.4183, -4.5167, -0.6653, -1.5994, -3.9121, -4.2781,\n",
       "                       -5.1403, -6.3913, -2.0675, -2.6454, -2.2475, -3.3489, -3.0543, -3.3195,\n",
       "                       -3.7124, -2.8566,  0.2100, -1.1776, -2.3026, -5.0968, -1.6714, -3.2174,\n",
       "                       -4.1996, -3.7995, -4.8007, -1.2997, -5.3567, -6.7394, -3.0238, -3.8048,\n",
       "                       -5.4116, -1.9124, -3.5887, -3.7645, -3.0835,  0.4196, -0.1750, -0.8241,\n",
       "                       -3.8663, -5.2823, -1.4541, -0.5725, -3.8569, -1.6381, -7.6170, -2.1444,\n",
       "                       -4.5620, -5.6154, -4.2468, -5.3433, -5.3010, -2.4488, -6.4545, -2.8165,\n",
       "                        0.4223, -3.1771, -4.7437, -3.0589, -3.0745, -5.9238, -3.7874, -2.2076,\n",
       "                       -3.5404,  0.2015, -1.2456, -3.9242,  0.0954, -3.9417,  2.5984, -3.5945,\n",
       "                       -5.9171, -6.4251, -2.2578, -7.8775, -4.0284, -1.5283, -4.6262, -4.2763,\n",
       "                       -3.8058, -3.8550,  1.3800, -4.1743, -2.1319, -3.8210,  0.2053, -6.9632,\n",
       "                        1.3226, -2.8647, -3.8293, -1.0065, -4.6257, -2.2867, -0.0156, -1.9057,\n",
       "                       -3.9294, -1.8285, -0.6933, -7.2701, -0.6164, -6.3500, -2.5230, -0.1673,\n",
       "                       -0.9316, -4.1876, -2.7565, -3.4657, -4.0930, -1.9206, -3.3713,  1.5430,\n",
       "                       -3.6946, -6.0348, -4.5280, -3.2375, -1.6931,  5.8075, -4.1949, -1.6370,\n",
       "                       -1.5397, -2.7168, -4.1562, -2.2200, -4.1181, -4.4697, -1.1916, -2.0798,\n",
       "                       -3.4317, -1.1386, -3.6220, -2.8417, -4.7057, -2.8248, -2.5854, -8.3990,\n",
       "                        5.7105, -3.2966, -4.7009, -3.6105, -1.5590, -3.8793, -4.2679, -4.7801,\n",
       "                       -3.7535, -1.4472, -1.8453, -3.9892, -3.5442, -4.9556,  0.1412, -5.7569,\n",
       "                       -2.0001, -2.6130, -3.2370, -3.9707, -3.0764, -7.3013, -3.8480, -2.5359,\n",
       "                       -0.9426, -2.6543, -2.9104, -2.9212, -2.5907, -3.6120, -8.9578, -5.6857,\n",
       "                       -0.9836, -5.1064, -5.8374, -5.6726, -4.7037,  0.2951, -4.0062, -3.3184,\n",
       "                       -2.3170, -4.5064, -6.1815, -0.9618,  0.3356,  1.5998, -6.5894, -3.6475,\n",
       "                       -1.6931, -4.1432, -2.0141, -4.7789, -0.4445, -3.1385, -0.5600, -1.2760,\n",
       "                       -5.1539,  0.3197, -2.1731,  0.3439, -0.0959, -4.5920, -3.5617, -1.3553,\n",
       "                       -4.1359, -2.9156, -3.2453,  0.2077, -2.4971, -4.5291,  0.4152, -5.2192,\n",
       "                       -4.4310, -4.0784, -3.5517, -2.5801, -3.5983,  1.2604, -2.5246, -2.3927,\n",
       "                       -3.4935, -2.9094, -2.1389, -1.9884, -3.0646, -8.0526, -1.8004, -0.2110,\n",
       "                       -2.6031,  2.8122, -1.1262, -3.0278, -4.2276, -5.0716, -3.3233, -3.3826,\n",
       "                       -5.1959, -0.9382, -2.2691, -0.8058, -2.6139, -5.5010, -5.3529, -1.8328,\n",
       "                       -3.7692, -0.9625, -3.4762, -3.4709, -3.0176, -3.5250, -4.4706, -1.3083],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.running_var',\n",
       "               tensor([ 6.1906, 10.7009, 24.1509, 10.8535, 20.8408, 33.6762,  5.2201,  9.7729,\n",
       "                       23.8067, 10.8420, 21.0792,  9.0527, 12.4375,  6.0220, 12.7975,  4.4165,\n",
       "                       19.1036, 15.9470,  6.0773,  5.3244,  5.8844, 15.2656, 13.7625, 17.2115,\n",
       "                        9.5323, 18.9623,  0.3134,  9.9714, 19.6615, 26.4770,  7.6843,  8.8536,\n",
       "                       19.2414, 11.6547, 12.2803, 10.6438, 12.2425, 16.1193, 18.3075, 13.7481,\n",
       "                       13.2419,  9.7243,  9.2443,  9.2479, 13.4569,  9.9631, 10.7243,  8.8279,\n",
       "                        9.7693,  7.5803,  3.7514,  7.1608, 17.4216,  5.2497, 14.5373,  5.3475,\n",
       "                       14.0407, 21.1500, 12.7579, 19.2692, 11.1483, 16.4439, 27.9443, 12.0953,\n",
       "                       11.8162, 16.3111, 16.5706, 20.7969,  6.6163, 11.7927, 11.9599,  6.9639,\n",
       "                       27.2784,  2.5325, 10.3721, 19.2093,  4.0294,  8.4838,  6.6247, 10.4096,\n",
       "                       14.7797, 14.9003, 15.6197, 22.0655,  6.7335,  4.0474, 13.0321,  4.2047,\n",
       "                       19.2052, 20.2889,  5.2874,  7.2998, 14.2664,  7.5100,  0.7746, 15.2723,\n",
       "                        2.8366, 10.4677,  9.4623, 10.7298, 16.2824, 14.4357,  8.2096,  7.2522,\n",
       "                        9.0731,  6.8159,  5.1362, 13.4172,  5.0952, 14.4018, 15.6126,  0.6714,\n",
       "                        5.5315,  9.3035,  9.0678, 10.5202,  8.3224,  7.0902, 10.3108, 14.5298,\n",
       "                       12.4740, 16.5915, 10.1835, 15.5011,  8.4438, 10.5427, 11.1548,  7.0762,\n",
       "                       11.7243,  7.0338, 14.6593,  7.7724, 11.6558, 15.6894, 10.9430, 10.4501,\n",
       "                        7.1322, 16.6671,  9.2184, 14.6290, 20.1197, 11.5443,  7.8513, 18.9911,\n",
       "                        4.9606, 12.3159, 28.1145, 11.0436,  9.8462, 14.1108,  6.0178, 29.4965,\n",
       "                       14.3037,  7.9433,  5.8518,  8.9415, 22.8256, 13.0112,  0.8590, 29.0803,\n",
       "                       15.0455,  6.8791, 29.8244, 16.2032, 26.9033, 13.4011,  7.0414, 14.9736,\n",
       "                       11.0406,  7.4606,  6.3046,  7.9925,  7.9554,  9.7872, 12.8046, 11.6541,\n",
       "                        3.6507,  9.7574, 16.0379, 10.1677, 17.7478,  4.3765, 11.2913, 11.3733,\n",
       "                       14.5081,  7.4594, 13.1381,  9.7234,  1.3204,  6.6638, 16.0777,  5.1876,\n",
       "                       14.0519, 19.1653, 14.3280,  9.4319,  8.8464,  7.8796,  2.3688,  1.8170,\n",
       "                       10.6819,  2.9820,  8.9859,  0.6444, 10.0688, 16.8911, 16.1451, 11.7682,\n",
       "                       10.2172, 14.2086,  7.7493, 10.2250,  7.0203, 14.0146,  0.5052, 16.7758,\n",
       "                        6.6086, 10.6471, 12.1595,  9.1270, 23.1104,  5.8590, 10.6717, 14.7882,\n",
       "                       10.8837,  7.7072,  8.7823, 14.0688, 11.8872, 14.3936,  9.7891, 13.1332,\n",
       "                       22.6213,  6.3628, 14.6721, 14.4389, 15.3946, 16.4688, 10.7773,  6.6466,\n",
       "                       21.1301, 10.7116,  6.1879,  8.1472,  7.0374, 16.1513, 11.5553,  6.8429,\n",
       "                       12.0741, 11.5021, 10.7611, 12.5017, 14.9984, 15.8575, 19.4742,  8.1398],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block3.bn2.weight',\n",
       "               tensor([0.9051, 0.9394, 0.3467, 1.0366, 1.0479, 1.1572, 1.6049, 1.1137, 0.9935,\n",
       "                       1.1752, 0.8874, 1.0937, 0.6876, 1.1102, 1.4864, 1.3248, 0.9897, 1.4706,\n",
       "                       1.4177, 0.2613, 1.1516, 0.9729, 1.2617, 0.2820, 1.0827, 0.2616, 1.4487,\n",
       "                       1.0664, 1.4253, 1.3209, 1.0332, 1.2626, 0.9325, 1.1220, 0.8981, 1.0424,\n",
       "                       0.9619, 1.2507, 1.3945, 1.1734, 0.9084, 0.8654, 1.2673, 1.0337, 1.0987,\n",
       "                       1.3766, 1.6624, 0.8357, 1.0707, 0.9537, 0.2633, 0.9885, 0.9755, 1.3231,\n",
       "                       1.2518, 1.4758, 1.3703, 1.1539, 1.1889, 1.1905, 1.4671, 1.0795, 0.8962,\n",
       "                       0.8735, 1.1473, 1.0061, 0.9262, 0.9056, 0.9279, 1.1607, 1.1400, 1.3418,\n",
       "                       0.2692, 1.0091, 1.3077, 0.5176, 0.9112, 0.9307, 1.0229, 0.8897, 1.0297,\n",
       "                       0.9391, 1.0971, 0.4626, 0.9116, 1.4098, 1.0808, 1.0182, 1.5772, 1.0186,\n",
       "                       1.0702, 0.9926, 1.3717, 0.9138, 1.1040, 1.0963, 0.8279, 1.0532, 1.3980,\n",
       "                       1.2943, 1.0913, 0.8435, 1.0859, 0.9802, 1.0216, 0.2935, 1.1645, 0.9617,\n",
       "                       1.4009, 1.1233, 0.9578, 0.6571, 1.0725, 0.7002, 1.0372, 1.1292, 1.2509,\n",
       "                       0.9716, 1.5299, 1.2976, 1.0172, 1.2507, 1.0353, 1.0831, 0.9625, 0.9419,\n",
       "                       1.1977, 1.0909, 1.2755, 0.8902, 1.2145, 1.3266, 0.8319, 0.9505, 0.9411,\n",
       "                       1.1432, 0.9254, 1.1651, 1.1642, 0.2505, 1.2972, 1.1613, 0.9954, 1.1288,\n",
       "                       1.1554, 1.1024, 1.4579, 0.8870, 1.1077, 1.3331, 1.1827, 1.0637, 0.9267,\n",
       "                       1.1762, 1.0574, 1.2458, 1.3292, 0.9216, 1.0776, 1.2446, 1.3153, 1.2265,\n",
       "                       1.1726, 1.0782, 0.2623, 0.8875, 0.2963, 1.2376, 1.4084, 1.0460, 1.2456,\n",
       "                       1.2219, 1.0095, 1.0642, 0.9782, 1.2341, 1.0097, 1.0705, 0.8490, 0.9098,\n",
       "                       1.0768, 1.0270, 1.1807, 1.2606, 1.3560, 1.4065, 1.1395, 1.1043, 1.0956,\n",
       "                       0.9400, 0.9232, 0.9482, 1.0033, 0.7078, 1.1307, 1.1774, 0.9191, 1.1546,\n",
       "                       0.9854, 0.8554, 1.0341, 0.8977, 0.8860, 0.9033, 1.0850, 1.0711, 1.1451,\n",
       "                       0.9898, 1.1208, 1.0563, 1.3754, 0.8993, 1.0484, 0.8753, 0.9922, 1.2163,\n",
       "                       1.0892, 1.1947, 0.7565, 0.9142, 1.3299, 0.9942, 1.0805, 1.3669, 0.8534,\n",
       "                       1.3016, 1.4345, 1.2004, 1.1323, 0.7956, 0.9888, 1.0292, 1.1574, 1.1866,\n",
       "                       1.1543, 1.0344, 1.4174, 0.3030, 1.4229, 1.2801, 0.2937, 0.9351, 0.9618,\n",
       "                       1.1582, 1.2652, 0.9315, 1.1234, 1.0876, 1.0357, 1.2522, 0.9250, 1.1716,\n",
       "                       1.2080, 1.2942, 1.3198, 1.2777], device='cuda:0')),\n",
       "              ('conv_block3.bn2.bias',\n",
       "               tensor([-0.6634, -0.5544, -0.0422, -0.6581, -0.8572, -0.9712, -1.6261, -0.5950,\n",
       "                       -0.7201, -1.2496, -0.5318, -0.7978, -0.1393, -0.6118, -1.3631, -1.3863,\n",
       "                       -0.6188, -1.2326, -1.6330, -0.1872, -0.8443, -0.7549, -1.2820, -0.0505,\n",
       "                       -1.1499, -0.0781, -1.2581, -1.0880, -1.3273, -1.2754, -0.6035, -0.7674,\n",
       "                       -0.4481, -1.0971, -0.9998, -0.6411, -0.5971, -1.3235, -1.3134, -0.8110,\n",
       "                       -0.5895, -0.6744, -0.8855, -1.1614, -1.0477, -1.3588, -1.3315, -0.6502,\n",
       "                       -1.0932, -0.7254, -0.3861, -0.5992, -1.0614, -1.1524, -1.2114, -1.0342,\n",
       "                       -1.3392, -0.7853, -0.7540, -0.9350, -1.7840, -0.9019, -0.7942, -0.5565,\n",
       "                       -1.1643, -0.6610, -0.6357, -0.4942, -0.7252, -1.0780, -0.9504, -1.2680,\n",
       "                       -0.0283, -0.9093, -1.0604,  0.0534, -0.5707, -0.8475, -0.7689, -0.7964,\n",
       "                       -1.0437, -0.7244, -0.6308, -0.0799, -0.6952, -1.1794, -0.9914, -0.9248,\n",
       "                       -1.2379, -0.8964, -1.0408, -0.6191, -1.2270, -0.5548, -0.9034, -1.1669,\n",
       "                       -0.6484, -0.8183, -1.1430, -1.5660, -0.9298, -0.2687, -0.6611, -0.5908,\n",
       "                       -0.7479, -0.0536, -1.2109, -0.8190, -1.3240, -0.9726, -0.5736, -0.2446,\n",
       "                       -0.9323, -0.2670, -0.8135, -0.9782, -1.0693, -0.8946, -1.2197, -1.2017,\n",
       "                       -0.8493, -1.0271, -0.7801, -0.9973, -0.5407, -0.5843, -0.8183, -0.9339,\n",
       "                       -1.1637, -0.6353, -0.8803, -1.1417, -0.6053, -0.5750, -0.9905, -1.1236,\n",
       "                       -0.7335, -0.7768, -1.1079, -0.0484, -1.5820, -1.2682, -0.9510, -0.8856,\n",
       "                       -1.1036, -1.2498, -1.1422, -0.8046, -0.9191, -1.1010, -0.9548, -0.9208,\n",
       "                       -0.7223, -0.7993, -0.9130, -0.6914, -1.4146, -0.8214, -0.7783, -0.7009,\n",
       "                       -1.1782, -0.8517, -0.7981, -1.0004, -0.0658, -0.6777,  0.1841, -0.9849,\n",
       "                       -1.3402, -0.8736, -0.5267, -0.7914, -0.9291, -1.1181, -0.5579, -0.9340,\n",
       "                       -1.1616, -1.0515, -0.6710, -0.8138, -0.8020, -0.6899, -1.1364, -1.0139,\n",
       "                       -0.7805, -1.3099, -0.3936, -0.8767, -0.4665, -0.8453, -0.6968, -0.5989,\n",
       "                       -0.8351, -0.6806, -0.9338, -1.0715, -0.7662, -1.4438, -0.6182, -0.7659,\n",
       "                       -1.0537, -0.5319, -0.5135, -0.9045, -0.5828, -0.8373, -0.9134, -0.7420,\n",
       "                       -1.1932, -0.9939, -0.7015, -0.5463, -1.0515, -0.5218, -0.5948, -0.8505,\n",
       "                       -1.0803, -0.9453, -0.5138, -0.3713, -1.3711, -0.6823, -0.7744, -1.3687,\n",
       "                       -0.5889, -0.9297, -1.4539, -0.9427, -0.8768, -0.5206, -1.0093, -0.6510,\n",
       "                       -0.8140, -1.1389, -1.1334, -0.8144, -1.4738,  0.0231, -1.1460, -1.0632,\n",
       "                       -0.0401, -0.7883, -0.5025, -0.6524, -1.0350, -0.7857, -0.7549, -0.8493,\n",
       "                       -0.7969, -0.8876, -0.9356, -0.6092, -1.0583, -1.3752, -1.4297, -1.2696],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn2.running_mean',\n",
       "               tensor([-3.4911e+00, -9.6107e+00, -5.3826e+00, -1.6101e+01, -5.5888e+00,\n",
       "                       -8.8130e+00, -9.5321e+00, -6.3366e+00, -8.2244e+00, -8.4098e+00,\n",
       "                       -3.3756e+00, -7.0694e+00, -4.1885e+00, -8.6844e+00, -7.0230e+00,\n",
       "                       -1.5198e+01, -1.1964e+01, -7.8929e+00, -3.9568e+00, -3.9354e+00,\n",
       "                       -1.1699e+01,  2.0371e+00, -9.2795e+00,  5.9330e-02, -5.3359e+00,\n",
       "                        1.4149e-02, -6.5833e+00, -4.7250e-01, -1.2001e+01, -5.9918e+00,\n",
       "                       -1.3095e+01, -6.4204e+00, -2.2617e+00, -1.1366e+01, -6.1231e+00,\n",
       "                       -9.6574e+00, -1.2655e+01, -3.6809e+00, -6.0819e+00, -2.5524e+00,\n",
       "                        4.1935e+00, -3.6395e+00, -4.0330e+00, -4.5607e+00, -5.9919e+00,\n",
       "                       -1.3055e+01, -4.4051e+00, -4.5932e+00, -7.9964e+00, -6.3563e+00,\n",
       "                        7.8042e-02, -8.5461e+00, -4.2503e+00, -7.0154e+00, -8.0652e+00,\n",
       "                       -7.5181e+00, -9.9843e+00, -1.2088e+01, -8.2631e+00, -1.6709e+01,\n",
       "                       -8.9786e+00, -3.2740e+00, -3.0352e+00, -5.7816e+00, -1.0367e+00,\n",
       "                       -9.6153e+00, -1.2270e+00, -6.9112e+00, -5.0506e+00, -1.1475e+01,\n",
       "                       -7.0857e+00, -9.1037e+00, -2.5610e-02, -6.9558e+00, -8.9153e+00,\n",
       "                       -1.1920e+00, -9.7330e+00, -1.3303e+01, -1.0187e+01, -3.5070e+00,\n",
       "                       -3.8751e+00, -6.2426e+00, -7.3738e+00, -7.2214e+00, -7.7449e+00,\n",
       "                       -1.9124e+00, -4.3638e+00, -2.4460e+00, -8.4248e+00, -7.2303e+00,\n",
       "                       -5.0449e+00, -6.1708e+00, -6.7142e+00, -8.7842e+00, -1.4931e+01,\n",
       "                       -8.3758e+00,  4.8030e+00, -1.2311e+01, -5.9956e+00, -2.1967e+00,\n",
       "                       -2.2356e+00, -3.7703e+00, -5.8839e+00, -1.1787e+01, -1.0484e+01,\n",
       "                        9.5356e-02, -6.3985e+00, -6.5360e+00, -9.0980e+00, -9.6880e+00,\n",
       "                       -1.0938e+01, -8.2971e+00, -8.1249e+00, -3.1658e+00, -3.9382e+00,\n",
       "                       -5.5435e+00, -1.3640e+01, -1.0127e+01, -5.9742e+00, -9.9183e+00,\n",
       "                       -5.7110e+00, -2.7085e+00, -3.4386e+00, -9.2171e+00, -7.6556e+00,\n",
       "                       -8.4008e+00, -7.3623e+00, -9.9678e+00, -6.5990e+00, -1.0719e+01,\n",
       "                       -8.8565e+00, -2.6989e+00, -8.4863e+00, -4.6265e+00, -1.0382e+01,\n",
       "                       -9.7883e+00, -1.2193e+01, -6.3949e+00, -4.8447e+00,  5.8276e-03,\n",
       "                       -6.2136e+00, -1.0262e+01, -8.1288e+00, -2.5930e+00, -1.1328e+01,\n",
       "                       -3.8169e+00, -5.9234e+00, -1.1199e+01, -7.7389e+00, -8.8508e+00,\n",
       "                       -9.2099e+00, -1.2340e+01, -7.9534e+00, -7.4613e+00, -3.8052e+00,\n",
       "                       -6.5691e+00, -9.9729e+00, -1.3705e+00, -5.1512e+00, -1.0458e+00,\n",
       "                       -4.5330e+00, -1.1094e+01, -9.7869e+00, -5.6063e+00,  7.8726e-02,\n",
       "                       -2.8889e+00, -1.3183e+00, -3.8979e+00, -8.7061e+00, -9.4747e+00,\n",
       "                       -7.4667e+00, -6.6214e+00, -1.0910e+01, -4.1701e+00, -4.1629e+00,\n",
       "                       -7.0732e+00, -6.9208e+00, -6.2487e+00, -5.0185e+00, -5.0112e+00,\n",
       "                       -1.0220e+01, -1.0323e+01, -6.2955e+00, -5.8233e+00, -1.1548e+01,\n",
       "                       -6.7834e+00, -4.5839e+00, -1.3402e+01, -4.6271e+00, -1.2829e+01,\n",
       "                       -6.7772e+00, -6.7742e+00, -8.2506e+00,  4.2465e-01, -1.3567e+01,\n",
       "                       -3.2647e+00, -6.7446e+00,  3.3160e-01, -6.1321e+00, -6.4997e+00,\n",
       "                       -8.8729e+00, -5.6220e+00, -3.4813e+00, -5.9370e+00, -1.0709e+01,\n",
       "                       -6.4628e+00, -1.1719e+01, -3.9484e+00,  3.1026e+00, -6.6003e+00,\n",
       "                       -9.4827e+00, -8.4693e+00, -9.2676e+00, -1.1096e+01, -5.9350e+00,\n",
       "                       -9.8378e+00,  2.6526e+00, -9.2605e+00, -3.1468e+00, -9.9574e+00,\n",
       "                        2.6649e+00, -1.0790e+01, -7.9090e+00, -1.0677e+01, -7.9327e+00,\n",
       "                       -7.8905e+00, -6.0571e+00, -7.4595e+00, -1.0302e+01, -1.7779e+00,\n",
       "                       -6.6011e+00, -4.6557e+00, -1.1171e+01, -6.7969e+00, -3.7002e+00,\n",
       "                       -1.0312e+01, -1.0197e+01,  2.4224e+00, -5.5731e+00, -6.1909e+00,\n",
       "                        2.6746e-02, -1.0855e+01, -1.0937e+01, -1.0483e+01, -6.3921e+00,\n",
       "                       -7.5746e+00, -2.4169e+00, -1.0476e+01, -7.3055e-01, -4.6117e+00,\n",
       "                       -7.9135e+00, -6.3495e+00, -5.4649e+00, -9.6260e+00, -6.5566e+00,\n",
       "                       -9.5391e+00], device='cuda:0')),\n",
       "              ('conv_block3.bn2.running_var',\n",
       "               tensor([32.6233, 51.5683, 12.6306, 65.5238, 32.6754, 44.7554, 64.5536, 27.7206,\n",
       "                       39.5589, 38.3092, 26.6532, 33.9899, 30.0790, 54.5678, 51.9654, 59.6498,\n",
       "                       30.5240, 46.6019, 27.9788,  6.7656, 67.2831, 29.2543, 63.4173,  4.0350,\n",
       "                       27.5978,  2.7838, 46.1793, 22.1832, 76.4300, 27.9449, 36.9475, 48.0723,\n",
       "                       45.7297, 53.8783, 28.5872, 56.5120, 47.0346, 60.6090, 60.9651, 25.6091,\n",
       "                       42.1833, 48.8448, 35.1397, 50.1726, 56.0075, 34.9519, 36.2864, 35.8140,\n",
       "                       37.3637, 29.9512,  2.6348, 26.1510, 42.6052, 53.2502, 25.8395, 35.5810,\n",
       "                       40.8477, 38.8935, 45.3449, 51.7833, 39.9969, 43.2109, 25.6505, 36.0094,\n",
       "                       33.2648, 62.1977, 39.1122, 57.3670, 33.4389, 38.1868, 52.7368, 54.3924,\n",
       "                        3.6088, 64.9561, 36.4023, 15.0502, 40.6238, 54.7768, 29.0203, 38.0345,\n",
       "                       65.5473, 53.0213, 29.6840, 11.6785, 36.9148, 31.7697, 59.0567, 56.0098,\n",
       "                       53.6699, 58.3168, 48.9750, 37.4606, 42.3741, 51.5572, 94.3404, 24.0388,\n",
       "                       25.0426, 38.1994, 50.9014, 22.3653, 39.0551, 24.0783, 40.2843, 49.7629,\n",
       "                       37.6483,  3.2578, 38.6164, 40.2132, 63.3210, 47.4026, 42.1460, 22.7260,\n",
       "                       44.6575, 34.8594, 43.7083, 44.9351, 45.3688, 48.0210, 33.4751, 45.1288,\n",
       "                       53.3950, 32.8214, 57.7978, 36.8290, 41.1461, 38.3068, 33.7378, 57.2282,\n",
       "                       33.2330, 48.1275, 42.6299, 27.8076, 46.1160, 46.7283, 42.1512, 28.0513,\n",
       "                       57.9283, 39.8380, 43.2196,  3.5073, 28.0107, 46.1415, 68.1599, 48.5282,\n",
       "                       56.3766, 35.8305, 39.1425, 44.9112, 59.0459, 36.1491, 35.4118, 41.4488,\n",
       "                       45.1702, 27.1920, 49.6938, 47.7060, 31.0848, 15.4609, 26.2254, 29.7920,\n",
       "                       23.0079, 73.6208, 41.7077, 37.2194,  2.4906, 26.4361,  8.6566, 37.1917,\n",
       "                       42.9030, 79.9636, 34.5892, 25.0802, 57.8477, 48.7814, 38.4691, 44.0872,\n",
       "                       38.7179, 67.8061, 36.7731, 20.4657, 46.1175, 40.5765, 36.2589, 49.1754,\n",
       "                       39.0490, 35.3677, 44.1855, 75.3239, 30.7163, 40.1691, 43.4779, 36.5468,\n",
       "                       39.9022, 23.8207, 47.7200, 35.6861, 49.6604, 36.0345, 42.3438, 26.6729,\n",
       "                       38.3238, 25.3345, 33.1475, 36.2977, 30.7630, 33.7805, 52.9490, 27.6904,\n",
       "                       37.3234, 65.8518, 69.2531, 35.1666, 37.9871, 40.7733, 24.8778, 32.4508,\n",
       "                       39.5215, 46.5822, 29.6104, 39.9276, 35.4048, 68.5465, 58.7924, 26.3959,\n",
       "                       44.8660, 41.4652, 37.1311, 36.3811, 38.8422, 38.1316, 46.0219, 37.1965,\n",
       "                       53.9513, 32.3594, 31.7732, 46.6417, 45.2628,  7.0563, 49.5439, 32.8643,\n",
       "                        3.0042, 29.8262, 41.4070, 42.1796, 28.3282, 47.5921, 33.2856, 51.8637,\n",
       "                       34.3875, 31.0627, 32.7539, 48.3618, 42.0343, 42.5362, 42.4494, 46.9895],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block4.conv1.weight',\n",
       "               tensor([[[[-2.8117e-01, -1.9448e-01, -3.2072e-01],\n",
       "                         [ 1.6667e-01,  7.5469e-03, -1.2761e-01],\n",
       "                         [ 1.5804e-01,  1.4452e-01,  5.4735e-03]],\n",
       "               \n",
       "                        [[ 5.7425e-03, -1.6190e-02, -4.9775e-01],\n",
       "                         [ 6.9577e-02,  3.7016e-02, -2.2179e-01],\n",
       "                         [-2.1399e-01, -1.8292e-01, -2.7259e-01]],\n",
       "               \n",
       "                        [[-3.2275e-02,  6.3697e-02,  3.6232e-02],\n",
       "                         [-1.0834e-02,  2.3389e-01, -1.6246e-02],\n",
       "                         [ 1.3494e-01,  1.3342e-01, -1.4910e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.0493e-01,  6.6150e-03,  9.4810e-02],\n",
       "                         [ 7.5323e-02, -8.4515e-02, -2.6031e-01],\n",
       "                         [-4.4923e-02,  1.3767e-01, -1.3903e-02]],\n",
       "               \n",
       "                        [[ 5.8768e-02,  3.0249e-03,  1.2129e-01],\n",
       "                         [-1.4058e-02, -1.4894e-02,  1.1285e-01],\n",
       "                         [ 7.8302e-02, -5.2702e-03,  1.2461e-01]],\n",
       "               \n",
       "                        [[-2.8437e-02, -1.5080e-01, -1.7280e-02],\n",
       "                         [ 2.3192e-01, -1.1718e-02, -4.4942e-02],\n",
       "                         [ 6.1271e-01,  2.4129e-01,  1.4843e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8397e-01,  1.0231e-01, -3.6553e-04],\n",
       "                         [ 3.4619e-01,  2.6139e-01,  2.4499e-01],\n",
       "                         [ 3.5390e-01,  2.8168e-01,  3.8342e-01]],\n",
       "               \n",
       "                        [[ 8.4976e-02,  2.6384e-01,  9.5468e-02],\n",
       "                         [-2.7714e-02, -2.2332e-02, -4.8102e-02],\n",
       "                         [-1.7257e-01,  6.8492e-02,  1.0205e-01]],\n",
       "               \n",
       "                        [[-2.5342e-02, -1.5528e-02, -6.1688e-02],\n",
       "                         [-2.7608e-02, -2.5081e-02, -6.0266e-02],\n",
       "                         [ 6.7514e-04, -1.2479e-03, -4.8764e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2393e-01, -9.4306e-02, -1.9476e-01],\n",
       "                         [ 5.8398e-03, -7.9925e-02, -4.1517e-01],\n",
       "                         [-5.0327e-02, -1.9655e-01, -1.1735e-01]],\n",
       "               \n",
       "                        [[ 2.7297e-01, -4.6044e-02,  2.8592e-02],\n",
       "                         [ 7.4112e-01, -5.0212e-02, -1.0976e-01],\n",
       "                         [ 6.0514e-01, -6.1636e-02,  1.5829e-01]],\n",
       "               \n",
       "                        [[-8.9858e-02, -1.4299e-01, -8.8171e-02],\n",
       "                         [-2.7729e-02, -5.3546e-02,  1.1596e-03],\n",
       "                         [ 1.9970e-01,  5.9318e-02,  1.9625e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.5145e-02, -7.8992e-02, -2.5136e-02],\n",
       "                         [-4.0007e-02, -3.4993e-02, -4.9632e-02],\n",
       "                         [ 2.2835e-02, -8.2773e-02, -1.4480e-01]],\n",
       "               \n",
       "                        [[ 8.8546e-02, -1.3631e-03,  7.4954e-05],\n",
       "                         [ 2.7300e-02, -2.4629e-02, -6.8863e-02],\n",
       "                         [ 9.9173e-02,  2.9239e-02, -1.0297e-02]],\n",
       "               \n",
       "                        [[ 1.6983e-02,  3.6542e-03, -6.4787e-02],\n",
       "                         [ 9.0322e-02,  2.4170e-02, -5.2050e-02],\n",
       "                         [ 6.6579e-02,  4.9823e-02, -2.5309e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.4695e-02,  4.1721e-02, -5.1636e-02],\n",
       "                         [-6.5091e-02, -4.3530e-02, -1.4238e-01],\n",
       "                         [-5.6960e-02, -3.9052e-02, -1.4414e-01]],\n",
       "               \n",
       "                        [[ 1.1531e-02,  5.8840e-02,  4.7447e-02],\n",
       "                         [ 6.2048e-02,  1.1637e-01,  5.8397e-02],\n",
       "                         [ 5.2231e-03, -4.5418e-03, -3.0628e-02]],\n",
       "               \n",
       "                        [[ 5.5873e-03,  3.9302e-02, -1.9303e-02],\n",
       "                         [-8.0556e-02,  4.2154e-03, -8.2461e-02],\n",
       "                         [-1.3790e-01, -1.9746e-02, -1.8784e-01]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-1.5198e-01, -3.6075e-02, -1.4837e-01],\n",
       "                         [-2.3885e-01, -2.8460e-02, -1.0875e-01],\n",
       "                         [-1.4545e-01, -7.0426e-02, -6.8133e-02]],\n",
       "               \n",
       "                        [[-5.5952e-02, -4.0911e-02, -3.3310e-02],\n",
       "                         [-1.7451e-01, -8.7108e-02,  1.2693e-02],\n",
       "                         [-7.0759e-02, -4.8385e-02, -3.3718e-03]],\n",
       "               \n",
       "                        [[ 2.9875e-02,  6.5026e-03, -1.0522e-01],\n",
       "                         [ 9.7180e-02,  5.2470e-02, -5.8483e-02],\n",
       "                         [ 1.0137e-02,  2.4127e-02, -2.8789e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.7989e-02,  1.1075e-01,  9.5427e-02],\n",
       "                         [ 2.2058e-02,  4.7560e-02,  4.7533e-02],\n",
       "                         [-1.4979e-02, -4.1187e-02, -8.4268e-03]],\n",
       "               \n",
       "                        [[-5.8950e-03, -4.3256e-02, -1.0115e-01],\n",
       "                         [-4.2977e-02,  7.3435e-04, -1.7013e-02],\n",
       "                         [-1.0561e-01, -1.1956e-01, -4.2652e-02]],\n",
       "               \n",
       "                        [[-3.0934e-02, -1.9715e-02, -4.4373e-02],\n",
       "                         [ 1.9279e-01,  1.6256e-01,  1.3915e-01],\n",
       "                         [ 4.7260e-02,  1.3291e-01, -8.4166e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.3602e-02,  2.0539e-02,  1.2633e-01],\n",
       "                         [-2.9732e-02,  6.9290e-02,  1.5418e-01],\n",
       "                         [ 7.1638e-02,  9.3394e-02,  1.5287e-01]],\n",
       "               \n",
       "                        [[-1.8831e-02,  1.6386e-02, -3.7939e-02],\n",
       "                         [-5.5418e-02,  3.2672e-03, -3.0469e-02],\n",
       "                         [ 1.9739e-03,  4.9307e-02, -2.8697e-02]],\n",
       "               \n",
       "                        [[ 1.1110e-02, -9.3922e-03, -1.0620e-01],\n",
       "                         [ 5.1250e-02,  4.8479e-02, -1.5916e-01],\n",
       "                         [ 2.6691e-02,  6.9313e-02, -1.7979e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.3847e-02, -1.4713e-02, -1.0052e-01],\n",
       "                         [ 1.9321e-02,  8.7875e-03, -5.4893e-02],\n",
       "                         [ 3.4401e-02,  1.7562e-02,  1.9163e-02]],\n",
       "               \n",
       "                        [[-1.8030e-04,  7.7708e-02,  1.5777e-01],\n",
       "                         [ 1.7430e-02,  5.9972e-02,  1.0575e-01],\n",
       "                         [-6.3385e-03,  6.1964e-02,  2.0596e-01]],\n",
       "               \n",
       "                        [[ 4.0382e-02,  1.6917e-01,  1.4179e-01],\n",
       "                         [ 6.5023e-02,  7.9723e-02,  1.8729e-01],\n",
       "                         [ 4.7586e-02,  1.4556e-01,  8.0061e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9561e-02,  1.6063e-02,  4.5139e-02],\n",
       "                         [-1.0781e-01, -1.5374e-02,  8.8728e-05],\n",
       "                         [-4.4376e-02,  5.6114e-03,  6.6437e-02]],\n",
       "               \n",
       "                        [[-2.1091e-02,  1.9502e-03, -5.8937e-02],\n",
       "                         [-4.3717e-02, -4.9178e-03, -1.5190e-01],\n",
       "                         [ 6.7578e-02,  5.1915e-02,  2.1604e-02]],\n",
       "               \n",
       "                        [[ 2.7038e-03, -4.4696e-02, -8.6027e-02],\n",
       "                         [ 8.1351e-02,  3.4863e-02, -1.7840e-01],\n",
       "                         [ 3.4614e-02,  3.6288e-02, -1.2641e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.3675e-03,  1.8449e-02, -4.5892e-02],\n",
       "                         [ 3.9285e-02,  1.1169e-02, -4.6597e-02],\n",
       "                         [ 1.1016e-02, -1.7599e-02, -4.0958e-02]],\n",
       "               \n",
       "                        [[ 1.7124e-02,  4.0852e-02,  7.1878e-02],\n",
       "                         [ 1.9256e-02,  2.0039e-02,  6.9166e-02],\n",
       "                         [ 8.0109e-02,  1.0178e-01,  1.2642e-01]],\n",
       "               \n",
       "                        [[-1.3671e-02,  2.6154e-02, -1.1227e-03],\n",
       "                         [-5.0951e-02,  1.0144e-02, -8.1067e-02],\n",
       "                         [-4.0022e-02, -1.2864e-02, -1.0272e-01]]]], device='cuda:0')),\n",
       "              ('conv_block4.conv2.weight',\n",
       "               tensor([[[[-1.3141e-01, -1.7014e-01, -3.1536e-01],\n",
       "                         [ 1.4788e-04, -1.2086e-01, -3.0856e-01],\n",
       "                         [-5.1835e-02, -1.7605e-01, -3.0941e-01]],\n",
       "               \n",
       "                        [[-1.5246e-01, -1.2831e-01, -4.4812e-02],\n",
       "                         [-1.6314e-01, -1.2917e-01, -7.5320e-02],\n",
       "                         [-1.5122e-01, -1.1717e-01, -1.5710e-01]],\n",
       "               \n",
       "                        [[-5.3818e-02, -5.1342e-02, -1.5757e-01],\n",
       "                         [-7.5635e-02, -9.9171e-02, -2.1828e-01],\n",
       "                         [-1.0729e-03, -1.0431e-01, -2.2602e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.4321e-02, -2.2552e-02, -8.8848e-02],\n",
       "                         [-2.5956e-02, -3.5327e-02, -1.3773e-01],\n",
       "                         [ 8.9133e-03,  3.0740e-03, -1.0050e-01]],\n",
       "               \n",
       "                        [[ 6.3828e-02,  1.4987e-05, -3.2330e-02],\n",
       "                         [ 1.6951e-03, -2.7668e-02, -1.7322e-01],\n",
       "                         [-6.9142e-03, -5.0586e-02, -1.9127e-01]],\n",
       "               \n",
       "                        [[-3.0931e-02, -6.4165e-02, -1.4262e-01],\n",
       "                         [-5.3583e-02, -1.3207e-01, -2.6642e-01],\n",
       "                         [-4.2838e-02, -6.4026e-02, -2.8391e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 9.9623e-02, -6.3867e-02,  2.5452e-02],\n",
       "                         [ 1.1098e-01, -3.8810e-02,  1.3309e-01],\n",
       "                         [ 1.2145e-01, -2.1395e-02,  1.1927e-01]],\n",
       "               \n",
       "                        [[ 2.8668e-01,  1.7305e-02,  8.8408e-02],\n",
       "                         [ 2.5384e-01, -1.9117e-01, -2.0238e-01],\n",
       "                         [ 2.4004e-01, -2.0833e-01, -1.6091e-01]],\n",
       "               \n",
       "                        [[-2.6671e-02, -1.1001e-01,  3.0393e-02],\n",
       "                         [ 4.0007e-04, -1.1037e-01,  4.0861e-03],\n",
       "                         [-1.8974e-02, -1.4899e-01,  2.3437e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.5335e-02, -6.9298e-02, -4.2384e-03],\n",
       "                         [-3.2748e-02, -7.9837e-02, -3.2012e-02],\n",
       "                         [-9.6534e-02, -1.6497e-01, -8.8456e-02]],\n",
       "               \n",
       "                        [[-1.4191e-02, -5.7730e-02,  7.7663e-02],\n",
       "                         [-1.6944e-02, -1.2329e-01,  6.6457e-02],\n",
       "                         [-3.9793e-02, -5.5077e-02,  1.8633e-02]],\n",
       "               \n",
       "                        [[-4.3596e-02, -1.3971e-01,  1.0534e-02],\n",
       "                         [-4.4777e-02, -1.0370e-01,  2.5256e-02],\n",
       "                         [-2.9126e-02, -1.2420e-01,  1.6884e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2084e-01, -6.4760e-02,  1.3030e-01],\n",
       "                         [-1.3044e-01, -2.5075e-02,  1.6151e-02],\n",
       "                         [-8.7644e-02,  1.5531e-03,  1.7084e-02]],\n",
       "               \n",
       "                        [[ 1.0630e-01,  6.8825e-02,  1.0841e-01],\n",
       "                         [ 6.3294e-02,  5.6313e-02,  9.1738e-02],\n",
       "                         [-8.5978e-02,  4.0142e-03,  4.2442e-02]],\n",
       "               \n",
       "                        [[-7.9506e-02, -5.3952e-01, -4.3850e-02],\n",
       "                         [-1.0070e-01, -6.0278e-01, -6.0825e-02],\n",
       "                         [-4.1294e-02, -4.5038e-01, -5.5793e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.0779e-02, -9.0226e-03,  3.3375e-03],\n",
       "                         [ 8.1960e-04, -7.6463e-02, -3.6247e-02],\n",
       "                         [ 1.9942e-02, -4.3963e-02, -3.7640e-02]],\n",
       "               \n",
       "                        [[-4.5117e-02, -9.3657e-02, -1.9836e-03],\n",
       "                         [-5.8529e-02, -8.0018e-02, -3.1515e-02],\n",
       "                         [-1.2475e-02, -7.1371e-02, -4.3010e-03]],\n",
       "               \n",
       "                        [[-5.3049e-02, -1.5731e-01, -2.5275e-02],\n",
       "                         [-5.1301e-02, -2.0356e-01, -2.3456e-02],\n",
       "                         [-2.6011e-02, -1.6314e-01, -5.0286e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.3632e-03, -1.2925e-02,  6.8488e-04],\n",
       "                         [-9.8775e-02, -8.1714e-02, -3.4547e-02],\n",
       "                         [-1.1710e-02, -7.6958e-02, -6.0914e-02]],\n",
       "               \n",
       "                        [[-1.0509e-01, -1.0036e-01, -3.5899e-02],\n",
       "                         [-1.3978e-01, -1.4804e-01, -3.0534e-02],\n",
       "                         [-1.9116e-01, -1.2482e-01, -7.7175e-02]],\n",
       "               \n",
       "                        [[ 1.0296e-02, -6.9565e-02,  7.9738e-02],\n",
       "                         [ 2.8699e-02, -1.6072e-01,  6.3567e-02],\n",
       "                         [ 1.6107e-02, -1.5727e-01,  4.8203e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.1035e-02, -1.2945e-01,  1.2868e-02],\n",
       "                         [-1.6226e-01, -2.2084e-01, -4.9709e-03],\n",
       "                         [-2.6686e-02, -8.8472e-02,  4.4570e-02]],\n",
       "               \n",
       "                        [[-5.2616e-03, -5.7111e-02,  5.4005e-02],\n",
       "                         [-2.7419e-02, -9.5018e-02,  4.9039e-02],\n",
       "                         [-2.7858e-04, -2.4506e-02,  3.1993e-02]],\n",
       "               \n",
       "                        [[-3.8276e-02, -7.3607e-02, -9.0714e-03],\n",
       "                         [-5.5761e-02, -1.2196e-01,  4.7025e-03],\n",
       "                         [-1.7847e-02, -1.2619e-01,  4.5440e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.4819e-02, -1.4828e-01, -1.0668e-01],\n",
       "                         [ 4.5886e-02,  2.8900e-02,  4.0922e-02],\n",
       "                         [ 1.8913e-03,  2.3505e-02,  1.6824e-01]],\n",
       "               \n",
       "                        [[ 1.5831e-01,  1.1025e-01,  3.2725e-01],\n",
       "                         [ 3.3227e-01,  2.0414e-01,  3.9934e-01],\n",
       "                         [ 3.2118e-01,  2.7469e-01,  3.1816e-01]],\n",
       "               \n",
       "                        [[ 4.3839e-03, -1.8127e-01,  3.0586e-02],\n",
       "                         [-5.1334e-02, -2.2614e-01,  6.0986e-02],\n",
       "                         [-9.7718e-03, -2.2800e-01,  7.6102e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.9273e-02, -9.4798e-02, -1.8765e-02],\n",
       "                         [ 2.7452e-02, -1.2884e-01, -6.5547e-03],\n",
       "                         [-1.1060e-01, -2.2181e-01, -8.4998e-02]],\n",
       "               \n",
       "                        [[-1.2539e-02, -9.0758e-02,  3.2262e-02],\n",
       "                         [-2.7983e-02, -1.2655e-01,  1.7510e-03],\n",
       "                         [-7.8804e-03, -1.0630e-01,  3.6500e-02]],\n",
       "               \n",
       "                        [[-4.5780e-02, -1.7082e-01,  3.4723e-02],\n",
       "                         [-4.5897e-02, -2.2459e-01, -1.2138e-02],\n",
       "                         [-5.9276e-02, -1.9904e-01, -7.6359e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 6.4527e-02,  2.3626e-03,  3.5323e-02],\n",
       "                         [ 5.2964e-02,  8.6002e-03,  9.5076e-02],\n",
       "                         [ 2.5534e-01,  2.2776e-01,  6.3691e-01]],\n",
       "               \n",
       "                        [[-3.1473e-01, -1.5584e-01, -2.4066e-01],\n",
       "                         [-5.6614e-01, -2.5919e-01, -4.8721e-01],\n",
       "                         [-4.7625e-01, -4.3592e-01, -5.6699e-01]],\n",
       "               \n",
       "                        [[-8.0138e-02, -2.7227e-01, -3.8287e-03],\n",
       "                         [-8.9857e-02, -3.3922e-01, -7.3446e-03],\n",
       "                         [-8.2277e-02, -2.2914e-01, -2.5482e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.4436e-02, -1.6535e-01, -6.6169e-02],\n",
       "                         [-1.0076e-01, -1.9541e-01, -2.1543e-02],\n",
       "                         [-4.8573e-02, -2.3831e-01, -7.6474e-02]],\n",
       "               \n",
       "                        [[-6.5030e-02, -1.0340e-01, -1.7654e-02],\n",
       "                         [-4.2388e-02, -9.1843e-02, -4.4946e-02],\n",
       "                         [-5.0771e-02, -9.4325e-02, -3.5689e-02]],\n",
       "               \n",
       "                        [[-1.0607e-01, -1.3761e-01, -1.6891e-01],\n",
       "                         [-7.1688e-02, -1.0667e-01, -9.9844e-02],\n",
       "                         [-6.6565e-02, -1.0376e-01, -2.3241e-02]]]], device='cuda:0')),\n",
       "              ('conv_block4.bn1.weight',\n",
       "               tensor([1.0171, 0.5798, 0.5005, 0.9467, 0.4131, 0.9769, 0.4462, 1.0130, 0.9361,\n",
       "                       1.1435, 1.0755, 0.8172, 1.2160, 1.1708, 0.8326, 1.0605, 1.3565, 1.1408,\n",
       "                       0.9933, 1.1301, 1.0148, 1.1272, 0.9770, 0.5058, 0.8135, 0.6770, 1.1596,\n",
       "                       1.0459, 1.0975, 1.0943, 1.0097, 0.8133, 1.1153, 0.8899, 1.0428, 1.2536,\n",
       "                       0.9832, 0.6203, 0.9139, 0.8731, 0.6918, 1.1260, 0.2733, 1.0130, 1.0926,\n",
       "                       1.0720, 1.1631, 1.1839, 0.5973, 1.1405, 1.1763, 0.9800, 1.0225, 1.0436,\n",
       "                       0.8502, 1.1530, 0.9835, 1.3239, 0.6362, 0.9547, 0.8648, 0.7036, 0.9891,\n",
       "                       0.8956, 0.6684, 1.0972, 0.9076, 0.6384, 0.8603, 1.0418, 0.8226, 0.9889,\n",
       "                       0.4692, 0.4991, 0.8975, 0.8536, 1.2099, 0.9635, 1.1211, 1.0741, 1.1748,\n",
       "                       1.0328, 0.9639, 0.8464, 0.9222, 0.8646, 0.9812, 1.0259, 0.9026, 1.0985,\n",
       "                       1.3200, 1.3520, 0.8091, 0.8493, 1.0194, 0.5287, 0.9658, 0.9977, 0.9788,\n",
       "                       1.3655, 0.4898, 0.7785, 0.9938, 0.4714, 0.3356, 0.9735, 0.8762, 0.8690,\n",
       "                       1.3053, 0.7439, 0.7643, 0.6878, 1.0019, 1.0641, 1.0696, 1.1539, 1.1049,\n",
       "                       0.8718, 1.3012, 0.9538, 0.9531, 0.5643, 1.0746, 0.9723, 0.8656, 1.3475,\n",
       "                       0.9380, 0.8953, 1.3727, 0.4535, 1.1457, 0.6542, 1.0409, 1.0981, 0.9023,\n",
       "                       1.1144, 1.0815, 1.2134, 0.8978, 0.9925, 0.8624, 1.0421, 1.3380, 1.1504,\n",
       "                       0.9870, 0.4670, 1.0330, 1.1302, 1.1419, 1.2744, 1.2785, 1.2513, 1.0941,\n",
       "                       1.1802, 1.2290, 1.3752, 0.9396, 0.9662, 0.9707, 1.0778, 0.3860, 0.9183,\n",
       "                       1.1586, 0.8619, 0.6188, 1.1147, 1.3675, 1.0019, 1.1476, 1.0775, 1.0792,\n",
       "                       1.1930, 0.9706, 0.9071, 0.9174, 0.9868, 0.7037, 0.7321, 0.8768, 1.0496,\n",
       "                       0.9915, 1.0660, 0.8966, 0.9964, 0.8852, 1.2159, 1.1580, 0.7111, 0.4730,\n",
       "                       1.0353, 1.0192, 0.8928, 1.2706, 1.4263, 0.9980, 0.3532, 0.4918, 0.9829,\n",
       "                       0.7474, 1.0839, 0.5446, 1.0956, 1.0380, 1.0943, 1.0517, 0.7094, 1.0557,\n",
       "                       0.6625, 1.1248, 1.0023, 1.5281, 1.3572, 1.0759, 0.7746, 1.2011, 1.1546,\n",
       "                       0.5964, 0.9852, 0.8495, 0.9046, 0.9232, 1.2807, 0.5028, 0.9053, 1.1093,\n",
       "                       1.2315, 1.0267, 1.0194, 1.2623, 0.9689, 1.0482, 1.0786, 0.8586, 0.4864,\n",
       "                       1.2161, 1.0685, 1.0953, 0.9853, 0.8778, 1.0397, 1.2730, 0.9377, 1.2230,\n",
       "                       0.9753, 1.0981, 0.5209, 0.9376, 0.6086, 0.4151, 0.7702, 0.9797, 1.2388,\n",
       "                       1.0349, 0.9509, 0.8632, 1.2876, 1.6126, 1.1258, 0.4149, 1.0089, 1.0519,\n",
       "                       0.8221, 1.2245, 1.0256, 1.0461, 0.9651, 0.8645, 1.0192, 1.0774, 1.0158,\n",
       "                       1.1035, 0.9729, 1.2657, 1.1162, 1.0492, 0.8497, 1.1300, 1.0705, 0.9149,\n",
       "                       0.5904, 0.9442, 1.1462, 0.9009, 1.3760, 0.4095, 1.0837, 1.2117, 0.5813,\n",
       "                       1.1220, 1.3137, 0.5588, 1.1104, 0.7647, 0.8270, 1.7138, 1.0442, 0.9528,\n",
       "                       1.1511, 0.8160, 1.0942, 1.2062, 1.0723, 0.9839, 1.4398, 1.0917, 1.1048,\n",
       "                       1.0294, 1.0739, 1.1939, 1.0529, 1.0129, 1.0052, 1.4338, 1.0208, 0.9004,\n",
       "                       1.1145, 0.8237, 1.2433, 0.9026, 1.0068, 1.1364, 0.9539, 0.7693, 1.0401,\n",
       "                       1.3652, 0.4287, 1.0163, 0.9942, 1.1042, 0.4577, 0.9942, 0.9551, 0.9146,\n",
       "                       1.0011, 1.1516, 0.9862, 0.7260, 1.1630, 1.0532, 0.9281, 0.9433, 0.6011,\n",
       "                       0.6257, 1.1354, 0.9504, 0.9805, 0.9760, 0.9792, 0.4477, 0.7953, 0.9629,\n",
       "                       0.8023, 1.1022, 1.1797, 0.8836, 1.0323, 0.5699, 1.0605, 1.1273, 1.0621,\n",
       "                       0.7290, 0.9571, 0.8671, 0.6478, 0.3853, 0.9439, 0.8821, 0.8617, 0.4659,\n",
       "                       1.0389, 0.3590, 1.1582, 0.9726, 1.0988, 1.0964, 0.8692, 1.2900, 0.8554,\n",
       "                       1.1174, 0.9015, 0.9937, 1.2691, 0.9923, 0.9630, 1.0504, 0.7922, 0.5388,\n",
       "                       1.0412, 1.0914, 0.9493, 1.1033, 0.9571, 0.9168, 0.9361, 1.1429, 0.4560,\n",
       "                       1.0962, 1.0570, 0.6944, 1.0913, 1.0084, 0.9310, 0.8042, 0.9676, 1.1645,\n",
       "                       1.0108, 0.9704, 0.8509, 0.8505, 0.9832, 0.9930, 1.0751, 0.9806, 1.0307,\n",
       "                       1.1843, 1.0450, 0.8979, 0.8262, 0.7724, 0.8858, 0.9827, 1.0757, 1.1863,\n",
       "                       0.9124, 0.8604, 1.0140, 1.1726, 0.8133, 0.9450, 0.7757, 0.9359, 0.8902,\n",
       "                       0.4347, 0.8054, 0.9967, 0.8918, 1.1201, 0.8330, 1.3714, 0.6347, 0.6996,\n",
       "                       0.9285, 0.9511, 1.2236, 1.0164, 0.8717, 1.0107, 1.2076, 0.9399, 1.1091,\n",
       "                       0.9706, 1.1365, 1.0346, 1.1798, 1.2603, 1.0090, 0.9313, 0.8644, 1.0968,\n",
       "                       0.7437, 1.1048, 1.1171, 0.9892, 0.9939, 1.4142, 1.0721, 1.1209, 1.0621,\n",
       "                       1.1425, 0.8798, 1.1274, 0.9831, 1.0430, 0.9428, 0.3956, 0.9816, 1.0278,\n",
       "                       0.9393, 0.9891, 1.3775, 1.0050, 0.8539, 0.9556, 1.1961, 1.1283, 1.0901,\n",
       "                       0.9547, 1.0527, 1.6421, 1.0322, 1.0283, 0.7542, 0.9550, 1.1278, 0.9013,\n",
       "                       1.0847, 1.1320, 0.8843, 1.1033, 1.0025, 1.0018, 1.0766, 0.2731, 1.0976,\n",
       "                       1.3175, 1.2517, 1.0063, 1.2144, 1.1150, 0.8921, 0.4834, 0.4870],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.bias',\n",
       "               tensor([-0.9268, -0.6266, -0.5309, -0.6357, -0.5046, -1.1536, -0.5173, -1.4939,\n",
       "                       -0.7832, -1.5075, -0.6342, -0.5730, -1.1893, -1.1652, -0.7942, -1.0887,\n",
       "                       -1.3104, -1.3070, -0.8438, -1.5253, -0.9678, -1.0071, -0.9260, -0.5962,\n",
       "                       -1.2304, -0.2258, -0.6201, -0.8741, -0.9973, -0.2882, -1.0181, -0.0473,\n",
       "                       -1.2342, -0.8188, -0.9273, -1.0032, -1.1131, -0.5810, -0.9244, -0.8191,\n",
       "                       -0.4738, -0.7664, -0.1053, -1.1785, -1.2238, -1.2519, -1.0774, -1.7462,\n",
       "                       -1.2521, -1.0098, -1.3732, -1.0013, -0.9384, -0.9089, -0.7262, -1.2270,\n",
       "                       -1.0483, -1.5191, -0.4390, -1.0361, -0.8670, -0.8597, -1.4813, -0.6777,\n",
       "                       -0.4823, -1.1131, -0.8683, -0.1681, -0.6160, -1.1000, -0.6691, -0.6610,\n",
       "                        0.1074, -0.4299, -0.8592, -0.8151, -1.7040, -1.0895, -0.9872, -1.5288,\n",
       "                       -1.1496, -0.6807, -0.8016, -0.7891, -0.9479, -0.6210, -1.0759, -1.1950,\n",
       "                       -0.9956, -1.2665, -1.5158, -1.7583, -0.7382, -0.5999, -0.9451, -0.5500,\n",
       "                       -1.0278, -0.6882, -1.0760, -1.4877, -0.7106, -0.9699, -1.1468, -0.5725,\n",
       "                       -0.2269, -1.4250, -0.7481, -0.9016, -1.3545, -0.4090, -0.5920, -0.7844,\n",
       "                       -1.2422, -1.0947, -1.3283, -1.2184, -1.1426, -0.8193, -1.3204, -0.8605,\n",
       "                       -0.7378, -0.5170, -1.3469, -1.0916, -0.9371, -1.4747, -1.0785, -1.3800,\n",
       "                       -1.3396, -0.4237, -1.3274, -0.8327, -0.8605, -1.2755, -0.9883, -1.0643,\n",
       "                       -1.1332, -1.2407, -1.0683, -0.9353, -0.8443, -1.0549, -1.1899, -1.0002,\n",
       "                       -1.4368, -0.4605, -0.8931, -1.3795, -1.1537, -1.2295, -1.5573, -1.3294,\n",
       "                       -1.2111, -1.4382, -1.0037, -1.4445, -0.7545, -1.1937, -1.0555, -0.8604,\n",
       "                       -0.3483, -0.8547, -1.4832, -0.9992, -0.6245, -1.1271, -1.8393, -0.8570,\n",
       "                       -1.1873, -0.9002, -1.1650, -1.4616, -1.0966, -1.0338, -0.8798, -1.0539,\n",
       "                       -0.5295, -0.5991, -0.5281, -1.1401, -1.3800, -1.1607, -1.0025, -0.7102,\n",
       "                       -0.9779, -1.1512, -1.1975, -0.7246, -0.4748, -0.9941, -0.7571, -0.8653,\n",
       "                       -1.4647, -1.8294, -0.6385, -0.2421, -0.4240, -0.7561, -0.7323, -1.0429,\n",
       "                       -0.5567, -0.7589, -0.8982, -1.1422, -1.3670, -0.8966, -0.7570, -0.8501,\n",
       "                       -1.4752, -1.3566, -1.5417, -1.3120, -1.4789, -0.8098, -1.1903, -1.1919,\n",
       "                       -0.5641, -1.0068, -0.6368, -1.1082, -0.6602, -1.2209, -0.5706, -0.8450,\n",
       "                       -1.4457, -1.1181, -0.5517, -1.0157, -1.0188, -1.3320, -1.1227, -0.8480,\n",
       "                       -0.9637, -0.3996, -1.1952, -1.4615, -1.0471, -0.8518, -1.3566, -1.1436,\n",
       "                       -1.2017, -0.7486, -1.5245, -0.9609, -1.2642, -0.4812, -1.1266, -0.8732,\n",
       "                       -0.4258, -0.7096, -0.8881, -1.1568, -1.1495, -1.0584, -0.5065, -2.0450,\n",
       "                       -1.8439, -1.0001, -0.4478, -1.3064, -1.2587, -0.7340, -0.7342, -0.9460,\n",
       "                       -1.0269, -0.9412, -0.7271, -0.9116, -0.7955, -1.3599, -1.3335, -1.3596,\n",
       "                       -2.0832, -1.4160, -0.9864, -0.7417, -0.7941, -1.4409, -0.8184, -0.5528,\n",
       "                       -0.7167, -1.1789, -0.8158, -1.4325, -0.2628, -1.1581, -1.9050, -0.4080,\n",
       "                       -1.2944, -1.1235, -0.6202, -1.1652, -0.9671, -1.1774, -1.8213, -0.8847,\n",
       "                       -0.6611, -1.5906, -0.7409, -1.0386, -1.0712, -1.1633, -1.0001, -1.3512,\n",
       "                       -0.9485, -1.2225, -1.0768, -1.1959, -1.0779, -1.0752, -1.1522, -0.9081,\n",
       "                       -1.0947, -0.8541, -0.9721, -1.3169, -0.8332, -1.1959, -0.8614, -1.2096,\n",
       "                       -1.2910, -1.3517, -0.7324, -0.7874, -1.2204, -0.3987, -1.2808, -1.0477,\n",
       "                       -1.0734, -0.4106, -0.8290, -0.8418, -1.1694, -1.0074, -1.2381, -1.2645,\n",
       "                       -0.4686, -0.9527, -0.7772, -0.9946, -0.5623, -0.7630, -0.8910, -1.0892,\n",
       "                       -0.8300, -0.9807, -0.9775, -1.3635, -0.4377, -0.6563, -1.3178, -0.7624,\n",
       "                       -1.1922, -1.3888, -1.3011, -0.8241, -0.6315, -1.0948, -1.0740, -1.1862,\n",
       "                       -1.2401, -0.8922, -0.8188, -0.4529, -0.3196, -0.9116, -0.5977, -0.7753,\n",
       "                       -0.3463, -0.9359, -0.2351, -1.1351, -0.8505, -1.2622, -0.8808, -0.8275,\n",
       "                       -1.4604, -0.6374, -0.9875, -0.5543, -0.9385, -1.4324, -1.0252, -0.7666,\n",
       "                       -1.3167, -0.6675, -0.3785, -0.6188, -1.1109, -0.7665, -0.6459, -1.3750,\n",
       "                       -0.9565, -0.8162, -1.1617, -0.2942, -1.1032, -0.9313, -0.6704, -0.9382,\n",
       "                       -1.4996, -0.6677, -0.9241, -0.9116, -1.5874, -1.2366, -0.9990, -0.7313,\n",
       "                       -0.6550, -0.9268, -0.9094, -1.2075, -0.7507, -1.5805, -1.3963, -1.1001,\n",
       "                       -0.8197, -0.6291, -0.5572, -0.6652, -1.0816, -1.0449, -1.2613, -0.6382,\n",
       "                       -0.4380, -1.4386, -1.2137, -0.5551, -1.0229, -0.9086, -0.8036, -0.8823,\n",
       "                       -0.4433, -0.5666, -1.3386, -0.8249, -1.0241, -0.9359, -1.3669, -0.1792,\n",
       "                       -0.4910, -0.6613, -0.6006, -1.2904, -1.2362, -0.9800, -0.7748, -0.8731,\n",
       "                       -0.9160, -1.3455, -0.6145, -1.3676, -0.9559, -0.8511, -1.0169, -1.0877,\n",
       "                       -0.6715, -0.8468, -0.9053, -0.6382, -0.7508, -1.1323, -1.2330, -1.0002,\n",
       "                       -1.0657, -1.0172, -1.3319, -1.0393, -1.2256, -0.7244, -1.3001, -1.1020,\n",
       "                       -1.2895, -0.6108, -0.4768, -1.4196, -1.3897, -0.7835, -1.0923, -1.2570,\n",
       "                       -0.9177, -0.8924, -0.9494, -0.8150, -1.1034, -1.1010, -0.7710, -1.2923,\n",
       "                       -1.7607, -0.8246, -1.0299, -0.7357, -0.8449, -1.3700, -0.9031, -1.1970,\n",
       "                       -1.0119, -0.7387, -1.1051, -1.0061, -1.1059, -0.8715, -0.2503, -0.7411,\n",
       "                       -1.5400, -1.4532, -0.8578, -1.6902, -1.4873, -0.8968, -0.5279, -0.5539],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.running_mean',\n",
       "               tensor([-10.9466,  -4.7064,   0.4896, -13.0394,   1.0596,  -5.1966,   2.5946,\n",
       "                        -6.1204,  -4.9037,  -9.0592,  -4.7538,  -7.4809, -10.2353,  -4.2202,\n",
       "                       -11.6675,  -6.0336,  -7.8942,  -5.2304,  -5.9133,  -4.6640,  -6.5091,\n",
       "                        -8.8374,  -5.8615,  -0.1198,  -3.0118,  -5.2285,   3.0720,  -9.0669,\n",
       "                        -8.2644,  -2.2407, -16.7493,  -3.2580,  -6.2603,  -3.2431,  -8.6461,\n",
       "                        -5.1161,  -6.8665,   1.6716,  -2.8061,  -2.2973,  -6.4704,   0.0351,\n",
       "                         1.7752, -12.2334,  -7.8868,  -4.4822,  -6.7287,  -1.5001,  -1.8367,\n",
       "                        -9.2483,  -5.0554,  -7.2483,  -5.0116,  -2.3397,  -5.7115,  -7.1529,\n",
       "                        -4.5376,  -8.3607,  -3.2629,  -4.0760,  -8.0348,  -4.2006,  -6.1257,\n",
       "                        -3.2869,  -1.5678,  -5.3736,  -4.9567,  -0.0239,  -8.7057,  -6.1706,\n",
       "                        -9.4158,  -1.2394,  -0.2976,   2.0511,  -2.4322,  -7.2357,  -5.7281,\n",
       "                        -3.8909,  -6.6181,  -6.5762,  -6.2335,  -7.7848,  -3.6213,  -4.4694,\n",
       "                        -6.5564,  -1.7735,  -6.3409,  -3.5482,  -4.7265,  -9.7434,  -5.2787,\n",
       "                        -4.4089,  -8.5867,  -8.9784,  -8.3622,  -1.1242,  -1.6125,  -6.1353,\n",
       "                        -1.8334,  -6.4470,   1.9517,  -4.0501,  -7.9616,  -0.0614,   1.8526,\n",
       "                        -8.1184,  -7.6924,  -3.5090, -13.9613,  -1.8541,  -6.5741,  -1.1032,\n",
       "                        -7.2868,  -5.5170, -13.6198,  -8.7831,  -6.9043,  -9.8543,  -8.1938,\n",
       "                       -10.9025,  -1.5706,   0.2536,  -6.2698,  -4.7969,  -2.5400,  -6.6330,\n",
       "                        -8.2245,  -8.3690,  -3.3294,   1.4847,  -5.6580,  -0.6512,  -2.6138,\n",
       "                        -5.4812,  -8.3086,  -6.6517,  -0.9511,  -6.5308,  -0.4880, -10.0147,\n",
       "                       -10.0530,  -8.8695,  -8.9923,  -9.2739,  -5.5759,   1.4889,  -5.5971,\n",
       "                        -6.5623,  -6.1954,  -6.9607,  -4.3671, -10.0267,  -6.3242,  -1.5743,\n",
       "                        -5.8862,  -8.4250,  -9.6883,  -0.3161,  -6.0573,  -0.9220,   2.8667,\n",
       "                        -3.4738,  -5.6987,  -4.2769,  -1.2995,  -6.1807, -10.4538, -10.6439,\n",
       "                        -6.4368,  -7.6672,  -6.1779,  -6.6622, -12.6275,  -5.0543, -13.3042,\n",
       "                        -9.2222,  -2.8990,  -1.0521, -10.5863, -12.6526,  -5.7583,  -6.1315,\n",
       "                        -4.1107,  -7.5637,  -8.3993,  -3.6659,  -1.5571,  -5.7016,   0.4822,\n",
       "                        -4.1579,  -4.2678,  -3.1378,  -7.7058,  -5.8783,  -6.5717,   1.4404,\n",
       "                         0.1798,  -6.9300,  -2.0510,  -6.2335,   0.7833,  -5.9191,  -9.1841,\n",
       "                        -3.7911,  -7.2584,  -3.9278,  -5.4451,  -1.0859,  -8.4004,  -4.5896,\n",
       "                        -3.7839,  -2.1272,  -0.8305,  -3.9474,  -5.0292,  -4.3324,   1.6887,\n",
       "                        -5.2468,  -9.3235, -12.2824,  -5.9639,  -6.0610,   1.1145,  -4.4179,\n",
       "                        -6.1781,  -7.4969,  -6.3649,  -8.0785,  -5.8291,  -7.1095,   0.0293,\n",
       "                        -7.3850,  -5.0077,  -4.7580,  -2.4646,  -4.9892,  -6.5832,  -8.1314,\n",
       "                        -3.3271,  -6.9148,  -5.1012,  -6.6263,  -6.5491,  -5.4777,  -4.7112,\n",
       "                        -1.7681,  -2.9845,  -0.6280,   0.6161,  -4.8205,  -5.8634,  -3.7613,\n",
       "                       -12.9779,  -4.8706,  -3.6795,  -3.5789,  -7.1662,  -6.3291,   2.0748,\n",
       "                        -6.3364,  -5.2135,  -5.4410,  -3.6490,  -1.8804,  -6.5819,  -6.4984,\n",
       "                       -11.3954,  -9.8010, -11.5818,  -5.1824,  -4.9084,  -6.3417,  -7.3625,\n",
       "                       -11.8305, -11.8492,  -5.2052,  -3.5223,  -1.8082,  -4.9645,  -1.7844,\n",
       "                        -6.9489,  -7.0825,  -2.0701,  -4.3015,   0.9403,  -7.6335,  -8.7052,\n",
       "                        -0.3232,  -8.0548,  -6.3594,   0.0384, -10.3239,  -5.7635,   1.2717,\n",
       "                       -10.4732,  -6.6686,  -1.0650,  -2.5657,  -9.0322,  -6.0299,  -7.6969,\n",
       "                        -8.4339,  -5.6820,  -6.2278,  -6.9537,  -7.1906,  -9.3338,  -3.2026,\n",
       "                        -0.8080,  -8.3156,  -3.4238,  -6.3102,  -6.0365,  -7.9017,  -6.0254,\n",
       "                        -3.1737,  -3.8924,  -1.3887,  -7.4180,  -8.3821,  -6.3889,   0.2771,\n",
       "                       -13.0124,  -7.0043,  -6.5420,   0.5211, -10.5753,  -4.8199,  -8.8597,\n",
       "                         0.7271,  -6.9438,  -5.8706,  -6.6012, -11.7251,  -9.9602,  -3.5897,\n",
       "                        -3.7250,   1.3409,  -6.2583,  -8.7168,  -4.7366,   0.7047,   0.6778,\n",
       "                        -3.3599,  -5.2760,  -7.6540,  -7.4514,  -5.3712,   0.7601,  -9.1521,\n",
       "                        -4.2634,  -8.8234,  -7.7530,  -2.1752,  -6.7177,  -7.7468,   1.3792,\n",
       "                        -7.6447,  -4.8029, -10.1590,   0.7072,  -6.5925,  -4.7821,  -6.2494,\n",
       "                         2.2727,  -4.8053,  -7.1708,  -1.1976,  -0.4371,  -7.4698,   2.2801,\n",
       "                       -10.9002,  -7.5096,  -6.9487,  -6.1443,  -0.9438, -11.0681,  -5.3732,\n",
       "                        -6.2433,  -3.4355,  -7.4783,  -2.8342,  -2.9182,  -2.5896,  -2.3832,\n",
       "                        -3.8353,   1.1935,  -5.2662,  -8.6400,  -2.4046,  -4.8689,  -6.6092,\n",
       "                        -0.7686,  -5.4240,  -6.4915,  -0.1485,  -7.4101,  -5.3624,  -3.9568,\n",
       "                        -8.2369,  -6.2680,  -7.4459,  -1.5998, -12.1062,  -6.4252,  -4.5093,\n",
       "                        -9.1467,  -1.7616,  -4.1337,  -7.5233, -11.9482,  -9.0477,  -0.1674,\n",
       "                        -6.2516,  -5.3855, -13.4576,  -7.5187,  -8.5937,  -8.9846,  -7.8837,\n",
       "                        -7.2620,  -8.1858, -10.8179,   0.6603,  -8.9839,  -6.2542, -10.4111,\n",
       "                        -7.0609,  -5.5050,  -0.5491,  -4.2341,  -4.2832,   1.9065,  -6.6364,\n",
       "                        -9.1535,  -7.1616,  -5.9491,  -4.5903,  -6.4505,  -3.0236,  -6.1423,\n",
       "                        -2.2690,  -3.9202,  -6.1200, -10.3187, -10.1729,  -6.7391,  -7.7427,\n",
       "                        -8.7977, -11.9383,  -5.3453,  -5.8036,  -6.7242,   0.4427,  -9.2209,\n",
       "                        -3.7368,  -4.7518,  -9.7832,  -4.4224,   1.3990,  -2.4374,  -4.9322,\n",
       "                        -3.9685,  -8.2084,  -5.6697,  -4.8616,  -7.2400,  -9.3516,  -6.3486,\n",
       "                        -4.4132,  -8.5907,  -7.9852,  -3.4281,  -7.5983,   0.6316,  -4.0236,\n",
       "                        -4.1680,  -6.6564,  -7.3984,  -5.0515,  -9.8773,  -5.5165,  -3.4083,\n",
       "                        -4.0908,  -5.4502,  -7.5116,  -4.7940,  -6.8727,  -6.4855,  -3.8047,\n",
       "                        -4.6048,   2.2831,  -0.6845,  -9.2537,   2.3546,  -7.3868,  -6.5038,\n",
       "                        -8.1104,  -4.6953,  -6.2870,  -5.7926,  -7.7083,   1.6947,  -6.8570,\n",
       "                        -4.1531,  -4.1234,  -9.3761,  -7.1345,  -5.3935,  -2.3333,   1.9098,\n",
       "                         1.1853], device='cuda:0')),\n",
       "              ('conv_block4.bn1.running_var',\n",
       "               tensor([30.5615, 19.5194,  6.8431, 33.2307,  7.7484, 19.5720,  5.7041, 16.7709,\n",
       "                       20.6506, 32.5822, 12.8072, 25.8494, 28.5697,  9.8946, 38.2908, 12.4467,\n",
       "                       22.7973, 15.6550, 30.3211, 15.4183, 13.8769, 20.1674, 13.4068,  5.2064,\n",
       "                        9.3205, 19.1652, 13.3040, 28.8858, 23.1700, 17.6359, 36.8522, 17.2134,\n",
       "                       22.6639, 14.3213, 17.0298, 16.1659, 17.5653,  5.6243,  8.1378, 23.6647,\n",
       "                       17.6713, 10.8439,  6.3442, 18.7229, 28.5044, 15.1650, 16.8111, 27.2365,\n",
       "                       13.7515, 18.3758, 15.7615, 18.0450, 18.5931, 15.1795, 30.1187, 16.0600,\n",
       "                       18.4562, 15.7618,  6.0597,  9.8101, 25.0701, 10.5290, 20.8149,  8.2874,\n",
       "                       10.5557, 36.5706, 20.3083, 10.9105, 26.9362, 24.1466, 27.5407,  7.9009,\n",
       "                       10.2477,  7.5243,  7.9346, 31.0490, 16.5714, 16.9582, 15.1790, 15.1728,\n",
       "                       11.0975, 17.7968,  9.3774, 17.2617, 18.0170, 11.2026, 10.0479, 21.4738,\n",
       "                       12.8184, 27.9929, 34.9499,  8.7972, 20.2416, 38.6349, 35.8775, 26.6058,\n",
       "                        8.6860, 16.5672,  8.6107,  9.6205,  4.9644, 12.9083, 37.8021,  5.3654,\n",
       "                        4.3570, 33.3336, 28.2035,  9.7090, 34.4627, 10.1998, 32.1513,  6.2575,\n",
       "                       17.9305, 12.3358, 35.8649, 17.6484, 13.4068, 34.7466, 20.6096, 24.9320,\n",
       "                       12.1647,  5.1258, 15.6527, 36.4144, 13.6576, 15.8207, 12.5088, 21.6173,\n",
       "                       13.0574,  5.9408, 17.3958,  8.3152,  6.9040, 11.4219, 22.0784, 15.1430,\n",
       "                       15.8226, 26.2072, 13.5272, 31.2710, 25.6707, 19.4369, 19.3787, 27.3696,\n",
       "                       16.0319,  5.6787, 22.4620, 22.5795, 10.0631, 19.1722, 10.5147, 28.1664,\n",
       "                       12.4213, 25.4380, 12.6300, 23.6269, 41.7899, 11.3836, 18.0569,  8.7249,\n",
       "                        8.8377,  7.6490, 19.9988, 36.8825,  8.3112, 10.9120, 29.6565, 20.1334,\n",
       "                       13.5106, 28.7123, 16.1448, 27.9076, 31.5709, 19.4292, 30.4554, 25.3627,\n",
       "                       10.2696, 13.9052, 40.8040, 32.9910, 15.3921, 17.6103, 13.1719, 29.6313,\n",
       "                       18.9846, 22.1142, 12.7236, 18.7990,  5.8783, 13.0427, 12.2896,  5.8145,\n",
       "                       23.3267, 19.1351, 14.7191,  8.4226,  4.0103, 14.8062, 13.1337, 12.5089,\n",
       "                        5.3677, 21.5225, 24.8644, 17.3675, 13.8637, 14.5169, 15.1201,  6.6010,\n",
       "                       18.9283, 18.7039, 15.5907, 11.7995, 15.9959,  7.8538, 13.7008, 10.5229,\n",
       "                        4.6169, 13.7895, 36.4701, 28.8091, 16.2106, 11.9121,  4.6951, 12.1054,\n",
       "                       11.0117, 34.8793, 11.1683, 17.6856, 20.5549, 19.9955,  8.9615, 20.1625,\n",
       "                        9.6848, 19.9802, 14.8742, 17.6910, 19.3254, 24.4685, 21.4280, 29.3899,\n",
       "                       15.4179, 10.9351, 24.2829,  9.6252, 12.0946,  5.1307, 13.8964,  7.6012,\n",
       "                        6.3450, 14.6780, 14.1869, 24.8011, 26.2712, 22.6321, 14.2291, 18.8901,\n",
       "                       17.4181, 16.2870,  5.9781, 14.9376, 11.4820, 22.6166, 19.5444, 14.1481,\n",
       "                       14.4549, 16.9543, 19.7434, 27.3365, 32.2359, 20.6217, 26.1336, 24.1979,\n",
       "                       10.0762, 37.4724, 41.0546, 13.7372, 14.8969, 14.4313, 13.2454,  5.9549,\n",
       "                       14.9837, 19.6615, 10.9641, 12.4789,  4.1697, 20.6397, 20.3398,  4.9947,\n",
       "                       18.0992, 15.6661,  6.3609, 21.8676, 10.3437,  7.0835, 31.1422, 18.8504,\n",
       "                       12.8874, 12.5800, 25.5613, 21.8090, 15.6999, 21.7496, 22.0028, 15.8032,\n",
       "                       14.4817, 13.5646, 36.0756, 19.3523, 14.9007, 20.0335,  8.7787, 20.0837,\n",
       "                       17.5363, 12.9350, 13.9228, 12.1984,  7.4850, 18.1529, 15.2906, 15.3669,\n",
       "                       15.1041, 10.5410, 34.7928, 16.7722, 37.1760,  5.0407, 41.1197, 15.3174,\n",
       "                       27.7526,  2.9424, 16.8891, 20.1124, 14.4424, 34.8773, 22.7271, 20.1915,\n",
       "                        9.4582, 13.8497, 14.3264, 23.0631, 10.5649,  4.2221,  6.9832,  8.8682,\n",
       "                       18.3566, 20.9455, 20.9889, 22.7778,  7.7765, 26.7661,  7.1429, 13.2231,\n",
       "                       21.4396, 12.0353, 22.3188, 13.8094,  8.5693, 17.9074, 11.7283, 24.9059,\n",
       "                        8.4410, 11.4587, 16.0788, 37.7887,  6.3968, 15.5928, 10.7083,  7.3945,\n",
       "                        7.8200, 13.3485,  3.1345, 23.7982, 25.3734, 10.9349, 13.1362, 13.6335,\n",
       "                       24.6937, 23.0011, 18.5087, 23.0593, 15.7291, 13.5202, 15.2368, 10.1596,\n",
       "                       13.8289,  8.0219,  6.9101, 17.6363, 23.8544, 13.7632, 21.9881, 19.5875,\n",
       "                        7.7525, 13.8248, 12.9938,  5.0650, 14.1804, 29.8344, 12.4386, 20.9369,\n",
       "                        9.7813, 22.8497,  6.1871, 34.4481, 28.4984, 15.5763, 32.3126, 27.9873,\n",
       "                       28.5361, 21.9034, 29.6870, 19.2119, 15.0388, 12.2173, 16.7385, 36.1602,\n",
       "                       24.9092, 24.9316, 30.5120, 24.6249, 19.2227, 11.0939, 26.7466,  6.8273,\n",
       "                       12.3371, 20.9441, 39.4448, 14.4986, 11.7440,  6.7282, 15.6753, 23.5683,\n",
       "                        5.7090, 18.3468, 18.0073, 23.0290, 16.6334, 19.7900, 15.3393, 21.3345,\n",
       "                       11.5967, 10.6765, 24.2350, 16.5404, 35.5970, 35.3758, 10.5018, 15.7377,\n",
       "                       24.5646, 25.9001, 15.3133, 19.3552, 21.6175,  9.0542, 22.2412, 15.1988,\n",
       "                        6.7641, 17.1693, 23.0440,  5.8231,  6.8925, 10.3310, 16.7413, 15.4752,\n",
       "                       15.6510, 16.4781, 20.7925, 35.9258, 13.2031, 10.9192, 23.5391, 19.5459,\n",
       "                       17.7848, 12.5372,  3.6360, 11.2511, 10.7330, 14.0641,  9.4343, 13.3173,\n",
       "                       31.3042, 20.5273, 27.5875, 12.0333, 20.2981, 13.8537, 11.4676, 14.6925,\n",
       "                       16.4561, 14.0791, 15.1365,  6.3850,  7.7605, 27.7311, 18.7079, 18.9606,\n",
       "                       37.4239, 24.0474, 12.9374, 19.4589, 20.7373, 21.8877,  7.4155, 18.6823,\n",
       "                       22.3549, 14.1555, 25.8358, 15.2212, 22.2576,  8.2511,  6.0334,  4.6805],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block4.bn2.weight',\n",
       "               tensor([0.8692, 1.0196, 0.9362, 0.9131, 1.0375, 1.0444, 1.0132, 1.0092, 1.0608,\n",
       "                       1.0743, 1.0304, 1.1891, 1.0405, 1.0412, 1.0269, 0.9653, 1.0626, 1.0576,\n",
       "                       1.0416, 1.0394, 1.0032, 0.9530, 1.0887, 1.1196, 1.2284, 1.1845, 1.2006,\n",
       "                       1.0038, 0.9120, 0.9737, 1.0074, 1.0234, 0.9587, 0.9566, 1.1203, 1.0380,\n",
       "                       1.2199, 1.0974, 1.0536, 0.7612, 0.9293, 1.2127, 1.0957, 1.0487, 1.0060,\n",
       "                       0.9303, 1.1301, 0.9962, 0.9253, 0.9390, 1.0552, 1.0215, 0.6022, 1.1631,\n",
       "                       1.0075, 0.9166, 1.1436, 1.1242, 0.9639, 0.8867, 0.8757, 1.0242, 1.0773,\n",
       "                       1.0337, 1.0872, 0.9788, 0.9669, 0.9332, 0.7769, 1.0834, 1.1052, 1.0670,\n",
       "                       1.2093, 1.0479, 0.8535, 1.0409, 1.0113, 0.8261, 0.9043, 1.0220, 1.0291,\n",
       "                       1.0649, 0.9358, 1.2345, 0.9310, 0.9950, 1.1893, 1.0115, 0.7559, 1.0712,\n",
       "                       1.0209, 0.9954, 0.8501, 1.0186, 1.1557, 0.9994, 0.9954, 1.0819, 1.0597,\n",
       "                       1.0474, 1.0162, 0.9761, 0.9244, 0.9922, 0.9519, 1.1067, 0.9372, 0.9337,\n",
       "                       1.1715, 1.0161, 1.0217, 1.0195, 1.1220, 1.0149, 1.1270, 1.1602, 0.9379,\n",
       "                       1.0706, 1.1358, 1.0445, 0.9419, 1.0347, 0.9873, 1.0045, 0.9723, 1.0441,\n",
       "                       0.8574, 1.0103, 1.0524, 0.9981, 0.9770, 1.0063, 1.0351, 1.0704, 1.0712,\n",
       "                       1.1775, 1.0923, 1.0152, 1.0871, 1.0963, 0.9691, 1.0647, 0.6194, 1.0080,\n",
       "                       1.0311, 1.1069, 0.9379, 1.0183, 1.0397, 0.9723, 1.0926, 0.9570, 1.1201,\n",
       "                       0.6124, 1.0335, 1.0131, 1.0401, 1.0126, 0.9381, 1.0591, 1.0451, 0.6448,\n",
       "                       1.2713, 0.8568, 1.0401, 0.9968, 0.9266, 0.9932, 1.0042, 1.0146, 0.9523,\n",
       "                       1.0785, 1.0504, 1.0440, 0.8292, 1.0258, 0.8946, 1.0836, 0.9695, 1.1255,\n",
       "                       1.0539, 1.0798, 1.0433, 0.9571, 1.0015, 1.0899, 0.9283, 1.0606, 0.9519,\n",
       "                       0.7614, 0.7617, 0.9541, 1.1838, 0.9471, 1.0733, 1.1440, 1.0788, 1.0504,\n",
       "                       0.9725, 0.7654, 1.0277, 0.7071, 0.9312, 1.0306, 1.0887, 1.1121, 0.9629,\n",
       "                       1.0552, 1.0747, 1.1719, 0.8791, 1.0809, 1.0920, 0.8258, 1.0560, 0.9856,\n",
       "                       1.0623, 0.8904, 0.9770, 0.9496, 1.1909, 0.8231, 0.9825, 0.9999, 1.0781,\n",
       "                       1.0322, 0.9479, 0.6987, 1.0529, 0.9777, 1.0731, 1.0085, 1.0309, 0.9760,\n",
       "                       1.1300, 1.0308, 0.9500, 0.8970, 1.0981, 0.9828, 1.0356, 1.0897, 1.0457,\n",
       "                       1.1373, 1.0823, 1.0683, 1.1204, 1.0674, 1.1082, 1.0366, 1.0477, 0.7976,\n",
       "                       1.0946, 1.0202, 0.9869, 0.9141, 0.9358, 1.0071, 1.0090, 0.9882, 1.2007,\n",
       "                       0.9805, 0.9280, 0.9648, 1.1031, 1.0952, 1.0682, 0.9051, 0.9703, 0.9847,\n",
       "                       1.0507, 1.0302, 1.0373, 1.0126, 1.1133, 0.9373, 1.0751, 1.0259, 0.8999,\n",
       "                       0.9758, 1.0634, 0.9822, 0.9974, 1.1841, 1.0385, 0.9460, 1.0757, 1.0571,\n",
       "                       0.8684, 0.7430, 1.0869, 1.0043, 0.8735, 0.9567, 1.0572, 1.0317, 1.0294,\n",
       "                       1.0523, 1.0352, 1.0453, 1.1801, 1.1518, 1.0357, 1.0031, 1.0059, 1.0505,\n",
       "                       0.8497, 0.8277, 0.7445, 1.0762, 1.0021, 1.1202, 1.0641, 0.9924, 1.1110,\n",
       "                       1.0767, 0.9756, 1.0253, 1.1018, 0.9259, 0.9461, 1.0254, 1.0322, 0.9632,\n",
       "                       1.0843, 0.8916, 0.8301, 1.1465, 0.9954, 0.9512, 0.9322, 0.9779, 0.9065,\n",
       "                       0.9694, 0.5169, 1.1076, 1.0327, 0.9517, 1.1000, 0.9666, 0.9286, 0.9862,\n",
       "                       1.1279, 0.9118, 0.9248, 0.8618, 0.8209, 0.7729, 0.9371, 0.8842, 0.9992,\n",
       "                       1.0429, 1.0914, 0.8012, 1.0192, 1.0117, 1.0623, 1.0231, 1.0377, 1.1539,\n",
       "                       0.8518, 0.6366, 1.0854, 0.9593, 0.9821, 0.8839, 1.2614, 0.9315, 0.8245,\n",
       "                       0.9191, 1.0720, 0.9815, 0.7630, 1.0368, 1.0000, 1.0597, 0.9025, 1.0035,\n",
       "                       1.1145, 0.9382, 1.0012, 0.9382, 0.9492, 1.0129, 0.7285, 1.0805, 0.9569,\n",
       "                       1.0730, 1.0464, 0.8662, 0.5841, 0.9371, 0.7384, 0.9628, 1.1045, 0.9737,\n",
       "                       1.0557, 1.1154, 1.1908, 0.9917, 0.9906, 0.7624, 1.0398, 0.9751, 1.0418,\n",
       "                       1.0149, 0.8918, 0.9710, 0.9319, 0.9814, 0.9381, 0.9196, 1.1777, 1.0211,\n",
       "                       1.0665, 0.9604, 1.0621, 1.0200, 0.8991, 0.9888, 0.8206, 1.0428, 1.0212,\n",
       "                       1.0214, 1.0759, 1.0050, 0.9450, 0.9638, 1.0861, 1.0789, 0.9607, 0.7226,\n",
       "                       0.8935, 1.0180, 0.9566, 1.1027, 0.9531, 0.9753, 1.1532, 1.0002, 0.9920,\n",
       "                       1.0342, 0.9385, 0.8641, 0.9388, 0.9327, 1.0506, 1.0106, 1.0389, 0.9956,\n",
       "                       1.0707, 1.0160, 1.1350, 1.1605, 0.9819, 0.9502, 1.0184, 1.0517, 1.0610,\n",
       "                       1.0803, 0.9218, 0.9971, 1.0046, 1.0675, 0.9909, 1.1060, 0.7715, 1.0106,\n",
       "                       0.9804, 1.0199, 1.0249, 1.0042, 1.0969, 0.8566, 1.0517, 0.6326, 1.0388,\n",
       "                       1.0691, 1.0669, 0.9527, 1.0403, 1.0416, 0.7403, 1.1037, 1.0038, 1.0177,\n",
       "                       0.5930, 0.9599, 1.0896, 0.9358, 0.9490, 0.9979, 1.0591, 0.9622, 0.9875,\n",
       "                       0.9553, 1.0062, 1.0119, 1.1283, 1.0414, 1.0745, 1.0687, 0.8101, 1.0115,\n",
       "                       1.1221, 1.0903, 0.9864, 1.1624, 1.0129, 1.0907, 0.9775, 0.7475],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn2.bias',\n",
       "               tensor([-0.6357, -0.8527, -0.7240, -0.7183, -0.9574, -0.9813, -0.7130, -0.8558,\n",
       "                       -0.8158, -0.8945, -0.7349, -0.9749, -1.0785, -0.7781, -0.8201, -0.7343,\n",
       "                       -1.2163, -0.9349, -0.9170, -0.7448, -0.8741, -0.8969, -1.0082, -0.9573,\n",
       "                       -1.1156, -1.2825, -1.2379, -0.9295, -0.6968, -1.0297, -0.9719, -0.8778,\n",
       "                       -0.6440, -0.7050, -1.0121, -1.0072, -1.1827, -0.8992, -0.8494, -0.6630,\n",
       "                       -0.6907, -1.1151, -0.9045, -1.0034, -0.8512, -0.8988, -1.0106, -0.6670,\n",
       "                       -0.6949, -0.8435, -1.0474, -0.8233, -0.4661, -1.0223, -0.9171, -0.9080,\n",
       "                       -1.1544, -1.0028, -1.1745, -0.8494, -0.5735, -1.0519, -0.8442, -0.8575,\n",
       "                       -1.1057, -0.8953, -0.8886, -0.8457, -0.5678, -1.0093, -0.9063, -0.9730,\n",
       "                       -1.3149, -0.9343, -0.6227, -0.9176, -0.9047, -0.6808, -0.7603, -0.9709,\n",
       "                       -0.9282, -1.0250, -0.7901, -1.1732, -0.9183, -0.8938, -1.0894, -0.7654,\n",
       "                       -0.7095, -1.1964, -0.8708, -0.8142, -0.8661, -0.9949, -1.1258, -0.9737,\n",
       "                       -0.7671, -0.9461, -0.8957, -0.9559, -0.8173, -0.8774, -0.8777, -0.9807,\n",
       "                       -0.6896, -0.9080, -0.7666, -0.7901, -0.9920, -1.0560, -0.9186, -0.8876,\n",
       "                       -0.9487, -0.8476, -0.9140, -1.0839, -0.7586, -1.0032, -1.0627, -0.9870,\n",
       "                       -0.6890, -0.7998, -0.8275, -0.7153, -0.7468, -0.9308, -0.5439, -0.7082,\n",
       "                       -0.9491, -0.8077, -0.7686, -0.8005, -1.1216, -1.0302, -0.8449, -1.2532,\n",
       "                       -1.0404, -0.8978, -0.8028, -1.0356, -0.8640, -0.9739, -0.3478, -0.7908,\n",
       "                       -1.0078, -1.0894, -0.6264, -0.9284, -0.8441, -0.6705, -0.9099, -0.6895,\n",
       "                       -1.0781, -0.4041, -0.9598, -0.9002, -0.8591, -0.8593, -0.9035, -0.9717,\n",
       "                       -0.8061, -0.4209, -1.1186, -0.6594, -0.9079, -0.8793, -0.6905, -0.7890,\n",
       "                       -0.7763, -0.8181, -0.7768, -0.9247, -1.1757, -0.9052, -0.6392, -0.9119,\n",
       "                       -0.8816, -1.1514, -0.6032, -1.1121, -1.0446, -0.9701, -0.9160, -0.7903,\n",
       "                       -0.9031, -0.9186, -0.8806, -0.9007, -0.8075, -0.5293, -0.7690, -0.7966,\n",
       "                       -1.0551, -0.7402, -0.9771, -1.1216, -1.0144, -0.7270, -0.8152, -0.4969,\n",
       "                       -0.9188, -0.5080, -0.6954, -0.8943, -0.9111, -0.9846, -0.7691, -0.7996,\n",
       "                       -0.9310, -0.9318, -0.7881, -1.0120, -1.1179, -0.6427, -0.8588, -0.8852,\n",
       "                       -0.9369, -0.6432, -0.8372, -0.7708, -1.0399, -0.5446, -0.8622, -1.0342,\n",
       "                       -1.0385, -0.9053, -0.7958, -0.5640, -1.0736, -0.7351, -0.9306, -0.7655,\n",
       "                       -0.9475, -0.9423, -1.0223, -0.8780, -0.8575, -0.8953, -1.0348, -0.9474,\n",
       "                       -1.0599, -0.8597, -0.9905, -0.8517, -0.8602, -1.0753, -0.9481, -1.0397,\n",
       "                       -0.9873, -0.9807, -0.9107, -0.8368, -0.9407, -0.9491, -0.9919, -0.6827,\n",
       "                       -1.0033, -0.8495, -0.9439, -0.7659, -0.9812, -0.7008, -0.6716, -0.7872,\n",
       "                       -0.7998, -0.9925, -0.7968, -0.6551, -0.9045, -0.9280, -1.0423, -0.9507,\n",
       "                       -0.8546, -0.7400, -1.2037, -0.9359, -0.8926, -0.8114, -0.8905, -0.9073,\n",
       "                       -0.9369, -0.8521, -0.9964, -0.9729, -0.9072, -0.6744, -0.9125, -0.8992,\n",
       "                       -0.6318, -0.5347, -0.9464, -1.0394, -0.8523, -0.7701, -0.8907, -0.9499,\n",
       "                       -1.0483, -0.9705, -0.9066, -0.9237, -1.2272, -1.3275, -0.8460, -0.7763,\n",
       "                       -0.6645, -0.9437, -0.4811, -0.6286, -0.5974, -0.9572, -0.8808, -0.9409,\n",
       "                       -0.9350, -0.8788, -0.9325, -0.9302, -0.9094, -0.8218, -1.0726, -0.7214,\n",
       "                       -0.9896, -0.8111, -1.0361, -0.7955, -0.7910, -0.7099, -0.6057, -0.9668,\n",
       "                       -0.8110, -0.9454, -0.8162, -0.7066, -0.6406, -0.9381, -0.2838, -1.2096,\n",
       "                       -0.8564, -0.9551, -1.0171, -0.8412, -0.7527, -0.7537, -0.9505, -0.7497,\n",
       "                       -0.8901, -0.6481, -0.7140, -0.4668, -0.8714, -0.9210, -1.0737, -0.9736,\n",
       "                       -0.9253, -0.8462, -0.9520, -0.7971, -1.1652, -0.9690, -0.9288, -0.8844,\n",
       "                       -0.7713, -0.4085, -0.9273, -0.7709, -0.9965, -0.7296, -1.0591, -0.8909,\n",
       "                       -0.6816, -0.7582, -0.8895, -1.0022, -0.4112, -0.9052, -0.8330, -0.7699,\n",
       "                       -0.6271, -0.7419, -0.9814, -0.8401, -0.8756, -0.7851, -0.8853, -0.9722,\n",
       "                       -0.4361, -1.0040, -0.8905, -0.9258, -0.8468, -0.6977, -0.3273, -0.7692,\n",
       "                       -0.5724, -0.7710, -0.9961, -0.9429, -1.0810, -1.0256, -1.0846, -0.8732,\n",
       "                       -0.8395, -0.6623, -0.7299, -0.7672, -1.0518, -0.8442, -0.7411, -1.0576,\n",
       "                       -1.0265, -0.9971, -0.9094, -0.6428, -1.1716, -0.7394, -0.8364, -0.8228,\n",
       "                       -0.9271, -0.7503, -0.7941, -0.9165, -0.6003, -0.7904, -0.8405, -1.0136,\n",
       "                       -0.8585, -0.9383, -0.6179, -0.9837, -1.0112, -0.8642, -0.8000, -0.4619,\n",
       "                       -0.7208, -0.9207, -0.8988, -0.8371, -0.9391, -0.8320, -0.9519, -0.8000,\n",
       "                       -0.8909, -0.9169, -0.8799, -0.7483, -0.7430, -0.9219, -0.8550, -0.8171,\n",
       "                       -0.7724, -0.8056, -0.8571, -0.8749, -1.1316, -1.0753, -1.0479, -0.9392,\n",
       "                       -0.8136, -0.8701, -0.9236, -0.9709, -0.8798, -0.6883, -0.9078, -0.9579,\n",
       "                       -0.9275, -1.1071, -0.5766, -0.9774, -0.8089, -0.9832, -1.1391, -0.9514,\n",
       "                       -0.9571, -0.8613, -0.9184, -0.5020, -1.0454, -0.9861, -0.8187, -0.9366,\n",
       "                       -0.9146, -0.9690, -0.4672, -1.0258, -0.9856, -0.9362, -0.3431, -0.7617,\n",
       "                       -0.8894, -0.7865, -0.8302, -0.9095, -0.8643, -0.8991, -0.9230, -0.7429,\n",
       "                       -0.7601, -0.8827, -1.0443, -0.8199, -0.9924, -0.9508, -0.6007, -0.8046,\n",
       "                       -0.9269, -0.9579, -0.7895, -0.9726, -0.8318, -1.0327, -0.9359, -0.5078],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn2.running_mean',\n",
       "               tensor([ -7.0704,  -9.1402,  -7.7512, -11.1341,  -9.7865, -10.2807,  -9.2352,\n",
       "                       -11.5114, -11.2539, -11.2583, -10.6623, -12.7442,  -9.5280, -10.9777,\n",
       "                        -9.3166,  -9.5266, -10.3923,  -9.1503, -11.8856, -12.7874,  -9.3444,\n",
       "                        -8.8380, -11.3720, -10.5587, -14.1978,  -8.0652, -12.6958, -13.7487,\n",
       "                        -5.7113,  -6.2154, -13.2550, -13.7632,  -7.7563,  -8.4884, -15.6846,\n",
       "                       -12.8679, -12.5408, -10.1373, -11.0303,  -8.8317,  -8.6962, -11.2265,\n",
       "                       -13.3940, -12.6671, -10.5173, -11.1147,  -9.7191,  -9.3235, -10.5189,\n",
       "                        -9.2362,  -9.7928, -11.5436,  -5.3139, -11.4657,  -8.1820,  -9.7276,\n",
       "                       -12.8487, -12.4356, -11.3890,  -8.5416,  -7.0600, -12.1388,  -9.2885,\n",
       "                       -10.2390,  -8.3354,  -8.1266,  -7.4188,  -9.0289,  -6.1786, -13.6227,\n",
       "                       -11.5395,  -8.3719, -11.4114,  -9.3470, -10.4304, -11.7534,  -6.6131,\n",
       "                        -6.4860,  -7.7830, -14.2819,  -9.1729,  -9.4956,  -8.8200, -14.3914,\n",
       "                        -9.2733,  -9.3520, -13.5086,  -8.6649,  -7.7513, -12.5135, -13.1946,\n",
       "                       -12.8133,  -7.7209, -10.5792, -14.4326, -11.0646,  -9.8393, -13.3821,\n",
       "                       -10.0047, -10.6789, -11.1940,  -8.6306, -14.4514, -11.5956,  -9.7265,\n",
       "                       -15.0767, -12.2830, -10.7356,  -9.0361,  -6.8977,  -8.7512,  -9.1303,\n",
       "                        -8.6288,  -8.0765, -10.9246, -12.0117, -10.5883,  -8.1081, -12.3401,\n",
       "                       -12.3190, -12.3612, -11.6358,  -8.5028,  -9.4126, -12.0485,  -6.3837,\n",
       "                       -11.4244, -10.0863, -15.5683,  -9.1223, -12.6953, -11.5748,  -8.9412,\n",
       "                       -11.3644,  -8.8625, -12.2167, -11.1881,  -7.3360,  -8.7879, -10.7554,\n",
       "                        -7.0423, -11.7585,  -8.4510,  -9.6842, -10.4855,  -7.7066,  -6.3143,\n",
       "                        -9.5375,  -8.0087,  -9.2176, -12.3142,  -7.4595, -11.3879,  -4.9095,\n",
       "                        -7.0090, -10.2986, -12.8484,  -7.3264, -10.5119, -10.7336, -10.8010,\n",
       "                        -8.6696, -17.8151,  -9.2606,  -9.9283, -11.1807,  -7.9112,  -6.7784,\n",
       "                       -10.9137,  -8.0106,  -6.9620, -11.6688,  -9.5805,  -8.5959,  -9.7636,\n",
       "                        -8.5198, -12.2389,  -9.1478,  -8.1453, -12.4756,  -9.4083,  -7.3629,\n",
       "                       -13.1045,  -9.6270,  -9.6665,  -9.8933,  -7.9381, -10.6922,  -9.2425,\n",
       "                        -7.8954,  -9.3268, -11.8413, -13.3432, -10.3631, -10.5183, -10.0359,\n",
       "                        -9.9202,  -7.8625,  -8.1335,  -8.9402, -11.4192,  -5.9625,  -9.5392,\n",
       "                        -7.0874,  -8.0605,  -9.4473, -11.1855, -12.7950, -10.7949, -12.3419,\n",
       "                        -7.6562, -14.0854, -10.3612,  -9.8623, -10.4224,  -9.1409, -14.9591,\n",
       "                       -11.8854,  -8.6520, -10.1927, -11.4755, -10.1710,  -9.4750,  -7.7925,\n",
       "                       -10.2812, -12.2564,  -7.7537,  -6.6620, -10.8340, -10.4059, -11.9272,\n",
       "                       -11.0039, -12.3004, -10.3599,  -8.9955, -12.5240, -11.8692,  -9.8073,\n",
       "                       -10.7393, -10.6546, -12.2049, -10.8643, -10.2018, -11.6912, -11.3565,\n",
       "                        -9.4278, -12.8465,  -9.0102, -13.0422, -11.7360, -11.8573,  -9.6732,\n",
       "                       -13.5239, -11.4994, -11.8104,  -8.9863,  -9.1722,  -9.2032,  -9.9717,\n",
       "                       -11.1541,  -9.3149, -10.5394,  -9.8313,  -7.8685, -14.3521, -11.8711,\n",
       "                        -8.4968,  -6.1572, -12.4332,  -7.9072,  -9.5356,  -8.9708,  -7.0380,\n",
       "                       -14.7917, -13.4908,  -7.9742, -10.2905, -10.6549,  -9.9388,  -9.2936,\n",
       "                       -13.1623, -11.8600, -10.0409, -10.6516,  -7.1750,  -8.7823,  -9.1282,\n",
       "                       -11.7259, -12.0622,  -8.9568,  -8.7477, -12.5159,  -8.3625,  -9.3127,\n",
       "                       -10.3506,  -8.5225,  -8.0484, -11.9778,  -7.7152, -12.3258, -11.5251,\n",
       "                       -10.6074,  -9.3330, -11.6243,  -7.4509, -12.0330,  -8.5127,  -9.2744,\n",
       "                        -8.0115,  -8.7962, -11.2252,  -7.7782, -10.5103, -10.7580, -14.4433,\n",
       "                       -12.4094, -12.7848, -11.1887, -11.2455,  -8.8453,  -8.7306, -10.3607,\n",
       "                       -10.7794,  -7.5537, -10.0302, -12.2000,  -8.8585, -13.6904, -10.2506,\n",
       "                       -12.8044, -11.9870,  -8.5768, -10.6659, -11.1175,  -5.8667, -11.2665,\n",
       "                        -9.6447, -12.2697,  -7.1850, -11.4209,  -4.9475, -11.3445, -11.0180,\n",
       "                       -10.6976, -12.0633,  -9.4174, -10.2803,  -9.7666,  -8.6389, -12.2479,\n",
       "                        -8.8226, -16.4966, -12.9197, -10.8278, -10.5766,  -8.5228, -10.4537,\n",
       "                       -14.5190, -12.3608, -10.0704,  -7.2365,  -8.9748,  -8.5510, -13.3488,\n",
       "                        -6.3004,  -4.8657,  -9.5620, -11.1047, -10.6984, -12.2717,  -8.1002,\n",
       "                       -12.3814,  -6.1011, -10.1579, -11.3373,  -8.9346,  -7.1032, -10.6421,\n",
       "                        -8.5353,  -8.8176,  -8.6552, -10.7790, -11.1876,  -8.9152,  -8.6046,\n",
       "                       -10.1903, -13.3491, -10.9219, -11.4192,  -8.0122,  -5.0803,  -7.1907,\n",
       "                        -9.2910,  -6.4443, -11.2285, -11.1397, -11.4683,  -9.4067,  -9.7184,\n",
       "                        -8.4264,  -9.8142,  -5.1804, -14.5606, -12.8593, -11.3980,  -9.0743,\n",
       "                       -13.2523,  -9.1607, -11.2102,  -7.6098,  -9.4769,  -9.2939,  -9.0630,\n",
       "                       -10.9464, -12.5919, -11.1671,  -8.9951,  -8.9873, -10.7743,  -9.5763,\n",
       "                        -8.8532,  -6.3426, -11.5980,  -9.5338, -11.9581, -10.1507,  -7.6085,\n",
       "                        -7.8964, -16.3195,  -7.9698, -11.2983,  -6.1035, -10.8961, -14.8799,\n",
       "                        -8.5117,  -9.6699,  -6.9834,  -9.0393, -10.1701, -11.1316, -10.9523,\n",
       "                        -8.6811, -11.9509, -12.3365,  -8.9529,  -8.8247, -11.8243, -13.2038,\n",
       "                       -10.8081,  -7.0179, -11.2472, -10.8153, -11.1608, -14.5949, -10.3344,\n",
       "                        -9.6759, -10.2307,  -9.8480, -15.7847, -10.8683,  -5.9520, -10.4720,\n",
       "                        -8.1118,  -8.9037,  -9.4431, -11.0172, -11.3063, -10.3130, -10.1860,\n",
       "                       -14.6933,  -9.0615, -10.6036, -11.3590,  -8.2459,  -7.5740,  -5.9723,\n",
       "                       -12.3277, -11.0075, -14.9161,  -9.8716,  -8.6900,  -9.5916,  -5.1327,\n",
       "                        -9.1199, -12.2774, -10.8230,  -6.6812,  -8.3982,  -9.7224,  -8.3312,\n",
       "                        -6.6135, -11.8535, -12.5668,  -9.0417,  -7.1228, -10.2076,  -8.1796,\n",
       "                        -8.7434, -15.6028, -10.1699, -12.5138,  -9.8046, -11.9482,  -9.7467,\n",
       "                       -11.5575, -10.9710,  -5.8092, -10.2086, -11.6999, -10.3494, -15.2646,\n",
       "                        -7.8103], device='cuda:0')),\n",
       "              ('conv_block4.bn2.running_var',\n",
       "               tensor([119.5330, 111.5851, 105.8014, 194.3960, 145.1584, 151.1561, 170.7872,\n",
       "                       168.1288, 169.7325, 246.5773, 183.6257, 201.1760,  90.3726, 235.3835,\n",
       "                       136.1833, 151.5590, 101.7934,  94.6865, 159.6302, 232.4375,  98.5792,\n",
       "                        93.2172, 166.5209, 154.0410, 183.5350,  73.4258, 103.5562, 228.6407,\n",
       "                        65.5826,  34.5725, 184.1561, 244.0851, 165.4411, 139.0002, 209.6452,\n",
       "                       160.1482, 166.1909, 149.4473, 197.4758,  98.0435, 122.8118, 115.8345,\n",
       "                       191.0247, 147.4830, 144.7492, 102.1568, 111.2490, 178.6992, 177.2030,\n",
       "                        91.5468,  92.0047, 178.1482, 100.3087, 138.4312,  77.9875,  88.8078,\n",
       "                       142.7540, 176.0923,  75.0477, 113.5099, 117.4905,  93.1809, 104.7753,\n",
       "                       177.5880,  54.8149, 112.3250,  53.3386, 124.4382,  84.0634, 165.6850,\n",
       "                       164.8729, 100.4674, 109.0026, 107.4236, 151.6819, 193.3995,  55.3059,\n",
       "                       106.1447,  84.0162, 209.6905, 126.8873, 106.6894, 127.1495, 166.2238,\n",
       "                        64.3243, 171.6260, 167.2073, 121.4679,  67.4339, 137.6332, 173.0528,\n",
       "                       252.8767, 100.0092, 127.1863, 139.5112,  84.4245, 186.3425, 247.4683,\n",
       "                       146.9553, 155.3842, 137.5345,  75.3665, 207.3246, 126.8592, 214.1089,\n",
       "                       209.7989, 148.8357, 182.2472, 100.6449,  49.5003, 100.7825,  93.1085,\n",
       "                        71.4692,  83.5189, 136.7704, 158.8071, 147.4560,  93.2384, 131.4757,\n",
       "                       137.1293, 202.9832, 152.5964, 108.1116, 216.2217, 239.0280,  76.2350,\n",
       "                       140.5914, 153.3451, 260.5764, 172.4119, 169.4218, 197.7206,  80.6323,\n",
       "                       101.7465, 104.0214, 106.3632, 113.2930,  57.2918, 113.4499, 126.2890,\n",
       "                        72.6041, 137.7473, 211.8665,  87.2345,  82.5531,  80.0018, 108.3961,\n",
       "                        97.3852, 104.7040, 240.5546, 190.8302, 114.5864, 130.0359,  90.7443,\n",
       "                        64.4102, 139.4491, 165.0707,  84.4786,  95.4657, 101.3506, 175.5658,\n",
       "                       131.7360, 281.9009, 146.9190, 150.1954, 161.3970, 109.4073,  95.7615,\n",
       "                       182.3277,  96.4348,  73.4839, 115.9752,  99.4877, 137.9911, 166.9402,\n",
       "                        91.8582, 125.5850,  95.9300, 185.0470, 132.8921,  63.0050,  94.5155,\n",
       "                       174.8960, 150.6762,  76.0643, 121.6214,  64.4462, 157.4700, 121.1129,\n",
       "                       109.1967,  90.4049, 124.2251, 240.2950, 145.4362, 115.4441,  83.2565,\n",
       "                        92.3168, 167.5009,  89.1367, 160.1980, 179.0705, 108.8378, 124.8380,\n",
       "                        62.1686,  86.0124, 159.5369, 188.2807, 239.6436, 194.1266, 152.7062,\n",
       "                        91.3488, 181.7483, 103.0574, 125.0780, 102.0396,  76.1436, 230.8262,\n",
       "                       159.3068, 131.1642, 183.1092, 154.2262, 284.9601, 109.3947,  50.4844,\n",
       "                        77.8616, 153.9754,  98.7566, 124.5419,  93.7722, 167.6795, 185.0094,\n",
       "                       200.0618, 179.7574,  87.7052,  76.7539, 136.9572, 161.2445,  76.2044,\n",
       "                       123.4741,  98.5624, 123.3278, 201.6077, 105.0393, 207.5891, 177.8371,\n",
       "                        79.6234, 183.8452,  76.3404, 190.6858, 128.7299, 186.1456,  79.0408,\n",
       "                       194.2552, 167.2675, 143.1439, 208.0128,  93.1392, 134.3249,  97.7061,\n",
       "                       131.9269, 134.8008, 234.3669, 289.1217,  83.8410, 243.2776, 166.5899,\n",
       "                       138.5753,  93.8360, 135.3104, 102.1121, 130.6812,  88.0845,  87.4273,\n",
       "                       354.1793, 120.9376,  49.8033, 108.2608, 191.9858,  83.2218, 124.6435,\n",
       "                       198.9207, 151.3005, 114.5484, 187.6745,  80.2599, 128.1988, 115.1032,\n",
       "                       290.1814, 238.4541, 149.8992, 125.2472, 111.4082,  72.5357, 121.9289,\n",
       "                       138.8316, 105.3264,  81.6092, 150.1974,  96.3888, 165.7158, 101.1007,\n",
       "                        66.8240, 127.8578, 161.8440, 107.5237, 163.1043, 186.2200, 122.2260,\n",
       "                       129.0678,  98.6127, 102.1676,  73.6693, 138.8832, 144.4659, 208.6830,\n",
       "                       176.8513, 120.0968, 162.8605, 143.4462, 162.6996,  69.2330, 128.3018,\n",
       "                       133.2198, 112.4777, 174.3360, 258.6885, 207.6651, 204.3252, 165.8202,\n",
       "                       132.7782, 156.4254, 125.7472, 294.2368, 126.8540, 155.4616,  79.2299,\n",
       "                       123.1838, 105.4637,  66.7107, 156.1684,  70.9858, 182.2789, 158.8055,\n",
       "                       186.7225, 146.6785, 152.9809,  99.1145, 168.4443,  83.2520, 137.6243,\n",
       "                        68.5944, 237.3921, 201.5072, 105.9986, 118.1479, 134.5408,  87.5844,\n",
       "                       242.6606, 172.6103, 138.2726,  75.9145, 133.1461,  86.2201, 310.4858,\n",
       "                        45.1279,  77.7772, 123.9231, 114.0875, 139.8184, 162.8016, 140.3397,\n",
       "                        96.5330, 167.8691, 138.7544, 171.2143, 135.1889, 125.9986, 175.9455,\n",
       "                        81.4727,  89.3942,  81.5546, 122.4892, 134.6115,  83.5224,  94.3160,\n",
       "                       121.9861, 168.8695, 144.2761, 198.3965,  89.1466, 237.1340,  98.3379,\n",
       "                       186.9334,  59.1445, 144.5183, 105.5614, 113.5008, 122.7501, 101.8751,\n",
       "                        83.4345, 160.4523,  88.1170, 319.9019, 152.8835, 123.0919,  91.8793,\n",
       "                       199.7066,  96.4695,  98.2488,  60.2616,  92.5484, 172.1201,  80.0252,\n",
       "                       211.5920, 169.3102, 206.1817, 120.4552, 144.4899, 123.4716,  79.5671,\n",
       "                       113.1695,  83.3126, 222.6195,  83.9858, 176.4949, 132.8481, 148.8628,\n",
       "                        52.2881, 246.3003,  96.7397, 203.4213, 119.4787, 223.7660, 277.8627,\n",
       "                       124.3682, 131.0021,  59.6992, 108.7543, 137.5425, 206.7273, 142.7591,\n",
       "                        88.6648, 104.4339, 207.0668, 119.0594,  67.7863, 203.4793, 217.6955,\n",
       "                       184.5082,  83.2572, 108.5184, 182.4813, 112.8087, 159.0301, 109.1860,\n",
       "                        99.9105, 148.3253, 132.4963, 237.3271, 184.7216,  54.4456, 222.5535,\n",
       "                        95.5209,  95.9788,  83.0696, 104.1740, 256.7545, 112.8713, 214.7532,\n",
       "                       224.7012,  56.6445,  99.2389, 126.1396,  78.9249,  87.1820,  76.5859,\n",
       "                       144.2391, 131.5220, 268.1415,  70.4655, 139.8484,  78.6657,  99.4189,\n",
       "                       124.7197, 115.7797,  92.5335, 174.9718, 168.3002, 117.1443, 112.4444,\n",
       "                        84.0920, 159.9541, 203.4507,  80.1847,  81.9829, 186.1985, 118.6786,\n",
       "                       106.9935, 172.8516, 150.0677, 230.2883, 186.6628, 200.1913, 131.3280,\n",
       "                       185.2038, 122.9916, 113.0203, 149.2874, 144.6691, 110.0487, 158.8798,\n",
       "                       158.9126], device='cuda:0')),\n",
       "              ('conv_block4.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('fc1.weight',\n",
       "               tensor([[-0.0162,  0.2051,  0.1045,  ..., -0.0675,  0.0420,  0.0474],\n",
       "                       [-0.1089, -0.0935, -0.1332,  ...,  0.1064,  0.1283,  0.1095],\n",
       "                       [-0.0769,  0.1070, -0.0794,  ..., -0.1325, -0.1202, -0.0031],\n",
       "                       ...,\n",
       "                       [-0.2049,  0.0241, -0.2252,  ..., -0.5683,  0.1057,  0.0919],\n",
       "                       [-0.1168, -0.1704,  0.0327,  ..., -0.0705, -0.1603,  0.0641],\n",
       "                       [ 0.0408, -0.0130, -0.0847,  ..., -0.0846,  0.0335,  0.0355]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc1.bias',\n",
       "               tensor([ 0.5390,  0.5386,  0.0718, -0.2857,  0.0245, -0.0327,  0.7104,  0.5407,\n",
       "                       -0.0533, -0.3832, -0.0618,  0.0038,  0.7356, -0.0791, -0.0786,  0.4660,\n",
       "                       -0.0875,  0.3958,  0.8654,  0.0343,  1.0210,  0.1983,  0.5465,  0.6340,\n",
       "                       -0.2606, -0.1079,  0.5308,  0.7250,  0.8561,  0.0458, -0.0163,  1.4613,\n",
       "                        0.1459,  0.5657,  0.0974, -0.3957,  0.4825,  0.0538, -0.2921,  0.6931,\n",
       "                        0.3894,  0.0033,  0.6783, -0.0054, -0.4779, -0.1824,  0.5314, -0.4128,\n",
       "                        0.3976,  0.6597, -0.3526,  0.4103,  0.6220, -0.0259, -0.2060,  0.2368,\n",
       "                       -0.0545,  0.0995,  0.1890,  0.7222, -0.0065,  0.9948,  0.0051, -0.0179,\n",
       "                       -0.2542, -0.0503,  0.2423,  0.0585,  0.7288, -0.2077,  1.3685, -0.0125,\n",
       "                        0.0168,  0.5329,  0.5047, -0.3545,  0.8285,  0.9625,  0.4309,  0.0344,\n",
       "                        0.6676, -0.1120, -0.0795,  0.2257, -0.1322,  0.7685, -0.2873, -0.1637,\n",
       "                        0.7472, -0.2636, -0.6023,  0.1480, -0.2895,  0.3800,  0.3542,  0.0336,\n",
       "                       -0.1534, -0.0077, -0.2535,  0.7723,  0.7742,  0.0843,  0.4135,  0.5900,\n",
       "                        0.7188,  0.5165,  0.5607,  1.4848, -0.2240,  0.7909, -0.0338,  0.8326,\n",
       "                        0.0656,  0.0045,  0.2118, -0.0539,  0.0855,  0.6208,  0.0530, -0.1141,\n",
       "                        0.2065,  0.2361,  1.0296,  0.0438,  0.4333,  0.3641, -0.0523,  0.7411,\n",
       "                        0.6331,  0.6274,  0.6925, -1.2867,  0.8086,  0.0173, -0.1901, -0.3369,\n",
       "                       -0.0032,  0.1064,  0.5409,  0.0720,  0.2645, -0.0785,  0.0313, -0.2220,\n",
       "                        0.2901,  0.5120, -0.0407,  0.4435, -0.4844,  0.0249,  0.7821,  0.6862,\n",
       "                       -0.7986, -0.0193,  0.8213,  1.0957, -0.3831,  0.6909, -0.0031, -0.0315,\n",
       "                        0.3736,  0.5035, -0.3834,  0.0250, -0.4908,  0.6797,  0.2503,  0.0392,\n",
       "                        0.0334,  0.0328,  0.7076,  0.6202,  0.6192, -0.0043,  0.5458, -0.2643,\n",
       "                       -0.7342, -0.0907,  0.7569,  0.0824,  0.0046, -0.1082,  0.0774, -0.0584,\n",
       "                       -0.0353,  0.0615,  0.5795, -0.2930,  0.6952,  0.2286,  0.4080,  0.6492,\n",
       "                       -0.1935,  0.8778,  0.5847,  0.0619,  0.7006,  1.0230,  0.6471,  0.6449,\n",
       "                        0.0760,  0.0229, -0.0660,  0.1966,  0.0250,  0.9624, -1.0504,  0.0090,\n",
       "                        0.5280,  0.8886, -0.3967,  0.3304,  0.3099, -0.0214,  1.0731,  0.7956,\n",
       "                        0.8134,  0.2016,  0.6136, -0.2428,  0.1177,  0.4334,  0.0131,  0.8510,\n",
       "                        0.0610,  0.7948,  0.5155, -0.0663,  0.4911, -0.8763,  0.8510,  0.7228,\n",
       "                        0.8229, -0.0220,  0.0983,  0.0610,  0.6902,  0.1753,  0.7661,  0.0874,\n",
       "                       -0.0046,  0.4422,  0.0411,  1.0061, -0.2448,  0.2282,  0.4859, -0.0152,\n",
       "                       -0.8320,  0.3044,  0.3033,  0.2701,  0.6300,  0.2581,  0.9366, -0.3989,\n",
       "                       -0.0423, -0.0848,  0.7038,  0.3513,  0.8420, -0.0679,  0.0851,  0.1601,\n",
       "                        0.8619,  0.9919, -0.0899,  0.6976, -0.0237,  1.0497,  0.4629, -0.0838,\n",
       "                        0.8751,  0.1089,  0.0120,  0.4143, -0.0554,  0.4155,  0.1813,  0.3214,\n",
       "                       -0.0190,  0.9575, -0.6662,  0.0173,  0.8417,  1.0557,  0.6580,  1.0432,\n",
       "                        0.1036,  0.5181, -0.3942,  0.4714, -0.6981,  0.5184,  0.0654,  0.5405,\n",
       "                        0.5567,  0.0060, -0.0396, -0.5671,  0.0902,  0.5639, -0.6331,  0.1842,\n",
       "                        0.0451, -0.1490, -0.2121,  0.8105,  0.0405,  0.0342,  0.5684,  0.3533,\n",
       "                        0.0036,  0.4902,  0.1283,  0.4577, -0.0264, -0.2958,  0.6845,  1.0332,\n",
       "                        0.6011,  0.6495,  0.8831,  0.0350,  0.7828,  0.9590, -0.0278,  0.9186,\n",
       "                        0.6269, -0.0297,  0.1410,  0.7537,  0.0240,  0.0256,  0.4615,  0.7308,\n",
       "                        0.1071, -0.9078,  0.1964,  0.4996,  0.5870, -0.0044, -0.1103,  0.1263,\n",
       "                        1.8711,  0.6102,  0.1896,  0.5381, -0.6056,  0.0078,  0.6531, -0.2677,\n",
       "                        0.0208,  0.5778,  0.0198,  0.2121,  0.0217,  0.1653, -0.0612,  0.0035,\n",
       "                       -1.0666, -0.0879, -0.0541, -0.1329,  0.6626,  0.7638,  0.2922,  0.0853,\n",
       "                        0.5237,  0.2026, -0.0352, -0.1551,  0.0853,  0.6013,  0.9664, -0.2932,\n",
       "                       -0.0207,  0.1017,  0.3746,  0.6826, -0.0119,  0.5998,  0.0069,  0.7347,\n",
       "                        0.3851, -0.0292, -0.6627,  0.7156,  0.9222,  0.1129,  0.8253, -0.0920,\n",
       "                        1.9585,  0.2107,  0.7375,  0.6403,  0.0144,  0.0324, -0.0371,  1.0825,\n",
       "                        0.1428,  0.7617,  0.2419,  0.3425,  0.7588, -0.0280,  0.8388,  0.0687,\n",
       "                        0.6463,  0.2129,  1.0098, -0.0627,  0.7320,  0.6724, -0.5646,  0.6478,\n",
       "                        0.9435,  0.7642, -0.5676, -0.0020,  0.4888,  0.5415,  0.0286, -0.0444,\n",
       "                        0.3874,  1.0348,  0.8692, -0.1861, -0.4097, -0.4449, -0.0587,  0.1921,\n",
       "                        0.1430,  0.1148, -0.0817,  0.2384,  0.1298,  0.5131,  0.4706,  0.2027,\n",
       "                        0.5833,  0.4381,  0.6469,  0.8394,  0.4661,  0.2742,  0.0402,  0.5458,\n",
       "                        0.0116,  0.1196,  0.9895, -0.3875,  0.7393, -0.0311,  0.3565,  0.0899,\n",
       "                       -0.0582,  0.3803, -0.0535,  0.4975,  0.3216, -0.4744,  0.2178,  0.6991,\n",
       "                       -0.1516,  0.1003,  0.6228,  0.1111,  0.7130,  0.8505,  0.5158,  0.7247,\n",
       "                        0.3823, -0.0385,  0.8897, -0.0693,  0.1624,  0.7634,  0.7517,  0.0310,\n",
       "                       -0.1659, -0.0226,  0.1614, -0.0026,  0.5967,  0.6866, -0.0344, -0.0937,\n",
       "                        0.9474,  0.6435,  0.5628, -0.1668,  0.1525,  0.6969,  0.5165, -0.0336,\n",
       "                        0.9038,  0.1055,  0.7125,  0.6618,  0.8524,  0.0132, -0.0358,  0.5847,\n",
       "                        0.5924,  0.0588,  0.0119, -0.1043, -0.5310,  0.3961,  0.5049,  0.0200],\n",
       "                      device='cuda:0')),\n",
       "              ('fc_audioset.weight',\n",
       "               tensor([[-0.0073,  0.0060, -0.0283,  ...,  0.1203,  0.0217,  0.0070],\n",
       "                       [-0.0506, -0.0685, -0.0697,  ..., -0.4943, -0.0545, -0.0633],\n",
       "                       [-0.0703,  0.0848, -0.0423,  ..., -0.3457, -0.1200, -0.0484],\n",
       "                       ...,\n",
       "                       [-0.2180,  0.1204, -0.0582,  ..., -0.4413, -0.1044,  0.0347],\n",
       "                       [-0.1677, -0.0202,  0.0103,  ..., -0.2483, -0.0535,  0.0531],\n",
       "                       [ 0.0720, -0.0735, -0.0046,  ..., -0.1864, -0.0848, -0.0013]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc_audioset.bias',\n",
       "               tensor([-0.3537, -0.2475, -0.4678, -0.3557, -0.2614, -0.1378, -0.2048, -0.1257,\n",
       "                       -0.1749, -0.2945, -0.3129, -0.2637, -0.1914, -0.1700, -0.3302, -0.1657,\n",
       "                       -0.2608, -0.2377, -0.1867, -0.2388, -0.1955, -0.2924, -0.2105, -0.3577,\n",
       "                       -0.2468, -0.1999, -0.1309, -0.5515, -0.3622, -0.1173, -0.2123, -0.1828,\n",
       "                       -0.2515, -0.1763, -0.3372, -0.1570, -0.0807, -0.1679, -0.2259, -0.1356,\n",
       "                       -0.1636, -0.2332, -0.1912, -0.0908, -0.1744, -0.2277, -0.3101, -0.2606,\n",
       "                       -0.3547, -0.3004, -0.1540, -0.2947, -0.3089, -0.2579, -0.2052, -0.2061,\n",
       "                       -0.1698, -0.1022, -0.1111, -0.3086, -0.1498, -0.2120, -0.1458, -0.1753,\n",
       "                       -0.2398, -0.3907, -0.2612, -0.0982, -0.1615, -0.3293, -0.1837, -0.1444,\n",
       "                       -0.3892, -0.4273, -0.3540, -0.3073, -0.4383, -0.1952, -0.2886, -0.3588,\n",
       "                       -0.3360, -0.2398, -0.1421, -0.1347, -0.3262, -0.1405, -0.4570, -0.2578,\n",
       "                       -0.1269, -0.1527, -0.4155, -0.2492, -0.1334, -0.4670, -0.1903, -0.2552,\n",
       "                       -0.2842, -0.2360, -0.4018, -0.2526, -0.2655, -0.2518, -0.2827, -0.3671,\n",
       "                       -0.3984, -0.3830, -0.3744, -0.3047, -0.1646, -0.1996, -0.2509, -0.3250,\n",
       "                       -0.5594, -0.5244, -0.1877, -0.2838, -0.2151, -0.1936, -0.2393, -0.1575,\n",
       "                       -0.1752, -0.2057, -0.2905, -0.1186, -0.2225, -0.1959, -0.4943, -0.1772,\n",
       "                       -0.2159, -0.3115, -0.3668, -0.3608, -0.2743, -0.3169, -0.1906, -0.2425,\n",
       "                       -0.3258, -0.0824, -0.3836, -0.4122, -0.4331, -0.2660, -0.2795, -0.3327,\n",
       "                       -0.1466, -0.2250, -0.2795, -0.3054, -0.1550, -0.1840, -0.1815, -0.1592,\n",
       "                       -0.4298, -0.4890, -0.2363, -0.1592, -0.1590, -0.2616, -0.3309, -0.3767,\n",
       "                       -0.2094, -0.3770, -0.3146, -0.2613, -0.3801, -0.3506, -0.3313, -0.2533,\n",
       "                       -0.2320, -0.2512, -0.1647, -0.3419, -0.2479, -0.1421, -0.1017, -0.2116,\n",
       "                       -0.1598, -0.1726, -0.2312, -0.3537, -0.3291, -0.2786, -0.1483, -0.1008,\n",
       "                       -0.4618, -0.2376, -0.2810, -0.3911, -0.2135, -0.4936, -0.2967, -0.1877,\n",
       "                       -0.2395, -0.4240, -0.3124, -0.2018, -0.1087, -0.1425, -0.1351, -0.1676,\n",
       "                       -0.1632, -0.1270, -0.2043, -0.2486, -0.1300, -0.2162, -0.1435, -0.2751,\n",
       "                       -0.3062, -0.1338, -0.0713, -0.0956, -0.1972, -0.1580, -0.0643, -0.1403,\n",
       "                       -0.4107, -0.2211, -0.1588, -0.4987, -0.2738, -0.2291, -0.2731, -0.2987,\n",
       "                       -0.1822, -0.1467, -0.2558, -0.1972, -0.2504, -0.4129, -0.1368, -0.2726,\n",
       "                       -0.3382, -0.4004, -0.2259, -0.2899, -0.4035, -0.3396, -0.1842, -0.3142,\n",
       "                       -0.3869, -0.1684, -0.2231, -0.2617, -0.2228, -0.3131, -0.1719, -0.2044,\n",
       "                       -0.2608, -0.1847, -0.2231, -0.5349, -0.2338, -0.2676, -0.2062, -0.1604,\n",
       "                       -0.2111, -0.3981, -0.5671, -0.2596, -0.2773, -0.2150, -0.1242, -0.1820,\n",
       "                       -0.2427, -0.2429, -0.3614, -0.4391, -0.2054, -0.3485, -0.4412, -0.1954,\n",
       "                       -0.0835, -0.4123, -0.5304, -0.1837, -0.2821, -0.2137, -0.4026, -0.4592,\n",
       "                       -0.2952, -0.1925, -0.1274, -0.4139, -0.2321, -0.2406, -0.1972, -0.1861,\n",
       "                       -0.3665, -0.2442, -0.3615, -0.2871, -0.2453, -0.1878, -0.3397, -0.3027,\n",
       "                       -0.2172, -0.4743, -0.3484, -0.3001, -0.2101, -0.2944, -0.3144, -0.1834,\n",
       "                       -0.2437, -0.2355, -0.3975, -0.3203, -0.1148, -0.2099, -0.2535, -0.2963,\n",
       "                       -0.1439, -0.2473, -0.1720, -0.1529, -0.5164, -0.2371, -0.1876, -0.1773,\n",
       "                       -0.1149, -0.2334, -0.2916, -0.2899, -0.2943, -0.2745, -0.1975, -0.2519,\n",
       "                       -0.4191, -0.3885, -0.2116, -0.2630, -0.3070, -0.2339, -0.4336, -0.3425,\n",
       "                       -0.2274, -0.2695, -0.2546, -0.2056, -0.3684, -0.2268, -0.1964, -0.3175,\n",
       "                       -0.1842, -0.1835, -0.1965, -0.2230, -0.1884, -0.2829, -0.1854, -0.3985,\n",
       "                       -0.1619, -0.1548, -0.3096, -0.1665, -0.4278, -0.2216, -0.2344, -0.2738,\n",
       "                       -0.2025, -0.1480, -0.1634, -0.1746, -0.4287, -0.2180, -0.1856, -0.3711,\n",
       "                       -0.2545, -0.3254, -0.2575, -0.3963, -0.2103, -0.2107, -0.3120, -0.2376,\n",
       "                       -0.2510, -0.4727, -0.1735, -0.1642, -0.1472, -0.1427, -0.1937, -0.1302,\n",
       "                       -0.2861, -0.2194, -0.1853, -0.1560, -0.1799, -0.2459, -0.2076, -0.4442,\n",
       "                       -0.2122, -0.1669, -0.1696, -0.1358, -0.3067, -0.1089, -0.2226, -0.2297,\n",
       "                       -0.1976, -0.1133, -0.1483, -0.1591, -0.2220, -0.2332, -0.2406, -0.2138,\n",
       "                       -0.2284, -0.2109, -0.1738, -0.2394, -0.2299, -0.2842, -0.1720, -0.1865,\n",
       "                       -0.3023, -0.2254, -0.3218, -0.4740, -0.4103, -0.1863, -0.2450, -0.3028,\n",
       "                       -0.4664, -0.2292, -0.2503, -0.3617, -0.2133, -0.0949, -0.2192, -0.1527,\n",
       "                       -0.1928, -0.2296, -0.2942, -0.3051, -0.1859, -0.4133, -0.2166, -0.3207,\n",
       "                       -0.2160, -0.2232, -0.3179, -0.1327, -0.2912, -0.1611, -0.1601, -0.3654,\n",
       "                       -0.1933, -0.2057, -0.3190, -0.1902, -0.2419, -0.1603, -0.2589, -0.1674,\n",
       "                       -0.2111, -0.1031, -0.2695, -0.4614, -0.2496, -0.2255, -0.3635, -0.4138,\n",
       "                       -0.2433, -0.1642, -0.3051, -0.1986, -0.1814, -0.1407, -0.1998, -0.2335,\n",
       "                       -0.1610, -0.2577, -0.2172, -0.3175, -0.2816, -0.2251, -0.2851, -0.1637,\n",
       "                       -0.1873, -0.3904, -0.3235, -0.3839, -0.1854, -0.1589, -0.1304, -0.2944,\n",
       "                       -0.2398, -0.2792, -0.2389, -0.0767, -0.2468, -0.1448, -0.2242, -0.2961,\n",
       "                       -0.2477, -0.2238, -0.1844, -0.4480, -0.2059, -0.2270, -0.2432, -0.3335,\n",
       "                       -0.3057, -0.2527, -0.8537, -0.7422, -0.2719, -0.7250, -0.8501, -0.1985,\n",
       "                       -0.2027, -0.2493, -0.2233, -0.3995, -0.1986, -0.2389, -0.1356, -0.1837,\n",
       "                       -0.2550, -0.2296, -0.2841, -0.2581, -0.2493, -0.0848, -0.2910],\n",
       "                      device='cuda:0'))])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85049d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Transfer_Cnn10(freeze_base=True,pretrain_checkpoint=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d589a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:base.bn0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.bn0.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 1, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 128, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 256, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block4.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "#model parameter 확인\n",
    "for name, param in cnn.named_parameters(): \n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str = 'Hello world, Python!'\n",
    "if str.startswith('Hello'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6db15c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea5aab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer , fc 풀기 2개 \n",
    "for name, param in cnn.named_parameters():\n",
    "    if name.startswith('base.conv_block3'):\n",
    "        param.requires_grad=True\n",
    "    \n",
    "    elif name.startswith('base.conv_block4'):\n",
    "        param.requires_grad=True\n",
    "    \n",
    "    #elif name.startswith('base.fc'):\n",
    "    #    param.requires_grad=True\n",
    "    else:\n",
    "        param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1274d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_base=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70808b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn14,Transfer_Cnn14,init_layer\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, batch_size, dropout=0.5,pretrain_cnn=None,\n",
    "                 pretrain_emb=None,freeze_cnn=True):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.model_type = 'cnn10+transformer'\n",
    "        decoder_layers = TransformerDecoderLayer(d_model=nhid, nhead=nhead, dropout=dropout)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "        self.word_emb = nn.Embedding(ntoken, nhid)\n",
    "        self.ninp = ninp\n",
    "        self.nhid = nhid\n",
    "        self.fc = nn.Linear(512, 512, bias=True)\n",
    "        self.fc1 = nn.Linear(512, nhid, bias=True)\n",
    "        self.dec_fc = nn.Linear(nhid, ntoken)\n",
    "        self.batch_size = batch_size\n",
    "        self.ntoken = ntoken\n",
    "\n",
    "        #def __init__(self, freeze_base, pretrain_checkpoint=None):\n",
    "        pretrain_cnn=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\"\n",
    "        \n",
    "        #self.encoder = Transfer_ResNet54(freeze_base=freeze_cnn, pretrain_checkpoint=pretrain_cnn)\n",
    "        self.encoder = cnn\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pos_encoder = PositionalEncoding(nhid, dropout)\n",
    "        self.generator = nn.Softmax(dim=-1)\n",
    "        self.init_weights()\n",
    "\n",
    "        '''\n",
    "        if pretrain_cnn is not None:\n",
    "            dict_trained = pretrain_cnn\n",
    "            dict_new = self.encoder.state_dict().copy()\n",
    "            new_list = list(self.encoder.state_dict().keys())\n",
    "            trained_list = list(dict_trained.keys())\n",
    "            for i in range(len(new_list)):\n",
    "                dict_new[new_list[i]] = dict_trained[trained_list[i]]\n",
    "            self.encoder.load_state_dict(dict_new)\n",
    "        \n",
    "        if freeze_cnn:\n",
    "            self.freeze_cnn()\n",
    "        '''\n",
    "\n",
    "        if pretrain_emb is not None:\n",
    "            self.word_emb.weight.data = pretrain_emb\n",
    "\n",
    "    '''\n",
    "    def freeze_cnn(self):\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "    '''\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc)\n",
    "        self.word_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dec_fc.bias.data.zero_()\n",
    "        self.dec_fc.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def encode(self, src, input_mask=None):\n",
    "        global x \n",
    "        x = self.encoder(src)  # (batch_size, 2048, T/16, mel_bins/16) ,mixup\n",
    "        x = torch.mean(x, dim=3)  # (batch_size, 2048, T/16)\n",
    "        x = x.permute(2, 0, 1)  # (T/16,batch_size,2048)\n",
    "        x = F.relu_(self.fc(x))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "    def decode(self, mem, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # tgt:(batch_size,T_out)\n",
    "        # mem:(T_mem,batch_size,nhid)\n",
    "\n",
    "        tgt = tgt.transpose(0, 1)  # (T_out,batch_size)\n",
    "        if target_mask is None or target_mask.size(0) != len(tgt):\n",
    "            device = tgt.device\n",
    "            target_mask = self.generate_square_subsequent_mask(len(tgt)).to(device)\n",
    "\n",
    "        tgt = self.dropout(self.word_emb(tgt)) * math.sqrt(self.nhid)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        # mem = self.pos_encoder(mem)\n",
    "        output = self.transformer_decoder(tgt, mem, memory_mask=input_mask, tgt_mask=target_mask,\n",
    "                                          tgt_key_padding_mask=target_padding_mask)\n",
    "        output = self.dec_fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, src, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # src:(batch_size,T_in,feature_dim)\n",
    "        # tgt:(batch_size,T_out)\n",
    "        mem = self.encode(src)\n",
    "        output = self.decode(mem, tgt, input_mask=input_mask, target_mask=target_mask,\n",
    "                             target_padding_mask=target_padding_mask)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e0614a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f62e80d2990>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "from data_handling import get_clotho_loader, get_test_data_loader\n",
    "#from model import TransformerModel  # , RNNModel, RNNModelSmall\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "from util import get_file_list, get_padding, print_hparams, greedy_decode, \\\n",
    "    calculate_bleu, calculate_spider, LabelSmoothingLoss, beam_search, align_word_embedding, gen_str\n",
    "from hparams import hparams\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "\n",
    "hp = hparams()\n",
    "parser = argparse.ArgumentParser(description='hparams for model')\n",
    "\n",
    "device = torch.device('cuda')\n",
    "np.random.seed(hp.seed)\n",
    "torch.manual_seed(hp.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3166e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_emb = align_word_embedding(hp.word_dict_pickle_path, hp.pretrain_emb_path, hp.ntoken,\n",
    "                                        hp.nhid) if hp.load_pretrain_emb else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "476ccfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(hp.ntoken, hp.ninp, hp.nhead, hp.nhid, hp.nlayers, hp.batch_size, dropout=0.2,\n",
    "                             pretrain_cnn=\"/home/hj20/dcase_2020_T6/Cnn10_mAP=0.380.pth\", pretrain_emb=pretrain_emb, freeze_cnn=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e6cadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_emb): Embedding(4371, 192)\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc1): Linear(in_features=512, out_features=192, bias=True)\n",
       "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
       "  (encoder): Transfer_Cnn10(\n",
       "    (base): Cnn10(\n",
       "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_block1): ConvBlock(\n",
       "        (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block2): ConvBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block3): ConvBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block4): ConvBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (generator): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14ee54d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:transformer_decoder.layers.0.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:word_emb.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.bn0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.bn0.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 1, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 2048, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 2048, 1, 1])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc_audioset.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([527, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc_audioset.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([527])\n",
      "param.requries_grad:True\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "#model parameter 확인\n",
    "for name, param in model.named_parameters(): \n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3255704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swa\n",
    "from torchcontrib.optim import SWA\n",
    "import torchcontrib\n",
    "\n",
    "base_opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=hp.lr, weight_decay=1e-6)\n",
    "optimizer = torchcontrib.optim.SWA(base_opt, swa_start=10, swa_freq=5, swa_lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, hp.scheduler_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b5da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swa 안할때\n",
    "optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=hp.lr, weight_decay=1e-6)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, hp.scheduler_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1809dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = hp.data_dir\n",
    "eval_data_dir = hp.eval_data_dir\n",
    "train_data_dir = hp.train_data_dir\n",
    "word_dict_pickle_path = hp.word_dict_pickle_path\n",
    "word_freq_pickle_path = hp.word_freq_pickle_path\n",
    "test_data_dir = hp.test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4fa72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixup\n",
    "#data_dir = hp.data_dir\n",
    "#eval_data_dir = hp.eval_data_dir\n",
    "#train_data_dir = hp.train_data_dir\n",
    "word_dict_pickle_path = hp.word_dict_pickle_path\n",
    "word_freq_pickle_path = hp.word_freq_pickle_path\n",
    "#test_data_dir = hp.test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cc2cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = get_clotho_loader(data_dir=data_dir, split='development',\n",
    "                                      input_field_name='features',\n",
    "                                      output_field_name='words_ind',\n",
    "                                      load_into_memory=False,\n",
    "                                      batch_size=hp.batch_size,\n",
    "                                      nb_t_steps_pad='max',\n",
    "                                      num_workers=4, return_reference=True, augment=hp.spec_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29c2b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3051 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3051 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전체 데이터 \n",
    "from tqdm import tqdm\n",
    "tqdm(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2304b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24420,\n",
       " 24739,\n",
       " 1,\n",
       " 718,\n",
       " 4808,\n",
       " 46,\n",
       " 16,\n",
       " 13138,\n",
       " 17,\n",
       " 24420,\n",
       " 45,\n",
       " 28,\n",
       " 71,\n",
       " 329,\n",
       " 873,\n",
       " 5,\n",
       " 7333,\n",
       " 12184,\n",
       " 768,\n",
       " 1,\n",
       " 97,\n",
       " 149,\n",
       " 45,\n",
       " 168,\n",
       " 132,\n",
       " 555,\n",
       " 1,\n",
       " 49,\n",
       " 3225,\n",
       " 1,\n",
       " 241,\n",
       " 1844,\n",
       " 9147,\n",
       " 81,\n",
       " 1,\n",
       " 991,\n",
       " 455,\n",
       " 14,\n",
       " 7,\n",
       " 3,\n",
       " 330,\n",
       " 1935,\n",
       " 36,\n",
       " 12,\n",
       " 62,\n",
       " 2,\n",
       " 3654,\n",
       " 258,\n",
       " 90,\n",
       " 84,\n",
       " 79,\n",
       " 2134,\n",
       " 1,\n",
       " 5,\n",
       " 75,\n",
       " 4060,\n",
       " 1703,\n",
       " 40,\n",
       " 2369,\n",
       " 468,\n",
       " 67,\n",
       " 630,\n",
       " 2,\n",
       " 114,\n",
       " 15,\n",
       " 5,\n",
       " 2986,\n",
       " 1905,\n",
       " 52,\n",
       " 481,\n",
       " 2,\n",
       " 5,\n",
       " 315,\n",
       " 3003,\n",
       " 121,\n",
       " 811,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 31,\n",
       " 2541,\n",
       " 15,\n",
       " 13,\n",
       " 172,\n",
       " 502,\n",
       " 567,\n",
       " 301,\n",
       " 844,\n",
       " 1,\n",
       " 2748,\n",
       " 2229,\n",
       " 28,\n",
       " 60,\n",
       " 133,\n",
       " 2,\n",
       " 423,\n",
       " 262,\n",
       " 88,\n",
       " 52,\n",
       " 1,\n",
       " 806,\n",
       " 282,\n",
       " 22,\n",
       " 211,\n",
       " 41,\n",
       " 759,\n",
       " 447,\n",
       " 338,\n",
       " 142,\n",
       " 454,\n",
       " 2337,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 22,\n",
       " 1,\n",
       " 129,\n",
       " 23,\n",
       " 268,\n",
       " 809,\n",
       " 692,\n",
       " 630,\n",
       " 417,\n",
       " 3,\n",
       " 148,\n",
       " 20,\n",
       " 55,\n",
       " 91,\n",
       " 38,\n",
       " 241,\n",
       " 2309,\n",
       " 783,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 52,\n",
       " 2,\n",
       " 134,\n",
       " 428,\n",
       " 107,\n",
       " 25,\n",
       " 1,\n",
       " 461,\n",
       " 11,\n",
       " 129,\n",
       " 36,\n",
       " 87,\n",
       " 492,\n",
       " 508,\n",
       " 7,\n",
       " 16,\n",
       " 28,\n",
       " 61,\n",
       " 27,\n",
       " 397,\n",
       " 40,\n",
       " 15,\n",
       " 25,\n",
       " 117,\n",
       " 22,\n",
       " 77,\n",
       " 873,\n",
       " 68,\n",
       " 21,\n",
       " 5,\n",
       " 1,\n",
       " 10,\n",
       " 44,\n",
       " 298,\n",
       " 428,\n",
       " 29,\n",
       " 103,\n",
       " 1259,\n",
       " 128,\n",
       " 1404,\n",
       " 1,\n",
       " 1149,\n",
       " 271,\n",
       " 1,\n",
       " 1,\n",
       " 274,\n",
       " 123,\n",
       " 59,\n",
       " 933,\n",
       " 404,\n",
       " 650,\n",
       " 446,\n",
       " 18,\n",
       " 600,\n",
       " 120,\n",
       " 1608,\n",
       " 11,\n",
       " 372,\n",
       " 209,\n",
       " 2,\n",
       " 900,\n",
       " 97,\n",
       " 46,\n",
       " 240,\n",
       " 60,\n",
       " 57,\n",
       " 9,\n",
       " 31,\n",
       " 175,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 526,\n",
       " 260,\n",
       " 44,\n",
       " 35,\n",
       " 319,\n",
       " 446,\n",
       " 87,\n",
       " 17,\n",
       " 5,\n",
       " 1,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 26,\n",
       " 15,\n",
       " 13,\n",
       " 1,\n",
       " 46,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 398,\n",
       " 8,\n",
       " 27,\n",
       " 6,\n",
       " 2,\n",
       " 10,\n",
       " 94,\n",
       " 241,\n",
       " 125,\n",
       " 2,\n",
       " 44,\n",
       " 77,\n",
       " 13,\n",
       " 29,\n",
       " 13,\n",
       " 538,\n",
       " 524,\n",
       " 410,\n",
       " 293,\n",
       " 209,\n",
       " 164,\n",
       " 107,\n",
       " 142,\n",
       " 137,\n",
       " 679,\n",
       " 104,\n",
       " 708,\n",
       " 323,\n",
       " 903,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 22,\n",
       " 32,\n",
       " 23,\n",
       " 3,\n",
       " 3,\n",
       " 298,\n",
       " 91,\n",
       " 1,\n",
       " 173,\n",
       " 9,\n",
       " 18,\n",
       " 115,\n",
       " 17,\n",
       " 1,\n",
       " 43,\n",
       " 2,\n",
       " 5,\n",
       " 299,\n",
       " 1325,\n",
       " 119,\n",
       " 423,\n",
       " 112,\n",
       " 30,\n",
       " 46,\n",
       " 423,\n",
       " 3,\n",
       " 174,\n",
       " 4,\n",
       " 1,\n",
       " 122,\n",
       " 65,\n",
       " 2,\n",
       " 206,\n",
       " 423,\n",
       " 17,\n",
       " 2216,\n",
       " 163,\n",
       " 14,\n",
       " 864,\n",
       " 273,\n",
       " 55,\n",
       " 61,\n",
       " 387,\n",
       " 15,\n",
       " 61,\n",
       " 4,\n",
       " 111,\n",
       " 136,\n",
       " 121,\n",
       " 372,\n",
       " 23,\n",
       " 238,\n",
       " 220,\n",
       " 20,\n",
       " 4,\n",
       " 124,\n",
       " 2,\n",
       " 16,\n",
       " 3,\n",
       " 12,\n",
       " 133,\n",
       " 967,\n",
       " 28,\n",
       " 1,\n",
       " 1,\n",
       " 191,\n",
       " 548,\n",
       " 189,\n",
       " 34,\n",
       " 4,\n",
       " 19,\n",
       " 5,\n",
       " 3,\n",
       " 10,\n",
       " 64,\n",
       " 468,\n",
       " 92,\n",
       " 146,\n",
       " 52,\n",
       " 160,\n",
       " 144,\n",
       " 180,\n",
       " 3,\n",
       " 342,\n",
       " 127,\n",
       " 430,\n",
       " 3,\n",
       " 1,\n",
       " 119,\n",
       " 4,\n",
       " 70,\n",
       " 5,\n",
       " 35,\n",
       " 1,\n",
       " 63,\n",
       " 73,\n",
       " 22,\n",
       " 5,\n",
       " 28,\n",
       " 1,\n",
       " 3,\n",
       " 158,\n",
       " 21,\n",
       " 25,\n",
       " 176,\n",
       " 4,\n",
       " 12,\n",
       " 181,\n",
       " 431,\n",
       " 81,\n",
       " 96,\n",
       " 8,\n",
       " 34,\n",
       " 522,\n",
       " 127,\n",
       " 1,\n",
       " 11,\n",
       " 8,\n",
       " 17,\n",
       " 3,\n",
       " 3,\n",
       " 30,\n",
       " 32,\n",
       " 899,\n",
       " 250,\n",
       " 50,\n",
       " 13,\n",
       " 1,\n",
       " 27,\n",
       " 10,\n",
       " 2,\n",
       " 15,\n",
       " 97,\n",
       " 4,\n",
       " 85,\n",
       " 5,\n",
       " 21,\n",
       " 12,\n",
       " 523,\n",
       " 537,\n",
       " 72,\n",
       " 12,\n",
       " 20,\n",
       " 128,\n",
       " 17,\n",
       " 44,\n",
       " 3,\n",
       " 9,\n",
       " 61,\n",
       " 3,\n",
       " 2,\n",
       " 20,\n",
       " 31,\n",
       " 160,\n",
       " 103,\n",
       " 47,\n",
       " 24,\n",
       " 126,\n",
       " 18,\n",
       " 124,\n",
       " 1,\n",
       " 8,\n",
       " 35,\n",
       " 76,\n",
       " 13,\n",
       " 13,\n",
       " 56,\n",
       " 1,\n",
       " 30,\n",
       " 17,\n",
       " 56,\n",
       " 990,\n",
       " 64,\n",
       " 4,\n",
       " 55,\n",
       " 64,\n",
       " 20,\n",
       " 39,\n",
       " 33,\n",
       " 633,\n",
       " 5,\n",
       " 137,\n",
       " 19,\n",
       " 3,\n",
       " 1170,\n",
       " 180,\n",
       " 1,\n",
       " 43,\n",
       " 629,\n",
       " 1,\n",
       " 4,\n",
       " 47,\n",
       " 373,\n",
       " 314,\n",
       " 47,\n",
       " 337,\n",
       " 217,\n",
       " 76,\n",
       " 335,\n",
       " 1011,\n",
       " 549,\n",
       " 75,\n",
       " 196,\n",
       " 224,\n",
       " 196,\n",
       " 22,\n",
       " 9,\n",
       " 227,\n",
       " 11,\n",
       " 9,\n",
       " 1,\n",
       " 87,\n",
       " 57,\n",
       " 1,\n",
       " 41,\n",
       " 1,\n",
       " 44,\n",
       " 150,\n",
       " 72,\n",
       " 33,\n",
       " 65,\n",
       " 10,\n",
       " 1,\n",
       " 4,\n",
       " 306,\n",
       " 39,\n",
       " 24,\n",
       " 6,\n",
       " 600,\n",
       " 149,\n",
       " 36,\n",
       " 19,\n",
       " 5,\n",
       " 11,\n",
       " 263,\n",
       " 39,\n",
       " 2,\n",
       " 926,\n",
       " 4,\n",
       " 79,\n",
       " 34,\n",
       " 1,\n",
       " 65,\n",
       " 61,\n",
       " 3,\n",
       " 37,\n",
       " 157,\n",
       " 25,\n",
       " 15,\n",
       " 193,\n",
       " 17,\n",
       " 4,\n",
       " 29,\n",
       " 67,\n",
       " 12,\n",
       " 759,\n",
       " 56,\n",
       " 16,\n",
       " 92,\n",
       " 20,\n",
       " 18,\n",
       " 95,\n",
       " 11,\n",
       " 5,\n",
       " 3,\n",
       " 29,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 103,\n",
       " 171,\n",
       " 411,\n",
       " 170,\n",
       " 100,\n",
       " 10,\n",
       " 142,\n",
       " 132,\n",
       " 4,\n",
       " 47,\n",
       " 4,\n",
       " 2,\n",
       " 127,\n",
       " 6,\n",
       " 2,\n",
       " 86,\n",
       " 106,\n",
       " 26,\n",
       " 40,\n",
       " 15,\n",
       " 32,\n",
       " 3,\n",
       " 4,\n",
       " 14,\n",
       " 68,\n",
       " 8,\n",
       " 13,\n",
       " 10,\n",
       " 672,\n",
       " 69,\n",
       " 36,\n",
       " 5,\n",
       " 15,\n",
       " 19,\n",
       " 50,\n",
       " 11,\n",
       " 313,\n",
       " 13,\n",
       " 21,\n",
       " 40,\n",
       " 33,\n",
       " 25,\n",
       " 41,\n",
       " 79,\n",
       " 111,\n",
       " 42,\n",
       " 75,\n",
       " 2,\n",
       " 1,\n",
       " 12,\n",
       " 23,\n",
       " 20,\n",
       " 124,\n",
       " 9,\n",
       " 7,\n",
       " 66,\n",
       " 43,\n",
       " 155,\n",
       " 85,\n",
       " 2,\n",
       " 7,\n",
       " 17,\n",
       " 145,\n",
       " 305,\n",
       " 51,\n",
       " 2,\n",
       " 441,\n",
       " 1,\n",
       " 34,\n",
       " 3,\n",
       " 24,\n",
       " 42,\n",
       " 47,\n",
       " 58,\n",
       " 2,\n",
       " 48,\n",
       " 7,\n",
       " 69,\n",
       " 126,\n",
       " 16,\n",
       " 169,\n",
       " 79,\n",
       " 17,\n",
       " 667,\n",
       " 232,\n",
       " 353,\n",
       " 38,\n",
       " 3,\n",
       " 3,\n",
       " 590,\n",
       " 399,\n",
       " 63,\n",
       " 82,\n",
       " 4,\n",
       " 3,\n",
       " 131,\n",
       " 9,\n",
       " 47,\n",
       " 288,\n",
       " 195,\n",
       " 8,\n",
       " 56,\n",
       " 1,\n",
       " 346,\n",
       " 6,\n",
       " 17,\n",
       " 60,\n",
       " 28,\n",
       " 47,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 41,\n",
       " 53,\n",
       " 32,\n",
       " 107,\n",
       " 50,\n",
       " 69,\n",
       " 97,\n",
       " 35,\n",
       " 22,\n",
       " 99,\n",
       " 107,\n",
       " 54,\n",
       " 849,\n",
       " 360,\n",
       " 115,\n",
       " 1,\n",
       " 43,\n",
       " 4,\n",
       " 1,\n",
       " 19,\n",
       " 170,\n",
       " 1,\n",
       " 3,\n",
       " 18,\n",
       " 38,\n",
       " 59,\n",
       " 112,\n",
       " 17,\n",
       " 140,\n",
       " 1,\n",
       " 130,\n",
       " 24,\n",
       " 7,\n",
       " 66,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 70,\n",
       " 6,\n",
       " 4,\n",
       " 23,\n",
       " 104,\n",
       " 25,\n",
       " 156,\n",
       " 28,\n",
       " 15,\n",
       " 5,\n",
       " 425,\n",
       " 86,\n",
       " 237,\n",
       " 92,\n",
       " 2,\n",
       " 10,\n",
       " 30,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 11,\n",
       " 6,\n",
       " 1,\n",
       " 52,\n",
       " 268,\n",
       " 176,\n",
       " 11,\n",
       " 7,\n",
       " 159,\n",
       " 33,\n",
       " 79,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 48,\n",
       " 2,\n",
       " 15,\n",
       " 139,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 131,\n",
       " 263,\n",
       " 12,\n",
       " 376,\n",
       " 9,\n",
       " 238,\n",
       " 21,\n",
       " 5,\n",
       " 128,\n",
       " 9,\n",
       " 107,\n",
       " 69,\n",
       " 129,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 116,\n",
       " 29,\n",
       " 43,\n",
       " 84,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 26,\n",
       " 279,\n",
       " 1,\n",
       " 157,\n",
       " 136,\n",
       " 48,\n",
       " 20,\n",
       " 16,\n",
       " 34,\n",
       " 223,\n",
       " 34,\n",
       " 16,\n",
       " 50,\n",
       " 5,\n",
       " 221,\n",
       " 55,\n",
       " 73,\n",
       " 43,\n",
       " 2,\n",
       " 80,\n",
       " 10,\n",
       " 89,\n",
       " 94,\n",
       " 3,\n",
       " 55,\n",
       " 57,\n",
       " 1,\n",
       " 51,\n",
       " 28,\n",
       " 115,\n",
       " 306,\n",
       " 12,\n",
       " 25,\n",
       " 275,\n",
       " 157,\n",
       " 8,\n",
       " 240,\n",
       " 8,\n",
       " 13,\n",
       " 43,\n",
       " 9,\n",
       " 31,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 22,\n",
       " 11,\n",
       " 5,\n",
       " 39,\n",
       " 17,\n",
       " 8,\n",
       " 14,\n",
       " 2,\n",
       " 39,\n",
       " 63,\n",
       " 6,\n",
       " 15,\n",
       " 8,\n",
       " 8,\n",
       " 14,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 24,\n",
       " 4,\n",
       " 10,\n",
       " 113,\n",
       " 3,\n",
       " 15,\n",
       " 20,\n",
       " 27,\n",
       " 21,\n",
       " 2,\n",
       " 48,\n",
       " 102,\n",
       " 75,\n",
       " 52,\n",
       " 314,\n",
       " 26,\n",
       " 26,\n",
       " 150,\n",
       " 6,\n",
       " 379,\n",
       " 9,\n",
       " 10,\n",
       " 2,\n",
       " 9,\n",
       " 91,\n",
       " 5,\n",
       " 195,\n",
       " 2,\n",
       " 27,\n",
       " 32,\n",
       " 51,\n",
       " 3,\n",
       " 35,\n",
       " 135,\n",
       " 60,\n",
       " 19,\n",
       " 1,\n",
       " 251,\n",
       " 33,\n",
       " 266,\n",
       " 28,\n",
       " 1,\n",
       " 13,\n",
       " 72,\n",
       " 25,\n",
       " 2,\n",
       " 79,\n",
       " 13,\n",
       " 41,\n",
       " 2,\n",
       " 5,\n",
       " 15,\n",
       " 101,\n",
       " 12,\n",
       " 56,\n",
       " 4,\n",
       " 27,\n",
       " 61,\n",
       " 61,\n",
       " 3,\n",
       " 4,\n",
       " 41,\n",
       " 9,\n",
       " 26,\n",
       " 188,\n",
       " 73,\n",
       " 36,\n",
       " 31,\n",
       " 17,\n",
       " 4,\n",
       " 10,\n",
       " 94,\n",
       " 23,\n",
       " 1,\n",
       " 16,\n",
       " 38,\n",
       " 131,\n",
       " 202,\n",
       " 27,\n",
       " 1,\n",
       " 180,\n",
       " 30,\n",
       " 3,\n",
       " 3,\n",
       " 84,\n",
       " 1,\n",
       " 147,\n",
       " 41,\n",
       " 3,\n",
       " 60,\n",
       " 1,\n",
       " 4,\n",
       " 21,\n",
       " 45,\n",
       " 175,\n",
       " 2,\n",
       " 104,\n",
       " 7,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 18,\n",
       " 8,\n",
       " 130,\n",
       " 2,\n",
       " 133,\n",
       " 9,\n",
       " 58,\n",
       " 20,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 133,\n",
       " 61,\n",
       " 8,\n",
       " 5,\n",
       " 103,\n",
       " 63,\n",
       " 5,\n",
       " 5,\n",
       " 251,\n",
       " 44,\n",
       " 3,\n",
       " 109,\n",
       " 2,\n",
       " 15,\n",
       " 7,\n",
       " 17,\n",
       " 76,\n",
       " 233,\n",
       " 282,\n",
       " 2,\n",
       " 29,\n",
       " 202,\n",
       " 50,\n",
       " 2,\n",
       " 56,\n",
       " 56,\n",
       " 73,\n",
       " 30,\n",
       " 89,\n",
       " 1,\n",
       " 5,\n",
       " 32,\n",
       " 2,\n",
       " 134,\n",
       " 2,\n",
       " 2,\n",
       " 179,\n",
       " 28,\n",
       " 87,\n",
       " 160,\n",
       " 12,\n",
       " 7,\n",
       " 4,\n",
       " 35,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 13,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 115,\n",
       " 2,\n",
       " 11,\n",
       " 39,\n",
       " 22,\n",
       " 62,\n",
       " 57,\n",
       " 3,\n",
       " 36,\n",
       " 1,\n",
       " 18,\n",
       " 1,\n",
       " 41,\n",
       " 34,\n",
       " 5,\n",
       " 17,\n",
       " 12,\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "#워드 개수 확인\n",
    "with open('./create_dataset/data/pickles/words_frequencies.p','rb') as f:\n",
    "    words_freq=pickle.load(f)\n",
    "words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85ae9cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4371"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f1f1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_beam = get_clotho_loader(data_dir=data_dir, split='evaluation',\n",
    "                                        input_field_name='features',\n",
    "                                        output_field_name='words_ind',\n",
    "                                        load_into_memory=False,\n",
    "                                        batch_size=32,\n",
    "                                        nb_t_steps_pad='max',\n",
    "                                        shuffle=False,\n",
    "                                        return_reference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cf2eb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "test_data = get_test_data_loader(data_dir=test_data_dir,\n",
    "                                     batch_size=hp.batch_size * 2,\n",
    "                                     nb_t_steps_pad='max',\n",
    "                                     shuffle=False,\n",
    "                                     drop_last=False,\n",
    "                                     input_pad_at='start',\n",
    "                                     num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "475347a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss_text = 0.\n",
    "    start_time = time.time()\n",
    "    batch = 0\n",
    "    for src, tgt, tgt_len,ref in training_data:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        tgt_pad_mask = get_padding(tgt, tgt_len)\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        tgt_pad_mask = tgt_pad_mask[:, :-1]\n",
    "        tgt_y = tgt[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, tgt_in, target_padding_mask=tgt_pad_mask)\n",
    "\n",
    "        loss_text = criterion(output.contiguous().view(-1, hp.ntoken), tgt_y.transpose(0, 1).contiguous().view(-1))\n",
    "        loss = loss_text\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), hp.clip_grad)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "        total_loss_text += loss_text.item()\n",
    "\n",
    "        writer.add_scalar('Loss/train-text', loss_text.item(), (epoch - 1) * len(training_data) + batch)\n",
    "        \n",
    "        \n",
    "        batch += 1\n",
    "        \n",
    "        if batch % hp.log_interval == 0 and batch > 0:\n",
    "            mean_text_loss = total_loss_text / hp.log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            current_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\n",
    "            logging.info('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2e} | ms/batch {:5.2f} | '\n",
    "                         'loss-text {:5.4f}'.format(\n",
    "                epoch, batch, len(training_data), current_lr,\n",
    "                elapsed * 1000 / hp.log_interval, mean_text_loss))\n",
    "            total_loss_text = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "            optimizer.swap_swa_sgd()\n",
    "\n",
    "def eval_all(evaluation_data, max_len=30, eos_ind=9, word_dict_pickle_path=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_sentence_all = []\n",
    "        ref_all = []\n",
    "        for src, tgt, _, ref in evaluation_data:\n",
    "            src = src.to(device)\n",
    "            output = greedy_decode(model, src, max_len=max_len)\n",
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for i in range(output.size()[0]):\n",
    "                output_sentence_ind = []\n",
    "                for j in range(1, output.size(1)):\n",
    "                    sym = output[i, j]\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n",
    "\n",
    "        loss_mean = score\n",
    "        writer.add_scalar(f'Loss/eval_greddy', loss_mean, epoch)\n",
    "        msg = f'eval_greddy SPIDEr: {loss_mean:2.4f}'\n",
    "        logging.info(msg)\n",
    "\n",
    "\n",
    "def eval_with_beam(evaluation_data, max_len=30, eos_ind=9, word_dict_pickle_path=None, beam_size=3):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_sentence_all = []\n",
    "        ref_all = []\n",
    "        for src, tgt, _, ref in evaluation_data:\n",
    "            src = src.to(device)\n",
    "            output = beam_search(model, src, max_len, start_symbol_ind=0, beam_size=beam_size)\n",
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for single_sample in output:\n",
    "                output_sentence_ind = []\n",
    "                for sym in single_sample:\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n",
    "\n",
    "        loss_mean = score\n",
    "        writer.add_scalar(f'Loss/eval_beam', loss_mean, epoch)\n",
    "        msg = f'eval_beam_{beam_size} SPIDEr: {loss_mean:2.4f}'\n",
    "        logging.info(msg)\n",
    "\n",
    "\n",
    "def test_with_beam(test_data, max_len=30, eos_ind=9, beam_size=3):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with open(\"test_out.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['file_name', 'caption_predicted'])\n",
    "            for src, filename in test_data:\n",
    "                src = src.to(device)\n",
    "                output = beam_search(model, src, max_len, start_symbol_ind=0, beam_size=beam_size)\n",
    "\n",
    "                output_sentence_ind_batch = []\n",
    "                for single_sample in output:\n",
    "                    output_sentence_ind = []\n",
    "                    for sym in single_sample:\n",
    "                        if sym == eos_ind: break\n",
    "                        output_sentence_ind.append(sym.item())\n",
    "                    output_sentence_ind_batch.append(output_sentence_ind)\n",
    "                out_str = gen_str(output_sentence_ind_batch, hp.word_dict_pickle_path)\n",
    "                for caption, fn in zip(out_str, filename):\n",
    "                    writer.writerow(['{}.wav'.format(fn), caption])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d583cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hp.label_smoothing:\n",
    "    criterion = LabelSmoothingLoss(hp.ntoken, smoothing=0.1)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=hp.ntoken - 1)\n",
    "\n",
    "now_time = str(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(time.time())))\n",
    "log_dir = 'models/{name}'.format(name=hp.name)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "log_path = os.path.join(log_dir, 'train.log')\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                        format=\n",
    "                        '%(asctime)s - %(levelname)s: %(message)s',\n",
    "                        handlers=[\n",
    "                            logging.FileHandler(log_path),\n",
    "                            logging.StreamHandler(sys.stdout)]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0708d0f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-04 22:26:04,490 - INFO: TransformerModel(\n",
      "  (transformer_decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (dropout3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (dropout3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_emb): Embedding(4371, 192)\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc1): Linear(in_features=512, out_features=192, bias=True)\n",
      "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
      "  (encoder): Transfer_Cnn10(\n",
      "    (base): Cnn10(\n",
      "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_block1): ConvBlock(\n",
      "        (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_block2): ConvBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_block3): ConvBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_block4): ConvBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (generator): Softmax(dim=-1)\n",
      ")\n",
      "2021-12-04 22:26:04,496 - INFO: {'batch_size': 8, 'beam_width': 3, 'checkpoint_save_interval': 5, 'clip_grad': 2.5, 'data_dir': PosixPath('/home/hj20/dcase_2020_T6/create_dataset/data/data_splits'), 'device': 'cuda', 'eval_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/data_splits/evaluation', 'freeze_cnn': True, 'label_smoothing': True, 'load_pretrain_cnn': True, 'load_pretrain_emb': False, 'load_pretrain_model': True, 'log_interval': 100, 'lr': 0.0001, 'mode': 'train', 'name': '1204cnn10일부', 'nhead': 4, 'nhid': 192, 'ninp': 64, 'nkeyword': 4979, 'nlayers': 2, 'ntoken': 4371, 'pretrain_cnn_path': '/home/hj20/dcase_2020_T6/models/tag_models/TagModel_45.pt', 'pretrain_emb_path': '/home/hj20/dcase_2020_T6/models/w2v_192.mod', 'pretrain_model_path': '/home/hj20/dcase_2020_T6/models/base/46.pt', 'scheduler_decay': 0.98, 'seed': 1111, 'spec_augmentation': True, 'test_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/test_data', 'train_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/data_splits/development', 'training_epochs': 50, 'word_dict_pickle_path': '/home/hj20/dcase_2020_T6/create_dataset/data/pickles/words_list.p', 'word_freq_pickle_path': '/home/hj20/dcase_2020_T6/create_dataset/data/pickles/words_frequencies.p'}\n",
      "2021-12-04 22:26:04,498 - INFO: Data loaded!\n",
      "2021-12-04 22:26:04,499 - INFO: Data size: 3051\n",
      "2021-12-04 22:26:04,500 - INFO: Total Model parameters: 8643283\n"
     ]
    }
   ],
   "source": [
    "    logging.info(str(model))\n",
    "\n",
    "    logging.info(str(print_hparams(hp)))\n",
    "\n",
    "    logging.info('Data loaded!')\n",
    "    logging.info('Data size: ' + str(len(training_data)))\n",
    "\n",
    "    logging.info('Total Model parameters: ' + str(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51859f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-04 22:26:14,576 - INFO: | epoch   1 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 91.87 | loss-text 5.8086\n",
      "2021-12-04 22:26:23,577 - INFO: | epoch   1 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 90.00 | loss-text 5.0820\n",
      "2021-12-04 22:26:32,601 - INFO: | epoch   1 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 90.23 | loss-text 4.9649\n",
      "2021-12-04 22:26:41,682 - INFO: | epoch   1 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 90.80 | loss-text 4.7717\n",
      "2021-12-04 22:26:50,699 - INFO: | epoch   1 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 90.17 | loss-text 4.7016\n",
      "2021-12-04 22:26:59,827 - INFO: | epoch   1 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 91.27 | loss-text 4.7260\n",
      "2021-12-04 22:27:08,891 - INFO: | epoch   1 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 90.64 | loss-text 4.6165\n",
      "2021-12-04 22:27:17,904 - INFO: | epoch   1 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 90.12 | loss-text 4.5694\n",
      "2021-12-04 22:27:27,118 - INFO: | epoch   1 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 92.14 | loss-text 4.5563\n",
      "2021-12-04 22:27:36,252 - INFO: | epoch   1 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 91.34 | loss-text 4.5457\n",
      "2021-12-04 22:27:45,376 - INFO: | epoch   1 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 91.23 | loss-text 4.4852\n",
      "2021-12-04 22:27:54,537 - INFO: | epoch   1 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 91.61 | loss-text 4.4754\n",
      "2021-12-04 22:28:03,632 - INFO: | epoch   1 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 90.95 | loss-text 4.3810\n",
      "2021-12-04 22:28:12,830 - INFO: | epoch   1 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 91.97 | loss-text 4.3971\n",
      "2021-12-04 22:28:22,039 - INFO: | epoch   1 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 92.08 | loss-text 4.3896\n",
      "2021-12-04 22:28:31,290 - INFO: | epoch   1 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 92.50 | loss-text 4.3867\n",
      "2021-12-04 22:28:40,529 - INFO: | epoch   1 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 92.38 | loss-text 4.3366\n",
      "2021-12-04 22:28:49,659 - INFO: | epoch   1 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 91.30 | loss-text 4.2827\n",
      "2021-12-04 22:28:58,966 - INFO: | epoch   1 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 93.06 | loss-text 4.3218\n",
      "2021-12-04 22:29:08,169 - INFO: | epoch   1 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 92.03 | loss-text 4.3265\n",
      "2021-12-04 22:29:17,506 - INFO: | epoch   1 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 93.36 | loss-text 4.3120\n",
      "2021-12-04 22:29:26,756 - INFO: | epoch   1 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 92.50 | loss-text 4.3409\n",
      "2021-12-04 22:29:36,011 - INFO: | epoch   1 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 92.55 | loss-text 4.2558\n",
      "2021-12-04 22:29:45,232 - INFO: | epoch   1 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 92.20 | loss-text 4.2580\n",
      "2021-12-04 22:29:54,511 - INFO: | epoch   1 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 92.78 | loss-text 4.2632\n",
      "2021-12-04 22:30:03,773 - INFO: | epoch   1 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 92.61 | loss-text 4.1718\n",
      "2021-12-04 22:30:13,003 - INFO: | epoch   1 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 92.29 | loss-text 4.1494\n",
      "2021-12-04 22:30:22,276 - INFO: | epoch   1 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 92.72 | loss-text 4.1799\n",
      "2021-12-04 22:30:31,508 - INFO: | epoch   1 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 92.32 | loss-text 4.1904\n",
      "2021-12-04 22:30:40,779 - INFO: | epoch   1 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 92.70 | loss-text 4.2267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003932\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 13143, 'reflen': 11256, 'guess': [13143, 12119, 11095, 10071], 'correct': [4391, 1123, 302, 44]}\n",
      "ratio: 1.1676439232408344\n",
      "Bleu_1: 0.334\n",
      "Bleu_2: 0.176\n",
      "Bleu_3: 0.094\n",
      "Bleu_4: 0.044\n",
      "computing METEOR score...\n",
      "METEOR: 0.107\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.278\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.088\n",
      "computing SPICE score...\n",
      "SPICE: 0.068\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.078\n",
      "2021-12-04 22:31:12,880 - INFO: eval_greddy SPIDEr: 0.0779\n",
      "loading annotations into memory...\n",
      "0:00:00.003917\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8464, 'reflen': 9444, 'guess': [8464, 7440, 6416, 5392], 'correct': [4333, 1268, 401, 92]}\n",
      "ratio: 0.8962304108427682\n",
      "Bleu_1: 0.456\n",
      "Bleu_2: 0.263\n",
      "Bleu_3: 0.157\n",
      "Bleu_4: 0.087\n",
      "computing METEOR score...\n",
      "METEOR: 0.117\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.321\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.140\n",
      "computing SPICE score...\n",
      "SPICE: 0.069\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.104\n",
      "2021-12-04 22:31:37,579 - INFO: eval_beam_2 SPIDEr: 0.1042\n",
      "loading annotations into memory...\n",
      "0:00:00.003897\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7777, 'reflen': 9244, 'guess': [7777, 6753, 5729, 4705], 'correct': [4242, 1353, 451, 105]}\n",
      "ratio: 0.8413024664646428\n",
      "Bleu_1: 0.452\n",
      "Bleu_2: 0.274\n",
      "Bleu_3: 0.170\n",
      "Bleu_4: 0.097\n",
      "computing METEOR score...\n",
      "METEOR: 0.120\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.329\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.158\n",
      "computing SPICE score...\n",
      "SPICE: 0.073\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.115\n",
      "2021-12-04 22:32:05,237 - INFO: eval_beam_3 SPIDEr: 0.1154\n",
      "loading annotations into memory...\n",
      "0:00:00.003865\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7128, 'reflen': 9210, 'guess': [7128, 6104, 5080, 4056], 'correct': [4197, 1486, 569, 141]}\n",
      "ratio: 0.7739413680780918\n",
      "Bleu_1: 0.440\n",
      "Bleu_2: 0.283\n",
      "Bleu_3: 0.188\n",
      "Bleu_4: 0.115\n",
      "computing METEOR score...\n",
      "METEOR: 0.125\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.344\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.192\n",
      "computing SPICE score...\n",
      "SPICE: 0.079\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.136\n",
      "2021-12-04 22:32:35,094 - INFO: eval_beam_4 SPIDEr: 0.1355\n",
      "2021-12-04 22:32:44,520 - INFO: | epoch   2 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 94.23 | loss-text 4.1115\n",
      "2021-12-04 22:32:53,639 - INFO: | epoch   2 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 91.18 | loss-text 4.1594\n",
      "2021-12-04 22:33:02,816 - INFO: | epoch   2 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 91.77 | loss-text 4.1428\n",
      "2021-12-04 22:33:12,086 - INFO: | epoch   2 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 92.69 | loss-text 4.1318\n",
      "2021-12-04 22:33:21,297 - INFO: | epoch   2 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 92.11 | loss-text 4.0737\n"
     ]
    }
   ],
   "source": [
    "#일부 레이어 1131\n",
    "epoch = 1\n",
    "if hp.mode == 'train':\n",
    "    while epoch < hp.training_epochs + 1:\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        torch.save(model.state_dict(), '{log_dir}/{num_epoch}.pt'.format(log_dir=log_dir, num_epoch=epoch))\n",
    "        scheduler.step(epoch)\n",
    "        eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=2)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=3)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=4)\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5950aaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-04 14:04:22,352 - INFO: | epoch   1 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 59.65 | loss-text 5.8095\n",
      "2021-12-04 14:04:28,155 - INFO: | epoch   1 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 58.03 | loss-text 5.0831\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cb09f8526cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{log_dir}/{num_epoch}.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-94649549a569>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_pad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9d2cd804fa0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, input_mask, target_mask, target_padding_mask)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         output = self.decode(mem, tgt, input_mask=input_mask, target_mask=target_mask,\n\u001b[0;32m--> 126\u001b[0;31m                              target_padding_mask=target_padding_mask)\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9d2cd804fa0a>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, mem, tgt, input_mask, target_mask, target_padding_mask)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mtarget_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#mixup\n",
    "epoch = 1\n",
    "if hp.mode == 'train':\n",
    "    while epoch < hp.training_epochs + 1:\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        torch.save(model.state_dict(), '{log_dir}/{num_epoch}.pt'.format(log_dir=log_dir, num_epoch=epoch))\n",
    "        scheduler.step(epoch)\n",
    "        eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=2)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=3)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=4)\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b593960e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-85fdcc81b46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for src, tgt, tgt_len in training_data:\n",
    "    src = src.to(device)\n",
    "    tgt = tgt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3df15dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.training_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6fa65a",
   "metadata": {},
   "source": [
    "epoch=37 eval_beam_3 SPIDEr: 0.2344 # 2개 layer 만 trainable -06/9  \n",
    " SPIDEr: # 5개 layer 만 trainable -06/10 0.2252\n",
    "별 차이 없음 ;;;;;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19ee5c",
   "metadata": {},
   "source": [
    "model score check (eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3852d268",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/base/48.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2f0e4443ea7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#if hp.mode == 'eval':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Evaluation model score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/base/48.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_beam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/base/48.pt'"
     ]
    }
   ],
   "source": [
    "#if hp.mode == 'eval':\n",
    "# Evaluation model score\n",
    "model.load_state_dict(torch.load(\"./models/base/48.pt\"))\n",
    "eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=2)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=3)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1735c2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./models/base/49.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixup(object):\n",
    "    def __init__(self, mixup_alpha, random_seed=1234):\n",
    "        \"\"\"Mixup coefficient generator.\n",
    "        \"\"\"\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    def get_lambda(self, batch_size):\n",
    "        \"\"\"Get mixup random coefficients.\n",
    "        Args:\n",
    "          batch_size: int\n",
    "        Returns:\n",
    "          mixup_lambdas: (batch_size,)\n",
    "        \"\"\"\n",
    "        mixup_lambdas = []\n",
    "        for n in range(0, batch_size, 2):\n",
    "            lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "            mixup_lambdas.append(lam)\n",
    "            mixup_lambdas.append(1. - lam)\n",
    "\n",
    "        return np.array(mixup_lambdas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fecb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd36458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mixup(x, mixup_lambda):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes \n",
    "    (1, 3, 5, ...).\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0 :: 2].transpose(0, -1) * mixup_lambda[0 :: 2] + \\\n",
    "        x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d22dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.feature.inverse import mel_to_audio, mel_to_stft\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University, Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['feature_extraction']\n",
    "\n",
    "\n",
    "def feature_extraction(audio_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"Feature extraction function.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: Log mel-bands energies of shape=(t, nb_mels)\n",
    "    :rtype: numpy.ndarray, numpy.float\n",
    "    \"\"\"\n",
    "    y = audio_data/abs(audio_data).max()\n",
    "    mel_bands = melspectrogram(\n",
    "        y=y, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power, n_mels=nb_mels,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm).T\n",
    "\n",
    "    return np.log(mel_bands + np.finfo(float).eps)\n",
    "\n",
    "\n",
    "def from_mel_to_audio(mel_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"Feature extraction inverse function.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: audio data\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.exp(mel_data) - np.finfo(float).eps\n",
    "    audio_data = mel_to_audio(\n",
    "        M=y.T, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm)\n",
    "\n",
    "    return audio_data\n",
    "\n",
    "\n",
    "def from_mel_to_stft(mel_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"From logmelspectrogram to stft.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: audio data\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.exp(mel_data) - np.finfo(float).eps\n",
    "    stft = mel_to_stft(\n",
    "        M=y.T, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm)\n",
    "\n",
    "    return stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beae2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "#from tools.features_log_mel_bands import feature_extraction, from_mel_to_audio, from_mel_to_stft\n",
    "from pathlib import Path\n",
    "import pysndfx\n",
    "import gc\n",
    "\n",
    "import copy\n",
    "\n",
    "#from tools.file_io import load_audio_file\n",
    "import torch\n",
    "\n",
    "\n",
    "__author__ = 'Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "\n",
    "class MixUp:\n",
    "\n",
    "    def __init__(self, p, settings_features, simple_concat_captions=True,\n",
    "                 sample_audio=False):\n",
    "\n",
    "        self.p = p\n",
    "        self.sample_audio = sample_audio\n",
    "        self.settings_features = settings_features\n",
    "        self.simple_concat_captions = simple_concat_captions\n",
    "\n",
    "    def from_mel(self, mel):\n",
    "        return 700 * (10 ** (mel / 2595.0) - 1)\n",
    "\n",
    "    def to_mel(self, hertz):\n",
    "        return 2595.0 * np.log10(1 + hertz / 700.0)\n",
    "\n",
    "    def mix_audio(self, first_audio, second_audio):\n",
    "\n",
    "        a = np.random.uniform(0.4, 0.6)\n",
    "\n",
    "        shorter, longer = first_audio, second_audio\n",
    "\n",
    "        if shorter.shape[0] == longer.shape[0]:\n",
    "            if self.sample_audio:\n",
    "                return (longer + shorter) / 2.0\n",
    "            else:\n",
    "                longer = from_mel_to_audio(longer, **self.settings_features['process']) * a\n",
    "                shorter = from_mel_to_audio(shorter,\n",
    "                                            **self.settings_features['process'])\n",
    "                return feature_extraction((longer + shorter) / 2, **self.settings_features['process'])\n",
    "\n",
    "        if first_audio.shape[0] > second_audio.shape[0]:\n",
    "            shorter, longer = longer, shorter\n",
    "\n",
    "\n",
    "        if self.sample_audio:\n",
    "            start = random.randint(0, longer.shape[0] - 1 - shorter.shape[0])\n",
    "            end = start + shorter.shape[0]\n",
    "            longer *= a\n",
    "            longer[start:end] += shorter * (1 - a)\n",
    "        else:\n",
    "            longer = from_mel_to_audio(longer, **self.settings_features['process']) * a\n",
    "            shorter = from_mel_to_audio(shorter,\n",
    "                                        **self.settings_features['process'])\n",
    "            start = random.randint(0, longer.shape[0] - 1 - shorter.shape[0])\n",
    "            end = start + shorter.shape[0]\n",
    "            longer[start:end] += shorter * (1 - a)\n",
    "            longer = feature_extraction(longer,\n",
    "                                        **self.settings_features['process'])\n",
    "\n",
    "        return longer\n",
    "\n",
    "    def mix_labels(self, first_labels, second_labels):\n",
    "        if self.simple_concat_captions:\n",
    "            return np.hstack([first_labels[:-1], second_labels[1:]])\n",
    "        else:\n",
    "\n",
    "            first_token = first_labels[0]\n",
    "            last_token = first_labels[-1]\n",
    "            first_labels = first_labels[1:-1]\n",
    "            second_labels = second_labels[1:-1]\n",
    "            res = np.empty((first_labels.size + second_labels.size,),\n",
    "                           dtype=first_labels.dtype)\n",
    "            min_size = min(first_labels.size, second_labels.size)\n",
    "            res[0:2*min_size:2] = first_labels[:min_size]\n",
    "            res[1:2*min_size:2] = second_labels[:min_size]\n",
    "            if first_labels.size > second_labels.size:\n",
    "                res[min_size * 2:] = first_labels[min_size:]\n",
    "            elif second_labels.size > first_labels.size:\n",
    "                res[min_size*2:] = second_labels[min_size:]\n",
    "            res = np.concatenate(([first_token], res))\n",
    "            res = np.concatenate((res, [last_token]))\n",
    "            return res\n",
    "\n",
    "    def mix_audio_and_labels(self,\n",
    "                             first_audio, second_audio,\n",
    "                             first_labels, second_labels):\n",
    "        mixed_audio = self.mix_audio(first_audio, second_audio)\n",
    "        mixed_labels = self.mix_labels(first_labels, second_labels)\n",
    "\n",
    "        return mixed_audio, mixed_labels\n",
    "\n",
    "    def __call__(self, dataset, inputs):\n",
    "        resulted_audio, resulted_labels, filename = inputs[0], inputs[1], inputs[2]\n",
    "        if np.random.uniform() <= self.p:\n",
    "            random_sample = dataset.random_sample(sample_audio=self.sample_audio)\n",
    "            resulted_audio, resulted_labels = self.mix_audio_and_labels(\n",
    "                resulted_audio, random_sample[0],\n",
    "                resulted_labels, random_sample[1]\n",
    "            )\n",
    "        return resulted_audio, resulted_labels\n",
    "\n",
    "\n",
    "class AudioAugmentation:\n",
    "    # https://github.com/ex4sperans/freesound-classification\n",
    "    def __init__(self, p):\n",
    "\n",
    "        self.p = p\n",
    "        self.effects_chain = (\n",
    "            pysndfx.AudioEffectsChain()\n",
    "                .reverb(\n",
    "                reverberance=random.randrange(50),\n",
    "                room_scale=random.randrange(50),\n",
    "                stereo_depth=random.randrange(50)\n",
    "            )\n",
    "                .pitch(shift=random.randrange(-300, 300))\n",
    "                .overdrive(gain=random.randrange(2, 10))\n",
    "                .speed(random.uniform(0.9, 1.1))\n",
    "        )\n",
    "\n",
    "    def __call__(self, dataset, inputs):\n",
    "\n",
    "        resulted_audio = inputs[0]\n",
    "        captions = inputs[1]\n",
    "        del inputs\n",
    "        gc.collect()\n",
    "        if np.random.uniform() < self.p:\n",
    "            resulted_audio = torch.from_numpy(self.effects_chain(resulted_audio.numpy()))\n",
    "        return resulted_audio, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a5ddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysndfx in /home/hj20/anaconda3/lib/python3.7/site-packages (0.3.6)\r\n",
      "Requirement already satisfied: numpy in /home/hj20/anaconda3/lib/python3.7/site-packages (from pysndfx) (1.20.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pysndfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f78e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchaudio\n",
    "from numpy import load as np_load, ndarray\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pympler import muppy, summary\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University, Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['ClothoDataset']\n",
    "\n",
    "\n",
    "class ClothoDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_dir: Path,\n",
    "                 split: str,\n",
    "                 input_field_name: str,\n",
    "                 output_field_name: str,\n",
    "                 load_into_memory: bool,\n",
    "                 settings_audio,\n",
    "                 settings_features,\n",
    "                 online_preprocessing=True,\n",
    "                 transforms=None) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "        :param data_dir: Data directory with Clotho dataset files.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: The split to use (`development`, `validation`)\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name for the input values\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name for the output (target) values.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load the dataset into memory?\n",
    "        :type load_into_memory: bool\n",
    "        :param settings_audio: Settings about audio loading\n",
    "        :type dict\n",
    "        :param settings_features: Settings about audio processing\n",
    "        :type dict\n",
    "        :param indexes: Indexes of files, which depends on validation strategy\n",
    "        :type indexes: numpy array\n",
    "        :param transforms: List of transforms\n",
    "        :type transforms: list\n",
    "        \"\"\"\n",
    "\n",
    "        super(ClothoDataset, self).__init__()\n",
    "        self.online_preprocessing = online_preprocessing\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "        self.split = split\n",
    "\n",
    "        self.settings_audio = settings_audio\n",
    "        self.settings_features = settings_features\n",
    "\n",
    "        #if indexes is None:\n",
    "        self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        #else:\n",
    "        #    self.examples: List[Path] = list(np.array(sorted(the_dir.iterdir()))[indexes])\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.transforms = transforms\n",
    "        self.resampler = torchaudio.transforms.Resample(orig_freq=settings_features['process']['sr'],\n",
    "                                                        new_freq=settings_features['process']['sr_resample'])\n",
    "        if load_into_memory:\n",
    "            self.examples: List[ndarray] = [\n",
    "                np_load(str(f), allow_pickle=True)\n",
    "                for f in self.examples]\n",
    "        self.cnt = 0\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int) \\\n",
    "            -> Tuple[ndarray, ndarray, Path]:\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values, and the Path of the file.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray, Path\n",
    "        \"\"\"\n",
    "\n",
    "        ex = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex = np_load(str(ex), allow_pickle=True)\n",
    "        if self.online_preprocessing:\n",
    "            in_e = torchaudio.load(Path('data', 'clotho_audio_files', self.split, ex.file_name[0]))[0][0]\n",
    "            ou_e = ex[self.output_name].item()\n",
    "        else:\n",
    "            in_e, ou_e = [ex[i].item()\n",
    "                          for i in [self.input_name, self.output_name]]\n",
    "        filename = ex.file_name[0]\n",
    "        del ex\n",
    "        if self.transforms is not None:\n",
    "            for transform in self.transforms:\n",
    "                in_e, ou_e = transform(dataset=self, inputs=(in_e, ou_e, filename))\n",
    "        return in_e, ou_e, filename\n",
    "\n",
    "    def random_sample(self, sample_audio=False):\n",
    "        \"\"\"\n",
    "        Sampling audio or melspectrogram and encoded output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        item = random.randint(0, len(self.examples) - 1)\n",
    "        ex = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex = np_load(str(ex), allow_pickle=True)\n",
    "        if sample_audio:\n",
    "            thedir = Path('./data/clotho_audio_files/').joinpath(self.split)\n",
    "            filename = Path(thedir, ex.file_name[0])\n",
    "            in_e = torchaudio.load(filepath=filename)[0][0]\n",
    "            #in_e = self.resampler.forward(in_e)\n",
    "            ou_e = ex[self.output_name].item()\n",
    "        else:\n",
    "            in_e, ou_e = [ex[i].item()\n",
    "                          for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        return in_e, ou_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c764639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import MutableSequence, MutableMapping, Union,\\\n",
    "    Tuple, List\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import cat, zeros, from_numpy, ones, Tensor\n",
    "from numpy import ndarray\n",
    "\n",
    "#from data_handlers._clotho import ClothoDataset\n",
    "#from tools.augmentations import MixUp, AudioAugmentation\n",
    "\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University. Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['get_clotho_loader']\n",
    "\n",
    "\n",
    "def _clotho_collate_fn(batch: MutableSequence[ndarray]) \\\n",
    "        -> Tuple[Tensor, Tensor, List[str]]:\n",
    "    \"\"\"Pads data.\n",
    "    For each batch, the maximum input and output\\\n",
    "    time-steps are calculated. Then, then input and\\\n",
    "    output data are padded to match the maximum time-steps.\n",
    "    The input data are padded with zeros in front, and\\\n",
    "    the output with] <EOS> tokens at the end.\n",
    "    :param batch: Batch data of batch x time x features.\\\n",
    "                  First element in the list are the input\\\n",
    "                  data, second the output data.\n",
    "    :type batch: list[numpy.ndarray]\n",
    "    :return: Padded data. First tensor is the input data\\\n",
    "             and second the output.\n",
    "    :rtype: torch.Tensor, torch.Tensor, list[str]\n",
    "    \"\"\"\n",
    "    max_input_t_steps = max([i[0].shape[0] for i in batch])\n",
    "    max_output_t_steps = max([i[1].shape[0] for i in batch])\n",
    "\n",
    "    file_names = [i[2] for i in batch]\n",
    "\n",
    "    #input_features = batch[0][0].shape[-1]\n",
    "    eos_token = batch[0][1][-1]\n",
    "    input_tensor = cat([\n",
    "        cat([zeros(\n",
    "            max_input_t_steps - i[0].shape[0]).float(),\n",
    "             i[0].float()]).unsqueeze(0) for i in batch])\n",
    "    output_tensor = cat([\n",
    "        cat([\n",
    "            from_numpy(i[1]).long(),\n",
    "            ones(max_output_t_steps - len(i[1])).mul(eos_token).long()\n",
    "        ]).unsqueeze(0) for i in batch])\n",
    "    return [input_tensor, output_tensor, file_names]\n",
    "\n",
    "\n",
    "def get_clotho_loader(split: str,\n",
    "                      is_training: bool,\n",
    "                      settings_data: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      settings_io: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[\n",
    "                              str, Union[str, MutableMapping[str, str]]]]],\n",
    "                      settings_features: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      settings_dataset: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      ) \\\n",
    "        -> DataLoader:\n",
    "    \"\"\"Gets the data loader.\n",
    "    :param split: Split to be used.\n",
    "    :type split: str\n",
    "    :param is_training: Is training data?\n",
    "    :type is_training: bool\n",
    "    :param settings_data: Data loading and dataset settings.\n",
    "    :type settings_data: dict\n",
    "    :param settings_io: Files I/O settings.\n",
    "    :type settings_io: dict\n",
    "    :param settings_features: Audio preprocessing features.\n",
    "    :type settings_features: dict\n",
    "    :param settings_dataset: Dataset settings.\n",
    "    :type settings_dataset: dict\n",
    "    :param indexes: Indexes of audio files, which depends on validation_strategy.\n",
    "    :type indexes: numpy array\n",
    "    :type settings_training: dict\n",
    "    :return: Data loader.\n",
    "    :rtype: torch.utils.data.DataLoader\n",
    "    \"\"\"\n",
    "    data_dir = Path(\n",
    "        settings_io['root_dirs']['data'],\n",
    "        settings_io['dataset']['features_dirs']['output'])\n",
    "\n",
    "    transforms = []\n",
    "    if settings_data['transforms'] == 'None' or (not is_training):\n",
    "        transforms = None\n",
    "    else:\n",
    "        if 'MixUp' in settings_data['transforms']:\n",
    "            print(settings_features['simple_concat_captions'], 'lalalalalal')\n",
    "            transforms.append(MixUp(p=settings_data['MixUp_p'],\n",
    "                              settings_features=settings_features,\n",
    "                              simple_concat_captions=settings_features['simple_concat_captions'],\n",
    "                              sample_audio=True))\n",
    "        if 'another' in settings_data['transforms']:\n",
    "            transforms.append(AudioAugmentation(p=settings_data['MixUp_p']))\n",
    "\n",
    "    #if settings_training['validation_strategy']\n",
    "    dataset = ClothoDataset(\n",
    "        data_dir=data_dir,\n",
    "        split=split,\n",
    "        input_field_name=settings_data['input_field_name'],\n",
    "        output_field_name=settings_data['output_field_name'],\n",
    "        load_into_memory=settings_data['load_into_memory'],\n",
    "        settings_audio=settings_dataset['audio'],\n",
    "        settings_features=settings_features,\n",
    "        transforms=transforms)\n",
    "\n",
    "    shuffle = settings_data['shuffle'] if is_training else False\n",
    "    drop_last = settings_data['drop_last'] if is_training else False\n",
    "    if is_training:\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=settings_data['batch_size'],\n",
    "            shuffle=shuffle,\n",
    "            num_workers=settings_data['num_workers'],\n",
    "            drop_last=drop_last,\n",
    "            # pin_memory=True,\n",
    "            collate_fn=_clotho_collate_fn)\n",
    "    else:\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=40,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=2,\n",
    "            drop_last=drop_last,\n",
    "            # pin_memory=True,\n",
    "            collate_fn=_clotho_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bdc159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file='main_settings'\n",
    "file_ext='yaml'\n",
    "file_dir='settings' \n",
    "settings = file_io.load_yaml_file(Path(\n",
    "        file_dir, f'{config_file}.{file_ext}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282439e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.file_io import load_audio_file\n",
    "from tools import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba6d900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True lalalalalal\n"
     ]
    }
   ],
   "source": [
    "training_data = get_clotho_loader(\n",
    "            settings_io['dataset']['features_dirs']['development'],\n",
    "            is_training=True,\n",
    "            settings_data=settings_data,\n",
    "            settings_io=settings_io,\n",
    "            settings_features=settings_features,\n",
    "            settings_dataset=settings_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da33e988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fc96caf",
   "metadata": {},
   "outputs": [],
   "source": [
    " =  get_clotho_loader(\n",
    "            settings_io['dataset']['features_dirs']['evaluation'],\n",
    "            is_training=False,\n",
    "            settings_data=settings_data,\n",
    "            settings_io=settings_io,\n",
    "            settings_features=settings_features,\n",
    "            settings_dataset=settings_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2e22027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c197368",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_io=settings['dirs_and_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586cf61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MixUp']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_data['transforms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46972f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_dirs': {'outputs': 'outputs', 'data': 'data'},\n",
       " 'dataset': {'development': 'development',\n",
       "  'evaluation': 'evaluation',\n",
       "  'features_dirs': {'output': 'data_splits_mel',\n",
       "   'development': 'development',\n",
       "   'evaluation': 'evaluation'},\n",
       "  'audio_dirs': {'downloaded': 'clotho_audio_files',\n",
       "   'output': 'data_splits_audio_mel',\n",
       "   'development': 'development',\n",
       "   'evaluation': 'evaluation'},\n",
       "  'annotations_dir': 'clotho_csv_files',\n",
       "  'pickle_files_dir': 'pickles',\n",
       "  'files': {'np_file_name_template': 'clotho_file_{audio_file_name}_{caption_index}.npy',\n",
       "   'words_list_file_name': 'words_list.p',\n",
       "   'words_counter_file_name': 'words_frequencies.p',\n",
       "   'characters_list_file_name': 'characters_list.p',\n",
       "   'characters_frequencies_file_name': 'characters_frequencies.p'}},\n",
       " 'model': {'model_dir': 'models',\n",
       "  'checkpoint_model_name': 'dcase_model_baseline.pt',\n",
       "  'pre_trained_model_name': 'dcase_model_baseline_pre_trained.pt'},\n",
       " 'logging': {'logger_dir': 'logging',\n",
       "  'caption_logger_file': 'captions_baseline.txt'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201948df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'development'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_io['dataset']['features_dirs']['development']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc641b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_data=settings['dnn_training_settings']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa82501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_field_name': 'features',\n",
       " 'output_field_name': 'words_ind',\n",
       " 'load_into_memory': False,\n",
       " 'transforms': ['MixUp'],\n",
       " 'MixUp_p': 0.5,\n",
       " 'batch_size': 16,\n",
       " 'shuffle': True,\n",
       " 'num_workers': 4,\n",
       " 'drop_last': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0419e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_features=settings['feature_extraction_settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f7120db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keep_raw_audio_data': False,\n",
       " 'simple_concat_captions': True,\n",
       " 'process': {'sr': 44100,\n",
       "  'sr_resample': 16000,\n",
       "  'nb_fft': 1024,\n",
       "  'hop_size': 512,\n",
       "  'nb_mels': 64,\n",
       "  'window_function': 'hann',\n",
       "  'center': True,\n",
       "  'f_min': 0.0,\n",
       "  'f_max': None,\n",
       "  'htk': False,\n",
       "  'power': 1.0,\n",
       "  'norm': 1}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04521df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dataset=settings['dataset_creation_settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd805b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workflow': {'create_dataset': True, 'validate_dataset': False},\n",
       " 'annotations': {'development_file': 'clotho_captions_development.csv',\n",
       "  'evaluation_file': 'clotho_captions_evaluation.csv',\n",
       "  'audio_file_column': 'file_name',\n",
       "  'captions_fields_prefix': 'caption_{}',\n",
       "  'use_special_tokens': True,\n",
       "  'nb_captions': 5,\n",
       "  'keep_case': False,\n",
       "  'remove_punctuation_words': True,\n",
       "  'remove_punctuation_chars': True,\n",
       "  'use_unique_words_per_caption': False,\n",
       "  'use_unique_chars_per_caption': False},\n",
       " 'audio': {'sr': 44100, 'to_mono': True, 'max_abs_value': 1.0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from typing import Tuple, List, AnyStr, Union\n",
    "from pathlib import Path\n",
    "\n",
    "from numpy import ndarray, recarray\n",
    "from torch.utils.data import Dataset\n",
    "from numpy import load as np_load\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['ClothoDataset']\n",
    "\n",
    "\n",
    "class ClothoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir: Path,\n",
    "                 split: AnyStr,\n",
    "                 input_field_name: AnyStr,\n",
    "                 output_field_name: AnyStr,\n",
    "                 load_into_memory: bool,\n",
    "                 transforms=transforms) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "\n",
    "        :param data_dir: Directory with data.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name of the clotho data\\\n",
    "                                 to be used as input data to the\\\n",
    "                                 method.\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name of the clotho data\\\n",
    "                                 to be used as output data to the\\\n",
    "                                 method.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load all data into memory?\n",
    "        :type load_into_memory: bool\n",
    "        \"\"\"\n",
    "        super(ClothoDataset, self).__init__()\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "\n",
    "        self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.transforms=transforms\n",
    "        if load_into_memory:\n",
    "            self.examples: List[recarray] = [np_load(str(f), allow_pickle=True)\n",
    "                                             for f in self.examples]\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int) \\\n",
    "            -> Tuple[ndarray, ndarray]:\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray\n",
    "        \"\"\"\n",
    "        ex: Union[Path, recarray] = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex: recarray = np_load(str(ex), allow_pickle=True)\n",
    "\n",
    "        in_e, ou_e = [ex[i].item() for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        return in_e, ou_e\n",
    "\n",
    "\n",
    "class ClothoDatasetEval(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir: Path,\n",
    "                 split: AnyStr,\n",
    "                 input_field_name: AnyStr,\n",
    "                 output_field_name: AnyStr,\n",
    "                 load_into_memory: bool) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "\n",
    "        :param data_dir: Directory with data.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name of the clotho data\\\n",
    "                                 to be used as input data to the\\\n",
    "                                 method.\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name of the clotho data\\\n",
    "                                 to be used as output data to the\\\n",
    "                                 method.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load all data into memory?\n",
    "        :type load_into_memory: bool\n",
    "        \"\"\"\n",
    "        super(ClothoDatasetEval, self).__init__()\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "        if split == 'evaluation':\n",
    "            self.examples: List[Path] = sorted(the_dir.iterdir())[::5]  # changed\n",
    "        else:\n",
    "            self.examples: List[Path] = sorted(the_dir.iterdir())  # changed\n",
    "        # self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.data_dir = the_dir\n",
    "\n",
    "        if load_into_memory:\n",
    "            self.examples: List[recarray] = [np_load(str(f), allow_pickle=True)\n",
    "                                             for f in self.examples]\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int):\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray\n",
    "        \"\"\"\n",
    "        ex: Union[Path, recarray] = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex: recarray = np_load(str(ex), allow_pickle=True)\n",
    "\n",
    "        in_e, ou_e = [ex[i].item() for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        all_ref = get_all_ref(ex['file_name'].item(), self.data_dir)\n",
    "\n",
    "        filename = str(ex['file_name'].item())\n",
    "        out_len = len(ou_e)\n",
    "        return in_e, ou_e, all_ref, filename,out_len\n",
    "\n",
    "\n",
    "def get_all_ref(filename, data_dir):\n",
    "    filename = str(filename)\n",
    "    # tgt = [np.load(d, allow_pickle=True).words_ind.tolist()\n",
    "    tgt = [np.load(d, allow_pickle=True)['words_ind'].item().tolist()\n",
    "           for d in [os.path.join(data_dir, 'clotho_file_{filename}.wav_{i}.npy'.\n",
    "                                  format(filename=filename[:-4],  # 删除'.wav'\n",
    "                                         i=i)) for i in range(5)]  # wav_0-wav_4\n",
    "           ]\n",
    "    return tgt\n",
    "# EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa295a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff041f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from typing import Callable, Union, Tuple, AnyStr, Optional\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from .clotho_dataset import ClothoDataset, ClothoDatasetEval\n",
    "from .collate_fn import clotho_collate_fn, clotho_collate_fn_eval\n",
    "\n",
    "__author__ = 'Konstantinos Drossos'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['get_clotho_loader']\n",
    "\n",
    "\n",
    "def get_clotho_loader(data_dir: Path,\n",
    "                      split: str,\n",
    "                      input_field_name: str,\n",
    "                      output_field_name: str,\n",
    "                      load_into_memory: bool,\n",
    "                      batch_size: int,\n",
    "                      nb_t_steps_pad: Union[AnyStr, Tuple[int, int]],\n",
    "                      shuffle: Optional[bool] = True,\n",
    "                      drop_last: Optional[bool] = True,\n",
    "                      input_pad_at: Optional[str] = 'start',\n",
    "                      output_pad_at: Optional[str] = 'end',\n",
    "                      num_workers: Optional[int] = 1,\n",
    "                      return_reference: Optional[bool] = False,\n",
    "                      augment: Optional[bool] = False) \\\n",
    "        -> DataLoader:\n",
    "    \"\"\"Gets the clotho data loader.\n",
    "\n",
    "    :param return_reference:\n",
    "    :param data_dir: Directory with data.\n",
    "    :type data_dir: pathlib.Path\n",
    "    :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "    :type split: str\n",
    "    :param input_field_name: Field name of the clotho data\\\n",
    "                             to be used as input data to the\\\n",
    "                             method.\n",
    "    :type input_field_name: str\n",
    "    :param output_field_name: Field name of the clotho data\\\n",
    "                             to be used as output data to the\\\n",
    "                             method.\n",
    "    :type output_field_name: str\n",
    "    :param load_into_memory: Load all data into memory?\n",
    "    :type load_into_memory: bool\n",
    "    :param batch_size: Batch size to use.\n",
    "    :type batch_size: int\n",
    "    :param nb_t_steps_pad: Number of time steps to\\\n",
    "                           pad/truncate to. Cab use\\\n",
    "                           'max', 'min', or exact number\\\n",
    "                           e.g. (1024, 10).\n",
    "    :type nb_t_steps_pad: str|(int, int)\n",
    "    :param shuffle: Shuffle examples? Defaults to True.\n",
    "    :type shuffle: bool, optional\n",
    "    :param drop_last: Drop the last examples if not making\\\n",
    "                      a batch of `batch_size`? Defaults to True.\n",
    "    :type drop_last: bool, optional\n",
    "    :param input_pad_at: Pad input at the start or\\\n",
    "                         at the end?\n",
    "    :type input_pad_at: str\n",
    "    :param output_pad_at: Pad output at the start or\\\n",
    "                          at the end?\n",
    "    :type output_pad_at: str\n",
    "    :param num_workers: Amount of workers, defaults to 1.\n",
    "    :type num_workers: int, optional\n",
    "    :return: Dataloader for Clotho data.\n",
    "    :rtype: torch.utils.data.dataloader.DataLoader\n",
    "    \"\"\"\n",
    "    if return_reference:\n",
    "        dataset: ClothoDatasetEval = ClothoDatasetEval(\n",
    "            data_dir=data_dir, split=split,\n",
    "            input_field_name=input_field_name,\n",
    "            output_field_name=output_field_name,\n",
    "            load_into_memory=load_into_memory\n",
    "            transforms=trans)\n",
    "\n",
    "        collate_fn: Callable = partial(\n",
    "            clotho_collate_fn_eval,\n",
    "            nb_t_steps=nb_t_steps_pad,\n",
    "            input_pad_at=input_pad_at,\n",
    "            output_pad_at=output_pad_at, split=split, augment=augment)\n",
    "    else:\n",
    "        dataset: ClothoDataset = ClothoDataset(\n",
    "            data_dir=data_dir, split=split,\n",
    "            input_field_name=input_field_name,\n",
    "            output_field_name=output_field_name,\n",
    "            load_into_memory=load_into_memory)\n",
    "\n",
    "        collate_fn: Callable = partial(\n",
    "            clotho_collate_fn,\n",
    "            nb_t_steps=nb_t_steps_pad,\n",
    "            input_pad_at=input_pad_at,\n",
    "            output_pad_at=output_pad_at)\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset=dataset, batch_size=batch_size,\n",
    "        shuffle=shuffle, num_workers=num_workers,\n",
    "        drop_last=drop_last, collate_fn=collate_fn)\n",
    "\n",
    "# EOF\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcaset6",
   "language": "python",
   "name": "dcase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
