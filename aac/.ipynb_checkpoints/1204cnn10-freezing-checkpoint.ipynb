{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f52a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5214a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a900f95",
   "metadata": {},
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e691952",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=out_channels,\n",
    "                               kernel_size=(3, 3), stride=(1, 1),\n",
    "                               padding=(1, 1), bias=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels,\n",
    "                               out_channels=out_channels,\n",
    "                               kernel_size=(3, 3), stride=(1, 1),\n",
    "                               padding=(1, 1), bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
    "\n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        if pool_type == 'max':\n",
    "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg+max':\n",
    "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            raise Exception('Incorrect argument!')\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d4906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(_ResNet, self).__init__()\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if stride == 1:\n",
    "                downsample = nn.Sequential(\n",
    "                    _resnet_conv1x1(self.inplanes, planes * block.expansion),\n",
    "                    norm_layer(planes * block.expansion),\n",
    "                )\n",
    "                init_layer(downsample[0])\n",
    "                init_bn(downsample[1])\n",
    "            elif stride == 2:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.AvgPool2d(kernel_size=2), \n",
    "                    _resnet_conv1x1(self.inplanes, planes * block.expansion),\n",
    "                    norm_layer(planes * block.expansion),\n",
    "                )\n",
    "                init_layer(downsample[1])\n",
    "                init_bn(downsample[2])\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f23ae3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ResnetBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(_ResnetBottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        self.stride = stride\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = _resnet_conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = _resnet_conv3x3(width, width)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = _resnet_conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_bn(self.bn1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn2)\n",
    "        init_layer(self.conv3)\n",
    "        init_bn(self.bn3)\n",
    "        nn.init.constant_(self.bn3.weight, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        if self.stride == 2:\n",
    "            x = F.avg_pool2d(x, kernel_size=(2, 2))\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = F.dropout(out, p=0.1, training=self.training)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0507f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resnet_conv1x1(in_planes, out_planes):\n",
    "    #1x1 convolution\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aafa193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resnet_conv3x3(in_planes, out_planes):\n",
    "    #3x3 convolution with padding\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n",
    "                     padding=1, groups=1, bias=False, dilation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b1afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet54(nn.Module):\n",
    "    def __init__(self, classes_num=527):\n",
    "        \n",
    "        super(ResNet54, self).__init__()\n",
    "\n",
    "      \n",
    "\n",
    "        # Spectrogram extractor\n",
    "       # self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "       #     win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "       #     freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        #self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "        #   n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "        #   freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        #self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "        #    freq_drop_width=8, freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
    "        # self.conv_block2 = ConvBlock(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.resnet = _ResNet(block=_ResnetBottleneck, layers=[3, 4, 6, 3], zero_init_residual=True)\n",
    "\n",
    "        self.conv_block_after1 = ConvBlock(in_channels=2048, out_channels=2048)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 2048)\n",
    "        self.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc_audioset)\n",
    "\n",
    "\n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"\n",
    "        Input: (batch_size, data_length)\"\"\"\n",
    "\n",
    "        #x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n",
    "        #x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "        x = input.unsqueeze(1)\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        \n",
    "        #if self.training:\n",
    "        #   x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "        \n",
    "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training, inplace=True)\n",
    "        x = self.resnet(x)\n",
    "        x = F.avg_pool2d(x, kernel_size=(2, 2))\n",
    "        x = F.dropout(x, p=0.2, training=self.training, inplace=True)\n",
    "        x = self.conv_block_after1(x, pool_size=(1, 1), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training, inplace=True)\n",
    "        \n",
    "        #x = torch.mean(x, dim=3)\n",
    "        \n",
    "        #(x1, _) = torch.max(x, dim=2)\n",
    "       # x2 = torch.mean(x, dim=2)\n",
    "       # x = x1 + x2\n",
    "       # x = F.dropout(x, p=0.5, training=self.training)\n",
    "       # x = F.relu_(self.fc1(x))\n",
    "       # embedding = F.dropout(x, p=0.5, training=self.training)\n",
    "       # clipwise_output = torch.sigmoid(self.fc_audioset(x))\n",
    "        \n",
    "        #output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abbeed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transfer_ResNet54(nn.Module):\n",
    "    def __init__(self, freeze_base, pretrain_checkpoint=None):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_ResNet54, self).__init__()\n",
    "\n",
    "        audioset_classes_num = 527\n",
    "        self.base = ResNet54(audioset_classes_num)\n",
    "\n",
    "        #self.init_weights()\n",
    "\n",
    "        if pretrain_checkpoint:\n",
    "            self.load_from_pretrain(pretrain_checkpoint)\n",
    "            \n",
    "        #self.base.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        # 안쓰이는이유는 multi-class clasification을 생략하기 때문,\n",
    "\n",
    "        \n",
    "        \n",
    "        #if freeze_base:\n",
    "        #    ct = 0\n",
    "        #    for child in self.base.children():\n",
    "        #        ct += 1\n",
    "        #        if ct < 6:\n",
    "        #            for param in child.parameters():\n",
    "        #                print(param)\n",
    "        #                param.requires_grad = False\n",
    "        \n",
    "        if freeze_base:\n",
    "            # 2단계 freeze / 3단계 freeze X\n",
    "             #Freeze AudioSet pretrained layers\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    #def init_weights(self):\n",
    "        #init_layer(self.fc_transfer)\n",
    "\n",
    "    def load_from_pretrain(self, pretrained_checkpoint):\n",
    "        pretrained_checkpoint=\"/home/hj20/dcase_2020_T6/models/ResNet54_mAP=0.429.pth\"\n",
    "        checkpoint = torch.load(pretrained_checkpoint)\n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_imag.weight')#가중치 삭제  \n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_real.weight')#가중치 삭제\n",
    "        checkpoint['model'].pop('logmel_extractor.melW')#가중치 삭제\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        output = self.base(input)\n",
    "\n",
    "        #embedding = output_dict['embedding']\n",
    "        #clipwise_output = output_dict['clipwise_output']\n",
    "\n",
    "        return output #, clipwise_output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc218255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4aa7afa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕\n"
     ]
    }
   ],
   "source": [
    "s = '안녕하세요. 좋은 아침이에요'\n",
    "m = re.search('^안녕', s)\n",
    "print(m.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff3134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b044b29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-6.8801e-02,  9.8489e-03,  7.2190e-02],\n",
      "          [-3.5383e-02,  3.5468e-02, -7.2592e-02],\n",
      "          [ 7.2946e-02,  1.1742e-02,  5.9962e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5678e-02,  1.4111e-02,  4.1614e-04],\n",
      "          [-5.2265e-02, -2.3830e-02,  7.5641e-04],\n",
      "          [-3.9783e-02,  4.5862e-02, -4.1354e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7620e-02,  7.4993e-02,  4.7068e-02],\n",
      "          [-1.8166e-02, -2.7438e-02,  4.5657e-02],\n",
      "          [-8.2510e-02, -1.6822e-02,  3.2192e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3439e-02,  6.3710e-03, -2.2590e-02],\n",
      "          [ 5.9020e-02, -4.8469e-02,  7.9852e-02],\n",
      "          [ 3.9914e-02,  6.3763e-02, -3.7569e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0786e-02, -3.3144e-02, -9.6115e-02],\n",
      "          [ 4.7617e-02,  5.7905e-02,  9.3807e-02],\n",
      "          [ 6.9900e-02,  4.7592e-02, -4.5049e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.6659e-02,  3.8989e-02,  8.2155e-02],\n",
      "          [ 9.9706e-02, -2.6382e-02,  4.2897e-02],\n",
      "          [ 1.7571e-02, -7.7318e-02,  9.2386e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7848e-02,  7.4888e-02,  6.9682e-02],\n",
      "          [ 2.5594e-04, -5.2396e-02, -6.6867e-02],\n",
      "          [-8.9829e-02,  4.0905e-02, -2.1229e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.4145e-02,  6.8241e-02, -4.9835e-02],\n",
      "          [ 1.7366e-02, -1.6463e-02,  7.9006e-02],\n",
      "          [-6.6782e-02,  1.8640e-03,  5.7348e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9030e-03, -9.0393e-02,  6.5903e-02],\n",
      "          [ 8.4913e-02, -4.0752e-02,  3.2158e-02],\n",
      "          [ 6.2715e-02,  6.4265e-02, -1.0109e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2049e-03, -9.7359e-02,  5.6504e-02],\n",
      "          [ 1.1739e-02,  6.8422e-02, -8.4861e-02],\n",
      "          [ 1.2504e-02, -5.6169e-02,  8.9619e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0708e-03, -1.0003e-01,  6.2650e-02],\n",
      "          [-9.7691e-02,  4.4138e-02, -1.0654e-02],\n",
      "          [ 5.0594e-02, -1.2240e-02,  3.1842e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.7457e-03, -4.5737e-02,  8.0904e-02],\n",
      "          [-1.7199e-02, -8.9437e-02,  7.1096e-02],\n",
      "          [-1.4715e-02,  3.1393e-02, -2.9506e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6454e-02, -4.3886e-02,  4.9608e-02],\n",
      "          [-8.1818e-02, -4.1100e-02, -1.1692e-02],\n",
      "          [ 1.0122e-01, -3.3471e-02, -4.5595e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9321e-02, -1.7293e-03,  4.6415e-02],\n",
      "          [ 8.4815e-02, -3.3715e-02, -1.1239e-02],\n",
      "          [-6.3232e-02,  8.9737e-02, -8.9808e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2728e-02,  6.7466e-03, -1.8429e-03],\n",
      "          [-2.2795e-02,  3.6072e-02,  6.9894e-03],\n",
      "          [ 9.4868e-02,  9.3336e-02, -8.0572e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8351e-02,  4.7126e-02, -5.8785e-02],\n",
      "          [-5.9972e-02, -2.3098e-02, -9.3097e-02],\n",
      "          [ 2.2217e-02,  9.4775e-02, -2.3199e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.6155e-02, -1.8615e-02, -1.0065e-01],\n",
      "          [-8.0193e-02,  2.0464e-02,  2.4985e-02],\n",
      "          [ 5.6345e-02,  6.3714e-03, -7.4648e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2753e-02, -3.0036e-02,  9.6220e-02],\n",
      "          [-9.3052e-02,  8.4418e-02,  5.6354e-02],\n",
      "          [ 1.5472e-02, -3.1916e-03, -3.0352e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.2612e-02, -1.8171e-04, -9.5026e-03],\n",
      "          [ 5.9760e-02,  7.1675e-02, -9.5590e-02],\n",
      "          [ 5.4710e-02,  1.2089e-02,  3.3318e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0801e-02,  9.9397e-02, -6.3940e-02],\n",
      "          [-6.3760e-02, -6.6237e-02,  7.2123e-02],\n",
      "          [ 4.0626e-02,  2.9545e-03, -2.1176e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9208e-03,  1.6760e-02, -3.8677e-02],\n",
      "          [-9.6581e-04, -9.5168e-02,  5.9635e-02],\n",
      "          [-9.1641e-02, -4.5845e-02,  5.0892e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5111e-02, -5.4121e-02, -1.0041e-01],\n",
      "          [-8.1371e-02, -1.0039e-01,  7.8164e-02],\n",
      "          [ 1.0075e-01, -2.7316e-02, -5.5151e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5690e-02,  6.5389e-02, -2.8947e-02],\n",
      "          [ 3.5249e-02, -1.0119e-04, -1.0019e-01],\n",
      "          [-9.0596e-02, -1.0046e-01, -1.7574e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0657e-02, -8.9824e-02, -7.9621e-02],\n",
      "          [ 9.2066e-02,  6.8453e-02, -9.2544e-03],\n",
      "          [ 5.1484e-02,  1.0072e-01, -2.5956e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0082e-01,  5.0172e-02, -7.1489e-02],\n",
      "          [-6.2175e-02,  8.3830e-02, -1.0048e-01],\n",
      "          [-2.7358e-02, -1.2077e-02, -7.7367e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.3163e-02,  2.3288e-02,  6.1254e-02],\n",
      "          [-7.8274e-02, -9.6450e-02, -5.8692e-02],\n",
      "          [-2.9478e-02, -1.2457e-02, -5.9514e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5932e-02, -3.8110e-02,  7.3259e-02],\n",
      "          [ 8.0487e-02,  8.1176e-02, -2.1932e-02],\n",
      "          [ 4.3294e-03,  9.0735e-02,  3.2419e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.8363e-02, -9.8715e-02,  3.4950e-02],\n",
      "          [-5.0996e-02, -1.0121e-01, -6.4834e-02],\n",
      "          [-6.7494e-02, -9.1578e-02,  2.5605e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7642e-02,  6.1581e-02,  6.9681e-02],\n",
      "          [-7.1353e-02,  6.9878e-02,  1.2625e-02],\n",
      "          [-7.0426e-02, -9.3931e-02, -4.2378e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9292e-02,  3.8698e-02, -8.6182e-02],\n",
      "          [-3.3591e-02,  9.2686e-03,  1.8181e-02],\n",
      "          [ 1.2417e-02,  3.7443e-02,  9.1081e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4277e-04, -7.0348e-02, -2.8595e-03],\n",
      "          [ 6.4502e-02,  7.2165e-02, -2.6149e-03],\n",
      "          [ 9.3238e-02, -8.9879e-02, -3.4105e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1287e-02, -3.4543e-02, -1.0934e-02],\n",
      "          [ 3.0752e-03,  3.3290e-03,  8.8923e-02],\n",
      "          [ 7.7527e-02,  5.3091e-02, -1.0125e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3279e-02,  8.9706e-02,  5.9856e-03],\n",
      "          [-3.4041e-02, -9.4663e-02, -4.0509e-02],\n",
      "          [-5.7723e-02,  5.7735e-02, -5.7143e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.3602e-02, -4.1812e-02, -4.6620e-02],\n",
      "          [-1.9832e-02, -5.8533e-02, -6.4180e-02],\n",
      "          [-5.9582e-02, -4.5233e-02,  5.9679e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.2952e-02,  4.2605e-02,  4.0196e-02],\n",
      "          [ 5.3697e-02, -4.7628e-02,  9.5927e-02],\n",
      "          [ 6.0351e-02,  2.7780e-02, -5.7477e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8362e-02, -7.4630e-02,  4.5605e-02],\n",
      "          [-4.0921e-02,  9.9808e-02, -2.8758e-02],\n",
      "          [-4.3441e-02,  8.1066e-02, -2.4052e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7514e-02,  1.9347e-02,  2.5570e-02],\n",
      "          [-3.4538e-02,  5.0704e-02,  3.4855e-02],\n",
      "          [ 6.5585e-02, -6.4972e-02,  9.9493e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4414e-02,  7.5956e-02, -4.8571e-02],\n",
      "          [ 5.8345e-02,  7.3459e-02, -8.1712e-02],\n",
      "          [-8.8177e-02, -3.8335e-02, -9.1781e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0710e-02, -4.6973e-02,  5.5591e-02],\n",
      "          [-7.5438e-02,  7.7745e-02, -8.9248e-02],\n",
      "          [-4.7942e-02, -3.0316e-03,  2.5181e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.0958e-02,  7.7665e-02,  5.8457e-02],\n",
      "          [ 8.5566e-02,  8.4945e-02,  3.3796e-03],\n",
      "          [ 1.6946e-02, -8.6897e-03,  5.9725e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.6706e-02, -4.7196e-02, -4.8952e-02],\n",
      "          [ 3.0651e-02,  8.5971e-02,  7.2463e-02],\n",
      "          [ 8.5691e-02, -4.0544e-03, -8.9397e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5593e-02,  9.8978e-02,  5.2676e-02],\n",
      "          [ 9.5072e-02,  7.8919e-02, -3.4637e-02],\n",
      "          [ 9.6739e-02,  6.6795e-02,  3.5826e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1429e-02, -5.1403e-02, -1.8557e-02],\n",
      "          [-9.0333e-02,  4.9581e-02, -4.0515e-02],\n",
      "          [ 9.3029e-02, -2.5382e-02,  5.3074e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4339e-02,  4.5284e-02, -6.1051e-02],\n",
      "          [-6.3779e-02,  1.1142e-02, -6.4577e-02],\n",
      "          [-5.9658e-02,  2.1811e-03,  8.3356e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6998e-02, -2.4311e-02,  8.7020e-02],\n",
      "          [-6.9933e-03, -7.9068e-02, -1.6720e-02],\n",
      "          [-1.4446e-02,  2.3993e-02, -6.2261e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0522e-02, -8.8709e-02,  4.0753e-02],\n",
      "          [-9.5612e-02, -7.5891e-03, -3.5704e-02],\n",
      "          [ 2.6811e-02, -1.4689e-02, -6.4756e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.0540e-02, -2.9945e-02, -4.5085e-02],\n",
      "          [ 5.1742e-02,  6.4015e-02, -7.2746e-02],\n",
      "          [ 9.0100e-02,  4.4035e-02, -6.7072e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3331e-02, -6.4739e-02, -9.1700e-02],\n",
      "          [-4.3418e-02,  2.5445e-02, -6.6646e-02],\n",
      "          [ 9.5747e-02,  7.6556e-02, -6.3597e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.4058e-02, -3.1304e-02, -1.3623e-03],\n",
      "          [-6.9989e-02,  6.5347e-02, -9.2740e-02],\n",
      "          [ 4.1581e-03, -2.3338e-02, -1.8309e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.1283e-02,  6.8428e-02,  2.5562e-02],\n",
      "          [-9.3465e-02,  1.7327e-02,  4.8439e-02],\n",
      "          [-7.8192e-03, -4.9041e-02,  5.0111e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.8624e-02,  7.5311e-02,  5.0396e-03],\n",
      "          [-9.3991e-02,  4.6749e-02, -6.8708e-02],\n",
      "          [-3.1078e-02,  5.3234e-02,  3.2466e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.0021e-02, -3.9494e-02,  5.9216e-02],\n",
      "          [-7.5533e-02,  2.2575e-02, -8.0650e-02],\n",
      "          [-1.4917e-02,  8.4272e-02,  1.0106e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0729e-03,  4.9699e-02, -8.1215e-02],\n",
      "          [ 4.8533e-02, -8.0359e-02, -9.5667e-02],\n",
      "          [ 7.0198e-02,  9.0276e-02, -2.2189e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.9233e-02,  9.8211e-02, -9.9516e-03],\n",
      "          [ 2.5240e-02,  3.8514e-03, -8.0997e-02],\n",
      "          [-9.9029e-02, -6.2268e-02, -8.9178e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.0131e-02,  8.7481e-02, -7.5004e-02],\n",
      "          [ 6.3963e-02,  5.5579e-02,  2.0878e-02],\n",
      "          [ 3.6130e-02, -4.9249e-02,  2.5219e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.6495e-02,  4.7001e-02, -1.5486e-03],\n",
      "          [ 9.2778e-02, -5.4886e-02, -3.5706e-02],\n",
      "          [-4.5221e-02,  1.8900e-02, -6.7559e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3735e-02, -5.9466e-02,  1.1726e-02],\n",
      "          [-5.0305e-02, -6.7867e-02,  7.3625e-03],\n",
      "          [ 1.5897e-02,  1.1707e-02,  1.2601e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.3572e-02, -8.8792e-02,  8.8346e-02],\n",
      "          [ 1.9965e-02, -7.8179e-02, -1.5084e-02],\n",
      "          [-8.9276e-02, -4.1863e-02, -9.4831e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.4543e-02, -4.4599e-02, -2.9434e-02],\n",
      "          [ 7.7482e-02,  4.1860e-02, -4.3355e-02],\n",
      "          [ 1.6767e-02,  1.1706e-02, -5.7778e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5349e-02, -6.5787e-02,  2.4393e-02],\n",
      "          [ 9.2536e-02, -2.7258e-03, -9.4007e-02],\n",
      "          [-4.5634e-02,  1.0265e-02, -9.1034e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.6240e-02,  8.0682e-02,  5.3395e-02],\n",
      "          [-1.7745e-03, -6.1148e-02, -1.8664e-02],\n",
      "          [ 7.0508e-02,  6.2771e-02,  9.2960e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8967e-02,  9.3232e-02,  1.1570e-02],\n",
      "          [ 6.2158e-02,  5.1605e-03,  4.5863e-02],\n",
      "          [-9.0200e-02,  8.8371e-02, -4.8958e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.4271e-02, -6.9417e-03, -1.2101e-02],\n",
      "          [ 8.0448e-02,  2.6439e-02,  7.0924e-02],\n",
      "          [ 9.2831e-02,  6.3417e-02, -8.0604e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7276e-02,  6.5091e-02,  6.8942e-02],\n",
      "          [-5.1172e-02, -1.5253e-02, -7.8260e-02],\n",
      "          [-2.6555e-02,  5.6564e-02,  2.8253e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0445,  0.0721, -0.0009],\n",
      "          [-0.0249, -0.0550,  0.0698],\n",
      "          [ 0.0371,  0.0484,  0.0169]],\n",
      "\n",
      "         [[ 0.0603, -0.0357, -0.0430],\n",
      "          [ 0.0265,  0.0115,  0.0415],\n",
      "          [ 0.0356,  0.0571, -0.0258]],\n",
      "\n",
      "         [[-0.0629,  0.0092, -0.0321],\n",
      "          [ 0.0114, -0.0297, -0.0581],\n",
      "          [-0.0570,  0.0153, -0.0317]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0241, -0.0546, -0.0703],\n",
      "          [-0.0564,  0.0444, -0.0060],\n",
      "          [-0.0009,  0.0123,  0.0612]],\n",
      "\n",
      "         [[-0.0322, -0.0076, -0.0452],\n",
      "          [-0.0264,  0.0180,  0.0267],\n",
      "          [ 0.0472,  0.0421,  0.0336]],\n",
      "\n",
      "         [[-0.0089,  0.0427,  0.0141],\n",
      "          [ 0.0344, -0.0465, -0.0392],\n",
      "          [ 0.0544,  0.0226, -0.0186]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0263,  0.0352,  0.0189],\n",
      "          [-0.0040,  0.0503,  0.0348],\n",
      "          [ 0.0498, -0.0093, -0.0041]],\n",
      "\n",
      "         [[ 0.0003, -0.0242, -0.0702],\n",
      "          [ 0.0461, -0.0188,  0.0479],\n",
      "          [-0.0647,  0.0143, -0.0222]],\n",
      "\n",
      "         [[ 0.0517,  0.0200, -0.0472],\n",
      "          [-0.0593, -0.0010,  0.0439],\n",
      "          [-0.0394,  0.0247,  0.0102]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0601,  0.0284,  0.0185],\n",
      "          [ 0.0467, -0.0276,  0.0069],\n",
      "          [-0.0347,  0.0338,  0.0631]],\n",
      "\n",
      "         [[-0.0518,  0.0492, -0.0288],\n",
      "          [ 0.0409, -0.0476, -0.0327],\n",
      "          [-0.0694, -0.0179, -0.0115]],\n",
      "\n",
      "         [[ 0.0265, -0.0037,  0.0070],\n",
      "          [ 0.0344, -0.0439,  0.0362],\n",
      "          [ 0.0114, -0.0289,  0.0012]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0003,  0.0109,  0.0507],\n",
      "          [ 0.0220, -0.0293,  0.0256],\n",
      "          [ 0.0649, -0.0201, -0.0497]],\n",
      "\n",
      "         [[-0.0403, -0.0135,  0.0303],\n",
      "          [ 0.0658, -0.0113, -0.0540],\n",
      "          [ 0.0638,  0.0563, -0.0119]],\n",
      "\n",
      "         [[ 0.0326, -0.0230, -0.0070],\n",
      "          [ 0.0365, -0.0385, -0.0062],\n",
      "          [ 0.0353, -0.0385, -0.0654]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0287, -0.0091,  0.0380],\n",
      "          [ 0.0054, -0.0158,  0.0609],\n",
      "          [ 0.0422,  0.0077, -0.0717]],\n",
      "\n",
      "         [[ 0.0504,  0.0511, -0.0033],\n",
      "          [ 0.0011, -0.0712, -0.0478],\n",
      "          [-0.0380, -0.0693,  0.0634]],\n",
      "\n",
      "         [[ 0.0109,  0.0493, -0.0414],\n",
      "          [ 0.0566, -0.0505,  0.0236],\n",
      "          [-0.0504,  0.0275, -0.0245]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0599, -0.0363, -0.0479],\n",
      "          [-0.0343,  0.0258,  0.0355],\n",
      "          [-0.0365, -0.0551,  0.0351]],\n",
      "\n",
      "         [[-0.0327,  0.0064,  0.0194],\n",
      "          [ 0.0060, -0.0554, -0.0662],\n",
      "          [-0.0015,  0.0413,  0.0306]],\n",
      "\n",
      "         [[ 0.0213,  0.0433, -0.0136],\n",
      "          [ 0.0339, -0.0662,  0.0084],\n",
      "          [ 0.0608, -0.0473, -0.0242]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0322, -0.0309, -0.0589],\n",
      "          [ 0.0405, -0.0142,  0.0359],\n",
      "          [ 0.0156, -0.0175,  0.0223]],\n",
      "\n",
      "         [[-0.0630,  0.0195, -0.0357],\n",
      "          [-0.0445, -0.0065,  0.0492],\n",
      "          [ 0.0002, -0.0179,  0.0678]],\n",
      "\n",
      "         [[-0.0636,  0.0286,  0.0333],\n",
      "          [-0.0132, -0.0135, -0.0338],\n",
      "          [-0.0348,  0.0291,  0.0241]]],\n",
      "\n",
      "\n",
      "        [[[-0.0650,  0.0469, -0.0159],\n",
      "          [ 0.0466, -0.0297, -0.0685],\n",
      "          [ 0.0542, -0.0631, -0.0422]],\n",
      "\n",
      "         [[ 0.0036,  0.0493,  0.0445],\n",
      "          [ 0.0635, -0.0656, -0.0654],\n",
      "          [ 0.0537,  0.0378,  0.0401]],\n",
      "\n",
      "         [[ 0.0273, -0.0203, -0.0050],\n",
      "          [-0.0692, -0.0023,  0.0014],\n",
      "          [ 0.0562,  0.0057,  0.0454]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0322,  0.0370, -0.0568],\n",
      "          [ 0.0607, -0.0718, -0.0619],\n",
      "          [-0.0377,  0.0582,  0.0658]],\n",
      "\n",
      "         [[ 0.0469, -0.0029,  0.0255],\n",
      "          [-0.0422, -0.0141,  0.0673],\n",
      "          [-0.0177, -0.0535, -0.0594]],\n",
      "\n",
      "         [[-0.0548,  0.0173, -0.0293],\n",
      "          [ 0.0696,  0.0663, -0.0464],\n",
      "          [-0.0521,  0.0543, -0.0241]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0464,  0.0445,  0.0624],\n",
      "          [ 0.0042,  0.0352, -0.0593],\n",
      "          [ 0.0502,  0.0342,  0.0609]],\n",
      "\n",
      "         [[-0.0228,  0.0558,  0.0443],\n",
      "          [-0.0608,  0.0320,  0.0569],\n",
      "          [-0.0266, -0.0101, -0.0324]],\n",
      "\n",
      "         [[-0.0033, -0.0673,  0.0134],\n",
      "          [-0.0686, -0.0197, -0.0687],\n",
      "          [ 0.0574, -0.0259,  0.0152]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0230,  0.0431,  0.0100],\n",
      "          [-0.0127, -0.0210,  0.0673],\n",
      "          [-0.0523, -0.0153,  0.0713]],\n",
      "\n",
      "         [[-0.0449,  0.0171,  0.0106],\n",
      "          [-0.0629,  0.0221, -0.0067],\n",
      "          [ 0.0336, -0.0340,  0.0375]],\n",
      "\n",
      "         [[ 0.0380, -0.0116, -0.0574],\n",
      "          [ 0.0403,  0.0119,  0.0609],\n",
      "          [-0.0195,  0.0264, -0.0111]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.1651]],\n",
      "\n",
      "         [[ 0.0537]],\n",
      "\n",
      "         [[ 0.1067]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1318]],\n",
      "\n",
      "         [[-0.2018]],\n",
      "\n",
      "         [[ 0.0538]]],\n",
      "\n",
      "\n",
      "        [[[-0.1632]],\n",
      "\n",
      "         [[-0.0620]],\n",
      "\n",
      "         [[ 0.2024]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0260]],\n",
      "\n",
      "         [[-0.1615]],\n",
      "\n",
      "         [[-0.0163]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1640]],\n",
      "\n",
      "         [[-0.0953]],\n",
      "\n",
      "         [[-0.1997]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1550]],\n",
      "\n",
      "         [[-0.0860]],\n",
      "\n",
      "         [[ 0.1707]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1495]],\n",
      "\n",
      "         [[-0.0485]],\n",
      "\n",
      "         [[-0.0508]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1378]],\n",
      "\n",
      "         [[-0.1997]],\n",
      "\n",
      "         [[-0.0925]]],\n",
      "\n",
      "\n",
      "        [[[-0.0650]],\n",
      "\n",
      "         [[-0.0307]],\n",
      "\n",
      "         [[-0.0803]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1198]],\n",
      "\n",
      "         [[ 0.1336]],\n",
      "\n",
      "         [[-0.0124]]],\n",
      "\n",
      "\n",
      "        [[[-0.0776]],\n",
      "\n",
      "         [[-0.0995]],\n",
      "\n",
      "         [[ 0.1350]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0685]],\n",
      "\n",
      "         [[-0.1957]],\n",
      "\n",
      "         [[ 0.1532]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-5.8361e-02,  4.3967e-02,  1.9335e-02],\n",
      "          [-6.9937e-02, -2.0025e-03, -6.8090e-02],\n",
      "          [ 4.7098e-02,  2.7067e-02, -1.9417e-02]],\n",
      "\n",
      "         [[-6.6299e-02,  2.3491e-02,  3.0739e-02],\n",
      "          [ 5.1637e-02,  6.6776e-02,  4.6423e-02],\n",
      "          [-4.4831e-02,  6.0082e-02, -6.6748e-02]],\n",
      "\n",
      "         [[-5.3881e-02,  4.4393e-02,  7.1249e-02],\n",
      "          [-5.4182e-02, -5.4947e-02,  3.6268e-02],\n",
      "          [-4.9698e-02, -3.3820e-02,  6.6589e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.5096e-04,  3.9687e-02, -4.4149e-02],\n",
      "          [-2.4187e-02,  1.8282e-05, -3.7464e-02],\n",
      "          [ 4.7236e-02,  3.8950e-02,  1.8970e-02]],\n",
      "\n",
      "         [[-4.3401e-02,  3.6917e-02,  3.8127e-02],\n",
      "          [-1.7634e-02, -2.9435e-02,  6.1850e-02],\n",
      "          [ 4.0274e-02,  3.0976e-02, -1.4159e-02]],\n",
      "\n",
      "         [[ 5.9940e-02, -4.0664e-02, -3.4104e-02],\n",
      "          [-5.7525e-02,  4.9651e-03, -6.0294e-02],\n",
      "          [-4.8260e-02,  2.7497e-02,  6.1873e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3584e-03,  6.9374e-02,  1.7406e-03],\n",
      "          [ 3.2924e-02, -4.6742e-02, -6.2671e-02],\n",
      "          [-5.6116e-02,  3.2433e-02,  3.7741e-02]],\n",
      "\n",
      "         [[-6.9405e-02, -4.0413e-03, -3.6516e-02],\n",
      "          [-4.9980e-02,  5.9302e-02,  4.7920e-02],\n",
      "          [ 3.0873e-02,  7.0760e-02, -4.9239e-02]],\n",
      "\n",
      "         [[ 1.6649e-02,  2.5722e-02,  6.1438e-02],\n",
      "          [-4.3194e-02, -2.7319e-02, -5.0372e-02],\n",
      "          [ 4.5982e-02,  1.1867e-02, -3.0318e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3288e-02,  1.0936e-02, -3.4010e-02],\n",
      "          [ 6.1534e-02,  3.4447e-03,  4.1700e-02],\n",
      "          [ 6.2551e-02,  6.7436e-03, -2.2963e-02]],\n",
      "\n",
      "         [[-4.8363e-02, -5.9332e-02,  2.7749e-02],\n",
      "          [-6.4096e-02, -6.7914e-02,  1.8328e-02],\n",
      "          [ 1.7719e-02, -3.7561e-02, -6.7607e-02]],\n",
      "\n",
      "         [[ 4.4425e-02, -2.7530e-02,  3.1674e-02],\n",
      "          [ 4.6315e-02,  5.1865e-02, -4.3293e-03],\n",
      "          [ 6.6707e-02,  4.8680e-02, -3.4611e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7538e-02, -6.4942e-03, -6.9893e-02],\n",
      "          [-5.3450e-02, -6.3718e-02,  4.7847e-02],\n",
      "          [-3.7329e-02,  2.5263e-02, -6.5040e-02]],\n",
      "\n",
      "         [[ 7.6333e-04, -9.4663e-03, -2.9179e-02],\n",
      "          [-9.7913e-03, -4.4311e-02,  5.0944e-02],\n",
      "          [-4.9464e-02,  1.6204e-02, -6.7356e-02]],\n",
      "\n",
      "         [[ 4.1183e-02, -6.1768e-02, -3.2091e-03],\n",
      "          [ 5.0096e-02, -5.0493e-02,  4.8132e-02],\n",
      "          [-2.1173e-02,  2.0968e-02,  1.4689e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8847e-02, -2.1903e-02,  5.7067e-02],\n",
      "          [ 4.8588e-03, -7.1166e-02, -3.3185e-03],\n",
      "          [-2.7669e-02,  2.9039e-02,  1.2090e-02]],\n",
      "\n",
      "         [[ 2.5297e-03,  2.1054e-03, -2.5435e-02],\n",
      "          [-2.4668e-02, -2.2192e-02,  6.9459e-02],\n",
      "          [-2.5951e-02, -5.9575e-03, -4.0420e-02]],\n",
      "\n",
      "         [[ 3.6359e-03,  4.7514e-02,  3.8554e-02],\n",
      "          [ 3.6749e-02, -4.3776e-02, -7.0704e-03],\n",
      "          [ 2.3637e-02, -4.1638e-02,  5.3511e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.4255e-03,  4.5287e-02, -8.3604e-04],\n",
      "          [-1.0131e-02,  5.8311e-02,  4.7475e-02],\n",
      "          [ 2.4177e-02,  1.7301e-03,  5.6660e-02]],\n",
      "\n",
      "         [[-4.8232e-02,  7.1842e-02,  1.1306e-03],\n",
      "          [ 5.9096e-02,  1.5274e-02, -6.5460e-02],\n",
      "          [ 3.8964e-02,  6.8718e-02,  5.8633e-02]],\n",
      "\n",
      "         [[ 3.4680e-02, -1.1001e-02,  1.2876e-02],\n",
      "          [ 1.6544e-02, -2.5788e-02, -4.5027e-02],\n",
      "          [-7.7967e-03,  6.0786e-02,  2.6727e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0871e-02,  5.0976e-04, -6.2212e-02],\n",
      "          [ 4.1213e-02,  4.5970e-02, -3.2748e-02],\n",
      "          [ 2.2624e-02, -2.2783e-02,  1.3581e-03]],\n",
      "\n",
      "         [[ 9.6492e-03,  4.8859e-02, -3.7977e-02],\n",
      "          [-6.5767e-02,  4.1305e-02, -1.9301e-02],\n",
      "          [-5.7338e-02, -7.0321e-02, -2.4290e-02]],\n",
      "\n",
      "         [[-6.3160e-02, -3.0796e-02, -2.1461e-02],\n",
      "          [-5.5878e-02, -4.6383e-02, -4.0222e-02],\n",
      "          [-1.6168e-02,  3.7260e-02, -1.7152e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0506e-03, -9.1884e-03, -3.6467e-03],\n",
      "          [-4.9381e-02,  1.9200e-02, -3.5441e-02],\n",
      "          [-4.8586e-02, -3.9366e-02,  4.6574e-04]],\n",
      "\n",
      "         [[-4.5583e-02,  2.0400e-02,  3.8844e-02],\n",
      "          [ 4.7514e-02, -7.6476e-03, -1.7592e-02],\n",
      "          [-1.8662e-02, -2.9073e-02, -7.7827e-04]],\n",
      "\n",
      "         [[ 4.3854e-02, -5.4793e-03, -5.2217e-02],\n",
      "          [ 7.2010e-02, -1.7207e-02, -3.0101e-02],\n",
      "          [-1.5090e-02, -2.4421e-03,  5.1381e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6641e-03, -2.4545e-02, -4.5588e-02],\n",
      "          [-6.0864e-02, -4.4741e-02, -4.6254e-02],\n",
      "          [ 4.2919e-03, -6.9190e-02, -3.5359e-02]],\n",
      "\n",
      "         [[-3.4922e-02,  5.9824e-02, -2.0407e-02],\n",
      "          [-1.0176e-02,  1.1207e-02,  6.3278e-03],\n",
      "          [ 1.1013e-02,  2.7773e-02,  1.9046e-02]],\n",
      "\n",
      "         [[-4.4901e-02, -3.5710e-02, -3.5639e-02],\n",
      "          [ 6.2610e-02,  4.5063e-02,  2.0926e-02],\n",
      "          [ 2.1458e-02,  5.3765e-02,  4.8530e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.0901e-02, -2.0406e-02, -5.3417e-02],\n",
      "          [ 5.8692e-02,  5.3131e-02,  3.8162e-02],\n",
      "          [-4.9677e-02, -4.1072e-02, -2.6139e-02]],\n",
      "\n",
      "         [[-6.6188e-02,  3.0452e-02,  2.2527e-02],\n",
      "          [-5.9044e-02, -5.7138e-03,  6.0402e-02],\n",
      "          [ 3.0980e-02,  4.9560e-02, -4.2639e-02]],\n",
      "\n",
      "         [[ 1.2343e-02, -5.4795e-02,  1.0605e-02],\n",
      "          [-6.2678e-02,  6.0579e-04, -4.4768e-02],\n",
      "          [-4.7622e-02, -6.5490e-02,  1.9713e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.2195e-02, -6.1870e-02,  7.0481e-02],\n",
      "          [ 3.2306e-02,  5.1075e-02,  3.3793e-02],\n",
      "          [ 5.1047e-02,  1.4186e-02, -1.8667e-02]],\n",
      "\n",
      "         [[-5.5092e-02, -2.1585e-02, -6.3316e-02],\n",
      "          [-2.6385e-02, -4.4519e-02, -1.3613e-02],\n",
      "          [-3.0805e-02,  1.0534e-02, -5.7188e-02]],\n",
      "\n",
      "         [[ 2.7061e-02,  9.7496e-03,  4.4829e-02],\n",
      "          [-5.3325e-02,  3.8027e-02, -6.1356e-02],\n",
      "          [-3.5708e-02, -3.1364e-02, -5.6054e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0162]],\n",
      "\n",
      "         [[ 0.1326]],\n",
      "\n",
      "         [[-0.0318]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0170]],\n",
      "\n",
      "         [[-0.0864]],\n",
      "\n",
      "         [[ 0.0523]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0254]],\n",
      "\n",
      "         [[-0.0981]],\n",
      "\n",
      "         [[-0.1254]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0699]],\n",
      "\n",
      "         [[-0.0277]],\n",
      "\n",
      "         [[ 0.0186]]],\n",
      "\n",
      "\n",
      "        [[[-0.0400]],\n",
      "\n",
      "         [[ 0.0598]],\n",
      "\n",
      "         [[ 0.0259]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1151]],\n",
      "\n",
      "         [[-0.0605]],\n",
      "\n",
      "         [[ 0.0768]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1053]],\n",
      "\n",
      "         [[-0.0170]],\n",
      "\n",
      "         [[-0.1224]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0931]],\n",
      "\n",
      "         [[ 0.0231]],\n",
      "\n",
      "         [[-0.0188]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1316]],\n",
      "\n",
      "         [[ 0.0420]],\n",
      "\n",
      "         [[ 0.0988]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0284]],\n",
      "\n",
      "         [[ 0.0349]],\n",
      "\n",
      "         [[-0.0131]]],\n",
      "\n",
      "\n",
      "        [[[-0.1233]],\n",
      "\n",
      "         [[-0.0569]],\n",
      "\n",
      "         [[ 0.0038]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1165]],\n",
      "\n",
      "         [[ 0.0573]],\n",
      "\n",
      "         [[ 0.0791]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0250]],\n",
      "\n",
      "         [[ 0.0652]],\n",
      "\n",
      "         [[ 0.1156]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0830]],\n",
      "\n",
      "         [[-0.1329]],\n",
      "\n",
      "         [[ 0.0489]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0086]],\n",
      "\n",
      "         [[ 0.0955]],\n",
      "\n",
      "         [[ 0.1120]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0258]],\n",
      "\n",
      "         [[-0.1092]],\n",
      "\n",
      "         [[-0.1199]]],\n",
      "\n",
      "\n",
      "        [[[-0.0880]],\n",
      "\n",
      "         [[-0.0261]],\n",
      "\n",
      "         [[-0.0833]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0384]],\n",
      "\n",
      "         [[-0.0714]],\n",
      "\n",
      "         [[ 0.0935]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0188]],\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         [[-0.0886]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0564]],\n",
      "\n",
      "         [[ 0.0056]],\n",
      "\n",
      "         [[-0.0280]]],\n",
      "\n",
      "\n",
      "        [[[-0.0210]],\n",
      "\n",
      "         [[-0.1313]],\n",
      "\n",
      "         [[-0.0759]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0256]],\n",
      "\n",
      "         [[ 0.0692]],\n",
      "\n",
      "         [[ 0.0591]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0822]],\n",
      "\n",
      "         [[ 0.0940]],\n",
      "\n",
      "         [[-0.0684]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1134]],\n",
      "\n",
      "         [[-0.0413]],\n",
      "\n",
      "         [[ 0.0423]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.1226]],\n",
      "\n",
      "         [[-0.1344]],\n",
      "\n",
      "         [[-0.0507]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1027]],\n",
      "\n",
      "         [[ 0.0573]],\n",
      "\n",
      "         [[-0.0309]]],\n",
      "\n",
      "\n",
      "        [[[-0.0690]],\n",
      "\n",
      "         [[ 0.1081]],\n",
      "\n",
      "         [[-0.0015]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1195]],\n",
      "\n",
      "         [[-0.0686]],\n",
      "\n",
      "         [[-0.1023]]],\n",
      "\n",
      "\n",
      "        [[[-0.1032]],\n",
      "\n",
      "         [[ 0.1315]],\n",
      "\n",
      "         [[ 0.1238]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0448]],\n",
      "\n",
      "         [[ 0.1220]],\n",
      "\n",
      "         [[ 0.0283]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1047]],\n",
      "\n",
      "         [[ 0.0879]],\n",
      "\n",
      "         [[ 0.0408]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0659]],\n",
      "\n",
      "         [[-0.0293]],\n",
      "\n",
      "         [[-0.0056]]],\n",
      "\n",
      "\n",
      "        [[[-0.1037]],\n",
      "\n",
      "         [[ 0.0310]],\n",
      "\n",
      "         [[-0.0901]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0592]],\n",
      "\n",
      "         [[-0.1106]],\n",
      "\n",
      "         [[ 0.0270]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0194]],\n",
      "\n",
      "         [[-0.0124]],\n",
      "\n",
      "         [[-0.1293]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0484]],\n",
      "\n",
      "         [[ 0.1252]],\n",
      "\n",
      "         [[ 0.1012]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0373,  0.0079, -0.0058],\n",
      "          [ 0.0508,  0.0460,  0.0515],\n",
      "          [-0.0288,  0.0454,  0.0228]],\n",
      "\n",
      "         [[-0.0014,  0.0717,  0.0473],\n",
      "          [-0.0469,  0.0345, -0.0633],\n",
      "          [ 0.0119,  0.0395,  0.0017]],\n",
      "\n",
      "         [[ 0.0311,  0.0058, -0.0259],\n",
      "          [-0.0151, -0.0439,  0.0526],\n",
      "          [-0.0067,  0.0500,  0.0067]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0039,  0.0674,  0.0422],\n",
      "          [ 0.0329,  0.0287,  0.0569],\n",
      "          [-0.0190, -0.0354,  0.0462]],\n",
      "\n",
      "         [[ 0.0401,  0.0362,  0.0642],\n",
      "          [-0.0551,  0.0087, -0.0450],\n",
      "          [ 0.0489,  0.0031, -0.0371]],\n",
      "\n",
      "         [[-0.0546,  0.0416, -0.0089],\n",
      "          [-0.0344, -0.0516,  0.0069],\n",
      "          [-0.0413,  0.0538,  0.0484]]],\n",
      "\n",
      "\n",
      "        [[[-0.0354, -0.0693, -0.0622],\n",
      "          [ 0.0418, -0.0701, -0.0013],\n",
      "          [ 0.0312,  0.0404,  0.0135]],\n",
      "\n",
      "         [[-0.0112,  0.0136,  0.0391],\n",
      "          [ 0.0444,  0.0536, -0.0372],\n",
      "          [ 0.0209, -0.0047, -0.0082]],\n",
      "\n",
      "         [[-0.0149,  0.0575,  0.0037],\n",
      "          [-0.0251,  0.0642, -0.0392],\n",
      "          [-0.0289, -0.0631,  0.0269]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0218, -0.0062,  0.0364],\n",
      "          [ 0.0488,  0.0298,  0.0496],\n",
      "          [-0.0002, -0.0010,  0.0049]],\n",
      "\n",
      "         [[ 0.0591, -0.0080, -0.0366],\n",
      "          [ 0.0156, -0.0354,  0.0408],\n",
      "          [-0.0020, -0.0406,  0.0558]],\n",
      "\n",
      "         [[-0.0352, -0.0484,  0.0613],\n",
      "          [ 0.0311, -0.0006, -0.0703],\n",
      "          [ 0.0308,  0.0168,  0.0404]]],\n",
      "\n",
      "\n",
      "        [[[-0.0091,  0.0551, -0.0083],\n",
      "          [ 0.0682,  0.0422,  0.0261],\n",
      "          [ 0.0051,  0.0222,  0.0318]],\n",
      "\n",
      "         [[-0.0558,  0.0700, -0.0341],\n",
      "          [-0.0219,  0.0637,  0.0433],\n",
      "          [ 0.0398,  0.0171,  0.0189]],\n",
      "\n",
      "         [[-0.0474,  0.0581, -0.0684],\n",
      "          [ 0.0090, -0.0690,  0.0444],\n",
      "          [ 0.0305, -0.0437, -0.0596]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0028,  0.0159,  0.0299],\n",
      "          [ 0.0220, -0.0030,  0.0481],\n",
      "          [ 0.0105,  0.0654,  0.0073]],\n",
      "\n",
      "         [[-0.0396, -0.0631,  0.0009],\n",
      "          [ 0.0210, -0.0312, -0.0626],\n",
      "          [-0.0501, -0.0157, -0.0415]],\n",
      "\n",
      "         [[ 0.0209, -0.0008,  0.0715],\n",
      "          [ 0.0358,  0.0387,  0.0340],\n",
      "          [-0.0641,  0.0277, -0.0291]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0503, -0.0002,  0.0394],\n",
      "          [ 0.0443, -0.0221,  0.0362],\n",
      "          [-0.0088, -0.0017, -0.0651]],\n",
      "\n",
      "         [[-0.0479,  0.0492,  0.0497],\n",
      "          [ 0.0501, -0.0538, -0.0438],\n",
      "          [-0.0291,  0.0656,  0.0203]],\n",
      "\n",
      "         [[-0.0137,  0.0167, -0.0417],\n",
      "          [-0.0321, -0.0071, -0.0314],\n",
      "          [ 0.0287,  0.0409, -0.0240]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0030,  0.0042, -0.0032],\n",
      "          [-0.0495,  0.0368, -0.0016],\n",
      "          [-0.0463, -0.0268,  0.0702]],\n",
      "\n",
      "         [[ 0.0266,  0.0487,  0.0536],\n",
      "          [-0.0649, -0.0490, -0.0564],\n",
      "          [ 0.0606,  0.0121, -0.0442]],\n",
      "\n",
      "         [[-0.0319,  0.0451, -0.0488],\n",
      "          [ 0.0118,  0.0293,  0.0201],\n",
      "          [-0.0189,  0.0389, -0.0321]]],\n",
      "\n",
      "\n",
      "        [[[-0.0278,  0.0059, -0.0305],\n",
      "          [ 0.0524, -0.0030, -0.0120],\n",
      "          [-0.0413,  0.0181, -0.0233]],\n",
      "\n",
      "         [[ 0.0620,  0.0085, -0.0574],\n",
      "          [-0.0343,  0.0428, -0.0155],\n",
      "          [ 0.0232,  0.0648, -0.0198]],\n",
      "\n",
      "         [[ 0.0259, -0.0579, -0.0443],\n",
      "          [-0.0675,  0.0245, -0.0196],\n",
      "          [ 0.0429,  0.0028,  0.0280]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0684, -0.0247,  0.0135],\n",
      "          [ 0.0554,  0.0557, -0.0682],\n",
      "          [-0.0175, -0.0013,  0.0160]],\n",
      "\n",
      "         [[ 0.0551, -0.0044, -0.0313],\n",
      "          [-0.0154, -0.0263, -0.0296],\n",
      "          [-0.0274, -0.0599,  0.0299]],\n",
      "\n",
      "         [[-0.0659, -0.0549, -0.0076],\n",
      "          [-0.0502,  0.0422, -0.0680],\n",
      "          [-0.0230,  0.0503,  0.0423]]],\n",
      "\n",
      "\n",
      "        [[[-0.0145, -0.0244, -0.0197],\n",
      "          [ 0.0399, -0.0479,  0.0332],\n",
      "          [-0.0676, -0.0102,  0.0025]],\n",
      "\n",
      "         [[-0.0504, -0.0236, -0.0361],\n",
      "          [-0.0066,  0.0584, -0.0576],\n",
      "          [-0.0149, -0.0181, -0.0452]],\n",
      "\n",
      "         [[ 0.0115,  0.0242, -0.0217],\n",
      "          [ 0.0086, -0.0478, -0.0131],\n",
      "          [-0.0296, -0.0357, -0.0189]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0088, -0.0114,  0.0538],\n",
      "          [ 0.0262,  0.0025,  0.0023],\n",
      "          [-0.0280, -0.0528, -0.0149]],\n",
      "\n",
      "         [[-0.0302, -0.0434, -0.0574],\n",
      "          [ 0.0343, -0.0679, -0.0596],\n",
      "          [ 0.0507,  0.0651, -0.0419]],\n",
      "\n",
      "         [[ 0.0440, -0.0590, -0.0524],\n",
      "          [-0.0625, -0.0643, -0.0541],\n",
      "          [ 0.0110,  0.0302, -0.0566]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0755]],\n",
      "\n",
      "         [[-0.0018]],\n",
      "\n",
      "         [[ 0.0927]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0734]],\n",
      "\n",
      "         [[ 0.1095]],\n",
      "\n",
      "         [[ 0.1307]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1349]],\n",
      "\n",
      "         [[-0.0415]],\n",
      "\n",
      "         [[ 0.0708]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[-0.0953]],\n",
      "\n",
      "         [[-0.1215]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0867]],\n",
      "\n",
      "         [[-0.1296]],\n",
      "\n",
      "         [[-0.0969]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1038]],\n",
      "\n",
      "         [[ 0.1103]],\n",
      "\n",
      "         [[ 0.0318]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0190]],\n",
      "\n",
      "         [[ 0.1053]],\n",
      "\n",
      "         [[-0.0915]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0806]],\n",
      "\n",
      "         [[ 0.1257]],\n",
      "\n",
      "         [[-0.0030]]],\n",
      "\n",
      "\n",
      "        [[[-0.0653]],\n",
      "\n",
      "         [[-0.0183]],\n",
      "\n",
      "         [[ 0.0392]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1229]],\n",
      "\n",
      "         [[-0.1132]],\n",
      "\n",
      "         [[-0.0747]]],\n",
      "\n",
      "\n",
      "        [[[-0.1089]],\n",
      "\n",
      "         [[-0.0181]],\n",
      "\n",
      "         [[ 0.0546]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1132]],\n",
      "\n",
      "         [[ 0.1088]],\n",
      "\n",
      "         [[ 0.0943]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0800]],\n",
      "\n",
      "         [[-0.0638]],\n",
      "\n",
      "         [[ 0.0253]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1208]],\n",
      "\n",
      "         [[-0.0342]],\n",
      "\n",
      "         [[ 0.0012]]],\n",
      "\n",
      "\n",
      "        [[[-0.0427]],\n",
      "\n",
      "         [[-0.0558]],\n",
      "\n",
      "         [[-0.1320]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         [[ 0.0219]],\n",
      "\n",
      "         [[ 0.0346]]],\n",
      "\n",
      "\n",
      "        [[[-0.1287]],\n",
      "\n",
      "         [[ 0.1200]],\n",
      "\n",
      "         [[-0.1149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0059]],\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[ 0.1003]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0869]],\n",
      "\n",
      "         [[ 0.1237]],\n",
      "\n",
      "         [[ 0.0092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0376]],\n",
      "\n",
      "         [[-0.0110]],\n",
      "\n",
      "         [[-0.1228]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1324]],\n",
      "\n",
      "         [[-0.0274]],\n",
      "\n",
      "         [[-0.0516]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0676]],\n",
      "\n",
      "         [[ 0.0739]],\n",
      "\n",
      "         [[-0.0073]]],\n",
      "\n",
      "\n",
      "        [[[-0.1230]],\n",
      "\n",
      "         [[-0.0746]],\n",
      "\n",
      "         [[ 0.0187]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0467]],\n",
      "\n",
      "         [[-0.1163]],\n",
      "\n",
      "         [[-0.0234]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0648, -0.0551,  0.0192],\n",
      "          [ 0.0201,  0.0492,  0.0720],\n",
      "          [-0.0540, -0.0193,  0.0334]],\n",
      "\n",
      "         [[-0.0473,  0.0353, -0.0115],\n",
      "          [-0.0355, -0.0356,  0.0454],\n",
      "          [ 0.0667,  0.0193, -0.0548]],\n",
      "\n",
      "         [[-0.0554,  0.0707, -0.0016],\n",
      "          [-0.0307, -0.0460,  0.0566],\n",
      "          [ 0.0255, -0.0025,  0.0032]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0268,  0.0023,  0.0640],\n",
      "          [ 0.0636, -0.0451,  0.0075],\n",
      "          [ 0.0356, -0.0084,  0.0419]],\n",
      "\n",
      "         [[-0.0421, -0.0311, -0.0165],\n",
      "          [ 0.0169,  0.0166,  0.0380],\n",
      "          [ 0.0150, -0.0543, -0.0711]],\n",
      "\n",
      "         [[ 0.0191, -0.0507, -0.0436],\n",
      "          [ 0.0070,  0.0615,  0.0591],\n",
      "          [ 0.0116, -0.0145, -0.0438]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0389,  0.0196,  0.0686],\n",
      "          [ 0.0117,  0.0146,  0.0330],\n",
      "          [-0.0162,  0.0153, -0.0716]],\n",
      "\n",
      "         [[ 0.0453, -0.0053,  0.0290],\n",
      "          [ 0.0591,  0.0099, -0.0223],\n",
      "          [ 0.0055, -0.0093, -0.0029]],\n",
      "\n",
      "         [[-0.0136,  0.0509, -0.0291],\n",
      "          [ 0.0303, -0.0159, -0.0637],\n",
      "          [ 0.0522, -0.0406,  0.0292]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0534, -0.0211,  0.0270],\n",
      "          [ 0.0573,  0.0617, -0.0472],\n",
      "          [ 0.0459,  0.0586, -0.0182]],\n",
      "\n",
      "         [[-0.0637, -0.0262, -0.0206],\n",
      "          [ 0.0108,  0.0216,  0.0113],\n",
      "          [-0.0403,  0.0096,  0.0488]],\n",
      "\n",
      "         [[ 0.0371, -0.0457, -0.0695],\n",
      "          [ 0.0350, -0.0696,  0.0286],\n",
      "          [-0.0036, -0.0051, -0.0251]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0396,  0.0277,  0.0409],\n",
      "          [ 0.0523,  0.0600, -0.0393],\n",
      "          [-0.0033, -0.0200, -0.0170]],\n",
      "\n",
      "         [[ 0.0302, -0.0282,  0.0664],\n",
      "          [ 0.0144, -0.0393,  0.0151],\n",
      "          [-0.0068, -0.0453,  0.0575]],\n",
      "\n",
      "         [[ 0.0163,  0.0611, -0.0279],\n",
      "          [ 0.0684,  0.0368, -0.0008],\n",
      "          [-0.0650, -0.0298, -0.0399]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0002, -0.0431,  0.0445],\n",
      "          [-0.0178,  0.0149, -0.0531],\n",
      "          [ 0.0231,  0.0614, -0.0103]],\n",
      "\n",
      "         [[ 0.0184, -0.0594,  0.0440],\n",
      "          [-0.0210, -0.0694, -0.0518],\n",
      "          [-0.0616, -0.0703,  0.0110]],\n",
      "\n",
      "         [[-0.0644,  0.0616, -0.0292],\n",
      "          [-0.0613, -0.0454,  0.0101],\n",
      "          [-0.0565,  0.0112, -0.0591]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0180, -0.0628,  0.0198],\n",
      "          [-0.0341, -0.0339, -0.0428],\n",
      "          [-0.0317,  0.0307,  0.0631]],\n",
      "\n",
      "         [[-0.0147, -0.0008,  0.0181],\n",
      "          [-0.0281,  0.0671, -0.0631],\n",
      "          [ 0.0678, -0.0475, -0.0491]],\n",
      "\n",
      "         [[-0.0391,  0.0196,  0.0515],\n",
      "          [ 0.0437,  0.0322, -0.0246],\n",
      "          [-0.0045,  0.0424, -0.0381]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0082, -0.0435,  0.0403],\n",
      "          [-0.0087, -0.0185, -0.0239],\n",
      "          [ 0.0381, -0.0286,  0.0041]],\n",
      "\n",
      "         [[ 0.0091,  0.0010, -0.0175],\n",
      "          [-0.0194, -0.0309, -0.0018],\n",
      "          [-0.0123,  0.0620,  0.0224]],\n",
      "\n",
      "         [[-0.0575, -0.0015, -0.0187],\n",
      "          [ 0.0234,  0.0674,  0.0492],\n",
      "          [ 0.0267, -0.0209,  0.0085]]],\n",
      "\n",
      "\n",
      "        [[[-0.0191,  0.0595,  0.0487],\n",
      "          [-0.0679,  0.0358,  0.0342],\n",
      "          [ 0.0282, -0.0597,  0.0217]],\n",
      "\n",
      "         [[ 0.0707, -0.0706,  0.0342],\n",
      "          [-0.0604,  0.0334,  0.0341],\n",
      "          [-0.0030,  0.0030,  0.0516]],\n",
      "\n",
      "         [[ 0.0653,  0.0710, -0.0243],\n",
      "          [ 0.0579,  0.0584,  0.0045],\n",
      "          [-0.0293, -0.0493,  0.0320]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0676,  0.0653, -0.0634],\n",
      "          [ 0.0576, -0.0302, -0.0442],\n",
      "          [ 0.0370,  0.0103,  0.0616]],\n",
      "\n",
      "         [[ 0.0198,  0.0100, -0.0276],\n",
      "          [ 0.0628,  0.0032, -0.0069],\n",
      "          [ 0.0166,  0.0442,  0.0092]],\n",
      "\n",
      "         [[ 0.0262, -0.0387, -0.0610],\n",
      "          [-0.0652,  0.0323, -0.0146],\n",
      "          [-0.0320,  0.0305, -0.0563]]],\n",
      "\n",
      "\n",
      "        [[[-0.0354,  0.0296,  0.0572],\n",
      "          [ 0.0317, -0.0108, -0.0163],\n",
      "          [-0.0525,  0.0138, -0.0622]],\n",
      "\n",
      "         [[-0.0448,  0.0622,  0.0170],\n",
      "          [-0.0329,  0.0535,  0.0501],\n",
      "          [ 0.0259, -0.0401, -0.0651]],\n",
      "\n",
      "         [[ 0.0686, -0.0491, -0.0189],\n",
      "          [ 0.0635,  0.0147,  0.0557],\n",
      "          [ 0.0245, -0.0564, -0.0500]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0533,  0.0003, -0.0411],\n",
      "          [ 0.0410,  0.0694,  0.0394],\n",
      "          [-0.0507,  0.0348, -0.0345]],\n",
      "\n",
      "         [[ 0.0041, -0.0183, -0.0279],\n",
      "          [-0.0712, -0.0407,  0.0230],\n",
      "          [-0.0263, -0.0096,  0.0296]],\n",
      "\n",
      "         [[ 0.0222, -0.0700,  0.0563],\n",
      "          [ 0.0223,  0.0548, -0.0677],\n",
      "          [-0.0630, -0.0265,  0.0254]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0780]],\n",
      "\n",
      "         [[ 0.1319]],\n",
      "\n",
      "         [[-0.0399]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0736]],\n",
      "\n",
      "         [[ 0.0686]],\n",
      "\n",
      "         [[-0.0022]]],\n",
      "\n",
      "\n",
      "        [[[-0.1181]],\n",
      "\n",
      "         [[ 0.1069]],\n",
      "\n",
      "         [[-0.1209]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0794]],\n",
      "\n",
      "         [[ 0.0257]],\n",
      "\n",
      "         [[ 0.0964]]],\n",
      "\n",
      "\n",
      "        [[[-0.1117]],\n",
      "\n",
      "         [[-0.0401]],\n",
      "\n",
      "         [[-0.1092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0581]],\n",
      "\n",
      "         [[ 0.0038]],\n",
      "\n",
      "         [[-0.1191]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1078]],\n",
      "\n",
      "         [[ 0.1129]],\n",
      "\n",
      "         [[-0.0299]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1239]],\n",
      "\n",
      "         [[-0.0435]],\n",
      "\n",
      "         [[-0.0843]]],\n",
      "\n",
      "\n",
      "        [[[-0.1291]],\n",
      "\n",
      "         [[-0.0964]],\n",
      "\n",
      "         [[-0.0612]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0889]],\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         [[-0.0045]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1140]],\n",
      "\n",
      "         [[ 0.1348]],\n",
      "\n",
      "         [[-0.1229]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0126]],\n",
      "\n",
      "         [[-0.1174]],\n",
      "\n",
      "         [[-0.0357]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0545]],\n",
      "\n",
      "         [[ 0.0828]],\n",
      "\n",
      "         [[-0.0217]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0164]],\n",
      "\n",
      "         [[-0.0946]],\n",
      "\n",
      "         [[ 0.1148]]],\n",
      "\n",
      "\n",
      "        [[[-0.0917]],\n",
      "\n",
      "         [[ 0.0654]],\n",
      "\n",
      "         [[-0.1246]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0295]],\n",
      "\n",
      "         [[-0.1205]],\n",
      "\n",
      "         [[-0.0170]]],\n",
      "\n",
      "\n",
      "        [[[-0.0226]],\n",
      "\n",
      "         [[ 0.0247]],\n",
      "\n",
      "         [[-0.0495]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0838]],\n",
      "\n",
      "         [[-0.0228]],\n",
      "\n",
      "         [[-0.1062]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0697]],\n",
      "\n",
      "         [[-0.0638]],\n",
      "\n",
      "         [[ 0.1089]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0727]],\n",
      "\n",
      "         [[ 0.0638]],\n",
      "\n",
      "         [[ 0.0729]]],\n",
      "\n",
      "\n",
      "        [[[-0.1234]],\n",
      "\n",
      "         [[-0.0873]],\n",
      "\n",
      "         [[-0.0884]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0279]],\n",
      "\n",
      "         [[ 0.0336]],\n",
      "\n",
      "         [[-0.0673]]],\n",
      "\n",
      "\n",
      "        [[[-0.0819]],\n",
      "\n",
      "         [[-0.0005]],\n",
      "\n",
      "         [[-0.0374]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0901]],\n",
      "\n",
      "         [[ 0.0411]],\n",
      "\n",
      "         [[-0.0322]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0142,  0.0254, -0.0507],\n",
      "          [-0.0308, -0.0381,  0.0151],\n",
      "          [ 0.0112,  0.0321,  0.0353]],\n",
      "\n",
      "         [[-0.0155,  0.0134,  0.0089],\n",
      "          [-0.0183,  0.0358, -0.0395],\n",
      "          [-0.0288, -0.0185,  0.0206]],\n",
      "\n",
      "         [[ 0.0291, -0.0086, -0.0014],\n",
      "          [-0.0434, -0.0053, -0.0307],\n",
      "          [-0.0389,  0.0166,  0.0491]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0092,  0.0043, -0.0456],\n",
      "          [-0.0440, -0.0393,  0.0277],\n",
      "          [ 0.0156, -0.0211,  0.0002]],\n",
      "\n",
      "         [[ 0.0053, -0.0500, -0.0362],\n",
      "          [ 0.0053,  0.0435, -0.0036],\n",
      "          [ 0.0279, -0.0477, -0.0422]],\n",
      "\n",
      "         [[ 0.0184, -0.0308,  0.0158],\n",
      "          [-0.0133,  0.0172, -0.0223],\n",
      "          [-0.0292,  0.0420, -0.0171]]],\n",
      "\n",
      "\n",
      "        [[[-0.0134,  0.0336,  0.0134],\n",
      "          [-0.0236, -0.0424,  0.0457],\n",
      "          [ 0.0252, -0.0090,  0.0069]],\n",
      "\n",
      "         [[ 0.0465,  0.0453, -0.0138],\n",
      "          [-0.0436, -0.0240, -0.0509],\n",
      "          [-0.0041, -0.0167, -0.0372]],\n",
      "\n",
      "         [[ 0.0368, -0.0487, -0.0433],\n",
      "          [-0.0252, -0.0395,  0.0210],\n",
      "          [ 0.0211, -0.0135, -0.0367]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0375,  0.0460,  0.0181],\n",
      "          [-0.0404, -0.0439, -0.0483],\n",
      "          [ 0.0121, -0.0426,  0.0054]],\n",
      "\n",
      "         [[-0.0043,  0.0196,  0.0339],\n",
      "          [-0.0221, -0.0415,  0.0414],\n",
      "          [ 0.0254, -0.0355, -0.0495]],\n",
      "\n",
      "         [[-0.0058,  0.0089,  0.0394],\n",
      "          [-0.0390, -0.0480, -0.0171],\n",
      "          [-0.0338,  0.0477, -0.0219]]],\n",
      "\n",
      "\n",
      "        [[[-0.0163,  0.0001, -0.0339],\n",
      "          [-0.0050,  0.0004, -0.0254],\n",
      "          [ 0.0078, -0.0036, -0.0263]],\n",
      "\n",
      "         [[-0.0371,  0.0020,  0.0050],\n",
      "          [-0.0274, -0.0219, -0.0188],\n",
      "          [ 0.0457,  0.0141, -0.0110]],\n",
      "\n",
      "         [[-0.0352, -0.0077, -0.0488],\n",
      "          [ 0.0479,  0.0033, -0.0438],\n",
      "          [-0.0455, -0.0417,  0.0480]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0231,  0.0503,  0.0232],\n",
      "          [-0.0405, -0.0035,  0.0466],\n",
      "          [ 0.0501,  0.0452, -0.0149]],\n",
      "\n",
      "         [[ 0.0423, -0.0496,  0.0420],\n",
      "          [ 0.0502, -0.0359,  0.0472],\n",
      "          [ 0.0366,  0.0018, -0.0036]],\n",
      "\n",
      "         [[ 0.0338,  0.0134, -0.0440],\n",
      "          [-0.0111,  0.0374, -0.0221],\n",
      "          [-0.0461, -0.0182, -0.0320]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0247,  0.0273,  0.0406],\n",
      "          [ 0.0046,  0.0286, -0.0509],\n",
      "          [-0.0027, -0.0289,  0.0291]],\n",
      "\n",
      "         [[-0.0239,  0.0247, -0.0234],\n",
      "          [-0.0462, -0.0199,  0.0339],\n",
      "          [-0.0457,  0.0323, -0.0466]],\n",
      "\n",
      "         [[ 0.0355, -0.0415,  0.0174],\n",
      "          [-0.0285,  0.0346, -0.0063],\n",
      "          [-0.0327, -0.0171,  0.0171]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0197, -0.0357,  0.0197],\n",
      "          [-0.0096,  0.0070,  0.0140],\n",
      "          [ 0.0031, -0.0209, -0.0096]],\n",
      "\n",
      "         [[-0.0208,  0.0032, -0.0099],\n",
      "          [-0.0310,  0.0483, -0.0098],\n",
      "          [-0.0069,  0.0249, -0.0494]],\n",
      "\n",
      "         [[ 0.0184, -0.0399, -0.0313],\n",
      "          [ 0.0169,  0.0099, -0.0097],\n",
      "          [-0.0401,  0.0292,  0.0249]]],\n",
      "\n",
      "\n",
      "        [[[-0.0233,  0.0388,  0.0011],\n",
      "          [ 0.0183, -0.0013,  0.0184],\n",
      "          [-0.0118,  0.0229, -0.0363]],\n",
      "\n",
      "         [[ 0.0062,  0.0160, -0.0286],\n",
      "          [ 0.0251, -0.0195,  0.0121],\n",
      "          [ 0.0177,  0.0015,  0.0024]],\n",
      "\n",
      "         [[ 0.0246, -0.0119, -0.0462],\n",
      "          [ 0.0175, -0.0486, -0.0381],\n",
      "          [ 0.0095,  0.0037,  0.0194]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0090, -0.0345, -0.0245],\n",
      "          [-0.0028, -0.0022, -0.0396],\n",
      "          [ 0.0413,  0.0130,  0.0100]],\n",
      "\n",
      "         [[-0.0093,  0.0071,  0.0139],\n",
      "          [ 0.0052,  0.0220,  0.0205],\n",
      "          [ 0.0156,  0.0481, -0.0040]],\n",
      "\n",
      "         [[ 0.0040, -0.0133, -0.0493],\n",
      "          [ 0.0163,  0.0141,  0.0455],\n",
      "          [-0.0368,  0.0492,  0.0301]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0336,  0.0402,  0.0203],\n",
      "          [-0.0489,  0.0299, -0.0492],\n",
      "          [-0.0048,  0.0273, -0.0146]],\n",
      "\n",
      "         [[ 0.0060,  0.0367, -0.0437],\n",
      "          [-0.0255, -0.0352,  0.0115],\n",
      "          [ 0.0315,  0.0484,  0.0210]],\n",
      "\n",
      "         [[ 0.0009, -0.0214, -0.0166],\n",
      "          [ 0.0316, -0.0191, -0.0198],\n",
      "          [-0.0442,  0.0056,  0.0166]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0189,  0.0483,  0.0042],\n",
      "          [-0.0198, -0.0486,  0.0478],\n",
      "          [ 0.0446,  0.0336, -0.0260]],\n",
      "\n",
      "         [[ 0.0153,  0.0268,  0.0115],\n",
      "          [-0.0049,  0.0507,  0.0114],\n",
      "          [-0.0112,  0.0335,  0.0499]],\n",
      "\n",
      "         [[ 0.0172, -0.0161, -0.0261],\n",
      "          [ 0.0255, -0.0359,  0.0298],\n",
      "          [ 0.0167, -0.0421,  0.0050]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0691]],\n",
      "\n",
      "         [[-0.0393]],\n",
      "\n",
      "         [[ 0.0448]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0014]],\n",
      "\n",
      "         [[-0.0073]],\n",
      "\n",
      "         [[ 0.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0726]],\n",
      "\n",
      "         [[-0.0244]],\n",
      "\n",
      "         [[-0.0683]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0525]],\n",
      "\n",
      "         [[ 0.0661]],\n",
      "\n",
      "         [[ 0.0173]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0011]],\n",
      "\n",
      "         [[-0.0601]],\n",
      "\n",
      "         [[-0.0931]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0522]],\n",
      "\n",
      "         [[ 0.0542]],\n",
      "\n",
      "         [[-0.0082]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0287]],\n",
      "\n",
      "         [[ 0.0785]],\n",
      "\n",
      "         [[-0.0047]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0437]],\n",
      "\n",
      "         [[-0.0007]],\n",
      "\n",
      "         [[ 0.0621]]],\n",
      "\n",
      "\n",
      "        [[[-0.0390]],\n",
      "\n",
      "         [[ 0.0185]],\n",
      "\n",
      "         [[ 0.0089]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0627]],\n",
      "\n",
      "         [[-0.0778]],\n",
      "\n",
      "         [[ 0.0328]]],\n",
      "\n",
      "\n",
      "        [[[-0.0110]],\n",
      "\n",
      "         [[-0.0808]],\n",
      "\n",
      "         [[ 0.0663]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0326]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[ 0.0727]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0478]],\n",
      "\n",
      "         [[-0.0090]],\n",
      "\n",
      "         [[ 0.0639]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0135]],\n",
      "\n",
      "         [[-0.0617]],\n",
      "\n",
      "         [[-0.0776]]],\n",
      "\n",
      "\n",
      "        [[[-0.0050]],\n",
      "\n",
      "         [[ 0.0327]],\n",
      "\n",
      "         [[ 0.0024]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0120]],\n",
      "\n",
      "         [[ 0.0113]],\n",
      "\n",
      "         [[ 0.0493]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0540]],\n",
      "\n",
      "         [[ 0.0622]],\n",
      "\n",
      "         [[ 0.0707]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0849]],\n",
      "\n",
      "         [[-0.0556]],\n",
      "\n",
      "         [[-0.0792]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0454]],\n",
      "\n",
      "         [[-0.0279]],\n",
      "\n",
      "         [[-0.0311]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0206]],\n",
      "\n",
      "         [[-0.0131]],\n",
      "\n",
      "         [[-0.0064]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0074]],\n",
      "\n",
      "         [[ 0.0238]],\n",
      "\n",
      "         [[ 0.0511]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0270]],\n",
      "\n",
      "         [[-0.0256]],\n",
      "\n",
      "         [[ 0.0484]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0180]],\n",
      "\n",
      "         [[ 0.0869]],\n",
      "\n",
      "         [[-0.0422]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0174]],\n",
      "\n",
      "         [[ 0.0072]],\n",
      "\n",
      "         [[-0.0508]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0052]],\n",
      "\n",
      "         [[ 0.0437]],\n",
      "\n",
      "         [[ 0.0457]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0806]],\n",
      "\n",
      "         [[-0.0001]],\n",
      "\n",
      "         [[-0.0924]]],\n",
      "\n",
      "\n",
      "        [[[-0.0797]],\n",
      "\n",
      "         [[-0.0346]],\n",
      "\n",
      "         [[-0.0489]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0745]],\n",
      "\n",
      "         [[ 0.0893]],\n",
      "\n",
      "         [[-0.0329]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0493]],\n",
      "\n",
      "         [[-0.0645]],\n",
      "\n",
      "         [[-0.0528]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0229]],\n",
      "\n",
      "         [[-0.0093]],\n",
      "\n",
      "         [[-0.0004]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0494]],\n",
      "\n",
      "         [[-0.0401]],\n",
      "\n",
      "         [[ 0.0465]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0492]],\n",
      "\n",
      "         [[ 0.0502]],\n",
      "\n",
      "         [[-0.0544]]],\n",
      "\n",
      "\n",
      "        [[[-0.0953]],\n",
      "\n",
      "         [[ 0.0770]],\n",
      "\n",
      "         [[-0.0805]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0569]],\n",
      "\n",
      "         [[-0.0723]],\n",
      "\n",
      "         [[-0.0002]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0200]],\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         [[-0.0228]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0626]],\n",
      "\n",
      "         [[ 0.0919]],\n",
      "\n",
      "         [[-0.0601]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0443,  0.0043, -0.0206],\n",
      "          [ 0.0159, -0.0457, -0.0060],\n",
      "          [-0.0471,  0.0077, -0.0179]],\n",
      "\n",
      "         [[-0.0457,  0.0364, -0.0015],\n",
      "          [-0.0343, -0.0310,  0.0155],\n",
      "          [-0.0228,  0.0383, -0.0052]],\n",
      "\n",
      "         [[ 0.0110,  0.0502,  0.0113],\n",
      "          [ 0.0090, -0.0282,  0.0238],\n",
      "          [-0.0213, -0.0128,  0.0272]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0496, -0.0381, -0.0145],\n",
      "          [ 0.0091, -0.0074,  0.0203],\n",
      "          [ 0.0359,  0.0388, -0.0010]],\n",
      "\n",
      "         [[ 0.0225, -0.0215, -0.0476],\n",
      "          [ 0.0055, -0.0199,  0.0490],\n",
      "          [ 0.0298,  0.0336, -0.0447]],\n",
      "\n",
      "         [[-0.0075, -0.0431,  0.0469],\n",
      "          [ 0.0451,  0.0240,  0.0502],\n",
      "          [-0.0112, -0.0429,  0.0270]]],\n",
      "\n",
      "\n",
      "        [[[-0.0005,  0.0134,  0.0233],\n",
      "          [ 0.0020,  0.0269,  0.0491],\n",
      "          [-0.0044, -0.0371,  0.0126]],\n",
      "\n",
      "         [[-0.0297, -0.0085,  0.0470],\n",
      "          [-0.0255,  0.0241,  0.0426],\n",
      "          [ 0.0499,  0.0111, -0.0305]],\n",
      "\n",
      "         [[ 0.0221, -0.0231,  0.0154],\n",
      "          [-0.0127,  0.0350,  0.0331],\n",
      "          [-0.0414, -0.0473, -0.0436]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0085,  0.0313,  0.0058],\n",
      "          [-0.0055,  0.0354,  0.0026],\n",
      "          [ 0.0205,  0.0327, -0.0213]],\n",
      "\n",
      "         [[-0.0346, -0.0414, -0.0298],\n",
      "          [ 0.0439,  0.0015, -0.0315],\n",
      "          [-0.0224,  0.0027,  0.0144]],\n",
      "\n",
      "         [[-0.0222, -0.0140,  0.0308],\n",
      "          [ 0.0152, -0.0393,  0.0475],\n",
      "          [-0.0488, -0.0390,  0.0225]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0219, -0.0464,  0.0312],\n",
      "          [ 0.0432, -0.0463, -0.0501],\n",
      "          [ 0.0414,  0.0207,  0.0128]],\n",
      "\n",
      "         [[-0.0426,  0.0508, -0.0231],\n",
      "          [-0.0259,  0.0213,  0.0132],\n",
      "          [-0.0272, -0.0354,  0.0445]],\n",
      "\n",
      "         [[ 0.0508,  0.0328, -0.0109],\n",
      "          [ 0.0283,  0.0437, -0.0236],\n",
      "          [-0.0105, -0.0422,  0.0157]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0312,  0.0407,  0.0230],\n",
      "          [ 0.0261,  0.0029, -0.0334],\n",
      "          [ 0.0292,  0.0230,  0.0157]],\n",
      "\n",
      "         [[ 0.0288,  0.0117, -0.0236],\n",
      "          [-0.0334,  0.0162,  0.0354],\n",
      "          [ 0.0278,  0.0026,  0.0140]],\n",
      "\n",
      "         [[-0.0089, -0.0135, -0.0287],\n",
      "          [ 0.0268,  0.0282, -0.0342],\n",
      "          [ 0.0368, -0.0431,  0.0136]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0300,  0.0121,  0.0056],\n",
      "          [-0.0120,  0.0008, -0.0239],\n",
      "          [-0.0323,  0.0287,  0.0314]],\n",
      "\n",
      "         [[ 0.0016,  0.0407,  0.0180],\n",
      "          [-0.0407, -0.0404, -0.0498],\n",
      "          [-0.0397, -0.0055, -0.0010]],\n",
      "\n",
      "         [[ 0.0355,  0.0448, -0.0390],\n",
      "          [-0.0377,  0.0426, -0.0301],\n",
      "          [ 0.0025,  0.0476, -0.0087]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0111, -0.0194,  0.0169],\n",
      "          [ 0.0443, -0.0437, -0.0454],\n",
      "          [-0.0336, -0.0003, -0.0345]],\n",
      "\n",
      "         [[-0.0184, -0.0336,  0.0135],\n",
      "          [-0.0395, -0.0350, -0.0315],\n",
      "          [ 0.0360, -0.0083,  0.0472]],\n",
      "\n",
      "         [[ 0.0422,  0.0301,  0.0435],\n",
      "          [ 0.0330, -0.0088,  0.0047],\n",
      "          [-0.0342,  0.0324,  0.0225]]],\n",
      "\n",
      "\n",
      "        [[[-0.0450, -0.0318,  0.0395],\n",
      "          [ 0.0066, -0.0243, -0.0341],\n",
      "          [ 0.0166,  0.0236,  0.0079]],\n",
      "\n",
      "         [[ 0.0325, -0.0012, -0.0014],\n",
      "          [ 0.0269, -0.0453, -0.0147],\n",
      "          [-0.0096,  0.0128, -0.0252]],\n",
      "\n",
      "         [[ 0.0213, -0.0304,  0.0191],\n",
      "          [-0.0069,  0.0176, -0.0268],\n",
      "          [-0.0209,  0.0090, -0.0032]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0318,  0.0372,  0.0473],\n",
      "          [ 0.0091,  0.0314, -0.0399],\n",
      "          [-0.0040,  0.0488, -0.0257]],\n",
      "\n",
      "         [[-0.0486,  0.0013,  0.0438],\n",
      "          [-0.0319, -0.0342, -0.0055],\n",
      "          [ 0.0038,  0.0125, -0.0321]],\n",
      "\n",
      "         [[ 0.0200,  0.0504, -0.0171],\n",
      "          [ 0.0134, -0.0290,  0.0080],\n",
      "          [ 0.0245, -0.0247, -0.0022]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0054,  0.0492,  0.0485],\n",
      "          [ 0.0125, -0.0331, -0.0177],\n",
      "          [ 0.0007, -0.0130, -0.0265]],\n",
      "\n",
      "         [[ 0.0112, -0.0145,  0.0181],\n",
      "          [-0.0086,  0.0417, -0.0438],\n",
      "          [-0.0018,  0.0312,  0.0338]],\n",
      "\n",
      "         [[ 0.0268, -0.0392,  0.0347],\n",
      "          [ 0.0056, -0.0043, -0.0401],\n",
      "          [ 0.0410,  0.0022, -0.0101]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0483, -0.0151, -0.0365],\n",
      "          [ 0.0070, -0.0325,  0.0131],\n",
      "          [-0.0123,  0.0089, -0.0472]],\n",
      "\n",
      "         [[ 0.0084, -0.0491,  0.0151],\n",
      "          [ 0.0164, -0.0009,  0.0172],\n",
      "          [ 0.0007, -0.0396, -0.0365]],\n",
      "\n",
      "         [[-0.0374,  0.0101, -0.0415],\n",
      "          [ 0.0282, -0.0465, -0.0070],\n",
      "          [-0.0409,  0.0153, -0.0482]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0589]],\n",
      "\n",
      "         [[ 0.0709]],\n",
      "\n",
      "         [[-0.0635]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0358]],\n",
      "\n",
      "         [[-0.0067]],\n",
      "\n",
      "         [[ 0.0607]]],\n",
      "\n",
      "\n",
      "        [[[-0.0702]],\n",
      "\n",
      "         [[ 0.0536]],\n",
      "\n",
      "         [[ 0.0928]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0307]],\n",
      "\n",
      "         [[ 0.0823]],\n",
      "\n",
      "         [[ 0.0757]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0721]],\n",
      "\n",
      "         [[-0.0101]],\n",
      "\n",
      "         [[ 0.0611]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0431]],\n",
      "\n",
      "         [[-0.0703]],\n",
      "\n",
      "         [[-0.0428]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0418]],\n",
      "\n",
      "         [[-0.0118]],\n",
      "\n",
      "         [[-0.0466]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0447]],\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[-0.0292]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0130]],\n",
      "\n",
      "         [[-0.0281]],\n",
      "\n",
      "         [[ 0.0813]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0186]],\n",
      "\n",
      "         [[ 0.0690]],\n",
      "\n",
      "         [[ 0.0764]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0023]],\n",
      "\n",
      "         [[-0.0662]],\n",
      "\n",
      "         [[-0.0841]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0725]],\n",
      "\n",
      "         [[ 0.0954]],\n",
      "\n",
      "         [[-0.0583]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-6.0279e-02]],\n",
      "\n",
      "         [[ 5.2253e-02]],\n",
      "\n",
      "         [[-2.5975e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9734e-02]],\n",
      "\n",
      "         [[ 3.2848e-02]],\n",
      "\n",
      "         [[-6.7955e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.3150e-02]],\n",
      "\n",
      "         [[-8.1378e-02]],\n",
      "\n",
      "         [[-3.5359e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2425e-02]],\n",
      "\n",
      "         [[-5.0916e-02]],\n",
      "\n",
      "         [[ 3.5729e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6549e-02]],\n",
      "\n",
      "         [[-6.6929e-03]],\n",
      "\n",
      "         [[-8.3192e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.4719e-02]],\n",
      "\n",
      "         [[ 1.7550e-02]],\n",
      "\n",
      "         [[-4.5050e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.9836e-02]],\n",
      "\n",
      "         [[ 5.8632e-02]],\n",
      "\n",
      "         [[ 8.2733e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7923e-02]],\n",
      "\n",
      "         [[-7.1449e-02]],\n",
      "\n",
      "         [[ 4.6919e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.9426e-02]],\n",
      "\n",
      "         [[ 1.0372e-02]],\n",
      "\n",
      "         [[ 4.0505e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.9964e-03]],\n",
      "\n",
      "         [[ 8.8216e-02]],\n",
      "\n",
      "         [[-7.6610e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4927e-05]],\n",
      "\n",
      "         [[-3.2047e-02]],\n",
      "\n",
      "         [[-1.4788e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.7715e-02]],\n",
      "\n",
      "         [[ 6.9161e-03]],\n",
      "\n",
      "         [[-3.1232e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 1.3763e-02, -3.3825e-02, -4.5018e-02],\n",
      "          [ 1.5222e-02, -3.8883e-02, -1.5357e-02],\n",
      "          [-8.2684e-04, -1.6775e-03,  7.9646e-03]],\n",
      "\n",
      "         [[-9.9019e-03, -2.3251e-02,  3.5381e-02],\n",
      "          [-4.1206e-03,  4.7282e-02,  3.1193e-02],\n",
      "          [ 6.3769e-03, -2.7437e-02, -7.0056e-03]],\n",
      "\n",
      "         [[-3.0905e-02,  7.8032e-03,  2.9718e-02],\n",
      "          [-3.9768e-02,  2.5511e-02,  3.7840e-02],\n",
      "          [-1.9581e-02, -4.8565e-02,  1.1457e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8018e-03, -3.2016e-02,  3.0004e-02],\n",
      "          [ 4.5100e-02, -1.7855e-02, -4.8018e-02],\n",
      "          [-3.7033e-02,  2.3745e-02, -4.7035e-03]],\n",
      "\n",
      "         [[ 3.5786e-02, -2.1846e-02, -1.2065e-02],\n",
      "          [ 2.2001e-02, -8.5545e-03, -3.6987e-02],\n",
      "          [-3.8786e-02, -1.4684e-02,  1.4208e-02]],\n",
      "\n",
      "         [[ 4.8337e-02,  3.5936e-02,  3.6175e-02],\n",
      "          [ 4.3061e-03, -2.5003e-02,  3.4655e-02],\n",
      "          [ 1.9429e-02, -3.6029e-03, -2.5772e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4234e-03, -3.7342e-02,  2.6945e-02],\n",
      "          [-2.6986e-02,  2.4417e-02, -1.3597e-02],\n",
      "          [-1.0776e-02,  3.2828e-02, -4.0122e-02]],\n",
      "\n",
      "         [[-2.7346e-02,  2.1627e-02,  3.5827e-02],\n",
      "          [-3.8768e-02,  7.1074e-03,  4.6814e-02],\n",
      "          [-3.8275e-02,  1.1163e-02,  5.0850e-02]],\n",
      "\n",
      "         [[ 3.1587e-02,  3.1877e-02, -4.8053e-02],\n",
      "          [ 2.6073e-02,  3.8194e-02,  6.8343e-03],\n",
      "          [-5.4069e-03, -1.9117e-02,  1.4401e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2083e-02, -6.4530e-03, -1.5565e-02],\n",
      "          [-3.5739e-02,  2.2285e-02,  1.7992e-02],\n",
      "          [-4.5658e-02, -2.5286e-02, -2.5054e-03]],\n",
      "\n",
      "         [[ 1.8468e-03, -8.8187e-03,  2.8548e-02],\n",
      "          [ 2.8270e-02,  1.3345e-02, -2.8519e-02],\n",
      "          [-3.8111e-02, -3.8226e-02,  3.1890e-03]],\n",
      "\n",
      "         [[-1.4202e-02, -3.2279e-02, -4.5909e-02],\n",
      "          [ 2.4311e-02, -3.7335e-02,  2.4191e-02],\n",
      "          [ 4.6568e-02,  7.7419e-03, -9.2568e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.1711e-02,  2.5136e-02, -3.0610e-02],\n",
      "          [ 3.6599e-02, -2.7489e-02,  7.3697e-03],\n",
      "          [ 3.6697e-02,  9.7347e-03, -3.5470e-02]],\n",
      "\n",
      "         [[-8.5858e-03,  3.5691e-02,  2.2073e-02],\n",
      "          [ 4.7062e-02,  1.8284e-02, -3.5284e-02],\n",
      "          [-6.6562e-03,  1.5741e-03,  2.2441e-02]],\n",
      "\n",
      "         [[ 1.9995e-02,  8.3330e-04,  4.3079e-02],\n",
      "          [-4.7420e-02, -1.8382e-02,  3.5182e-02],\n",
      "          [ 3.4943e-02,  3.8123e-03, -4.7495e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4158e-02, -2.2384e-02,  3.9159e-02],\n",
      "          [ 1.7283e-02, -3.8892e-02,  3.9017e-02],\n",
      "          [ 4.7803e-02, -3.5291e-02,  3.3698e-03]],\n",
      "\n",
      "         [[ 7.8959e-03, -3.7386e-02,  3.6343e-02],\n",
      "          [-4.1847e-02, -3.9158e-03, -4.5017e-02],\n",
      "          [ 2.7214e-02,  5.0019e-02, -1.2480e-02]],\n",
      "\n",
      "         [[ 2.9865e-03,  3.0474e-02,  1.1112e-02],\n",
      "          [-2.6460e-02, -4.8873e-02, -2.6558e-02],\n",
      "          [ 1.7385e-02,  3.4615e-02,  8.1902e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.8083e-02, -3.5107e-02, -4.9861e-02],\n",
      "          [ 4.8049e-02, -1.8558e-02, -4.9739e-02],\n",
      "          [-1.2642e-02, -5.1200e-03, -2.8944e-02]],\n",
      "\n",
      "         [[ 2.4737e-02,  2.4013e-02,  2.2619e-02],\n",
      "          [-2.8723e-02, -4.0339e-02,  2.7349e-02],\n",
      "          [ 1.4712e-02, -3.2105e-02,  3.7561e-02]],\n",
      "\n",
      "         [[-4.7127e-02, -3.8954e-02, -3.1313e-02],\n",
      "          [-2.0253e-02,  2.5391e-02,  4.8432e-02],\n",
      "          [ 4.4204e-02, -2.9596e-02, -4.0893e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0485e-02, -4.4909e-02,  9.5284e-03],\n",
      "          [ 3.1092e-05,  2.9059e-02,  4.7547e-02],\n",
      "          [-3.0723e-03, -3.9733e-02, -8.0967e-03]],\n",
      "\n",
      "         [[-1.3113e-02, -4.4654e-02,  1.4122e-02],\n",
      "          [-2.3500e-02, -4.5732e-02,  2.4346e-05],\n",
      "          [ 2.5746e-02,  3.3939e-02,  2.9948e-02]],\n",
      "\n",
      "         [[-1.2745e-02, -3.3739e-02,  3.7723e-02],\n",
      "          [ 2.0818e-02,  2.3328e-02, -4.4016e-03],\n",
      "          [ 3.6613e-02, -1.1867e-02,  2.2514e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7426e-03, -9.8005e-04, -4.0316e-02],\n",
      "          [ 3.0031e-02, -4.1844e-02, -3.7724e-03],\n",
      "          [-3.9181e-02, -9.5570e-03,  2.1002e-02]],\n",
      "\n",
      "         [[ 3.3859e-02, -4.2381e-02, -2.8407e-02],\n",
      "          [-8.3568e-03,  1.1453e-02,  4.1071e-02],\n",
      "          [-4.1884e-02, -1.2362e-03,  2.9103e-02]],\n",
      "\n",
      "         [[ 3.2473e-03, -4.2008e-02,  4.2975e-02],\n",
      "          [-1.7816e-02, -4.8001e-02,  2.2379e-02],\n",
      "          [-3.7249e-02, -1.3183e-02, -2.1801e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9160e-02,  4.3843e-02,  2.4129e-02],\n",
      "          [-4.0716e-02,  7.2773e-03, -3.6532e-04],\n",
      "          [-3.3115e-02, -1.8322e-02,  2.5207e-02]],\n",
      "\n",
      "         [[ 4.6560e-03, -4.7022e-02,  3.5568e-02],\n",
      "          [-3.3973e-02,  1.1137e-02, -4.6558e-02],\n",
      "          [ 4.8246e-02,  2.4377e-02,  3.9868e-02]],\n",
      "\n",
      "         [[-3.6559e-02, -3.0106e-02, -3.4754e-02],\n",
      "          [ 1.9192e-02,  4.5740e-02,  3.2091e-02],\n",
      "          [ 3.4426e-02, -5.0825e-02, -1.1221e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2177e-02,  3.5402e-02, -3.2185e-02],\n",
      "          [ 2.6396e-02,  6.8419e-03,  5.0738e-02],\n",
      "          [-2.5527e-02,  1.9644e-03,  3.5774e-02]],\n",
      "\n",
      "         [[ 4.7345e-02, -1.7943e-02, -4.9361e-02],\n",
      "          [ 4.5747e-02, -1.4473e-02, -3.5912e-02],\n",
      "          [-5.0740e-02,  1.3891e-02, -2.5768e-02]],\n",
      "\n",
      "         [[-3.1244e-02,  6.5432e-03, -1.8054e-02],\n",
      "          [ 2.3247e-02,  2.7761e-02,  4.3669e-02],\n",
      "          [ 1.7650e-02, -5.4675e-03,  2.8034e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.5663e-02, -2.1108e-02,  4.9276e-02],\n",
      "          [ 3.2243e-02,  6.2304e-03,  1.8938e-02],\n",
      "          [ 3.3840e-02,  3.3271e-02, -4.5935e-02]],\n",
      "\n",
      "         [[-1.3486e-03,  4.7185e-03, -3.3253e-02],\n",
      "          [ 3.8523e-03, -5.0238e-02, -4.3335e-02],\n",
      "          [-2.6660e-02, -1.9240e-02,  2.1668e-02]],\n",
      "\n",
      "         [[ 2.8395e-02,  2.6108e-04, -1.4660e-03],\n",
      "          [ 3.7892e-02,  8.8507e-03,  3.4766e-02],\n",
      "          [ 6.2196e-03, -1.1132e-02, -4.0075e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0598]],\n",
      "\n",
      "         [[ 0.0087]],\n",
      "\n",
      "         [[ 0.0547]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0101]],\n",
      "\n",
      "         [[ 0.0092]],\n",
      "\n",
      "         [[-0.0132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0111]],\n",
      "\n",
      "         [[-0.0485]],\n",
      "\n",
      "         [[ 0.0244]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0180]],\n",
      "\n",
      "         [[-0.0374]],\n",
      "\n",
      "         [[ 0.0333]]],\n",
      "\n",
      "\n",
      "        [[[-0.0513]],\n",
      "\n",
      "         [[-0.0968]],\n",
      "\n",
      "         [[-0.0877]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0604]],\n",
      "\n",
      "         [[-0.0437]],\n",
      "\n",
      "         [[ 0.0780]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0891]],\n",
      "\n",
      "         [[ 0.0276]],\n",
      "\n",
      "         [[-0.0697]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0551]],\n",
      "\n",
      "         [[-0.0426]],\n",
      "\n",
      "         [[-0.0915]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0499]],\n",
      "\n",
      "         [[ 0.0027]],\n",
      "\n",
      "         [[-0.0909]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0542]],\n",
      "\n",
      "         [[ 0.0104]],\n",
      "\n",
      "         [[-0.0287]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0078]],\n",
      "\n",
      "         [[-0.0121]],\n",
      "\n",
      "         [[-0.0880]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0551]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[ 0.0099]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0891]],\n",
      "\n",
      "         [[-0.0595]],\n",
      "\n",
      "         [[ 0.0637]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0874]],\n",
      "\n",
      "         [[-0.0277]],\n",
      "\n",
      "         [[ 0.0743]]],\n",
      "\n",
      "\n",
      "        [[[-0.0220]],\n",
      "\n",
      "         [[-0.0730]],\n",
      "\n",
      "         [[-0.0404]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0033]],\n",
      "\n",
      "         [[-0.0938]],\n",
      "\n",
      "         [[-0.0398]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0851]],\n",
      "\n",
      "         [[-0.0421]],\n",
      "\n",
      "         [[ 0.0403]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0953]],\n",
      "\n",
      "         [[-0.0614]],\n",
      "\n",
      "         [[-0.0121]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0070]],\n",
      "\n",
      "         [[-0.0940]],\n",
      "\n",
      "         [[ 0.0202]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0475]],\n",
      "\n",
      "         [[ 0.0867]],\n",
      "\n",
      "         [[-0.0010]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0058]],\n",
      "\n",
      "         [[ 0.0965]],\n",
      "\n",
      "         [[ 0.0181]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[-0.0837]],\n",
      "\n",
      "         [[-0.0387]]],\n",
      "\n",
      "\n",
      "        [[[-0.0051]],\n",
      "\n",
      "         [[ 0.0749]],\n",
      "\n",
      "         [[ 0.0507]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0226]],\n",
      "\n",
      "         [[-0.0636]],\n",
      "\n",
      "         [[-0.0552]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0045, -0.0444, -0.0292],\n",
      "          [ 0.0328,  0.0368, -0.0297],\n",
      "          [ 0.0205,  0.0276,  0.0428]],\n",
      "\n",
      "         [[-0.0035, -0.0322, -0.0102],\n",
      "          [ 0.0247,  0.0200,  0.0265],\n",
      "          [-0.0266, -0.0023,  0.0109]],\n",
      "\n",
      "         [[-0.0461, -0.0270,  0.0328],\n",
      "          [-0.0191, -0.0023, -0.0224],\n",
      "          [ 0.0320, -0.0047, -0.0309]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0402, -0.0430, -0.0469],\n",
      "          [ 0.0505, -0.0420,  0.0411],\n",
      "          [-0.0282, -0.0164, -0.0110]],\n",
      "\n",
      "         [[-0.0476,  0.0117, -0.0056],\n",
      "          [ 0.0205,  0.0017,  0.0382],\n",
      "          [ 0.0275, -0.0310, -0.0398]],\n",
      "\n",
      "         [[-0.0370,  0.0411,  0.0319],\n",
      "          [-0.0333,  0.0459,  0.0311],\n",
      "          [-0.0159,  0.0374,  0.0499]]],\n",
      "\n",
      "\n",
      "        [[[-0.0389, -0.0289, -0.0352],\n",
      "          [-0.0047, -0.0007,  0.0345],\n",
      "          [-0.0173,  0.0307, -0.0320]],\n",
      "\n",
      "         [[ 0.0228, -0.0087, -0.0016],\n",
      "          [-0.0334,  0.0337,  0.0177],\n",
      "          [-0.0064, -0.0263, -0.0155]],\n",
      "\n",
      "         [[-0.0122,  0.0106, -0.0168],\n",
      "          [-0.0219,  0.0082,  0.0354],\n",
      "          [ 0.0435,  0.0441, -0.0268]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0173, -0.0107, -0.0026],\n",
      "          [-0.0436, -0.0216, -0.0039],\n",
      "          [-0.0493,  0.0435,  0.0156]],\n",
      "\n",
      "         [[ 0.0099, -0.0353, -0.0422],\n",
      "          [ 0.0327,  0.0137,  0.0447],\n",
      "          [-0.0248, -0.0261, -0.0369]],\n",
      "\n",
      "         [[ 0.0206,  0.0024, -0.0350],\n",
      "          [ 0.0401,  0.0102,  0.0294],\n",
      "          [-0.0198,  0.0005, -0.0054]]],\n",
      "\n",
      "\n",
      "        [[[-0.0419, -0.0497, -0.0302],\n",
      "          [-0.0410, -0.0104, -0.0156],\n",
      "          [-0.0456,  0.0120,  0.0259]],\n",
      "\n",
      "         [[-0.0278,  0.0189,  0.0141],\n",
      "          [-0.0014,  0.0465, -0.0339],\n",
      "          [ 0.0106,  0.0107, -0.0360]],\n",
      "\n",
      "         [[-0.0021,  0.0198,  0.0332],\n",
      "          [ 0.0390,  0.0381,  0.0070],\n",
      "          [ 0.0070, -0.0500, -0.0029]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0259,  0.0479, -0.0293],\n",
      "          [-0.0228, -0.0076, -0.0027],\n",
      "          [ 0.0003, -0.0166,  0.0342]],\n",
      "\n",
      "         [[ 0.0394, -0.0363,  0.0256],\n",
      "          [ 0.0489, -0.0399, -0.0458],\n",
      "          [-0.0380, -0.0473, -0.0212]],\n",
      "\n",
      "         [[ 0.0387,  0.0273,  0.0169],\n",
      "          [ 0.0442,  0.0402,  0.0505],\n",
      "          [ 0.0393,  0.0057,  0.0248]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0266,  0.0500, -0.0345],\n",
      "          [-0.0009, -0.0459,  0.0429],\n",
      "          [-0.0472, -0.0209,  0.0441]],\n",
      "\n",
      "         [[ 0.0141, -0.0414,  0.0510],\n",
      "          [ 0.0492, -0.0017,  0.0479],\n",
      "          [ 0.0354, -0.0131,  0.0086]],\n",
      "\n",
      "         [[-0.0244,  0.0480, -0.0287],\n",
      "          [-0.0186,  0.0216, -0.0032],\n",
      "          [-0.0034, -0.0440,  0.0319]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0251,  0.0459,  0.0046],\n",
      "          [-0.0510, -0.0002, -0.0174],\n",
      "          [-0.0413,  0.0429,  0.0157]],\n",
      "\n",
      "         [[ 0.0385,  0.0309, -0.0422],\n",
      "          [-0.0364,  0.0069,  0.0347],\n",
      "          [-0.0290, -0.0353,  0.0214]],\n",
      "\n",
      "         [[-0.0044,  0.0053, -0.0344],\n",
      "          [ 0.0160,  0.0235, -0.0314],\n",
      "          [ 0.0093,  0.0263, -0.0122]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0370, -0.0430, -0.0104],\n",
      "          [-0.0424, -0.0007,  0.0338],\n",
      "          [-0.0313,  0.0195,  0.0062]],\n",
      "\n",
      "         [[-0.0273,  0.0437, -0.0107],\n",
      "          [ 0.0117,  0.0128,  0.0190],\n",
      "          [ 0.0310,  0.0089, -0.0137]],\n",
      "\n",
      "         [[ 0.0035, -0.0440, -0.0174],\n",
      "          [ 0.0462,  0.0409,  0.0279],\n",
      "          [-0.0012,  0.0144,  0.0426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0165,  0.0117,  0.0047],\n",
      "          [-0.0160, -0.0176,  0.0199],\n",
      "          [ 0.0286, -0.0481, -0.0467]],\n",
      "\n",
      "         [[-0.0014,  0.0333,  0.0361],\n",
      "          [ 0.0261, -0.0476, -0.0088],\n",
      "          [ 0.0217, -0.0297, -0.0064]],\n",
      "\n",
      "         [[-0.0277,  0.0220,  0.0163],\n",
      "          [ 0.0340, -0.0388,  0.0222],\n",
      "          [-0.0239,  0.0219,  0.0377]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0180, -0.0349,  0.0446],\n",
      "          [ 0.0248,  0.0500, -0.0048],\n",
      "          [ 0.0450, -0.0045, -0.0338]],\n",
      "\n",
      "         [[ 0.0011,  0.0328,  0.0076],\n",
      "          [-0.0082,  0.0037, -0.0040],\n",
      "          [ 0.0140,  0.0199, -0.0320]],\n",
      "\n",
      "         [[ 0.0378,  0.0090, -0.0505],\n",
      "          [-0.0210, -0.0384,  0.0035],\n",
      "          [ 0.0448, -0.0010,  0.0153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0292, -0.0225,  0.0315],\n",
      "          [ 0.0433,  0.0063, -0.0157],\n",
      "          [ 0.0367,  0.0012,  0.0046]],\n",
      "\n",
      "         [[-0.0361, -0.0292,  0.0410],\n",
      "          [-0.0474, -0.0016,  0.0220],\n",
      "          [-0.0270,  0.0218,  0.0474]],\n",
      "\n",
      "         [[-0.0193,  0.0321, -0.0296],\n",
      "          [-0.0463, -0.0334,  0.0070],\n",
      "          [-0.0117, -0.0056,  0.0118]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0646]],\n",
      "\n",
      "         [[-0.0374]],\n",
      "\n",
      "         [[-0.0874]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0468]],\n",
      "\n",
      "         [[ 0.0172]],\n",
      "\n",
      "         [[-0.0240]]],\n",
      "\n",
      "\n",
      "        [[[-0.0491]],\n",
      "\n",
      "         [[-0.0556]],\n",
      "\n",
      "         [[ 0.0059]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0391]],\n",
      "\n",
      "         [[ 0.0837]],\n",
      "\n",
      "         [[ 0.0238]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0047]],\n",
      "\n",
      "         [[-0.0863]],\n",
      "\n",
      "         [[ 0.0282]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0286]],\n",
      "\n",
      "         [[ 0.0202]],\n",
      "\n",
      "         [[-0.0102]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0887]],\n",
      "\n",
      "         [[-0.0184]],\n",
      "\n",
      "         [[ 0.0809]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0683]],\n",
      "\n",
      "         [[-0.0416]],\n",
      "\n",
      "         [[-0.0084]]],\n",
      "\n",
      "\n",
      "        [[[-0.0471]],\n",
      "\n",
      "         [[-0.0689]],\n",
      "\n",
      "         [[ 0.0456]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0605]],\n",
      "\n",
      "         [[ 0.0799]],\n",
      "\n",
      "         [[-0.0950]]],\n",
      "\n",
      "\n",
      "        [[[-0.0115]],\n",
      "\n",
      "         [[ 0.0103]],\n",
      "\n",
      "         [[ 0.0026]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0847]],\n",
      "\n",
      "         [[-0.0800]],\n",
      "\n",
      "         [[-0.0129]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0506]],\n",
      "\n",
      "         [[ 0.0709]],\n",
      "\n",
      "         [[ 0.0428]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0027]],\n",
      "\n",
      "         [[ 0.0598]],\n",
      "\n",
      "         [[-0.0308]]],\n",
      "\n",
      "\n",
      "        [[[-0.0200]],\n",
      "\n",
      "         [[ 0.0705]],\n",
      "\n",
      "         [[ 0.0280]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0830]],\n",
      "\n",
      "         [[-0.0786]],\n",
      "\n",
      "         [[ 0.0844]]],\n",
      "\n",
      "\n",
      "        [[[-0.0798]],\n",
      "\n",
      "         [[-0.0427]],\n",
      "\n",
      "         [[ 0.0503]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0277]],\n",
      "\n",
      "         [[ 0.0253]],\n",
      "\n",
      "         [[ 0.0701]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0095]],\n",
      "\n",
      "         [[-0.0430]],\n",
      "\n",
      "         [[-0.0721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0557]],\n",
      "\n",
      "         [[-0.0175]],\n",
      "\n",
      "         [[ 0.0028]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0149]],\n",
      "\n",
      "         [[ 0.0340]],\n",
      "\n",
      "         [[-0.0345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0637]],\n",
      "\n",
      "         [[-0.0333]],\n",
      "\n",
      "         [[ 0.0007]]],\n",
      "\n",
      "\n",
      "        [[[-0.0693]],\n",
      "\n",
      "         [[-0.0421]],\n",
      "\n",
      "         [[ 0.0378]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0401]],\n",
      "\n",
      "         [[-0.0603]],\n",
      "\n",
      "         [[ 0.0718]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 9.3295e-03,  2.4703e-02,  1.6544e-02],\n",
      "          [-1.5088e-02, -3.5671e-02, -2.4658e-02],\n",
      "          [ 6.7608e-03, -9.3554e-03, -1.1992e-02]],\n",
      "\n",
      "         [[-3.2987e-02,  2.8239e-02,  3.5807e-02],\n",
      "          [-3.4645e-02,  3.7447e-03, -1.9541e-02],\n",
      "          [-2.0435e-02,  3.4325e-02, -1.2712e-02]],\n",
      "\n",
      "         [[ 1.9251e-02,  1.3014e-02,  1.9754e-02],\n",
      "          [ 5.2274e-03,  3.1696e-02, -3.1382e-02],\n",
      "          [ 2.9047e-02,  3.0941e-02,  9.1919e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2758e-03,  2.8150e-02,  1.7314e-02],\n",
      "          [ 2.6879e-02,  4.3012e-03, -5.0320e-04],\n",
      "          [ 3.2813e-02, -1.6824e-02,  8.7705e-03]],\n",
      "\n",
      "         [[-1.2421e-02,  3.1576e-02, -3.1969e-02],\n",
      "          [-6.4835e-03,  2.1224e-02,  3.5744e-02],\n",
      "          [ 1.9813e-02,  1.1616e-02,  3.9327e-04]],\n",
      "\n",
      "         [[-1.7430e-02,  1.3487e-02, -1.1476e-02],\n",
      "          [ 4.2571e-03,  3.5503e-02,  2.4651e-02],\n",
      "          [ 2.2659e-02, -5.3071e-03,  2.5952e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6013e-03, -1.7950e-02,  3.4107e-02],\n",
      "          [ 3.1544e-02,  1.4952e-02,  1.3227e-02],\n",
      "          [ 2.0420e-02, -2.1302e-02,  2.1456e-02]],\n",
      "\n",
      "         [[-2.0221e-02,  2.4802e-02,  3.0536e-02],\n",
      "          [-1.8431e-02,  2.5993e-02, -2.5737e-02],\n",
      "          [-1.5027e-02, -3.0124e-02, -2.1250e-02]],\n",
      "\n",
      "         [[ 3.5929e-02,  1.4767e-02, -5.9146e-03],\n",
      "          [ 1.8813e-02, -2.3337e-03, -3.1455e-04],\n",
      "          [ 7.7966e-05,  3.4444e-02,  2.6047e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0483e-02, -6.5532e-04, -3.5157e-02],\n",
      "          [ 1.3910e-02,  1.7185e-02,  2.9381e-02],\n",
      "          [ 5.9522e-04, -6.5010e-03,  3.0204e-02]],\n",
      "\n",
      "         [[ 2.4892e-02, -9.2901e-03,  2.8233e-02],\n",
      "          [-2.2836e-02, -3.4672e-02,  1.1563e-02],\n",
      "          [ 2.6715e-02,  2.8317e-02,  3.5424e-02]],\n",
      "\n",
      "         [[-2.7873e-02, -2.5745e-02, -4.6573e-03],\n",
      "          [-3.3240e-02,  1.0987e-02,  6.0512e-03],\n",
      "          [ 7.9107e-03,  1.9632e-02, -2.4016e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.5724e-02, -2.9482e-03,  6.6746e-03],\n",
      "          [ 4.3933e-03,  6.4169e-03, -6.9095e-03],\n",
      "          [ 3.2181e-02,  2.7637e-02,  1.0610e-02]],\n",
      "\n",
      "         [[ 5.8665e-03, -1.1719e-02, -1.3370e-03],\n",
      "          [ 1.6627e-03, -1.6977e-02, -1.4842e-02],\n",
      "          [-8.7264e-04, -1.9284e-02,  1.1158e-02]],\n",
      "\n",
      "         [[-1.0917e-02, -3.5409e-02, -2.5960e-02],\n",
      "          [-1.3770e-02, -3.1280e-03, -2.7009e-02],\n",
      "          [ 3.7716e-03, -1.6191e-02, -3.2799e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4959e-02,  2.6743e-02, -7.4904e-05],\n",
      "          [-1.8677e-02, -3.5065e-02, -2.4662e-02],\n",
      "          [ 2.9792e-02,  2.2667e-02, -2.5527e-02]],\n",
      "\n",
      "         [[-3.5223e-02,  8.4825e-03, -1.7834e-02],\n",
      "          [ 2.5628e-03, -6.9216e-03,  1.1908e-03],\n",
      "          [ 2.4021e-02, -2.4960e-02,  2.7848e-02]],\n",
      "\n",
      "         [[-1.4010e-02, -9.7200e-03,  9.1006e-03],\n",
      "          [-2.8634e-02, -3.5506e-03, -1.5081e-02],\n",
      "          [ 3.5061e-02, -1.1594e-02, -2.7114e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 8.2450e-03, -3.4132e-02,  8.4231e-03],\n",
      "          [ 3.8522e-04, -2.6527e-02,  1.8879e-02],\n",
      "          [ 3.9740e-03,  2.6040e-02, -1.2733e-02]],\n",
      "\n",
      "         [[ 6.5628e-03, -2.2171e-02,  3.4659e-02],\n",
      "          [-1.5747e-02,  1.4415e-02,  3.4789e-02],\n",
      "          [-8.5481e-03,  1.2281e-02, -3.2671e-02]],\n",
      "\n",
      "         [[-1.3947e-02, -5.2777e-03, -3.4863e-02],\n",
      "          [-3.3077e-02,  8.6308e-03,  1.1907e-02],\n",
      "          [-3.4851e-03,  2.2378e-02, -2.0908e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6319e-02, -1.3179e-02,  2.4924e-02],\n",
      "          [-1.4107e-02, -7.6787e-03,  1.3708e-02],\n",
      "          [-4.8813e-03,  1.3153e-02,  3.1641e-03]],\n",
      "\n",
      "         [[ 1.5858e-03, -1.1306e-02, -1.3526e-02],\n",
      "          [ 2.1192e-02, -7.5420e-03,  3.0551e-02],\n",
      "          [ 2.8385e-02,  5.8569e-03, -1.0679e-02]],\n",
      "\n",
      "         [[ 2.5434e-02,  1.2425e-02, -1.9486e-02],\n",
      "          [-1.5043e-02,  2.7997e-03,  2.0136e-02],\n",
      "          [-2.7411e-02,  2.0512e-02,  1.2575e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0749e-02, -1.9860e-02,  2.2931e-02],\n",
      "          [-9.7909e-03, -3.2225e-02, -1.9730e-02],\n",
      "          [ 2.7944e-02,  1.4463e-03, -2.6830e-04]],\n",
      "\n",
      "         [[ 2.6270e-02,  1.2259e-02,  7.9334e-03],\n",
      "          [-3.5881e-02, -8.7999e-03,  6.7675e-03],\n",
      "          [-2.3242e-02, -3.5151e-02, -2.6482e-02]],\n",
      "\n",
      "         [[ 5.6410e-03,  2.8745e-02,  1.6294e-02],\n",
      "          [-1.3430e-02,  3.5063e-02, -1.5810e-02],\n",
      "          [-3.0567e-02,  2.7046e-02,  5.3173e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7922e-02,  1.0367e-02, -3.3689e-03],\n",
      "          [-2.2953e-02,  3.3783e-02, -3.5093e-02],\n",
      "          [-2.1433e-02, -7.1024e-03, -1.9155e-02]],\n",
      "\n",
      "         [[-2.0182e-02, -3.0984e-02, -2.9748e-02],\n",
      "          [ 3.5156e-02,  2.8873e-02,  3.3751e-02],\n",
      "          [ 2.2185e-02,  9.2265e-03, -3.9699e-03]],\n",
      "\n",
      "         [[ 1.8031e-02,  1.5028e-02, -2.1948e-02],\n",
      "          [ 2.4501e-02,  2.7744e-02, -2.0907e-02],\n",
      "          [ 3.3296e-02,  2.6317e-02, -1.7190e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4016e-02,  2.6393e-02,  2.5775e-02],\n",
      "          [ 5.6377e-03,  3.1445e-02,  7.0939e-03],\n",
      "          [-1.2055e-02, -2.6607e-02,  2.0806e-02]],\n",
      "\n",
      "         [[-1.2831e-02,  1.5544e-02, -2.9643e-02],\n",
      "          [-3.4516e-02, -1.0782e-02, -3.1462e-02],\n",
      "          [-1.2443e-02, -3.5716e-02,  1.7521e-02]],\n",
      "\n",
      "         [[-1.3211e-02, -2.0944e-02,  2.3319e-02],\n",
      "          [ 3.5433e-02,  4.8533e-03, -1.1164e-02],\n",
      "          [-2.5298e-02, -3.3049e-02, -8.5664e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0005e-02, -3.1344e-02, -2.9328e-02],\n",
      "          [-2.8781e-02,  3.1001e-02, -2.8816e-02],\n",
      "          [ 1.3966e-02, -3.0881e-02,  2.6417e-02]],\n",
      "\n",
      "         [[ 1.9307e-02, -6.9184e-04,  1.5255e-02],\n",
      "          [-2.0627e-02, -2.1686e-03,  2.5354e-02],\n",
      "          [-1.0183e-02,  2.9118e-02, -4.0142e-03]],\n",
      "\n",
      "         [[-1.8670e-02,  3.4727e-02, -1.3126e-02],\n",
      "          [ 9.1248e-03, -2.4312e-02,  6.1124e-04],\n",
      "          [ 2.2325e-02,  1.9466e-03,  3.4437e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0273]],\n",
      "\n",
      "         [[ 0.0061]],\n",
      "\n",
      "         [[ 0.0034]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0220]],\n",
      "\n",
      "         [[-0.0182]],\n",
      "\n",
      "         [[ 0.0136]]],\n",
      "\n",
      "\n",
      "        [[[-0.0413]],\n",
      "\n",
      "         [[-0.0145]],\n",
      "\n",
      "         [[ 0.0271]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0107]],\n",
      "\n",
      "         [[ 0.0307]],\n",
      "\n",
      "         [[-0.0547]]],\n",
      "\n",
      "\n",
      "        [[[-0.0605]],\n",
      "\n",
      "         [[ 0.0281]],\n",
      "\n",
      "         [[-0.0361]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0009]],\n",
      "\n",
      "         [[-0.0460]],\n",
      "\n",
      "         [[-0.0063]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0467]],\n",
      "\n",
      "         [[-0.0586]],\n",
      "\n",
      "         [[-0.0166]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0646]],\n",
      "\n",
      "         [[ 0.0432]],\n",
      "\n",
      "         [[ 0.0597]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0046]],\n",
      "\n",
      "         [[ 0.0429]],\n",
      "\n",
      "         [[ 0.0392]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0159]],\n",
      "\n",
      "         [[ 0.0097]],\n",
      "\n",
      "         [[-0.0243]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0575]],\n",
      "\n",
      "         [[-0.0397]],\n",
      "\n",
      "         [[-0.0467]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0636]],\n",
      "\n",
      "         [[-0.0206]],\n",
      "\n",
      "         [[ 0.0523]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0139]],\n",
      "\n",
      "         [[-0.0545]],\n",
      "\n",
      "         [[ 0.0409]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0067]],\n",
      "\n",
      "         [[ 0.0500]],\n",
      "\n",
      "         [[ 0.0393]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0503]],\n",
      "\n",
      "         [[-0.0513]],\n",
      "\n",
      "         [[ 0.0325]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0299]],\n",
      "\n",
      "         [[-0.0536]],\n",
      "\n",
      "         [[-0.0118]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0580]],\n",
      "\n",
      "         [[ 0.0360]],\n",
      "\n",
      "         [[-0.0166]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0381]],\n",
      "\n",
      "         [[-0.0252]],\n",
      "\n",
      "         [[ 0.0416]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0105]],\n",
      "\n",
      "         [[-0.0020]],\n",
      "\n",
      "         [[-0.0473]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0427]],\n",
      "\n",
      "         [[-0.0154]],\n",
      "\n",
      "         [[-0.0431]]],\n",
      "\n",
      "\n",
      "        [[[-0.0203]],\n",
      "\n",
      "         [[ 0.0623]],\n",
      "\n",
      "         [[-0.0091]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0141]],\n",
      "\n",
      "         [[ 0.0621]],\n",
      "\n",
      "         [[ 0.0315]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0148]],\n",
      "\n",
      "         [[-0.0552]],\n",
      "\n",
      "         [[-0.0535]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0547]],\n",
      "\n",
      "         [[ 0.0131]],\n",
      "\n",
      "         [[ 0.0533]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0333]],\n",
      "\n",
      "         [[-0.0550]],\n",
      "\n",
      "         [[ 0.0264]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0544]],\n",
      "\n",
      "         [[ 0.0257]],\n",
      "\n",
      "         [[ 0.0244]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0248]],\n",
      "\n",
      "         [[-0.0041]],\n",
      "\n",
      "         [[ 0.0027]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0069]],\n",
      "\n",
      "         [[-0.0500]],\n",
      "\n",
      "         [[-0.0114]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0274]],\n",
      "\n",
      "         [[ 0.0666]],\n",
      "\n",
      "         [[-0.0042]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0602]],\n",
      "\n",
      "         [[ 0.0083]],\n",
      "\n",
      "         [[ 0.0095]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0097]],\n",
      "\n",
      "         [[ 0.0252]],\n",
      "\n",
      "         [[-0.0368]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0379]],\n",
      "\n",
      "         [[ 0.0073]],\n",
      "\n",
      "         [[-0.0564]]],\n",
      "\n",
      "\n",
      "        [[[-0.0614]],\n",
      "\n",
      "         [[-0.0316]],\n",
      "\n",
      "         [[ 0.0623]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0060]],\n",
      "\n",
      "         [[-0.0432]],\n",
      "\n",
      "         [[-0.0295]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0344]],\n",
      "\n",
      "         [[-0.0420]],\n",
      "\n",
      "         [[ 0.0594]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0508]],\n",
      "\n",
      "         [[-0.0316]],\n",
      "\n",
      "         [[-0.0603]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0187,  0.0052, -0.0264],\n",
      "          [ 0.0031,  0.0105,  0.0302],\n",
      "          [ 0.0307, -0.0331, -0.0123]],\n",
      "\n",
      "         [[-0.0347, -0.0149,  0.0117],\n",
      "          [ 0.0302,  0.0257, -0.0073],\n",
      "          [ 0.0171, -0.0286, -0.0258]],\n",
      "\n",
      "         [[-0.0352, -0.0210, -0.0124],\n",
      "          [-0.0050,  0.0201,  0.0314],\n",
      "          [ 0.0230, -0.0058, -0.0158]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0032, -0.0102, -0.0053],\n",
      "          [ 0.0346, -0.0010,  0.0239],\n",
      "          [-0.0296, -0.0062, -0.0303]],\n",
      "\n",
      "         [[-0.0095,  0.0355, -0.0267],\n",
      "          [ 0.0227, -0.0187,  0.0121],\n",
      "          [-0.0127, -0.0175,  0.0043]],\n",
      "\n",
      "         [[-0.0166, -0.0223,  0.0014],\n",
      "          [ 0.0348,  0.0074, -0.0142],\n",
      "          [-0.0282,  0.0324,  0.0129]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0243, -0.0030,  0.0160],\n",
      "          [-0.0279, -0.0227,  0.0080],\n",
      "          [-0.0095,  0.0301, -0.0351]],\n",
      "\n",
      "         [[-0.0202, -0.0164,  0.0061],\n",
      "          [ 0.0023, -0.0228, -0.0207],\n",
      "          [-0.0024,  0.0215,  0.0212]],\n",
      "\n",
      "         [[ 0.0138, -0.0359, -0.0277],\n",
      "          [-0.0256,  0.0080, -0.0134],\n",
      "          [-0.0019,  0.0256, -0.0181]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0002,  0.0296, -0.0336],\n",
      "          [-0.0069,  0.0160,  0.0022],\n",
      "          [-0.0011,  0.0037,  0.0153]],\n",
      "\n",
      "         [[-0.0087, -0.0066, -0.0152],\n",
      "          [-0.0049,  0.0255, -0.0085],\n",
      "          [ 0.0131,  0.0038, -0.0089]],\n",
      "\n",
      "         [[-0.0267, -0.0121,  0.0285],\n",
      "          [ 0.0351, -0.0304, -0.0109],\n",
      "          [ 0.0017, -0.0159,  0.0268]]],\n",
      "\n",
      "\n",
      "        [[[-0.0109, -0.0311, -0.0346],\n",
      "          [ 0.0281,  0.0150,  0.0346],\n",
      "          [ 0.0009, -0.0246, -0.0255]],\n",
      "\n",
      "         [[ 0.0135,  0.0307, -0.0142],\n",
      "          [ 0.0277,  0.0207,  0.0033],\n",
      "          [-0.0290, -0.0320,  0.0078]],\n",
      "\n",
      "         [[ 0.0271, -0.0275,  0.0098],\n",
      "          [ 0.0343,  0.0294, -0.0175],\n",
      "          [-0.0087,  0.0317, -0.0331]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0143, -0.0049, -0.0266],\n",
      "          [ 0.0229, -0.0268,  0.0215],\n",
      "          [-0.0225,  0.0305, -0.0055]],\n",
      "\n",
      "         [[ 0.0259, -0.0345,  0.0050],\n",
      "          [-0.0199,  0.0242,  0.0274],\n",
      "          [-0.0345,  0.0061, -0.0302]],\n",
      "\n",
      "         [[-0.0184,  0.0322,  0.0153],\n",
      "          [-0.0124,  0.0162, -0.0220],\n",
      "          [ 0.0315,  0.0114,  0.0101]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0178,  0.0267,  0.0353],\n",
      "          [-0.0090, -0.0111, -0.0357],\n",
      "          [ 0.0182,  0.0103, -0.0155]],\n",
      "\n",
      "         [[ 0.0157,  0.0266, -0.0320],\n",
      "          [-0.0207,  0.0240,  0.0170],\n",
      "          [ 0.0338, -0.0336,  0.0323]],\n",
      "\n",
      "         [[ 0.0021,  0.0116,  0.0276],\n",
      "          [ 0.0227,  0.0123, -0.0190],\n",
      "          [-0.0050,  0.0054, -0.0164]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0142,  0.0235,  0.0078],\n",
      "          [ 0.0260,  0.0303,  0.0287],\n",
      "          [ 0.0213, -0.0163,  0.0328]],\n",
      "\n",
      "         [[ 0.0145,  0.0356, -0.0124],\n",
      "          [-0.0327, -0.0360,  0.0002],\n",
      "          [-0.0336, -0.0240,  0.0055]],\n",
      "\n",
      "         [[ 0.0205,  0.0121,  0.0249],\n",
      "          [ 0.0111,  0.0342,  0.0301],\n",
      "          [-0.0183,  0.0084, -0.0067]]],\n",
      "\n",
      "\n",
      "        [[[-0.0002, -0.0032, -0.0117],\n",
      "          [-0.0278,  0.0309, -0.0329],\n",
      "          [-0.0306, -0.0167, -0.0331]],\n",
      "\n",
      "         [[-0.0231, -0.0144,  0.0259],\n",
      "          [-0.0294,  0.0256,  0.0316],\n",
      "          [ 0.0232,  0.0179,  0.0222]],\n",
      "\n",
      "         [[-0.0122,  0.0026, -0.0343],\n",
      "          [-0.0061, -0.0200,  0.0142],\n",
      "          [ 0.0222, -0.0071, -0.0085]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0102,  0.0053, -0.0067],\n",
      "          [ 0.0359,  0.0078,  0.0255],\n",
      "          [-0.0202,  0.0296, -0.0306]],\n",
      "\n",
      "         [[ 0.0326, -0.0114,  0.0199],\n",
      "          [-0.0148,  0.0195,  0.0176],\n",
      "          [ 0.0266,  0.0080,  0.0356]],\n",
      "\n",
      "         [[-0.0222, -0.0120, -0.0179],\n",
      "          [-0.0156,  0.0327, -0.0250],\n",
      "          [-0.0039,  0.0340, -0.0012]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0081, -0.0259,  0.0110],\n",
      "          [ 0.0016, -0.0172,  0.0114],\n",
      "          [ 0.0332, -0.0354, -0.0091]],\n",
      "\n",
      "         [[-0.0333,  0.0262, -0.0108],\n",
      "          [ 0.0076, -0.0109,  0.0301],\n",
      "          [ 0.0102,  0.0206,  0.0178]],\n",
      "\n",
      "         [[-0.0269,  0.0039, -0.0306],\n",
      "          [ 0.0050, -0.0002, -0.0261],\n",
      "          [ 0.0354, -0.0266,  0.0208]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0300, -0.0355,  0.0271],\n",
      "          [ 0.0182,  0.0206, -0.0288],\n",
      "          [-0.0130,  0.0172, -0.0179]],\n",
      "\n",
      "         [[ 0.0172, -0.0090,  0.0155],\n",
      "          [-0.0291, -0.0281,  0.0098],\n",
      "          [ 0.0342, -0.0313, -0.0342]],\n",
      "\n",
      "         [[ 0.0014,  0.0076, -0.0045],\n",
      "          [-0.0256, -0.0267,  0.0047],\n",
      "          [ 0.0211, -0.0335,  0.0296]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0444]],\n",
      "\n",
      "         [[-0.0261]],\n",
      "\n",
      "         [[ 0.0468]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0002]],\n",
      "\n",
      "         [[ 0.0352]],\n",
      "\n",
      "         [[-0.0114]]],\n",
      "\n",
      "\n",
      "        [[[-0.0593]],\n",
      "\n",
      "         [[ 0.0295]],\n",
      "\n",
      "         [[ 0.0298]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0202]],\n",
      "\n",
      "         [[-0.0325]],\n",
      "\n",
      "         [[-0.0630]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0560]],\n",
      "\n",
      "         [[-0.0446]],\n",
      "\n",
      "         [[ 0.0110]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0025]],\n",
      "\n",
      "         [[ 0.0558]],\n",
      "\n",
      "         [[ 0.0509]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0043]],\n",
      "\n",
      "         [[-0.0468]],\n",
      "\n",
      "         [[ 0.0436]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0249]],\n",
      "\n",
      "         [[-0.0175]],\n",
      "\n",
      "         [[ 0.0620]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0149]],\n",
      "\n",
      "         [[ 0.0461]],\n",
      "\n",
      "         [[-0.0403]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         [[-0.0682]],\n",
      "\n",
      "         [[-0.0298]]],\n",
      "\n",
      "\n",
      "        [[[-0.0038]],\n",
      "\n",
      "         [[ 0.0423]],\n",
      "\n",
      "         [[-0.0490]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0133]],\n",
      "\n",
      "         [[ 0.0060]],\n",
      "\n",
      "         [[ 0.0249]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0333]],\n",
      "\n",
      "         [[-0.0090]],\n",
      "\n",
      "         [[-0.0528]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0676]],\n",
      "\n",
      "         [[ 0.0605]],\n",
      "\n",
      "         [[-0.0672]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0201]],\n",
      "\n",
      "         [[-0.0514]],\n",
      "\n",
      "         [[ 0.0034]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0242]],\n",
      "\n",
      "         [[-0.0303]],\n",
      "\n",
      "         [[-0.0120]]],\n",
      "\n",
      "\n",
      "        [[[-0.0260]],\n",
      "\n",
      "         [[-0.0218]],\n",
      "\n",
      "         [[ 0.0255]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0404]],\n",
      "\n",
      "         [[-0.0665]],\n",
      "\n",
      "         [[ 0.0009]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0467]],\n",
      "\n",
      "         [[ 0.0478]],\n",
      "\n",
      "         [[ 0.0045]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0145]],\n",
      "\n",
      "         [[-0.0210]],\n",
      "\n",
      "         [[ 0.0678]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0267]],\n",
      "\n",
      "         [[-0.0505]],\n",
      "\n",
      "         [[-0.0571]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0133]],\n",
      "\n",
      "         [[-0.0514]],\n",
      "\n",
      "         [[-0.0106]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0392]],\n",
      "\n",
      "         [[ 0.0058]],\n",
      "\n",
      "         [[ 0.0186]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0158]],\n",
      "\n",
      "         [[-0.0095]],\n",
      "\n",
      "         [[ 0.0075]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0336, -0.0268, -0.0259],\n",
      "          [ 0.0300, -0.0008,  0.0244],\n",
      "          [ 0.0096, -0.0274,  0.0107]],\n",
      "\n",
      "         [[-0.0144, -0.0032, -0.0333],\n",
      "          [ 0.0361, -0.0244,  0.0289],\n",
      "          [-0.0285,  0.0218,  0.0211]],\n",
      "\n",
      "         [[ 0.0114, -0.0124,  0.0090],\n",
      "          [ 0.0128, -0.0195,  0.0057],\n",
      "          [-0.0262, -0.0263,  0.0113]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0091,  0.0298, -0.0208],\n",
      "          [ 0.0306,  0.0119,  0.0222],\n",
      "          [-0.0197,  0.0037, -0.0281]],\n",
      "\n",
      "         [[-0.0262,  0.0294,  0.0093],\n",
      "          [-0.0120, -0.0233,  0.0037],\n",
      "          [ 0.0197, -0.0249, -0.0191]],\n",
      "\n",
      "         [[ 0.0210,  0.0258, -0.0076],\n",
      "          [-0.0125, -0.0306,  0.0303],\n",
      "          [ 0.0280,  0.0323, -0.0179]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0036,  0.0146, -0.0269],\n",
      "          [-0.0162,  0.0218,  0.0110],\n",
      "          [ 0.0197, -0.0207,  0.0245]],\n",
      "\n",
      "         [[ 0.0243,  0.0245,  0.0072],\n",
      "          [-0.0185, -0.0292,  0.0273],\n",
      "          [-0.0165, -0.0248, -0.0116]],\n",
      "\n",
      "         [[ 0.0317,  0.0038, -0.0264],\n",
      "          [-0.0134, -0.0296, -0.0099],\n",
      "          [ 0.0059, -0.0238,  0.0172]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0350, -0.0292, -0.0215],\n",
      "          [ 0.0288, -0.0176,  0.0307],\n",
      "          [-0.0100,  0.0233, -0.0005]],\n",
      "\n",
      "         [[ 0.0111, -0.0307,  0.0196],\n",
      "          [ 0.0248,  0.0223,  0.0217],\n",
      "          [-0.0187, -0.0179, -0.0092]],\n",
      "\n",
      "         [[ 0.0221, -0.0298,  0.0070],\n",
      "          [-0.0010, -0.0088,  0.0114],\n",
      "          [-0.0048, -0.0010,  0.0204]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0248, -0.0113, -0.0234],\n",
      "          [-0.0001, -0.0144, -0.0265],\n",
      "          [ 0.0311,  0.0077, -0.0098]],\n",
      "\n",
      "         [[ 0.0213,  0.0124, -0.0201],\n",
      "          [-0.0108,  0.0064, -0.0264],\n",
      "          [ 0.0264, -0.0335,  0.0138]],\n",
      "\n",
      "         [[ 0.0317,  0.0250, -0.0065],\n",
      "          [ 0.0224, -0.0029, -0.0033],\n",
      "          [ 0.0234,  0.0182,  0.0003]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0278,  0.0135,  0.0263],\n",
      "          [-0.0357,  0.0100, -0.0155],\n",
      "          [-0.0030, -0.0305,  0.0020]],\n",
      "\n",
      "         [[ 0.0309, -0.0011, -0.0144],\n",
      "          [ 0.0244,  0.0174,  0.0083],\n",
      "          [-0.0141,  0.0089,  0.0167]],\n",
      "\n",
      "         [[-0.0068, -0.0279,  0.0039],\n",
      "          [ 0.0187, -0.0191,  0.0227],\n",
      "          [-0.0314,  0.0094,  0.0227]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0122, -0.0336,  0.0282],\n",
      "          [-0.0173, -0.0022, -0.0089],\n",
      "          [ 0.0064, -0.0309,  0.0124]],\n",
      "\n",
      "         [[-0.0050,  0.0280,  0.0131],\n",
      "          [ 0.0106,  0.0031,  0.0155],\n",
      "          [-0.0216, -0.0339, -0.0264]],\n",
      "\n",
      "         [[ 0.0184, -0.0226, -0.0192],\n",
      "          [-0.0143, -0.0209, -0.0333],\n",
      "          [ 0.0281,  0.0036,  0.0069]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0298, -0.0258,  0.0010],\n",
      "          [ 0.0117,  0.0196, -0.0032],\n",
      "          [ 0.0052,  0.0154, -0.0116]],\n",
      "\n",
      "         [[-0.0334, -0.0056, -0.0206],\n",
      "          [-0.0079, -0.0220,  0.0181],\n",
      "          [ 0.0221,  0.0021, -0.0335]],\n",
      "\n",
      "         [[ 0.0296, -0.0279, -0.0108],\n",
      "          [-0.0353, -0.0232, -0.0221],\n",
      "          [ 0.0128, -0.0283,  0.0202]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0134,  0.0188,  0.0027],\n",
      "          [ 0.0358,  0.0055, -0.0082],\n",
      "          [-0.0309,  0.0159, -0.0080]],\n",
      "\n",
      "         [[ 0.0038,  0.0146,  0.0179],\n",
      "          [-0.0066,  0.0279, -0.0351],\n",
      "          [ 0.0031, -0.0260, -0.0136]],\n",
      "\n",
      "         [[-0.0131,  0.0219, -0.0300],\n",
      "          [-0.0083, -0.0192, -0.0281],\n",
      "          [ 0.0177,  0.0279,  0.0012]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0127, -0.0143, -0.0033],\n",
      "          [-0.0196, -0.0222,  0.0254],\n",
      "          [-0.0013,  0.0224, -0.0282]],\n",
      "\n",
      "         [[-0.0304,  0.0157,  0.0267],\n",
      "          [ 0.0353,  0.0108, -0.0135],\n",
      "          [-0.0181,  0.0198,  0.0301]],\n",
      "\n",
      "         [[ 0.0057, -0.0070, -0.0060],\n",
      "          [ 0.0045, -0.0057,  0.0214],\n",
      "          [ 0.0283, -0.0185,  0.0021]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0279, -0.0261,  0.0011],\n",
      "          [ 0.0017,  0.0042, -0.0272],\n",
      "          [ 0.0096, -0.0252,  0.0352]],\n",
      "\n",
      "         [[-0.0206, -0.0161,  0.0058],\n",
      "          [ 0.0201,  0.0121,  0.0107],\n",
      "          [ 0.0342, -0.0215,  0.0080]],\n",
      "\n",
      "         [[-0.0161, -0.0202,  0.0147],\n",
      "          [ 0.0181,  0.0024,  0.0074],\n",
      "          [ 0.0351,  0.0168,  0.0179]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0346, -0.0096, -0.0329],\n",
      "          [ 0.0101, -0.0035, -0.0241],\n",
      "          [-0.0291,  0.0273,  0.0250]],\n",
      "\n",
      "         [[ 0.0166,  0.0195, -0.0183],\n",
      "          [-0.0081,  0.0274, -0.0258],\n",
      "          [ 0.0129, -0.0260, -0.0059]],\n",
      "\n",
      "         [[-0.0094, -0.0028, -0.0178],\n",
      "          [ 0.0352,  0.0037,  0.0248],\n",
      "          [ 0.0282, -0.0112, -0.0110]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0330]],\n",
      "\n",
      "         [[-0.0672]],\n",
      "\n",
      "         [[ 0.0586]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0493]],\n",
      "\n",
      "         [[-0.0151]],\n",
      "\n",
      "         [[ 0.0172]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0592]],\n",
      "\n",
      "         [[-0.0561]],\n",
      "\n",
      "         [[-0.0110]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0207]],\n",
      "\n",
      "         [[-0.0401]],\n",
      "\n",
      "         [[ 0.0132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0601]],\n",
      "\n",
      "         [[ 0.0043]],\n",
      "\n",
      "         [[ 0.0647]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0422]],\n",
      "\n",
      "         [[ 0.0578]],\n",
      "\n",
      "         [[-0.0612]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0038]],\n",
      "\n",
      "         [[ 0.0485]],\n",
      "\n",
      "         [[-0.0293]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0681]],\n",
      "\n",
      "         [[ 0.0401]],\n",
      "\n",
      "         [[ 0.0333]]],\n",
      "\n",
      "\n",
      "        [[[-0.0586]],\n",
      "\n",
      "         [[ 0.0029]],\n",
      "\n",
      "         [[ 0.0601]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0342]],\n",
      "\n",
      "         [[-0.0021]],\n",
      "\n",
      "         [[ 0.0630]]],\n",
      "\n",
      "\n",
      "        [[[-0.0161]],\n",
      "\n",
      "         [[-0.0562]],\n",
      "\n",
      "         [[-0.0414]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0456]],\n",
      "\n",
      "         [[ 0.0036]],\n",
      "\n",
      "         [[-0.0523]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0010]],\n",
      "\n",
      "         [[ 0.0395]],\n",
      "\n",
      "         [[-0.0040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0270]],\n",
      "\n",
      "         [[ 0.0321]],\n",
      "\n",
      "         [[-0.0528]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0336]],\n",
      "\n",
      "         [[ 0.0118]],\n",
      "\n",
      "         [[-0.0460]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0306]],\n",
      "\n",
      "         [[-0.0597]],\n",
      "\n",
      "         [[ 0.0160]]],\n",
      "\n",
      "\n",
      "        [[[-0.0441]],\n",
      "\n",
      "         [[-0.0504]],\n",
      "\n",
      "         [[ 0.0390]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[-0.0465]],\n",
      "\n",
      "         [[-0.0410]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0061]],\n",
      "\n",
      "         [[ 0.0087]],\n",
      "\n",
      "         [[-0.0487]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0279]],\n",
      "\n",
      "         [[-0.0250]],\n",
      "\n",
      "         [[ 0.0671]]],\n",
      "\n",
      "\n",
      "        [[[-0.0327]],\n",
      "\n",
      "         [[-0.0556]],\n",
      "\n",
      "         [[-0.0146]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0177]],\n",
      "\n",
      "         [[-0.0163]],\n",
      "\n",
      "         [[-0.0197]]],\n",
      "\n",
      "\n",
      "        [[[-0.0196]],\n",
      "\n",
      "         [[ 0.0218]],\n",
      "\n",
      "         [[-0.0426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0228]],\n",
      "\n",
      "         [[ 0.0354]],\n",
      "\n",
      "         [[-0.0442]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-9.2543e-03, -6.7663e-03,  1.9330e-02],\n",
      "          [-2.3350e-02, -2.5822e-02,  1.4480e-02],\n",
      "          [-2.4212e-02,  3.4244e-02,  3.4262e-02]],\n",
      "\n",
      "         [[ 1.3895e-02, -1.5936e-02, -3.3491e-02],\n",
      "          [ 1.2580e-02, -1.6369e-02,  5.6938e-04],\n",
      "          [ 1.3668e-02, -1.4357e-02,  3.3011e-03]],\n",
      "\n",
      "         [[-2.0693e-02, -1.1783e-02, -1.9767e-02],\n",
      "          [-2.4416e-03,  2.2312e-02,  1.1594e-02],\n",
      "          [-2.4614e-02, -1.9153e-03,  1.8488e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6211e-02, -2.9753e-02,  5.9454e-04],\n",
      "          [ 8.4726e-03, -3.5393e-02,  1.3606e-02],\n",
      "          [ 1.4572e-03,  3.5774e-02,  3.9358e-03]],\n",
      "\n",
      "         [[ 2.8941e-02, -3.0547e-02, -3.0982e-02],\n",
      "          [ 3.0880e-02, -3.3403e-02, -1.4864e-02],\n",
      "          [ 2.1001e-02,  2.6575e-02,  2.9449e-02]],\n",
      "\n",
      "         [[ 9.8538e-03, -2.6131e-02, -3.4458e-02],\n",
      "          [ 2.5325e-02,  1.0411e-02,  1.5796e-02],\n",
      "          [ 1.9748e-03,  3.9800e-03, -2.8419e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5410e-02,  3.3096e-02, -2.4703e-04],\n",
      "          [-1.9487e-02, -2.3770e-02,  2.9741e-02],\n",
      "          [-7.4059e-03, -1.1895e-02,  5.9649e-03]],\n",
      "\n",
      "         [[ 2.3676e-02, -1.2918e-02, -1.4532e-02],\n",
      "          [ 8.4462e-03,  1.7935e-02, -2.4899e-02],\n",
      "          [ 2.2885e-03, -2.8262e-03, -5.1141e-03]],\n",
      "\n",
      "         [[ 3.4453e-02, -1.6059e-02,  3.2137e-02],\n",
      "          [ 2.6652e-03, -2.6889e-02, -2.9630e-02],\n",
      "          [ 2.1722e-02,  2.8167e-02,  3.6758e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0187e-02,  3.2496e-03, -1.7972e-04],\n",
      "          [-3.2225e-03, -2.6169e-02, -3.7945e-03],\n",
      "          [ 2.9865e-02, -2.5650e-02,  4.2035e-03]],\n",
      "\n",
      "         [[-8.1575e-03, -2.1473e-03, -2.1710e-02],\n",
      "          [-3.4483e-02, -8.9817e-04, -7.1026e-03],\n",
      "          [-6.1457e-03,  1.0761e-02, -2.2104e-02]],\n",
      "\n",
      "         [[-3.0250e-02,  2.5263e-02, -2.6558e-03],\n",
      "          [-2.1040e-02, -9.9745e-03, -1.3688e-02],\n",
      "          [-2.7630e-02,  2.3812e-02, -5.0462e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9603e-02, -4.9442e-03,  1.2729e-02],\n",
      "          [ 1.4590e-02, -1.2811e-02,  1.9759e-03],\n",
      "          [-6.2034e-03,  2.9700e-02,  2.7776e-02]],\n",
      "\n",
      "         [[ 1.6358e-02, -3.5877e-02,  7.3269e-03],\n",
      "          [ 2.6641e-02, -3.3154e-02, -4.1870e-03],\n",
      "          [-2.4571e-02,  3.2173e-02, -2.3377e-02]],\n",
      "\n",
      "         [[-7.6799e-03, -2.2398e-03,  1.9796e-02],\n",
      "          [ 3.2556e-03,  9.7768e-04,  3.6701e-03],\n",
      "          [ 1.8286e-03,  5.3449e-04, -2.4818e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5217e-02,  1.7805e-02, -2.6573e-02],\n",
      "          [ 2.7341e-02,  7.0724e-03,  3.1493e-02],\n",
      "          [-3.7625e-03,  6.9247e-03, -2.9892e-02]],\n",
      "\n",
      "         [[ 1.6109e-02, -4.2136e-03,  2.7063e-02],\n",
      "          [-1.7532e-02,  2.2205e-02,  2.5027e-02],\n",
      "          [ 6.9629e-03,  3.4835e-02,  2.3570e-02]],\n",
      "\n",
      "         [[-1.4280e-02,  1.7459e-02, -1.6914e-02],\n",
      "          [-3.5335e-02, -3.0839e-02, -1.0643e-03],\n",
      "          [ 2.8703e-02, -1.6595e-03,  1.8769e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.0049e-02,  3.7938e-03,  1.4129e-03],\n",
      "          [ 1.5417e-02,  7.5008e-03,  3.2553e-02],\n",
      "          [-2.9843e-02, -3.5613e-02,  1.4840e-03]],\n",
      "\n",
      "         [[-3.4372e-03,  1.9966e-02,  1.5636e-02],\n",
      "          [-1.6003e-02, -2.8545e-04, -3.1585e-02],\n",
      "          [-2.3263e-02, -3.5566e-03,  2.7709e-02]],\n",
      "\n",
      "         [[ 2.3729e-03,  2.0068e-02,  8.0371e-03],\n",
      "          [ 1.1105e-02, -9.1593e-03,  2.3298e-02],\n",
      "          [ 3.6059e-02,  1.1972e-03,  9.9916e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.8221e-04,  1.0669e-02, -8.9487e-03],\n",
      "          [-2.0889e-02,  2.6568e-02, -7.8041e-03],\n",
      "          [-3.0078e-02, -1.2253e-02,  2.7422e-02]],\n",
      "\n",
      "         [[ 3.5636e-02,  9.5837e-03,  9.1308e-03],\n",
      "          [-1.5788e-03, -9.0675e-03,  1.8712e-02],\n",
      "          [-1.7038e-02,  2.4082e-02,  1.0949e-02]],\n",
      "\n",
      "         [[-4.1984e-04, -1.5565e-03, -3.1067e-02],\n",
      "          [-1.5617e-02,  3.8915e-03, -6.7156e-03],\n",
      "          [-1.0642e-02,  1.6560e-02, -2.4648e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8237e-02,  3.2338e-02,  3.6318e-03],\n",
      "          [ 3.2135e-02, -8.0334e-03,  3.6879e-03],\n",
      "          [-3.0533e-02,  3.0707e-02,  2.1379e-02]],\n",
      "\n",
      "         [[ 8.9042e-04, -3.5006e-02,  2.2371e-02],\n",
      "          [ 1.7470e-02,  2.5431e-05,  3.3630e-02],\n",
      "          [ 1.0319e-02,  1.3225e-02, -3.1215e-03]],\n",
      "\n",
      "         [[ 2.2793e-02, -1.5440e-02, -2.0281e-02],\n",
      "          [ 1.7907e-02,  5.8864e-03, -8.1730e-03],\n",
      "          [-2.2351e-02,  8.1402e-03, -5.0174e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2315e-02, -2.9617e-02,  4.4544e-03],\n",
      "          [ 3.0102e-02,  2.6518e-03, -2.8412e-02],\n",
      "          [ 9.5961e-03,  1.6421e-02,  1.7080e-02]],\n",
      "\n",
      "         [[ 2.0015e-02,  3.5798e-03,  1.7035e-03],\n",
      "          [-3.3750e-02, -1.9692e-02, -3.1905e-02],\n",
      "          [ 1.7751e-02,  1.4799e-02,  2.4110e-03]],\n",
      "\n",
      "         [[ 2.5842e-02,  3.3843e-02, -3.4353e-02],\n",
      "          [-6.7193e-03,  3.0761e-02, -2.9776e-02],\n",
      "          [-3.7759e-03, -9.9407e-03,  1.3091e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4070e-02, -1.5138e-02, -1.3759e-02],\n",
      "          [ 1.6173e-03, -1.8402e-03,  1.7742e-02],\n",
      "          [ 3.3575e-02, -2.7390e-02, -1.6464e-02]],\n",
      "\n",
      "         [[ 1.9930e-02,  5.5430e-03, -3.3342e-02],\n",
      "          [-2.5430e-02,  2.5800e-03, -9.0174e-03],\n",
      "          [-2.5405e-02,  7.3684e-04, -3.4722e-02]],\n",
      "\n",
      "         [[ 1.5031e-02, -2.3164e-02,  1.1304e-02],\n",
      "          [-3.3527e-02, -2.6510e-02, -3.7312e-03],\n",
      "          [-1.8540e-02,  1.8184e-04, -1.6719e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9624e-02, -1.0224e-02,  2.4242e-02],\n",
      "          [ 2.5507e-02, -1.8400e-02, -3.3604e-02],\n",
      "          [-1.6584e-03, -1.5941e-02, -2.3525e-02]],\n",
      "\n",
      "         [[-3.1573e-02,  2.7438e-02,  3.2818e-02],\n",
      "          [ 2.9388e-02,  1.9749e-02,  2.8788e-02],\n",
      "          [-2.1195e-02,  3.2379e-02,  1.8772e-03]],\n",
      "\n",
      "         [[ 3.5630e-03, -1.8127e-02, -3.6268e-03],\n",
      "          [ 6.5077e-03, -5.2902e-03,  1.8089e-02],\n",
      "          [ 6.3137e-03,  3.5349e-02,  2.2368e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0101]],\n",
      "\n",
      "         [[ 0.0225]],\n",
      "\n",
      "         [[ 0.0411]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         [[-0.0202]],\n",
      "\n",
      "         [[ 0.0516]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0608]],\n",
      "\n",
      "         [[-0.0272]],\n",
      "\n",
      "         [[-0.0318]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0313]],\n",
      "\n",
      "         [[-0.0627]],\n",
      "\n",
      "         [[ 0.0574]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0419]],\n",
      "\n",
      "         [[ 0.0090]],\n",
      "\n",
      "         [[ 0.0399]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0540]],\n",
      "\n",
      "         [[ 0.0683]],\n",
      "\n",
      "         [[-0.0563]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0530]],\n",
      "\n",
      "         [[ 0.0629]],\n",
      "\n",
      "         [[-0.0370]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0029]],\n",
      "\n",
      "         [[ 0.0375]],\n",
      "\n",
      "         [[-0.0615]]],\n",
      "\n",
      "\n",
      "        [[[-0.0584]],\n",
      "\n",
      "         [[ 0.0681]],\n",
      "\n",
      "         [[ 0.0228]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0590]],\n",
      "\n",
      "         [[ 0.0011]],\n",
      "\n",
      "         [[-0.0103]]],\n",
      "\n",
      "\n",
      "        [[[-0.0541]],\n",
      "\n",
      "         [[ 0.0066]],\n",
      "\n",
      "         [[-0.0430]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         [[-0.0445]],\n",
      "\n",
      "         [[ 0.0371]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0404]],\n",
      "\n",
      "         [[-0.0517]],\n",
      "\n",
      "         [[ 0.0343]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0230]],\n",
      "\n",
      "         [[ 0.0280]],\n",
      "\n",
      "         [[-0.0552]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0463]],\n",
      "\n",
      "         [[-0.0061]],\n",
      "\n",
      "         [[ 0.0444]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0411]],\n",
      "\n",
      "         [[ 0.0142]],\n",
      "\n",
      "         [[-0.0407]]],\n",
      "\n",
      "\n",
      "        [[[-0.0641]],\n",
      "\n",
      "         [[ 0.0365]],\n",
      "\n",
      "         [[ 0.0150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0366]],\n",
      "\n",
      "         [[ 0.0485]],\n",
      "\n",
      "         [[ 0.0259]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0351]],\n",
      "\n",
      "         [[-0.0310]],\n",
      "\n",
      "         [[ 0.0289]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0568]],\n",
      "\n",
      "         [[ 0.0638]],\n",
      "\n",
      "         [[ 0.0055]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0154]],\n",
      "\n",
      "         [[ 0.0567]],\n",
      "\n",
      "         [[-0.0135]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0219]],\n",
      "\n",
      "         [[ 0.0405]],\n",
      "\n",
      "         [[-0.0641]]],\n",
      "\n",
      "\n",
      "        [[[-0.0569]],\n",
      "\n",
      "         [[-0.0443]],\n",
      "\n",
      "         [[ 0.0644]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0110]],\n",
      "\n",
      "         [[ 0.0220]],\n",
      "\n",
      "         [[ 0.0176]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 4.4577e-05, -2.4172e-02, -1.4779e-02],\n",
      "          [ 1.9826e-02,  3.1916e-02, -1.6865e-02],\n",
      "          [ 2.9582e-02,  3.4114e-02, -6.8299e-04]],\n",
      "\n",
      "         [[ 3.7707e-03, -3.1067e-02, -1.4462e-03],\n",
      "          [ 2.1584e-02, -3.2259e-02,  2.4106e-02],\n",
      "          [ 9.5232e-03,  1.1738e-02,  4.5833e-03]],\n",
      "\n",
      "         [[ 2.3576e-02, -1.7419e-03, -2.0334e-02],\n",
      "          [ 2.5468e-02,  3.7896e-03, -1.9217e-02],\n",
      "          [ 2.6614e-02,  2.5007e-02,  1.5609e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.4806e-03,  3.1604e-02, -1.7192e-02],\n",
      "          [-9.9101e-03,  8.0606e-04, -7.4689e-03],\n",
      "          [ 1.9461e-02,  3.6095e-03,  1.6175e-02]],\n",
      "\n",
      "         [[ 2.4312e-02, -8.9124e-03, -8.3220e-03],\n",
      "          [ 8.3265e-03, -1.6766e-02,  2.5490e-02],\n",
      "          [-1.6016e-03,  1.0535e-02, -2.9948e-02]],\n",
      "\n",
      "         [[ 1.5034e-02,  2.7886e-02,  2.6957e-02],\n",
      "          [-3.5050e-02, -1.1646e-02, -3.5875e-02],\n",
      "          [-1.3513e-03, -3.2111e-02,  1.0083e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3337e-02,  2.1243e-02,  6.4143e-03],\n",
      "          [ 2.8437e-02, -2.4649e-02,  2.9891e-02],\n",
      "          [ 2.2938e-02,  3.5601e-02,  2.9937e-02]],\n",
      "\n",
      "         [[-2.0187e-02, -1.0806e-02,  2.0383e-02],\n",
      "          [ 2.2014e-02, -3.3272e-02,  4.9212e-03],\n",
      "          [ 2.3154e-02,  2.4781e-02, -3.2092e-02]],\n",
      "\n",
      "         [[ 3.3463e-02,  2.7903e-02, -1.3777e-03],\n",
      "          [ 2.0202e-02,  1.3162e-02,  1.2938e-02],\n",
      "          [ 2.9487e-02, -1.9934e-02, -1.8036e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8923e-02,  4.7146e-03,  2.4824e-02],\n",
      "          [ 2.1327e-02, -2.4010e-02, -3.5353e-02],\n",
      "          [ 2.4947e-02, -2.9838e-02, -1.4629e-02]],\n",
      "\n",
      "         [[-1.7962e-02,  1.1157e-02, -1.1517e-02],\n",
      "          [-3.1998e-02,  1.5355e-02,  3.2855e-02],\n",
      "          [-2.5396e-02,  1.0845e-02, -2.0133e-02]],\n",
      "\n",
      "         [[ 1.8654e-02,  2.4275e-03, -3.0764e-02],\n",
      "          [ 2.0119e-02,  2.8409e-02,  2.3045e-02],\n",
      "          [-1.4548e-02, -3.0962e-02, -2.5071e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2471e-02, -2.9269e-02,  2.2913e-02],\n",
      "          [-3.5298e-02, -3.5754e-02,  1.8924e-02],\n",
      "          [ 1.4677e-02,  4.7971e-03, -3.3661e-03]],\n",
      "\n",
      "         [[-1.9722e-02, -1.5378e-02,  7.0441e-04],\n",
      "          [ 2.5131e-02, -1.9520e-02,  1.6591e-02],\n",
      "          [ 1.2554e-03, -9.6990e-03,  3.0549e-02]],\n",
      "\n",
      "         [[ 1.8687e-02, -2.7876e-02,  3.3891e-02],\n",
      "          [-3.5518e-02, -1.4194e-02, -1.8771e-03],\n",
      "          [-3.1578e-02,  2.2685e-03,  2.2213e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2063e-03, -1.0199e-02, -3.3935e-02],\n",
      "          [ 2.3561e-02,  3.0094e-05,  1.5140e-02],\n",
      "          [ 5.2278e-04,  2.0203e-03, -1.9151e-02]],\n",
      "\n",
      "         [[-3.3467e-02, -5.8158e-03, -4.5664e-03],\n",
      "          [-2.6493e-02, -2.7011e-02, -3.5315e-02],\n",
      "          [-1.4144e-02,  7.1707e-03,  1.9087e-02]],\n",
      "\n",
      "         [[ 2.8276e-02, -2.0679e-02,  3.2424e-02],\n",
      "          [-3.2251e-02, -3.3109e-03, -3.4130e-04],\n",
      "          [ 9.8805e-03,  2.4807e-02, -2.4199e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2744e-02, -1.2454e-02,  6.7799e-03],\n",
      "          [-1.3289e-02,  3.5022e-03,  3.2132e-02],\n",
      "          [-1.9952e-02,  3.4529e-02,  6.0386e-03]],\n",
      "\n",
      "         [[-4.2513e-05, -3.5907e-02, -2.9639e-02],\n",
      "          [ 1.9687e-02,  6.6851e-03,  3.5120e-02],\n",
      "          [ 2.8704e-02,  2.5935e-02, -3.2488e-02]],\n",
      "\n",
      "         [[-1.0272e-02, -3.0887e-02, -1.4763e-02],\n",
      "          [ 2.9116e-02,  1.6947e-02, -2.1357e-02],\n",
      "          [ 2.1200e-03,  2.3375e-02, -2.1739e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.4305e-03, -1.4031e-02,  2.9125e-02],\n",
      "          [-2.0664e-03,  3.0909e-04, -2.5585e-02],\n",
      "          [-1.4386e-02,  2.5832e-02,  3.0868e-02]],\n",
      "\n",
      "         [[-2.2324e-02,  3.3352e-02, -3.5000e-02],\n",
      "          [-2.8292e-03,  7.8564e-03,  1.1086e-02],\n",
      "          [-2.3431e-02,  2.7783e-02,  3.1439e-02]],\n",
      "\n",
      "         [[-2.6795e-02,  7.5541e-03,  3.3368e-03],\n",
      "          [ 2.5305e-02,  3.1843e-02,  1.5250e-02],\n",
      "          [-3.5821e-02, -3.2557e-02, -3.5651e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.3986e-03, -2.3656e-02, -1.5731e-03],\n",
      "          [-5.0246e-03,  5.6581e-03, -2.2428e-03],\n",
      "          [ 1.4255e-02,  1.4786e-02,  1.8280e-02]],\n",
      "\n",
      "         [[-2.1126e-02, -1.1387e-02, -3.0006e-02],\n",
      "          [ 1.7389e-02, -1.1419e-02, -3.5999e-02],\n",
      "          [ 3.3980e-03, -4.3693e-03, -1.0013e-02]],\n",
      "\n",
      "         [[-1.0698e-02,  1.3784e-03,  6.3845e-03],\n",
      "          [-3.7462e-03, -2.5383e-02,  2.1004e-02],\n",
      "          [ 3.5737e-02, -3.4775e-02, -2.5701e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7586e-02, -2.5958e-02,  3.0090e-02],\n",
      "          [ 2.3114e-02,  1.0836e-02,  8.4295e-03],\n",
      "          [-3.5342e-02,  2.1091e-02,  2.2077e-03]],\n",
      "\n",
      "         [[-2.3577e-02, -3.5062e-02, -3.1348e-02],\n",
      "          [-3.2162e-03,  2.4387e-02, -1.4664e-02],\n",
      "          [ 2.1307e-02, -1.7405e-02, -2.5990e-02]],\n",
      "\n",
      "         [[ 4.9489e-03,  2.3079e-03,  6.4752e-03],\n",
      "          [-2.0900e-02,  1.1036e-03,  2.0158e-04],\n",
      "          [-3.2762e-02,  1.3776e-03,  1.0216e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0619e-03,  3.0125e-03, -4.2549e-03],\n",
      "          [-2.0132e-02,  9.7307e-03, -2.4345e-02],\n",
      "          [ 3.5923e-02,  1.2344e-02,  2.5594e-02]],\n",
      "\n",
      "         [[-2.1130e-02, -1.0187e-02,  2.3901e-02],\n",
      "          [ 6.8649e-03,  7.4480e-03, -3.5548e-02],\n",
      "          [-1.6922e-02, -4.6403e-03, -6.9950e-03]],\n",
      "\n",
      "         [[ 3.0703e-02,  3.5970e-03, -2.7108e-02],\n",
      "          [-1.0401e-02,  2.7335e-03, -9.3371e-04],\n",
      "          [ 2.5035e-03, -3.0935e-03,  6.5726e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4456e-02, -3.1086e-03, -1.7311e-02],\n",
      "          [ 3.1607e-02,  7.1273e-03,  2.8073e-02],\n",
      "          [-1.8028e-02,  1.0956e-02,  1.9578e-02]],\n",
      "\n",
      "         [[ 3.1664e-02,  1.5836e-02,  1.1069e-02],\n",
      "          [-9.5548e-03, -1.3984e-02,  1.6471e-02],\n",
      "          [ 3.0633e-02,  4.0356e-03,  8.2171e-03]],\n",
      "\n",
      "         [[-2.0088e-02,  3.3341e-02, -2.4979e-02],\n",
      "          [-6.2830e-03, -1.3463e-02,  3.1705e-03],\n",
      "          [ 2.6656e-02,  1.2841e-03,  3.5105e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0625]],\n",
      "\n",
      "         [[ 0.0675]],\n",
      "\n",
      "         [[-0.0145]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0309]],\n",
      "\n",
      "         [[-0.0425]],\n",
      "\n",
      "         [[ 0.0135]]],\n",
      "\n",
      "\n",
      "        [[[-0.0573]],\n",
      "\n",
      "         [[-0.0355]],\n",
      "\n",
      "         [[-0.0678]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0258]],\n",
      "\n",
      "         [[ 0.0582]],\n",
      "\n",
      "         [[ 0.0289]]],\n",
      "\n",
      "\n",
      "        [[[-0.0636]],\n",
      "\n",
      "         [[ 0.0529]],\n",
      "\n",
      "         [[ 0.0470]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0623]],\n",
      "\n",
      "         [[-0.0536]],\n",
      "\n",
      "         [[-0.0607]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0250]],\n",
      "\n",
      "         [[-0.0230]],\n",
      "\n",
      "         [[-0.0516]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0323]],\n",
      "\n",
      "         [[-0.0129]],\n",
      "\n",
      "         [[-0.0533]]],\n",
      "\n",
      "\n",
      "        [[[-0.0654]],\n",
      "\n",
      "         [[-0.0342]],\n",
      "\n",
      "         [[-0.0546]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0570]],\n",
      "\n",
      "         [[ 0.0462]],\n",
      "\n",
      "         [[ 0.0188]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0005]],\n",
      "\n",
      "         [[ 0.0264]],\n",
      "\n",
      "         [[-0.0524]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0266]],\n",
      "\n",
      "         [[-0.0502]],\n",
      "\n",
      "         [[-0.0350]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0169]],\n",
      "\n",
      "         [[-0.0629]],\n",
      "\n",
      "         [[ 0.0456]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0471]],\n",
      "\n",
      "         [[-0.0480]],\n",
      "\n",
      "         [[ 0.0373]]],\n",
      "\n",
      "\n",
      "        [[[-0.0624]],\n",
      "\n",
      "         [[-0.0032]],\n",
      "\n",
      "         [[ 0.0611]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0063]],\n",
      "\n",
      "         [[-0.0426]],\n",
      "\n",
      "         [[-0.0544]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0537]],\n",
      "\n",
      "         [[ 0.0404]],\n",
      "\n",
      "         [[ 0.0640]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0115]],\n",
      "\n",
      "         [[ 0.0028]],\n",
      "\n",
      "         [[ 0.0546]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0393]],\n",
      "\n",
      "         [[-0.0532]],\n",
      "\n",
      "         [[-0.0461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0267]],\n",
      "\n",
      "         [[-0.0203]],\n",
      "\n",
      "         [[-0.0636]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0109]],\n",
      "\n",
      "         [[-0.0651]],\n",
      "\n",
      "         [[ 0.0139]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0098]],\n",
      "\n",
      "         [[ 0.0136]],\n",
      "\n",
      "         [[-0.0615]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0449]],\n",
      "\n",
      "         [[ 0.0460]],\n",
      "\n",
      "         [[ 0.0570]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0583]],\n",
      "\n",
      "         [[-0.0034]],\n",
      "\n",
      "         [[-0.0582]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0271, -0.0205,  0.0180],\n",
      "          [-0.0008,  0.0120,  0.0201],\n",
      "          [ 0.0094, -0.0312, -0.0183]],\n",
      "\n",
      "         [[-0.0013,  0.0240, -0.0124],\n",
      "          [-0.0142, -0.0299,  0.0030],\n",
      "          [ 0.0277, -0.0052, -0.0121]],\n",
      "\n",
      "         [[-0.0278,  0.0285,  0.0196],\n",
      "          [ 0.0245,  0.0263,  0.0274],\n",
      "          [-0.0080, -0.0317, -0.0271]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0049,  0.0105,  0.0071],\n",
      "          [-0.0344,  0.0114,  0.0319],\n",
      "          [ 0.0028,  0.0081, -0.0300]],\n",
      "\n",
      "         [[ 0.0179,  0.0176, -0.0101],\n",
      "          [ 0.0116,  0.0142, -0.0352],\n",
      "          [-0.0278, -0.0224,  0.0152]],\n",
      "\n",
      "         [[-0.0313, -0.0261,  0.0104],\n",
      "          [ 0.0352,  0.0250,  0.0033],\n",
      "          [ 0.0136,  0.0193,  0.0232]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0156,  0.0120, -0.0216],\n",
      "          [-0.0204,  0.0179,  0.0267],\n",
      "          [ 0.0265, -0.0182,  0.0341]],\n",
      "\n",
      "         [[ 0.0064, -0.0332,  0.0131],\n",
      "          [ 0.0087, -0.0214, -0.0231],\n",
      "          [ 0.0020,  0.0047, -0.0139]],\n",
      "\n",
      "         [[-0.0035, -0.0142, -0.0107],\n",
      "          [-0.0246,  0.0145,  0.0268],\n",
      "          [ 0.0235,  0.0207, -0.0261]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0315,  0.0125,  0.0320],\n",
      "          [ 0.0012,  0.0268, -0.0007],\n",
      "          [-0.0248, -0.0143, -0.0034]],\n",
      "\n",
      "         [[-0.0247,  0.0345,  0.0350],\n",
      "          [-0.0343, -0.0172,  0.0205],\n",
      "          [-0.0336, -0.0090,  0.0072]],\n",
      "\n",
      "         [[ 0.0175, -0.0182,  0.0014],\n",
      "          [-0.0058, -0.0351, -0.0101],\n",
      "          [ 0.0050,  0.0233,  0.0122]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0245,  0.0052, -0.0180],\n",
      "          [ 0.0200,  0.0073,  0.0063],\n",
      "          [-0.0103, -0.0212, -0.0257]],\n",
      "\n",
      "         [[-0.0344, -0.0081, -0.0142],\n",
      "          [-0.0296,  0.0343, -0.0156],\n",
      "          [-0.0244, -0.0233,  0.0335]],\n",
      "\n",
      "         [[ 0.0084, -0.0261,  0.0254],\n",
      "          [-0.0109,  0.0361,  0.0222],\n",
      "          [-0.0331, -0.0170,  0.0280]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0359, -0.0145, -0.0006],\n",
      "          [ 0.0212,  0.0003, -0.0234],\n",
      "          [ 0.0355, -0.0117,  0.0234]],\n",
      "\n",
      "         [[-0.0291,  0.0143,  0.0029],\n",
      "          [ 0.0163, -0.0244, -0.0211],\n",
      "          [-0.0321,  0.0077, -0.0226]],\n",
      "\n",
      "         [[-0.0054,  0.0278,  0.0267],\n",
      "          [ 0.0323,  0.0251, -0.0271],\n",
      "          [ 0.0056, -0.0084, -0.0317]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0141,  0.0165,  0.0358],\n",
      "          [ 0.0154,  0.0081, -0.0077],\n",
      "          [-0.0200,  0.0290, -0.0178]],\n",
      "\n",
      "         [[ 0.0079,  0.0167,  0.0067],\n",
      "          [ 0.0125, -0.0343,  0.0042],\n",
      "          [ 0.0049, -0.0100,  0.0244]],\n",
      "\n",
      "         [[-0.0308, -0.0293,  0.0043],\n",
      "          [ 0.0052, -0.0237,  0.0247],\n",
      "          [ 0.0096, -0.0229, -0.0185]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0122,  0.0165, -0.0228],\n",
      "          [ 0.0255,  0.0208,  0.0186],\n",
      "          [-0.0171,  0.0232,  0.0133]],\n",
      "\n",
      "         [[ 0.0354, -0.0335,  0.0326],\n",
      "          [-0.0023, -0.0194,  0.0072],\n",
      "          [-0.0328,  0.0208,  0.0043]],\n",
      "\n",
      "         [[-0.0046, -0.0199, -0.0046],\n",
      "          [ 0.0013,  0.0347,  0.0289],\n",
      "          [-0.0352, -0.0204,  0.0125]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0302, -0.0053, -0.0250],\n",
      "          [-0.0035, -0.0004, -0.0056],\n",
      "          [-0.0016, -0.0160,  0.0035]],\n",
      "\n",
      "         [[ 0.0094,  0.0303,  0.0129],\n",
      "          [ 0.0085,  0.0324, -0.0239],\n",
      "          [-0.0041,  0.0358,  0.0191]],\n",
      "\n",
      "         [[-0.0287,  0.0048,  0.0312],\n",
      "          [ 0.0302, -0.0201, -0.0007],\n",
      "          [ 0.0214,  0.0146,  0.0068]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0204,  0.0251, -0.0188],\n",
      "          [-0.0217, -0.0356, -0.0106],\n",
      "          [ 0.0171, -0.0023, -0.0076]],\n",
      "\n",
      "         [[ 0.0084, -0.0097,  0.0176],\n",
      "          [-0.0237, -0.0246,  0.0058],\n",
      "          [-0.0228, -0.0064,  0.0319]],\n",
      "\n",
      "         [[-0.0231,  0.0290,  0.0287],\n",
      "          [ 0.0043, -0.0070, -0.0355],\n",
      "          [-0.0087, -0.0071,  0.0062]]],\n",
      "\n",
      "\n",
      "        [[[-0.0122, -0.0360, -0.0361],\n",
      "          [-0.0024, -0.0238,  0.0112],\n",
      "          [-0.0095, -0.0359, -0.0136]],\n",
      "\n",
      "         [[ 0.0248, -0.0122,  0.0283],\n",
      "          [ 0.0279, -0.0136, -0.0258],\n",
      "          [ 0.0140, -0.0124, -0.0298]],\n",
      "\n",
      "         [[ 0.0264, -0.0274,  0.0268],\n",
      "          [ 0.0305, -0.0221, -0.0178],\n",
      "          [-0.0235, -0.0263,  0.0142]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0099, -0.0031,  0.0313],\n",
      "          [ 0.0090, -0.0131, -0.0324],\n",
      "          [ 0.0069, -0.0313, -0.0257]],\n",
      "\n",
      "         [[-0.0218, -0.0281, -0.0230],\n",
      "          [-0.0275,  0.0087, -0.0038],\n",
      "          [-0.0291, -0.0213,  0.0130]],\n",
      "\n",
      "         [[ 0.0062, -0.0168, -0.0261],\n",
      "          [-0.0286,  0.0207,  0.0050],\n",
      "          [-0.0145,  0.0360,  0.0189]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0310]],\n",
      "\n",
      "         [[-0.0269]],\n",
      "\n",
      "         [[ 0.0262]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0514]],\n",
      "\n",
      "         [[ 0.0535]],\n",
      "\n",
      "         [[-0.0059]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0028]],\n",
      "\n",
      "         [[ 0.0076]],\n",
      "\n",
      "         [[-0.0010]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0542]],\n",
      "\n",
      "         [[-0.0323]],\n",
      "\n",
      "         [[ 0.0636]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0080]],\n",
      "\n",
      "         [[ 0.0271]],\n",
      "\n",
      "         [[ 0.0471]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0681]],\n",
      "\n",
      "         [[-0.0575]],\n",
      "\n",
      "         [[ 0.0262]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0048]],\n",
      "\n",
      "         [[-0.0011]],\n",
      "\n",
      "         [[-0.0389]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0375]],\n",
      "\n",
      "         [[ 0.0356]],\n",
      "\n",
      "         [[-0.0240]]],\n",
      "\n",
      "\n",
      "        [[[-0.0184]],\n",
      "\n",
      "         [[-0.0380]],\n",
      "\n",
      "         [[-0.0682]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0225]],\n",
      "\n",
      "         [[-0.0658]],\n",
      "\n",
      "         [[-0.0626]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0041]],\n",
      "\n",
      "         [[-0.0262]],\n",
      "\n",
      "         [[-0.0229]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0548]],\n",
      "\n",
      "         [[ 0.0118]],\n",
      "\n",
      "         [[ 0.0461]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0557]],\n",
      "\n",
      "         [[ 0.0426]],\n",
      "\n",
      "         [[-0.0269]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0184]],\n",
      "\n",
      "         [[ 0.0104]],\n",
      "\n",
      "         [[ 0.0341]]],\n",
      "\n",
      "\n",
      "        [[[-0.0021]],\n",
      "\n",
      "         [[ 0.0314]],\n",
      "\n",
      "         [[-0.0031]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0221]],\n",
      "\n",
      "         [[-0.0370]],\n",
      "\n",
      "         [[-0.0068]]],\n",
      "\n",
      "\n",
      "        [[[-0.0308]],\n",
      "\n",
      "         [[ 0.0511]],\n",
      "\n",
      "         [[-0.0469]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0397]],\n",
      "\n",
      "         [[ 0.0502]],\n",
      "\n",
      "         [[-0.0149]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0601]],\n",
      "\n",
      "         [[-0.0083]],\n",
      "\n",
      "         [[ 0.0562]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0334]],\n",
      "\n",
      "         [[ 0.0471]],\n",
      "\n",
      "         [[-0.0444]]],\n",
      "\n",
      "\n",
      "        [[[-0.0361]],\n",
      "\n",
      "         [[-0.0460]],\n",
      "\n",
      "         [[-0.0419]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0101]],\n",
      "\n",
      "         [[ 0.0338]],\n",
      "\n",
      "         [[-0.0454]]],\n",
      "\n",
      "\n",
      "        [[[-0.0565]],\n",
      "\n",
      "         [[-0.0267]],\n",
      "\n",
      "         [[ 0.0434]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0465]],\n",
      "\n",
      "         [[-0.0491]],\n",
      "\n",
      "         [[-0.0181]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0180,  0.0189,  0.0209],\n",
      "          [ 0.0139,  0.0237,  0.0145],\n",
      "          [-0.0180,  0.0048,  0.0071]],\n",
      "\n",
      "         [[-0.0114,  0.0043, -0.0005],\n",
      "          [-0.0184, -0.0136, -0.0215],\n",
      "          [ 0.0066,  0.0152,  0.0057]],\n",
      "\n",
      "         [[ 0.0152, -0.0156,  0.0111],\n",
      "          [-0.0234,  0.0248,  0.0167],\n",
      "          [ 0.0180,  0.0137,  0.0195]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0119, -0.0016,  0.0251],\n",
      "          [-0.0012,  0.0172,  0.0091],\n",
      "          [-0.0138,  0.0190,  0.0076]],\n",
      "\n",
      "         [[ 0.0209, -0.0012, -0.0241],\n",
      "          [ 0.0137, -0.0058,  0.0125],\n",
      "          [ 0.0117, -0.0116, -0.0104]],\n",
      "\n",
      "         [[-0.0191, -0.0251, -0.0218],\n",
      "          [ 0.0019, -0.0067, -0.0192],\n",
      "          [ 0.0236, -0.0201,  0.0040]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0113, -0.0168,  0.0061],\n",
      "          [-0.0173,  0.0155, -0.0147],\n",
      "          [ 0.0089, -0.0017, -0.0083]],\n",
      "\n",
      "         [[-0.0056,  0.0152,  0.0020],\n",
      "          [ 0.0027, -0.0079,  0.0046],\n",
      "          [-0.0070,  0.0004, -0.0045]],\n",
      "\n",
      "         [[-0.0039, -0.0025,  0.0061],\n",
      "          [ 0.0115,  0.0189,  0.0255],\n",
      "          [ 0.0239, -0.0157, -0.0043]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0057, -0.0159, -0.0080],\n",
      "          [ 0.0152, -0.0198,  0.0062],\n",
      "          [-0.0241, -0.0210,  0.0163]],\n",
      "\n",
      "         [[ 0.0226,  0.0030, -0.0099],\n",
      "          [-0.0139,  0.0077,  0.0029],\n",
      "          [ 0.0006,  0.0122,  0.0082]],\n",
      "\n",
      "         [[-0.0239, -0.0231,  0.0110],\n",
      "          [-0.0233, -0.0094, -0.0199],\n",
      "          [-0.0052,  0.0180,  0.0013]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0086,  0.0031,  0.0165],\n",
      "          [ 0.0125,  0.0173,  0.0246],\n",
      "          [-0.0145,  0.0142, -0.0053]],\n",
      "\n",
      "         [[-0.0247,  0.0252,  0.0145],\n",
      "          [-0.0185,  0.0156,  0.0084],\n",
      "          [-0.0104,  0.0197,  0.0027]],\n",
      "\n",
      "         [[-0.0159,  0.0107,  0.0027],\n",
      "          [ 0.0112, -0.0083,  0.0129],\n",
      "          [-0.0077,  0.0169, -0.0130]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0001, -0.0138,  0.0031],\n",
      "          [ 0.0233,  0.0193, -0.0181],\n",
      "          [-0.0029,  0.0179,  0.0111]],\n",
      "\n",
      "         [[ 0.0055,  0.0243, -0.0059],\n",
      "          [ 0.0211,  0.0115,  0.0079],\n",
      "          [ 0.0118, -0.0133,  0.0151]],\n",
      "\n",
      "         [[-0.0173,  0.0228,  0.0158],\n",
      "          [-0.0213, -0.0042, -0.0128],\n",
      "          [ 0.0191, -0.0236,  0.0200]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0042, -0.0017,  0.0229],\n",
      "          [-0.0066, -0.0235,  0.0175],\n",
      "          [-0.0002,  0.0142, -0.0095]],\n",
      "\n",
      "         [[ 0.0191, -0.0078, -0.0214],\n",
      "          [ 0.0201,  0.0211, -0.0048],\n",
      "          [ 0.0134, -0.0215, -0.0158]],\n",
      "\n",
      "         [[ 0.0045,  0.0103, -0.0210],\n",
      "          [ 0.0008,  0.0122, -0.0006],\n",
      "          [-0.0101, -0.0115, -0.0140]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0120, -0.0023, -0.0199],\n",
      "          [ 0.0237,  0.0238,  0.0172],\n",
      "          [-0.0192, -0.0220, -0.0158]],\n",
      "\n",
      "         [[ 0.0162, -0.0004,  0.0017],\n",
      "          [ 0.0130,  0.0138,  0.0064],\n",
      "          [-0.0036, -0.0224,  0.0111]],\n",
      "\n",
      "         [[-0.0008, -0.0242, -0.0110],\n",
      "          [-0.0061, -0.0241,  0.0040],\n",
      "          [ 0.0177, -0.0107, -0.0023]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0015, -0.0105,  0.0195],\n",
      "          [ 0.0077,  0.0082,  0.0080],\n",
      "          [ 0.0183,  0.0074,  0.0127]],\n",
      "\n",
      "         [[-0.0224, -0.0248,  0.0037],\n",
      "          [-0.0197, -0.0009, -0.0243],\n",
      "          [-0.0089,  0.0108,  0.0099]],\n",
      "\n",
      "         [[-0.0085,  0.0149,  0.0223],\n",
      "          [ 0.0161,  0.0033,  0.0194],\n",
      "          [ 0.0032,  0.0167,  0.0114]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0230, -0.0150, -0.0053],\n",
      "          [ 0.0009, -0.0174,  0.0173],\n",
      "          [ 0.0047, -0.0034,  0.0211]],\n",
      "\n",
      "         [[-0.0226,  0.0191,  0.0242],\n",
      "          [ 0.0008,  0.0213,  0.0127],\n",
      "          [-0.0221,  0.0083,  0.0130]],\n",
      "\n",
      "         [[-0.0200, -0.0141, -0.0142],\n",
      "          [-0.0107,  0.0050,  0.0213],\n",
      "          [-0.0073, -0.0109, -0.0116]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0067,  0.0205, -0.0234],\n",
      "          [ 0.0212, -0.0212,  0.0060],\n",
      "          [ 0.0173,  0.0113, -0.0074]],\n",
      "\n",
      "         [[-0.0109, -0.0254, -0.0239],\n",
      "          [ 0.0192,  0.0036,  0.0168],\n",
      "          [-0.0050,  0.0240, -0.0127]],\n",
      "\n",
      "         [[-0.0082, -0.0120,  0.0189],\n",
      "          [ 0.0020,  0.0210,  0.0122],\n",
      "          [-0.0195,  0.0052, -0.0015]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0064,  0.0118, -0.0210],\n",
      "          [ 0.0214, -0.0194, -0.0010],\n",
      "          [ 0.0201, -0.0155,  0.0054]],\n",
      "\n",
      "         [[ 0.0015,  0.0029, -0.0188],\n",
      "          [ 0.0127, -0.0082, -0.0048],\n",
      "          [-0.0182,  0.0039, -0.0143]],\n",
      "\n",
      "         [[ 0.0148,  0.0161, -0.0204],\n",
      "          [-0.0215,  0.0248, -0.0172],\n",
      "          [ 0.0026, -0.0235, -0.0159]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0250]],\n",
      "\n",
      "         [[-0.0477]],\n",
      "\n",
      "         [[-0.0413]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0184]],\n",
      "\n",
      "         [[ 0.0142]],\n",
      "\n",
      "         [[-0.0136]]],\n",
      "\n",
      "\n",
      "        [[[-0.0333]],\n",
      "\n",
      "         [[ 0.0450]],\n",
      "\n",
      "         [[-0.0257]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0327]],\n",
      "\n",
      "         [[-0.0299]],\n",
      "\n",
      "         [[ 0.0156]]],\n",
      "\n",
      "\n",
      "        [[[-0.0135]],\n",
      "\n",
      "         [[ 0.0154]],\n",
      "\n",
      "         [[ 0.0023]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0302]],\n",
      "\n",
      "         [[ 0.0328]],\n",
      "\n",
      "         [[ 0.0313]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0147]],\n",
      "\n",
      "         [[ 0.0033]],\n",
      "\n",
      "         [[-0.0156]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0146]],\n",
      "\n",
      "         [[ 0.0044]],\n",
      "\n",
      "         [[ 0.0109]]],\n",
      "\n",
      "\n",
      "        [[[-0.0398]],\n",
      "\n",
      "         [[ 0.0255]],\n",
      "\n",
      "         [[ 0.0340]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0316]],\n",
      "\n",
      "         [[ 0.0188]],\n",
      "\n",
      "         [[-0.0410]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0377]],\n",
      "\n",
      "         [[-0.0327]],\n",
      "\n",
      "         [[-0.0306]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0348]],\n",
      "\n",
      "         [[ 0.0285]],\n",
      "\n",
      "         [[-0.0301]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0019]],\n",
      "\n",
      "         [[-0.0331]],\n",
      "\n",
      "         [[ 0.0216]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0280]],\n",
      "\n",
      "         [[-0.0379]],\n",
      "\n",
      "         [[-0.0186]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0096]],\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         [[ 0.0181]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0026]],\n",
      "\n",
      "         [[ 0.0425]],\n",
      "\n",
      "         [[ 0.0067]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0118]],\n",
      "\n",
      "         [[-0.0356]],\n",
      "\n",
      "         [[ 0.0104]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0083]],\n",
      "\n",
      "         [[-0.0333]],\n",
      "\n",
      "         [[ 0.0405]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0218]],\n",
      "\n",
      "         [[ 0.0295]],\n",
      "\n",
      "         [[ 0.0033]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0437]],\n",
      "\n",
      "         [[-0.0274]],\n",
      "\n",
      "         [[-0.0080]]],\n",
      "\n",
      "\n",
      "        [[[-0.0111]],\n",
      "\n",
      "         [[-0.0366]],\n",
      "\n",
      "         [[ 0.0191]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0187]],\n",
      "\n",
      "         [[ 0.0367]],\n",
      "\n",
      "         [[ 0.0048]]],\n",
      "\n",
      "\n",
      "        [[[-0.0364]],\n",
      "\n",
      "         [[-0.0054]],\n",
      "\n",
      "         [[ 0.0397]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0264]],\n",
      "\n",
      "         [[ 0.0065]],\n",
      "\n",
      "         [[-0.0353]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0408]],\n",
      "\n",
      "         [[ 0.0317]],\n",
      "\n",
      "         [[ 0.0320]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0080]],\n",
      "\n",
      "         [[ 0.0135]],\n",
      "\n",
      "         [[ 0.0185]]],\n",
      "\n",
      "\n",
      "        [[[-0.0464]],\n",
      "\n",
      "         [[-0.0267]],\n",
      "\n",
      "         [[ 0.0213]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0431]],\n",
      "\n",
      "         [[ 0.0359]],\n",
      "\n",
      "         [[ 0.0150]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0289]],\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         [[-0.0019]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0237]],\n",
      "\n",
      "         [[-0.0333]],\n",
      "\n",
      "         [[-0.0224]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0480]],\n",
      "\n",
      "         [[ 0.0152]],\n",
      "\n",
      "         [[ 0.0453]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         [[ 0.0051]],\n",
      "\n",
      "         [[-0.0438]]],\n",
      "\n",
      "\n",
      "        [[[-0.0029]],\n",
      "\n",
      "         [[ 0.0347]],\n",
      "\n",
      "         [[-0.0259]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0340]],\n",
      "\n",
      "         [[-0.0079]],\n",
      "\n",
      "         [[-0.0101]]],\n",
      "\n",
      "\n",
      "        [[[-0.0107]],\n",
      "\n",
      "         [[-0.0263]],\n",
      "\n",
      "         [[ 0.0270]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0081]],\n",
      "\n",
      "         [[ 0.0236]],\n",
      "\n",
      "         [[ 0.0103]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-2.1386e-02,  1.8744e-02, -1.9556e-02],\n",
      "          [-3.7144e-03, -1.0650e-02, -1.9985e-02],\n",
      "          [ 2.1160e-02,  7.4966e-03,  1.2759e-02]],\n",
      "\n",
      "         [[-7.4762e-03,  1.2146e-02,  1.8255e-02],\n",
      "          [-5.0381e-03, -1.2311e-02, -2.2728e-02],\n",
      "          [-1.9722e-02, -8.0697e-04, -2.5091e-02]],\n",
      "\n",
      "         [[ 2.3185e-04,  9.7584e-03,  9.3740e-03],\n",
      "          [ 2.2715e-02, -6.1371e-03, -3.4725e-04],\n",
      "          [-1.1186e-02, -1.2208e-02, -1.1214e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2448e-02,  1.7327e-02, -3.5719e-03],\n",
      "          [ 1.1132e-02, -1.8393e-03,  2.0458e-02],\n",
      "          [ 1.5309e-02, -1.7042e-02,  5.4237e-03]],\n",
      "\n",
      "         [[-2.0283e-02,  1.0912e-02, -2.0742e-02],\n",
      "          [-9.1056e-03,  5.8768e-03,  6.8594e-03],\n",
      "          [ 1.1145e-02, -1.4112e-02, -5.9176e-03]],\n",
      "\n",
      "         [[ 1.8071e-02,  1.0631e-02,  4.0827e-03],\n",
      "          [-1.2214e-02,  1.6682e-02, -8.0508e-03],\n",
      "          [-1.8664e-02,  1.2448e-02, -1.1615e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.1035e-03,  2.4464e-02, -9.1286e-03],\n",
      "          [-2.1106e-03,  3.9234e-03,  2.5290e-02],\n",
      "          [ 6.4158e-03,  6.1793e-04,  1.5956e-03]],\n",
      "\n",
      "         [[ 8.8051e-03,  1.8763e-02, -4.8733e-03],\n",
      "          [-7.8624e-03,  6.3710e-03, -7.9193e-03],\n",
      "          [-6.6971e-03, -1.1129e-02,  1.1475e-02]],\n",
      "\n",
      "         [[-2.0185e-02,  1.3411e-02, -1.2647e-02],\n",
      "          [-1.2986e-02,  2.3361e-02, -1.2624e-02],\n",
      "          [ 1.8040e-02, -5.3729e-03,  2.4022e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5250e-02, -6.1602e-03,  6.2882e-03],\n",
      "          [ 8.6840e-03, -2.4927e-02,  1.4727e-02],\n",
      "          [ 1.1489e-02, -9.9204e-03, -2.4625e-02]],\n",
      "\n",
      "         [[-1.0902e-02, -1.4416e-02, -2.5430e-02],\n",
      "          [ 1.2237e-02, -1.1206e-02, -1.1528e-02],\n",
      "          [-1.9040e-02, -1.6706e-02, -1.5303e-02]],\n",
      "\n",
      "         [[ 1.8576e-02,  1.1710e-03, -2.1445e-02],\n",
      "          [-5.2560e-03, -1.7666e-02, -1.3213e-05],\n",
      "          [ 1.2157e-02, -1.4233e-02, -1.4106e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1229e-03,  8.9963e-03,  9.0348e-04],\n",
      "          [-2.1825e-02, -2.0172e-02, -1.2886e-02],\n",
      "          [-1.7973e-02, -1.5566e-02, -2.1660e-02]],\n",
      "\n",
      "         [[-2.5138e-02,  8.2300e-03,  2.0138e-02],\n",
      "          [ 5.4776e-03, -8.6342e-04, -1.9055e-03],\n",
      "          [-7.2060e-03,  1.6258e-02,  2.2587e-02]],\n",
      "\n",
      "         [[ 2.4316e-02,  1.4154e-02,  2.0526e-02],\n",
      "          [ 9.1786e-03,  1.7908e-02, -8.4447e-04],\n",
      "          [ 1.7646e-04, -4.8275e-03,  1.4800e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3508e-02, -1.4979e-02, -1.4411e-02],\n",
      "          [-2.3627e-02, -1.4910e-02,  3.0750e-03],\n",
      "          [ 1.7219e-02,  4.3106e-03,  2.5150e-02]],\n",
      "\n",
      "         [[-2.3506e-02, -2.4793e-02,  1.2696e-02],\n",
      "          [ 1.8525e-02, -1.8690e-02,  2.3243e-02],\n",
      "          [-1.6532e-02, -7.1102e-03,  2.1724e-02]],\n",
      "\n",
      "         [[-8.1192e-03, -1.3399e-03,  3.8093e-03],\n",
      "          [ 1.3432e-02, -2.2948e-02,  2.3201e-02],\n",
      "          [-1.1821e-02, -1.1750e-03, -1.8284e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.0795e-02,  2.3493e-02,  6.9322e-03],\n",
      "          [ 5.2581e-03,  2.2720e-03,  1.2496e-02],\n",
      "          [-9.7443e-03, -2.1186e-02,  1.5690e-02]],\n",
      "\n",
      "         [[-4.2493e-03, -2.7367e-03,  6.2807e-03],\n",
      "          [-1.0573e-02, -1.5447e-02,  2.2316e-02],\n",
      "          [-6.2441e-03, -1.5391e-02,  1.4172e-02]],\n",
      "\n",
      "         [[ 1.8078e-02,  8.9712e-03,  2.2576e-02],\n",
      "          [ 1.4767e-03,  1.3359e-02, -1.5671e-02],\n",
      "          [-1.4702e-02, -4.7694e-03, -2.1433e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9552e-02, -2.1597e-02, -6.8214e-03],\n",
      "          [-2.2674e-02, -2.4377e-02, -1.1320e-02],\n",
      "          [-8.6894e-03, -1.0111e-03,  2.2432e-02]],\n",
      "\n",
      "         [[-9.0691e-05,  2.4325e-02,  1.5254e-02],\n",
      "          [-9.0466e-04,  1.8761e-02,  1.3736e-02],\n",
      "          [ 4.0490e-03,  2.2060e-02, -1.5556e-02]],\n",
      "\n",
      "         [[ 1.9600e-02, -2.4883e-02,  2.5109e-02],\n",
      "          [ 1.4430e-02,  1.0831e-02,  4.9356e-03],\n",
      "          [ 4.4454e-03,  1.7522e-02,  1.7986e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8849e-02,  6.4469e-04,  1.7301e-02],\n",
      "          [ 1.3444e-02, -3.7394e-04,  4.4068e-04],\n",
      "          [ 1.4315e-02, -1.5557e-02,  1.0983e-02]],\n",
      "\n",
      "         [[-2.8869e-03,  1.8073e-02,  9.9939e-03],\n",
      "          [-2.4408e-02,  3.1706e-03, -3.3235e-03],\n",
      "          [ 2.5366e-02, -7.7783e-03,  2.0469e-02]],\n",
      "\n",
      "         [[ 1.4130e-02, -4.6650e-03, -1.4911e-02],\n",
      "          [ 2.0928e-02,  2.4220e-02,  8.2898e-03],\n",
      "          [-2.2904e-02, -2.1577e-03, -2.2239e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4693e-02,  1.1965e-02, -1.8542e-02],\n",
      "          [-5.8377e-03, -1.4579e-02,  6.8075e-03],\n",
      "          [-1.4979e-02, -1.8469e-02, -1.1166e-03]],\n",
      "\n",
      "         [[-3.4813e-03, -8.2742e-03, -1.5975e-02],\n",
      "          [-1.1689e-03, -8.2216e-03,  1.0616e-02],\n",
      "          [-1.0759e-02, -2.4430e-02,  1.5481e-02]],\n",
      "\n",
      "         [[ 2.2271e-02, -1.7391e-02,  2.0088e-02],\n",
      "          [-2.2453e-02, -9.0483e-03,  1.3342e-02],\n",
      "          [ 1.1837e-03,  3.1349e-03,  4.0185e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2433e-02,  1.2449e-02, -1.9730e-02],\n",
      "          [-1.8092e-03,  1.6549e-02,  2.2998e-02],\n",
      "          [-3.8438e-05,  2.0906e-02,  3.8444e-03]],\n",
      "\n",
      "         [[-5.8397e-03,  2.2368e-02,  1.0588e-02],\n",
      "          [ 6.9692e-03,  2.1083e-02,  2.4070e-02],\n",
      "          [ 1.2328e-02,  5.4379e-03, -4.2587e-03]],\n",
      "\n",
      "         [[-6.3649e-03, -3.9339e-04,  5.6901e-03],\n",
      "          [-1.8434e-02,  1.8902e-02, -1.2032e-02],\n",
      "          [-1.1395e-03,  1.4175e-02,  2.3987e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.6426e-03,  9.4038e-03,  6.8690e-03],\n",
      "          [-2.1645e-02,  2.4637e-02, -2.0031e-02],\n",
      "          [ 1.4096e-02,  5.3370e-03,  2.2710e-02]],\n",
      "\n",
      "         [[ 2.2187e-02, -3.0327e-03,  2.4611e-02],\n",
      "          [-2.1149e-02,  2.2443e-02, -9.0300e-04],\n",
      "          [ 9.1790e-03,  1.7799e-04,  1.2856e-02]],\n",
      "\n",
      "         [[ 2.5254e-02,  2.0264e-03,  2.3736e-02],\n",
      "          [-2.0742e-02, -2.2513e-02,  1.4794e-02],\n",
      "          [ 1.4715e-02, -1.5355e-02, -1.1156e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0050]],\n",
      "\n",
      "         [[ 0.0290]],\n",
      "\n",
      "         [[ 0.0386]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0016]],\n",
      "\n",
      "         [[ 0.0300]],\n",
      "\n",
      "         [[-0.0104]]],\n",
      "\n",
      "\n",
      "        [[[-0.0043]],\n",
      "\n",
      "         [[-0.0009]],\n",
      "\n",
      "         [[ 0.0352]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0466]],\n",
      "\n",
      "         [[-0.0402]],\n",
      "\n",
      "         [[-0.0324]]],\n",
      "\n",
      "\n",
      "        [[[-0.0010]],\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         [[ 0.0207]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0181]],\n",
      "\n",
      "         [[-0.0163]],\n",
      "\n",
      "         [[ 0.0443]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0045]],\n",
      "\n",
      "         [[ 0.0161]],\n",
      "\n",
      "         [[-0.0232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0394]],\n",
      "\n",
      "         [[ 0.0169]],\n",
      "\n",
      "         [[ 0.0036]]],\n",
      "\n",
      "\n",
      "        [[[-0.0176]],\n",
      "\n",
      "         [[-0.0480]],\n",
      "\n",
      "         [[-0.0143]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0041]],\n",
      "\n",
      "         [[-0.0064]],\n",
      "\n",
      "         [[ 0.0364]]],\n",
      "\n",
      "\n",
      "        [[[-0.0470]],\n",
      "\n",
      "         [[ 0.0061]],\n",
      "\n",
      "         [[ 0.0007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0099]],\n",
      "\n",
      "         [[-0.0287]],\n",
      "\n",
      "         [[-0.0148]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0257]],\n",
      "\n",
      "         [[ 0.0133]],\n",
      "\n",
      "         [[ 0.0226]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0316]],\n",
      "\n",
      "         [[ 0.0349]],\n",
      "\n",
      "         [[-0.0147]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0059]],\n",
      "\n",
      "         [[ 0.0366]],\n",
      "\n",
      "         [[ 0.0054]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0197]],\n",
      "\n",
      "         [[-0.0068]],\n",
      "\n",
      "         [[-0.0384]]],\n",
      "\n",
      "\n",
      "        [[[-0.0138]],\n",
      "\n",
      "         [[ 0.0153]],\n",
      "\n",
      "         [[-0.0141]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0125]],\n",
      "\n",
      "         [[ 0.0124]],\n",
      "\n",
      "         [[-0.0441]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0261]],\n",
      "\n",
      "         [[ 0.0048]],\n",
      "\n",
      "         [[ 0.0420]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0413]],\n",
      "\n",
      "         [[-0.0477]],\n",
      "\n",
      "         [[ 0.0334]]],\n",
      "\n",
      "\n",
      "        [[[-0.0093]],\n",
      "\n",
      "         [[-0.0369]],\n",
      "\n",
      "         [[ 0.0364]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0376]],\n",
      "\n",
      "         [[ 0.0464]],\n",
      "\n",
      "         [[-0.0225]]],\n",
      "\n",
      "\n",
      "        [[[-0.0147]],\n",
      "\n",
      "         [[-0.0208]],\n",
      "\n",
      "         [[ 0.0401]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0250]],\n",
      "\n",
      "         [[-0.0173]],\n",
      "\n",
      "         [[-0.0034]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-7.5005e-03, -1.8976e-02, -1.7033e-02],\n",
      "          [-2.3920e-02,  1.6242e-02, -7.7935e-03],\n",
      "          [ 5.2746e-03,  7.0828e-03,  1.6501e-03]],\n",
      "\n",
      "         [[ 1.6647e-03, -6.6069e-03, -1.4863e-02],\n",
      "          [-1.2214e-02, -1.6674e-02,  7.1490e-03],\n",
      "          [ 7.5549e-03,  1.6343e-02,  8.6085e-03]],\n",
      "\n",
      "         [[ 1.9618e-02, -1.8664e-02,  3.1173e-03],\n",
      "          [ 2.1349e-02,  1.6973e-02,  1.9610e-03],\n",
      "          [ 8.4438e-03,  8.0934e-03, -2.3811e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9398e-02, -1.3319e-02, -1.7535e-03],\n",
      "          [-3.8645e-03, -1.5820e-02, -9.8651e-03],\n",
      "          [ 1.3828e-03,  1.3075e-02, -4.4122e-03]],\n",
      "\n",
      "         [[-1.5716e-02, -2.0333e-02, -1.7809e-02],\n",
      "          [ 1.4910e-02,  2.1940e-02, -1.9281e-05],\n",
      "          [ 6.9718e-03,  2.2056e-02, -2.3524e-02]],\n",
      "\n",
      "         [[-9.1965e-03, -1.2295e-02,  1.6367e-02],\n",
      "          [ 3.5268e-03,  5.9402e-03,  6.8713e-03],\n",
      "          [-2.0079e-02,  4.1488e-03,  1.4178e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5093e-02,  1.8841e-02,  6.2258e-03],\n",
      "          [ 6.7188e-03, -5.2246e-03,  1.1774e-02],\n",
      "          [-3.2651e-03,  1.8890e-02, -1.2260e-02]],\n",
      "\n",
      "         [[ 1.9948e-02,  2.3002e-02, -2.4668e-02],\n",
      "          [-2.3388e-02, -2.6467e-03, -1.6850e-02],\n",
      "          [-5.8430e-03,  1.9120e-02, -2.4258e-02]],\n",
      "\n",
      "         [[ 2.1312e-02,  1.8250e-02,  5.5411e-03],\n",
      "          [ 5.8912e-03,  2.8394e-03,  2.2936e-02],\n",
      "          [ 2.0228e-03,  5.3749e-03, -5.3104e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3427e-02,  1.2732e-02,  2.4756e-02],\n",
      "          [ 1.7902e-02,  1.3170e-02,  4.0913e-03],\n",
      "          [-2.0109e-02,  1.6356e-02,  1.8475e-02]],\n",
      "\n",
      "         [[-7.4137e-03,  1.8807e-02, -9.1838e-03],\n",
      "          [-1.7585e-02, -1.3437e-02,  2.3131e-02],\n",
      "          [-2.2411e-02, -4.8162e-03,  2.1441e-02]],\n",
      "\n",
      "         [[-1.5176e-02,  1.6702e-02, -1.4656e-02],\n",
      "          [-1.3767e-02, -5.6806e-03, -1.6419e-02],\n",
      "          [ 4.0547e-03,  1.7499e-02, -4.3864e-05]]],\n",
      "\n",
      "\n",
      "        [[[-1.9738e-02, -2.0597e-02, -8.4984e-03],\n",
      "          [ 1.2143e-02, -1.5741e-02, -1.9104e-02],\n",
      "          [-2.0623e-02,  1.3120e-02,  1.6820e-02]],\n",
      "\n",
      "         [[ 1.7489e-02,  2.3969e-02, -1.2319e-02],\n",
      "          [-2.4555e-02,  8.3270e-03, -1.8331e-02],\n",
      "          [-1.5584e-02, -1.1564e-02,  4.0510e-03]],\n",
      "\n",
      "         [[ 2.0785e-02, -2.5510e-02, -1.7585e-02],\n",
      "          [-9.5628e-05, -1.1990e-02,  9.5542e-03],\n",
      "          [ 4.7636e-03, -1.9386e-02,  8.7424e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.6800e-03, -1.2091e-02, -1.3085e-02],\n",
      "          [-2.0833e-02, -1.8277e-03, -1.3668e-02],\n",
      "          [-4.2707e-03,  1.1847e-02, -2.2781e-02]],\n",
      "\n",
      "         [[-4.8748e-03,  7.3881e-04,  1.0324e-02],\n",
      "          [-2.0901e-02, -1.9927e-02, -1.5582e-02],\n",
      "          [-1.6386e-02, -1.8820e-02,  4.2887e-03]],\n",
      "\n",
      "         [[ 2.0484e-02,  9.0273e-03,  4.5385e-04],\n",
      "          [ 3.3558e-03,  7.3601e-03,  7.3918e-03],\n",
      "          [ 3.8188e-03, -8.7465e-03,  7.0767e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.9279e-03,  8.1713e-03,  8.1988e-03],\n",
      "          [ 1.6109e-02, -2.4280e-02, -1.4722e-02],\n",
      "          [-2.5424e-03,  1.8947e-02, -2.0300e-02]],\n",
      "\n",
      "         [[ 3.6109e-03,  2.1417e-02,  1.7869e-02],\n",
      "          [ 2.2869e-02,  2.0764e-02, -1.4523e-04],\n",
      "          [-2.0782e-02, -1.6354e-02, -2.3310e-03]],\n",
      "\n",
      "         [[ 5.3483e-03,  1.0233e-02, -2.2613e-02],\n",
      "          [-1.2601e-02,  2.2307e-02, -2.2597e-02],\n",
      "          [-9.7221e-03,  8.9464e-03, -9.4382e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.1288e-03,  1.8342e-03, -4.8803e-03],\n",
      "          [ 1.4192e-02, -7.3792e-03,  6.4627e-03],\n",
      "          [ 2.2023e-02,  3.4180e-03,  3.9842e-04]],\n",
      "\n",
      "         [[ 1.5953e-02,  1.6386e-02, -4.7358e-03],\n",
      "          [-3.3937e-03, -3.3739e-03, -2.0610e-04],\n",
      "          [ 1.8241e-02, -2.4851e-02,  1.2939e-05]],\n",
      "\n",
      "         [[-1.3943e-02, -1.7525e-02, -2.1582e-02],\n",
      "          [ 1.4474e-02, -1.6580e-02, -1.9492e-02],\n",
      "          [-4.5286e-04,  4.1984e-03, -3.9736e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2891e-04,  1.9070e-02,  5.8217e-04],\n",
      "          [-1.3725e-02, -2.1320e-02, -1.8985e-02],\n",
      "          [-1.9055e-02,  2.2387e-02,  2.1252e-02]],\n",
      "\n",
      "         [[-2.7367e-03,  1.7129e-02, -9.0084e-03],\n",
      "          [ 1.3183e-02, -1.8254e-02,  1.0260e-03],\n",
      "          [-2.4341e-02,  1.1405e-02, -4.8428e-03]],\n",
      "\n",
      "         [[-2.5235e-02,  1.5915e-02,  2.1294e-02],\n",
      "          [-2.0994e-03, -1.2894e-02, -2.3752e-02],\n",
      "          [-1.3188e-02,  3.7076e-03, -1.6222e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.6862e-03, -2.2371e-02,  2.1168e-02],\n",
      "          [ 2.3449e-02, -2.0467e-02,  8.2646e-03],\n",
      "          [ 1.2965e-03, -2.4942e-02, -1.9558e-02]],\n",
      "\n",
      "         [[-2.2748e-02, -1.4285e-02,  1.6123e-02],\n",
      "          [-2.2915e-02,  1.2914e-02, -1.4119e-02],\n",
      "          [-7.1716e-03, -1.2647e-03,  1.0940e-02]],\n",
      "\n",
      "         [[-1.8793e-02, -2.4261e-02,  2.2367e-02],\n",
      "          [-1.3905e-02, -2.2364e-02,  5.5541e-03],\n",
      "          [ 2.4330e-02, -3.0495e-03,  1.6988e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5666e-02, -2.3832e-02,  4.2561e-03],\n",
      "          [-2.5077e-02, -7.0324e-03, -1.8295e-02],\n",
      "          [-9.7904e-03, -9.6809e-03,  1.1434e-04]],\n",
      "\n",
      "         [[-2.3151e-03,  3.0680e-03,  1.8997e-02],\n",
      "          [-1.6922e-02, -2.2110e-03,  2.0499e-02],\n",
      "          [-7.4925e-03, -4.3709e-06, -4.0369e-03]],\n",
      "\n",
      "         [[ 8.2426e-03,  2.1495e-02, -5.9972e-03],\n",
      "          [ 1.2602e-02, -1.3538e-02, -4.3765e-03],\n",
      "          [-1.4142e-02, -6.5953e-03,  2.2999e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4962e-02, -1.9368e-02, -1.1433e-02],\n",
      "          [-2.2227e-02,  3.0755e-03, -1.2061e-02],\n",
      "          [ 2.5426e-02,  1.3583e-02,  1.8095e-02]],\n",
      "\n",
      "         [[-7.6607e-03,  1.7238e-02, -5.5156e-03],\n",
      "          [ 2.4608e-02, -1.9216e-03, -2.4209e-02],\n",
      "          [-3.7275e-03, -7.5010e-03, -1.5281e-02]],\n",
      "\n",
      "         [[ 7.4292e-03,  1.2458e-02,  1.9702e-02],\n",
      "          [-1.4860e-02,  6.9414e-03, -8.8173e-03],\n",
      "          [-1.6829e-02, -4.4016e-03, -1.4984e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0476]],\n",
      "\n",
      "         [[-0.0254]],\n",
      "\n",
      "         [[-0.0061]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0052]],\n",
      "\n",
      "         [[ 0.0381]],\n",
      "\n",
      "         [[-0.0329]]],\n",
      "\n",
      "\n",
      "        [[[-0.0118]],\n",
      "\n",
      "         [[ 0.0382]],\n",
      "\n",
      "         [[-0.0054]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         [[-0.0118]],\n",
      "\n",
      "         [[-0.0375]]],\n",
      "\n",
      "\n",
      "        [[[-0.0069]],\n",
      "\n",
      "         [[ 0.0220]],\n",
      "\n",
      "         [[-0.0073]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0013]],\n",
      "\n",
      "         [[-0.0216]],\n",
      "\n",
      "         [[ 0.0040]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0303]],\n",
      "\n",
      "         [[-0.0205]],\n",
      "\n",
      "         [[-0.0437]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0022]],\n",
      "\n",
      "         [[ 0.0454]],\n",
      "\n",
      "         [[ 0.0045]]],\n",
      "\n",
      "\n",
      "        [[[-0.0383]],\n",
      "\n",
      "         [[ 0.0061]],\n",
      "\n",
      "         [[-0.0282]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0227]],\n",
      "\n",
      "         [[ 0.0431]],\n",
      "\n",
      "         [[ 0.0140]]],\n",
      "\n",
      "\n",
      "        [[[-0.0298]],\n",
      "\n",
      "         [[-0.0085]],\n",
      "\n",
      "         [[-0.0425]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0422]],\n",
      "\n",
      "         [[-0.0262]],\n",
      "\n",
      "         [[-0.0177]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-1.2019e-02,  8.7907e-03,  1.2037e-02],\n",
      "          [ 1.1765e-02, -1.9583e-03, -4.9230e-03],\n",
      "          [-1.0355e-02, -3.7789e-03,  3.1636e-03]],\n",
      "\n",
      "         [[ 5.6746e-04, -2.7969e-03, -1.0658e-02],\n",
      "          [ 5.7705e-03,  8.9282e-03, -5.6131e-03],\n",
      "          [ 1.0000e-02,  2.5649e-03, -1.2226e-03]],\n",
      "\n",
      "         [[ 1.1564e-02,  9.7092e-03,  4.4589e-03],\n",
      "          [-9.8455e-03,  1.2407e-02, -9.5579e-03],\n",
      "          [-6.7910e-03,  1.2444e-02,  4.3143e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7713e-03,  1.1632e-02, -9.7348e-03],\n",
      "          [-6.1757e-04, -7.6612e-03,  2.3752e-03],\n",
      "          [-3.2926e-03, -6.3145e-03,  6.8634e-03]],\n",
      "\n",
      "         [[ 1.1984e-02,  1.0163e-04,  1.2514e-02],\n",
      "          [-2.7251e-03, -3.4172e-03, -5.5911e-03],\n",
      "          [ 1.1646e-02,  7.4072e-03, -1.1799e-02]],\n",
      "\n",
      "         [[ 8.2270e-03,  1.0796e-03,  9.5853e-03],\n",
      "          [ 4.7451e-03, -4.4556e-03,  5.8045e-03],\n",
      "          [ 9.6110e-03,  2.8122e-03, -7.9940e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.9659e-03,  1.0130e-02,  9.6650e-03],\n",
      "          [-5.5676e-04, -1.1416e-02, -8.2422e-03],\n",
      "          [ 9.9433e-06,  1.6383e-03,  4.9438e-03]],\n",
      "\n",
      "         [[ 2.0873e-03,  1.3685e-04, -9.8325e-04],\n",
      "          [ 2.3591e-03,  7.7008e-03,  3.7069e-03],\n",
      "          [-6.2664e-03,  8.2796e-03,  8.7541e-03]],\n",
      "\n",
      "         [[ 3.4793e-03, -6.0325e-03, -4.4540e-03],\n",
      "          [-1.1317e-02, -6.3162e-03,  9.4732e-03],\n",
      "          [-9.8354e-03, -1.0748e-02, -8.4839e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.5549e-03, -1.9932e-05, -1.7189e-03],\n",
      "          [-1.0281e-02,  8.4368e-03,  6.9358e-03],\n",
      "          [-3.9732e-03,  8.0254e-03, -7.5435e-03]],\n",
      "\n",
      "         [[-6.7520e-03,  1.2076e-02, -9.2919e-03],\n",
      "          [-1.1994e-02, -6.4063e-03, -1.0302e-02],\n",
      "          [-4.9343e-03, -7.4564e-03, -6.3518e-03]],\n",
      "\n",
      "         [[ 6.5537e-03, -2.6992e-03,  1.1956e-03],\n",
      "          [-6.4050e-03,  1.2560e-02, -1.1080e-02],\n",
      "          [ 9.3797e-03, -4.8018e-03, -7.2456e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3474e-03, -1.2499e-02,  2.6702e-03],\n",
      "          [-6.5499e-03, -1.2484e-02, -1.0563e-02],\n",
      "          [ 4.0664e-03,  5.4232e-03, -9.3217e-03]],\n",
      "\n",
      "         [[ 7.2945e-03,  4.5301e-03, -5.1989e-03],\n",
      "          [ 1.1250e-02,  4.1316e-03,  1.1108e-02],\n",
      "          [-1.0566e-02, -1.0060e-02,  6.5752e-03]],\n",
      "\n",
      "         [[-2.2637e-03, -9.9576e-03, -9.5069e-03],\n",
      "          [ 5.7406e-03,  1.1710e-02,  1.2254e-02],\n",
      "          [-1.0891e-02, -1.2647e-02, -1.1936e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1808e-03,  1.0416e-03,  1.1288e-02],\n",
      "          [ 1.0623e-02,  3.0893e-03, -5.8280e-03],\n",
      "          [-8.2672e-03,  8.8361e-03,  8.4412e-03]],\n",
      "\n",
      "         [[ 6.0328e-03,  5.5478e-03,  5.6188e-03],\n",
      "          [-4.2115e-03,  7.9793e-03, -1.0758e-02],\n",
      "          [-5.1099e-03, -7.1361e-03, -2.1080e-03]],\n",
      "\n",
      "         [[-8.5992e-03,  3.6191e-03,  7.4691e-03],\n",
      "          [ 2.9377e-03,  1.1545e-02, -1.0693e-02],\n",
      "          [-1.2580e-02, -8.8351e-03,  7.0577e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.1935e-03, -1.1326e-02, -1.3663e-03],\n",
      "          [ 7.9664e-03,  7.5219e-03,  8.8653e-03],\n",
      "          [-4.6129e-03,  8.5696e-03, -3.5877e-03]],\n",
      "\n",
      "         [[ 9.9850e-03,  1.0615e-02, -6.0920e-04],\n",
      "          [-4.1854e-03, -2.7934e-04, -5.7285e-03],\n",
      "          [ 3.6641e-03,  6.4349e-03,  2.0443e-03]],\n",
      "\n",
      "         [[ 2.7224e-03,  7.3601e-05, -5.0526e-03],\n",
      "          [-2.5321e-03, -1.0967e-02,  6.0564e-03],\n",
      "          [-1.1700e-02, -1.2199e-02,  8.7465e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1061e-02, -7.1700e-04, -2.6152e-03],\n",
      "          [-3.0554e-03, -1.0957e-02,  6.2390e-03],\n",
      "          [ 8.2750e-03, -3.8072e-04,  4.8661e-03]],\n",
      "\n",
      "         [[-4.5384e-03,  1.1293e-02, -9.3221e-03],\n",
      "          [-1.0013e-02,  5.9215e-03, -9.1247e-03],\n",
      "          [ 5.6965e-04,  1.1032e-03,  1.1858e-02]],\n",
      "\n",
      "         [[ 9.5256e-03, -5.1079e-03, -7.3875e-03],\n",
      "          [-1.0319e-02, -1.3458e-03, -8.8370e-03],\n",
      "          [ 1.2395e-03, -8.2114e-03,  1.7236e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.8194e-03, -8.1616e-04, -3.0823e-03],\n",
      "          [ 4.1601e-03,  2.6384e-03, -8.5480e-03],\n",
      "          [-1.2755e-02,  9.2673e-03, -1.2044e-03]],\n",
      "\n",
      "         [[-6.3128e-03, -1.2293e-02,  4.5932e-03],\n",
      "          [-6.6301e-03, -9.3864e-03, -3.7374e-03],\n",
      "          [ 1.5661e-03,  7.1290e-03, -3.3347e-03]],\n",
      "\n",
      "         [[-3.5736e-03, -4.1524e-03,  6.9508e-03],\n",
      "          [ 1.0881e-02,  8.8642e-03, -5.9429e-03],\n",
      "          [-1.1035e-02,  6.5877e-03, -7.9665e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3724e-03,  7.5369e-03, -9.8010e-03],\n",
      "          [-6.3096e-03,  1.1365e-02, -6.3969e-03],\n",
      "          [-8.9894e-03, -1.1952e-02, -1.6585e-03]],\n",
      "\n",
      "         [[-6.5682e-03, -3.5214e-03, -5.4052e-03],\n",
      "          [ 3.7626e-03,  9.9656e-03,  8.0270e-03],\n",
      "          [ 1.1359e-02, -9.4336e-03,  2.0645e-04]],\n",
      "\n",
      "         [[-1.1138e-02,  1.7454e-03, -1.0673e-04],\n",
      "          [-9.7097e-03, -9.3019e-03,  9.0588e-03],\n",
      "          [ 9.2920e-03, -6.1730e-03,  1.2165e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3123e-03,  1.8603e-03, -7.2983e-03],\n",
      "          [-7.0898e-03,  6.2824e-03, -1.1286e-02],\n",
      "          [ 9.3482e-03,  4.9974e-04,  2.6568e-03]],\n",
      "\n",
      "         [[-6.6260e-03,  1.1365e-02,  1.6276e-03],\n",
      "          [ 8.8920e-04,  1.0586e-02, -7.3402e-03],\n",
      "          [ 1.2501e-02,  3.4825e-03, -1.5644e-03]],\n",
      "\n",
      "         [[ 6.2387e-03,  5.1789e-03,  7.4074e-03],\n",
      "          [-5.8536e-03, -9.4335e-03,  3.7539e-03],\n",
      "          [ 6.7568e-03, -7.4904e-03, -2.5916e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.9694e-03,  6.2800e-03, -7.3224e-03],\n",
      "          [-2.4496e-05, -5.7018e-03,  1.1076e-02],\n",
      "          [-1.0539e-02, -1.0625e-02, -1.1235e-02]],\n",
      "\n",
      "         [[ 2.3085e-03, -6.4150e-03,  1.1753e-02],\n",
      "          [-2.6284e-03,  1.0424e-02,  3.2530e-03],\n",
      "          [-2.8428e-03, -7.9811e-03,  1.0347e-02]],\n",
      "\n",
      "         [[-3.6918e-03, -9.6061e-03,  4.0477e-04],\n",
      "          [-3.6721e-03, -6.0170e-03,  3.6510e-03],\n",
      "          [ 3.0816e-03, -3.7117e-03,  8.6408e-03]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-5.5375e-03, -6.4438e-03,  5.9393e-03],\n",
      "          [-6.1711e-03,  2.6523e-04, -5.3612e-03],\n",
      "          [-1.1633e-02, -1.2736e-02,  1.1110e-03]],\n",
      "\n",
      "         [[ 5.0947e-03,  1.2598e-02, -1.8448e-03],\n",
      "          [-1.2351e-02,  3.2218e-03,  9.2766e-04],\n",
      "          [-5.2905e-03, -6.1876e-03, -3.6337e-03]],\n",
      "\n",
      "         [[ 7.7185e-03, -5.8903e-03, -6.9528e-03],\n",
      "          [ 2.1740e-03, -8.9523e-03,  1.2627e-02],\n",
      "          [ 2.0006e-03,  8.3434e-03,  6.6989e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.6918e-03, -9.1071e-05,  7.7535e-03],\n",
      "          [-4.0077e-03,  1.1595e-02, -1.2128e-03],\n",
      "          [-6.4498e-03,  6.5417e-03,  2.5156e-03]],\n",
      "\n",
      "         [[ 8.7678e-03,  2.2064e-04, -4.0268e-03],\n",
      "          [-2.4067e-03,  3.2901e-03, -5.1872e-03],\n",
      "          [ 9.3284e-03,  3.8520e-03,  9.7748e-03]],\n",
      "\n",
      "         [[-6.2813e-03, -4.6567e-03, -5.6561e-03],\n",
      "          [ 8.7703e-03, -5.9192e-03,  5.4509e-03],\n",
      "          [ 1.0818e-02, -4.2724e-03, -1.0802e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5456e-03,  4.0202e-03, -2.7246e-04],\n",
      "          [-6.1756e-03, -1.0753e-02,  3.1871e-03],\n",
      "          [-1.1530e-02, -2.7159e-03, -1.1131e-02]],\n",
      "\n",
      "         [[ 1.1152e-02, -1.3308e-03,  7.5543e-03],\n",
      "          [-9.4838e-03,  1.0578e-02, -9.2572e-03],\n",
      "          [ 1.0198e-02,  2.4166e-03,  4.5597e-04]],\n",
      "\n",
      "         [[ 3.3478e-03, -1.2008e-02, -3.9663e-03],\n",
      "          [ 1.8935e-06, -6.4566e-04,  3.0223e-03],\n",
      "          [-1.2210e-02, -2.2812e-03, -4.5645e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5294e-03, -1.2744e-02, -3.8448e-03],\n",
      "          [ 1.0132e-02, -4.6935e-03, -3.6374e-03],\n",
      "          [-1.2605e-02, -1.2084e-02,  1.2353e-02]],\n",
      "\n",
      "         [[ 4.0096e-03,  7.6640e-03, -4.6891e-03],\n",
      "          [ 9.0707e-03, -1.2433e-02, -4.5323e-03],\n",
      "          [-6.8621e-03,  2.3516e-03,  2.0940e-03]],\n",
      "\n",
      "         [[-1.3311e-03,  1.2149e-02,  1.2370e-02],\n",
      "          [-9.0692e-03,  5.2072e-03, -1.2357e-02],\n",
      "          [-1.0468e-02, -5.9064e-03, -7.5448e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5808e-03, -1.0420e-02, -1.2252e-02],\n",
      "          [ 9.9374e-03,  8.1895e-03, -9.4422e-04],\n",
      "          [ 1.5411e-03, -7.1749e-03,  1.0859e-02]],\n",
      "\n",
      "         [[ 3.4788e-03, -5.0634e-03, -9.1928e-03],\n",
      "          [ 8.3405e-03,  2.3159e-03,  3.8014e-03],\n",
      "          [-6.9947e-03, -4.5341e-04, -6.9621e-03]],\n",
      "\n",
      "         [[-2.7185e-03,  1.2312e-02,  4.6760e-03],\n",
      "          [ 1.8977e-03, -7.0709e-03, -9.0397e-03],\n",
      "          [-6.9679e-03, -1.0956e-02, -7.5684e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.1565e-03, -7.0766e-03, -2.9382e-03],\n",
      "          [-1.1168e-02,  6.4904e-03, -1.1341e-02],\n",
      "          [ 3.3805e-03, -6.5386e-03,  7.4563e-03]],\n",
      "\n",
      "         [[-1.2514e-02, -6.1550e-03, -5.5469e-03],\n",
      "          [-1.2068e-02,  6.4668e-03, -1.0373e-02],\n",
      "          [-7.0416e-03, -1.7325e-03,  1.2143e-02]],\n",
      "\n",
      "         [[-1.1075e-02, -4.3973e-03,  1.2465e-02],\n",
      "          [-1.0334e-02, -4.3809e-03,  8.1839e-03],\n",
      "          [-1.2641e-02, -3.7047e-03, -1.2523e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.9698e-03,  1.0080e-02, -4.8416e-03],\n",
      "          [-9.0273e-03,  8.2433e-03, -9.0187e-03],\n",
      "          [ 4.4486e-03,  7.3915e-03, -1.1802e-02]],\n",
      "\n",
      "         [[ 3.0781e-03, -1.2592e-02, -7.1782e-03],\n",
      "          [-1.1625e-02,  1.6471e-03, -8.0320e-03],\n",
      "          [ 1.0209e-02,  5.6716e-03, -1.4106e-04]],\n",
      "\n",
      "         [[-9.7922e-03,  1.2067e-02, -3.8897e-03],\n",
      "          [ 1.1827e-02,  1.0138e-02,  7.2376e-03],\n",
      "          [ 5.7177e-03, -2.0243e-03,  5.1314e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.2960e-03,  1.2513e-02, -6.0536e-03],\n",
      "          [ 9.8574e-03,  3.6272e-03,  1.2380e-02],\n",
      "          [ 1.0779e-02,  6.5991e-04,  6.4952e-03]],\n",
      "\n",
      "         [[ 1.0422e-02, -7.2286e-03,  1.0568e-02],\n",
      "          [-1.1518e-02, -1.2091e-02,  1.1276e-02],\n",
      "          [ 1.0742e-02,  1.3576e-03, -1.0131e-02]],\n",
      "\n",
      "         [[-5.4576e-03, -2.8579e-03,  1.6737e-03],\n",
      "          [ 1.2058e-02, -8.4247e-03, -1.0141e-02],\n",
      "          [-6.0823e-03, -4.3232e-03, -6.7188e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0889e-04,  6.9482e-03, -8.4406e-03],\n",
      "          [ 4.0801e-03,  2.8784e-04,  8.9259e-03],\n",
      "          [-8.0421e-03,  1.0053e-02,  5.4183e-03]],\n",
      "\n",
      "         [[ 3.0574e-04,  2.2529e-03,  1.0031e-02],\n",
      "          [ 5.6536e-04,  9.0564e-04,  2.2976e-03],\n",
      "          [-9.9441e-03, -1.2433e-02,  8.7658e-03]],\n",
      "\n",
      "         [[-5.2150e-03,  5.0329e-03, -2.3461e-03],\n",
      "          [ 8.5127e-03,  9.2210e-03, -1.2284e-02],\n",
      "          [ 6.9484e-03, -5.7239e-03, -3.8850e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1609e-03, -5.7220e-03,  1.1371e-02],\n",
      "          [ 1.0113e-02,  6.1259e-04,  1.2516e-02],\n",
      "          [ 8.2905e-03,  7.4937e-03,  7.5967e-03]],\n",
      "\n",
      "         [[-6.0641e-03,  9.7982e-03, -2.5993e-03],\n",
      "          [-1.2564e-02, -6.1586e-04, -3.4356e-03],\n",
      "          [ 6.4952e-03,  7.7168e-03, -1.2753e-02]],\n",
      "\n",
      "         [[ 2.7948e-03, -7.9427e-03,  1.4460e-03],\n",
      "          [ 1.0706e-02,  7.1102e-04, -5.1530e-03],\n",
      "          [ 5.5393e-03,  8.6020e-03,  1.0396e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3907e-03, -9.5251e-03, -5.9105e-03],\n",
      "          [ 1.0734e-02,  1.1256e-02, -1.1750e-02],\n",
      "          [-5.0790e-03,  2.6908e-03,  7.6013e-03]],\n",
      "\n",
      "         [[-1.2252e-02, -1.0510e-02, -3.0132e-05],\n",
      "          [ 5.5670e-03,  4.1933e-03,  1.0895e-02],\n",
      "          [ 1.5293e-03, -7.0967e-03, -9.1919e-03]],\n",
      "\n",
      "         [[-1.1461e-02,  1.1181e-02,  8.7375e-04],\n",
      "          [ 9.6097e-03,  6.1023e-03,  2.5485e-03],\n",
      "          [-9.6054e-03, -9.0837e-03,  8.0990e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5170e-03,  1.2683e-02,  9.7495e-03],\n",
      "          [ 2.8811e-03, -7.4330e-03, -9.8610e-03],\n",
      "          [-4.0855e-03,  6.0132e-03, -5.4537e-03]],\n",
      "\n",
      "         [[-7.0907e-03,  9.8316e-03, -1.1740e-02],\n",
      "          [-7.3071e-03,  5.7712e-03, -6.9765e-03],\n",
      "          [-5.4605e-03, -9.3492e-03, -6.0726e-03]],\n",
      "\n",
      "         [[-9.7955e-03,  9.2115e-03,  1.2764e-03],\n",
      "          [-1.1225e-02,  5.0114e-03,  2.3905e-04],\n",
      "          [ 9.0627e-03,  4.8860e-03, -9.3228e-03]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 3.5487e-02,  6.5704e-03, -1.1536e-02,  ...,  1.7244e-02,\n",
      "         -1.3876e-02,  1.9376e-02],\n",
      "        [-2.4490e-02, -3.7479e-02, -3.7165e-02,  ..., -3.2102e-02,\n",
      "         -1.3403e-02,  3.1006e-02],\n",
      "        [ 2.9258e-02, -3.0074e-02, -2.9449e-02,  ..., -2.7861e-02,\n",
      "          2.5015e-03, -3.7178e-02],\n",
      "        ...,\n",
      "        [-8.8750e-03, -1.4407e-02, -3.2405e-02,  ...,  2.5100e-02,\n",
      "         -2.9085e-02,  6.8586e-03],\n",
      "        [-1.6311e-02,  2.7552e-02,  4.0588e-05,  ...,  1.6142e-02,\n",
      "         -8.4220e-03, -7.9962e-03],\n",
      "        [-3.2436e-02,  5.9203e-03,  3.5821e-02,  ...,  3.5279e-02,\n",
      "         -9.8200e-03, -1.4307e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0111, -0.0414, -0.0353,  ..., -0.0371, -0.0182,  0.0218],\n",
      "        [ 0.0176,  0.0342, -0.0052,  ..., -0.0225,  0.0312,  0.0323],\n",
      "        [ 0.0478, -0.0049, -0.0148,  ..., -0.0059,  0.0166, -0.0256],\n",
      "        ...,\n",
      "        [ 0.0231, -0.0036, -0.0298,  ...,  0.0134,  0.0286,  0.0157],\n",
      "        [-0.0470,  0.0020,  0.0030,  ...,  0.0410, -0.0141,  0.0295],\n",
      "        [ 0.0364,  0.0449, -0.0476,  ..., -0.0133, -0.0031,  0.0465]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in resnet.parameters():\n",
    "    if re.search('')\n",
    "    param.requires_grad =  True\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c58c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "params= []\n",
    "for param in child.parameters():\n",
    "    params.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bf27574",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_block_after1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-654555278d1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m        \u001b[0mconv_block_after1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'conv_block_after1' is not defined"
     ]
    }
   ],
   "source": [
    "for child in resnet.children():\n",
    "       conv_block_after1.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85049d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet=Transfer_ResNet54(freeze_base=True,pretrain_checkpoint=\"/home/hj20/dcase_2020_T6/models/ResNet54_mAP=0.429.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d589a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:base.bn0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.bn0.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 1, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.conv_block1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.downsample.0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.0.downsample.1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer1.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.3.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.3.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer2.3.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.3.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.3.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.3.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.4.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.4.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.4.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.4.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.4.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.4.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.4.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.4.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.4.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.5.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.5.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.5.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.5.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.5.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.5.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.5.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.5.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer3.5.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 2048, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:base.resnet.layer4.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 2048, 1, 1])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.resnet.layer4.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.resnet.layer4.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.resnet.layer4.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.resnet.layer4.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.resnet.layer4.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.resnet.layer4.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.resnet.layer4.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.resnet.layer4.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block_after1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block_after1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block_after1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block_after1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block_after1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.conv_block_after1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.fc_audioset.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([527, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:base.fc_audioset.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([527])\n",
      "param.requries_grad:True\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "#model parameter 확인\n",
    "for name, param in resnet.named_parameters(): \n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str = 'Hello world, Python!'\n",
    "if str.startswith('Hello'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6db15c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea5aab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer , fc 풀기\n",
    "for name, param in resnet.named_parameters():\n",
    "    if name.startswith('base.resnet.layer4.2'):\n",
    "        param.requires_grad=True\n",
    "    \n",
    "    elif name.startswith('base.conv_block_after1'):\n",
    "        param.requires_grad=True\n",
    "    \n",
    "    elif name.startswith('base.fc'):\n",
    "        param.requires_grad=True\n",
    "    else:\n",
    "        param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1274d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_base=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70808b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn14,Transfer_Cnn14,init_layer\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, batch_size, dropout=0.5,pretrain_cnn=None,\n",
    "                 pretrain_emb=None,freeze_cnn=True):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.model_type = 'resnet+transformer'\n",
    "        decoder_layers = TransformerDecoderLayer(d_model=nhid, nhead=nhead, dropout=dropout)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "        self.word_emb = nn.Embedding(ntoken, nhid)\n",
    "        self.ninp = ninp\n",
    "        self.nhid = nhid\n",
    "        self.fc = nn.Linear(2048, 2048, bias=True)\n",
    "        self.fc1 = nn.Linear(2048, nhid, bias=True)\n",
    "        self.dec_fc = nn.Linear(nhid, ntoken)\n",
    "        self.batch_size = batch_size\n",
    "        self.ntoken = ntoken\n",
    "\n",
    "        #def __init__(self, freeze_base, pretrain_checkpoint=None):\n",
    "        pretrain_cnn=\"/home/hj20/dcase_2020_T6/models/ResNet54_mAP=0.429.pth\"\n",
    "        \n",
    "        #self.encoder = Transfer_ResNet54(freeze_base=freeze_cnn, pretrain_checkpoint=pretrain_cnn)\n",
    "        self.encoder = resnet\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pos_encoder = PositionalEncoding(nhid, dropout)\n",
    "        self.generator = nn.Softmax(dim=-1)\n",
    "        self.init_weights()\n",
    "\n",
    "        '''\n",
    "        if pretrain_cnn is not None:\n",
    "            dict_trained = pretrain_cnn\n",
    "            dict_new = self.encoder.state_dict().copy()\n",
    "            new_list = list(self.encoder.state_dict().keys())\n",
    "            trained_list = list(dict_trained.keys())\n",
    "            for i in range(len(new_list)):\n",
    "                dict_new[new_list[i]] = dict_trained[trained_list[i]]\n",
    "            self.encoder.load_state_dict(dict_new)\n",
    "        \n",
    "        if freeze_cnn:\n",
    "            self.freeze_cnn()\n",
    "        '''\n",
    "\n",
    "        if pretrain_emb is not None:\n",
    "            self.word_emb.weight.data = pretrain_emb\n",
    "\n",
    "    '''\n",
    "    def freeze_cnn(self):\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "    '''\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc)\n",
    "        self.word_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dec_fc.bias.data.zero_()\n",
    "        self.dec_fc.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def encode(self, src, input_mask=None):\n",
    "        global x \n",
    "        x = self.encoder(src)  # (batch_size, 2048, T/16, mel_bins/16) ,mixup\n",
    "        x = torch.mean(x, dim=3)  # (batch_size, 2048, T/16)\n",
    "        x = x.permute(2, 0, 1)  # (T/16,batch_size,2048)\n",
    "        x = F.relu_(self.fc(x))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "    def decode(self, mem, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # tgt:(batch_size,T_out)\n",
    "        # mem:(T_mem,batch_size,nhid)\n",
    "\n",
    "        tgt = tgt.transpose(0, 1)  # (T_out,batch_size)\n",
    "        if target_mask is None or target_mask.size(0) != len(tgt):\n",
    "            device = tgt.device\n",
    "            target_mask = self.generate_square_subsequent_mask(len(tgt)).to(device)\n",
    "\n",
    "        tgt = self.dropout(self.word_emb(tgt)) * math.sqrt(self.nhid)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        # mem = self.pos_encoder(mem)\n",
    "        output = self.transformer_decoder(tgt, mem, memory_mask=input_mask, tgt_mask=target_mask,\n",
    "                                          tgt_key_padding_mask=target_padding_mask)\n",
    "        output = self.dec_fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, src, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # src:(batch_size,T_in,feature_dim)\n",
    "        # tgt:(batch_size,T_out)\n",
    "        mem = self.encode(src)\n",
    "        output = self.decode(mem, tgt, input_mask=input_mask, target_mask=target_mask,\n",
    "                             target_padding_mask=target_padding_mask)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88e0614a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4e441f1990>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "from data_handling import get_clotho_loader, get_test_data_loader\n",
    "#from model import TransformerModel  # , RNNModel, RNNModelSmall\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "from util import get_file_list, get_padding, print_hparams, greedy_decode, \\\n",
    "    calculate_bleu, calculate_spider, LabelSmoothingLoss, beam_search, align_word_embedding, gen_str\n",
    "from hparams import hparams\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "\n",
    "hp = hparams()\n",
    "parser = argparse.ArgumentParser(description='hparams for model')\n",
    "\n",
    "device = torch.device('cuda')\n",
    "np.random.seed(hp.seed)\n",
    "torch.manual_seed(hp.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3166e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_emb = align_word_embedding(hp.word_dict_pickle_path, hp.pretrain_emb_path, hp.ntoken,\n",
    "                                        hp.nhid) if hp.load_pretrain_emb else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "476ccfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(hp.ntoken, hp.ninp, hp.nhead, hp.nhid, hp.nlayers, hp.batch_size, dropout=0.2,\n",
    "                             pretrain_cnn=\"/home/hj20/dcase_2020_T6/models/ResNet54_mAP=0.429.pth\", pretrain_emb=pretrain_emb, freeze_cnn=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3e6cadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_emb): Embedding(4371, 192)\n",
       "  (fc): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (fc1): Linear(in_features=2048, out_features=192, bias=True)\n",
       "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
       "  (encoder): Transfer_ResNet54(\n",
       "    (base): ResNet54(\n",
       "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_block1): ConvBlock(\n",
       "        (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (resnet): _ResNet(\n",
       "        (layer1): Sequential(\n",
       "          (0): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): _ResnetBottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_block_after1): ConvBlock(\n",
       "        (conv1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (fc_audioset): Linear(in_features=2048, out_features=527, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (generator): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14ee54d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:transformer_decoder.layers.0.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:word_emb.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.bn0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.bn0.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 1, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 2048, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 2048, 1, 1])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc_audioset.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([527, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc_audioset.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([527])\n",
      "param.requries_grad:True\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "#model parameter 확인\n",
    "for name, param in model.named_parameters(): \n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3255704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swa\n",
    "from torchcontrib.optim import SWA\n",
    "import torchcontrib\n",
    "\n",
    "base_opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=hp.lr, weight_decay=1e-6)\n",
    "optimizer = torchcontrib.optim.SWA(base_opt, swa_start=10, swa_freq=5, swa_lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, hp.scheduler_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b5da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swa 안할때\n",
    "optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=hp.lr, weight_decay=1e-6)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, hp.scheduler_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1809dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = hp.data_dir\n",
    "eval_data_dir = hp.eval_data_dir\n",
    "train_data_dir = hp.train_data_dir\n",
    "word_dict_pickle_path = hp.word_dict_pickle_path\n",
    "word_freq_pickle_path = hp.word_freq_pickle_path\n",
    "test_data_dir = hp.test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4fa72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixup\n",
    "#data_dir = hp.data_dir\n",
    "#eval_data_dir = hp.eval_data_dir\n",
    "#train_data_dir = hp.train_data_dir\n",
    "word_dict_pickle_path = hp.word_dict_pickle_path\n",
    "word_freq_pickle_path = hp.word_freq_pickle_path\n",
    "#test_data_dir = hp.test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cc2cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = get_clotho_loader(data_dir=data_dir, split='development',\n",
    "                                      input_field_name='features',\n",
    "                                      output_field_name='words_ind',\n",
    "                                      load_into_memory=False,\n",
    "                                      batch_size=hp.batch_size,\n",
    "                                      nb_t_steps_pad='max',\n",
    "                                      num_workers=4, return_reference=True, augment=hp.spec_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29c2b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3051 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3051 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전체 데이터 \n",
    "from tqdm import tqdm\n",
    "tqdm(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2304b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24420,\n",
       " 24739,\n",
       " 1,\n",
       " 718,\n",
       " 4808,\n",
       " 46,\n",
       " 16,\n",
       " 13138,\n",
       " 17,\n",
       " 24420,\n",
       " 45,\n",
       " 28,\n",
       " 71,\n",
       " 329,\n",
       " 873,\n",
       " 5,\n",
       " 7333,\n",
       " 12184,\n",
       " 768,\n",
       " 1,\n",
       " 97,\n",
       " 149,\n",
       " 45,\n",
       " 168,\n",
       " 132,\n",
       " 555,\n",
       " 1,\n",
       " 49,\n",
       " 3225,\n",
       " 1,\n",
       " 241,\n",
       " 1844,\n",
       " 9147,\n",
       " 81,\n",
       " 1,\n",
       " 991,\n",
       " 455,\n",
       " 14,\n",
       " 7,\n",
       " 3,\n",
       " 330,\n",
       " 1935,\n",
       " 36,\n",
       " 12,\n",
       " 62,\n",
       " 2,\n",
       " 3654,\n",
       " 258,\n",
       " 90,\n",
       " 84,\n",
       " 79,\n",
       " 2134,\n",
       " 1,\n",
       " 5,\n",
       " 75,\n",
       " 4060,\n",
       " 1703,\n",
       " 40,\n",
       " 2369,\n",
       " 468,\n",
       " 67,\n",
       " 630,\n",
       " 2,\n",
       " 114,\n",
       " 15,\n",
       " 5,\n",
       " 2986,\n",
       " 1905,\n",
       " 52,\n",
       " 481,\n",
       " 2,\n",
       " 5,\n",
       " 315,\n",
       " 3003,\n",
       " 121,\n",
       " 811,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 31,\n",
       " 2541,\n",
       " 15,\n",
       " 13,\n",
       " 172,\n",
       " 502,\n",
       " 567,\n",
       " 301,\n",
       " 844,\n",
       " 1,\n",
       " 2748,\n",
       " 2229,\n",
       " 28,\n",
       " 60,\n",
       " 133,\n",
       " 2,\n",
       " 423,\n",
       " 262,\n",
       " 88,\n",
       " 52,\n",
       " 1,\n",
       " 806,\n",
       " 282,\n",
       " 22,\n",
       " 211,\n",
       " 41,\n",
       " 759,\n",
       " 447,\n",
       " 338,\n",
       " 142,\n",
       " 454,\n",
       " 2337,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 22,\n",
       " 1,\n",
       " 129,\n",
       " 23,\n",
       " 268,\n",
       " 809,\n",
       " 692,\n",
       " 630,\n",
       " 417,\n",
       " 3,\n",
       " 148,\n",
       " 20,\n",
       " 55,\n",
       " 91,\n",
       " 38,\n",
       " 241,\n",
       " 2309,\n",
       " 783,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 52,\n",
       " 2,\n",
       " 134,\n",
       " 428,\n",
       " 107,\n",
       " 25,\n",
       " 1,\n",
       " 461,\n",
       " 11,\n",
       " 129,\n",
       " 36,\n",
       " 87,\n",
       " 492,\n",
       " 508,\n",
       " 7,\n",
       " 16,\n",
       " 28,\n",
       " 61,\n",
       " 27,\n",
       " 397,\n",
       " 40,\n",
       " 15,\n",
       " 25,\n",
       " 117,\n",
       " 22,\n",
       " 77,\n",
       " 873,\n",
       " 68,\n",
       " 21,\n",
       " 5,\n",
       " 1,\n",
       " 10,\n",
       " 44,\n",
       " 298,\n",
       " 428,\n",
       " 29,\n",
       " 103,\n",
       " 1259,\n",
       " 128,\n",
       " 1404,\n",
       " 1,\n",
       " 1149,\n",
       " 271,\n",
       " 1,\n",
       " 1,\n",
       " 274,\n",
       " 123,\n",
       " 59,\n",
       " 933,\n",
       " 404,\n",
       " 650,\n",
       " 446,\n",
       " 18,\n",
       " 600,\n",
       " 120,\n",
       " 1608,\n",
       " 11,\n",
       " 372,\n",
       " 209,\n",
       " 2,\n",
       " 900,\n",
       " 97,\n",
       " 46,\n",
       " 240,\n",
       " 60,\n",
       " 57,\n",
       " 9,\n",
       " 31,\n",
       " 175,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 526,\n",
       " 260,\n",
       " 44,\n",
       " 35,\n",
       " 319,\n",
       " 446,\n",
       " 87,\n",
       " 17,\n",
       " 5,\n",
       " 1,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 26,\n",
       " 15,\n",
       " 13,\n",
       " 1,\n",
       " 46,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 398,\n",
       " 8,\n",
       " 27,\n",
       " 6,\n",
       " 2,\n",
       " 10,\n",
       " 94,\n",
       " 241,\n",
       " 125,\n",
       " 2,\n",
       " 44,\n",
       " 77,\n",
       " 13,\n",
       " 29,\n",
       " 13,\n",
       " 538,\n",
       " 524,\n",
       " 410,\n",
       " 293,\n",
       " 209,\n",
       " 164,\n",
       " 107,\n",
       " 142,\n",
       " 137,\n",
       " 679,\n",
       " 104,\n",
       " 708,\n",
       " 323,\n",
       " 903,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 22,\n",
       " 32,\n",
       " 23,\n",
       " 3,\n",
       " 3,\n",
       " 298,\n",
       " 91,\n",
       " 1,\n",
       " 173,\n",
       " 9,\n",
       " 18,\n",
       " 115,\n",
       " 17,\n",
       " 1,\n",
       " 43,\n",
       " 2,\n",
       " 5,\n",
       " 299,\n",
       " 1325,\n",
       " 119,\n",
       " 423,\n",
       " 112,\n",
       " 30,\n",
       " 46,\n",
       " 423,\n",
       " 3,\n",
       " 174,\n",
       " 4,\n",
       " 1,\n",
       " 122,\n",
       " 65,\n",
       " 2,\n",
       " 206,\n",
       " 423,\n",
       " 17,\n",
       " 2216,\n",
       " 163,\n",
       " 14,\n",
       " 864,\n",
       " 273,\n",
       " 55,\n",
       " 61,\n",
       " 387,\n",
       " 15,\n",
       " 61,\n",
       " 4,\n",
       " 111,\n",
       " 136,\n",
       " 121,\n",
       " 372,\n",
       " 23,\n",
       " 238,\n",
       " 220,\n",
       " 20,\n",
       " 4,\n",
       " 124,\n",
       " 2,\n",
       " 16,\n",
       " 3,\n",
       " 12,\n",
       " 133,\n",
       " 967,\n",
       " 28,\n",
       " 1,\n",
       " 1,\n",
       " 191,\n",
       " 548,\n",
       " 189,\n",
       " 34,\n",
       " 4,\n",
       " 19,\n",
       " 5,\n",
       " 3,\n",
       " 10,\n",
       " 64,\n",
       " 468,\n",
       " 92,\n",
       " 146,\n",
       " 52,\n",
       " 160,\n",
       " 144,\n",
       " 180,\n",
       " 3,\n",
       " 342,\n",
       " 127,\n",
       " 430,\n",
       " 3,\n",
       " 1,\n",
       " 119,\n",
       " 4,\n",
       " 70,\n",
       " 5,\n",
       " 35,\n",
       " 1,\n",
       " 63,\n",
       " 73,\n",
       " 22,\n",
       " 5,\n",
       " 28,\n",
       " 1,\n",
       " 3,\n",
       " 158,\n",
       " 21,\n",
       " 25,\n",
       " 176,\n",
       " 4,\n",
       " 12,\n",
       " 181,\n",
       " 431,\n",
       " 81,\n",
       " 96,\n",
       " 8,\n",
       " 34,\n",
       " 522,\n",
       " 127,\n",
       " 1,\n",
       " 11,\n",
       " 8,\n",
       " 17,\n",
       " 3,\n",
       " 3,\n",
       " 30,\n",
       " 32,\n",
       " 899,\n",
       " 250,\n",
       " 50,\n",
       " 13,\n",
       " 1,\n",
       " 27,\n",
       " 10,\n",
       " 2,\n",
       " 15,\n",
       " 97,\n",
       " 4,\n",
       " 85,\n",
       " 5,\n",
       " 21,\n",
       " 12,\n",
       " 523,\n",
       " 537,\n",
       " 72,\n",
       " 12,\n",
       " 20,\n",
       " 128,\n",
       " 17,\n",
       " 44,\n",
       " 3,\n",
       " 9,\n",
       " 61,\n",
       " 3,\n",
       " 2,\n",
       " 20,\n",
       " 31,\n",
       " 160,\n",
       " 103,\n",
       " 47,\n",
       " 24,\n",
       " 126,\n",
       " 18,\n",
       " 124,\n",
       " 1,\n",
       " 8,\n",
       " 35,\n",
       " 76,\n",
       " 13,\n",
       " 13,\n",
       " 56,\n",
       " 1,\n",
       " 30,\n",
       " 17,\n",
       " 56,\n",
       " 990,\n",
       " 64,\n",
       " 4,\n",
       " 55,\n",
       " 64,\n",
       " 20,\n",
       " 39,\n",
       " 33,\n",
       " 633,\n",
       " 5,\n",
       " 137,\n",
       " 19,\n",
       " 3,\n",
       " 1170,\n",
       " 180,\n",
       " 1,\n",
       " 43,\n",
       " 629,\n",
       " 1,\n",
       " 4,\n",
       " 47,\n",
       " 373,\n",
       " 314,\n",
       " 47,\n",
       " 337,\n",
       " 217,\n",
       " 76,\n",
       " 335,\n",
       " 1011,\n",
       " 549,\n",
       " 75,\n",
       " 196,\n",
       " 224,\n",
       " 196,\n",
       " 22,\n",
       " 9,\n",
       " 227,\n",
       " 11,\n",
       " 9,\n",
       " 1,\n",
       " 87,\n",
       " 57,\n",
       " 1,\n",
       " 41,\n",
       " 1,\n",
       " 44,\n",
       " 150,\n",
       " 72,\n",
       " 33,\n",
       " 65,\n",
       " 10,\n",
       " 1,\n",
       " 4,\n",
       " 306,\n",
       " 39,\n",
       " 24,\n",
       " 6,\n",
       " 600,\n",
       " 149,\n",
       " 36,\n",
       " 19,\n",
       " 5,\n",
       " 11,\n",
       " 263,\n",
       " 39,\n",
       " 2,\n",
       " 926,\n",
       " 4,\n",
       " 79,\n",
       " 34,\n",
       " 1,\n",
       " 65,\n",
       " 61,\n",
       " 3,\n",
       " 37,\n",
       " 157,\n",
       " 25,\n",
       " 15,\n",
       " 193,\n",
       " 17,\n",
       " 4,\n",
       " 29,\n",
       " 67,\n",
       " 12,\n",
       " 759,\n",
       " 56,\n",
       " 16,\n",
       " 92,\n",
       " 20,\n",
       " 18,\n",
       " 95,\n",
       " 11,\n",
       " 5,\n",
       " 3,\n",
       " 29,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 103,\n",
       " 171,\n",
       " 411,\n",
       " 170,\n",
       " 100,\n",
       " 10,\n",
       " 142,\n",
       " 132,\n",
       " 4,\n",
       " 47,\n",
       " 4,\n",
       " 2,\n",
       " 127,\n",
       " 6,\n",
       " 2,\n",
       " 86,\n",
       " 106,\n",
       " 26,\n",
       " 40,\n",
       " 15,\n",
       " 32,\n",
       " 3,\n",
       " 4,\n",
       " 14,\n",
       " 68,\n",
       " 8,\n",
       " 13,\n",
       " 10,\n",
       " 672,\n",
       " 69,\n",
       " 36,\n",
       " 5,\n",
       " 15,\n",
       " 19,\n",
       " 50,\n",
       " 11,\n",
       " 313,\n",
       " 13,\n",
       " 21,\n",
       " 40,\n",
       " 33,\n",
       " 25,\n",
       " 41,\n",
       " 79,\n",
       " 111,\n",
       " 42,\n",
       " 75,\n",
       " 2,\n",
       " 1,\n",
       " 12,\n",
       " 23,\n",
       " 20,\n",
       " 124,\n",
       " 9,\n",
       " 7,\n",
       " 66,\n",
       " 43,\n",
       " 155,\n",
       " 85,\n",
       " 2,\n",
       " 7,\n",
       " 17,\n",
       " 145,\n",
       " 305,\n",
       " 51,\n",
       " 2,\n",
       " 441,\n",
       " 1,\n",
       " 34,\n",
       " 3,\n",
       " 24,\n",
       " 42,\n",
       " 47,\n",
       " 58,\n",
       " 2,\n",
       " 48,\n",
       " 7,\n",
       " 69,\n",
       " 126,\n",
       " 16,\n",
       " 169,\n",
       " 79,\n",
       " 17,\n",
       " 667,\n",
       " 232,\n",
       " 353,\n",
       " 38,\n",
       " 3,\n",
       " 3,\n",
       " 590,\n",
       " 399,\n",
       " 63,\n",
       " 82,\n",
       " 4,\n",
       " 3,\n",
       " 131,\n",
       " 9,\n",
       " 47,\n",
       " 288,\n",
       " 195,\n",
       " 8,\n",
       " 56,\n",
       " 1,\n",
       " 346,\n",
       " 6,\n",
       " 17,\n",
       " 60,\n",
       " 28,\n",
       " 47,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 41,\n",
       " 53,\n",
       " 32,\n",
       " 107,\n",
       " 50,\n",
       " 69,\n",
       " 97,\n",
       " 35,\n",
       " 22,\n",
       " 99,\n",
       " 107,\n",
       " 54,\n",
       " 849,\n",
       " 360,\n",
       " 115,\n",
       " 1,\n",
       " 43,\n",
       " 4,\n",
       " 1,\n",
       " 19,\n",
       " 170,\n",
       " 1,\n",
       " 3,\n",
       " 18,\n",
       " 38,\n",
       " 59,\n",
       " 112,\n",
       " 17,\n",
       " 140,\n",
       " 1,\n",
       " 130,\n",
       " 24,\n",
       " 7,\n",
       " 66,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 70,\n",
       " 6,\n",
       " 4,\n",
       " 23,\n",
       " 104,\n",
       " 25,\n",
       " 156,\n",
       " 28,\n",
       " 15,\n",
       " 5,\n",
       " 425,\n",
       " 86,\n",
       " 237,\n",
       " 92,\n",
       " 2,\n",
       " 10,\n",
       " 30,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 11,\n",
       " 6,\n",
       " 1,\n",
       " 52,\n",
       " 268,\n",
       " 176,\n",
       " 11,\n",
       " 7,\n",
       " 159,\n",
       " 33,\n",
       " 79,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 48,\n",
       " 2,\n",
       " 15,\n",
       " 139,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 131,\n",
       " 263,\n",
       " 12,\n",
       " 376,\n",
       " 9,\n",
       " 238,\n",
       " 21,\n",
       " 5,\n",
       " 128,\n",
       " 9,\n",
       " 107,\n",
       " 69,\n",
       " 129,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 116,\n",
       " 29,\n",
       " 43,\n",
       " 84,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 26,\n",
       " 279,\n",
       " 1,\n",
       " 157,\n",
       " 136,\n",
       " 48,\n",
       " 20,\n",
       " 16,\n",
       " 34,\n",
       " 223,\n",
       " 34,\n",
       " 16,\n",
       " 50,\n",
       " 5,\n",
       " 221,\n",
       " 55,\n",
       " 73,\n",
       " 43,\n",
       " 2,\n",
       " 80,\n",
       " 10,\n",
       " 89,\n",
       " 94,\n",
       " 3,\n",
       " 55,\n",
       " 57,\n",
       " 1,\n",
       " 51,\n",
       " 28,\n",
       " 115,\n",
       " 306,\n",
       " 12,\n",
       " 25,\n",
       " 275,\n",
       " 157,\n",
       " 8,\n",
       " 240,\n",
       " 8,\n",
       " 13,\n",
       " 43,\n",
       " 9,\n",
       " 31,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 22,\n",
       " 11,\n",
       " 5,\n",
       " 39,\n",
       " 17,\n",
       " 8,\n",
       " 14,\n",
       " 2,\n",
       " 39,\n",
       " 63,\n",
       " 6,\n",
       " 15,\n",
       " 8,\n",
       " 8,\n",
       " 14,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 24,\n",
       " 4,\n",
       " 10,\n",
       " 113,\n",
       " 3,\n",
       " 15,\n",
       " 20,\n",
       " 27,\n",
       " 21,\n",
       " 2,\n",
       " 48,\n",
       " 102,\n",
       " 75,\n",
       " 52,\n",
       " 314,\n",
       " 26,\n",
       " 26,\n",
       " 150,\n",
       " 6,\n",
       " 379,\n",
       " 9,\n",
       " 10,\n",
       " 2,\n",
       " 9,\n",
       " 91,\n",
       " 5,\n",
       " 195,\n",
       " 2,\n",
       " 27,\n",
       " 32,\n",
       " 51,\n",
       " 3,\n",
       " 35,\n",
       " 135,\n",
       " 60,\n",
       " 19,\n",
       " 1,\n",
       " 251,\n",
       " 33,\n",
       " 266,\n",
       " 28,\n",
       " 1,\n",
       " 13,\n",
       " 72,\n",
       " 25,\n",
       " 2,\n",
       " 79,\n",
       " 13,\n",
       " 41,\n",
       " 2,\n",
       " 5,\n",
       " 15,\n",
       " 101,\n",
       " 12,\n",
       " 56,\n",
       " 4,\n",
       " 27,\n",
       " 61,\n",
       " 61,\n",
       " 3,\n",
       " 4,\n",
       " 41,\n",
       " 9,\n",
       " 26,\n",
       " 188,\n",
       " 73,\n",
       " 36,\n",
       " 31,\n",
       " 17,\n",
       " 4,\n",
       " 10,\n",
       " 94,\n",
       " 23,\n",
       " 1,\n",
       " 16,\n",
       " 38,\n",
       " 131,\n",
       " 202,\n",
       " 27,\n",
       " 1,\n",
       " 180,\n",
       " 30,\n",
       " 3,\n",
       " 3,\n",
       " 84,\n",
       " 1,\n",
       " 147,\n",
       " 41,\n",
       " 3,\n",
       " 60,\n",
       " 1,\n",
       " 4,\n",
       " 21,\n",
       " 45,\n",
       " 175,\n",
       " 2,\n",
       " 104,\n",
       " 7,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 18,\n",
       " 8,\n",
       " 130,\n",
       " 2,\n",
       " 133,\n",
       " 9,\n",
       " 58,\n",
       " 20,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 133,\n",
       " 61,\n",
       " 8,\n",
       " 5,\n",
       " 103,\n",
       " 63,\n",
       " 5,\n",
       " 5,\n",
       " 251,\n",
       " 44,\n",
       " 3,\n",
       " 109,\n",
       " 2,\n",
       " 15,\n",
       " 7,\n",
       " 17,\n",
       " 76,\n",
       " 233,\n",
       " 282,\n",
       " 2,\n",
       " 29,\n",
       " 202,\n",
       " 50,\n",
       " 2,\n",
       " 56,\n",
       " 56,\n",
       " 73,\n",
       " 30,\n",
       " 89,\n",
       " 1,\n",
       " 5,\n",
       " 32,\n",
       " 2,\n",
       " 134,\n",
       " 2,\n",
       " 2,\n",
       " 179,\n",
       " 28,\n",
       " 87,\n",
       " 160,\n",
       " 12,\n",
       " 7,\n",
       " 4,\n",
       " 35,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 13,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 115,\n",
       " 2,\n",
       " 11,\n",
       " 39,\n",
       " 22,\n",
       " 62,\n",
       " 57,\n",
       " 3,\n",
       " 36,\n",
       " 1,\n",
       " 18,\n",
       " 1,\n",
       " 41,\n",
       " 34,\n",
       " 5,\n",
       " 17,\n",
       " 12,\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "#워드 개수 확인\n",
    "with open('./create_dataset/data/pickles/words_frequencies.p','rb') as f:\n",
    "    words_freq=pickle.load(f)\n",
    "words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85ae9cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4371"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f1f1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_beam = get_clotho_loader(data_dir=data_dir, split='evaluation',\n",
    "                                        input_field_name='features',\n",
    "                                        output_field_name='words_ind',\n",
    "                                        load_into_memory=False,\n",
    "                                        batch_size=32,\n",
    "                                        nb_t_steps_pad='max',\n",
    "                                        shuffle=False,\n",
    "                                        return_reference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cf2eb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "test_data = get_test_data_loader(data_dir=test_data_dir,\n",
    "                                     batch_size=hp.batch_size * 2,\n",
    "                                     nb_t_steps_pad='max',\n",
    "                                     shuffle=False,\n",
    "                                     drop_last=False,\n",
    "                                     input_pad_at='start',\n",
    "                                     num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "475347a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss_text = 0.\n",
    "    start_time = time.time()\n",
    "    batch = 0\n",
    "    for src, tgt, tgt_len,ref in training_data:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        tgt_pad_mask = get_padding(tgt, tgt_len)\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        tgt_pad_mask = tgt_pad_mask[:, :-1]\n",
    "        tgt_y = tgt[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, tgt_in, target_padding_mask=tgt_pad_mask)\n",
    "\n",
    "        loss_text = criterion(output.contiguous().view(-1, hp.ntoken), tgt_y.transpose(0, 1).contiguous().view(-1))\n",
    "        loss = loss_text\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), hp.clip_grad)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "        total_loss_text += loss_text.item()\n",
    "\n",
    "        writer.add_scalar('Loss/train-text', loss_text.item(), (epoch - 1) * len(training_data) + batch)\n",
    "        \n",
    "        \n",
    "        batch += 1\n",
    "        \n",
    "        if batch % hp.log_interval == 0 and batch > 0:\n",
    "            mean_text_loss = total_loss_text / hp.log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            current_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\n",
    "            logging.info('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2e} | ms/batch {:5.2f} | '\n",
    "                         'loss-text {:5.4f}'.format(\n",
    "                epoch, batch, len(training_data), current_lr,\n",
    "                elapsed * 1000 / hp.log_interval, mean_text_loss))\n",
    "            total_loss_text = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "            optimizer.swap_swa_sgd()\n",
    "\n",
    "def eval_all(evaluation_data, max_len=30, eos_ind=9, word_dict_pickle_path=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_sentence_all = []\n",
    "        ref_all = []\n",
    "        for src, tgt, _, ref in evaluation_data:\n",
    "            src = src.to(device)\n",
    "            output = greedy_decode(model, src, max_len=max_len)\n",
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for i in range(output.size()[0]):\n",
    "                output_sentence_ind = []\n",
    "                for j in range(1, output.size(1)):\n",
    "                    sym = output[i, j]\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n",
    "\n",
    "        loss_mean = score\n",
    "        writer.add_scalar(f'Loss/eval_greddy', loss_mean, epoch)\n",
    "        msg = f'eval_greddy SPIDEr: {loss_mean:2.4f}'\n",
    "        logging.info(msg)\n",
    "\n",
    "\n",
    "def eval_with_beam(evaluation_data, max_len=30, eos_ind=9, word_dict_pickle_path=None, beam_size=3):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_sentence_all = []\n",
    "        ref_all = []\n",
    "        for src, tgt, _, ref in evaluation_data:\n",
    "            src = src.to(device)\n",
    "            output = beam_search(model, src, max_len, start_symbol_ind=0, beam_size=beam_size)\n",
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for single_sample in output:\n",
    "                output_sentence_ind = []\n",
    "                for sym in single_sample:\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n",
    "\n",
    "        loss_mean = score\n",
    "        writer.add_scalar(f'Loss/eval_beam', loss_mean, epoch)\n",
    "        msg = f'eval_beam_{beam_size} SPIDEr: {loss_mean:2.4f}'\n",
    "        logging.info(msg)\n",
    "\n",
    "\n",
    "def test_with_beam(test_data, max_len=30, eos_ind=9, beam_size=3):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with open(\"test_out.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['file_name', 'caption_predicted'])\n",
    "            for src, filename in test_data:\n",
    "                src = src.to(device)\n",
    "                output = beam_search(model, src, max_len, start_symbol_ind=0, beam_size=beam_size)\n",
    "\n",
    "                output_sentence_ind_batch = []\n",
    "                for single_sample in output:\n",
    "                    output_sentence_ind = []\n",
    "                    for sym in single_sample:\n",
    "                        if sym == eos_ind: break\n",
    "                        output_sentence_ind.append(sym.item())\n",
    "                    output_sentence_ind_batch.append(output_sentence_ind)\n",
    "                out_str = gen_str(output_sentence_ind_batch, hp.word_dict_pickle_path)\n",
    "                for caption, fn in zip(out_str, filename):\n",
    "                    writer.writerow(['{}.wav'.format(fn), caption])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d583cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hp.label_smoothing:\n",
    "    criterion = LabelSmoothingLoss(hp.ntoken, smoothing=0.1)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=hp.ntoken - 1)\n",
    "\n",
    "now_time = str(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(time.time())))\n",
    "log_dir = 'models/{name}'.format(name=hp.name)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "log_path = os.path.join(log_dir, 'train.log')\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                        format=\n",
    "                        '%(asctime)s - %(levelname)s: %(message)s',\n",
    "                        handlers=[\n",
    "                            logging.FileHandler(log_path),\n",
    "                            logging.StreamHandler(sys.stdout)]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0708d0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 15:22:55,867 - INFO: TransformerModel(\n",
      "  (transformer_decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (dropout3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (dropout3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_emb): Embedding(4371, 192)\n",
      "  (fc): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (fc1): Linear(in_features=2048, out_features=192, bias=True)\n",
      "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
      "  (encoder): Transfer_ResNet54(\n",
      "    (base): ResNet54(\n",
      "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_block1): ConvBlock(\n",
      "        (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (resnet): _ResNet(\n",
      "        (layer1): Sequential(\n",
      "          (0): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (layer2): Sequential(\n",
      "          (0): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "              (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (layer3): Sequential(\n",
      "          (0): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "              (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (5): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (layer4): Sequential(\n",
      "          (0): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "              (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): _ResnetBottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_block_after1): ConvBlock(\n",
      "        (conv1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (fc_audioset): Linear(in_features=2048, out_features=527, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (generator): Softmax(dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 15:22:55,868 - INFO: {'batch_size': 8, 'beam_width': 3, 'checkpoint_save_interval': 5, 'clip_grad': 2.5, 'data_dir': PosixPath('/home/hj20/dcase_2020_T6/create_dataset/data/data_splits'), 'device': 'cuda', 'eval_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/data_splits/evaluation', 'freeze_cnn': True, 'label_smoothing': True, 'load_pretrain_cnn': True, 'load_pretrain_emb': False, 'load_pretrain_model': True, 'log_interval': 100, 'lr': 0.0001, 'mode': 'train', 'name': '1203resnet_layer4 ', 'nhead': 4, 'nhid': 192, 'ninp': 64, 'nkeyword': 4979, 'nlayers': 2, 'ntoken': 4371, 'pretrain_cnn_path': '/home/hj20/dcase_2020_T6/models/tag_models/TagModel_45.pt', 'pretrain_emb_path': '/home/hj20/dcase_2020_T6/models/w2v_192.mod', 'pretrain_model_path': '/home/hj20/dcase_2020_T6/models/base/46.pt', 'scheduler_decay': 0.98, 'seed': 1111, 'spec_augmentation': True, 'test_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/test_data', 'train_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/data_splits/development', 'training_epochs': 50, 'word_dict_pickle_path': '/home/hj20/dcase_2020_T6/create_dataset/data/pickles/words_list.p', 'word_freq_pickle_path': '/home/hj20/dcase_2020_T6/create_dataset/data/pickles/words_frequencies.p'}\n",
      "2021-12-03 15:22:55,869 - INFO: Data loaded!\n",
      "2021-12-03 15:22:55,869 - INFO: Data size: 3051\n",
      "2021-12-03 15:22:55,870 - INFO: Total Model parameters: 93689570\n"
     ]
    }
   ],
   "source": [
    "    logging.info(str(model))\n",
    "\n",
    "    logging.info(str(print_hparams(hp)))\n",
    "\n",
    "    logging.info('Data loaded!')\n",
    "    logging.info('Data size: ' + str(len(training_data)))\n",
    "\n",
    "    logging.info('Total Model parameters: ' + str(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc51859f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 15:23:31,004 - INFO: | epoch   1 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 342.32 | loss-text 5.9000\n",
      "2021-12-03 15:24:05,339 - INFO: | epoch   1 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 343.34 | loss-text 5.1418\n",
      "2021-12-03 15:24:39,340 - INFO: | epoch   1 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 340.01 | loss-text 4.9829\n",
      "2021-12-03 15:25:13,556 - INFO: | epoch   1 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 342.15 | loss-text 4.8647\n",
      "2021-12-03 15:25:47,947 - INFO: | epoch   1 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 343.90 | loss-text 4.7501\n",
      "2021-12-03 15:26:22,625 - INFO: | epoch   1 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 346.78 | loss-text 4.6166\n",
      "2021-12-03 15:26:57,142 - INFO: | epoch   1 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 345.17 | loss-text 4.6930\n",
      "2021-12-03 15:27:31,530 - INFO: | epoch   1 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.88 | loss-text 4.5190\n",
      "2021-12-03 15:28:06,442 - INFO: | epoch   1 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 349.11 | loss-text 4.4473\n",
      "2021-12-03 15:28:42,147 - INFO: | epoch   1 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 357.04 | loss-text 4.5574\n",
      "2021-12-03 15:29:16,651 - INFO: | epoch   1 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 345.04 | loss-text 4.5040\n",
      "2021-12-03 15:29:51,273 - INFO: | epoch   1 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 346.19 | loss-text 4.4523\n",
      "2021-12-03 15:30:25,300 - INFO: | epoch   1 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 340.27 | loss-text 4.3940\n",
      "2021-12-03 15:30:59,448 - INFO: | epoch   1 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.47 | loss-text 4.3975\n",
      "2021-12-03 15:31:33,996 - INFO: | epoch   1 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 345.47 | loss-text 4.4215\n",
      "2021-12-03 15:32:08,353 - INFO: | epoch   1 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.56 | loss-text 4.4205\n",
      "2021-12-03 15:32:42,698 - INFO: | epoch   1 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.44 | loss-text 4.3634\n",
      "2021-12-03 15:33:17,099 - INFO: | epoch   1 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.00 | loss-text 4.3464\n",
      "2021-12-03 15:33:51,712 - INFO: | epoch   1 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 346.12 | loss-text 4.2429\n",
      "2021-12-03 15:34:26,288 - INFO: | epoch   1 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 345.75 | loss-text 4.3153\n",
      "2021-12-03 15:35:00,733 - INFO: | epoch   1 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 344.44 | loss-text 4.2854\n",
      "2021-12-03 15:35:35,203 - INFO: | epoch   1 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 344.70 | loss-text 4.2531\n",
      "2021-12-03 15:36:09,540 - INFO: | epoch   1 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 343.36 | loss-text 4.2534\n",
      "2021-12-03 15:36:43,946 - INFO: | epoch   1 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 344.05 | loss-text 4.3190\n",
      "2021-12-03 15:37:18,062 - INFO: | epoch   1 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 341.16 | loss-text 4.2569\n",
      "2021-12-03 15:37:52,596 - INFO: | epoch   1 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 345.33 | loss-text 4.2229\n",
      "2021-12-03 15:38:26,874 - INFO: | epoch   1 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.77 | loss-text 4.1368\n",
      "2021-12-03 15:39:01,149 - INFO: | epoch   1 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.75 | loss-text 4.1897\n",
      "2021-12-03 15:39:35,522 - INFO: | epoch   1 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 343.72 | loss-text 4.1830\n",
      "2021-12-03 15:40:09,981 - INFO: | epoch   1 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 344.59 | loss-text 4.1640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003999\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 17899, 'reflen': 11908, 'guess': [17899, 16875, 15851, 14827], 'correct': [4862, 1225, 296, 43]}\n",
      "ratio: 1.5031071548537536\n",
      "Bleu_1: 0.272\n",
      "Bleu_2: 0.140\n",
      "Bleu_3: 0.072\n",
      "Bleu_4: 0.032\n",
      "computing METEOR score...\n",
      "METEOR: 0.108\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.259\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.093\n",
      "computing SPICE score...\n",
      "SPICE: 0.075\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.084\n",
      "2021-12-03 15:41:22,422 - INFO: eval_greddy SPIDEr: 0.0838\n",
      "loading annotations into memory...\n",
      "0:00:00.003818\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8918, 'reflen': 9514, 'guess': [8918, 7894, 6870, 5846], 'correct': [4852, 1562, 524, 130]}\n",
      "ratio: 0.9373554761403261\n",
      "Bleu_1: 0.509\n",
      "Bleu_2: 0.307\n",
      "Bleu_3: 0.189\n",
      "Bleu_4: 0.109\n",
      "computing METEOR score...\n",
      "METEOR: 0.132\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.335\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.189\n",
      "computing SPICE score...\n",
      "SPICE: 0.081\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.135\n",
      "2021-12-03 15:42:03,764 - INFO: eval_beam_2 SPIDEr: 0.1348\n",
      "loading annotations into memory...\n",
      "0:00:00.003993\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8363, 'reflen': 9327, 'guess': [8363, 7339, 6315, 5291], 'correct': [4782, 1645, 607, 160]}\n",
      "ratio: 0.896644151388346\n",
      "Bleu_1: 0.510\n",
      "Bleu_2: 0.319\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.134\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.344\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.202\n",
      "computing SPICE score...\n",
      "SPICE: 0.083\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.142\n",
      "2021-12-03 15:42:47,078 - INFO: eval_beam_3 SPIDEr: 0.1425\n",
      "loading annotations into memory...\n",
      "0:00:00.003769\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8074, 'reflen': 9276, 'guess': [8074, 7050, 6026, 5003], 'correct': [4706, 1670, 623, 164]}\n",
      "ratio: 0.8704182837428988\n",
      "Bleu_1: 0.502\n",
      "Bleu_2: 0.320\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.134\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.346\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.209\n",
      "computing SPICE score...\n",
      "SPICE: 0.084\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.146\n",
      "2021-12-03 15:43:34,706 - INFO: eval_beam_4 SPIDEr: 0.1463\n",
      "2021-12-03 15:44:08,837 - INFO: | epoch   2 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 341.28 | loss-text 4.1182\n",
      "2021-12-03 15:44:43,047 - INFO: | epoch   2 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 342.09 | loss-text 4.1029\n",
      "2021-12-03 15:45:17,242 - INFO: | epoch   2 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.94 | loss-text 4.0836\n",
      "2021-12-03 15:45:51,737 - INFO: | epoch   2 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 344.94 | loss-text 4.0680\n",
      "2021-12-03 15:46:26,174 - INFO: | epoch   2 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 344.36 | loss-text 4.0593\n",
      "2021-12-03 15:47:00,454 - INFO: | epoch   2 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.79 | loss-text 4.0925\n",
      "2021-12-03 15:47:35,024 - INFO: | epoch   2 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 345.70 | loss-text 4.0588\n",
      "2021-12-03 15:48:09,097 - INFO: | epoch   2 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 340.72 | loss-text 4.0524\n",
      "2021-12-03 15:48:43,685 - INFO: | epoch   2 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 345.87 | loss-text 4.0532\n",
      "2021-12-03 15:49:18,215 - INFO: | epoch   2 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 345.30 | loss-text 3.9953\n",
      "2021-12-03 15:49:52,624 - INFO: | epoch   2 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 344.08 | loss-text 4.0742\n",
      "2021-12-03 15:50:26,690 - INFO: | epoch   2 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 340.65 | loss-text 4.0139\n",
      "2021-12-03 15:51:00,735 - INFO: | epoch   2 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 340.44 | loss-text 4.0249\n",
      "2021-12-03 15:51:35,157 - INFO: | epoch   2 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 344.22 | loss-text 4.0248\n",
      "2021-12-03 15:52:09,317 - INFO: | epoch   2 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 341.59 | loss-text 3.9831\n",
      "2021-12-03 15:52:43,329 - INFO: | epoch   2 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 340.12 | loss-text 4.0203\n",
      "2021-12-03 15:53:17,610 - INFO: | epoch   2 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 342.80 | loss-text 4.0196\n",
      "2021-12-03 15:53:52,094 - INFO: | epoch   2 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.84 | loss-text 3.9886\n",
      "2021-12-03 15:54:26,355 - INFO: | epoch   2 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.60 | loss-text 3.9386\n",
      "2021-12-03 15:55:00,811 - INFO: | epoch   2 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 344.55 | loss-text 4.0279\n",
      "2021-12-03 15:55:36,298 - INFO: | epoch   2 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 354.86 | loss-text 3.9836\n",
      "2021-12-03 15:56:10,686 - INFO: | epoch   2 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 343.88 | loss-text 4.0015\n",
      "2021-12-03 15:56:45,328 - INFO: | epoch   2 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 346.41 | loss-text 3.9687\n",
      "2021-12-03 15:57:19,859 - INFO: | epoch   2 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 345.30 | loss-text 4.0131\n",
      "2021-12-03 15:57:54,303 - INFO: | epoch   2 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 344.43 | loss-text 3.9905\n",
      "2021-12-03 15:58:28,599 - INFO: | epoch   2 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.96 | loss-text 3.9527\n",
      "2021-12-03 15:59:02,952 - INFO: | epoch   2 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 343.52 | loss-text 3.9205\n",
      "2021-12-03 15:59:37,268 - INFO: | epoch   2 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.16 | loss-text 3.9583\n",
      "2021-12-03 16:00:11,525 - INFO: | epoch   2 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.56 | loss-text 3.8509\n",
      "2021-12-03 16:00:46,505 - INFO: | epoch   2 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 349.79 | loss-text 3.9529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003764\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9487, 'reflen': 9787, 'guess': [9487, 8463, 7439, 6415], 'correct': [4635, 1433, 474, 121]}\n",
      "ratio: 0.9693470930825616\n",
      "Bleu_1: 0.473\n",
      "Bleu_2: 0.279\n",
      "Bleu_3: 0.169\n",
      "Bleu_4: 0.097\n",
      "computing METEOR score...\n",
      "METEOR: 0.130\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.321\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.195\n",
      "computing SPICE score...\n",
      "SPICE: 0.083\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.139\n",
      "2021-12-03 16:01:39,574 - INFO: eval_greddy SPIDEr: 0.1392\n",
      "loading annotations into memory...\n",
      "0:00:00.003874\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8493, 'reflen': 9338, 'guess': [8493, 7469, 6445, 5421], 'correct': [4485, 1568, 581, 163]}\n",
      "ratio: 0.9095095309487139\n",
      "Bleu_1: 0.478\n",
      "Bleu_2: 0.301\n",
      "Bleu_3: 0.195\n",
      "Bleu_4: 0.119\n",
      "computing METEOR score...\n",
      "METEOR: 0.132\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.336\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.218\n",
      "computing SPICE score...\n",
      "SPICE: 0.083\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.150\n",
      "2021-12-03 16:02:15,399 - INFO: eval_beam_2 SPIDEr: 0.1504\n",
      "loading annotations into memory...\n",
      "0:00:00.003734\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8311, 'reflen': 9286, 'guess': [8311, 7287, 6263, 5239], 'correct': [4461, 1621, 621, 180]}\n",
      "ratio: 0.8950032306697291\n",
      "Bleu_1: 0.477\n",
      "Bleu_2: 0.307\n",
      "Bleu_3: 0.203\n",
      "Bleu_4: 0.126\n",
      "computing METEOR score...\n",
      "METEOR: 0.133\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.338\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.224\n",
      "computing SPICE score...\n",
      "SPICE: 0.083\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.153\n",
      "2021-12-03 16:02:53,310 - INFO: eval_beam_3 SPIDEr: 0.1533\n",
      "loading annotations into memory...\n",
      "0:00:00.003895\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8110, 'reflen': 9241, 'guess': [8110, 7086, 6062, 5038], 'correct': [4398, 1622, 627, 184]}\n",
      "ratio: 0.8776106481981519\n",
      "Bleu_1: 0.472\n",
      "Bleu_2: 0.306\n",
      "Bleu_3: 0.204\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.132\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.338\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.214\n",
      "computing SPICE score...\n",
      "SPICE: 0.085\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.150\n",
      "2021-12-03 16:03:34,257 - INFO: eval_beam_4 SPIDEr: 0.1498\n",
      "2021-12-03 16:04:08,020 - INFO: | epoch   3 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 337.59 | loss-text 3.9045\n",
      "2021-12-03 16:04:42,345 - INFO: | epoch   3 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 343.24 | loss-text 3.8514\n",
      "2021-12-03 16:05:16,749 - INFO: | epoch   3 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 344.03 | loss-text 3.9470\n",
      "2021-12-03 16:05:50,789 - INFO: | epoch   3 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 340.40 | loss-text 3.8928\n",
      "2021-12-03 16:06:25,330 - INFO: | epoch   3 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 345.40 | loss-text 3.9366\n",
      "2021-12-03 16:06:59,670 - INFO: | epoch   3 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 343.40 | loss-text 3.8826\n",
      "2021-12-03 16:07:34,324 - INFO: | epoch   3 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 346.53 | loss-text 3.8575\n",
      "2021-12-03 16:08:10,787 - INFO: | epoch   3 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 364.62 | loss-text 3.8928\n",
      "2021-12-03 16:08:45,903 - INFO: | epoch   3 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 351.15 | loss-text 3.8315\n",
      "2021-12-03 16:09:20,999 - INFO: | epoch   3 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 350.95 | loss-text 3.8738\n",
      "2021-12-03 16:09:55,580 - INFO: | epoch   3 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 345.81 | loss-text 3.8789\n",
      "2021-12-03 16:10:29,973 - INFO: | epoch   3 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 343.91 | loss-text 3.8756\n",
      "2021-12-03 16:11:04,394 - INFO: | epoch   3 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 344.21 | loss-text 3.8285\n",
      "2021-12-03 16:11:38,683 - INFO: | epoch   3 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.88 | loss-text 3.8012\n",
      "2021-12-03 16:12:13,139 - INFO: | epoch   3 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 344.56 | loss-text 3.8605\n",
      "2021-12-03 16:12:47,505 - INFO: | epoch   3 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.65 | loss-text 3.7852\n",
      "2021-12-03 16:13:21,783 - INFO: | epoch   3 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 342.77 | loss-text 3.8085\n",
      "2021-12-03 16:13:56,385 - INFO: | epoch   3 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 346.01 | loss-text 3.8715\n",
      "2021-12-03 16:14:31,212 - INFO: | epoch   3 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 348.27 | loss-text 3.8011\n",
      "2021-12-03 16:15:05,383 - INFO: | epoch   3 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 341.70 | loss-text 3.8160\n",
      "2021-12-03 16:15:39,568 - INFO: | epoch   3 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 341.84 | loss-text 3.7833\n",
      "2021-12-03 16:16:13,818 - INFO: | epoch   3 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 342.49 | loss-text 3.8143\n",
      "2021-12-03 16:16:48,095 - INFO: | epoch   3 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.76 | loss-text 3.7989\n",
      "2021-12-03 16:17:22,403 - INFO: | epoch   3 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.08 | loss-text 3.7375\n",
      "2021-12-03 16:17:56,554 - INFO: | epoch   3 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 341.50 | loss-text 3.7664\n",
      "2021-12-03 16:18:31,022 - INFO: | epoch   3 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 344.68 | loss-text 3.7991\n",
      "2021-12-03 16:19:05,167 - INFO: | epoch   3 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.44 | loss-text 3.7831\n",
      "2021-12-03 16:19:39,522 - INFO: | epoch   3 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.55 | loss-text 3.7744\n",
      "2021-12-03 16:20:13,700 - INFO: | epoch   3 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 341.77 | loss-text 3.8381\n",
      "2021-12-03 16:20:48,109 - INFO: | epoch   3 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 344.08 | loss-text 3.8281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004069\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10675, 'reflen': 10516, 'guess': [10675, 9651, 8627, 7603], 'correct': [5163, 1697, 579, 162]}\n",
      "ratio: 1.0151198174209761\n",
      "Bleu_1: 0.484\n",
      "Bleu_2: 0.292\n",
      "Bleu_3: 0.179\n",
      "Bleu_4: 0.105\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.332\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.224\n",
      "computing SPICE score...\n",
      "SPICE: 0.090\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.157\n",
      "2021-12-03 16:21:42,527 - INFO: eval_greddy SPIDEr: 0.1569\n",
      "loading annotations into memory...\n",
      "0:00:00.003801\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9146, 'reflen': 9652, 'guess': [9146, 8122, 7098, 6074], 'correct': [5024, 1831, 700, 215]}\n",
      "ratio: 0.947575631993271\n",
      "Bleu_1: 0.520\n",
      "Bleu_2: 0.333\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.347\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.270\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.183\n",
      "2021-12-03 16:22:18,850 - INFO: eval_beam_2 SPIDEr: 0.1825\n",
      "loading annotations into memory...\n",
      "0:00:00.003717\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8722, 'reflen': 9482, 'guess': [8722, 7698, 6674, 5650], 'correct': [4878, 1874, 726, 218]}\n",
      "ratio: 0.9198481333051128\n",
      "Bleu_1: 0.513\n",
      "Bleu_2: 0.338\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.274\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.185\n",
      "2021-12-03 16:22:58,295 - INFO: eval_beam_3 SPIDEr: 0.1850\n",
      "loading annotations into memory...\n",
      "0:00:00.003844\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8402, 'reflen': 9394, 'guess': [8402, 7378, 6354, 5330], 'correct': [4769, 1895, 756, 232]}\n",
      "ratio: 0.8944006812858319\n",
      "Bleu_1: 0.504\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.353\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.274\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.185\n",
      "2021-12-03 16:23:41,336 - INFO: eval_beam_4 SPIDEr: 0.1847\n",
      "2021-12-03 16:24:15,449 - INFO: | epoch   4 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 341.11 | loss-text 3.7443\n",
      "2021-12-03 16:24:49,666 - INFO: | epoch   4 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 342.15 | loss-text 3.7334\n",
      "2021-12-03 16:25:23,787 - INFO: | epoch   4 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.20 | loss-text 3.7788\n",
      "2021-12-03 16:25:57,952 - INFO: | epoch   4 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.65 | loss-text 3.7412\n",
      "2021-12-03 16:26:32,017 - INFO: | epoch   4 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 340.64 | loss-text 3.6683\n",
      "2021-12-03 16:27:06,243 - INFO: | epoch   4 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.26 | loss-text 3.7692\n",
      "2021-12-03 16:27:40,605 - INFO: | epoch   4 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 343.62 | loss-text 3.7407\n",
      "2021-12-03 16:28:14,991 - INFO: | epoch   4 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.85 | loss-text 3.7486\n",
      "2021-12-03 16:28:49,226 - INFO: | epoch   4 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.34 | loss-text 3.7720\n",
      "2021-12-03 16:29:23,214 - INFO: | epoch   4 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 339.87 | loss-text 3.6819\n",
      "2021-12-03 16:29:57,371 - INFO: | epoch   4 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 341.57 | loss-text 3.7647\n",
      "2021-12-03 16:30:31,628 - INFO: | epoch   4 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.56 | loss-text 3.7186\n",
      "2021-12-03 16:31:05,894 - INFO: | epoch   4 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.65 | loss-text 3.6861\n",
      "2021-12-03 16:31:40,321 - INFO: | epoch   4 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 344.26 | loss-text 3.7098\n",
      "2021-12-03 16:32:14,646 - INFO: | epoch   4 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 343.25 | loss-text 3.6956\n",
      "2021-12-03 16:32:48,659 - INFO: | epoch   4 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 340.12 | loss-text 3.7401\n",
      "2021-12-03 16:33:23,056 - INFO: | epoch   4 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.97 | loss-text 3.7563\n",
      "2021-12-03 16:33:57,412 - INFO: | epoch   4 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 343.55 | loss-text 3.7132\n",
      "2021-12-03 16:34:31,707 - INFO: | epoch   4 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.95 | loss-text 3.6662\n",
      "2021-12-03 16:35:06,057 - INFO: | epoch   4 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 343.50 | loss-text 3.7392\n",
      "2021-12-03 16:35:40,305 - INFO: | epoch   4 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 342.47 | loss-text 3.7235\n",
      "2021-12-03 16:36:14,833 - INFO: | epoch   4 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 345.27 | loss-text 3.6885\n",
      "2021-12-03 16:36:49,101 - INFO: | epoch   4 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.68 | loss-text 3.6473\n",
      "2021-12-03 16:37:23,430 - INFO: | epoch   4 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.28 | loss-text 3.7096\n",
      "2021-12-03 16:37:57,591 - INFO: | epoch   4 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 341.60 | loss-text 3.7296\n",
      "2021-12-03 16:38:31,811 - INFO: | epoch   4 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.19 | loss-text 3.7321\n",
      "2021-12-03 16:39:06,191 - INFO: | epoch   4 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 343.79 | loss-text 3.6833\n",
      "2021-12-03 16:39:40,463 - INFO: | epoch   4 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.72 | loss-text 3.7042\n",
      "2021-12-03 16:40:14,599 - INFO: | epoch   4 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 341.35 | loss-text 3.6822\n",
      "2021-12-03 16:40:48,871 - INFO: | epoch   4 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.72 | loss-text 3.6504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003717\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11097, 'reflen': 10725, 'guess': [11097, 10073, 9049, 8025], 'correct': [5202, 1562, 491, 102]}\n",
      "ratio: 1.0346853146852182\n",
      "Bleu_1: 0.469\n",
      "Bleu_2: 0.270\n",
      "Bleu_3: 0.158\n",
      "Bleu_4: 0.084\n",
      "computing METEOR score...\n",
      "METEOR: 0.138\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.329\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.203\n",
      "computing SPICE score...\n",
      "SPICE: 0.091\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.147\n",
      "2021-12-03 16:41:43,791 - INFO: eval_greddy SPIDEr: 0.1471\n",
      "loading annotations into memory...\n",
      "0:00:00.004007\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9088, 'reflen': 9633, 'guess': [9088, 8064, 7040, 6016], 'correct': [4855, 1690, 623, 162]}\n",
      "ratio: 0.9434236478769912\n",
      "Bleu_1: 0.503\n",
      "Bleu_2: 0.315\n",
      "Bleu_3: 0.202\n",
      "Bleu_4: 0.120\n",
      "computing METEOR score...\n",
      "METEOR: 0.142\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.341\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.257\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.178\n",
      "2021-12-03 16:42:20,274 - INFO: eval_beam_2 SPIDEr: 0.1779\n",
      "loading annotations into memory...\n",
      "0:00:00.003907\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8577, 'reflen': 9413, 'guess': [8577, 7553, 6529, 5505], 'correct': [4705, 1743, 672, 207]}\n",
      "ratio: 0.9111866567512046\n",
      "Bleu_1: 0.498\n",
      "Bleu_2: 0.323\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.143\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.346\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.269\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.184\n",
      "2021-12-03 16:42:59,528 - INFO: eval_beam_3 SPIDEr: 0.1837\n",
      "loading annotations into memory...\n",
      "0:00:00.003913\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8309, 'reflen': 9332, 'guess': [8309, 7285, 6261, 5237], 'correct': [4634, 1728, 660, 193]}\n",
      "ratio: 0.8903771967422963\n",
      "Bleu_1: 0.493\n",
      "Bleu_2: 0.322\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.142\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.345\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.271\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.185\n",
      "2021-12-03 16:43:42,186 - INFO: eval_beam_4 SPIDEr: 0.1855\n",
      "2021-12-03 16:44:16,407 - INFO: | epoch   5 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 342.18 | loss-text 3.6394\n",
      "2021-12-03 16:44:50,451 - INFO: | epoch   5 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.42 | loss-text 3.6434\n",
      "2021-12-03 16:45:24,740 - INFO: | epoch   5 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 342.89 | loss-text 3.6927\n",
      "2021-12-03 16:45:58,913 - INFO: | epoch   5 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.73 | loss-text 3.6786\n",
      "2021-12-03 16:46:32,982 - INFO: | epoch   5 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 340.68 | loss-text 3.6380\n",
      "2021-12-03 16:47:07,047 - INFO: | epoch   5 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 340.64 | loss-text 3.6134\n",
      "2021-12-03 16:47:41,122 - INFO: | epoch   5 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 340.75 | loss-text 3.6493\n",
      "2021-12-03 16:48:15,514 - INFO: | epoch   5 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.91 | loss-text 3.6355\n",
      "2021-12-03 16:48:49,703 - INFO: | epoch   5 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.88 | loss-text 3.5910\n",
      "2021-12-03 16:49:24,067 - INFO: | epoch   5 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 343.64 | loss-text 3.6202\n",
      "2021-12-03 16:49:58,287 - INFO: | epoch   5 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.19 | loss-text 3.6606\n",
      "2021-12-03 16:50:32,415 - INFO: | epoch   5 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.27 | loss-text 3.6802\n",
      "2021-12-03 16:51:06,651 - INFO: | epoch   5 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.36 | loss-text 3.6380\n",
      "2021-12-03 16:51:41,045 - INFO: | epoch   5 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 343.93 | loss-text 3.6472\n",
      "2021-12-03 16:52:15,444 - INFO: | epoch   5 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 343.98 | loss-text 3.5547\n",
      "2021-12-03 16:52:49,819 - INFO: | epoch   5 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.74 | loss-text 3.6019\n",
      "2021-12-03 16:53:24,050 - INFO: | epoch   5 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 342.31 | loss-text 3.6317\n",
      "2021-12-03 16:53:58,167 - INFO: | epoch   5 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 341.17 | loss-text 3.6151\n",
      "2021-12-03 16:54:32,199 - INFO: | epoch   5 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 340.32 | loss-text 3.6026\n",
      "2021-12-03 16:55:06,617 - INFO: | epoch   5 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 344.17 | loss-text 3.5897\n",
      "2021-12-03 16:55:40,596 - INFO: | epoch   5 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 339.78 | loss-text 3.5915\n",
      "2021-12-03 16:56:14,828 - INFO: | epoch   5 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 342.31 | loss-text 3.6313\n",
      "2021-12-03 16:56:49,230 - INFO: | epoch   5 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 344.01 | loss-text 3.6257\n",
      "2021-12-03 16:57:23,362 - INFO: | epoch   5 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 341.32 | loss-text 3.5828\n",
      "2021-12-03 16:57:57,803 - INFO: | epoch   5 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 344.40 | loss-text 3.5930\n",
      "2021-12-03 16:58:32,034 - INFO: | epoch   5 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.30 | loss-text 3.6222\n",
      "2021-12-03 16:59:06,325 - INFO: | epoch   5 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.91 | loss-text 3.5887\n",
      "2021-12-03 16:59:40,707 - INFO: | epoch   5 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.81 | loss-text 3.6324\n",
      "2021-12-03 17:00:15,099 - INFO: | epoch   5 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 343.92 | loss-text 3.6250\n",
      "2021-12-03 17:00:49,381 - INFO: | epoch   5 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.81 | loss-text 3.6269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003849\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10353, 'reflen': 10380, 'guess': [10353, 9329, 8305, 7281], 'correct': [5191, 1696, 586, 156]}\n",
      "ratio: 0.9973988439305397\n",
      "Bleu_1: 0.500\n",
      "Bleu_2: 0.301\n",
      "Bleu_3: 0.185\n",
      "Bleu_4: 0.108\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.340\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.255\n",
      "computing SPICE score...\n",
      "SPICE: 0.097\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.176\n",
      "2021-12-03 17:01:45,020 - INFO: eval_greddy SPIDEr: 0.1763\n",
      "loading annotations into memory...\n",
      "0:00:00.003823\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8875, 'reflen': 9535, 'guess': [8875, 7851, 6827, 5803], 'correct': [5093, 1853, 734, 220]}\n",
      "ratio: 0.9307813319348788\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.342\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.142\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.310\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.207\n",
      "2021-12-03 17:02:20,883 - INFO: eval_beam_2 SPIDEr: 0.2072\n",
      "loading annotations into memory...\n",
      "0:00:00.003988\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8656, 'reflen': 9447, 'guess': [8656, 7632, 6608, 5584], 'correct': [5005, 1918, 775, 229]}\n",
      "ratio: 0.9162697152534226\n",
      "Bleu_1: 0.528\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.310\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.205\n",
      "2021-12-03 17:03:00,031 - INFO: eval_beam_3 SPIDEr: 0.2054\n",
      "loading annotations into memory...\n",
      "0:00:00.003937\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8361, 'reflen': 9337, 'guess': [8361, 7337, 6313, 5289], 'correct': [4891, 1896, 776, 243]}\n",
      "ratio: 0.8954696369282537\n",
      "Bleu_1: 0.521\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.152\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.311\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.206\n",
      "2021-12-03 17:03:41,798 - INFO: eval_beam_4 SPIDEr: 0.2055\n",
      "2021-12-03 17:04:15,854 - INFO: | epoch   6 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.53 | loss-text 3.5415\n",
      "2021-12-03 17:04:50,134 - INFO: | epoch   6 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 342.79 | loss-text 3.5801\n",
      "2021-12-03 17:05:24,411 - INFO: | epoch   6 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 342.76 | loss-text 3.5599\n",
      "2021-12-03 17:05:58,941 - INFO: | epoch   6 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 345.29 | loss-text 3.5552\n",
      "2021-12-03 17:06:33,166 - INFO: | epoch   6 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.25 | loss-text 3.5222\n",
      "2021-12-03 17:07:07,571 - INFO: | epoch   6 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 344.04 | loss-text 3.5748\n",
      "2021-12-03 17:07:41,823 - INFO: | epoch   6 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.51 | loss-text 3.5448\n",
      "2021-12-03 17:08:16,210 - INFO: | epoch   6 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.87 | loss-text 3.6175\n",
      "2021-12-03 17:08:50,575 - INFO: | epoch   6 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 343.65 | loss-text 3.5924\n",
      "2021-12-03 17:09:24,838 - INFO: | epoch   6 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.62 | loss-text 3.5961\n",
      "2021-12-03 17:09:59,090 - INFO: | epoch   6 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.51 | loss-text 3.5566\n",
      "2021-12-03 17:10:33,453 - INFO: | epoch   6 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 343.61 | loss-text 3.5858\n",
      "2021-12-03 17:11:07,607 - INFO: | epoch   6 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 341.54 | loss-text 3.5783\n",
      "2021-12-03 17:11:41,774 - INFO: | epoch   6 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.66 | loss-text 3.5318\n",
      "2021-12-03 17:12:16,073 - INFO: | epoch   6 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.99 | loss-text 3.5845\n",
      "2021-12-03 17:12:50,382 - INFO: | epoch   6 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.09 | loss-text 3.5188\n",
      "2021-12-03 17:13:24,795 - INFO: | epoch   6 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 344.12 | loss-text 3.5641\n",
      "2021-12-03 17:13:59,295 - INFO: | epoch   6 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.99 | loss-text 3.5604\n",
      "2021-12-03 17:14:33,370 - INFO: | epoch   6 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 340.74 | loss-text 3.5664\n",
      "2021-12-03 17:15:07,832 - INFO: | epoch   6 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 344.62 | loss-text 3.5428\n",
      "2021-12-03 17:15:42,163 - INFO: | epoch   6 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 343.30 | loss-text 3.5811\n",
      "2021-12-03 17:16:16,738 - INFO: | epoch   6 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 345.74 | loss-text 3.5996\n",
      "2021-12-03 17:16:51,073 - INFO: | epoch   6 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 343.35 | loss-text 3.5884\n",
      "2021-12-03 17:17:25,325 - INFO: | epoch   6 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 342.51 | loss-text 3.4714\n",
      "2021-12-03 17:17:59,692 - INFO: | epoch   6 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.66 | loss-text 3.5448\n",
      "2021-12-03 17:18:34,075 - INFO: | epoch   6 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 343.81 | loss-text 3.5452\n",
      "2021-12-03 17:19:08,301 - INFO: | epoch   6 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.25 | loss-text 3.4932\n",
      "2021-12-03 17:19:42,547 - INFO: | epoch   6 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.45 | loss-text 3.5026\n",
      "2021-12-03 17:20:16,658 - INFO: | epoch   6 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 341.10 | loss-text 3.4803\n",
      "2021-12-03 17:20:51,028 - INFO: | epoch   6 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 343.70 | loss-text 3.5929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003815\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11396, 'reflen': 10863, 'guess': [11396, 10372, 9348, 8324], 'correct': [5494, 1898, 682, 179]}\n",
      "ratio: 1.0490656356438324\n",
      "Bleu_1: 0.482\n",
      "Bleu_2: 0.297\n",
      "Bleu_3: 0.186\n",
      "Bleu_4: 0.108\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.348\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.260\n",
      "computing SPICE score...\n",
      "SPICE: 0.100\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.180\n",
      "2021-12-03 17:21:45,751 - INFO: eval_greddy SPIDEr: 0.1801\n",
      "loading annotations into memory...\n",
      "0:00:00.003908\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9404, 'reflen': 9830, 'guess': [9404, 8380, 7356, 6332], 'correct': [5304, 1944, 755, 220]}\n",
      "ratio: 0.956663275686576\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.305\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.205\n",
      "2021-12-03 17:22:22,124 - INFO: eval_beam_2 SPIDEr: 0.2053\n",
      "loading annotations into memory...\n",
      "0:00:00.003970\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9150, 'reflen': 9708, 'guess': [9150, 8126, 7102, 6078], 'correct': [5234, 2008, 818, 254]}\n",
      "ratio: 0.9425216316439078\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.323\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.213\n",
      "2021-12-03 17:23:01,161 - INFO: eval_beam_3 SPIDEr: 0.2129\n",
      "loading annotations into memory...\n",
      "0:00:00.003918\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8833, 'reflen': 9567, 'guess': [8833, 7809, 6785, 5761], 'correct': [5095, 1988, 830, 271]}\n",
      "ratio: 0.9232779345666433\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.330\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2021-12-03 17:23:44,144 - INFO: eval_beam_4 SPIDEr: 0.2168\n",
      "2021-12-03 17:24:18,454 - INFO: | epoch   7 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 343.06 | loss-text 3.5160\n",
      "2021-12-03 17:24:52,496 - INFO: | epoch   7 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.42 | loss-text 3.4741\n",
      "2021-12-03 17:25:26,682 - INFO: | epoch   7 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.84 | loss-text 3.5548\n",
      "2021-12-03 17:26:01,084 - INFO: | epoch   7 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 344.02 | loss-text 3.5236\n",
      "2021-12-03 17:26:35,365 - INFO: | epoch   7 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.81 | loss-text 3.4755\n",
      "2021-12-03 17:27:09,458 - INFO: | epoch   7 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 340.92 | loss-text 3.5242\n",
      "2021-12-03 17:27:43,994 - INFO: | epoch   7 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 345.35 | loss-text 3.4867\n",
      "2021-12-03 17:28:18,176 - INFO: | epoch   7 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 341.81 | loss-text 3.5358\n",
      "2021-12-03 17:28:52,439 - INFO: | epoch   7 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.62 | loss-text 3.5495\n",
      "2021-12-03 17:29:26,781 - INFO: | epoch   7 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 343.42 | loss-text 3.5180\n",
      "2021-12-03 17:30:01,143 - INFO: | epoch   7 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 343.61 | loss-text 3.4898\n",
      "2021-12-03 17:30:35,461 - INFO: | epoch   7 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 343.17 | loss-text 3.4951\n",
      "2021-12-03 17:31:09,904 - INFO: | epoch   7 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 344.43 | loss-text 3.4656\n",
      "2021-12-03 17:31:43,982 - INFO: | epoch   7 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 340.77 | loss-text 3.5441\n",
      "2021-12-03 17:32:18,175 - INFO: | epoch   7 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 341.92 | loss-text 3.4659\n",
      "2021-12-03 17:32:52,514 - INFO: | epoch   7 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.38 | loss-text 3.4453\n",
      "2021-12-03 17:33:26,879 - INFO: | epoch   7 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.65 | loss-text 3.5275\n",
      "2021-12-03 17:34:01,296 - INFO: | epoch   7 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.16 | loss-text 3.5130\n",
      "2021-12-03 17:34:35,525 - INFO: | epoch   7 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.28 | loss-text 3.4943\n",
      "2021-12-03 17:35:09,802 - INFO: | epoch   7 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.77 | loss-text 3.4843\n",
      "2021-12-03 17:35:44,266 - INFO: | epoch   7 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 344.63 | loss-text 3.4742\n",
      "2021-12-03 17:36:18,083 - INFO: | epoch   7 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 338.16 | loss-text 3.4858\n",
      "2021-12-03 17:36:52,480 - INFO: | epoch   7 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 343.97 | loss-text 3.4773\n",
      "2021-12-03 17:37:27,177 - INFO: | epoch   7 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 346.96 | loss-text 3.4948\n",
      "2021-12-03 17:38:01,697 - INFO: | epoch   7 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 345.20 | loss-text 3.5052\n",
      "2021-12-03 17:38:36,023 - INFO: | epoch   7 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 343.25 | loss-text 3.5282\n",
      "2021-12-03 17:39:10,269 - INFO: | epoch   7 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.45 | loss-text 3.4680\n",
      "2021-12-03 17:39:44,633 - INFO: | epoch   7 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.63 | loss-text 3.5109\n",
      "2021-12-03 17:40:18,789 - INFO: | epoch   7 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 341.55 | loss-text 3.4715\n",
      "2021-12-03 17:40:53,166 - INFO: | epoch   7 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 343.77 | loss-text 3.5176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003889\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10933, 'reflen': 10792, 'guess': [10933, 9909, 8885, 7861], 'correct': [5529, 1858, 664, 180]}\n",
      "ratio: 1.0130652335062071\n",
      "Bleu_1: 0.506\n",
      "Bleu_2: 0.308\n",
      "Bleu_3: 0.192\n",
      "Bleu_4: 0.113\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.346\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.261\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.182\n",
      "2021-12-03 17:41:47,499 - INFO: eval_greddy SPIDEr: 0.1820\n",
      "loading annotations into memory...\n",
      "0:00:00.003679\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9848, 'reflen': 10116, 'guess': [9848, 8824, 7800, 6776], 'correct': [5400, 1931, 760, 226]}\n",
      "ratio: 0.9735073151442295\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.303\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.204\n",
      "2021-12-03 17:42:25,093 - INFO: eval_beam_2 SPIDEr: 0.2042\n",
      "loading annotations into memory...\n",
      "0:00:00.003994\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9284, 'reflen': 9839, 'guess': [9284, 8260, 7236, 6213], 'correct': [5239, 1962, 785, 239]}\n",
      "ratio: 0.9435918284377535\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.313\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.209\n",
      "2021-12-03 17:43:04,453 - INFO: eval_beam_3 SPIDEr: 0.2086\n",
      "loading annotations into memory...\n",
      "0:00:00.003974\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8607, 'reflen': 9514, 'guess': [8607, 7583, 6559, 5536], 'correct': [5055, 1956, 817, 264]}\n",
      "ratio: 0.9046668068109203\n",
      "Bleu_1: 0.529\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.330\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2021-12-03 17:43:48,640 - INFO: eval_beam_4 SPIDEr: 0.2169\n",
      "2021-12-03 17:44:22,957 - INFO: | epoch   8 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 343.13 | loss-text 3.4747\n",
      "2021-12-03 17:44:57,143 - INFO: | epoch   8 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 341.85 | loss-text 3.4355\n",
      "2021-12-03 17:45:31,447 - INFO: | epoch   8 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 343.03 | loss-text 3.4377\n",
      "2021-12-03 17:46:05,595 - INFO: | epoch   8 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.48 | loss-text 3.4594\n",
      "2021-12-03 17:46:39,964 - INFO: | epoch   8 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 343.68 | loss-text 3.4615\n",
      "2021-12-03 17:47:14,034 - INFO: | epoch   8 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 340.69 | loss-text 3.4046\n",
      "2021-12-03 17:47:48,376 - INFO: | epoch   8 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 343.42 | loss-text 3.4476\n",
      "2021-12-03 17:48:22,476 - INFO: | epoch   8 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 341.00 | loss-text 3.4479\n",
      "2021-12-03 17:48:56,881 - INFO: | epoch   8 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 344.04 | loss-text 3.4178\n",
      "2021-12-03 17:49:31,060 - INFO: | epoch   8 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 341.78 | loss-text 3.4907\n",
      "2021-12-03 17:50:05,223 - INFO: | epoch   8 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 341.62 | loss-text 3.4202\n",
      "2021-12-03 17:50:39,587 - INFO: | epoch   8 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 343.64 | loss-text 3.4492\n",
      "2021-12-03 17:51:13,681 - INFO: | epoch   8 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 340.93 | loss-text 3.4308\n",
      "2021-12-03 17:51:48,101 - INFO: | epoch   8 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 344.19 | loss-text 3.4634\n",
      "2021-12-03 17:52:22,323 - INFO: | epoch   8 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.21 | loss-text 3.4165\n",
      "2021-12-03 17:52:56,318 - INFO: | epoch   8 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 339.95 | loss-text 3.4233\n",
      "2021-12-03 17:53:30,879 - INFO: | epoch   8 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 345.60 | loss-text 3.4378\n",
      "2021-12-03 17:54:05,335 - INFO: | epoch   8 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.55 | loss-text 3.4098\n",
      "2021-12-03 17:54:39,595 - INFO: | epoch   8 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.60 | loss-text 3.4075\n",
      "2021-12-03 17:55:14,047 - INFO: | epoch   8 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 344.51 | loss-text 3.4371\n",
      "2021-12-03 17:55:48,385 - INFO: | epoch   8 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 343.38 | loss-text 3.5023\n",
      "2021-12-03 17:56:22,904 - INFO: | epoch   8 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 345.18 | loss-text 3.4431\n",
      "2021-12-03 17:56:57,203 - INFO: | epoch   8 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.98 | loss-text 3.4134\n",
      "2021-12-03 17:57:31,603 - INFO: | epoch   8 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.99 | loss-text 3.3957\n",
      "2021-12-03 17:58:06,000 - INFO: | epoch   8 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.96 | loss-text 3.3975\n",
      "2021-12-03 17:58:40,160 - INFO: | epoch   8 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 341.59 | loss-text 3.4546\n",
      "2021-12-03 17:59:14,516 - INFO: | epoch   8 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 343.56 | loss-text 3.4540\n",
      "2021-12-03 17:59:48,782 - INFO: | epoch   8 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.65 | loss-text 3.5122\n",
      "2021-12-03 18:00:23,188 - INFO: | epoch   8 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 344.05 | loss-text 3.4334\n",
      "2021-12-03 18:00:57,492 - INFO: | epoch   8 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 343.03 | loss-text 3.4360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003825\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10490, 'reflen': 10509, 'guess': [10490, 9466, 8442, 7418], 'correct': [5499, 1905, 692, 188]}\n",
      "ratio: 0.9981920258824818\n",
      "Bleu_1: 0.523\n",
      "Bleu_2: 0.324\n",
      "Bleu_3: 0.205\n",
      "Bleu_4: 0.121\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.287\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.194\n",
      "2021-12-03 18:01:50,919 - INFO: eval_greddy SPIDEr: 0.1943\n",
      "loading annotations into memory...\n",
      "0:00:00.003875\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9375, 'reflen': 9828, 'guess': [9375, 8351, 7327, 6303], 'correct': [5306, 1970, 795, 256]}\n",
      "ratio: 0.9539072039071068\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.327\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-03 18:02:26,681 - INFO: eval_beam_2 SPIDEr: 0.2155\n",
      "loading annotations into memory...\n",
      "0:00:00.003973\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8947, 'reflen': 9607, 'guess': [8947, 7923, 6899, 5875], 'correct': [5149, 1939, 809, 268]}\n",
      "ratio: 0.9313000936815935\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.332\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2021-12-03 18:03:05,587 - INFO: eval_beam_3 SPIDEr: 0.2170\n",
      "loading annotations into memory...\n",
      "0:00:00.003864\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8728, 'reflen': 9476, 'guess': [8728, 7704, 6680, 5656], 'correct': [5039, 1924, 812, 269]}\n",
      "ratio: 0.9210637399745756\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.335\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.218\n",
      "2021-12-03 18:03:47,132 - INFO: eval_beam_4 SPIDEr: 0.2179\n",
      "2021-12-03 18:04:21,211 - INFO: | epoch   9 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.76 | loss-text 3.4084\n",
      "2021-12-03 18:04:55,387 - INFO: | epoch   9 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 341.75 | loss-text 3.4306\n",
      "2021-12-03 18:05:29,669 - INFO: | epoch   9 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 342.81 | loss-text 3.4179\n",
      "2021-12-03 18:06:03,872 - INFO: | epoch   9 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 342.03 | loss-text 3.4063\n",
      "2021-12-03 18:06:38,153 - INFO: | epoch   9 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.80 | loss-text 3.3851\n",
      "2021-12-03 18:07:12,163 - INFO: | epoch   9 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 340.10 | loss-text 3.3659\n",
      "2021-12-03 18:07:46,381 - INFO: | epoch   9 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.17 | loss-text 3.3790\n",
      "2021-12-03 18:08:20,447 - INFO: | epoch   9 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 340.65 | loss-text 3.4438\n",
      "2021-12-03 18:08:54,727 - INFO: | epoch   9 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.79 | loss-text 3.4115\n",
      "2021-12-03 18:09:29,085 - INFO: | epoch   9 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 343.58 | loss-text 3.4237\n",
      "2021-12-03 18:10:03,179 - INFO: | epoch   9 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 340.93 | loss-text 3.4336\n",
      "2021-12-03 18:10:37,654 - INFO: | epoch   9 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 344.74 | loss-text 3.4207\n",
      "2021-12-03 18:11:11,729 - INFO: | epoch   9 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 340.72 | loss-text 3.3667\n",
      "2021-12-03 18:11:46,153 - INFO: | epoch   9 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 344.24 | loss-text 3.4397\n",
      "2021-12-03 18:12:20,393 - INFO: | epoch   9 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.38 | loss-text 3.3936\n",
      "2021-12-03 18:12:54,890 - INFO: | epoch   9 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 344.96 | loss-text 3.4416\n",
      "2021-12-03 18:13:29,192 - INFO: | epoch   9 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.02 | loss-text 3.3587\n",
      "2021-12-03 18:14:03,481 - INFO: | epoch   9 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 342.89 | loss-text 3.3774\n",
      "2021-12-03 18:14:38,095 - INFO: | epoch   9 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 346.13 | loss-text 3.3585\n",
      "2021-12-03 18:15:12,206 - INFO: | epoch   9 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 341.10 | loss-text 3.3451\n",
      "2021-12-03 18:15:46,440 - INFO: | epoch   9 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 342.34 | loss-text 3.3764\n",
      "2021-12-03 18:16:20,765 - INFO: | epoch   9 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 343.24 | loss-text 3.4451\n",
      "2021-12-03 18:16:55,197 - INFO: | epoch   9 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 344.32 | loss-text 3.4087\n",
      "2021-12-03 18:17:29,535 - INFO: | epoch   9 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.38 | loss-text 3.4367\n",
      "2021-12-03 18:18:03,715 - INFO: | epoch   9 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 341.79 | loss-text 3.3777\n",
      "2021-12-03 18:18:37,723 - INFO: | epoch   9 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 340.07 | loss-text 3.4008\n",
      "2021-12-03 18:19:11,860 - INFO: | epoch   9 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.36 | loss-text 3.4276\n",
      "2021-12-03 18:19:46,138 - INFO: | epoch   9 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.77 | loss-text 3.3729\n",
      "2021-12-03 18:20:20,350 - INFO: | epoch   9 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.12 | loss-text 3.4076\n",
      "2021-12-03 18:20:54,612 - INFO: | epoch   9 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.62 | loss-text 3.4077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003850\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10084, 'reflen': 10206, 'guess': [10084, 9060, 8036, 7012], 'correct': [5463, 1929, 734, 201]}\n",
      "ratio: 0.9880462473054097\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.336\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.301\n",
      "computing SPICE score...\n",
      "SPICE: 0.104\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.203\n",
      "2021-12-03 18:21:46,774 - INFO: eval_greddy SPIDEr: 0.2026\n",
      "loading annotations into memory...\n",
      "0:00:00.003707\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9240, 'reflen': 9762, 'guess': [9240, 8216, 7192, 6168], 'correct': [5397, 2082, 857, 271]}\n",
      "ratio: 0.9465273509525767\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.364\n",
      "Bleu_3: 0.246\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.345\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2021-12-03 18:22:22,403 - INFO: eval_beam_2 SPIDEr: 0.2287\n",
      "loading annotations into memory...\n",
      "0:00:00.003865\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8867, 'reflen': 9560, 'guess': [8867, 7843, 6819, 5795], 'correct': [5210, 2041, 862, 280]}\n",
      "ratio: 0.927510460250949\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.362\n",
      "Bleu_3: 0.248\n",
      "Bleu_4: 0.162\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.345\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2021-12-03 18:23:00,407 - INFO: eval_beam_3 SPIDEr: 0.2269\n",
      "loading annotations into memory...\n",
      "0:00:00.003924\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8629, 'reflen': 9435, 'guess': [8629, 7605, 6581, 5557], 'correct': [5082, 2016, 857, 281]}\n",
      "ratio: 0.9145733969262412\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.249\n",
      "Bleu_4: 0.163\n",
      "computing METEOR score...\n",
      "METEOR: 0.156\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.342\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2021-12-03 18:23:42,533 - INFO: eval_beam_4 SPIDEr: 0.2252\n",
      "2021-12-03 18:24:16,586 - INFO: | epoch  10 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.50 | loss-text 3.3626\n",
      "2021-12-03 18:24:50,577 - INFO: | epoch  10 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.90 | loss-text 3.3173\n",
      "2021-12-03 18:25:24,765 - INFO: | epoch  10 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.88 | loss-text 3.3754\n",
      "2021-12-03 18:25:58,866 - INFO: | epoch  10 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.00 | loss-text 3.3740\n",
      "2021-12-03 18:26:32,980 - INFO: | epoch  10 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 341.14 | loss-text 3.4000\n",
      "2021-12-03 18:27:07,361 - INFO: | epoch  10 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 343.80 | loss-text 3.3724\n",
      "2021-12-03 18:27:41,258 - INFO: | epoch  10 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 338.96 | loss-text 3.3750\n",
      "2021-12-03 18:28:15,375 - INFO: | epoch  10 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 341.16 | loss-text 3.3892\n",
      "2021-12-03 18:28:49,606 - INFO: | epoch  10 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.31 | loss-text 3.3551\n",
      "2021-12-03 18:29:24,128 - INFO: | epoch  10 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 345.22 | loss-text 3.3915\n",
      "2021-12-03 18:29:58,382 - INFO: | epoch  10 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.53 | loss-text 3.3421\n",
      "2021-12-03 18:30:32,624 - INFO: | epoch  10 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.41 | loss-text 3.3923\n",
      "2021-12-03 18:31:06,782 - INFO: | epoch  10 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 341.58 | loss-text 3.3547\n",
      "2021-12-03 18:31:41,045 - INFO: | epoch  10 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.63 | loss-text 3.3705\n",
      "2021-12-03 18:32:15,548 - INFO: | epoch  10 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 345.02 | loss-text 3.3150\n",
      "2021-12-03 18:32:49,725 - INFO: | epoch  10 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 341.77 | loss-text 3.2996\n",
      "2021-12-03 18:33:24,048 - INFO: | epoch  10 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.22 | loss-text 3.3252\n",
      "2021-12-03 18:33:58,172 - INFO: | epoch  10 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 341.23 | loss-text 3.3389\n",
      "2021-12-03 18:34:32,393 - INFO: | epoch  10 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.21 | loss-text 3.3956\n",
      "2021-12-03 18:35:06,689 - INFO: | epoch  10 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.95 | loss-text 3.3585\n",
      "2021-12-03 18:35:40,918 - INFO: | epoch  10 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 342.28 | loss-text 3.3385\n",
      "2021-12-03 18:36:15,254 - INFO: | epoch  10 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 343.36 | loss-text 3.3683\n",
      "2021-12-03 18:36:49,535 - INFO: | epoch  10 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.80 | loss-text 3.3110\n",
      "2021-12-03 18:37:23,709 - INFO: | epoch  10 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 341.73 | loss-text 3.3350\n",
      "2021-12-03 18:37:57,740 - INFO: | epoch  10 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 340.31 | loss-text 3.4022\n",
      "2021-12-03 18:38:31,923 - INFO: | epoch  10 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 341.82 | loss-text 3.3427\n",
      "2021-12-03 18:39:06,445 - INFO: | epoch  10 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 345.22 | loss-text 3.3440\n",
      "2021-12-03 18:39:40,999 - INFO: | epoch  10 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 345.53 | loss-text 3.3388\n",
      "2021-12-03 18:40:15,038 - INFO: | epoch  10 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 340.38 | loss-text 3.3386\n",
      "2021-12-03 18:40:49,389 - INFO: | epoch  10 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 343.50 | loss-text 3.2997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003960\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10849, 'reflen': 10712, 'guess': [10849, 9825, 8801, 7777], 'correct': [5643, 1922, 679, 194]}\n",
      "ratio: 1.012789395070854\n",
      "Bleu_1: 0.520\n",
      "Bleu_2: 0.319\n",
      "Bleu_3: 0.199\n",
      "Bleu_4: 0.118\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.295\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.202\n",
      "2021-12-03 18:41:43,884 - INFO: eval_greddy SPIDEr: 0.2018\n",
      "loading annotations into memory...\n",
      "0:00:00.003906\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9689, 'reflen': 9984, 'guess': [9689, 8665, 7641, 6617], 'correct': [5515, 2035, 779, 229]}\n",
      "ratio: 0.9704527243588771\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.355\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.341\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2021-12-03 18:42:20,820 - INFO: eval_beam_2 SPIDEr: 0.2272\n",
      "loading annotations into memory...\n",
      "0:00:00.003998\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9308, 'reflen': 9741, 'guess': [9308, 8284, 7260, 6236], 'correct': [5341, 2021, 834, 263]}\n",
      "ratio: 0.9555487116311512\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.357\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.341\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2021-12-03 18:43:00,149 - INFO: eval_beam_3 SPIDEr: 0.2252\n",
      "loading annotations into memory...\n",
      "0:00:00.003951\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9014, 'reflen': 9577, 'guess': [9014, 7990, 6966, 5942], 'correct': [5248, 2025, 855, 287]}\n",
      "ratio: 0.9412133235876641\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.361\n",
      "Bleu_3: 0.247\n",
      "Bleu_4: 0.162\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.351\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2021-12-03 18:43:42,875 - INFO: eval_beam_4 SPIDEr: 0.2302\n",
      "2021-12-03 18:44:16,824 - INFO: | epoch  11 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 339.46 | loss-text 3.3161\n",
      "2021-12-03 18:44:51,048 - INFO: | epoch  11 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 342.23 | loss-text 3.3137\n",
      "2021-12-03 18:45:25,405 - INFO: | epoch  11 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 343.57 | loss-text 3.3404\n",
      "2021-12-03 18:45:59,593 - INFO: | epoch  11 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.87 | loss-text 3.3574\n",
      "2021-12-03 18:46:33,718 - INFO: | epoch  11 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 341.24 | loss-text 3.3264\n",
      "2021-12-03 18:47:08,239 - INFO: | epoch  11 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 345.21 | loss-text 3.3712\n",
      "2021-12-03 18:47:42,485 - INFO: | epoch  11 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.44 | loss-text 3.3050\n",
      "2021-12-03 18:48:16,636 - INFO: | epoch  11 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 341.51 | loss-text 3.3298\n",
      "2021-12-03 18:48:51,259 - INFO: | epoch  11 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 346.22 | loss-text 3.3486\n",
      "2021-12-03 18:49:25,576 - INFO: | epoch  11 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 343.16 | loss-text 3.2889\n",
      "2021-12-03 18:49:59,859 - INFO: | epoch  11 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.83 | loss-text 3.2999\n",
      "2021-12-03 18:50:33,971 - INFO: | epoch  11 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.11 | loss-text 3.3567\n",
      "2021-12-03 18:51:08,314 - INFO: | epoch  11 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 343.43 | loss-text 3.3492\n",
      "2021-12-03 18:51:42,621 - INFO: | epoch  11 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 343.07 | loss-text 3.3301\n",
      "2021-12-03 18:52:16,942 - INFO: | epoch  11 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 343.20 | loss-text 3.3767\n",
      "2021-12-03 18:52:51,155 - INFO: | epoch  11 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.12 | loss-text 3.3464\n",
      "2021-12-03 18:53:25,464 - INFO: | epoch  11 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.08 | loss-text 3.3194\n",
      "2021-12-03 18:53:59,785 - INFO: | epoch  11 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 343.20 | loss-text 3.3596\n",
      "2021-12-03 18:54:33,960 - INFO: | epoch  11 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 341.75 | loss-text 3.3293\n",
      "2021-12-03 18:55:08,193 - INFO: | epoch  11 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.32 | loss-text 3.3090\n",
      "2021-12-03 18:55:42,598 - INFO: | epoch  11 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 344.05 | loss-text 3.3359\n",
      "2021-12-03 18:56:16,971 - INFO: | epoch  11 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 343.72 | loss-text 3.3558\n",
      "2021-12-03 18:56:51,197 - INFO: | epoch  11 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.25 | loss-text 3.3052\n",
      "2021-12-03 18:57:25,514 - INFO: | epoch  11 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.17 | loss-text 3.3336\n",
      "2021-12-03 18:57:59,716 - INFO: | epoch  11 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 342.01 | loss-text 3.3373\n",
      "2021-12-03 18:58:34,056 - INFO: | epoch  11 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 343.40 | loss-text 3.3287\n",
      "2021-12-03 18:59:08,496 - INFO: | epoch  11 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 344.39 | loss-text 3.2759\n",
      "2021-12-03 18:59:42,892 - INFO: | epoch  11 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.96 | loss-text 3.3553\n",
      "2021-12-03 19:00:17,259 - INFO: | epoch  11 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 343.66 | loss-text 3.2668\n",
      "2021-12-03 19:00:51,342 - INFO: | epoch  11 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 340.82 | loss-text 3.2951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003920\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10224, 'reflen': 10316, 'guess': [10224, 9200, 8176, 7152], 'correct': [5530, 1920, 721, 223]}\n",
      "ratio: 0.9910818146567476\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.333\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.314\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.211\n",
      "2021-12-03 19:01:44,964 - INFO: eval_greddy SPIDEr: 0.2106\n",
      "loading annotations into memory...\n",
      "0:00:00.003833\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9305, 'reflen': 9782, 'guess': [9305, 8281, 7257, 6233], 'correct': [5351, 2002, 804, 262]}\n",
      "ratio: 0.951236965855556\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.347\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2021-12-03 19:02:20,961 - INFO: eval_beam_2 SPIDEr: 0.2277\n",
      "loading annotations into memory...\n",
      "0:00:00.003895\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8957, 'reflen': 9548, 'guess': [8957, 7933, 6909, 5885], 'correct': [5210, 1977, 803, 275]}\n",
      "ratio: 0.9381022203601865\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.350\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2021-12-03 19:02:59,065 - INFO: eval_beam_3 SPIDEr: 0.2285\n",
      "loading annotations into memory...\n",
      "0:00:00.004042\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8784, 'reflen': 9469, 'guess': [8784, 7760, 6736, 5712], 'correct': [5142, 1978, 818, 281]}\n",
      "ratio: 0.927658675678432\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.357\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.354\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2021-12-03 19:03:41,360 - INFO: eval_beam_4 SPIDEr: 0.2297\n",
      "2021-12-03 19:04:15,822 - INFO: | epoch  12 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 344.58 | loss-text 3.2896\n",
      "2021-12-03 19:04:49,930 - INFO: | epoch  12 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 341.07 | loss-text 3.2457\n",
      "2021-12-03 19:05:23,968 - INFO: | epoch  12 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 340.37 | loss-text 3.3070\n",
      "2021-12-03 19:05:58,067 - INFO: | epoch  12 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 340.98 | loss-text 3.3050\n",
      "2021-12-03 19:06:32,499 - INFO: | epoch  12 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 344.32 | loss-text 3.2753\n",
      "2021-12-03 19:07:06,726 - INFO: | epoch  12 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.25 | loss-text 3.3186\n",
      "2021-12-03 19:07:41,171 - INFO: | epoch  12 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 344.45 | loss-text 3.2879\n",
      "2021-12-03 19:08:15,408 - INFO: | epoch  12 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 342.37 | loss-text 3.3187\n",
      "2021-12-03 19:08:49,582 - INFO: | epoch  12 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.73 | loss-text 3.2989\n",
      "2021-12-03 19:09:23,942 - INFO: | epoch  12 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 343.59 | loss-text 3.3118\n",
      "2021-12-03 19:09:58,098 - INFO: | epoch  12 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 341.55 | loss-text 3.3184\n",
      "2021-12-03 19:10:32,701 - INFO: | epoch  12 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 346.02 | loss-text 3.2948\n",
      "2021-12-03 19:11:06,905 - INFO: | epoch  12 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.03 | loss-text 3.2643\n",
      "2021-12-03 19:11:41,050 - INFO: | epoch  12 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.44 | loss-text 3.2934\n",
      "2021-12-03 19:12:15,122 - INFO: | epoch  12 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 340.71 | loss-text 3.2946\n",
      "2021-12-03 19:12:49,280 - INFO: | epoch  12 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 341.57 | loss-text 3.3143\n",
      "2021-12-03 19:13:23,588 - INFO: | epoch  12 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.07 | loss-text 3.3190\n",
      "2021-12-03 19:13:57,874 - INFO: | epoch  12 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 342.86 | loss-text 3.2946\n",
      "2021-12-03 19:14:31,995 - INFO: | epoch  12 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 341.20 | loss-text 3.2612\n",
      "2021-12-03 19:15:06,351 - INFO: | epoch  12 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 343.55 | loss-text 3.2702\n",
      "2021-12-03 19:15:40,668 - INFO: | epoch  12 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 343.16 | loss-text 3.2727\n",
      "2021-12-03 19:16:15,139 - INFO: | epoch  12 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 344.70 | loss-text 3.2454\n",
      "2021-12-03 19:16:49,500 - INFO: | epoch  12 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 343.61 | loss-text 3.3111\n",
      "2021-12-03 19:17:23,941 - INFO: | epoch  12 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 344.41 | loss-text 3.3267\n",
      "2021-12-03 19:17:58,277 - INFO: | epoch  12 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.35 | loss-text 3.3068\n",
      "2021-12-03 19:18:32,549 - INFO: | epoch  12 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.71 | loss-text 3.2827\n",
      "2021-12-03 19:19:06,838 - INFO: | epoch  12 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.89 | loss-text 3.2785\n",
      "2021-12-03 19:19:41,213 - INFO: | epoch  12 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.75 | loss-text 3.2712\n",
      "2021-12-03 19:20:15,644 - INFO: | epoch  12 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 344.30 | loss-text 3.2765\n",
      "2021-12-03 19:20:50,086 - INFO: | epoch  12 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 344.41 | loss-text 3.2661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003883\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10432, 'reflen': 10418, 'guess': [10432, 9408, 8384, 7360], 'correct': [5644, 1907, 686, 216]}\n",
      "ratio: 1.0013438279899212\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.323\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.216\n",
      "2021-12-03 19:21:44,290 - INFO: eval_greddy SPIDEr: 0.2159\n",
      "loading annotations into memory...\n",
      "0:00:00.003967\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9214, 'reflen': 9682, 'guess': [9214, 8190, 7166, 6142], 'correct': [5354, 1944, 761, 235]}\n",
      "ratio: 0.9516628795702383\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-03 19:22:19,974 - INFO: eval_beam_2 SPIDEr: 0.2358\n",
      "loading annotations into memory...\n",
      "0:00:00.003917\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8804, 'reflen': 9480, 'guess': [8804, 7780, 6756, 5732], 'correct': [5160, 1901, 741, 228]}\n",
      "ratio: 0.9286919831222649\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.354\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2021-12-03 19:22:58,597 - INFO: eval_beam_3 SPIDEr: 0.2299\n",
      "loading annotations into memory...\n",
      "0:00:00.004059\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8633, 'reflen': 9403, 'guess': [8633, 7609, 6585, 5561], 'correct': [5087, 1912, 788, 279]}\n",
      "ratio: 0.9181112410931704\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-03 19:23:40,133 - INFO: eval_beam_4 SPIDEr: 0.2336\n",
      "2021-12-03 19:24:14,437 - INFO: | epoch  13 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 343.01 | loss-text 3.2768\n",
      "2021-12-03 19:24:48,389 - INFO: | epoch  13 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.50 | loss-text 3.2572\n",
      "2021-12-03 19:25:22,807 - INFO: | epoch  13 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 344.18 | loss-text 3.2210\n",
      "2021-12-03 19:25:56,699 - INFO: | epoch  13 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 338.92 | loss-text 3.2620\n",
      "2021-12-03 19:26:31,054 - INFO: | epoch  13 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 343.54 | loss-text 3.2991\n",
      "2021-12-03 19:27:05,353 - INFO: | epoch  13 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.99 | loss-text 3.3183\n",
      "2021-12-03 19:27:39,430 - INFO: | epoch  13 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 340.76 | loss-text 3.2351\n",
      "2021-12-03 19:28:13,720 - INFO: | epoch  13 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 342.89 | loss-text 3.2399\n",
      "2021-12-03 19:28:47,926 - INFO: | epoch  13 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.06 | loss-text 3.2609\n",
      "2021-12-03 19:29:22,288 - INFO: | epoch  13 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 343.61 | loss-text 3.2651\n",
      "2021-12-03 19:29:56,651 - INFO: | epoch  13 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 343.62 | loss-text 3.2584\n",
      "2021-12-03 19:30:30,843 - INFO: | epoch  13 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.91 | loss-text 3.2718\n",
      "2021-12-03 19:31:05,326 - INFO: | epoch  13 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 344.83 | loss-text 3.2869\n",
      "2021-12-03 19:31:39,544 - INFO: | epoch  13 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.17 | loss-text 3.2499\n",
      "2021-12-03 19:32:13,841 - INFO: | epoch  13 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.97 | loss-text 3.2169\n",
      "2021-12-03 19:32:48,077 - INFO: | epoch  13 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.35 | loss-text 3.2682\n",
      "2021-12-03 19:33:22,372 - INFO: | epoch  13 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 342.95 | loss-text 3.3001\n",
      "2021-12-03 19:33:56,602 - INFO: | epoch  13 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 342.30 | loss-text 3.2492\n",
      "2021-12-03 19:34:30,823 - INFO: | epoch  13 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.20 | loss-text 3.2540\n",
      "2021-12-03 19:35:05,021 - INFO: | epoch  13 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 341.98 | loss-text 3.2470\n",
      "2021-12-03 19:35:39,464 - INFO: | epoch  13 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 344.43 | loss-text 3.2766\n",
      "2021-12-03 19:36:14,037 - INFO: | epoch  13 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 345.72 | loss-text 3.2405\n",
      "2021-12-03 19:36:48,459 - INFO: | epoch  13 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 344.21 | loss-text 3.3398\n",
      "2021-12-03 19:37:22,893 - INFO: | epoch  13 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 344.33 | loss-text 3.2510\n",
      "2021-12-03 19:37:57,401 - INFO: | epoch  13 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 345.08 | loss-text 3.2764\n",
      "2021-12-03 19:38:31,561 - INFO: | epoch  13 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 341.60 | loss-text 3.2302\n",
      "2021-12-03 19:39:06,160 - INFO: | epoch  13 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 345.98 | loss-text 3.2602\n",
      "2021-12-03 19:39:40,445 - INFO: | epoch  13 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.84 | loss-text 3.2446\n",
      "2021-12-03 19:40:14,791 - INFO: | epoch  13 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 343.46 | loss-text 3.2460\n",
      "2021-12-03 19:40:49,027 - INFO: | epoch  13 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.35 | loss-text 3.2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004163\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10032, 'reflen': 10221, 'guess': [10032, 9008, 7984, 6960], 'correct': [5483, 1902, 698, 203]}\n",
      "ratio: 0.9815086586438723\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.333\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.320\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2021-12-03 19:41:42,194 - INFO: eval_greddy SPIDEr: 0.2145\n",
      "loading annotations into memory...\n",
      "0:00:00.003856\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9107, 'reflen': 9649, 'guess': [9107, 8083, 7059, 6035], 'correct': [5301, 1990, 799, 249]}\n",
      "ratio: 0.9438283759974149\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.357\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.344\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2021-12-03 19:42:18,544 - INFO: eval_beam_2 SPIDEr: 0.2274\n",
      "loading annotations into memory...\n",
      "0:00:00.003891\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8819, 'reflen': 9497, 'guess': [8819, 7795, 6771, 5747], 'correct': [5205, 1993, 822, 266]}\n",
      "ratio: 0.9286090344318281\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.352\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-03 19:42:56,449 - INFO: eval_beam_3 SPIDEr: 0.2307\n",
      "loading annotations into memory...\n",
      "0:00:00.003782\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8669, 'reflen': 9394, 'guess': [8669, 7645, 6621, 5597], 'correct': [5118, 1986, 815, 266]}\n",
      "ratio: 0.9228230785606852\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.245\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.355\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-03 19:43:39,008 - INFO: eval_beam_4 SPIDEr: 0.2320\n",
      "2021-12-03 19:44:13,426 - INFO: | epoch  14 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 344.15 | loss-text 3.1758\n",
      "2021-12-03 19:44:47,605 - INFO: | epoch  14 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 341.78 | loss-text 3.2735\n",
      "2021-12-03 19:45:21,667 - INFO: | epoch  14 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 340.61 | loss-text 3.2401\n",
      "2021-12-03 19:45:55,828 - INFO: | epoch  14 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.60 | loss-text 3.2489\n",
      "2021-12-03 19:46:30,153 - INFO: | epoch  14 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 343.24 | loss-text 3.1978\n",
      "2021-12-03 19:47:04,611 - INFO: | epoch  14 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 344.58 | loss-text 3.1774\n",
      "2021-12-03 19:47:38,811 - INFO: | epoch  14 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 341.99 | loss-text 3.2114\n",
      "2021-12-03 19:48:13,342 - INFO: | epoch  14 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 345.30 | loss-text 3.2199\n",
      "2021-12-03 19:48:47,427 - INFO: | epoch  14 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 340.85 | loss-text 3.2393\n",
      "2021-12-03 19:49:21,898 - INFO: | epoch  14 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 344.70 | loss-text 3.1788\n",
      "2021-12-03 19:49:56,319 - INFO: | epoch  14 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 344.20 | loss-text 3.2208\n",
      "2021-12-03 19:50:30,305 - INFO: | epoch  14 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 339.86 | loss-text 3.2610\n",
      "2021-12-03 19:51:04,946 - INFO: | epoch  14 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 346.41 | loss-text 3.2320\n",
      "2021-12-03 19:51:39,335 - INFO: | epoch  14 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 343.88 | loss-text 3.2451\n",
      "2021-12-03 19:52:13,809 - INFO: | epoch  14 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 344.74 | loss-text 3.2279\n",
      "2021-12-03 19:52:47,885 - INFO: | epoch  14 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 340.75 | loss-text 3.2181\n",
      "2021-12-03 19:53:22,294 - INFO: | epoch  14 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 344.09 | loss-text 3.1861\n",
      "2021-12-03 19:53:56,655 - INFO: | epoch  14 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 343.60 | loss-text 3.2106\n",
      "2021-12-03 19:54:31,001 - INFO: | epoch  14 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 343.46 | loss-text 3.2053\n",
      "2021-12-03 19:55:05,274 - INFO: | epoch  14 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.72 | loss-text 3.2136\n",
      "2021-12-03 19:55:39,691 - INFO: | epoch  14 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 344.16 | loss-text 3.2670\n",
      "2021-12-03 19:56:14,032 - INFO: | epoch  14 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 343.41 | loss-text 3.2447\n",
      "2021-12-03 19:56:48,463 - INFO: | epoch  14 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 344.30 | loss-text 3.2010\n",
      "2021-12-03 19:57:22,849 - INFO: | epoch  14 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.86 | loss-text 3.2721\n",
      "2021-12-03 19:57:56,942 - INFO: | epoch  14 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 340.92 | loss-text 3.2404\n",
      "2021-12-03 19:58:30,854 - INFO: | epoch  14 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 339.11 | loss-text 3.2499\n",
      "2021-12-03 19:59:05,159 - INFO: | epoch  14 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 343.04 | loss-text 3.2015\n",
      "2021-12-03 19:59:39,255 - INFO: | epoch  14 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 340.95 | loss-text 3.2545\n",
      "2021-12-03 20:00:13,372 - INFO: | epoch  14 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 341.17 | loss-text 3.2592\n",
      "2021-12-03 20:00:47,653 - INFO: | epoch  14 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.80 | loss-text 3.2721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003890\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10329, 'reflen': 10381, 'guess': [10329, 9305, 8281, 7257], 'correct': [5660, 2092, 779, 226]}\n",
      "ratio: 0.994990848665736\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.328\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.219\n",
      "2021-12-03 20:01:41,455 - INFO: eval_greddy SPIDEr: 0.2188\n",
      "loading annotations into memory...\n",
      "0:00:00.004014\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9615, 'reflen': 9914, 'guess': [9615, 8591, 7567, 6543], 'correct': [5504, 2070, 823, 261]}\n",
      "ratio: 0.9698406294128535\n",
      "Bleu_1: 0.555\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-03 20:02:17,785 - INFO: eval_beam_2 SPIDEr: 0.2383\n",
      "loading annotations into memory...\n",
      "0:00:00.003845\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9279, 'reflen': 9705, 'guess': [9279, 8255, 7231, 6207], 'correct': [5362, 2085, 863, 291]}\n",
      "ratio: 0.95610510046358\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.365\n",
      "Bleu_3: 0.248\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-03 20:02:56,985 - INFO: eval_beam_3 SPIDEr: 0.2440\n",
      "loading annotations into memory...\n",
      "0:00:00.004017\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9089, 'reflen': 9622, 'guess': [9089, 8065, 7042, 6019], 'correct': [5270, 2085, 864, 300]}\n",
      "ratio: 0.9446061109955368\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.365\n",
      "Bleu_3: 0.249\n",
      "Bleu_4: 0.164\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-03 20:03:39,952 - INFO: eval_beam_4 SPIDEr: 0.2426\n",
      "2021-12-03 20:04:14,236 - INFO: | epoch  15 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 342.80 | loss-text 3.1892\n",
      "2021-12-03 20:04:48,256 - INFO: | epoch  15 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.19 | loss-text 3.1848\n",
      "2021-12-03 20:05:22,387 - INFO: | epoch  15 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.31 | loss-text 3.1993\n",
      "2021-12-03 20:05:56,590 - INFO: | epoch  15 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 342.02 | loss-text 3.2119\n",
      "2021-12-03 20:06:30,985 - INFO: | epoch  15 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 343.94 | loss-text 3.2078\n",
      "2021-12-03 20:07:05,374 - INFO: | epoch  15 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 343.88 | loss-text 3.1940\n",
      "2021-12-03 20:07:39,704 - INFO: | epoch  15 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 343.30 | loss-text 3.2307\n",
      "2021-12-03 20:08:14,143 - INFO: | epoch  15 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 344.38 | loss-text 3.1379\n",
      "2021-12-03 20:08:48,599 - INFO: | epoch  15 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 344.55 | loss-text 3.1445\n",
      "2021-12-03 20:09:22,876 - INFO: | epoch  15 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.76 | loss-text 3.1946\n",
      "2021-12-03 20:09:57,078 - INFO: | epoch  15 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.02 | loss-text 3.1852\n",
      "2021-12-03 20:10:31,242 - INFO: | epoch  15 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.64 | loss-text 3.2274\n",
      "2021-12-03 20:11:05,407 - INFO: | epoch  15 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 341.64 | loss-text 3.2391\n",
      "2021-12-03 20:11:39,423 - INFO: | epoch  15 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 340.16 | loss-text 3.2347\n",
      "2021-12-03 20:12:13,709 - INFO: | epoch  15 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.85 | loss-text 3.2237\n",
      "2021-12-03 20:12:48,014 - INFO: | epoch  15 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.05 | loss-text 3.2328\n",
      "2021-12-03 20:13:22,103 - INFO: | epoch  15 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 340.88 | loss-text 3.2133\n",
      "2021-12-03 20:13:56,622 - INFO: | epoch  15 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 345.18 | loss-text 3.2158\n",
      "2021-12-03 20:14:30,593 - INFO: | epoch  15 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 339.71 | loss-text 3.1660\n",
      "2021-12-03 20:15:04,884 - INFO: | epoch  15 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.90 | loss-text 3.1762\n",
      "2021-12-03 20:15:39,017 - INFO: | epoch  15 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 341.33 | loss-text 3.1965\n",
      "2021-12-03 20:16:13,180 - INFO: | epoch  15 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 341.63 | loss-text 3.2231\n",
      "2021-12-03 20:16:47,628 - INFO: | epoch  15 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 344.47 | loss-text 3.1761\n",
      "2021-12-03 20:17:21,818 - INFO: | epoch  15 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 341.89 | loss-text 3.2733\n",
      "2021-12-03 20:17:56,199 - INFO: | epoch  15 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.81 | loss-text 3.1770\n",
      "2021-12-03 20:18:30,424 - INFO: | epoch  15 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.25 | loss-text 3.1875\n",
      "2021-12-03 20:19:04,989 - INFO: | epoch  15 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 345.64 | loss-text 3.1871\n",
      "2021-12-03 20:19:39,467 - INFO: | epoch  15 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 344.77 | loss-text 3.2306\n",
      "2021-12-03 20:20:13,681 - INFO: | epoch  15 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.14 | loss-text 3.2362\n",
      "2021-12-03 20:20:48,093 - INFO: | epoch  15 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 344.12 | loss-text 3.2227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003955\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10232, 'reflen': 10297, 'guess': [10232, 9208, 8184, 7160], 'correct': [5534, 1934, 701, 193]}\n",
      "ratio: 0.9936874817907163\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.335\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.126\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.315\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.210\n",
      "2021-12-03 20:21:40,630 - INFO: eval_greddy SPIDEr: 0.2101\n",
      "loading annotations into memory...\n",
      "0:00:00.003950\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9469, 'reflen': 9814, 'guess': [9469, 8445, 7421, 6397], 'correct': [5442, 2056, 840, 271]}\n",
      "ratio: 0.964846138169863\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.361\n",
      "Bleu_3: 0.242\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-03 20:22:19,700 - INFO: eval_beam_2 SPIDEr: 0.2410\n",
      "loading annotations into memory...\n",
      "0:00:00.003990\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9157, 'reflen': 9658, 'guess': [9157, 8133, 7109, 6085], 'correct': [5279, 2044, 842, 279]}\n",
      "ratio: 0.9481259059845777\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-03 20:22:58,130 - INFO: eval_beam_3 SPIDEr: 0.2396\n",
      "loading annotations into memory...\n",
      "0:00:00.003594\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8961, 'reflen': 9565, 'guess': [8961, 7937, 6913, 5889], 'correct': [5192, 2019, 847, 293]}\n",
      "ratio: 0.9368531102978633\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.359\n",
      "Bleu_3: 0.245\n",
      "Bleu_4: 0.162\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-03 20:23:40,695 - INFO: eval_beam_4 SPIDEr: 0.2415\n",
      "2021-12-03 20:24:15,138 - INFO: | epoch  16 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 344.39 | loss-text 3.1611\n",
      "2021-12-03 20:24:49,204 - INFO: | epoch  16 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.65 | loss-text 3.1319\n",
      "2021-12-03 20:25:23,322 - INFO: | epoch  16 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.17 | loss-text 3.1087\n",
      "2021-12-03 20:25:57,448 - INFO: | epoch  16 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.26 | loss-text 3.1213\n",
      "2021-12-03 20:26:31,613 - INFO: | epoch  16 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 341.65 | loss-text 3.1860\n",
      "2021-12-03 20:27:05,789 - INFO: | epoch  16 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.75 | loss-text 3.1890\n",
      "2021-12-03 20:27:40,072 - INFO: | epoch  16 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.83 | loss-text 3.1934\n",
      "2021-12-03 20:28:14,309 - INFO: | epoch  16 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 342.36 | loss-text 3.1753\n",
      "2021-12-03 20:28:48,502 - INFO: | epoch  16 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.93 | loss-text 3.1874\n",
      "2021-12-03 20:29:22,822 - INFO: | epoch  16 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 343.19 | loss-text 3.2122\n",
      "2021-12-03 20:29:57,272 - INFO: | epoch  16 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 344.49 | loss-text 3.2170\n",
      "2021-12-03 20:30:31,736 - INFO: | epoch  16 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 344.63 | loss-text 3.1872\n",
      "2021-12-03 20:31:05,911 - INFO: | epoch  16 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 341.75 | loss-text 3.1489\n",
      "2021-12-03 20:31:40,430 - INFO: | epoch  16 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 345.18 | loss-text 3.1932\n",
      "2021-12-03 20:32:14,584 - INFO: | epoch  16 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 341.54 | loss-text 3.1704\n",
      "2021-12-03 20:32:48,848 - INFO: | epoch  16 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.63 | loss-text 3.1350\n",
      "2021-12-03 20:33:23,220 - INFO: | epoch  16 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.71 | loss-text 3.2082\n",
      "2021-12-03 20:33:57,634 - INFO: | epoch  16 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.14 | loss-text 3.1895\n",
      "2021-12-03 20:34:32,187 - INFO: | epoch  16 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 345.52 | loss-text 3.1690\n",
      "2021-12-03 20:35:06,537 - INFO: | epoch  16 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 343.50 | loss-text 3.1562\n",
      "2021-12-03 20:35:41,049 - INFO: | epoch  16 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 345.11 | loss-text 3.2044\n",
      "2021-12-03 20:36:15,165 - INFO: | epoch  16 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 341.15 | loss-text 3.1935\n",
      "2021-12-03 20:36:49,472 - INFO: | epoch  16 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 343.07 | loss-text 3.1801\n",
      "2021-12-03 20:37:23,866 - INFO: | epoch  16 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.93 | loss-text 3.1539\n",
      "2021-12-03 20:37:58,359 - INFO: | epoch  16 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 344.93 | loss-text 3.1731\n",
      "2021-12-03 20:38:32,394 - INFO: | epoch  16 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 340.34 | loss-text 3.1916\n",
      "2021-12-03 20:39:06,795 - INFO: | epoch  16 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 344.00 | loss-text 3.1921\n",
      "2021-12-03 20:39:41,041 - INFO: | epoch  16 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.46 | loss-text 3.1976\n",
      "2021-12-03 20:40:15,565 - INFO: | epoch  16 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 345.23 | loss-text 3.1536\n",
      "2021-12-03 20:40:49,952 - INFO: | epoch  16 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 343.87 | loss-text 3.1690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003919\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10431, 'reflen': 10445, 'guess': [10431, 9407, 8383, 7359], 'correct': [5569, 1959, 719, 225]}\n",
      "ratio: 0.9986596457634276\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.333\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.219\n",
      "2021-12-03 20:41:43,932 - INFO: eval_greddy SPIDEr: 0.2186\n",
      "loading annotations into memory...\n",
      "0:00:00.003914\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9572, 'reflen': 9883, 'guess': [9572, 8548, 7524, 6500], 'correct': [5406, 2013, 800, 259]}\n",
      "ratio: 0.9685318223210595\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-03 20:42:19,815 - INFO: eval_beam_2 SPIDEr: 0.2396\n",
      "loading annotations into memory...\n",
      "0:00:00.003745\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9192, 'reflen': 9672, 'guess': [9192, 8168, 7144, 6120], 'correct': [5346, 2056, 845, 291]}\n",
      "ratio: 0.9503722084366263\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.246\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.386\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.250\n",
      "2021-12-03 20:42:58,439 - INFO: eval_beam_3 SPIDEr: 0.2497\n",
      "loading annotations into memory...\n",
      "0:00:00.003907\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8914, 'reflen': 9529, 'guess': [8914, 7890, 6866, 5842], 'correct': [5192, 2013, 856, 315]}\n",
      "ratio: 0.9354601742049601\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.247\n",
      "Bleu_4: 0.166\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.385\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.248\n",
      "2021-12-03 20:43:40,487 - INFO: eval_beam_4 SPIDEr: 0.2484\n",
      "2021-12-03 20:44:14,668 - INFO: | epoch  17 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 341.78 | loss-text 3.1420\n",
      "2021-12-03 20:44:48,983 - INFO: | epoch  17 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 343.14 | loss-text 3.1331\n",
      "2021-12-03 20:45:23,334 - INFO: | epoch  17 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 343.50 | loss-text 3.1759\n",
      "2021-12-03 20:45:57,724 - INFO: | epoch  17 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 343.90 | loss-text 3.1832\n",
      "2021-12-03 20:46:32,024 - INFO: | epoch  17 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.99 | loss-text 3.1391\n",
      "2021-12-03 20:47:06,188 - INFO: | epoch  17 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.64 | loss-text 3.1364\n",
      "2021-12-03 20:47:40,721 - INFO: | epoch  17 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 345.32 | loss-text 3.1657\n",
      "2021-12-03 20:48:15,182 - INFO: | epoch  17 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 344.60 | loss-text 3.1667\n",
      "2021-12-03 20:48:49,358 - INFO: | epoch  17 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.75 | loss-text 3.1689\n",
      "2021-12-03 20:49:23,633 - INFO: | epoch  17 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.74 | loss-text 3.1774\n",
      "2021-12-03 20:49:57,761 - INFO: | epoch  17 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 341.27 | loss-text 3.1477\n",
      "2021-12-03 20:50:32,110 - INFO: | epoch  17 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 343.48 | loss-text 3.1627\n",
      "2021-12-03 20:51:06,520 - INFO: | epoch  17 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 344.10 | loss-text 3.1480\n",
      "2021-12-03 20:51:40,670 - INFO: | epoch  17 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.49 | loss-text 3.1350\n",
      "2021-12-03 20:52:15,159 - INFO: | epoch  17 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 344.88 | loss-text 3.1091\n",
      "2021-12-03 20:52:49,504 - INFO: | epoch  17 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.44 | loss-text 3.1820\n",
      "2021-12-03 20:53:23,885 - INFO: | epoch  17 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.81 | loss-text 3.1391\n",
      "2021-12-03 20:53:58,094 - INFO: | epoch  17 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 342.08 | loss-text 3.1302\n",
      "2021-12-03 20:54:32,280 - INFO: | epoch  17 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 341.86 | loss-text 3.1603\n",
      "2021-12-03 20:55:06,638 - INFO: | epoch  17 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 343.57 | loss-text 3.1536\n",
      "2021-12-03 20:55:41,278 - INFO: | epoch  17 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 346.39 | loss-text 3.1268\n",
      "2021-12-03 20:56:15,555 - INFO: | epoch  17 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 342.77 | loss-text 3.1471\n",
      "2021-12-03 20:56:49,825 - INFO: | epoch  17 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.69 | loss-text 3.1648\n",
      "2021-12-03 20:57:24,085 - INFO: | epoch  17 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 342.59 | loss-text 3.1486\n",
      "2021-12-03 20:57:58,557 - INFO: | epoch  17 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 344.71 | loss-text 3.1641\n",
      "2021-12-03 20:58:32,885 - INFO: | epoch  17 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 343.28 | loss-text 3.1463\n",
      "2021-12-03 20:59:07,200 - INFO: | epoch  17 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 343.14 | loss-text 3.1547\n",
      "2021-12-03 20:59:41,502 - INFO: | epoch  17 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.01 | loss-text 3.1626\n",
      "2021-12-03 21:00:15,804 - INFO: | epoch  17 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 343.01 | loss-text 3.1410\n",
      "2021-12-03 21:00:49,943 - INFO: | epoch  17 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 341.39 | loss-text 3.1957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003859\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10139, 'reflen': 10261, 'guess': [10139, 9115, 8091, 7067], 'correct': [5480, 1901, 664, 187]}\n",
      "ratio: 0.988110320631421\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.319\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.213\n",
      "2021-12-03 21:01:41,932 - INFO: eval_greddy SPIDEr: 0.2135\n",
      "loading annotations into memory...\n",
      "0:00:00.004057\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9373, 'reflen': 9749, 'guess': [9373, 8349, 7325, 6301], 'correct': [5440, 2023, 810, 263]}\n",
      "ratio: 0.9614319417375154\n",
      "Bleu_1: 0.558\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.372\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-03 21:02:17,727 - INFO: eval_beam_2 SPIDEr: 0.2414\n",
      "loading annotations into memory...\n",
      "0:00:00.003807\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9099, 'reflen': 9602, 'guess': [9099, 8075, 7051, 6027], 'correct': [5341, 2039, 841, 284]}\n",
      "ratio: 0.947615080191528\n",
      "Bleu_1: 0.555\n",
      "Bleu_2: 0.364\n",
      "Bleu_3: 0.246\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.374\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.382\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.247\n",
      "2021-12-03 21:02:55,624 - INFO: eval_beam_3 SPIDEr: 0.2473\n",
      "loading annotations into memory...\n",
      "0:00:00.003827\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8947, 'reflen': 9518, 'guess': [8947, 7923, 6899, 5875], 'correct': [5267, 2051, 846, 282]}\n",
      "ratio: 0.9400084051270288\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.366\n",
      "Bleu_3: 0.249\n",
      "Bleu_4: 0.162\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.374\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.379\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-03 21:03:37,523 - INFO: eval_beam_4 SPIDEr: 0.2458\n",
      "2021-12-03 21:04:11,734 - INFO: | epoch  18 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 342.08 | loss-text 3.0930\n",
      "2021-12-03 21:04:46,131 - INFO: | epoch  18 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 343.96 | loss-text 3.0983\n",
      "2021-12-03 21:05:20,289 - INFO: | epoch  18 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.57 | loss-text 3.1178\n",
      "2021-12-03 21:05:54,349 - INFO: | epoch  18 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 340.60 | loss-text 3.1158\n",
      "2021-12-03 21:06:28,359 - INFO: | epoch  18 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 340.09 | loss-text 3.1032\n",
      "2021-12-03 21:07:02,441 - INFO: | epoch  18 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 340.81 | loss-text 3.1562\n",
      "2021-12-03 21:07:36,568 - INFO: | epoch  18 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 341.27 | loss-text 3.1231\n",
      "2021-12-03 21:08:10,883 - INFO: | epoch  18 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.14 | loss-text 3.1065\n",
      "2021-12-03 21:08:45,084 - INFO: | epoch  18 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.01 | loss-text 3.1504\n",
      "2021-12-03 21:09:19,345 - INFO: | epoch  18 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.60 | loss-text 3.1435\n",
      "2021-12-03 21:09:53,697 - INFO: | epoch  18 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 343.51 | loss-text 3.1244\n",
      "2021-12-03 21:10:27,923 - INFO: | epoch  18 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.26 | loss-text 3.1329\n",
      "2021-12-03 21:11:02,198 - INFO: | epoch  18 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.74 | loss-text 3.0849\n",
      "2021-12-03 21:11:36,340 - INFO: | epoch  18 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.41 | loss-text 3.1425\n",
      "2021-12-03 21:12:10,558 - INFO: | epoch  18 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.18 | loss-text 3.1872\n",
      "2021-12-03 21:12:45,007 - INFO: | epoch  18 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 344.49 | loss-text 3.1138\n",
      "2021-12-03 21:13:19,286 - INFO: | epoch  18 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 342.78 | loss-text 3.1800\n",
      "2021-12-03 21:13:53,624 - INFO: | epoch  18 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 343.38 | loss-text 3.1337\n",
      "2021-12-03 21:14:28,017 - INFO: | epoch  18 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 343.92 | loss-text 3.1478\n",
      "2021-12-03 21:15:02,267 - INFO: | epoch  18 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.49 | loss-text 3.1373\n",
      "2021-12-03 21:15:36,485 - INFO: | epoch  18 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 342.18 | loss-text 3.1510\n",
      "2021-12-03 21:16:10,751 - INFO: | epoch  18 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 342.65 | loss-text 3.2001\n",
      "2021-12-03 21:16:45,079 - INFO: | epoch  18 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 343.27 | loss-text 3.0876\n",
      "2021-12-03 21:17:19,431 - INFO: | epoch  18 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.52 | loss-text 3.1194\n",
      "2021-12-03 21:17:53,611 - INFO: | epoch  18 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 341.79 | loss-text 3.1752\n",
      "2021-12-03 21:18:28,023 - INFO: | epoch  18 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 344.12 | loss-text 3.1249\n",
      "2021-12-03 21:19:02,216 - INFO: | epoch  18 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.92 | loss-text 3.0734\n",
      "2021-12-03 21:19:36,586 - INFO: | epoch  18 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.70 | loss-text 3.1780\n",
      "2021-12-03 21:20:10,768 - INFO: | epoch  18 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 341.81 | loss-text 3.0911\n",
      "2021-12-03 21:20:44,971 - INFO: | epoch  18 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.02 | loss-text 3.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004051\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10397, 'reflen': 10414, 'guess': [10397, 9373, 8349, 7325], 'correct': [5610, 1954, 727, 218]}\n",
      "ratio: 0.9983675821009219\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.335\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.336\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.222\n",
      "2021-12-03 21:21:37,851 - INFO: eval_greddy SPIDEr: 0.2224\n",
      "loading annotations into memory...\n",
      "0:00:00.003938\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9671, 'reflen': 9964, 'guess': [9671, 8647, 7623, 6599], 'correct': [5456, 1942, 750, 239]}\n",
      "ratio: 0.9705941388999427\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-03 21:22:15,361 - INFO: eval_beam_2 SPIDEr: 0.2364\n",
      "loading annotations into memory...\n",
      "0:00:00.004099\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9269, 'reflen': 9765, 'guess': [9269, 8245, 7221, 6197], 'correct': [5364, 1966, 801, 273]}\n",
      "ratio: 0.9492063492062519\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.379\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.245\n",
      "2021-12-03 21:22:54,461 - INFO: eval_beam_3 SPIDEr: 0.2449\n",
      "loading annotations into memory...\n",
      "0:00:00.004151\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9044, 'reflen': 9622, 'guess': [9044, 8020, 6996, 5972], 'correct': [5275, 1997, 846, 317]}\n",
      "ratio: 0.9399293286218104\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.164\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.385\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.247\n",
      "2021-12-03 21:23:37,719 - INFO: eval_beam_4 SPIDEr: 0.2468\n",
      "2021-12-03 21:24:11,724 - INFO: | epoch  19 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.02 | loss-text 3.0777\n",
      "2021-12-03 21:24:45,849 - INFO: | epoch  19 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 341.23 | loss-text 3.1383\n",
      "2021-12-03 21:25:20,071 - INFO: | epoch  19 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 342.22 | loss-text 3.0968\n",
      "2021-12-03 21:25:54,189 - INFO: | epoch  19 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.17 | loss-text 3.0810\n",
      "2021-12-03 21:26:28,406 - INFO: | epoch  19 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.16 | loss-text 3.1332\n",
      "2021-12-03 21:27:02,610 - INFO: | epoch  19 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.03 | loss-text 3.1224\n",
      "2021-12-03 21:27:36,664 - INFO: | epoch  19 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 340.54 | loss-text 3.0962\n",
      "2021-12-03 21:28:10,892 - INFO: | epoch  19 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 342.27 | loss-text 3.0858\n",
      "2021-12-03 21:28:45,220 - INFO: | epoch  19 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 343.27 | loss-text 3.0679\n",
      "2021-12-03 21:29:19,272 - INFO: | epoch  19 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 340.52 | loss-text 3.1230\n",
      "2021-12-03 21:29:53,537 - INFO: | epoch  19 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.64 | loss-text 3.1554\n",
      "2021-12-03 21:30:27,864 - INFO: | epoch  19 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 343.27 | loss-text 3.1337\n",
      "2021-12-03 21:31:02,067 - INFO: | epoch  19 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.02 | loss-text 3.0860\n",
      "2021-12-03 21:31:36,319 - INFO: | epoch  19 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.51 | loss-text 3.1429\n",
      "2021-12-03 21:32:10,459 - INFO: | epoch  19 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 341.39 | loss-text 3.1416\n",
      "2021-12-03 21:32:44,738 - INFO: | epoch  19 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.79 | loss-text 3.1184\n",
      "2021-12-03 21:33:18,857 - INFO: | epoch  19 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 341.18 | loss-text 3.0890\n",
      "2021-12-03 21:33:52,978 - INFO: | epoch  19 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 341.21 | loss-text 3.0569\n",
      "2021-12-03 21:34:27,345 - INFO: | epoch  19 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 343.66 | loss-text 3.0411\n",
      "2021-12-03 21:35:01,593 - INFO: | epoch  19 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.47 | loss-text 3.0964\n",
      "2021-12-03 21:35:36,043 - INFO: | epoch  19 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 344.50 | loss-text 3.0656\n",
      "2021-12-03 21:36:10,344 - INFO: | epoch  19 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 343.00 | loss-text 3.0992\n",
      "2021-12-03 21:36:44,552 - INFO: | epoch  19 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.07 | loss-text 3.1384\n",
      "2021-12-03 21:37:18,900 - INFO: | epoch  19 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.47 | loss-text 3.0926\n",
      "2021-12-03 21:37:53,100 - INFO: | epoch  19 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 341.99 | loss-text 3.1113\n",
      "2021-12-03 21:38:27,527 - INFO: | epoch  19 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 344.27 | loss-text 3.0908\n",
      "2021-12-03 21:39:01,821 - INFO: | epoch  19 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.93 | loss-text 3.1092\n",
      "2021-12-03 21:39:36,065 - INFO: | epoch  19 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.43 | loss-text 3.1055\n",
      "2021-12-03 21:40:10,485 - INFO: | epoch  19 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 344.19 | loss-text 3.1238\n",
      "2021-12-03 21:40:44,751 - INFO: | epoch  19 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.66 | loss-text 3.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004018\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10581, 'reflen': 10552, 'guess': [10581, 9557, 8533, 7509], 'correct': [5642, 1929, 683, 209]}\n",
      "ratio: 1.002748294162149\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.205\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.317\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.212\n",
      "2021-12-03 21:41:38,876 - INFO: eval_greddy SPIDEr: 0.2115\n",
      "loading annotations into memory...\n",
      "0:00:00.003931\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9784, 'reflen': 9986, 'guess': [9784, 8760, 7736, 6712], 'correct': [5539, 2021, 790, 263]}\n",
      "ratio: 0.9797716803523954\n",
      "Bleu_1: 0.555\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-03 21:42:15,131 - INFO: eval_beam_2 SPIDEr: 0.2353\n",
      "loading annotations into memory...\n",
      "0:00:00.003702\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9366, 'reflen': 9728, 'guess': [9366, 8342, 7318, 6294], 'correct': [5445, 2046, 846, 296]}\n",
      "ratio: 0.9627878289472694\n",
      "Bleu_1: 0.559\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.245\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-03 21:42:54,247 - INFO: eval_beam_3 SPIDEr: 0.2422\n",
      "loading annotations into memory...\n",
      "0:00:00.003894\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9144, 'reflen': 9614, 'guess': [9144, 8120, 7096, 6072], 'correct': [5337, 2017, 839, 292]}\n",
      "ratio: 0.9511129602661794\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.362\n",
      "Bleu_3: 0.245\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-03 21:43:37,170 - INFO: eval_beam_4 SPIDEr: 0.2421\n",
      "2021-12-03 21:44:11,228 - INFO: | epoch  20 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.55 | loss-text 3.0620\n",
      "2021-12-03 21:44:45,357 - INFO: | epoch  20 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 341.28 | loss-text 3.0946\n",
      "2021-12-03 21:45:19,484 - INFO: | epoch  20 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.26 | loss-text 3.0737\n",
      "2021-12-03 21:45:53,482 - INFO: | epoch  20 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 339.98 | loss-text 3.1179\n",
      "2021-12-03 21:46:27,698 - INFO: | epoch  20 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.15 | loss-text 3.1019\n",
      "2021-12-03 21:47:01,700 - INFO: | epoch  20 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 340.02 | loss-text 3.0978\n",
      "2021-12-03 21:47:35,800 - INFO: | epoch  20 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 340.99 | loss-text 3.0861\n",
      "2021-12-03 21:48:09,937 - INFO: | epoch  20 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 341.37 | loss-text 3.0809\n",
      "2021-12-03 21:48:43,984 - INFO: | epoch  20 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 340.47 | loss-text 3.0258\n",
      "2021-12-03 21:49:18,194 - INFO: | epoch  20 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.09 | loss-text 3.1110\n",
      "2021-12-03 21:49:52,507 - INFO: | epoch  20 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 343.13 | loss-text 3.1051\n",
      "2021-12-03 21:50:26,716 - INFO: | epoch  20 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.08 | loss-text 3.0618\n",
      "2021-12-03 21:51:01,079 - INFO: | epoch  20 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 343.62 | loss-text 3.0725\n",
      "2021-12-03 21:51:35,202 - INFO: | epoch  20 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.22 | loss-text 3.1083\n",
      "2021-12-03 21:52:09,048 - INFO: | epoch  20 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 338.45 | loss-text 3.0807\n",
      "2021-12-03 21:52:43,356 - INFO: | epoch  20 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.08 | loss-text 3.0844\n",
      "2021-12-03 21:53:17,283 - INFO: | epoch  20 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 339.25 | loss-text 3.0870\n",
      "2021-12-03 21:53:51,672 - INFO: | epoch  20 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 343.88 | loss-text 3.1101\n",
      "2021-12-03 21:54:25,980 - INFO: | epoch  20 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 343.07 | loss-text 3.0603\n",
      "2021-12-03 21:55:00,125 - INFO: | epoch  20 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 341.45 | loss-text 3.0634\n",
      "2021-12-03 21:55:34,286 - INFO: | epoch  20 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 341.60 | loss-text 3.0421\n",
      "2021-12-03 21:56:08,432 - INFO: | epoch  20 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 341.46 | loss-text 3.0955\n",
      "2021-12-03 21:56:42,510 - INFO: | epoch  20 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 340.77 | loss-text 3.0649\n",
      "2021-12-03 21:57:16,771 - INFO: | epoch  20 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 342.61 | loss-text 3.1025\n",
      "2021-12-03 21:57:50,943 - INFO: | epoch  20 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 341.71 | loss-text 3.0921\n",
      "2021-12-03 21:58:25,281 - INFO: | epoch  20 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 343.37 | loss-text 3.0679\n",
      "2021-12-03 21:58:59,513 - INFO: | epoch  20 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.32 | loss-text 3.0691\n",
      "2021-12-03 21:59:33,708 - INFO: | epoch  20 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 341.94 | loss-text 3.0826\n",
      "2021-12-03 22:00:07,929 - INFO: | epoch  20 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.20 | loss-text 3.1206\n",
      "2021-12-03 22:00:41,882 - INFO: | epoch  20 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 339.53 | loss-text 3.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003830\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10163, 'reflen': 10290, 'guess': [10163, 9140, 8117, 7094], 'correct': [5460, 1918, 685, 201]}\n",
      "ratio: 0.9876579203108855\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.313\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.210\n",
      "2021-12-03 22:01:35,756 - INFO: eval_greddy SPIDEr: 0.2096\n",
      "loading annotations into memory...\n",
      "0:00:00.003912\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9417, 'reflen': 9806, 'guess': [9417, 8393, 7369, 6345], 'correct': [5308, 1992, 817, 280]}\n",
      "ratio: 0.960330409952992\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.358\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-03 22:02:11,402 - INFO: eval_beam_2 SPIDEr: 0.2331\n",
      "loading annotations into memory...\n",
      "0:00:00.004021\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9119, 'reflen': 9635, 'guess': [9119, 8095, 7071, 6047], 'correct': [5117, 1943, 814, 290]}\n",
      "ratio: 0.9464452516864611\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-03 22:02:50,718 - INFO: eval_beam_3 SPIDEr: 0.2335\n",
      "loading annotations into memory...\n",
      "0:00:00.004068\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8926, 'reflen': 9539, 'guess': [8926, 7902, 6878, 5854], 'correct': [5066, 1956, 826, 298]}\n",
      "ratio: 0.935737498689492\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-03 22:03:33,204 - INFO: eval_beam_4 SPIDEr: 0.2378\n",
      "2021-12-03 22:04:07,411 - INFO: | epoch  21 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 342.03 | loss-text 3.0064\n",
      "2021-12-03 22:04:41,260 - INFO: | epoch  21 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 338.48 | loss-text 3.0991\n",
      "2021-12-03 22:05:15,299 - INFO: | epoch  21 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 340.38 | loss-text 3.1075\n",
      "2021-12-03 22:05:49,477 - INFO: | epoch  21 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.78 | loss-text 3.0157\n",
      "2021-12-03 22:06:23,690 - INFO: | epoch  21 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.12 | loss-text 3.0534\n",
      "2021-12-03 22:06:57,817 - INFO: | epoch  21 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.27 | loss-text 3.0939\n",
      "2021-12-03 22:07:31,542 - INFO: | epoch  21 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 337.23 | loss-text 3.0349\n",
      "2021-12-03 22:08:06,001 - INFO: | epoch  21 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 344.59 | loss-text 3.0779\n",
      "2021-12-03 22:08:40,433 - INFO: | epoch  21 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 344.31 | loss-text 3.0377\n",
      "2021-12-03 22:09:14,481 - INFO: | epoch  21 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 340.47 | loss-text 3.0767\n",
      "2021-12-03 22:09:48,367 - INFO: | epoch  21 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 338.85 | loss-text 3.0466\n",
      "2021-12-03 22:10:22,356 - INFO: | epoch  21 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 339.88 | loss-text 3.1362\n",
      "2021-12-03 22:10:56,620 - INFO: | epoch  21 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.64 | loss-text 3.1093\n",
      "2021-12-03 22:11:30,773 - INFO: | epoch  21 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.52 | loss-text 3.0547\n",
      "2021-12-03 22:12:05,014 - INFO: | epoch  21 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.41 | loss-text 3.0712\n",
      "2021-12-03 22:12:39,426 - INFO: | epoch  21 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 344.11 | loss-text 3.0583\n",
      "2021-12-03 22:13:13,568 - INFO: | epoch  21 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 341.41 | loss-text 3.0356\n",
      "2021-12-03 22:13:47,968 - INFO: | epoch  21 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 343.99 | loss-text 3.0626\n",
      "2021-12-03 22:14:21,821 - INFO: | epoch  21 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 338.52 | loss-text 3.0410\n",
      "2021-12-03 22:14:56,058 - INFO: | epoch  21 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.36 | loss-text 3.0684\n",
      "2021-12-03 22:15:30,404 - INFO: | epoch  21 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 343.46 | loss-text 3.0707\n",
      "2021-12-03 22:16:04,488 - INFO: | epoch  21 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 340.83 | loss-text 3.0697\n",
      "2021-12-03 22:16:38,776 - INFO: | epoch  21 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.87 | loss-text 3.0850\n",
      "2021-12-03 22:17:13,133 - INFO: | epoch  21 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.57 | loss-text 3.1280\n",
      "2021-12-03 22:17:47,051 - INFO: | epoch  21 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 339.17 | loss-text 3.0946\n",
      "2021-12-03 22:18:21,347 - INFO: | epoch  21 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.95 | loss-text 3.0710\n",
      "2021-12-03 22:18:55,476 - INFO: | epoch  21 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.29 | loss-text 3.0080\n",
      "2021-12-03 22:19:29,758 - INFO: | epoch  21 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.81 | loss-text 3.0490\n",
      "2021-12-03 22:20:03,997 - INFO: | epoch  21 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.38 | loss-text 3.1018\n",
      "2021-12-03 22:20:38,080 - INFO: | epoch  21 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 340.82 | loss-text 3.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003751\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9948, 'reflen': 10118, 'guess': [9948, 8924, 7900, 6876], 'correct': [5501, 1905, 695, 218]}\n",
      "ratio: 0.9831982605256984\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.338\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.330\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.220\n",
      "2021-12-03 22:21:31,178 - INFO: eval_greddy SPIDEr: 0.2203\n",
      "loading annotations into memory...\n",
      "0:00:00.003969\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9329, 'reflen': 9703, 'guess': [9329, 8305, 7281, 6257], 'correct': [5422, 2003, 805, 262]}\n",
      "ratio: 0.9614552200349415\n",
      "Bleu_1: 0.558\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.375\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-03 22:22:07,082 - INFO: eval_beam_2 SPIDEr: 0.2438\n",
      "loading annotations into memory...\n",
      "0:00:00.003952\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9077, 'reflen': 9594, 'guess': [9077, 8053, 7029, 6005], 'correct': [5308, 2008, 828, 284]}\n",
      "ratio: 0.9461121534291279\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.361\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.379\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-03 22:22:46,698 - INFO: eval_beam_3 SPIDEr: 0.2459\n",
      "loading annotations into memory...\n",
      "0:00:00.003695\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8873, 'reflen': 9514, 'guess': [8873, 7849, 6825, 5801], 'correct': [5222, 1969, 821, 275]}\n",
      "ratio: 0.9326256043724056\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.357\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-03 22:23:29,667 - INFO: eval_beam_4 SPIDEr: 0.2428\n",
      "2021-12-03 22:24:03,701 - INFO: | epoch  22 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.31 | loss-text 2.9733\n",
      "2021-12-03 22:24:37,619 - INFO: | epoch  22 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.17 | loss-text 3.0582\n",
      "2021-12-03 22:25:11,560 - INFO: | epoch  22 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 339.40 | loss-text 3.0051\n",
      "2021-12-03 22:25:45,629 - INFO: | epoch  22 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 340.68 | loss-text 3.0351\n",
      "2021-12-03 22:26:19,817 - INFO: | epoch  22 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 341.87 | loss-text 3.0462\n",
      "2021-12-03 22:26:54,064 - INFO: | epoch  22 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.46 | loss-text 3.0400\n",
      "2021-12-03 22:27:27,969 - INFO: | epoch  22 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 339.05 | loss-text 3.0288\n",
      "2021-12-03 22:28:01,984 - INFO: | epoch  22 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 340.14 | loss-text 3.0572\n",
      "2021-12-03 22:28:36,209 - INFO: | epoch  22 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.24 | loss-text 3.0149\n",
      "2021-12-03 22:29:10,285 - INFO: | epoch  22 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 340.75 | loss-text 3.0534\n",
      "2021-12-03 22:29:44,559 - INFO: | epoch  22 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.73 | loss-text 3.0896\n",
      "2021-12-03 22:30:18,668 - INFO: | epoch  22 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.08 | loss-text 3.0701\n",
      "2021-12-03 22:30:53,165 - INFO: | epoch  22 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 344.97 | loss-text 3.0406\n",
      "2021-12-03 22:31:27,336 - INFO: | epoch  22 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.70 | loss-text 3.0905\n",
      "2021-12-03 22:32:01,151 - INFO: | epoch  22 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 338.14 | loss-text 3.0880\n",
      "2021-12-03 22:32:35,316 - INFO: | epoch  22 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 341.65 | loss-text 3.0796\n",
      "2021-12-03 22:33:09,340 - INFO: | epoch  22 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 340.24 | loss-text 3.0359\n",
      "2021-12-03 22:33:43,295 - INFO: | epoch  22 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 339.54 | loss-text 3.0758\n",
      "2021-12-03 22:34:17,456 - INFO: | epoch  22 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 341.61 | loss-text 3.0672\n",
      "2021-12-03 22:34:51,468 - INFO: | epoch  22 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 340.12 | loss-text 3.0720\n",
      "2021-12-03 22:35:25,561 - INFO: | epoch  22 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 340.92 | loss-text 3.0391\n",
      "2021-12-03 22:35:59,783 - INFO: | epoch  22 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 342.22 | loss-text 3.0401\n",
      "2021-12-03 22:36:33,999 - INFO: | epoch  22 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.15 | loss-text 3.0334\n",
      "2021-12-03 22:37:08,282 - INFO: | epoch  22 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 342.82 | loss-text 3.0393\n",
      "2021-12-03 22:37:42,447 - INFO: | epoch  22 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 341.64 | loss-text 3.0591\n",
      "2021-12-03 22:38:16,524 - INFO: | epoch  22 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 340.76 | loss-text 3.0350\n",
      "2021-12-03 22:38:50,774 - INFO: | epoch  22 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.50 | loss-text 2.9855\n",
      "2021-12-03 22:39:25,080 - INFO: | epoch  22 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.05 | loss-text 3.0682\n",
      "2021-12-03 22:39:59,414 - INFO: | epoch  22 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 343.33 | loss-text 3.0879\n",
      "2021-12-03 22:40:33,919 - INFO: | epoch  22 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 345.05 | loss-text 3.0471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003888\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10496, 'reflen': 10509, 'guess': [10496, 9472, 8448, 7424], 'correct': [5749, 2023, 750, 229]}\n",
      "ratio: 0.9987629650774575\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.342\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.342\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2021-12-03 22:41:27,848 - INFO: eval_greddy SPIDEr: 0.2273\n",
      "loading annotations into memory...\n",
      "0:00:00.003827\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9678, 'reflen': 9912, 'guess': [9678, 8654, 7630, 6606], 'correct': [5445, 1991, 791, 244]}\n",
      "ratio: 0.9763922518158821\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-03 22:42:04,089 - INFO: eval_beam_2 SPIDEr: 0.2400\n",
      "loading annotations into memory...\n",
      "0:00:00.003890\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9287, 'reflen': 9726, 'guess': [9287, 8263, 7239, 6215], 'correct': [5367, 2052, 857, 294]}\n",
      "ratio: 0.9548632531358261\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.361\n",
      "Bleu_3: 0.245\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.389\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.253\n",
      "2021-12-03 22:42:43,841 - INFO: eval_beam_3 SPIDEr: 0.2525\n",
      "loading annotations into memory...\n",
      "0:00:00.003931\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9118, 'reflen': 9647, 'guess': [9118, 8094, 7072, 6050], 'correct': [5290, 2035, 861, 304]}\n",
      "ratio: 0.9451642997822177\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.246\n",
      "Bleu_4: 0.163\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.386\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.250\n",
      "2021-12-03 22:43:27,879 - INFO: eval_beam_4 SPIDEr: 0.2501\n",
      "2021-12-03 22:44:01,689 - INFO: | epoch  23 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 338.06 | loss-text 2.9838\n",
      "2021-12-03 22:44:35,645 - INFO: | epoch  23 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.55 | loss-text 3.0020\n",
      "2021-12-03 22:45:09,723 - INFO: | epoch  23 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 340.77 | loss-text 2.9972\n",
      "2021-12-03 22:45:43,651 - INFO: | epoch  23 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 339.27 | loss-text 3.0379\n",
      "2021-12-03 22:46:17,889 - INFO: | epoch  23 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.38 | loss-text 3.0302\n",
      "2021-12-03 22:46:52,059 - INFO: | epoch  23 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.69 | loss-text 3.0412\n",
      "2021-12-03 22:47:26,167 - INFO: | epoch  23 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 341.07 | loss-text 2.9897\n",
      "2021-12-03 22:47:59,968 - INFO: | epoch  23 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 338.01 | loss-text 3.0530\n",
      "2021-12-03 22:48:34,386 - INFO: | epoch  23 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 344.18 | loss-text 3.0156\n",
      "2021-12-03 22:49:08,466 - INFO: | epoch  23 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 340.79 | loss-text 3.0135\n",
      "2021-12-03 22:49:42,994 - INFO: | epoch  23 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 345.27 | loss-text 3.0556\n",
      "2021-12-03 22:50:17,367 - INFO: | epoch  23 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 343.73 | loss-text 3.0012\n",
      "2021-12-03 22:50:51,681 - INFO: | epoch  23 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 343.13 | loss-text 3.0578\n",
      "2021-12-03 22:51:25,758 - INFO: | epoch  23 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 340.76 | loss-text 3.0252\n",
      "2021-12-03 22:52:00,208 - INFO: | epoch  23 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 344.49 | loss-text 3.0539\n",
      "2021-12-03 22:52:34,329 - INFO: | epoch  23 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 341.21 | loss-text 3.0336\n",
      "2021-12-03 22:53:08,465 - INFO: | epoch  23 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 341.35 | loss-text 3.0238\n",
      "2021-12-03 22:53:43,006 - INFO: | epoch  23 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 345.40 | loss-text 3.0654\n",
      "2021-12-03 22:54:17,231 - INFO: | epoch  23 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.25 | loss-text 3.0666\n",
      "2021-12-03 22:54:51,529 - INFO: | epoch  23 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.97 | loss-text 3.0328\n",
      "2021-12-03 22:55:25,479 - INFO: | epoch  23 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 339.49 | loss-text 3.0278\n",
      "2021-12-03 22:55:59,757 - INFO: | epoch  23 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 342.77 | loss-text 3.0260\n",
      "2021-12-03 22:56:34,028 - INFO: | epoch  23 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.71 | loss-text 3.0185\n",
      "2021-12-03 22:57:08,058 - INFO: | epoch  23 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 340.29 | loss-text 3.0433\n",
      "2021-12-03 22:57:42,285 - INFO: | epoch  23 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 342.26 | loss-text 3.0090\n",
      "2021-12-03 22:58:16,494 - INFO: | epoch  23 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.08 | loss-text 3.0250\n",
      "2021-12-03 22:58:50,608 - INFO: | epoch  23 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.13 | loss-text 3.0637\n",
      "2021-12-03 22:59:24,702 - INFO: | epoch  23 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 340.94 | loss-text 3.0340\n",
      "2021-12-03 22:59:58,922 - INFO: | epoch  23 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.19 | loss-text 3.0202\n",
      "2021-12-03 23:00:33,153 - INFO: | epoch  23 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.30 | loss-text 3.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003840\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9981, 'reflen': 10136, 'guess': [9981, 8957, 7933, 6909], 'correct': [5419, 1836, 645, 202]}\n",
      "ratio: 0.9847079715863274\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.205\n",
      "Bleu_4: 0.126\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2021-12-03 23:01:26,867 - INFO: eval_greddy SPIDEr: 0.2148\n",
      "loading annotations into memory...\n",
      "0:00:00.004195\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9212, 'reflen': 9666, 'guess': [9212, 8188, 7164, 6140], 'correct': [5283, 1933, 768, 260]}\n",
      "ratio: 0.9530312435339382\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-03 23:02:02,379 - INFO: eval_beam_2 SPIDEr: 0.2400\n",
      "loading annotations into memory...\n",
      "0:00:00.003907\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8963, 'reflen': 9534, 'guess': [8963, 7939, 6915, 5891], 'correct': [5192, 1941, 794, 279]}\n",
      "ratio: 0.9401090832807908\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.379\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-03 23:02:40,855 - INFO: eval_beam_3 SPIDEr: 0.2438\n",
      "loading annotations into memory...\n",
      "0:00:00.003994\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8810, 'reflen': 9472, 'guess': [8810, 7786, 6762, 5738], 'correct': [5071, 1905, 817, 307]}\n",
      "ratio: 0.930109797297199\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.377\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-03 23:03:23,186 - INFO: eval_beam_4 SPIDEr: 0.2418\n",
      "2021-12-03 23:03:57,194 - INFO: | epoch  24 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.04 | loss-text 2.9925\n",
      "2021-12-03 23:04:31,251 - INFO: | epoch  24 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.56 | loss-text 3.0055\n",
      "2021-12-03 23:05:05,479 - INFO: | epoch  24 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 342.27 | loss-text 2.9859\n",
      "2021-12-03 23:05:39,323 - INFO: | epoch  24 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 338.43 | loss-text 2.9616\n",
      "2021-12-03 23:06:13,755 - INFO: | epoch  24 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 344.32 | loss-text 3.0540\n",
      "2021-12-03 23:06:47,738 - INFO: | epoch  24 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 339.82 | loss-text 2.9983\n",
      "2021-12-03 23:07:21,931 - INFO: | epoch  24 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 341.93 | loss-text 2.9549\n",
      "2021-12-03 23:07:56,108 - INFO: | epoch  24 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 341.76 | loss-text 3.0922\n",
      "2021-12-03 23:08:30,155 - INFO: | epoch  24 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 340.46 | loss-text 3.0403\n",
      "2021-12-03 23:09:04,313 - INFO: | epoch  24 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 341.57 | loss-text 3.0118\n",
      "2021-12-03 23:09:38,560 - INFO: | epoch  24 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.46 | loss-text 3.0091\n",
      "2021-12-03 23:10:12,519 - INFO: | epoch  24 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 339.58 | loss-text 3.0222\n",
      "2021-12-03 23:10:46,775 - INFO: | epoch  24 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.56 | loss-text 3.0166\n",
      "2021-12-03 23:11:21,098 - INFO: | epoch  24 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 343.22 | loss-text 3.0102\n",
      "2021-12-03 23:11:55,384 - INFO: | epoch  24 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.86 | loss-text 3.0250\n",
      "2021-12-03 23:12:29,551 - INFO: | epoch  24 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 341.66 | loss-text 2.9656\n",
      "2021-12-03 23:13:03,884 - INFO: | epoch  24 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.33 | loss-text 3.0179\n",
      "2021-12-03 23:13:38,026 - INFO: | epoch  24 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 341.41 | loss-text 2.9717\n",
      "2021-12-03 23:14:12,278 - INFO: | epoch  24 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.51 | loss-text 3.0288\n",
      "2021-12-03 23:14:46,191 - INFO: | epoch  24 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 339.13 | loss-text 3.0282\n",
      "2021-12-03 23:15:20,334 - INFO: | epoch  24 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 341.42 | loss-text 3.0238\n",
      "2021-12-03 23:15:54,388 - INFO: | epoch  24 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 340.54 | loss-text 3.0660\n",
      "2021-12-03 23:16:28,489 - INFO: | epoch  24 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 341.00 | loss-text 3.0378\n",
      "2021-12-03 23:17:02,717 - INFO: | epoch  24 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 342.28 | loss-text 3.0077\n",
      "2021-12-03 23:17:36,946 - INFO: | epoch  24 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 342.28 | loss-text 3.0062\n",
      "2021-12-03 23:18:11,103 - INFO: | epoch  24 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 341.57 | loss-text 3.0513\n",
      "2021-12-03 23:18:45,250 - INFO: | epoch  24 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.46 | loss-text 3.0193\n",
      "2021-12-03 23:19:19,147 - INFO: | epoch  24 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 338.96 | loss-text 3.0027\n",
      "2021-12-03 23:19:53,324 - INFO: | epoch  24 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 341.76 | loss-text 3.0057\n",
      "2021-12-03 23:20:27,482 - INFO: | epoch  24 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 341.57 | loss-text 3.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003933\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10469, 'reflen': 10407, 'guess': [10469, 9445, 8421, 7397], 'correct': [5619, 1931, 704, 216]}\n",
      "ratio: 1.0059575285864315\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.332\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.220\n",
      "2021-12-03 23:21:21,639 - INFO: eval_greddy SPIDEr: 0.2195\n",
      "loading annotations into memory...\n",
      "0:00:00.003924\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9666, 'reflen': 9927, 'guess': [9666, 8642, 7618, 6594], 'correct': [5471, 1995, 785, 254]}\n",
      "ratio: 0.9737080689028937\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-03 23:21:58,428 - INFO: eval_beam_2 SPIDEr: 0.2393\n",
      "loading annotations into memory...\n",
      "0:00:00.003886\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9244, 'reflen': 9690, 'guess': [9244, 8220, 7197, 6174], 'correct': [5375, 2048, 832, 285]}\n",
      "ratio: 0.9539731682145558\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.378\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-03 23:22:37,094 - INFO: eval_beam_3 SPIDEr: 0.2463\n",
      "loading annotations into memory...\n",
      "0:00:00.004064\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9048, 'reflen': 9579, 'guess': [9048, 8024, 7002, 5980], 'correct': [5282, 2008, 819, 289]}\n",
      "ratio: 0.9445662386469418\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-03 23:23:20,995 - INFO: eval_beam_4 SPIDEr: 0.2412\n",
      "2021-12-03 23:23:55,117 - INFO: | epoch  25 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 341.19 | loss-text 2.9974\n",
      "2021-12-03 23:24:29,293 - INFO: | epoch  25 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 341.75 | loss-text 2.9836\n",
      "2021-12-03 23:25:03,463 - INFO: | epoch  25 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.70 | loss-text 2.9705\n",
      "2021-12-03 23:25:37,231 - INFO: | epoch  25 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 337.67 | loss-text 2.9853\n",
      "2021-12-03 23:26:11,553 - INFO: | epoch  25 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 343.21 | loss-text 2.9717\n",
      "2021-12-03 23:26:45,768 - INFO: | epoch  25 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.14 | loss-text 2.9859\n",
      "2021-12-03 23:27:19,778 - INFO: | epoch  25 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 340.10 | loss-text 2.9557\n",
      "2021-12-03 23:27:54,053 - INFO: | epoch  25 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 342.75 | loss-text 2.9941\n",
      "2021-12-03 23:28:28,216 - INFO: | epoch  25 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.61 | loss-text 3.0048\n",
      "2021-12-03 23:29:02,085 - INFO: | epoch  25 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 338.69 | loss-text 3.0051\n",
      "2021-12-03 23:29:35,993 - INFO: | epoch  25 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 339.07 | loss-text 2.9482\n",
      "2021-12-03 23:30:10,290 - INFO: | epoch  25 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.96 | loss-text 3.0158\n",
      "2021-12-03 23:30:44,491 - INFO: | epoch  25 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.00 | loss-text 3.0004\n",
      "2021-12-03 23:31:18,658 - INFO: | epoch  25 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.67 | loss-text 3.0380\n",
      "2021-12-03 23:31:52,637 - INFO: | epoch  25 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 339.78 | loss-text 2.9314\n",
      "2021-12-03 23:32:27,019 - INFO: | epoch  25 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.82 | loss-text 3.0268\n",
      "2021-12-03 23:33:01,201 - INFO: | epoch  25 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 341.82 | loss-text 2.9869\n",
      "2021-12-03 23:33:35,388 - INFO: | epoch  25 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 341.86 | loss-text 3.0001\n",
      "2021-12-03 23:34:09,522 - INFO: | epoch  25 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 341.34 | loss-text 3.0039\n",
      "2021-12-03 23:34:43,745 - INFO: | epoch  25 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.22 | loss-text 3.0143\n",
      "2021-12-03 23:35:17,829 - INFO: | epoch  25 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 340.84 | loss-text 2.9909\n",
      "2021-12-03 23:35:51,982 - INFO: | epoch  25 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 341.52 | loss-text 2.9791\n",
      "2021-12-03 23:36:26,111 - INFO: | epoch  25 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 341.29 | loss-text 3.0038\n",
      "2021-12-03 23:37:00,129 - INFO: | epoch  25 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 340.17 | loss-text 3.0508\n",
      "2021-12-03 23:37:34,429 - INFO: | epoch  25 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 342.99 | loss-text 3.0004\n",
      "2021-12-03 23:38:08,380 - INFO: | epoch  25 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 339.51 | loss-text 2.9521\n",
      "2021-12-03 23:38:42,497 - INFO: | epoch  25 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.16 | loss-text 2.9917\n",
      "2021-12-03 23:39:16,829 - INFO: | epoch  25 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.32 | loss-text 2.9617\n",
      "2021-12-03 23:39:50,887 - INFO: | epoch  25 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 340.57 | loss-text 3.0290\n",
      "2021-12-03 23:40:25,187 - INFO: | epoch  25 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 343.00 | loss-text 3.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003850\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10257, 'reflen': 10294, 'guess': [10257, 9233, 8209, 7185], 'correct': [5447, 1837, 659, 209]}\n",
      "ratio: 0.996405673207597\n",
      "Bleu_1: 0.529\n",
      "Bleu_2: 0.324\n",
      "Bleu_3: 0.203\n",
      "Bleu_4: 0.125\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.320\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2021-12-03 23:41:18,919 - INFO: eval_greddy SPIDEr: 0.2135\n",
      "loading annotations into memory...\n",
      "0:00:00.003877\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9534, 'reflen': 9836, 'guess': [9534, 8510, 7486, 6462], 'correct': [5342, 1934, 746, 253]}\n",
      "ratio: 0.9692964619763146\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-03 23:41:55,326 - INFO: eval_beam_2 SPIDEr: 0.2362\n",
      "loading annotations into memory...\n",
      "0:00:00.003850\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9219, 'reflen': 9693, 'guess': [9219, 8195, 7171, 6147], 'correct': [5254, 1965, 784, 287]}\n",
      "ratio: 0.9510987310429225\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.377\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-03 23:42:34,742 - INFO: eval_beam_3 SPIDEr: 0.2425\n",
      "loading annotations into memory...\n",
      "0:00:00.003853\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9063, 'reflen': 9607, 'guess': [9063, 8039, 7017, 5995], 'correct': [5191, 1972, 798, 298]}\n",
      "ratio: 0.9433746226708708\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.380\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-03 23:43:17,233 - INFO: eval_beam_4 SPIDEr: 0.2438\n",
      "2021-12-03 23:43:51,461 - INFO: | epoch  26 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 342.24 | loss-text 2.9798\n",
      "2021-12-03 23:44:25,379 - INFO: | epoch  26 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.18 | loss-text 2.9487\n",
      "2021-12-03 23:44:59,523 - INFO: | epoch  26 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.43 | loss-text 2.9518\n",
      "2021-12-03 23:45:33,548 - INFO: | epoch  26 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 340.25 | loss-text 3.0324\n",
      "2021-12-03 23:46:07,673 - INFO: | epoch  26 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 341.24 | loss-text 2.9586\n",
      "2021-12-03 23:46:41,832 - INFO: | epoch  26 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.58 | loss-text 2.9560\n",
      "2021-12-03 23:47:15,795 - INFO: | epoch  26 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 339.63 | loss-text 2.9819\n",
      "2021-12-03 23:47:49,999 - INFO: | epoch  26 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 342.03 | loss-text 2.9805\n",
      "2021-12-03 23:48:23,949 - INFO: | epoch  26 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 339.50 | loss-text 2.9615\n",
      "2021-12-03 23:48:58,006 - INFO: | epoch  26 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 340.56 | loss-text 2.9793\n",
      "2021-12-03 23:49:32,071 - INFO: | epoch  26 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 340.64 | loss-text 3.0117\n",
      "2021-12-03 23:50:06,404 - INFO: | epoch  26 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 343.33 | loss-text 2.9712\n",
      "2021-12-03 23:50:40,817 - INFO: | epoch  26 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 344.13 | loss-text 2.9659\n",
      "2021-12-03 23:51:15,007 - INFO: | epoch  26 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.89 | loss-text 2.9403\n",
      "2021-12-03 23:51:49,021 - INFO: | epoch  26 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 340.13 | loss-text 2.9782\n",
      "2021-12-03 23:52:23,242 - INFO: | epoch  26 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.21 | loss-text 2.9912\n",
      "2021-12-03 23:52:57,287 - INFO: | epoch  26 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 340.44 | loss-text 2.9871\n",
      "2021-12-03 23:53:31,396 - INFO: | epoch  26 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 341.08 | loss-text 3.0120\n",
      "2021-12-03 23:54:05,702 - INFO: | epoch  26 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 343.05 | loss-text 3.0104\n",
      "2021-12-03 23:54:39,786 - INFO: | epoch  26 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 340.83 | loss-text 2.9729\n",
      "2021-12-03 23:55:13,821 - INFO: | epoch  26 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 340.34 | loss-text 2.9708\n",
      "2021-12-03 23:55:47,813 - INFO: | epoch  26 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 339.92 | loss-text 2.9949\n",
      "2021-12-03 23:56:22,296 - INFO: | epoch  26 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 344.82 | loss-text 2.9937\n",
      "2021-12-03 23:56:56,358 - INFO: | epoch  26 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 340.61 | loss-text 3.0121\n",
      "2021-12-03 23:57:30,490 - INFO: | epoch  26 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 341.32 | loss-text 2.9786\n",
      "2021-12-03 23:58:04,608 - INFO: | epoch  26 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 341.17 | loss-text 3.0070\n",
      "2021-12-03 23:58:38,835 - INFO: | epoch  26 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.26 | loss-text 2.9438\n",
      "2021-12-03 23:59:12,991 - INFO: | epoch  26 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 341.56 | loss-text 2.9850\n",
      "2021-12-03 23:59:47,198 - INFO: | epoch  26 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.06 | loss-text 2.9848\n",
      "2021-12-04 00:00:21,337 - INFO: | epoch  26 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 341.39 | loss-text 2.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003814\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10267, 'reflen': 10335, 'guess': [10267, 9243, 8219, 7195], 'correct': [5641, 1939, 711, 238]}\n",
      "ratio: 0.9934204160618293\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.343\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.226\n",
      "2021-12-04 00:01:16,005 - INFO: eval_greddy SPIDEr: 0.2263\n",
      "loading annotations into memory...\n",
      "0:00:00.008650\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9642, 'reflen': 9953, 'guess': [9642, 8618, 7594, 6570], 'correct': [5520, 2037, 805, 283]}\n",
      "ratio: 0.9687531397567598\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.377\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.245\n",
      "2021-12-04 00:01:52,484 - INFO: eval_beam_2 SPIDEr: 0.2449\n",
      "loading annotations into memory...\n",
      "0:00:00.003817\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9254, 'reflen': 9703, 'guess': [9254, 8230, 7206, 6182], 'correct': [5372, 2052, 845, 315]}\n",
      "ratio: 0.9537256518601511\n",
      "Bleu_1: 0.553\n",
      "Bleu_2: 0.362\n",
      "Bleu_3: 0.245\n",
      "Bleu_4: 0.163\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.385\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.248\n",
      "2021-12-04 00:02:31,014 - INFO: eval_beam_3 SPIDEr: 0.2480\n",
      "loading annotations into memory...\n",
      "0:00:00.003941\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9112, 'reflen': 9593, 'guess': [9112, 8088, 7065, 6042], 'correct': [5333, 2051, 847, 316]}\n",
      "ratio: 0.9498592723860159\n",
      "Bleu_1: 0.555\n",
      "Bleu_2: 0.365\n",
      "Bleu_3: 0.248\n",
      "Bleu_4: 0.166\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.388\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.248\n",
      "2021-12-04 00:03:14,492 - INFO: eval_beam_4 SPIDEr: 0.2484\n",
      "2021-12-04 00:03:48,571 - INFO: | epoch  27 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.76 | loss-text 2.9175\n",
      "2021-12-04 00:04:22,478 - INFO: | epoch  27 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.06 | loss-text 2.9749\n",
      "2021-12-04 00:04:56,838 - INFO: | epoch  27 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 343.59 | loss-text 2.9163\n",
      "2021-12-04 00:05:30,886 - INFO: | epoch  27 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 340.47 | loss-text 2.9391\n",
      "2021-12-04 00:06:05,007 - INFO: | epoch  27 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 341.21 | loss-text 2.9684\n",
      "2021-12-04 00:06:39,018 - INFO: | epoch  27 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 340.10 | loss-text 2.9628\n",
      "2021-12-04 00:07:13,147 - INFO: | epoch  27 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 341.28 | loss-text 2.9859\n",
      "2021-12-04 00:07:47,456 - INFO: | epoch  27 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.09 | loss-text 2.9641\n",
      "2021-12-04 00:08:21,402 - INFO: | epoch  27 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 339.45 | loss-text 2.9958\n",
      "2021-12-04 00:08:55,527 - INFO: | epoch  27 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 341.24 | loss-text 2.9898\n",
      "2021-12-04 00:09:29,521 - INFO: | epoch  27 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 339.94 | loss-text 2.9431\n",
      "2021-12-04 00:10:03,823 - INFO: | epoch  27 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 343.01 | loss-text 2.9465\n",
      "2021-12-04 00:10:37,878 - INFO: | epoch  27 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 340.55 | loss-text 2.9406\n",
      "2021-12-04 00:11:11,679 - INFO: | epoch  27 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 338.00 | loss-text 2.9369\n",
      "2021-12-04 00:11:45,751 - INFO: | epoch  27 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 340.72 | loss-text 2.9412\n",
      "2021-12-04 00:12:20,113 - INFO: | epoch  27 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.61 | loss-text 2.9562\n",
      "2021-12-04 00:12:54,332 - INFO: | epoch  27 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 342.19 | loss-text 2.9790\n",
      "2021-12-04 00:13:28,487 - INFO: | epoch  27 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 341.54 | loss-text 2.9990\n",
      "2021-12-04 00:14:02,758 - INFO: | epoch  27 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.70 | loss-text 2.9306\n",
      "2021-12-04 00:14:37,040 - INFO: | epoch  27 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.82 | loss-text 2.9499\n",
      "2021-12-04 00:15:11,094 - INFO: | epoch  27 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 340.53 | loss-text 2.9440\n",
      "2021-12-04 00:15:45,196 - INFO: | epoch  27 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 341.02 | loss-text 3.0029\n",
      "2021-12-04 00:16:19,213 - INFO: | epoch  27 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 340.16 | loss-text 2.9770\n",
      "2021-12-04 00:16:53,487 - INFO: | epoch  27 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 342.73 | loss-text 3.0018\n",
      "2021-12-04 00:17:27,577 - INFO: | epoch  27 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 340.89 | loss-text 2.9986\n",
      "2021-12-04 00:18:01,808 - INFO: | epoch  27 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.31 | loss-text 3.0015\n",
      "2021-12-04 00:18:35,938 - INFO: | epoch  27 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.30 | loss-text 2.9061\n",
      "2021-12-04 00:19:10,304 - INFO: | epoch  27 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.65 | loss-text 2.9932\n",
      "2021-12-04 00:19:44,590 - INFO: | epoch  27 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.86 | loss-text 2.9744\n",
      "2021-12-04 00:20:19,140 - INFO: | epoch  27 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 345.50 | loss-text 2.9558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003754\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10147, 'reflen': 10247, 'guess': [10147, 9123, 8099, 7075], 'correct': [5606, 1984, 741, 224]}\n",
      "ratio: 0.990241046159755\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.351\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-04 00:21:12,013 - INFO: eval_greddy SPIDEr: 0.2306\n",
      "loading annotations into memory...\n",
      "0:00:00.003998\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9545, 'reflen': 9851, 'guess': [9545, 8521, 7497, 6473], 'correct': [5417, 2004, 786, 270]}\n",
      "ratio: 0.9689371637396235\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-04 00:21:49,603 - INFO: eval_beam_2 SPIDEr: 0.2398\n",
      "loading annotations into memory...\n",
      "0:00:00.003866\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9264, 'reflen': 9722, 'guess': [9264, 8240, 7216, 6192], 'correct': [5333, 2047, 847, 312]}\n",
      "ratio: 0.9528903517793712\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.162\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.389\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.251\n",
      "2021-12-04 00:22:28,243 - INFO: eval_beam_3 SPIDEr: 0.2507\n",
      "loading annotations into memory...\n",
      "0:00:00.003883\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9101, 'reflen': 9619, 'guess': [9101, 8077, 7054, 6031], 'correct': [5255, 2028, 839, 315]}\n",
      "ratio: 0.9461482482585564\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.164\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.393\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.252\n",
      "2021-12-04 00:23:10,887 - INFO: eval_beam_4 SPIDEr: 0.2521\n",
      "2021-12-04 00:23:44,916 - INFO: | epoch  28 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.25 | loss-text 2.9141\n",
      "2021-12-04 00:24:18,825 - INFO: | epoch  28 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.08 | loss-text 2.9438\n",
      "2021-12-04 00:24:53,091 - INFO: | epoch  28 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 342.65 | loss-text 2.9100\n",
      "2021-12-04 00:25:27,116 - INFO: | epoch  28 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 340.25 | loss-text 2.9643\n",
      "2021-12-04 00:26:01,197 - INFO: | epoch  28 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 340.80 | loss-text 2.9532\n",
      "2021-12-04 00:26:35,122 - INFO: | epoch  28 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 339.24 | loss-text 2.9384\n",
      "2021-12-04 00:27:09,182 - INFO: | epoch  28 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 340.60 | loss-text 2.9467\n",
      "2021-12-04 00:27:43,177 - INFO: | epoch  28 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 339.94 | loss-text 2.9779\n",
      "2021-12-04 00:28:17,388 - INFO: | epoch  28 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.10 | loss-text 2.8874\n",
      "2021-12-04 00:28:51,527 - INFO: | epoch  28 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 341.38 | loss-text 2.9664\n",
      "2021-12-04 00:29:25,696 - INFO: | epoch  28 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 341.68 | loss-text 2.9449\n",
      "2021-12-04 00:29:59,729 - INFO: | epoch  28 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 340.33 | loss-text 2.9301\n",
      "2021-12-04 00:30:33,767 - INFO: | epoch  28 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 340.37 | loss-text 2.8918\n",
      "2021-12-04 00:31:07,716 - INFO: | epoch  28 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 339.49 | loss-text 2.9564\n",
      "2021-12-04 00:31:42,036 - INFO: | epoch  28 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 343.19 | loss-text 2.9559\n",
      "2021-12-04 00:32:15,924 - INFO: | epoch  28 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 338.87 | loss-text 2.9263\n",
      "2021-12-04 00:32:50,002 - INFO: | epoch  28 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 340.77 | loss-text 2.9649\n",
      "2021-12-04 00:33:24,070 - INFO: | epoch  28 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 340.68 | loss-text 2.9493\n",
      "2021-12-04 00:33:58,418 - INFO: | epoch  28 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 343.48 | loss-text 2.9222\n",
      "2021-12-04 00:34:32,449 - INFO: | epoch  28 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 340.30 | loss-text 2.9261\n",
      "2021-12-04 00:35:06,656 - INFO: | epoch  28 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 342.06 | loss-text 2.9453\n",
      "2021-12-04 00:35:40,927 - INFO: | epoch  28 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 342.71 | loss-text 2.9803\n",
      "2021-12-04 00:36:14,976 - INFO: | epoch  28 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 340.49 | loss-text 2.9682\n",
      "2021-12-04 00:36:48,840 - INFO: | epoch  28 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 338.63 | loss-text 2.9331\n",
      "2021-12-04 00:37:23,136 - INFO: | epoch  28 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 342.96 | loss-text 2.9791\n",
      "2021-12-04 00:37:57,395 - INFO: | epoch  28 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.58 | loss-text 2.9821\n",
      "2021-12-04 00:38:31,375 - INFO: | epoch  28 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 339.79 | loss-text 2.9533\n",
      "2021-12-04 00:39:05,495 - INFO: | epoch  28 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 341.19 | loss-text 2.9466\n",
      "2021-12-04 00:39:39,478 - INFO: | epoch  28 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 339.82 | loss-text 2.9757\n",
      "2021-12-04 00:40:13,469 - INFO: | epoch  28 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 339.91 | loss-text 2.9723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003971\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10251, 'reflen': 10356, 'guess': [10251, 9227, 8203, 7179], 'correct': [5471, 1867, 659, 187]}\n",
      "ratio: 0.9898609501737167\n",
      "Bleu_1: 0.528\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.203\n",
      "Bleu_4: 0.121\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.353\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.317\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.212\n",
      "2021-12-04 00:41:07,866 - INFO: eval_greddy SPIDEr: 0.2122\n",
      "loading annotations into memory...\n",
      "0:00:00.003931\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9586, 'reflen': 9878, 'guess': [9586, 8562, 7538, 6514], 'correct': [5427, 1997, 763, 250]}\n",
      "ratio: 0.970439360194273\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.357\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-04 00:41:44,380 - INFO: eval_beam_2 SPIDEr: 0.2343\n",
      "loading annotations into memory...\n",
      "0:00:00.003906\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9293, 'reflen': 9702, 'guess': [9293, 8269, 7245, 6221], 'correct': [5348, 2036, 806, 270]}\n",
      "ratio: 0.9578437435579304\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-04 00:42:22,830 - INFO: eval_beam_3 SPIDEr: 0.2405\n",
      "loading annotations into memory...\n",
      "0:00:00.003882\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9041, 'reflen': 9577, 'guess': [9041, 8017, 6994, 5971], 'correct': [5199, 1975, 783, 272]}\n",
      "ratio: 0.9440325780514833\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.355\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-04 00:43:05,664 - INFO: eval_beam_4 SPIDEr: 0.2386\n",
      "2021-12-04 00:43:39,791 - INFO: | epoch  29 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 341.23 | loss-text 2.9161\n",
      "2021-12-04 00:44:13,980 - INFO: | epoch  29 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 341.88 | loss-text 2.8901\n",
      "2021-12-04 00:44:48,008 - INFO: | epoch  29 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 340.28 | loss-text 2.9158\n",
      "2021-12-04 00:45:22,213 - INFO: | epoch  29 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 342.04 | loss-text 2.9571\n",
      "2021-12-04 00:45:56,362 - INFO: | epoch  29 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 341.49 | loss-text 2.9074\n",
      "2021-12-04 00:46:30,552 - INFO: | epoch  29 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.89 | loss-text 2.8885\n",
      "2021-12-04 00:47:04,815 - INFO: | epoch  29 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.62 | loss-text 2.9116\n",
      "2021-12-04 00:47:39,069 - INFO: | epoch  29 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 342.53 | loss-text 2.9186\n",
      "2021-12-04 00:48:13,296 - INFO: | epoch  29 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.26 | loss-text 2.9356\n",
      "2021-12-04 00:48:47,186 - INFO: | epoch  29 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 338.90 | loss-text 2.9043\n",
      "2021-12-04 00:49:21,397 - INFO: | epoch  29 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.10 | loss-text 2.9385\n",
      "2021-12-04 00:49:55,476 - INFO: | epoch  29 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 340.79 | loss-text 2.9539\n",
      "2021-12-04 00:50:29,603 - INFO: | epoch  29 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 341.26 | loss-text 2.9281\n",
      "2021-12-04 00:51:03,611 - INFO: | epoch  29 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 340.08 | loss-text 2.9416\n",
      "2021-12-04 00:51:37,930 - INFO: | epoch  29 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 343.18 | loss-text 2.9182\n",
      "2021-12-04 00:52:12,118 - INFO: | epoch  29 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 341.87 | loss-text 2.9089\n",
      "2021-12-04 00:52:46,119 - INFO: | epoch  29 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 340.00 | loss-text 2.9134\n",
      "2021-12-04 00:53:20,324 - INFO: | epoch  29 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 342.04 | loss-text 2.9400\n",
      "2021-12-04 00:53:54,611 - INFO: | epoch  29 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.87 | loss-text 2.9133\n",
      "2021-12-04 00:54:28,681 - INFO: | epoch  29 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 340.69 | loss-text 2.9301\n",
      "2021-12-04 00:55:02,845 - INFO: | epoch  29 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 341.63 | loss-text 2.9141\n",
      "2021-12-04 00:55:37,054 - INFO: | epoch  29 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 342.08 | loss-text 2.9581\n",
      "2021-12-04 00:56:11,098 - INFO: | epoch  29 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 340.44 | loss-text 2.9298\n",
      "2021-12-04 00:56:45,113 - INFO: | epoch  29 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 340.14 | loss-text 2.9090\n",
      "2021-12-04 00:57:19,426 - INFO: | epoch  29 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.12 | loss-text 2.9425\n",
      "2021-12-04 00:57:53,628 - INFO: | epoch  29 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.02 | loss-text 2.9803\n",
      "2021-12-04 00:58:27,663 - INFO: | epoch  29 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 340.34 | loss-text 2.9316\n",
      "2021-12-04 00:59:02,053 - INFO: | epoch  29 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.90 | loss-text 2.9803\n",
      "2021-12-04 00:59:36,308 - INFO: | epoch  29 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.55 | loss-text 2.9330\n",
      "2021-12-04 01:00:10,569 - INFO: | epoch  29 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.60 | loss-text 2.9582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003845\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10159, 'reflen': 10277, 'guess': [10159, 9135, 8111, 7087], 'correct': [5359, 1811, 655, 202]}\n",
      "ratio: 0.9885180500144994\n",
      "Bleu_1: 0.521\n",
      "Bleu_2: 0.320\n",
      "Bleu_3: 0.201\n",
      "Bleu_4: 0.123\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.330\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.219\n",
      "2021-12-04 01:01:03,916 - INFO: eval_greddy SPIDEr: 0.2186\n",
      "loading annotations into memory...\n",
      "0:00:00.003846\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9383, 'reflen': 9771, 'guess': [9383, 8359, 7335, 6311], 'correct': [5299, 1895, 761, 267]}\n",
      "ratio: 0.9602906560228267\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-04 01:01:40,138 - INFO: eval_beam_2 SPIDEr: 0.2387\n",
      "loading annotations into memory...\n",
      "0:00:00.003811\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9094, 'reflen': 9612, 'guess': [9094, 8070, 7046, 6022], 'correct': [5203, 1933, 781, 283]}\n",
      "ratio: 0.9461090303785948\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.382\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-04 01:02:20,441 - INFO: eval_beam_3 SPIDEr: 0.2456\n",
      "loading annotations into memory...\n",
      "0:00:00.003934\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8931, 'reflen': 9535, 'guess': [8931, 7907, 6884, 5861], 'correct': [5094, 1882, 742, 256]}\n",
      "ratio: 0.9366544310434256\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-04 01:03:02,859 - INFO: eval_beam_4 SPIDEr: 0.2374\n",
      "2021-12-04 01:03:37,172 - INFO: | epoch  30 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 343.10 | loss-text 2.8404\n",
      "2021-12-04 01:04:11,259 - INFO: | epoch  30 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.85 | loss-text 2.9198\n",
      "2021-12-04 01:04:45,227 - INFO: | epoch  30 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 339.67 | loss-text 2.8869\n",
      "2021-12-04 01:05:19,274 - INFO: | epoch  30 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 340.47 | loss-text 2.8827\n",
      "2021-12-04 01:05:53,581 - INFO: | epoch  30 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 343.07 | loss-text 2.8921\n",
      "2021-12-04 01:06:27,740 - INFO: | epoch  30 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.58 | loss-text 2.9377\n",
      "2021-12-04 01:07:02,071 - INFO: | epoch  30 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 343.30 | loss-text 2.9216\n",
      "2021-12-04 01:07:36,512 - INFO: | epoch  30 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 344.41 | loss-text 2.8780\n",
      "2021-12-04 01:08:10,946 - INFO: | epoch  30 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 344.33 | loss-text 2.9344\n",
      "2021-12-04 01:08:45,045 - INFO: | epoch  30 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 340.97 | loss-text 2.9173\n",
      "2021-12-04 01:09:18,994 - INFO: | epoch  30 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 339.49 | loss-text 2.8647\n",
      "2021-12-04 01:09:53,122 - INFO: | epoch  30 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.27 | loss-text 2.8855\n",
      "2021-12-04 01:10:27,108 - INFO: | epoch  30 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 339.85 | loss-text 2.9116\n",
      "2021-12-04 01:11:01,434 - INFO: | epoch  30 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 343.25 | loss-text 2.9298\n",
      "2021-12-04 01:11:35,464 - INFO: | epoch  30 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 340.29 | loss-text 2.9268\n",
      "2021-12-04 01:12:09,687 - INFO: | epoch  30 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.22 | loss-text 2.9694\n",
      "2021-12-04 01:12:43,752 - INFO: | epoch  30 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 340.64 | loss-text 2.9193\n",
      "2021-12-04 01:13:18,283 - INFO: | epoch  30 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 345.30 | loss-text 2.9241\n",
      "2021-12-04 01:13:52,389 - INFO: | epoch  30 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 341.05 | loss-text 2.9314\n",
      "2021-12-04 01:14:26,472 - INFO: | epoch  30 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 340.83 | loss-text 2.9079\n",
      "2021-12-04 01:15:00,501 - INFO: | epoch  30 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 340.29 | loss-text 2.9176\n",
      "2021-12-04 01:15:34,614 - INFO: | epoch  30 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 341.12 | loss-text 2.9016\n",
      "2021-12-04 01:16:08,647 - INFO: | epoch  30 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 340.33 | loss-text 2.9168\n",
      "2021-12-04 01:16:42,742 - INFO: | epoch  30 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 340.94 | loss-text 2.9178\n",
      "2021-12-04 01:17:16,965 - INFO: | epoch  30 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 342.23 | loss-text 2.9021\n",
      "2021-12-04 01:17:50,989 - INFO: | epoch  30 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 340.23 | loss-text 2.8912\n",
      "2021-12-04 01:18:24,893 - INFO: | epoch  30 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 339.03 | loss-text 2.9154\n",
      "2021-12-04 01:18:59,122 - INFO: | epoch  30 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.28 | loss-text 2.9767\n",
      "2021-12-04 01:19:33,287 - INFO: | epoch  30 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 341.65 | loss-text 2.9209\n",
      "2021-12-04 01:20:07,500 - INFO: | epoch  30 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.12 | loss-text 2.9187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003831\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10104, 'reflen': 10187, 'guess': [10104, 9080, 8056, 7032], 'correct': [5500, 1891, 714, 210]}\n",
      "ratio: 0.9918523608519689\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.334\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.131\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.332\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.219\n",
      "2021-12-04 01:21:01,312 - INFO: eval_greddy SPIDEr: 0.2191\n",
      "loading annotations into memory...\n",
      "0:00:00.004060\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9468, 'reflen': 9799, 'guess': [9468, 8444, 7420, 6396], 'correct': [5357, 1961, 789, 265]}\n",
      "ratio: 0.9662210429634691\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-04 01:21:37,561 - INFO: eval_beam_2 SPIDEr: 0.2383\n",
      "loading annotations into memory...\n",
      "0:00:00.004007\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9226, 'reflen': 9669, 'guess': [9226, 8202, 7178, 6154], 'correct': [5269, 1954, 792, 283]}\n",
      "ratio: 0.9541834729547053\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-04 01:22:17,171 - INFO: eval_beam_3 SPIDEr: 0.2415\n",
      "loading annotations into memory...\n",
      "0:00:00.003874\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9083, 'reflen': 9585, 'guess': [9083, 8059, 7035, 6011], 'correct': [5224, 1963, 821, 307]}\n",
      "ratio: 0.9476264997390769\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.384\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.245\n",
      "2021-12-04 01:22:59,334 - INFO: eval_beam_4 SPIDEr: 0.2452\n",
      "2021-12-04 01:23:33,268 - INFO: | epoch  31 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 339.31 | loss-text 2.8721\n",
      "2021-12-04 01:24:07,301 - INFO: | epoch  31 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.32 | loss-text 2.8806\n",
      "2021-12-04 01:24:41,627 - INFO: | epoch  31 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 343.26 | loss-text 2.9107\n",
      "2021-12-04 01:25:15,780 - INFO: | epoch  31 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.52 | loss-text 2.9128\n",
      "2021-12-04 01:25:50,037 - INFO: | epoch  31 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.56 | loss-text 2.8457\n",
      "2021-12-04 01:26:24,147 - INFO: | epoch  31 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.10 | loss-text 2.9100\n",
      "2021-12-04 01:26:58,489 - INFO: | epoch  31 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 343.41 | loss-text 2.9001\n",
      "2021-12-04 01:27:32,776 - INFO: | epoch  31 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 342.86 | loss-text 2.8756\n",
      "2021-12-04 01:28:06,942 - INFO: | epoch  31 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.65 | loss-text 2.8684\n",
      "2021-12-04 01:28:41,271 - INFO: | epoch  31 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 343.29 | loss-text 2.8717\n",
      "2021-12-04 01:29:15,478 - INFO: | epoch  31 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.06 | loss-text 2.9108\n",
      "2021-12-04 01:29:49,890 - INFO: | epoch  31 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 344.11 | loss-text 2.9456\n",
      "2021-12-04 01:30:24,211 - INFO: | epoch  31 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 343.21 | loss-text 2.8720\n",
      "2021-12-04 01:30:58,412 - INFO: | epoch  31 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.00 | loss-text 2.8743\n",
      "2021-12-04 01:31:32,337 - INFO: | epoch  31 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 339.24 | loss-text 2.9318\n",
      "2021-12-04 01:32:06,489 - INFO: | epoch  31 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 341.51 | loss-text 2.9395\n",
      "2021-12-04 01:32:40,726 - INFO: | epoch  31 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 342.37 | loss-text 2.8988\n",
      "2021-12-04 01:33:14,759 - INFO: | epoch  31 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 340.32 | loss-text 2.8947\n",
      "2021-12-04 01:33:48,937 - INFO: | epoch  31 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 341.77 | loss-text 2.9105\n",
      "2021-12-04 01:34:23,159 - INFO: | epoch  31 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.22 | loss-text 2.9100\n",
      "2021-12-04 01:34:57,326 - INFO: | epoch  31 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 341.67 | loss-text 2.8996\n",
      "2021-12-04 01:35:31,278 - INFO: | epoch  31 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 339.51 | loss-text 2.9350\n",
      "2021-12-04 01:36:05,428 - INFO: | epoch  31 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 341.49 | loss-text 2.8869\n",
      "2021-12-04 01:36:39,671 - INFO: | epoch  31 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 342.42 | loss-text 2.9075\n",
      "2021-12-04 01:37:13,902 - INFO: | epoch  31 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 342.30 | loss-text 2.9181\n",
      "2021-12-04 01:37:47,971 - INFO: | epoch  31 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 340.69 | loss-text 2.9195\n",
      "2021-12-04 01:38:22,267 - INFO: | epoch  31 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.95 | loss-text 2.9272\n",
      "2021-12-04 01:38:56,417 - INFO: | epoch  31 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 341.49 | loss-text 2.8677\n",
      "2021-12-04 01:39:30,274 - INFO: | epoch  31 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 338.56 | loss-text 2.9000\n",
      "2021-12-04 01:40:04,524 - INFO: | epoch  31 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.49 | loss-text 2.9256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003736\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10288, 'reflen': 10373, 'guess': [10288, 9264, 8240, 7216], 'correct': [5606, 2013, 737, 219]}\n",
      "ratio: 0.9918056492816936\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.341\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.343\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.226\n",
      "2021-12-04 01:40:57,735 - INFO: eval_greddy SPIDEr: 0.2259\n",
      "loading annotations into memory...\n",
      "0:00:00.004216\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9499, 'reflen': 9837, 'guess': [9499, 8475, 7451, 6427], 'correct': [5425, 2031, 806, 289]}\n",
      "ratio: 0.9656399308731355\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.357\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.379\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-04 01:41:33,783 - INFO: eval_beam_2 SPIDEr: 0.2444\n",
      "loading annotations into memory...\n",
      "0:00:00.003890\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9233, 'reflen': 9688, 'guess': [9233, 8209, 7185, 6161], 'correct': [5318, 2035, 844, 318]}\n",
      "ratio: 0.9530346820808264\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.163\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.379\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-04 01:42:12,202 - INFO: eval_beam_3 SPIDEr: 0.2430\n",
      "loading annotations into memory...\n",
      "0:00:00.003859\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9063, 'reflen': 9591, 'guess': [9063, 8039, 7015, 5991], 'correct': [5214, 1980, 802, 289]}\n",
      "ratio: 0.9449483891146966\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.355\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.379\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-04 01:42:54,814 - INFO: eval_beam_4 SPIDEr: 0.2424\n",
      "2021-12-04 01:43:29,056 - INFO: | epoch  32 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 342.39 | loss-text 2.8439\n",
      "2021-12-04 01:44:03,420 - INFO: | epoch  32 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 343.63 | loss-text 2.9083\n",
      "2021-12-04 01:44:37,595 - INFO: | epoch  32 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.74 | loss-text 2.8637\n",
      "2021-12-04 01:45:11,666 - INFO: | epoch  32 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 340.71 | loss-text 2.8522\n",
      "2021-12-04 01:45:46,088 - INFO: | epoch  32 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 344.21 | loss-text 2.8962\n",
      "2021-12-04 01:46:20,438 - INFO: | epoch  32 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 343.50 | loss-text 2.8225\n",
      "2021-12-04 01:46:54,500 - INFO: | epoch  32 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 340.61 | loss-text 2.8519\n",
      "2021-12-04 01:47:28,855 - INFO: | epoch  32 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.54 | loss-text 2.9033\n",
      "2021-12-04 01:48:02,885 - INFO: | epoch  32 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 340.30 | loss-text 2.8627\n",
      "2021-12-04 01:48:37,166 - INFO: | epoch  32 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.80 | loss-text 2.8618\n",
      "2021-12-04 01:49:11,476 - INFO: | epoch  32 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 343.09 | loss-text 2.8859\n",
      "2021-12-04 01:49:45,684 - INFO: | epoch  32 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.07 | loss-text 2.8847\n",
      "2021-12-04 01:50:20,023 - INFO: | epoch  32 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 343.39 | loss-text 2.9154\n",
      "2021-12-04 01:50:54,235 - INFO: | epoch  32 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.11 | loss-text 2.8976\n",
      "2021-12-04 01:51:28,514 - INFO: | epoch  32 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.78 | loss-text 2.9227\n",
      "2021-12-04 01:52:02,671 - INFO: | epoch  32 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 341.56 | loss-text 2.9141\n",
      "2021-12-04 01:52:36,842 - INFO: | epoch  32 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 341.70 | loss-text 2.8855\n",
      "2021-12-04 01:53:11,071 - INFO: | epoch  32 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 342.29 | loss-text 2.9044\n",
      "2021-12-04 01:53:45,105 - INFO: | epoch  32 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 340.33 | loss-text 2.8756\n",
      "2021-12-04 01:54:19,285 - INFO: | epoch  32 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 341.79 | loss-text 2.9116\n",
      "2021-12-04 01:54:53,635 - INFO: | epoch  32 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 343.49 | loss-text 2.9271\n",
      "2021-12-04 01:55:28,014 - INFO: | epoch  32 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 343.79 | loss-text 2.9044\n",
      "2021-12-04 01:56:02,294 - INFO: | epoch  32 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.80 | loss-text 2.8994\n",
      "2021-12-04 01:56:36,217 - INFO: | epoch  32 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 339.22 | loss-text 2.9274\n",
      "2021-12-04 01:57:10,301 - INFO: | epoch  32 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 340.83 | loss-text 2.9157\n",
      "2021-12-04 01:57:44,448 - INFO: | epoch  32 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 341.47 | loss-text 2.9306\n",
      "2021-12-04 01:58:18,272 - INFO: | epoch  32 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 338.23 | loss-text 2.9039\n",
      "2021-12-04 01:58:52,812 - INFO: | epoch  32 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 345.39 | loss-text 2.8755\n",
      "2021-12-04 01:59:27,102 - INFO: | epoch  32 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.89 | loss-text 2.8636\n",
      "2021-12-04 02:00:01,313 - INFO: | epoch  32 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.10 | loss-text 2.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003780\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10262, 'reflen': 10347, 'guess': [10262, 9238, 8214, 7190], 'correct': [5558, 1910, 684, 210]}\n",
      "ratio: 0.9917850584709585\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.209\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.335\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.221\n",
      "2021-12-04 02:00:55,488 - INFO: eval_greddy SPIDEr: 0.2213\n",
      "loading annotations into memory...\n",
      "0:00:00.003806\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9434, 'reflen': 9779, 'guess': [9434, 8410, 7386, 6362], 'correct': [5357, 1935, 749, 249]}\n",
      "ratio: 0.964720319050929\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-04 02:01:31,851 - INFO: eval_beam_2 SPIDEr: 0.2382\n",
      "loading annotations into memory...\n",
      "0:00:00.003967\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9243, 'reflen': 9656, 'guess': [9243, 8219, 7195, 6171], 'correct': [5257, 1928, 778, 281]}\n",
      "ratio: 0.9572286661142339\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-04 02:02:10,492 - INFO: eval_beam_3 SPIDEr: 0.2394\n",
      "loading annotations into memory...\n",
      "0:00:00.004058\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9056, 'reflen': 9537, 'guess': [9056, 8032, 7008, 5984], 'correct': [5160, 1880, 745, 264]}\n",
      "ratio: 0.94956485267894\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-04 02:02:52,952 - INFO: eval_beam_4 SPIDEr: 0.2398\n",
      "2021-12-04 02:03:26,864 - INFO: | epoch  33 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 339.08 | loss-text 2.8562\n",
      "2021-12-04 02:04:00,713 - INFO: | epoch  33 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 338.48 | loss-text 2.8514\n",
      "2021-12-04 02:04:34,761 - INFO: | epoch  33 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 340.47 | loss-text 2.8294\n",
      "2021-12-04 02:05:08,985 - INFO: | epoch  33 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 342.23 | loss-text 2.8769\n",
      "2021-12-04 02:05:43,323 - INFO: | epoch  33 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 343.38 | loss-text 2.8365\n",
      "2021-12-04 02:06:17,577 - INFO: | epoch  33 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.53 | loss-text 2.8813\n",
      "2021-12-04 02:06:51,835 - INFO: | epoch  33 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.58 | loss-text 2.8390\n",
      "2021-12-04 02:07:26,251 - INFO: | epoch  33 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 344.14 | loss-text 2.8889\n",
      "2021-12-04 02:08:00,625 - INFO: | epoch  33 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 343.74 | loss-text 2.8750\n",
      "2021-12-04 02:08:34,914 - INFO: | epoch  33 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.88 | loss-text 2.8742\n",
      "2021-12-04 02:09:09,189 - INFO: | epoch  33 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.75 | loss-text 2.8516\n",
      "2021-12-04 02:09:43,382 - INFO: | epoch  33 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.92 | loss-text 2.8460\n",
      "2021-12-04 02:10:17,505 - INFO: | epoch  33 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 341.22 | loss-text 2.8805\n",
      "2021-12-04 02:10:51,908 - INFO: | epoch  33 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 344.03 | loss-text 2.8386\n",
      "2021-12-04 02:11:26,258 - INFO: | epoch  33 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 343.49 | loss-text 2.8564\n",
      "2021-12-04 02:12:00,521 - INFO: | epoch  33 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.62 | loss-text 2.8365\n",
      "2021-12-04 02:12:34,786 - INFO: | epoch  33 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 342.65 | loss-text 2.8852\n",
      "2021-12-04 02:13:08,840 - INFO: | epoch  33 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 340.53 | loss-text 2.8427\n",
      "2021-12-04 02:13:42,921 - INFO: | epoch  33 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 340.81 | loss-text 2.8940\n",
      "2021-12-04 02:14:16,782 - INFO: | epoch  33 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 338.60 | loss-text 2.9124\n",
      "2021-12-04 02:14:51,030 - INFO: | epoch  33 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 342.47 | loss-text 2.8600\n",
      "2021-12-04 02:15:25,138 - INFO: | epoch  33 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 341.07 | loss-text 2.8651\n",
      "2021-12-04 02:15:59,341 - INFO: | epoch  33 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.02 | loss-text 2.9254\n",
      "2021-12-04 02:16:33,680 - INFO: | epoch  33 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.39 | loss-text 2.8753\n",
      "2021-12-04 02:17:08,071 - INFO: | epoch  33 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.91 | loss-text 2.8777\n",
      "2021-12-04 02:17:42,361 - INFO: | epoch  33 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.89 | loss-text 2.8665\n",
      "2021-12-04 02:18:16,757 - INFO: | epoch  33 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 343.96 | loss-text 2.8826\n",
      "2021-12-04 02:18:50,996 - INFO: | epoch  33 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.38 | loss-text 2.9453\n",
      "2021-12-04 02:19:25,007 - INFO: | epoch  33 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 340.10 | loss-text 2.9064\n",
      "2021-12-04 02:19:59,151 - INFO: | epoch  33 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 341.44 | loss-text 2.8605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003955\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10206, 'reflen': 10323, 'guess': [10206, 9182, 8158, 7134], 'correct': [5577, 1952, 731, 223]}\n",
      "ratio: 0.9886660854401832\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.343\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2021-12-04 02:20:53,246 - INFO: eval_greddy SPIDEr: 0.2249\n",
      "loading annotations into memory...\n",
      "0:00:00.003847\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9475, 'reflen': 9810, 'guess': [9475, 8451, 7427, 6403], 'correct': [5404, 1983, 774, 269]}\n",
      "ratio: 0.9658511722730921\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-04 02:21:30,265 - INFO: eval_beam_2 SPIDEr: 0.2395\n",
      "loading annotations into memory...\n",
      "0:00:00.003613\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9200, 'reflen': 9661, 'guess': [9200, 8176, 7152, 6128], 'correct': [5275, 1971, 793, 284]}\n",
      "ratio: 0.9522823724251162\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-04 02:22:09,603 - INFO: eval_beam_3 SPIDEr: 0.2423\n",
      "loading annotations into memory...\n",
      "0:00:00.003865\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9057, 'reflen': 9593, 'guess': [9057, 8033, 7009, 5985], 'correct': [5194, 1975, 822, 307]}\n",
      "ratio: 0.9441259251536595\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.381\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.245\n",
      "2021-12-04 02:22:52,014 - INFO: eval_beam_4 SPIDEr: 0.2448\n",
      "2021-12-04 02:23:26,311 - INFO: | epoch  34 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 342.94 | loss-text 2.8405\n",
      "2021-12-04 02:24:00,628 - INFO: | epoch  34 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 343.16 | loss-text 2.8777\n",
      "2021-12-04 02:24:34,707 - INFO: | epoch  34 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 340.78 | loss-text 2.8676\n",
      "2021-12-04 02:25:08,855 - INFO: | epoch  34 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.47 | loss-text 2.8107\n",
      "2021-12-04 02:25:42,647 - INFO: | epoch  34 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 337.92 | loss-text 2.8278\n",
      "2021-12-04 02:26:16,929 - INFO: | epoch  34 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.82 | loss-text 2.8224\n",
      "2021-12-04 02:26:50,853 - INFO: | epoch  34 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 339.23 | loss-text 2.8197\n",
      "2021-12-04 02:27:25,021 - INFO: | epoch  34 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 341.67 | loss-text 2.8468\n",
      "2021-12-04 02:27:59,335 - INFO: | epoch  34 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 343.13 | loss-text 2.8480\n",
      "2021-12-04 02:28:33,853 - INFO: | epoch  34 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 345.18 | loss-text 2.8769\n",
      "2021-12-04 02:29:08,273 - INFO: | epoch  34 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 344.19 | loss-text 2.8886\n",
      "2021-12-04 02:29:42,369 - INFO: | epoch  34 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 340.96 | loss-text 2.8246\n",
      "2021-12-04 02:30:16,768 - INFO: | epoch  34 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 343.99 | loss-text 2.8493\n",
      "2021-12-04 02:30:51,103 - INFO: | epoch  34 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 343.34 | loss-text 2.8749\n",
      "2021-12-04 02:31:25,272 - INFO: | epoch  34 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 341.67 | loss-text 2.8339\n",
      "2021-12-04 02:31:59,390 - INFO: | epoch  34 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 341.18 | loss-text 2.8578\n",
      "2021-12-04 02:32:33,505 - INFO: | epoch  34 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 341.13 | loss-text 2.8713\n",
      "2021-12-04 02:33:07,908 - INFO: | epoch  34 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.03 | loss-text 2.8923\n",
      "2021-12-04 02:33:42,304 - INFO: | epoch  34 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 343.95 | loss-text 2.8838\n",
      "2021-12-04 02:34:16,522 - INFO: | epoch  34 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.18 | loss-text 2.8506\n",
      "2021-12-04 02:34:50,470 - INFO: | epoch  34 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 339.47 | loss-text 2.8589\n",
      "2021-12-04 02:35:24,780 - INFO: | epoch  34 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 343.10 | loss-text 2.9129\n",
      "2021-12-04 02:35:59,219 - INFO: | epoch  34 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 344.38 | loss-text 2.8411\n",
      "2021-12-04 02:36:33,562 - INFO: | epoch  34 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.43 | loss-text 2.8831\n",
      "2021-12-04 02:37:07,631 - INFO: | epoch  34 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 340.68 | loss-text 2.8430\n",
      "2021-12-04 02:37:41,963 - INFO: | epoch  34 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 343.31 | loss-text 2.8413\n",
      "2021-12-04 02:38:16,570 - INFO: | epoch  34 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 346.07 | loss-text 2.8677\n",
      "2021-12-04 02:38:50,917 - INFO: | epoch  34 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.46 | loss-text 2.8963\n",
      "2021-12-04 02:39:25,181 - INFO: | epoch  34 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.63 | loss-text 2.8769\n",
      "2021-12-04 02:39:59,071 - INFO: | epoch  34 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 338.90 | loss-text 2.8909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003916\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10197, 'reflen': 10303, 'guess': [10197, 9173, 8149, 7125], 'correct': [5542, 1890, 673, 213]}\n",
      "ratio: 0.9897117344461817\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.346\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2021-12-04 02:40:52,084 - INFO: eval_greddy SPIDEr: 0.2271\n",
      "loading annotations into memory...\n",
      "0:00:00.003933\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9445, 'reflen': 9810, 'guess': [9445, 8421, 7397, 6373], 'correct': [5362, 1907, 722, 247]}\n",
      "ratio: 0.9627930682975573\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.224\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-04 02:41:28,372 - INFO: eval_beam_2 SPIDEr: 0.2372\n",
      "loading annotations into memory...\n",
      "0:00:00.003893\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9184, 'reflen': 9676, 'guess': [9184, 8160, 7136, 6112], 'correct': [5252, 1895, 738, 261]}\n",
      "ratio: 0.9491525423727832\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.227\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-04 02:42:07,126 - INFO: eval_beam_3 SPIDEr: 0.2376\n",
      "loading annotations into memory...\n",
      "0:00:00.003849\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9004, 'reflen': 9575, 'guess': [9004, 7980, 6956, 5933], 'correct': [5126, 1885, 756, 276]}\n",
      "ratio: 0.9403655352479435\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.375\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-04 02:42:49,619 - INFO: eval_beam_4 SPIDEr: 0.2415\n",
      "2021-12-04 02:43:23,722 - INFO: | epoch  35 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 341.00 | loss-text 2.8358\n",
      "2021-12-04 02:43:57,606 - INFO: | epoch  35 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 338.82 | loss-text 2.8366\n",
      "2021-12-04 02:44:31,646 - INFO: | epoch  35 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 340.40 | loss-text 2.8329\n",
      "2021-12-04 02:45:05,881 - INFO: | epoch  35 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 342.34 | loss-text 2.8742\n",
      "2021-12-04 02:45:39,776 - INFO: | epoch  35 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 338.94 | loss-text 2.8329\n",
      "2021-12-04 02:46:14,037 - INFO: | epoch  35 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.61 | loss-text 2.8035\n",
      "2021-12-04 02:46:48,285 - INFO: | epoch  35 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.47 | loss-text 2.8361\n",
      "2021-12-04 02:47:22,251 - INFO: | epoch  35 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 339.65 | loss-text 2.8565\n",
      "2021-12-04 02:47:56,342 - INFO: | epoch  35 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 340.90 | loss-text 2.7986\n",
      "2021-12-04 02:48:30,771 - INFO: | epoch  35 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 344.28 | loss-text 2.8648\n",
      "2021-12-04 02:49:04,992 - INFO: | epoch  35 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.20 | loss-text 2.8425\n",
      "2021-12-04 02:49:39,231 - INFO: | epoch  35 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.39 | loss-text 2.9104\n",
      "2021-12-04 02:50:13,439 - INFO: | epoch  35 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.07 | loss-text 2.8182\n",
      "2021-12-04 02:50:47,753 - INFO: | epoch  35 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 343.13 | loss-text 2.8917\n",
      "2021-12-04 02:51:22,106 - INFO: | epoch  35 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 343.52 | loss-text 2.8821\n",
      "2021-12-04 02:51:56,324 - INFO: | epoch  35 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.17 | loss-text 2.8330\n",
      "2021-12-04 02:52:30,884 - INFO: | epoch  35 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 345.59 | loss-text 2.8773\n",
      "2021-12-04 02:53:05,321 - INFO: | epoch  35 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.37 | loss-text 2.8583\n",
      "2021-12-04 02:53:39,506 - INFO: | epoch  35 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 341.84 | loss-text 2.8361\n",
      "2021-12-04 02:54:13,936 - INFO: | epoch  35 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 344.29 | loss-text 2.8526\n",
      "2021-12-04 02:54:48,161 - INFO: | epoch  35 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 342.24 | loss-text 2.8277\n",
      "2021-12-04 02:55:22,295 - INFO: | epoch  35 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 341.34 | loss-text 2.8861\n",
      "2021-12-04 02:55:56,736 - INFO: | epoch  35 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 344.40 | loss-text 2.8360\n",
      "2021-12-04 02:56:31,057 - INFO: | epoch  35 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.21 | loss-text 2.8620\n",
      "2021-12-04 02:57:05,393 - INFO: | epoch  35 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.35 | loss-text 2.8507\n",
      "2021-12-04 02:57:39,726 - INFO: | epoch  35 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 343.33 | loss-text 2.8646\n",
      "2021-12-04 02:58:13,991 - INFO: | epoch  35 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.65 | loss-text 2.8581\n",
      "2021-12-04 02:58:48,336 - INFO: | epoch  35 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.44 | loss-text 2.8570\n",
      "2021-12-04 02:59:22,657 - INFO: | epoch  35 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 343.20 | loss-text 2.8850\n",
      "2021-12-04 02:59:57,191 - INFO: | epoch  35 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 345.33 | loss-text 2.8449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003859\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10278, 'reflen': 10320, 'guess': [10278, 9254, 8230, 7206], 'correct': [5571, 1972, 707, 202]}\n",
      "ratio: 0.995930232558043\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.338\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.129\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.349\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-04 03:00:51,807 - INFO: eval_greddy SPIDEr: 0.2309\n",
      "loading annotations into memory...\n",
      "0:00:00.003878\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9579, 'reflen': 9867, 'guess': [9579, 8555, 7531, 6507], 'correct': [5432, 2006, 787, 270]}\n",
      "ratio: 0.9708117968986549\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.382\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.249\n",
      "2021-12-04 03:01:28,846 - INFO: eval_beam_2 SPIDEr: 0.2491\n",
      "loading annotations into memory...\n",
      "0:00:00.003996\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9357, 'reflen': 9758, 'guess': [9357, 8333, 7309, 6285], 'correct': [5364, 2034, 816, 288]}\n",
      "ratio: 0.9589055134247838\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.397\n",
      "computing SPICE score...\n",
      "SPICE: 0.117\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.257\n",
      "2021-12-04 03:02:08,328 - INFO: eval_beam_3 SPIDEr: 0.2567\n",
      "loading annotations into memory...\n",
      "0:00:00.003888\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9181, 'reflen': 9670, 'guess': [9181, 8157, 7133, 6109], 'correct': [5275, 2003, 806, 288]}\n",
      "ratio: 0.9494312306100362\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.396\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.255\n",
      "2021-12-04 03:02:51,373 - INFO: eval_beam_4 SPIDEr: 0.2551\n",
      "2021-12-04 03:03:25,534 - INFO: | epoch  36 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 341.58 | loss-text 2.7999\n",
      "2021-12-04 03:03:59,737 - INFO: | epoch  36 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 342.02 | loss-text 2.7721\n",
      "2021-12-04 03:04:33,806 - INFO: | epoch  36 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 340.68 | loss-text 2.8053\n",
      "2021-12-04 03:05:07,907 - INFO: | epoch  36 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.00 | loss-text 2.8242\n",
      "2021-12-04 03:05:42,156 - INFO: | epoch  36 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.48 | loss-text 2.8146\n",
      "2021-12-04 03:06:16,292 - INFO: | epoch  36 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.35 | loss-text 2.8474\n",
      "2021-12-04 03:06:50,551 - INFO: | epoch  36 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.58 | loss-text 2.8072\n",
      "2021-12-04 03:07:24,479 - INFO: | epoch  36 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 339.27 | loss-text 2.8079\n",
      "2021-12-04 03:07:58,687 - INFO: | epoch  36 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.08 | loss-text 2.7857\n",
      "2021-12-04 03:08:33,267 - INFO: | epoch  36 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 345.79 | loss-text 2.8088\n",
      "2021-12-04 03:09:07,465 - INFO: | epoch  36 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 341.97 | loss-text 2.8063\n",
      "2021-12-04 03:09:41,678 - INFO: | epoch  36 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.13 | loss-text 2.8222\n",
      "2021-12-04 03:10:15,710 - INFO: | epoch  36 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 340.31 | loss-text 2.8411\n",
      "2021-12-04 03:10:50,237 - INFO: | epoch  36 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 345.27 | loss-text 2.8621\n",
      "2021-12-04 03:11:24,415 - INFO: | epoch  36 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 341.77 | loss-text 2.8686\n",
      "2021-12-04 03:11:58,680 - INFO: | epoch  36 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.65 | loss-text 2.8477\n",
      "2021-12-04 03:12:32,738 - INFO: | epoch  36 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 340.57 | loss-text 2.8477\n",
      "2021-12-04 03:13:06,870 - INFO: | epoch  36 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 341.32 | loss-text 2.8552\n",
      "2021-12-04 03:13:41,297 - INFO: | epoch  36 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 344.26 | loss-text 2.8574\n",
      "2021-12-04 03:14:15,421 - INFO: | epoch  36 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 341.24 | loss-text 2.7925\n",
      "2021-12-04 03:14:49,791 - INFO: | epoch  36 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 343.68 | loss-text 2.8397\n",
      "2021-12-04 03:15:24,217 - INFO: | epoch  36 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 344.26 | loss-text 2.8271\n",
      "2021-12-04 03:15:58,673 - INFO: | epoch  36 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 344.55 | loss-text 2.8150\n",
      "2021-12-04 03:16:32,952 - INFO: | epoch  36 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 342.79 | loss-text 2.8337\n",
      "2021-12-04 03:17:07,086 - INFO: | epoch  36 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 341.33 | loss-text 2.7975\n",
      "2021-12-04 03:17:41,378 - INFO: | epoch  36 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.92 | loss-text 2.8561\n",
      "2021-12-04 03:18:15,476 - INFO: | epoch  36 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 340.98 | loss-text 2.8794\n",
      "2021-12-04 03:18:49,788 - INFO: | epoch  36 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.11 | loss-text 2.8178\n",
      "2021-12-04 03:19:24,037 - INFO: | epoch  36 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.49 | loss-text 2.8872\n",
      "2021-12-04 03:19:58,271 - INFO: | epoch  36 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.33 | loss-text 2.8430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003896\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10170, 'reflen': 10288, 'guess': [10170, 9146, 8122, 7098], 'correct': [5585, 1956, 726, 238]}\n",
      "ratio: 0.9885303265939941\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.350\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-04 03:20:52,515 - INFO: eval_greddy SPIDEr: 0.2318\n",
      "loading annotations into memory...\n",
      "0:00:00.003995\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9477, 'reflen': 9834, 'guess': [9477, 8453, 7429, 6405], 'correct': [5381, 1999, 784, 279]}\n",
      "ratio: 0.9636973764489563\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.380\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.247\n",
      "2021-12-04 03:21:29,549 - INFO: eval_beam_2 SPIDEr: 0.2473\n",
      "loading annotations into memory...\n",
      "0:00:00.003984\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9116, 'reflen': 9624, 'guess': [9116, 8092, 7068, 6044], 'correct': [5230, 1967, 788, 271]}\n",
      "ratio: 0.9472152950954958\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.384\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.249\n",
      "2021-12-04 03:22:09,004 - INFO: eval_beam_3 SPIDEr: 0.2489\n",
      "loading annotations into memory...\n",
      "0:00:00.003965\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8980, 'reflen': 9544, 'guess': [8980, 7956, 6932, 5908], 'correct': [5138, 1932, 778, 280]}\n",
      "ratio: 0.9409052808045955\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.378\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-04 03:22:52,142 - INFO: eval_beam_4 SPIDEr: 0.2440\n",
      "2021-12-04 03:23:26,138 - INFO: | epoch  37 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 339.93 | loss-text 2.7599\n",
      "2021-12-04 03:24:00,230 - INFO: | epoch  37 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.91 | loss-text 2.8409\n",
      "2021-12-04 03:24:34,445 - INFO: | epoch  37 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 342.14 | loss-text 2.7853\n",
      "2021-12-04 03:25:08,562 - INFO: | epoch  37 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.17 | loss-text 2.8024\n",
      "2021-12-04 03:25:42,748 - INFO: | epoch  37 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 341.85 | loss-text 2.8116\n",
      "2021-12-04 03:26:16,912 - INFO: | epoch  37 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.63 | loss-text 2.8128\n",
      "2021-12-04 03:26:50,987 - INFO: | epoch  37 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 340.75 | loss-text 2.8134\n",
      "2021-12-04 03:27:25,379 - INFO: | epoch  37 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.91 | loss-text 2.8119\n",
      "2021-12-04 03:27:59,814 - INFO: | epoch  37 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 344.35 | loss-text 2.7877\n",
      "2021-12-04 03:28:34,232 - INFO: | epoch  37 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 344.17 | loss-text 2.8553\n",
      "2021-12-04 03:29:08,358 - INFO: | epoch  37 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 341.25 | loss-text 2.8130\n",
      "2021-12-04 03:29:42,639 - INFO: | epoch  37 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.80 | loss-text 2.8255\n",
      "2021-12-04 03:30:16,833 - INFO: | epoch  37 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 341.93 | loss-text 2.8208\n",
      "2021-12-04 03:30:51,194 - INFO: | epoch  37 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 343.61 | loss-text 2.8413\n",
      "2021-12-04 03:31:25,890 - INFO: | epoch  37 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 346.95 | loss-text 2.8299\n",
      "2021-12-04 03:32:00,213 - INFO: | epoch  37 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.23 | loss-text 2.8609\n",
      "2021-12-04 03:32:34,451 - INFO: | epoch  37 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 342.37 | loss-text 2.8094\n",
      "2021-12-04 03:33:08,655 - INFO: | epoch  37 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 342.03 | loss-text 2.7945\n",
      "2021-12-04 03:33:43,116 - INFO: | epoch  37 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 344.61 | loss-text 2.7882\n",
      "2021-12-04 03:34:17,320 - INFO: | epoch  37 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.04 | loss-text 2.8383\n",
      "2021-12-04 03:34:51,733 - INFO: | epoch  37 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 344.12 | loss-text 2.8397\n",
      "2021-12-04 03:35:26,031 - INFO: | epoch  37 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 342.97 | loss-text 2.8051\n",
      "2021-12-04 03:36:00,119 - INFO: | epoch  37 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 340.87 | loss-text 2.8733\n",
      "2021-12-04 03:36:34,531 - INFO: | epoch  37 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 344.12 | loss-text 2.8219\n",
      "2021-12-04 03:37:08,763 - INFO: | epoch  37 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 342.31 | loss-text 2.7934\n",
      "2021-12-04 03:37:42,886 - INFO: | epoch  37 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 341.22 | loss-text 2.8502\n",
      "2021-12-04 03:38:17,119 - INFO: | epoch  37 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.32 | loss-text 2.8442\n",
      "2021-12-04 03:38:51,057 - INFO: | epoch  37 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 339.38 | loss-text 2.8122\n",
      "2021-12-04 03:39:25,408 - INFO: | epoch  37 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 343.51 | loss-text 2.8267\n",
      "2021-12-04 03:39:59,338 - INFO: | epoch  37 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 339.29 | loss-text 2.7817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003842\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10338, 'reflen': 10363, 'guess': [10338, 9314, 8290, 7266], 'correct': [5541, 1945, 686, 189]}\n",
      "ratio: 0.9975875711665543\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.334\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.219\n",
      "2021-12-04 03:40:55,170 - INFO: eval_greddy SPIDEr: 0.2193\n",
      "loading annotations into memory...\n",
      "0:00:00.004046\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9618, 'reflen': 9903, 'guess': [9618, 8594, 7570, 6546], 'correct': [5342, 2005, 781, 252]}\n",
      "ratio: 0.9712208421689416\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-04 03:41:32,607 - INFO: eval_beam_2 SPIDEr: 0.2402\n",
      "loading annotations into memory...\n",
      "0:00:00.004166\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9369, 'reflen': 9766, 'guess': [9369, 8345, 7321, 6297], 'correct': [5234, 1936, 744, 240]}\n",
      "ratio: 0.959348761007479\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.360\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-04 03:42:12,671 - INFO: eval_beam_3 SPIDEr: 0.2345\n",
      "loading annotations into memory...\n",
      "0:00:00.003934\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9135, 'reflen': 9635, 'guess': [9135, 8111, 7087, 6064], 'correct': [5095, 1895, 730, 249]}\n",
      "ratio: 0.9481058640372654\n",
      "Bleu_1: 0.528\n",
      "Bleu_2: 0.342\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-04 03:42:57,089 - INFO: eval_beam_4 SPIDEr: 0.2330\n",
      "2021-12-04 03:43:31,415 - INFO: | epoch  38 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 343.22 | loss-text 2.7793\n",
      "2021-12-04 03:44:05,423 - INFO: | epoch  38 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.07 | loss-text 2.7877\n",
      "2021-12-04 03:44:39,465 - INFO: | epoch  38 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 340.41 | loss-text 2.7273\n",
      "2021-12-04 03:45:13,763 - INFO: | epoch  38 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 342.97 | loss-text 2.7826\n",
      "2021-12-04 03:45:47,753 - INFO: | epoch  38 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 339.90 | loss-text 2.7710\n",
      "2021-12-04 03:46:22,008 - INFO: | epoch  38 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.55 | loss-text 2.8731\n",
      "2021-12-04 03:46:56,517 - INFO: | epoch  38 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 345.08 | loss-text 2.7989\n",
      "2021-12-04 03:47:30,882 - INFO: | epoch  38 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.64 | loss-text 2.8202\n",
      "2021-12-04 03:48:04,864 - INFO: | epoch  38 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 339.82 | loss-text 2.8075\n",
      "2021-12-04 03:48:39,155 - INFO: | epoch  38 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.90 | loss-text 2.7789\n",
      "2021-12-04 03:49:13,447 - INFO: | epoch  38 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.91 | loss-text 2.7564\n",
      "2021-12-04 03:49:47,573 - INFO: | epoch  38 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.25 | loss-text 2.8187\n",
      "2021-12-04 03:50:22,019 - INFO: | epoch  38 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 344.46 | loss-text 2.7857\n",
      "2021-12-04 03:50:56,440 - INFO: | epoch  38 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 344.20 | loss-text 2.8361\n",
      "2021-12-04 03:51:30,477 - INFO: | epoch  38 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 340.36 | loss-text 2.7696\n",
      "2021-12-04 03:52:04,939 - INFO: | epoch  38 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 344.61 | loss-text 2.8117\n",
      "2021-12-04 03:52:39,439 - INFO: | epoch  38 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 345.00 | loss-text 2.8283\n",
      "2021-12-04 03:53:13,800 - INFO: | epoch  38 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 343.60 | loss-text 2.8349\n",
      "2021-12-04 03:53:47,804 - INFO: | epoch  38 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 340.03 | loss-text 2.8517\n",
      "2021-12-04 03:54:21,714 - INFO: | epoch  38 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 339.10 | loss-text 2.8532\n",
      "2021-12-04 03:54:56,071 - INFO: | epoch  38 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 343.57 | loss-text 2.7872\n",
      "2021-12-04 03:55:30,309 - INFO: | epoch  38 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 342.38 | loss-text 2.8088\n",
      "2021-12-04 03:56:04,880 - INFO: | epoch  38 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 345.70 | loss-text 2.8269\n",
      "2021-12-04 03:56:39,108 - INFO: | epoch  38 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 342.27 | loss-text 2.8519\n",
      "2021-12-04 03:57:13,369 - INFO: | epoch  38 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 342.60 | loss-text 2.8276\n",
      "2021-12-04 03:57:47,689 - INFO: | epoch  38 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 343.19 | loss-text 2.8397\n",
      "2021-12-04 03:58:21,969 - INFO: | epoch  38 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.80 | loss-text 2.8146\n",
      "2021-12-04 03:58:56,518 - INFO: | epoch  38 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 345.48 | loss-text 2.8132\n",
      "2021-12-04 03:59:30,938 - INFO: | epoch  38 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 344.19 | loss-text 2.8107\n",
      "2021-12-04 04:00:04,960 - INFO: | epoch  38 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 340.22 | loss-text 2.8135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003979\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10406, 'reflen': 10408, 'guess': [10406, 9382, 8358, 7334], 'correct': [5685, 1993, 724, 194]}\n",
      "ratio: 0.9998078401228863\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.341\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.351\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-04 04:00:58,353 - INFO: eval_greddy SPIDEr: 0.2319\n",
      "loading annotations into memory...\n",
      "0:00:00.003942\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9668, 'reflen': 9956, 'guess': [9668, 8644, 7620, 6596], 'correct': [5427, 1937, 735, 230]}\n",
      "ratio: 0.971072719967761\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.223\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-04 04:01:34,740 - INFO: eval_beam_2 SPIDEr: 0.2393\n",
      "loading annotations into memory...\n",
      "0:00:00.003965\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9317, 'reflen': 9760, 'guess': [9317, 8293, 7269, 6245], 'correct': [5289, 1927, 764, 264]}\n",
      "ratio: 0.9546106557376071\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-04 04:02:14,878 - INFO: eval_beam_3 SPIDEr: 0.2400\n",
      "loading annotations into memory...\n",
      "0:00:00.003833\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9184, 'reflen': 9680, 'guess': [9184, 8160, 7137, 6114], 'correct': [5211, 1924, 770, 262]}\n",
      "ratio: 0.9487603305784144\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-04 04:02:59,157 - INFO: eval_beam_4 SPIDEr: 0.2417\n",
      "2021-12-04 04:03:33,622 - INFO: | epoch  39 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 344.62 | loss-text 2.7310\n",
      "2021-12-04 04:04:07,608 - INFO: | epoch  39 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.85 | loss-text 2.7706\n",
      "2021-12-04 04:04:41,879 - INFO: | epoch  39 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 342.70 | loss-text 2.7776\n",
      "2021-12-04 04:05:16,086 - INFO: | epoch  39 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 342.07 | loss-text 2.8124\n",
      "2021-12-04 04:05:50,438 - INFO: | epoch  39 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 343.52 | loss-text 2.7890\n",
      "2021-12-04 04:06:24,615 - INFO: | epoch  39 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.76 | loss-text 2.7842\n",
      "2021-12-04 04:06:58,721 - INFO: | epoch  39 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 341.05 | loss-text 2.7769\n",
      "2021-12-04 04:07:33,041 - INFO: | epoch  39 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.19 | loss-text 2.7919\n",
      "2021-12-04 04:08:07,329 - INFO: | epoch  39 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.88 | loss-text 2.7777\n",
      "2021-12-04 04:08:41,626 - INFO: | epoch  39 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.96 | loss-text 2.8005\n",
      "2021-12-04 04:09:16,009 - INFO: | epoch  39 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 343.82 | loss-text 2.7792\n",
      "2021-12-04 04:09:50,215 - INFO: | epoch  39 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.06 | loss-text 2.7991\n",
      "2021-12-04 04:10:24,632 - INFO: | epoch  39 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 344.16 | loss-text 2.7926\n",
      "2021-12-04 04:10:58,810 - INFO: | epoch  39 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.78 | loss-text 2.7747\n",
      "2021-12-04 04:11:32,976 - INFO: | epoch  39 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 341.65 | loss-text 2.7815\n",
      "2021-12-04 04:12:07,036 - INFO: | epoch  39 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 340.60 | loss-text 2.7727\n",
      "2021-12-04 04:12:41,275 - INFO: | epoch  39 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 342.38 | loss-text 2.8199\n",
      "2021-12-04 04:13:15,612 - INFO: | epoch  39 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 343.36 | loss-text 2.8298\n",
      "2021-12-04 04:13:49,688 - INFO: | epoch  39 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 340.76 | loss-text 2.7988\n",
      "2021-12-04 04:14:23,769 - INFO: | epoch  39 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 340.80 | loss-text 2.7636\n",
      "2021-12-04 04:14:58,117 - INFO: | epoch  39 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 343.48 | loss-text 2.7906\n",
      "2021-12-04 04:15:32,564 - INFO: | epoch  39 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 344.47 | loss-text 2.8137\n",
      "2021-12-04 04:16:06,641 - INFO: | epoch  39 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 340.76 | loss-text 2.7788\n",
      "2021-12-04 04:16:40,868 - INFO: | epoch  39 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 342.26 | loss-text 2.8146\n",
      "2021-12-04 04:17:15,188 - INFO: | epoch  39 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.20 | loss-text 2.7955\n",
      "2021-12-04 04:17:49,597 - INFO: | epoch  39 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 344.08 | loss-text 2.8322\n",
      "2021-12-04 04:18:24,160 - INFO: | epoch  39 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 345.63 | loss-text 2.7914\n",
      "2021-12-04 04:18:58,580 - INFO: | epoch  39 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 344.19 | loss-text 2.8418\n",
      "2021-12-04 04:19:32,921 - INFO: | epoch  39 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 343.40 | loss-text 2.8013\n",
      "2021-12-04 04:20:07,052 - INFO: | epoch  39 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 341.31 | loss-text 2.8135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003896\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10307, 'reflen': 10398, 'guess': [10307, 9283, 8259, 7235], 'correct': [5533, 1925, 729, 245]}\n",
      "ratio: 0.99124831698394\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.331\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.348\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2021-12-04 04:21:01,674 - INFO: eval_greddy SPIDEr: 0.2290\n",
      "loading annotations into memory...\n",
      "0:00:00.004212\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9508, 'reflen': 9854, 'guess': [9508, 8484, 7460, 6436], 'correct': [5314, 1924, 743, 263]}\n",
      "ratio: 0.9648873553885767\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-04 04:21:38,768 - INFO: eval_beam_2 SPIDEr: 0.2404\n",
      "loading annotations into memory...\n",
      "0:00:00.003867\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9260, 'reflen': 9728, 'guess': [9260, 8236, 7212, 6188], 'correct': [5250, 1936, 762, 278]}\n",
      "ratio: 0.9518914473683232\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-04 04:22:18,108 - INFO: eval_beam_3 SPIDEr: 0.2425\n",
      "loading annotations into memory...\n",
      "0:00:00.003868\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9102, 'reflen': 9643, 'guess': [9102, 8078, 7054, 6031], 'correct': [5154, 1926, 782, 293]}\n",
      "ratio: 0.9438971274498658\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.380\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-04 04:23:00,863 - INFO: eval_beam_4 SPIDEr: 0.2439\n",
      "2021-12-04 04:23:35,002 - INFO: | epoch  40 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 341.36 | loss-text 2.7809\n",
      "2021-12-04 04:24:08,967 - INFO: | epoch  40 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.63 | loss-text 2.7388\n",
      "2021-12-04 04:24:43,293 - INFO: | epoch  40 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 343.26 | loss-text 2.7713\n",
      "2021-12-04 04:25:17,399 - INFO: | epoch  40 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.05 | loss-text 2.7926\n",
      "2021-12-04 04:25:51,775 - INFO: | epoch  40 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 343.75 | loss-text 2.7278\n",
      "2021-12-04 04:26:26,051 - INFO: | epoch  40 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.75 | loss-text 2.7682\n",
      "2021-12-04 04:27:00,423 - INFO: | epoch  40 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 343.72 | loss-text 2.7685\n",
      "2021-12-04 04:27:34,688 - INFO: | epoch  40 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 342.65 | loss-text 2.8044\n",
      "2021-12-04 04:28:08,825 - INFO: | epoch  40 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.36 | loss-text 2.7731\n",
      "2021-12-04 04:28:43,083 - INFO: | epoch  40 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.57 | loss-text 2.7949\n",
      "2021-12-04 04:29:17,341 - INFO: | epoch  40 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.57 | loss-text 2.7798\n",
      "2021-12-04 04:29:51,542 - INFO: | epoch  40 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.01 | loss-text 2.7761\n",
      "2021-12-04 04:30:25,752 - INFO: | epoch  40 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.09 | loss-text 2.7729\n",
      "2021-12-04 04:31:00,028 - INFO: | epoch  40 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.75 | loss-text 2.8108\n",
      "2021-12-04 04:31:34,365 - INFO: | epoch  40 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 343.36 | loss-text 2.7915\n",
      "2021-12-04 04:32:08,810 - INFO: | epoch  40 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 344.45 | loss-text 2.8047\n",
      "2021-12-04 04:32:43,077 - INFO: | epoch  40 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 342.66 | loss-text 2.7719\n",
      "2021-12-04 04:33:17,335 - INFO: | epoch  40 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 342.58 | loss-text 2.7767\n",
      "2021-12-04 04:33:51,695 - INFO: | epoch  40 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 343.60 | loss-text 2.7923\n",
      "2021-12-04 04:34:25,974 - INFO: | epoch  40 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.78 | loss-text 2.7867\n",
      "2021-12-04 04:35:00,124 - INFO: | epoch  40 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 341.50 | loss-text 2.8220\n",
      "2021-12-04 04:35:34,615 - INFO: | epoch  40 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 344.89 | loss-text 2.7648\n",
      "2021-12-04 04:36:08,889 - INFO: | epoch  40 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.74 | loss-text 2.7912\n",
      "2021-12-04 04:36:43,213 - INFO: | epoch  40 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.23 | loss-text 2.7636\n",
      "2021-12-04 04:37:17,541 - INFO: | epoch  40 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.28 | loss-text 2.7930\n",
      "2021-12-04 04:37:51,748 - INFO: | epoch  40 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.06 | loss-text 2.8034\n",
      "2021-12-04 04:38:25,768 - INFO: | epoch  40 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 340.19 | loss-text 2.8429\n",
      "2021-12-04 04:38:59,707 - INFO: | epoch  40 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 339.39 | loss-text 2.7829\n",
      "2021-12-04 04:39:34,263 - INFO: | epoch  40 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 345.54 | loss-text 2.7932\n",
      "2021-12-04 04:40:08,651 - INFO: | epoch  40 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 343.88 | loss-text 2.8351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003791\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10187, 'reflen': 10274, 'guess': [10187, 9163, 8139, 7115], 'correct': [5481, 1926, 730, 231]}\n",
      "ratio: 0.9915320225811766\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.333\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.344\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.226\n",
      "2021-12-04 04:41:02,448 - INFO: eval_greddy SPIDEr: 0.2265\n",
      "loading annotations into memory...\n",
      "0:00:00.003932\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9403, 'reflen': 9803, 'guess': [9403, 8379, 7355, 6331], 'correct': [5303, 1983, 794, 267]}\n",
      "ratio: 0.9591961644393594\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-04 04:41:39,647 - INFO: eval_beam_2 SPIDEr: 0.2386\n",
      "loading annotations into memory...\n",
      "0:00:00.004015\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9219, 'reflen': 9669, 'guess': [9219, 8195, 7171, 6147], 'correct': [5236, 1976, 830, 313]}\n",
      "ratio: 0.9534595097734043\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.381\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.245\n",
      "2021-12-04 04:42:19,387 - INFO: eval_beam_3 SPIDEr: 0.2454\n",
      "loading annotations into memory...\n",
      "0:00:00.003809\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8987, 'reflen': 9573, 'guess': [8987, 7963, 6939, 5915], 'correct': [5100, 1950, 825, 315]}\n",
      "ratio: 0.9387861694347708\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.379\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-04 04:43:02,401 - INFO: eval_beam_4 SPIDEr: 0.2439\n",
      "2021-12-04 04:43:36,454 - INFO: | epoch  41 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.50 | loss-text 2.6799\n",
      "2021-12-04 04:44:10,488 - INFO: | epoch  41 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.33 | loss-text 2.7853\n",
      "2021-12-04 04:44:44,777 - INFO: | epoch  41 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 342.88 | loss-text 2.7711\n",
      "2021-12-04 04:45:18,976 - INFO: | epoch  41 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.98 | loss-text 2.7577\n",
      "2021-12-04 04:45:53,272 - INFO: | epoch  41 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.95 | loss-text 2.7562\n",
      "2021-12-04 04:46:27,267 - INFO: | epoch  41 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 339.95 | loss-text 2.7528\n",
      "2021-12-04 04:47:01,664 - INFO: | epoch  41 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 343.96 | loss-text 2.7565\n",
      "2021-12-04 04:47:35,743 - INFO: | epoch  41 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 340.79 | loss-text 2.7736\n",
      "2021-12-04 04:48:10,361 - INFO: | epoch  41 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 346.17 | loss-text 2.7310\n",
      "2021-12-04 04:48:44,565 - INFO: | epoch  41 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.03 | loss-text 2.7903\n",
      "2021-12-04 04:49:18,698 - INFO: | epoch  41 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 341.32 | loss-text 2.7486\n",
      "2021-12-04 04:49:52,817 - INFO: | epoch  41 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.18 | loss-text 2.7620\n",
      "2021-12-04 04:50:27,351 - INFO: | epoch  41 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 345.33 | loss-text 2.7677\n",
      "2021-12-04 04:51:01,568 - INFO: | epoch  41 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.17 | loss-text 2.7773\n",
      "2021-12-04 04:51:35,846 - INFO: | epoch  41 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.77 | loss-text 2.7449\n",
      "2021-12-04 04:52:10,155 - INFO: | epoch  41 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 343.09 | loss-text 2.7849\n",
      "2021-12-04 04:52:44,307 - INFO: | epoch  41 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 341.51 | loss-text 2.7964\n",
      "2021-12-04 04:53:18,670 - INFO: | epoch  41 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 343.62 | loss-text 2.7903\n",
      "2021-12-04 04:53:52,892 - INFO: | epoch  41 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.21 | loss-text 2.7639\n",
      "2021-12-04 04:54:27,113 - INFO: | epoch  41 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.20 | loss-text 2.7729\n",
      "2021-12-04 04:55:01,338 - INFO: | epoch  41 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 342.25 | loss-text 2.8116\n",
      "2021-12-04 04:55:35,795 - INFO: | epoch  41 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 344.56 | loss-text 2.7955\n",
      "2021-12-04 04:56:10,060 - INFO: | epoch  41 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 342.64 | loss-text 2.7374\n",
      "2021-12-04 04:56:44,328 - INFO: | epoch  41 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 342.67 | loss-text 2.7825\n",
      "2021-12-04 04:57:18,632 - INFO: | epoch  41 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.03 | loss-text 2.8279\n",
      "2021-12-04 04:57:53,153 - INFO: | epoch  41 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 345.20 | loss-text 2.7598\n",
      "2021-12-04 04:58:27,282 - INFO: | epoch  41 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.29 | loss-text 2.7856\n",
      "2021-12-04 04:59:01,264 - INFO: | epoch  41 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 339.81 | loss-text 2.7985\n",
      "2021-12-04 04:59:35,677 - INFO: | epoch  41 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 344.12 | loss-text 2.7836\n",
      "2021-12-04 05:00:10,006 - INFO: | epoch  41 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 343.28 | loss-text 2.7992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003965\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10167, 'reflen': 10249, 'guess': [10167, 9143, 8119, 7095], 'correct': [5547, 1933, 689, 199]}\n",
      "ratio: 0.9919992194359457\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.340\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2021-12-04 05:01:04,123 - INFO: eval_greddy SPIDEr: 0.2248\n",
      "loading annotations into memory...\n",
      "0:00:00.003950\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9464, 'reflen': 9801, 'guess': [9464, 8440, 7416, 6392], 'correct': [5318, 1959, 786, 266]}\n",
      "ratio: 0.9656157534944428\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-04 05:01:41,028 - INFO: eval_beam_2 SPIDEr: 0.2406\n",
      "loading annotations into memory...\n",
      "0:00:00.003866\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9246, 'reflen': 9690, 'guess': [9246, 8222, 7198, 6174], 'correct': [5179, 1924, 777, 271]}\n",
      "ratio: 0.954179566563369\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-04 05:02:20,345 - INFO: eval_beam_3 SPIDEr: 0.2383\n",
      "loading annotations into memory...\n",
      "0:00:00.003986\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9114, 'reflen': 9612, 'guess': [9114, 8090, 7066, 6042], 'correct': [5117, 1908, 779, 272]}\n",
      "ratio: 0.9481897627964057\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-04 05:03:02,989 - INFO: eval_beam_4 SPIDEr: 0.2398\n",
      "2021-12-04 05:03:37,428 - INFO: | epoch  42 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 344.35 | loss-text 2.7335\n",
      "2021-12-04 05:04:11,415 - INFO: | epoch  42 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.86 | loss-text 2.7391\n",
      "2021-12-04 05:04:45,594 - INFO: | epoch  42 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.79 | loss-text 2.7343\n",
      "2021-12-04 05:05:19,872 - INFO: | epoch  42 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 342.77 | loss-text 2.7703\n",
      "2021-12-04 05:05:53,975 - INFO: | epoch  42 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 341.02 | loss-text 2.7460\n",
      "2021-12-04 05:06:28,012 - INFO: | epoch  42 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 340.36 | loss-text 2.7587\n",
      "2021-12-04 05:07:02,380 - INFO: | epoch  42 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 343.66 | loss-text 2.7587\n",
      "2021-12-04 05:07:36,495 - INFO: | epoch  42 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 341.15 | loss-text 2.7580\n",
      "2021-12-04 05:08:10,821 - INFO: | epoch  42 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 343.25 | loss-text 2.7326\n",
      "2021-12-04 05:08:45,060 - INFO: | epoch  42 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.38 | loss-text 2.7132\n",
      "2021-12-04 05:09:19,303 - INFO: | epoch  42 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.42 | loss-text 2.7466\n",
      "2021-12-04 05:09:53,499 - INFO: | epoch  42 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.95 | loss-text 2.7454\n",
      "2021-12-04 05:10:27,679 - INFO: | epoch  42 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 341.80 | loss-text 2.7435\n",
      "2021-12-04 05:11:01,691 - INFO: | epoch  42 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 340.11 | loss-text 2.7837\n",
      "2021-12-04 05:11:35,954 - INFO: | epoch  42 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.62 | loss-text 2.7472\n",
      "2021-12-04 05:12:10,189 - INFO: | epoch  42 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.34 | loss-text 2.7418\n",
      "2021-12-04 05:12:44,626 - INFO: | epoch  42 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 344.37 | loss-text 2.7571\n",
      "2021-12-04 05:13:19,063 - INFO: | epoch  42 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.36 | loss-text 2.7579\n",
      "2021-12-04 05:13:53,264 - INFO: | epoch  42 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.00 | loss-text 2.7545\n",
      "2021-12-04 05:14:27,466 - INFO: | epoch  42 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.01 | loss-text 2.7635\n",
      "2021-12-04 05:15:01,705 - INFO: | epoch  42 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 342.38 | loss-text 2.7367\n",
      "2021-12-04 05:15:36,086 - INFO: | epoch  42 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 343.80 | loss-text 2.7717\n",
      "2021-12-04 05:16:10,069 - INFO: | epoch  42 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 339.82 | loss-text 2.7468\n",
      "2021-12-04 05:16:44,485 - INFO: | epoch  42 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 344.16 | loss-text 2.8257\n",
      "2021-12-04 05:17:18,832 - INFO: | epoch  42 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.46 | loss-text 2.7723\n",
      "2021-12-04 05:17:52,916 - INFO: | epoch  42 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 340.84 | loss-text 2.8174\n",
      "2021-12-04 05:18:27,115 - INFO: | epoch  42 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.98 | loss-text 2.7466\n",
      "2021-12-04 05:19:01,292 - INFO: | epoch  42 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 341.76 | loss-text 2.7709\n",
      "2021-12-04 05:19:35,481 - INFO: | epoch  42 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 341.89 | loss-text 2.7763\n",
      "2021-12-04 05:20:09,771 - INFO: | epoch  42 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 342.89 | loss-text 2.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003897\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10428, 'reflen': 10456, 'guess': [10428, 9404, 8380, 7356], 'correct': [5680, 1976, 725, 213]}\n",
      "ratio: 0.997322111706102\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.353\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-04 05:21:04,490 - INFO: eval_greddy SPIDEr: 0.2333\n",
      "loading annotations into memory...\n",
      "0:00:00.003912\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9703, 'reflen': 9983, 'guess': [9703, 8679, 7655, 6631], 'correct': [5481, 1993, 763, 229]}\n",
      "ratio: 0.9719523189421043\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.141\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-04 05:21:41,916 - INFO: eval_beam_2 SPIDEr: 0.2426\n",
      "loading annotations into memory...\n",
      "0:00:00.004065\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9346, 'reflen': 9749, 'guess': [9346, 8322, 7298, 6274], 'correct': [5302, 1977, 779, 261]}\n",
      "ratio: 0.9586624269154828\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.375\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-04 05:22:21,885 - INFO: eval_beam_3 SPIDEr: 0.2434\n",
      "loading annotations into memory...\n",
      "0:00:00.003769\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9209, 'reflen': 9679, 'guess': [9209, 8185, 7161, 6137], 'correct': [5235, 1978, 786, 271]}\n",
      "ratio: 0.9514412645933514\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-04 05:23:05,600 - INFO: eval_beam_4 SPIDEr: 0.2431\n",
      "2021-12-04 05:23:39,670 - INFO: | epoch  43 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.67 | loss-text 2.7548\n",
      "2021-12-04 05:24:13,693 - INFO: | epoch  43 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.22 | loss-text 2.7142\n",
      "2021-12-04 05:24:47,835 - INFO: | epoch  43 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.40 | loss-text 2.7040\n",
      "2021-12-04 05:25:22,031 - INFO: | epoch  43 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.96 | loss-text 2.7199\n",
      "2021-12-04 05:25:56,273 - INFO: | epoch  43 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.41 | loss-text 2.7428\n",
      "2021-12-04 05:26:30,363 - INFO: | epoch  43 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 340.89 | loss-text 2.7360\n",
      "2021-12-04 05:27:04,599 - INFO: | epoch  43 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.36 | loss-text 2.6943\n",
      "2021-12-04 05:27:38,958 - INFO: | epoch  43 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.59 | loss-text 2.7120\n",
      "2021-12-04 05:28:13,147 - INFO: | epoch  43 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.88 | loss-text 2.7360\n",
      "2021-12-04 05:28:46,953 - INFO: | epoch  43 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 338.06 | loss-text 2.7310\n",
      "2021-12-04 05:29:21,182 - INFO: | epoch  43 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 342.29 | loss-text 2.7621\n",
      "2021-12-04 05:29:55,645 - INFO: | epoch  43 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 344.63 | loss-text 2.7397\n",
      "2021-12-04 05:30:29,754 - INFO: | epoch  43 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 341.08 | loss-text 2.7434\n",
      "2021-12-04 05:31:04,052 - INFO: | epoch  43 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.98 | loss-text 2.7601\n",
      "2021-12-04 05:31:38,324 - INFO: | epoch  43 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.71 | loss-text 2.7060\n",
      "2021-12-04 05:32:12,493 - INFO: | epoch  43 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 341.69 | loss-text 2.7787\n",
      "2021-12-04 05:32:46,804 - INFO: | epoch  43 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.11 | loss-text 2.7419\n",
      "2021-12-04 05:33:21,248 - INFO: | epoch  43 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.43 | loss-text 2.7568\n",
      "2021-12-04 05:33:55,300 - INFO: | epoch  43 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 340.51 | loss-text 2.7710\n",
      "2021-12-04 05:34:29,344 - INFO: | epoch  43 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 340.44 | loss-text 2.7463\n",
      "2021-12-04 05:35:03,298 - INFO: | epoch  43 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 339.53 | loss-text 2.7297\n",
      "2021-12-04 05:35:37,662 - INFO: | epoch  43 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 343.63 | loss-text 2.7996\n",
      "2021-12-04 05:36:11,984 - INFO: | epoch  43 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 343.21 | loss-text 2.7717\n",
      "2021-12-04 05:36:46,608 - INFO: | epoch  43 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 346.24 | loss-text 2.7708\n",
      "2021-12-04 05:37:20,909 - INFO: | epoch  43 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.00 | loss-text 2.7235\n",
      "2021-12-04 05:37:55,221 - INFO: | epoch  43 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 343.11 | loss-text 2.7655\n",
      "2021-12-04 05:38:29,766 - INFO: | epoch  43 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 345.45 | loss-text 2.7527\n",
      "2021-12-04 05:39:03,924 - INFO: | epoch  43 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 341.57 | loss-text 2.8021\n",
      "2021-12-04 05:39:37,900 - INFO: | epoch  43 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 339.75 | loss-text 2.7666\n",
      "2021-12-04 05:40:12,032 - INFO: | epoch  43 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 341.31 | loss-text 2.7497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003888\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10520, 'reflen': 10474, 'guess': [10520, 9496, 8472, 7448], 'correct': [5600, 1921, 698, 193]}\n",
      "ratio: 1.004391827381993\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.328\n",
      "Bleu_3: 0.207\n",
      "Bleu_4: 0.123\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.328\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.219\n",
      "2021-12-04 05:41:06,549 - INFO: eval_greddy SPIDEr: 0.2192\n",
      "loading annotations into memory...\n",
      "0:00:00.003778\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9788, 'reflen': 10007, 'guess': [9788, 8764, 7740, 6716], 'correct': [5347, 1878, 716, 241]}\n",
      "ratio: 0.9781153192764087\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.335\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.347\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2021-12-04 05:41:43,916 - INFO: eval_beam_2 SPIDEr: 0.2277\n",
      "loading annotations into memory...\n",
      "0:00:00.003761\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9459, 'reflen': 9777, 'guess': [9459, 8435, 7411, 6387], 'correct': [5206, 1863, 713, 242]}\n",
      "ratio: 0.9674746854862465\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.219\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.349\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2021-12-04 05:42:23,730 - INFO: eval_beam_3 SPIDEr: 0.2286\n",
      "loading annotations into memory...\n",
      "0:00:00.003988\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9287, 'reflen': 9683, 'guess': [9287, 8263, 7239, 6215], 'correct': [5148, 1886, 728, 247]}\n",
      "ratio: 0.9591035836000248\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.341\n",
      "Bleu_3: 0.224\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.354\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.352\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2021-12-04 05:43:09,052 - INFO: eval_beam_4 SPIDEr: 0.2300\n",
      "2021-12-04 05:43:43,345 - INFO: | epoch  44 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 342.90 | loss-text 2.7036\n",
      "2021-12-04 05:44:17,527 - INFO: | epoch  44 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 341.80 | loss-text 2.6931\n",
      "2021-12-04 05:44:51,642 - INFO: | epoch  44 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.15 | loss-text 2.7082\n",
      "2021-12-04 05:45:25,937 - INFO: | epoch  44 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 342.94 | loss-text 2.7186\n",
      "2021-12-04 05:45:59,839 - INFO: | epoch  44 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 339.02 | loss-text 2.7484\n",
      "2021-12-04 05:46:34,224 - INFO: | epoch  44 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 343.84 | loss-text 2.7521\n",
      "2021-12-04 05:47:08,230 - INFO: | epoch  44 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 340.06 | loss-text 2.7016\n",
      "2021-12-04 05:47:42,412 - INFO: | epoch  44 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 341.81 | loss-text 2.6964\n",
      "2021-12-04 05:48:16,534 - INFO: | epoch  44 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.21 | loss-text 2.7087\n",
      "2021-12-04 05:48:50,504 - INFO: | epoch  44 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 339.70 | loss-text 2.7122\n",
      "2021-12-04 05:49:24,673 - INFO: | epoch  44 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 341.68 | loss-text 2.7097\n",
      "2021-12-04 05:49:59,081 - INFO: | epoch  44 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 344.07 | loss-text 2.7607\n",
      "2021-12-04 05:50:33,570 - INFO: | epoch  44 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 344.88 | loss-text 2.7258\n",
      "2021-12-04 05:51:07,915 - INFO: | epoch  44 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 343.44 | loss-text 2.7605\n",
      "2021-12-04 05:51:42,429 - INFO: | epoch  44 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 345.13 | loss-text 2.7208\n",
      "2021-12-04 05:52:16,848 - INFO: | epoch  44 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 344.18 | loss-text 2.7629\n",
      "2021-12-04 05:52:51,386 - INFO: | epoch  44 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 345.38 | loss-text 2.7332\n",
      "2021-12-04 05:53:25,710 - INFO: | epoch  44 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 343.23 | loss-text 2.7435\n",
      "2021-12-04 05:54:00,174 - INFO: | epoch  44 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 344.64 | loss-text 2.7268\n",
      "2021-12-04 05:54:34,483 - INFO: | epoch  44 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 343.09 | loss-text 2.7295\n",
      "2021-12-04 05:55:08,863 - INFO: | epoch  44 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 343.79 | loss-text 2.7922\n",
      "2021-12-04 05:55:43,164 - INFO: | epoch  44 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 343.00 | loss-text 2.7414\n",
      "2021-12-04 05:56:17,468 - INFO: | epoch  44 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 343.04 | loss-text 2.7658\n",
      "2021-12-04 05:56:51,815 - INFO: | epoch  44 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.46 | loss-text 2.8092\n",
      "2021-12-04 05:57:26,131 - INFO: | epoch  44 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.15 | loss-text 2.7502\n",
      "2021-12-04 05:58:00,269 - INFO: | epoch  44 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 341.38 | loss-text 2.7559\n",
      "2021-12-04 05:58:34,746 - INFO: | epoch  44 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 344.77 | loss-text 2.7417\n",
      "2021-12-04 05:59:09,119 - INFO: | epoch  44 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.72 | loss-text 2.7596\n",
      "2021-12-04 05:59:43,269 - INFO: | epoch  44 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 341.49 | loss-text 2.7761\n",
      "2021-12-04 06:00:17,145 - INFO: | epoch  44 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 338.76 | loss-text 2.7550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004416\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10473, 'reflen': 10421, 'guess': [10473, 9449, 8425, 7401], 'correct': [5677, 2003, 719, 204]}\n",
      "ratio: 1.0049899241914397\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.344\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2021-12-04 06:01:10,809 - INFO: eval_greddy SPIDEr: 0.2279\n",
      "loading annotations into memory...\n",
      "0:00:00.003965\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9638, 'reflen': 9907, 'guess': [9638, 8614, 7590, 6566], 'correct': [5464, 2027, 779, 258]}\n",
      "ratio: 0.9728474815785835\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.355\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.385\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.249\n",
      "2021-12-04 06:01:48,687 - INFO: eval_beam_2 SPIDEr: 0.2489\n",
      "loading annotations into memory...\n",
      "0:00:00.003860\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9413, 'reflen': 9757, 'guess': [9413, 8389, 7365, 6341], 'correct': [5379, 2020, 798, 277]}\n",
      "ratio: 0.9647432612482356\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.389\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.251\n",
      "2021-12-04 06:02:27,974 - INFO: eval_beam_3 SPIDEr: 0.2515\n",
      "loading annotations into memory...\n",
      "0:00:00.003867\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9251, 'reflen': 9673, 'guess': [9251, 8227, 7203, 6179], 'correct': [5321, 2024, 800, 282]}\n",
      "ratio: 0.9563734105240405\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.359\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.392\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.253\n",
      "2021-12-04 06:03:11,143 - INFO: eval_beam_4 SPIDEr: 0.2530\n",
      "2021-12-04 06:03:45,419 - INFO: | epoch  45 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 342.73 | loss-text 2.6785\n",
      "2021-12-04 06:04:19,660 - INFO: | epoch  45 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 342.40 | loss-text 2.7073\n",
      "2021-12-04 06:04:53,802 - INFO: | epoch  45 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.41 | loss-text 2.7082\n",
      "2021-12-04 06:05:28,152 - INFO: | epoch  45 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 343.49 | loss-text 2.7134\n",
      "2021-12-04 06:06:02,354 - INFO: | epoch  45 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.01 | loss-text 2.7234\n",
      "2021-12-04 06:06:36,744 - INFO: | epoch  45 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 343.89 | loss-text 2.7472\n",
      "2021-12-04 06:07:11,097 - INFO: | epoch  45 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 343.53 | loss-text 2.7155\n",
      "2021-12-04 06:07:45,330 - INFO: | epoch  45 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 342.32 | loss-text 2.7301\n",
      "2021-12-04 06:08:19,708 - INFO: | epoch  45 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 343.77 | loss-text 2.6648\n",
      "2021-12-04 06:08:54,169 - INFO: | epoch  45 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 344.61 | loss-text 2.7018\n",
      "2021-12-04 06:09:28,306 - INFO: | epoch  45 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 341.36 | loss-text 2.7087\n",
      "2021-12-04 06:10:02,601 - INFO: | epoch  45 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.95 | loss-text 2.7364\n",
      "2021-12-04 06:10:36,973 - INFO: | epoch  45 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 343.71 | loss-text 2.7572\n",
      "2021-12-04 06:11:11,237 - INFO: | epoch  45 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.63 | loss-text 2.7282\n",
      "2021-12-04 06:11:45,431 - INFO: | epoch  45 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 341.94 | loss-text 2.7053\n",
      "2021-12-04 06:12:19,451 - INFO: | epoch  45 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 340.19 | loss-text 2.7135\n",
      "2021-12-04 06:12:53,873 - INFO: | epoch  45 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 344.21 | loss-text 2.7435\n",
      "2021-12-04 06:13:27,803 - INFO: | epoch  45 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 339.30 | loss-text 2.7231\n",
      "2021-12-04 06:14:02,073 - INFO: | epoch  45 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.69 | loss-text 2.7188\n",
      "2021-12-04 06:14:36,175 - INFO: | epoch  45 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 341.01 | loss-text 2.7257\n",
      "2021-12-04 06:15:10,327 - INFO: | epoch  45 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 341.51 | loss-text 2.7289\n",
      "2021-12-04 06:15:44,573 - INFO: | epoch  45 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 342.45 | loss-text 2.7505\n",
      "2021-12-04 06:16:18,703 - INFO: | epoch  45 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 341.29 | loss-text 2.7483\n",
      "2021-12-04 06:16:52,842 - INFO: | epoch  45 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 341.38 | loss-text 2.7606\n",
      "2021-12-04 06:17:26,961 - INFO: | epoch  45 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 341.18 | loss-text 2.7387\n",
      "2021-12-04 06:18:00,967 - INFO: | epoch  45 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 340.05 | loss-text 2.7435\n",
      "2021-12-04 06:18:35,153 - INFO: | epoch  45 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.85 | loss-text 2.7173\n",
      "2021-12-04 06:19:09,556 - INFO: | epoch  45 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 344.02 | loss-text 2.7789\n",
      "2021-12-04 06:19:43,837 - INFO: | epoch  45 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.80 | loss-text 2.7575\n",
      "2021-12-04 06:20:18,353 - INFO: | epoch  45 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 345.16 | loss-text 2.7480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003838\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10378, 'reflen': 10441, 'guess': [10378, 9354, 8330, 7306], 'correct': [5580, 1965, 724, 204]}\n",
      "ratio: 0.9939660952015138\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.334\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.344\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2021-12-04 06:21:12,363 - INFO: eval_greddy SPIDEr: 0.2270\n",
      "loading annotations into memory...\n",
      "0:00:00.004229\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9694, 'reflen': 9978, 'guess': [9694, 8670, 7646, 6622], 'correct': [5410, 1988, 791, 259]}\n",
      "ratio: 0.9715373822408326\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.380\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-04 06:21:49,689 - INFO: eval_beam_2 SPIDEr: 0.2458\n",
      "loading annotations into memory...\n",
      "0:00:00.003856\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9351, 'reflen': 9757, 'guess': [9351, 8327, 7303, 6279], 'correct': [5225, 1913, 747, 254]}\n",
      "ratio: 0.9583888490313663\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-04 06:22:28,858 - INFO: eval_beam_3 SPIDEr: 0.2385\n",
      "loading annotations into memory...\n",
      "0:00:00.004039\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9201, 'reflen': 9678, 'guess': [9201, 8177, 7153, 6129], 'correct': [5120, 1892, 752, 264]}\n",
      "ratio: 0.9507129572224684\n",
      "Bleu_1: 0.528\n",
      "Bleu_2: 0.341\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-04 06:23:12,342 - INFO: eval_beam_4 SPIDEr: 0.2379\n",
      "2021-12-04 06:23:46,467 - INFO: | epoch  46 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 341.21 | loss-text 2.6697\n",
      "2021-12-04 06:24:20,793 - INFO: | epoch  46 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 343.25 | loss-text 2.7380\n",
      "2021-12-04 06:24:55,184 - INFO: | epoch  46 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 343.91 | loss-text 2.6891\n",
      "2021-12-04 06:25:29,127 - INFO: | epoch  46 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 339.41 | loss-text 2.6830\n",
      "2021-12-04 06:26:03,555 - INFO: | epoch  46 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 344.28 | loss-text 2.7029\n",
      "2021-12-04 06:26:37,693 - INFO: | epoch  46 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.37 | loss-text 2.6871\n",
      "2021-12-04 06:27:11,976 - INFO: | epoch  46 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.82 | loss-text 2.7014\n",
      "2021-12-04 06:27:46,063 - INFO: | epoch  46 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 340.86 | loss-text 2.7138\n",
      "2021-12-04 06:28:20,351 - INFO: | epoch  46 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 342.87 | loss-text 2.7023\n",
      "2021-12-04 06:28:54,567 - INFO: | epoch  46 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 342.16 | loss-text 2.7205\n",
      "2021-12-04 06:29:28,869 - INFO: | epoch  46 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 343.01 | loss-text 2.7091\n",
      "2021-12-04 06:30:03,045 - INFO: | epoch  46 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.76 | loss-text 2.7324\n",
      "2021-12-04 06:30:37,109 - INFO: | epoch  46 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 340.63 | loss-text 2.7151\n",
      "2021-12-04 06:31:11,472 - INFO: | epoch  46 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 343.62 | loss-text 2.7174\n",
      "2021-12-04 06:31:45,591 - INFO: | epoch  46 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 341.18 | loss-text 2.7143\n",
      "2021-12-04 06:32:20,006 - INFO: | epoch  46 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 344.14 | loss-text 2.7406\n",
      "2021-12-04 06:32:54,513 - INFO: | epoch  46 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 345.06 | loss-text 2.7017\n",
      "2021-12-04 06:33:28,519 - INFO: | epoch  46 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 340.06 | loss-text 2.7218\n",
      "2021-12-04 06:34:02,775 - INFO: | epoch  46 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.55 | loss-text 2.7264\n",
      "2021-12-04 06:34:36,880 - INFO: | epoch  46 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 341.05 | loss-text 2.7305\n",
      "2021-12-04 06:35:11,286 - INFO: | epoch  46 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 344.05 | loss-text 2.6866\n",
      "2021-12-04 06:35:45,356 - INFO: | epoch  46 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 340.69 | loss-text 2.7538\n",
      "2021-12-04 06:36:19,512 - INFO: | epoch  46 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 341.56 | loss-text 2.7153\n",
      "2021-12-04 06:36:54,126 - INFO: | epoch  46 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 346.13 | loss-text 2.7111\n",
      "2021-12-04 06:37:28,411 - INFO: | epoch  46 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 342.84 | loss-text 2.7222\n",
      "2021-12-04 06:38:02,612 - INFO: | epoch  46 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.00 | loss-text 2.7013\n",
      "2021-12-04 06:38:36,973 - INFO: | epoch  46 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 343.61 | loss-text 2.6934\n",
      "2021-12-04 06:39:11,340 - INFO: | epoch  46 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 343.66 | loss-text 2.7450\n",
      "2021-12-04 06:39:45,650 - INFO: | epoch  46 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 343.09 | loss-text 2.7118\n",
      "2021-12-04 06:40:19,787 - INFO: | epoch  46 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 341.35 | loss-text 2.7515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003766\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10361, 'reflen': 10388, 'guess': [10361, 9337, 8313, 7289], 'correct': [5574, 1921, 698, 213]}\n",
      "ratio: 0.9974008471312092\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.349\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2021-12-04 06:41:13,699 - INFO: eval_greddy SPIDEr: 0.2296\n",
      "loading annotations into memory...\n",
      "0:00:00.003939\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9557, 'reflen': 9832, 'guess': [9557, 8533, 7509, 6485], 'correct': [5280, 1857, 688, 231]}\n",
      "ratio: 0.9720301057769556\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.358\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-04 06:41:51,168 - INFO: eval_beam_2 SPIDEr: 0.2343\n",
      "loading annotations into memory...\n",
      "0:00:00.003852\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9319, 'reflen': 9706, 'guess': [9319, 8295, 7271, 6247], 'correct': [5197, 1880, 719, 257]}\n",
      "ratio: 0.9601277560271007\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.341\n",
      "Bleu_3: 0.223\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.351\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-04 06:42:29,973 - INFO: eval_beam_3 SPIDEr: 0.2370\n",
      "loading annotations into memory...\n",
      "0:00:00.003860\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9189, 'reflen': 9639, 'guess': [9189, 8165, 7141, 6117], 'correct': [5119, 1886, 742, 273]}\n",
      "ratio: 0.9533146591969132\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.342\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-04 06:43:13,840 - INFO: eval_beam_4 SPIDEr: 0.2412\n",
      "2021-12-04 06:43:47,876 - INFO: | epoch  47 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.32 | loss-text 2.6630\n",
      "2021-12-04 06:44:21,974 - INFO: | epoch  47 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 340.97 | loss-text 2.7082\n",
      "2021-12-04 06:44:56,088 - INFO: | epoch  47 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.13 | loss-text 2.7130\n",
      "2021-12-04 06:45:29,926 - INFO: | epoch  47 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 338.37 | loss-text 2.6823\n",
      "2021-12-04 06:46:03,959 - INFO: | epoch  47 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 340.33 | loss-text 2.6939\n",
      "2021-12-04 06:46:38,078 - INFO: | epoch  47 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 341.18 | loss-text 2.6665\n",
      "2021-12-04 06:47:12,341 - INFO: | epoch  47 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.62 | loss-text 2.6617\n",
      "2021-12-04 06:47:46,519 - INFO: | epoch  47 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 341.77 | loss-text 2.6562\n",
      "2021-12-04 06:48:20,668 - INFO: | epoch  47 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.48 | loss-text 2.7128\n",
      "2021-12-04 06:48:54,640 - INFO: | epoch  47 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 339.72 | loss-text 2.6974\n",
      "2021-12-04 06:49:28,994 - INFO: | epoch  47 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 343.52 | loss-text 2.6628\n",
      "2021-12-04 06:50:03,528 - INFO: | epoch  47 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 345.33 | loss-text 2.6926\n",
      "2021-12-04 06:50:37,961 - INFO: | epoch  47 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 344.32 | loss-text 2.7047\n",
      "2021-12-04 06:51:12,119 - INFO: | epoch  47 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 341.57 | loss-text 2.7014\n",
      "2021-12-04 06:51:46,330 - INFO: | epoch  47 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.11 | loss-text 2.6693\n",
      "2021-12-04 06:52:20,555 - INFO: | epoch  47 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.25 | loss-text 2.7331\n",
      "2021-12-04 06:52:54,928 - INFO: | epoch  47 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.72 | loss-text 2.7199\n",
      "2021-12-04 06:53:29,408 - INFO: | epoch  47 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.79 | loss-text 2.7066\n",
      "2021-12-04 06:54:03,495 - INFO: | epoch  47 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 340.86 | loss-text 2.7048\n",
      "2021-12-04 06:54:37,721 - INFO: | epoch  47 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.26 | loss-text 2.7532\n",
      "2021-12-04 06:55:12,322 - INFO: | epoch  47 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 346.00 | loss-text 2.6807\n",
      "2021-12-04 06:55:46,518 - INFO: | epoch  47 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 341.95 | loss-text 2.7358\n",
      "2021-12-04 06:56:20,959 - INFO: | epoch  47 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 344.41 | loss-text 2.7251\n",
      "2021-12-04 06:56:55,389 - INFO: | epoch  47 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 344.29 | loss-text 2.6993\n",
      "2021-12-04 06:57:29,720 - INFO: | epoch  47 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.30 | loss-text 2.7260\n",
      "2021-12-04 06:58:03,971 - INFO: | epoch  47 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.50 | loss-text 2.7258\n",
      "2021-12-04 06:58:38,406 - INFO: | epoch  47 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 344.34 | loss-text 2.7173\n",
      "2021-12-04 06:59:12,629 - INFO: | epoch  47 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.22 | loss-text 2.6923\n",
      "2021-12-04 06:59:47,138 - INFO: | epoch  47 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 345.09 | loss-text 2.7159\n",
      "2021-12-04 07:00:21,336 - INFO: | epoch  47 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 341.97 | loss-text 2.7218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003932\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10458, 'reflen': 10484, 'guess': [10458, 9434, 8410, 7386], 'correct': [5585, 1929, 698, 205]}\n",
      "ratio: 0.9975200305226061\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.208\n",
      "Bleu_4: 0.126\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.344\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2021-12-04 07:01:16,897 - INFO: eval_greddy SPIDEr: 0.2282\n",
      "loading annotations into memory...\n",
      "0:00:00.003680\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9731, 'reflen': 9971, 'guess': [9731, 8707, 7683, 6659], 'correct': [5332, 1920, 727, 237]}\n",
      "ratio: 0.9759301975728637\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.375\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.245\n",
      "2021-12-04 07:01:55,060 - INFO: eval_beam_2 SPIDEr: 0.2445\n",
      "loading annotations into memory...\n",
      "0:00:00.003920\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9418, 'reflen': 9770, 'guess': [9418, 8394, 7370, 6346], 'correct': [5211, 1914, 736, 249]}\n",
      "ratio: 0.9639713408392053\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.342\n",
      "Bleu_3: 0.224\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-04 07:02:34,707 - INFO: eval_beam_3 SPIDEr: 0.2417\n",
      "loading annotations into memory...\n",
      "0:00:00.004179\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9281, 'reflen': 9690, 'guess': [9281, 8257, 7233, 6209], 'correct': [5153, 1904, 737, 249]}\n",
      "ratio: 0.9577915376675997\n",
      "Bleu_1: 0.531\n",
      "Bleu_2: 0.342\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.353\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-04 07:03:18,648 - INFO: eval_beam_4 SPIDEr: 0.2412\n",
      "2021-12-04 07:03:52,659 - INFO: | epoch  48 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 340.06 | loss-text 2.6509\n",
      "2021-12-04 07:04:26,657 - INFO: | epoch  48 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.98 | loss-text 2.6527\n",
      "2021-12-04 07:05:00,790 - INFO: | epoch  48 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 341.31 | loss-text 2.6875\n",
      "2021-12-04 07:05:34,933 - INFO: | epoch  48 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.43 | loss-text 2.6785\n",
      "2021-12-04 07:06:09,183 - INFO: | epoch  48 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 342.49 | loss-text 2.7018\n",
      "2021-12-04 07:06:43,549 - INFO: | epoch  48 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 343.66 | loss-text 2.6899\n",
      "2021-12-04 07:07:17,942 - INFO: | epoch  48 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 343.92 | loss-text 2.7091\n",
      "2021-12-04 07:07:52,298 - INFO: | epoch  48 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.56 | loss-text 2.6876\n",
      "2021-12-04 07:08:26,474 - INFO: | epoch  48 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.75 | loss-text 2.6758\n",
      "2021-12-04 07:09:00,670 - INFO: | epoch  48 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 341.95 | loss-text 2.6707\n",
      "2021-12-04 07:09:34,973 - INFO: | epoch  48 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 343.03 | loss-text 2.6793\n",
      "2021-12-04 07:10:09,129 - INFO: | epoch  48 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 341.55 | loss-text 2.6995\n",
      "2021-12-04 07:10:43,305 - INFO: | epoch  48 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 341.76 | loss-text 2.6868\n",
      "2021-12-04 07:11:17,559 - INFO: | epoch  48 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.53 | loss-text 2.6613\n",
      "2021-12-04 07:11:52,092 - INFO: | epoch  48 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 345.33 | loss-text 2.6928\n",
      "2021-12-04 07:12:26,360 - INFO: | epoch  48 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 342.67 | loss-text 2.6968\n",
      "2021-12-04 07:13:00,413 - INFO: | epoch  48 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 340.52 | loss-text 2.7035\n",
      "2021-12-04 07:13:34,780 - INFO: | epoch  48 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 343.67 | loss-text 2.7102\n",
      "2021-12-04 07:14:09,048 - INFO: | epoch  48 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 342.67 | loss-text 2.7126\n",
      "2021-12-04 07:14:43,227 - INFO: | epoch  48 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 341.79 | loss-text 2.7116\n",
      "2021-12-04 07:15:17,739 - INFO: | epoch  48 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 345.12 | loss-text 2.7006\n",
      "2021-12-04 07:15:52,142 - INFO: | epoch  48 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 344.02 | loss-text 2.7108\n",
      "2021-12-04 07:16:26,516 - INFO: | epoch  48 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 343.73 | loss-text 2.6945\n",
      "2021-12-04 07:17:00,865 - INFO: | epoch  48 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 343.49 | loss-text 2.7343\n",
      "2021-12-04 07:17:35,124 - INFO: | epoch  48 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 342.58 | loss-text 2.7135\n",
      "2021-12-04 07:18:09,576 - INFO: | epoch  48 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 344.51 | loss-text 2.7276\n",
      "2021-12-04 07:18:43,905 - INFO: | epoch  48 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 343.29 | loss-text 2.7239\n",
      "2021-12-04 07:19:18,095 - INFO: | epoch  48 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 341.90 | loss-text 2.6954\n",
      "2021-12-04 07:19:52,420 - INFO: | epoch  48 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 343.24 | loss-text 2.7066\n",
      "2021-12-04 07:20:26,846 - INFO: | epoch  48 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 344.25 | loss-text 2.7524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004070\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10604, 'reflen': 10567, 'guess': [10604, 9580, 8556, 7532], 'correct': [5568, 1909, 682, 195]}\n",
      "ratio: 1.0035014668306044\n",
      "Bleu_1: 0.525\n",
      "Bleu_2: 0.323\n",
      "Bleu_3: 0.203\n",
      "Bleu_4: 0.121\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.330\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.218\n",
      "2021-12-04 07:21:20,502 - INFO: eval_greddy SPIDEr: 0.2181\n",
      "loading annotations into memory...\n",
      "0:00:00.003988\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9820, 'reflen': 10068, 'guess': [9820, 8796, 7772, 6748], 'correct': [5364, 1930, 747, 246]}\n",
      "ratio: 0.9753675009931491\n",
      "Bleu_1: 0.533\n",
      "Bleu_2: 0.338\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-04 07:21:58,053 - INFO: eval_beam_2 SPIDEr: 0.2341\n",
      "loading annotations into memory...\n",
      "0:00:00.003735\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9493, 'reflen': 9834, 'guess': [9493, 8469, 7445, 6421], 'correct': [5216, 1900, 747, 261]}\n",
      "ratio: 0.9653243847873738\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.223\n",
      "Bleu_4: 0.144\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.352\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-04 07:22:38,321 - INFO: eval_beam_3 SPIDEr: 0.2382\n",
      "loading annotations into memory...\n",
      "0:00:00.003842\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9373, 'reflen': 9765, 'guess': [9373, 8349, 7325, 6301], 'correct': [5140, 1877, 753, 275]}\n",
      "ratio: 0.9598566308242744\n",
      "Bleu_1: 0.526\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.224\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.350\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-04 07:23:21,911 - INFO: eval_beam_4 SPIDEr: 0.2369\n",
      "2021-12-04 07:23:56,135 - INFO: | epoch  49 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 342.20 | loss-text 2.7053\n",
      "2021-12-04 07:24:30,246 - INFO: | epoch  49 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 341.09 | loss-text 2.6595\n",
      "2021-12-04 07:25:04,229 - INFO: | epoch  49 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 339.82 | loss-text 2.6750\n",
      "2021-12-04 07:25:38,593 - INFO: | epoch  49 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 343.64 | loss-text 2.6424\n",
      "2021-12-04 07:26:12,531 - INFO: | epoch  49 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 339.37 | loss-text 2.6564\n",
      "2021-12-04 07:26:46,743 - INFO: | epoch  49 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 342.12 | loss-text 2.7074\n",
      "2021-12-04 07:27:21,044 - INFO: | epoch  49 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 343.01 | loss-text 2.6761\n",
      "2021-12-04 07:27:55,381 - INFO: | epoch  49 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 343.36 | loss-text 2.7054\n",
      "2021-12-04 07:28:29,834 - INFO: | epoch  49 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 344.52 | loss-text 2.6796\n",
      "2021-12-04 07:29:04,190 - INFO: | epoch  49 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 343.55 | loss-text 2.6924\n",
      "2021-12-04 07:29:38,818 - INFO: | epoch  49 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 346.28 | loss-text 2.6609\n",
      "2021-12-04 07:30:12,801 - INFO: | epoch  49 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 339.82 | loss-text 2.7053\n",
      "2021-12-04 07:30:47,064 - INFO: | epoch  49 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.62 | loss-text 2.6617\n",
      "2021-12-04 07:31:21,293 - INFO: | epoch  49 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 342.29 | loss-text 2.6825\n",
      "2021-12-04 07:31:55,551 - INFO: | epoch  49 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 342.58 | loss-text 2.6899\n",
      "2021-12-04 07:32:29,515 - INFO: | epoch  49 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 339.63 | loss-text 2.6743\n",
      "2021-12-04 07:33:03,881 - INFO: | epoch  49 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 343.65 | loss-text 2.6735\n",
      "2021-12-04 07:33:38,483 - INFO: | epoch  49 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 346.01 | loss-text 2.6977\n",
      "2021-12-04 07:34:12,680 - INFO: | epoch  49 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 341.96 | loss-text 2.6672\n",
      "2021-12-04 07:34:46,889 - INFO: | epoch  49 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.09 | loss-text 2.7197\n",
      "2021-12-04 07:35:21,409 - INFO: | epoch  49 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 345.19 | loss-text 2.6877\n",
      "2021-12-04 07:35:55,976 - INFO: | epoch  49 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 345.67 | loss-text 2.6451\n",
      "2021-12-04 07:36:30,089 - INFO: | epoch  49 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 341.12 | loss-text 2.7201\n",
      "2021-12-04 07:37:04,517 - INFO: | epoch  49 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 344.28 | loss-text 2.6766\n",
      "2021-12-04 07:37:38,429 - INFO: | epoch  49 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 339.11 | loss-text 2.7077\n",
      "2021-12-04 07:38:12,546 - INFO: | epoch  49 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 341.16 | loss-text 2.6620\n",
      "2021-12-04 07:38:46,698 - INFO: | epoch  49 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 341.52 | loss-text 2.6859\n",
      "2021-12-04 07:39:20,944 - INFO: | epoch  49 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 342.45 | loss-text 2.6907\n",
      "2021-12-04 07:39:55,146 - INFO: | epoch  49 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 342.01 | loss-text 2.6729\n",
      "2021-12-04 07:40:29,458 - INFO: | epoch  49 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 343.11 | loss-text 2.7112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003800\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10199, 'reflen': 10298, 'guess': [10199, 9175, 8151, 7127], 'correct': [5430, 1796, 617, 157]}\n",
      "ratio: 0.9903864828121003\n",
      "Bleu_1: 0.527\n",
      "Bleu_2: 0.320\n",
      "Bleu_3: 0.197\n",
      "Bleu_4: 0.114\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.351\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.327\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2021-12-04 07:41:23,819 - INFO: eval_greddy SPIDEr: 0.2174\n",
      "loading annotations into memory...\n",
      "0:00:00.003973\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9447, 'reflen': 9809, 'guess': [9447, 8423, 7399, 6375], 'correct': [5219, 1831, 682, 206]}\n",
      "ratio: 0.9630951167294358\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.334\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.353\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.357\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-04 07:42:01,351 - INFO: eval_beam_2 SPIDEr: 0.2322\n",
      "loading annotations into memory...\n",
      "0:00:00.003867\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9206, 'reflen': 9664, 'guess': [9206, 8182, 7158, 6134], 'correct': [5098, 1812, 688, 216]}\n",
      "ratio: 0.9526076158939412\n",
      "Bleu_1: 0.527\n",
      "Bleu_2: 0.333\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.351\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.359\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-04 07:42:41,209 - INFO: eval_beam_3 SPIDEr: 0.2330\n",
      "loading annotations into memory...\n",
      "0:00:00.003926\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9087, 'reflen': 9594, 'guess': [9087, 8063, 7039, 6015], 'correct': [5030, 1771, 671, 217]}\n",
      "ratio: 0.9471544715446166\n",
      "Bleu_1: 0.523\n",
      "Bleu_2: 0.330\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-04 07:43:24,348 - INFO: eval_beam_4 SPIDEr: 0.2337\n",
      "2021-12-04 07:43:57,960 - INFO: | epoch  50 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 336.08 | loss-text 2.6370\n",
      "2021-12-04 07:44:31,860 - INFO: | epoch  50 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 339.00 | loss-text 2.6690\n",
      "2021-12-04 07:45:06,102 - INFO: | epoch  50 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 342.41 | loss-text 2.6424\n",
      "2021-12-04 07:45:40,286 - INFO: | epoch  50 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 341.84 | loss-text 2.6688\n",
      "2021-12-04 07:46:14,329 - INFO: | epoch  50 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 340.42 | loss-text 2.6572\n",
      "2021-12-04 07:46:48,632 - INFO: | epoch  50 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 343.02 | loss-text 2.6582\n",
      "2021-12-04 07:47:22,918 - INFO: | epoch  50 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 342.85 | loss-text 2.6543\n",
      "2021-12-04 07:47:57,465 - INFO: | epoch  50 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 345.47 | loss-text 2.6690\n",
      "2021-12-04 07:48:31,622 - INFO: | epoch  50 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 341.56 | loss-text 2.6591\n",
      "2021-12-04 07:49:05,945 - INFO: | epoch  50 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 343.22 | loss-text 2.6657\n",
      "2021-12-04 07:49:40,261 - INFO: | epoch  50 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 343.15 | loss-text 2.6381\n",
      "2021-12-04 07:50:14,502 - INFO: | epoch  50 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 342.41 | loss-text 2.6728\n",
      "2021-12-04 07:50:48,749 - INFO: | epoch  50 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 342.46 | loss-text 2.6695\n",
      "2021-12-04 07:51:23,244 - INFO: | epoch  50 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 344.94 | loss-text 2.6186\n",
      "2021-12-04 07:51:57,352 - INFO: | epoch  50 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 341.07 | loss-text 2.7011\n",
      "2021-12-04 07:52:31,318 - INFO: | epoch  50 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 339.66 | loss-text 2.7111\n",
      "2021-12-04 07:53:05,516 - INFO: | epoch  50 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 341.97 | loss-text 2.6456\n",
      "2021-12-04 07:53:39,956 - INFO: | epoch  50 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 344.39 | loss-text 2.6638\n",
      "2021-12-04 07:54:14,382 - INFO: | epoch  50 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 344.25 | loss-text 2.6837\n",
      "2021-12-04 07:54:48,639 - INFO: | epoch  50 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 342.56 | loss-text 2.6837\n",
      "2021-12-04 07:55:22,776 - INFO: | epoch  50 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 341.37 | loss-text 2.6587\n",
      "2021-12-04 07:55:57,280 - INFO: | epoch  50 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 345.04 | loss-text 2.7326\n",
      "2021-12-04 07:56:31,959 - INFO: | epoch  50 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 346.78 | loss-text 2.6839\n",
      "2021-12-04 07:57:06,150 - INFO: | epoch  50 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 341.91 | loss-text 2.7017\n",
      "2021-12-04 07:57:40,499 - INFO: | epoch  50 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 343.49 | loss-text 2.6529\n",
      "2021-12-04 07:58:14,706 - INFO: | epoch  50 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 342.06 | loss-text 2.6874\n",
      "2021-12-04 07:58:48,923 - INFO: | epoch  50 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 342.17 | loss-text 2.7063\n",
      "2021-12-04 07:59:23,658 - INFO: | epoch  50 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 347.34 | loss-text 2.7375\n",
      "2021-12-04 07:59:57,715 - INFO: | epoch  50 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 340.56 | loss-text 2.6585\n",
      "2021-12-04 08:00:31,910 - INFO: | epoch  50 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 341.95 | loss-text 2.6790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003959\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10298, 'reflen': 10363, 'guess': [10298, 9274, 8250, 7226], 'correct': [5575, 1922, 713, 235]}\n",
      "ratio: 0.9937276850331955\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.333\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.355\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-04 08:01:25,650 - INFO: eval_greddy SPIDEr: 0.2337\n",
      "loading annotations into memory...\n",
      "0:00:00.003650\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9574, 'reflen': 9835, 'guess': [9574, 8550, 7526, 6502], 'correct': [5343, 1919, 712, 231]}\n",
      "ratio: 0.9734621250634495\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-04 08:02:02,573 - INFO: eval_beam_2 SPIDEr: 0.2414\n",
      "loading annotations into memory...\n",
      "0:00:00.003976\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9242, 'reflen': 9652, 'guess': [9242, 8218, 7194, 6170], 'correct': [5209, 1904, 724, 250]}\n",
      "ratio: 0.9575217571486782\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.377\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-04 08:02:42,159 - INFO: eval_beam_3 SPIDEr: 0.2440\n",
      "loading annotations into memory...\n",
      "0:00:00.003884\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9124, 'reflen': 9582, 'guess': [9124, 8100, 7076, 6052], 'correct': [5189, 1933, 738, 265]}\n",
      "ratio: 0.9522020455018835\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.381\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.247\n",
      "2021-12-04 08:03:25,395 - INFO: eval_beam_4 SPIDEr: 0.2466\n"
     ]
    }
   ],
   "source": [
    "#일부 레이어 1131\n",
    "epoch = 1\n",
    "if hp.mode == 'train':\n",
    "    while epoch < hp.training_epochs + 1:\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        torch.save(model.state_dict(), '{log_dir}/{num_epoch}.pt'.format(log_dir=log_dir, num_epoch=epoch))\n",
    "        scheduler.step(epoch)\n",
    "        eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=2)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=3)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=4)\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5950aaf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-cb09f8526cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{log_dir}/{num_epoch}.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-60bd68f9806e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "#mixup\n",
    "epoch = 1\n",
    "if hp.mode == 'train':\n",
    "    while epoch < hp.training_epochs + 1:\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        torch.save(model.state_dict(), '{log_dir}/{num_epoch}.pt'.format(log_dir=log_dir, num_epoch=epoch))\n",
    "        scheduler.step(epoch)\n",
    "        eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=2)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=3)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=4)\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b593960e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-85fdcc81b46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for src, tgt, tgt_len in training_data:\n",
    "    src = src.to(device)\n",
    "    tgt = tgt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3df15dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.training_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6fa65a",
   "metadata": {},
   "source": [
    "epoch=37 eval_beam_3 SPIDEr: 0.2344 # 2개 layer 만 trainable -06/9  \n",
    " SPIDEr: # 5개 layer 만 trainable -06/10 0.2252\n",
    "별 차이 없음 ;;;;;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19ee5c",
   "metadata": {},
   "source": [
    "model score check (eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3852d268",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/base/48.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2f0e4443ea7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#if hp.mode == 'eval':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Evaluation model score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/base/48.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_beam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/base/48.pt'"
     ]
    }
   ],
   "source": [
    "#if hp.mode == 'eval':\n",
    "# Evaluation model score\n",
    "model.load_state_dict(torch.load(\"./models/base/48.pt\"))\n",
    "eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=2)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=3)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1735c2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./models/base/49.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixup(object):\n",
    "    def __init__(self, mixup_alpha, random_seed=1234):\n",
    "        \"\"\"Mixup coefficient generator.\n",
    "        \"\"\"\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    def get_lambda(self, batch_size):\n",
    "        \"\"\"Get mixup random coefficients.\n",
    "        Args:\n",
    "          batch_size: int\n",
    "        Returns:\n",
    "          mixup_lambdas: (batch_size,)\n",
    "        \"\"\"\n",
    "        mixup_lambdas = []\n",
    "        for n in range(0, batch_size, 2):\n",
    "            lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "            mixup_lambdas.append(lam)\n",
    "            mixup_lambdas.append(1. - lam)\n",
    "\n",
    "        return np.array(mixup_lambdas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fecb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd36458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mixup(x, mixup_lambda):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes \n",
    "    (1, 3, 5, ...).\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0 :: 2].transpose(0, -1) * mixup_lambda[0 :: 2] + \\\n",
    "        x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d22dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.feature.inverse import mel_to_audio, mel_to_stft\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University, Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['feature_extraction']\n",
    "\n",
    "\n",
    "def feature_extraction(audio_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"Feature extraction function.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: Log mel-bands energies of shape=(t, nb_mels)\n",
    "    :rtype: numpy.ndarray, numpy.float\n",
    "    \"\"\"\n",
    "    y = audio_data/abs(audio_data).max()\n",
    "    mel_bands = melspectrogram(\n",
    "        y=y, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power, n_mels=nb_mels,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm).T\n",
    "\n",
    "    return np.log(mel_bands + np.finfo(float).eps)\n",
    "\n",
    "\n",
    "def from_mel_to_audio(mel_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"Feature extraction inverse function.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: audio data\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.exp(mel_data) - np.finfo(float).eps\n",
    "    audio_data = mel_to_audio(\n",
    "        M=y.T, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm)\n",
    "\n",
    "    return audio_data\n",
    "\n",
    "\n",
    "def from_mel_to_stft(mel_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"From logmelspectrogram to stft.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: audio data\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.exp(mel_data) - np.finfo(float).eps\n",
    "    stft = mel_to_stft(\n",
    "        M=y.T, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm)\n",
    "\n",
    "    return stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beae2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "#from tools.features_log_mel_bands import feature_extraction, from_mel_to_audio, from_mel_to_stft\n",
    "from pathlib import Path\n",
    "import pysndfx\n",
    "import gc\n",
    "\n",
    "import copy\n",
    "\n",
    "#from tools.file_io import load_audio_file\n",
    "import torch\n",
    "\n",
    "\n",
    "__author__ = 'Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "\n",
    "class MixUp:\n",
    "\n",
    "    def __init__(self, p, settings_features, simple_concat_captions=True,\n",
    "                 sample_audio=False):\n",
    "\n",
    "        self.p = p\n",
    "        self.sample_audio = sample_audio\n",
    "        self.settings_features = settings_features\n",
    "        self.simple_concat_captions = simple_concat_captions\n",
    "\n",
    "    def from_mel(self, mel):\n",
    "        return 700 * (10 ** (mel / 2595.0) - 1)\n",
    "\n",
    "    def to_mel(self, hertz):\n",
    "        return 2595.0 * np.log10(1 + hertz / 700.0)\n",
    "\n",
    "    def mix_audio(self, first_audio, second_audio):\n",
    "\n",
    "        a = np.random.uniform(0.4, 0.6)\n",
    "\n",
    "        shorter, longer = first_audio, second_audio\n",
    "\n",
    "        if shorter.shape[0] == longer.shape[0]:\n",
    "            if self.sample_audio:\n",
    "                return (longer + shorter) / 2.0\n",
    "            else:\n",
    "                longer = from_mel_to_audio(longer, **self.settings_features['process']) * a\n",
    "                shorter = from_mel_to_audio(shorter,\n",
    "                                            **self.settings_features['process'])\n",
    "                return feature_extraction((longer + shorter) / 2, **self.settings_features['process'])\n",
    "\n",
    "        if first_audio.shape[0] > second_audio.shape[0]:\n",
    "            shorter, longer = longer, shorter\n",
    "\n",
    "\n",
    "        if self.sample_audio:\n",
    "            start = random.randint(0, longer.shape[0] - 1 - shorter.shape[0])\n",
    "            end = start + shorter.shape[0]\n",
    "            longer *= a\n",
    "            longer[start:end] += shorter * (1 - a)\n",
    "        else:\n",
    "            longer = from_mel_to_audio(longer, **self.settings_features['process']) * a\n",
    "            shorter = from_mel_to_audio(shorter,\n",
    "                                        **self.settings_features['process'])\n",
    "            start = random.randint(0, longer.shape[0] - 1 - shorter.shape[0])\n",
    "            end = start + shorter.shape[0]\n",
    "            longer[start:end] += shorter * (1 - a)\n",
    "            longer = feature_extraction(longer,\n",
    "                                        **self.settings_features['process'])\n",
    "\n",
    "        return longer\n",
    "\n",
    "    def mix_labels(self, first_labels, second_labels):\n",
    "        if self.simple_concat_captions:\n",
    "            return np.hstack([first_labels[:-1], second_labels[1:]])\n",
    "        else:\n",
    "\n",
    "            first_token = first_labels[0]\n",
    "            last_token = first_labels[-1]\n",
    "            first_labels = first_labels[1:-1]\n",
    "            second_labels = second_labels[1:-1]\n",
    "            res = np.empty((first_labels.size + second_labels.size,),\n",
    "                           dtype=first_labels.dtype)\n",
    "            min_size = min(first_labels.size, second_labels.size)\n",
    "            res[0:2*min_size:2] = first_labels[:min_size]\n",
    "            res[1:2*min_size:2] = second_labels[:min_size]\n",
    "            if first_labels.size > second_labels.size:\n",
    "                res[min_size * 2:] = first_labels[min_size:]\n",
    "            elif second_labels.size > first_labels.size:\n",
    "                res[min_size*2:] = second_labels[min_size:]\n",
    "            res = np.concatenate(([first_token], res))\n",
    "            res = np.concatenate((res, [last_token]))\n",
    "            return res\n",
    "\n",
    "    def mix_audio_and_labels(self,\n",
    "                             first_audio, second_audio,\n",
    "                             first_labels, second_labels):\n",
    "        mixed_audio = self.mix_audio(first_audio, second_audio)\n",
    "        mixed_labels = self.mix_labels(first_labels, second_labels)\n",
    "\n",
    "        return mixed_audio, mixed_labels\n",
    "\n",
    "    def __call__(self, dataset, inputs):\n",
    "        resulted_audio, resulted_labels, filename = inputs[0], inputs[1], inputs[2]\n",
    "        if np.random.uniform() <= self.p:\n",
    "            random_sample = dataset.random_sample(sample_audio=self.sample_audio)\n",
    "            resulted_audio, resulted_labels = self.mix_audio_and_labels(\n",
    "                resulted_audio, random_sample[0],\n",
    "                resulted_labels, random_sample[1]\n",
    "            )\n",
    "        return resulted_audio, resulted_labels\n",
    "\n",
    "\n",
    "class AudioAugmentation:\n",
    "    # https://github.com/ex4sperans/freesound-classification\n",
    "    def __init__(self, p):\n",
    "\n",
    "        self.p = p\n",
    "        self.effects_chain = (\n",
    "            pysndfx.AudioEffectsChain()\n",
    "                .reverb(\n",
    "                reverberance=random.randrange(50),\n",
    "                room_scale=random.randrange(50),\n",
    "                stereo_depth=random.randrange(50)\n",
    "            )\n",
    "                .pitch(shift=random.randrange(-300, 300))\n",
    "                .overdrive(gain=random.randrange(2, 10))\n",
    "                .speed(random.uniform(0.9, 1.1))\n",
    "        )\n",
    "\n",
    "    def __call__(self, dataset, inputs):\n",
    "\n",
    "        resulted_audio = inputs[0]\n",
    "        captions = inputs[1]\n",
    "        del inputs\n",
    "        gc.collect()\n",
    "        if np.random.uniform() < self.p:\n",
    "            resulted_audio = torch.from_numpy(self.effects_chain(resulted_audio.numpy()))\n",
    "        return resulted_audio, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a5ddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysndfx in /home/hj20/anaconda3/lib/python3.7/site-packages (0.3.6)\r\n",
      "Requirement already satisfied: numpy in /home/hj20/anaconda3/lib/python3.7/site-packages (from pysndfx) (1.20.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pysndfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f78e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchaudio\n",
    "from numpy import load as np_load, ndarray\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pympler import muppy, summary\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University, Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['ClothoDataset']\n",
    "\n",
    "\n",
    "class ClothoDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_dir: Path,\n",
    "                 split: str,\n",
    "                 input_field_name: str,\n",
    "                 output_field_name: str,\n",
    "                 load_into_memory: bool,\n",
    "                 settings_audio,\n",
    "                 settings_features,\n",
    "                 online_preprocessing=True,\n",
    "                 transforms=None) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "        :param data_dir: Data directory with Clotho dataset files.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: The split to use (`development`, `validation`)\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name for the input values\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name for the output (target) values.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load the dataset into memory?\n",
    "        :type load_into_memory: bool\n",
    "        :param settings_audio: Settings about audio loading\n",
    "        :type dict\n",
    "        :param settings_features: Settings about audio processing\n",
    "        :type dict\n",
    "        :param indexes: Indexes of files, which depends on validation strategy\n",
    "        :type indexes: numpy array\n",
    "        :param transforms: List of transforms\n",
    "        :type transforms: list\n",
    "        \"\"\"\n",
    "\n",
    "        super(ClothoDataset, self).__init__()\n",
    "        self.online_preprocessing = online_preprocessing\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "        self.split = split\n",
    "\n",
    "        self.settings_audio = settings_audio\n",
    "        self.settings_features = settings_features\n",
    "\n",
    "        #if indexes is None:\n",
    "        self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        #else:\n",
    "        #    self.examples: List[Path] = list(np.array(sorted(the_dir.iterdir()))[indexes])\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.transforms = transforms\n",
    "        self.resampler = torchaudio.transforms.Resample(orig_freq=settings_features['process']['sr'],\n",
    "                                                        new_freq=settings_features['process']['sr_resample'])\n",
    "        if load_into_memory:\n",
    "            self.examples: List[ndarray] = [\n",
    "                np_load(str(f), allow_pickle=True)\n",
    "                for f in self.examples]\n",
    "        self.cnt = 0\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int) \\\n",
    "            -> Tuple[ndarray, ndarray, Path]:\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values, and the Path of the file.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray, Path\n",
    "        \"\"\"\n",
    "\n",
    "        ex = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex = np_load(str(ex), allow_pickle=True)\n",
    "        if self.online_preprocessing:\n",
    "            in_e = torchaudio.load(Path('data', 'clotho_audio_files', self.split, ex.file_name[0]))[0][0]\n",
    "            ou_e = ex[self.output_name].item()\n",
    "        else:\n",
    "            in_e, ou_e = [ex[i].item()\n",
    "                          for i in [self.input_name, self.output_name]]\n",
    "        filename = ex.file_name[0]\n",
    "        del ex\n",
    "        if self.transforms is not None:\n",
    "            for transform in self.transforms:\n",
    "                in_e, ou_e = transform(dataset=self, inputs=(in_e, ou_e, filename))\n",
    "        return in_e, ou_e, filename\n",
    "\n",
    "    def random_sample(self, sample_audio=False):\n",
    "        \"\"\"\n",
    "        Sampling audio or melspectrogram and encoded output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        item = random.randint(0, len(self.examples) - 1)\n",
    "        ex = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex = np_load(str(ex), allow_pickle=True)\n",
    "        if sample_audio:\n",
    "            thedir = Path('./data/clotho_audio_files/').joinpath(self.split)\n",
    "            filename = Path(thedir, ex.file_name[0])\n",
    "            in_e = torchaudio.load(filepath=filename)[0][0]\n",
    "            #in_e = self.resampler.forward(in_e)\n",
    "            ou_e = ex[self.output_name].item()\n",
    "        else:\n",
    "            in_e, ou_e = [ex[i].item()\n",
    "                          for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        return in_e, ou_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c764639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import MutableSequence, MutableMapping, Union,\\\n",
    "    Tuple, List\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import cat, zeros, from_numpy, ones, Tensor\n",
    "from numpy import ndarray\n",
    "\n",
    "#from data_handlers._clotho import ClothoDataset\n",
    "#from tools.augmentations import MixUp, AudioAugmentation\n",
    "\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University. Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['get_clotho_loader']\n",
    "\n",
    "\n",
    "def _clotho_collate_fn(batch: MutableSequence[ndarray]) \\\n",
    "        -> Tuple[Tensor, Tensor, List[str]]:\n",
    "    \"\"\"Pads data.\n",
    "    For each batch, the maximum input and output\\\n",
    "    time-steps are calculated. Then, then input and\\\n",
    "    output data are padded to match the maximum time-steps.\n",
    "    The input data are padded with zeros in front, and\\\n",
    "    the output with] <EOS> tokens at the end.\n",
    "    :param batch: Batch data of batch x time x features.\\\n",
    "                  First element in the list are the input\\\n",
    "                  data, second the output data.\n",
    "    :type batch: list[numpy.ndarray]\n",
    "    :return: Padded data. First tensor is the input data\\\n",
    "             and second the output.\n",
    "    :rtype: torch.Tensor, torch.Tensor, list[str]\n",
    "    \"\"\"\n",
    "    max_input_t_steps = max([i[0].shape[0] for i in batch])\n",
    "    max_output_t_steps = max([i[1].shape[0] for i in batch])\n",
    "\n",
    "    file_names = [i[2] for i in batch]\n",
    "\n",
    "    #input_features = batch[0][0].shape[-1]\n",
    "    eos_token = batch[0][1][-1]\n",
    "    input_tensor = cat([\n",
    "        cat([zeros(\n",
    "            max_input_t_steps - i[0].shape[0]).float(),\n",
    "             i[0].float()]).unsqueeze(0) for i in batch])\n",
    "    output_tensor = cat([\n",
    "        cat([\n",
    "            from_numpy(i[1]).long(),\n",
    "            ones(max_output_t_steps - len(i[1])).mul(eos_token).long()\n",
    "        ]).unsqueeze(0) for i in batch])\n",
    "    return [input_tensor, output_tensor, file_names]\n",
    "\n",
    "\n",
    "def get_clotho_loader(split: str,\n",
    "                      is_training: bool,\n",
    "                      settings_data: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      settings_io: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[\n",
    "                              str, Union[str, MutableMapping[str, str]]]]],\n",
    "                      settings_features: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      settings_dataset: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      ) \\\n",
    "        -> DataLoader:\n",
    "    \"\"\"Gets the data loader.\n",
    "    :param split: Split to be used.\n",
    "    :type split: str\n",
    "    :param is_training: Is training data?\n",
    "    :type is_training: bool\n",
    "    :param settings_data: Data loading and dataset settings.\n",
    "    :type settings_data: dict\n",
    "    :param settings_io: Files I/O settings.\n",
    "    :type settings_io: dict\n",
    "    :param settings_features: Audio preprocessing features.\n",
    "    :type settings_features: dict\n",
    "    :param settings_dataset: Dataset settings.\n",
    "    :type settings_dataset: dict\n",
    "    :param indexes: Indexes of audio files, which depends on validation_strategy.\n",
    "    :type indexes: numpy array\n",
    "    :type settings_training: dict\n",
    "    :return: Data loader.\n",
    "    :rtype: torch.utils.data.DataLoader\n",
    "    \"\"\"\n",
    "    data_dir = Path(\n",
    "        settings_io['root_dirs']['data'],\n",
    "        settings_io['dataset']['features_dirs']['output'])\n",
    "\n",
    "    transforms = []\n",
    "    if settings_data['transforms'] == 'None' or (not is_training):\n",
    "        transforms = None\n",
    "    else:\n",
    "        if 'MixUp' in settings_data['transforms']:\n",
    "            print(settings_features['simple_concat_captions'], 'lalalalalal')\n",
    "            transforms.append(MixUp(p=settings_data['MixUp_p'],\n",
    "                              settings_features=settings_features,\n",
    "                              simple_concat_captions=settings_features['simple_concat_captions'],\n",
    "                              sample_audio=True))\n",
    "        if 'another' in settings_data['transforms']:\n",
    "            transforms.append(AudioAugmentation(p=settings_data['MixUp_p']))\n",
    "\n",
    "    #if settings_training['validation_strategy']\n",
    "    dataset = ClothoDataset(\n",
    "        data_dir=data_dir,\n",
    "        split=split,\n",
    "        input_field_name=settings_data['input_field_name'],\n",
    "        output_field_name=settings_data['output_field_name'],\n",
    "        load_into_memory=settings_data['load_into_memory'],\n",
    "        settings_audio=settings_dataset['audio'],\n",
    "        settings_features=settings_features,\n",
    "        transforms=transforms)\n",
    "\n",
    "    shuffle = settings_data['shuffle'] if is_training else False\n",
    "    drop_last = settings_data['drop_last'] if is_training else False\n",
    "    if is_training:\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=settings_data['batch_size'],\n",
    "            shuffle=shuffle,\n",
    "            num_workers=settings_data['num_workers'],\n",
    "            drop_last=drop_last,\n",
    "            # pin_memory=True,\n",
    "            collate_fn=_clotho_collate_fn)\n",
    "    else:\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=40,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=2,\n",
    "            drop_last=drop_last,\n",
    "            # pin_memory=True,\n",
    "            collate_fn=_clotho_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bdc159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file='main_settings'\n",
    "file_ext='yaml'\n",
    "file_dir='settings' \n",
    "settings = file_io.load_yaml_file(Path(\n",
    "        file_dir, f'{config_file}.{file_ext}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282439e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.file_io import load_audio_file\n",
    "from tools import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba6d900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True lalalalalal\n"
     ]
    }
   ],
   "source": [
    "training_data = get_clotho_loader(\n",
    "            settings_io['dataset']['features_dirs']['development'],\n",
    "            is_training=True,\n",
    "            settings_data=settings_data,\n",
    "            settings_io=settings_io,\n",
    "            settings_features=settings_features,\n",
    "            settings_dataset=settings_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da33e988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fc96caf",
   "metadata": {},
   "outputs": [],
   "source": [
    " =  get_clotho_loader(\n",
    "            settings_io['dataset']['features_dirs']['evaluation'],\n",
    "            is_training=False,\n",
    "            settings_data=settings_data,\n",
    "            settings_io=settings_io,\n",
    "            settings_features=settings_features,\n",
    "            settings_dataset=settings_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2e22027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c197368",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_io=settings['dirs_and_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586cf61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MixUp']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_data['transforms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46972f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_dirs': {'outputs': 'outputs', 'data': 'data'},\n",
       " 'dataset': {'development': 'development',\n",
       "  'evaluation': 'evaluation',\n",
       "  'features_dirs': {'output': 'data_splits_mel',\n",
       "   'development': 'development',\n",
       "   'evaluation': 'evaluation'},\n",
       "  'audio_dirs': {'downloaded': 'clotho_audio_files',\n",
       "   'output': 'data_splits_audio_mel',\n",
       "   'development': 'development',\n",
       "   'evaluation': 'evaluation'},\n",
       "  'annotations_dir': 'clotho_csv_files',\n",
       "  'pickle_files_dir': 'pickles',\n",
       "  'files': {'np_file_name_template': 'clotho_file_{audio_file_name}_{caption_index}.npy',\n",
       "   'words_list_file_name': 'words_list.p',\n",
       "   'words_counter_file_name': 'words_frequencies.p',\n",
       "   'characters_list_file_name': 'characters_list.p',\n",
       "   'characters_frequencies_file_name': 'characters_frequencies.p'}},\n",
       " 'model': {'model_dir': 'models',\n",
       "  'checkpoint_model_name': 'dcase_model_baseline.pt',\n",
       "  'pre_trained_model_name': 'dcase_model_baseline_pre_trained.pt'},\n",
       " 'logging': {'logger_dir': 'logging',\n",
       "  'caption_logger_file': 'captions_baseline.txt'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201948df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'development'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_io['dataset']['features_dirs']['development']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc641b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_data=settings['dnn_training_settings']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa82501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_field_name': 'features',\n",
       " 'output_field_name': 'words_ind',\n",
       " 'load_into_memory': False,\n",
       " 'transforms': ['MixUp'],\n",
       " 'MixUp_p': 0.5,\n",
       " 'batch_size': 16,\n",
       " 'shuffle': True,\n",
       " 'num_workers': 4,\n",
       " 'drop_last': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0419e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_features=settings['feature_extraction_settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f7120db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keep_raw_audio_data': False,\n",
       " 'simple_concat_captions': True,\n",
       " 'process': {'sr': 44100,\n",
       "  'sr_resample': 16000,\n",
       "  'nb_fft': 1024,\n",
       "  'hop_size': 512,\n",
       "  'nb_mels': 64,\n",
       "  'window_function': 'hann',\n",
       "  'center': True,\n",
       "  'f_min': 0.0,\n",
       "  'f_max': None,\n",
       "  'htk': False,\n",
       "  'power': 1.0,\n",
       "  'norm': 1}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04521df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dataset=settings['dataset_creation_settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd805b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workflow': {'create_dataset': True, 'validate_dataset': False},\n",
       " 'annotations': {'development_file': 'clotho_captions_development.csv',\n",
       "  'evaluation_file': 'clotho_captions_evaluation.csv',\n",
       "  'audio_file_column': 'file_name',\n",
       "  'captions_fields_prefix': 'caption_{}',\n",
       "  'use_special_tokens': True,\n",
       "  'nb_captions': 5,\n",
       "  'keep_case': False,\n",
       "  'remove_punctuation_words': True,\n",
       "  'remove_punctuation_chars': True,\n",
       "  'use_unique_words_per_caption': False,\n",
       "  'use_unique_chars_per_caption': False},\n",
       " 'audio': {'sr': 44100, 'to_mono': True, 'max_abs_value': 1.0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from typing import Tuple, List, AnyStr, Union\n",
    "from pathlib import Path\n",
    "\n",
    "from numpy import ndarray, recarray\n",
    "from torch.utils.data import Dataset\n",
    "from numpy import load as np_load\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['ClothoDataset']\n",
    "\n",
    "\n",
    "class ClothoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir: Path,\n",
    "                 split: AnyStr,\n",
    "                 input_field_name: AnyStr,\n",
    "                 output_field_name: AnyStr,\n",
    "                 load_into_memory: bool,\n",
    "                 transforms=transforms) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "\n",
    "        :param data_dir: Directory with data.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name of the clotho data\\\n",
    "                                 to be used as input data to the\\\n",
    "                                 method.\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name of the clotho data\\\n",
    "                                 to be used as output data to the\\\n",
    "                                 method.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load all data into memory?\n",
    "        :type load_into_memory: bool\n",
    "        \"\"\"\n",
    "        super(ClothoDataset, self).__init__()\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "\n",
    "        self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.transforms=transforms\n",
    "        if load_into_memory:\n",
    "            self.examples: List[recarray] = [np_load(str(f), allow_pickle=True)\n",
    "                                             for f in self.examples]\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int) \\\n",
    "            -> Tuple[ndarray, ndarray]:\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray\n",
    "        \"\"\"\n",
    "        ex: Union[Path, recarray] = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex: recarray = np_load(str(ex), allow_pickle=True)\n",
    "\n",
    "        in_e, ou_e = [ex[i].item() for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        return in_e, ou_e\n",
    "\n",
    "\n",
    "class ClothoDatasetEval(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir: Path,\n",
    "                 split: AnyStr,\n",
    "                 input_field_name: AnyStr,\n",
    "                 output_field_name: AnyStr,\n",
    "                 load_into_memory: bool) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "\n",
    "        :param data_dir: Directory with data.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name of the clotho data\\\n",
    "                                 to be used as input data to the\\\n",
    "                                 method.\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name of the clotho data\\\n",
    "                                 to be used as output data to the\\\n",
    "                                 method.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load all data into memory?\n",
    "        :type load_into_memory: bool\n",
    "        \"\"\"\n",
    "        super(ClothoDatasetEval, self).__init__()\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "        if split == 'evaluation':\n",
    "            self.examples: List[Path] = sorted(the_dir.iterdir())[::5]  # changed\n",
    "        else:\n",
    "            self.examples: List[Path] = sorted(the_dir.iterdir())  # changed\n",
    "        # self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.data_dir = the_dir\n",
    "\n",
    "        if load_into_memory:\n",
    "            self.examples: List[recarray] = [np_load(str(f), allow_pickle=True)\n",
    "                                             for f in self.examples]\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int):\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray\n",
    "        \"\"\"\n",
    "        ex: Union[Path, recarray] = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex: recarray = np_load(str(ex), allow_pickle=True)\n",
    "\n",
    "        in_e, ou_e = [ex[i].item() for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        all_ref = get_all_ref(ex['file_name'].item(), self.data_dir)\n",
    "\n",
    "        filename = str(ex['file_name'].item())\n",
    "        out_len = len(ou_e)\n",
    "        return in_e, ou_e, all_ref, filename,out_len\n",
    "\n",
    "\n",
    "def get_all_ref(filename, data_dir):\n",
    "    filename = str(filename)\n",
    "    # tgt = [np.load(d, allow_pickle=True).words_ind.tolist()\n",
    "    tgt = [np.load(d, allow_pickle=True)['words_ind'].item().tolist()\n",
    "           for d in [os.path.join(data_dir, 'clotho_file_{filename}.wav_{i}.npy'.\n",
    "                                  format(filename=filename[:-4],  # 删除'.wav'\n",
    "                                         i=i)) for i in range(5)]  # wav_0-wav_4\n",
    "           ]\n",
    "    return tgt\n",
    "# EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa295a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff041f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from typing import Callable, Union, Tuple, AnyStr, Optional\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from .clotho_dataset import ClothoDataset, ClothoDatasetEval\n",
    "from .collate_fn import clotho_collate_fn, clotho_collate_fn_eval\n",
    "\n",
    "__author__ = 'Konstantinos Drossos'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['get_clotho_loader']\n",
    "\n",
    "\n",
    "def get_clotho_loader(data_dir: Path,\n",
    "                      split: str,\n",
    "                      input_field_name: str,\n",
    "                      output_field_name: str,\n",
    "                      load_into_memory: bool,\n",
    "                      batch_size: int,\n",
    "                      nb_t_steps_pad: Union[AnyStr, Tuple[int, int]],\n",
    "                      shuffle: Optional[bool] = True,\n",
    "                      drop_last: Optional[bool] = True,\n",
    "                      input_pad_at: Optional[str] = 'start',\n",
    "                      output_pad_at: Optional[str] = 'end',\n",
    "                      num_workers: Optional[int] = 1,\n",
    "                      return_reference: Optional[bool] = False,\n",
    "                      augment: Optional[bool] = False) \\\n",
    "        -> DataLoader:\n",
    "    \"\"\"Gets the clotho data loader.\n",
    "\n",
    "    :param return_reference:\n",
    "    :param data_dir: Directory with data.\n",
    "    :type data_dir: pathlib.Path\n",
    "    :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "    :type split: str\n",
    "    :param input_field_name: Field name of the clotho data\\\n",
    "                             to be used as input data to the\\\n",
    "                             method.\n",
    "    :type input_field_name: str\n",
    "    :param output_field_name: Field name of the clotho data\\\n",
    "                             to be used as output data to the\\\n",
    "                             method.\n",
    "    :type output_field_name: str\n",
    "    :param load_into_memory: Load all data into memory?\n",
    "    :type load_into_memory: bool\n",
    "    :param batch_size: Batch size to use.\n",
    "    :type batch_size: int\n",
    "    :param nb_t_steps_pad: Number of time steps to\\\n",
    "                           pad/truncate to. Cab use\\\n",
    "                           'max', 'min', or exact number\\\n",
    "                           e.g. (1024, 10).\n",
    "    :type nb_t_steps_pad: str|(int, int)\n",
    "    :param shuffle: Shuffle examples? Defaults to True.\n",
    "    :type shuffle: bool, optional\n",
    "    :param drop_last: Drop the last examples if not making\\\n",
    "                      a batch of `batch_size`? Defaults to True.\n",
    "    :type drop_last: bool, optional\n",
    "    :param input_pad_at: Pad input at the start or\\\n",
    "                         at the end?\n",
    "    :type input_pad_at: str\n",
    "    :param output_pad_at: Pad output at the start or\\\n",
    "                          at the end?\n",
    "    :type output_pad_at: str\n",
    "    :param num_workers: Amount of workers, defaults to 1.\n",
    "    :type num_workers: int, optional\n",
    "    :return: Dataloader for Clotho data.\n",
    "    :rtype: torch.utils.data.dataloader.DataLoader\n",
    "    \"\"\"\n",
    "    if return_reference:\n",
    "        dataset: ClothoDatasetEval = ClothoDatasetEval(\n",
    "            data_dir=data_dir, split=split,\n",
    "            input_field_name=input_field_name,\n",
    "            output_field_name=output_field_name,\n",
    "            load_into_memory=load_into_memory\n",
    "            transforms=trans)\n",
    "\n",
    "        collate_fn: Callable = partial(\n",
    "            clotho_collate_fn_eval,\n",
    "            nb_t_steps=nb_t_steps_pad,\n",
    "            input_pad_at=input_pad_at,\n",
    "            output_pad_at=output_pad_at, split=split, augment=augment)\n",
    "    else:\n",
    "        dataset: ClothoDataset = ClothoDataset(\n",
    "            data_dir=data_dir, split=split,\n",
    "            input_field_name=input_field_name,\n",
    "            output_field_name=output_field_name,\n",
    "            load_into_memory=load_into_memory)\n",
    "\n",
    "        collate_fn: Callable = partial(\n",
    "            clotho_collate_fn,\n",
    "            nb_t_steps=nb_t_steps_pad,\n",
    "            input_pad_at=input_pad_at,\n",
    "            output_pad_at=output_pad_at)\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset=dataset, batch_size=batch_size,\n",
    "        shuffle=shuffle, num_workers=num_workers,\n",
    "        drop_last=drop_last, collate_fn=collate_fn)\n",
    "\n",
    "# EOF\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcaset6",
   "language": "python",
   "name": "dcase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
