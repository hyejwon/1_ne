{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64263411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hj20/dcase_2020_T6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f507869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
    "                               out_channels=out_channels,\n",
    "                               kernel_size=(5, 5), stride=(1, 1),\n",
    "                               padding=(1, 1), bias=False)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "\n",
    "\n",
    "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
    "\n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        if pool_type == 'max':\n",
    "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg+max':\n",
    "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            raise Exception('Incorrect argument!')\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Cnn14(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Cnn14,self).__init__()\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
    "        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n",
    "        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n",
    "        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n",
    "        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n",
    "        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n",
    "                                     \n",
    "        \n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = input.unsqueeze(1)   # (batch_size, 1, time_steps, mel_bins)\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)     #(batch_size, 512, T/16, mel_bins/16)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Tag(nn.Module):\n",
    "    def __init__(self,class_num):\n",
    "        super(Tag, self).__init__()\n",
    "        self.feature = Cnn14()\n",
    "        self.fc1 = nn.Linear(512,512,bias=True)\n",
    "        self.fc = nn.Linear(512,class_num,bias=True)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc)\n",
    "\n",
    "    def forward(self,input):\n",
    "        '''\n",
    "        :param input: (batch_size,time_steps, mel_bins)\n",
    "        :return: ()\n",
    "        '''\n",
    "        x = self.feature(input)     #(batch_size, 512, T/16, mel_bins/16)\n",
    "        x = torch.mean(x,dim=3)     #(batch_size, 512, T/16)\n",
    "        (x1, _) = torch.max(x, dim=2)\n",
    "        x2 = torch.mean(x, dim=2)\n",
    "        x = x1 + x2\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        #(batch_size,class_num)\n",
    "        output = torch.sigmoid(self.fc(x))\n",
    "        # output = self.fc(x)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaa91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag_concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c48186a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5b11221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "from audio_tag.data_loader import tag_loader\n",
    "import numpy as np\n",
    "from hparams import hparams as hp\n",
    "#from encoder import Tag\n",
    "from tqdm import tqdm\n",
    "\n",
    "class_num = 500\n",
    "device = torch.device(\"cuda\")\n",
    "data_dir = hp.data_dir\n",
    "learning_rate=1e-3\n",
    "model = Tag(class_num).to(device)\n",
    "training_data = tag_loader(data_dir=data_dir, split='development',\n",
    "                                      batch_size=16,class_num=class_num)\n",
    "test_data = tag_loader(data_dir=data_dir, split='evaluation',\n",
    "                               batch_size=16,class_num=class_num)\n",
    "optimizer =torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "        betas=(0.9, 0.999), eps=1e-08, weight_decay=0., amsgrad=True)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=hp.lr, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.98)\n",
    "tag_loss = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae3fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    # bar  = tqdm(training_data,total=len(training_data))\n",
    "    loss_list = []\n",
    "    model.train()\n",
    "    with tqdm(training_data,total=len(training_data)) as bar:\n",
    "        for i, (feature, tag) in enumerate(bar):\n",
    "            feature = feature.to(device)\n",
    "            tag = tag.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out_tag = model(feature)\n",
    "            loss = tag_loss(out_tag,tag)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "            bar.set_description(\"epoch:{} idx:{} loss:{:.6f}\".format(epoch, i, np.mean(loss_list)))\n",
    "    return np.mean(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf406b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(epoch):\n",
    "    eva_loss = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (feature, tag) in enumerate(test_data):\n",
    "            feature = feature.to(device)\n",
    "            tag = tag.to(device)\n",
    "            out_tag = model(feature)\n",
    "            loss = tag_loss(out_tag, tag)\n",
    "            eva_loss.append(loss.item())\n",
    "    mean_loss = np.mean(eva_loss)\n",
    "    print(\"epoch:{:d}--testloss:{:.6f}\".format(epoch,mean_loss.item()))\n",
    "\n",
    "    # return  mean_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761eeded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:1 idx:195 loss:0.112109:  64%|██████▍   | 196/305 [03:38<02:01,  1.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4656725bfe37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# model.load_state_dict(torch.load(\"./models/280/TagModel_{}.pt\".format(str(40))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_last\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-117405e42701>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dcase_2020_T6/audio_tag/data_loader.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(batch, input_pad_at)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mtmp_in\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt_cat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mtmp_in\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0min_t_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_b = True\n",
    "    epoch_last = 0\n",
    "    if train_b:\n",
    "        # model.load_state_dict(torch.load(\"./models/280/TagModel_{}.pt\".format(str(40))))\n",
    "        for epoch in range(epoch_last+1,300):\n",
    "            train(epoch)\n",
    "            scheduler.step(epoch)\n",
    "            test(epoch)\n",
    "            if epoch%5==0:\n",
    "                torch.save(model.state_dict(),'./models/tag_models/TagModel_{}.pt'.format(epoch))\n",
    "    else:\n",
    "        for epoch in range(0,225,5):\n",
    "            model.load_state_dict(torch.load(\"./models/tag_models/TagModel_{}.pt\".format(str(epoch))))\n",
    "            test(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3aa8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e140e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModelA, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class MyModelB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModelB, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.classifier = nn.Linear(4, 2)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.modelA(x1)\n",
    "        x2 = self.modelB(x2)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e28d3cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\r\n",
      "\r\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\r\n",
      "       usage information.\r\n",
      "\r\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\r\n",
      "\r\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\r\n",
      "       usage information.\r\n",
      "\r\n",
      "Thu Oct 28 20:36:49 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 35%   34C    P8    21W / 260W |  10375MiB / 11016MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1289      G   /usr/lib/xorg/Xorg                 18MiB |\r\n",
      "|    0   N/A  N/A      1399      G   /usr/bin/gnome-shell               73MiB |\r\n",
      "|    0   N/A  N/A      1621      G   /usr/lib/xorg/Xorg                453MiB |\r\n",
      "|    0   N/A  N/A      1761      G   /usr/bin/gnome-shell              302MiB |\r\n",
      "|    0   N/A  N/A      6198      G   ...AAAAAAAAA= --shared-files       47MiB |\r\n",
      "|    0   N/A  N/A     10168      G   ...AAAAAAAAA= --shared-files       46MiB |\r\n",
      "|    0   N/A  N/A     16301      C   ...hj20/anaconda3/bin/python     8445MiB |\r\n",
      "|    0   N/A  N/A     17064      G   ...AAAAAAAAA= --shared-files      312MiB |\r\n",
      "|    0   N/A  N/A     21634      C   ...hj20/anaconda3/bin/python      625MiB |\r\n",
      "|    0   N/A  N/A     26686      G   ...AAAAAAAAA= --shared-files       43MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b80d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 16301"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8821e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee437603",
   "metadata": {},
   "source": [
    "image_net으로 학습된 resnet18 사용하여 tag train 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "689a5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#프리트레인 된 모델 불러오기\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "model=models.resnet18(pretrained=True).cuda()\n",
    "num_ftrs=model.fc.in_features\n",
    "model.fc=nn.Linear(num_ftrs,300)\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f47440f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d22a60ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=300, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0925bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class VGGish(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of the VGGish model.\n",
    "    Adapted from: https://github.com/harritaylor/torch-vggish\n",
    "    The following modifications were made: (i) correction for the missing ReLU layers, (ii) correction for the\n",
    "    improperly formatted data when transitioning from NHWC --> NCHW in the fully-connected layers, and (iii)\n",
    "    correction for flattening in the fully-connected layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGGish, self).__init__()\n",
    "        \n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 1, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 1, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 1, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 1, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, 1, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 1, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 24, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 300),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    \n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "    \n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        x = input.unsqueeze(-1)\n",
    "        x = self.features(x)\n",
    "        x = torch.mean(x,dim=3)  \n",
    "        (x1, _) = torch.max(x, dim=2)\n",
    "        x2 = torch.mean(x, dim=2)\n",
    "        x = x1 + x2\n",
    "        \n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        #x = F.relu_(self.fc(x)) \n",
    "        \n",
    "        output = torch.sigmoid(self.fc(x)) \n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "def main():\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c41ca8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[[[1, 2],[3, 4]]]\n",
    "x=torch.tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ad7fdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d9f94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=x.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a505fe4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d4b378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177891e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1d7296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VGGish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4888682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGGish(\n",
       "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=12288, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=4096, out_features=300, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3904c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00856896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    # bar  = tqdm(training_data,total=len(training_data))\n",
    "    loss_list = []\n",
    "    model.train()\n",
    "    with tqdm(training_data,total=len(training_data)) as bar:\n",
    "        for i, (feature, tag) in enumerate(bar):\n",
    "            feature = feature.to(device)\n",
    "            tag = tag.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out_tag = model(feature)\n",
    "            loss = tag_loss(out_tag,tag)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "            bar.set_description(\"epoch:{} idx:{} loss:{:.6f}\".format(epoch, i, np.mean(loss_list)))\n",
    "    return np.mean(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c8ad54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/239 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 1, 1], expected input[16, 2559, 64, 1] to have 1 channels, but got 2559 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-79aab3034eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# model.load_state_dict(torch.load(\"./models/280/TagModel_{}.pt\".format(str(40))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_last\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_last\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-117405e42701>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mout_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-97efaf06333d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 1, 1], expected input[16, 2559, 64, 1] to have 1 channels, but got 2559 channels instead"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_b = True\n",
    "    epoch_last = 0\n",
    "    if train_b:\n",
    "        # model.load_state_dict(torch.load(\"./models/280/TagModel_{}.pt\".format(str(40))))\n",
    "        for epoch in range(epoch_last+1,epoch_last+5):\n",
    "            train(epoch)\n",
    "            scheduler.step(epoch)\n",
    "            test(epoch)\n",
    "            if epoch%5==0:\n",
    "                torch.save(model.state_dict(),'./models/tag_models/TagModel_{}.pt'.format(epoch))\n",
    "    else:\n",
    "        for epoch in range(0,225,5):\n",
    "            model.load_state_dict(torch.load(\"./models/tag_models/TagModel_{}.pt\".format(str(epoch))))\n",
    "            test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64458be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf5882",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#차원맞추기\n",
    "y = audio_data\n",
    "mel_bands = melspectrogram(\n",
    "        y=y, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power, n_mels=nb_mels,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm).T\n",
    "logmel_spectrogram = librosa.core.power_to_db(\n",
    "            mel_bands, ref=1.0, amin=1e-10, \n",
    "            top_db=None)\n",
    "logmel_spectrogram = logmel_spectrogram.astype(np.float32)        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f34e4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class ConvTasNet(torch.nn.Module):\n",
    "    \"\"\"Conv-TasNet: a fully-convolutional time-domain audio separation network\n",
    "\n",
    "    Args:\n",
    "        num_sources (int): The number of sources to split.\n",
    "        enc_kernel_size (int): The convolution kernel size of the encoder/decoder, <L>.\n",
    "        enc_num_feats (int): The feature dimensions passed to mask generator, <N>.\n",
    "        msk_kernel_size (int): The convolution kernel size of the mask generator, <P>.\n",
    "        msk_num_feats (int): The input/output feature dimension of conv block in the mask generator, <B, Sc>.\n",
    "        msk_num_hidden_feats (int): The internal feature dimension of conv block of the mask generator, <H>.\n",
    "        msk_num_layers (int): The number of layers in one conv block of the mask generator, <X>.\n",
    "        msk_num_stacks (int): The numbr of conv blocks of the mask generator, <R>.\n",
    "\n",
    "    Note:\n",
    "        This implementation corresponds to the \"non-causal\" setting in the paper.\n",
    "\n",
    "    Reference:\n",
    "        - Conv-TasNet: Surpassing Ideal Time--Frequency Magnitude Masking for Speech Separation\n",
    "\n",
    "          Luo, Yi and Mesgarani, Nima\n",
    "\n",
    "          https://arxiv.org/abs/1809.07454\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_sources: int = 2,\n",
    "        # encoder/decoder parameters\n",
    "        enc_kernel_size: int = 16,\n",
    "        enc_num_feats: int = 512,\n",
    "        # mask generator parameters\n",
    "        msk_kernel_size: int = 3,\n",
    "        msk_num_feats: int = 128,\n",
    "        msk_num_hidden_feats: int = 512,\n",
    "        msk_num_layers: int = 8,\n",
    "        msk_num_stacks: int = 3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_sources = num_sources\n",
    "        self.enc_num_feats = enc_num_feats\n",
    "        self.enc_kernel_size = enc_kernel_size\n",
    "        self.enc_stride = enc_kernel_size // 2\n",
    "\n",
    "        self.encoder = torch.nn.Conv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=enc_num_feats,\n",
    "            kernel_size=enc_kernel_size,\n",
    "            stride=self.enc_stride,\n",
    "            padding=self.enc_stride,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.mask_generator = MaskGenerator(\n",
    "            input_dim=enc_num_feats,\n",
    "            num_sources=num_sources,\n",
    "            kernel_size=msk_kernel_size,\n",
    "            num_feats=msk_num_feats,\n",
    "            num_hidden=msk_num_hidden_feats,\n",
    "            num_layers=msk_num_layers,\n",
    "            num_stacks=msk_num_stacks,\n",
    "        )\n",
    "        self.decoder = torch.nn.ConvTranspose1d(\n",
    "            in_channels=enc_num_feats,\n",
    "            out_channels=1,\n",
    "            kernel_size=enc_kernel_size,\n",
    "            stride=self.enc_stride,\n",
    "            padding=self.enc_stride,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    def _align_num_frames_with_strides(\n",
    "        self, input: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, int]:\n",
    "        \n",
    "        batch_size, num_channels, num_frames = input.shape\n",
    "        is_odd = self.enc_kernel_size % 2\n",
    "        num_strides = (num_frames - is_odd) // self.enc_stride\n",
    "        num_remainings = num_frames - (is_odd + num_strides * self.enc_stride)\n",
    "        if num_remainings == 0:\n",
    "            return input, 0\n",
    "\n",
    "        num_paddings = self.enc_stride - num_remainings\n",
    "        pad = torch.zeros(\n",
    "            batch_size,\n",
    "            num_channels,\n",
    "            num_paddings,\n",
    "            dtype=input.dtype,\n",
    "            device=input.device,\n",
    "        )\n",
    "        return torch.cat([input, pad], 2), num_paddings\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Perform source separation. Generate audio source waveforms.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): 3D Tensor with shape [batch, channel==1, frames]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 3D Tensor with shape [batch, channel==num_sources, frames]\n",
    "        \"\"\"\n",
    "        if input.ndim != 3 or input.shape[1] != 1:\n",
    "            raise ValueError(\n",
    "                f\"Expected 3D tensor (batch, channel==1, frames). Found: {input.shape}\"\n",
    "            )\n",
    "\n",
    "        # B: batch size\n",
    "        # L: input frame length\n",
    "        # L': padded input frame length\n",
    "        # F: feature dimension\n",
    "        # M: feature frame length\n",
    "        # S: number of sources\n",
    "\n",
    "        padded, num_pads = self._align_num_frames_with_strides(input)  # B, 1, L'\n",
    "        batch_size, num_padded_frames = padded.shape[0], padded.shape[2]\n",
    "        feats = self.encoder(padded)  # B, F, M\n",
    "        masked = self.mask_generator(feats) * feats.unsqueeze(1)  # B, S, F, M\n",
    "        masked = masked.view(\n",
    "            batch_size * self.num_sources, self.enc_num_feats, -1\n",
    "        )  # B*S, F, M\n",
    "        decoded = self.decoder(masked)  # B*S, 1, L'\n",
    "        output = decoded.view(\n",
    "            batch_size, self.num_sources, num_padded_frames\n",
    "        )  # B, S, L'\n",
    "        if num_pads > 0:\n",
    "            output = output[..., :-num_pads]  # B, S, L\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c685a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskGenerator(torch.nn.Module):\n",
    "    \"\"\"TCN (Temporal Convolution Network) Separation Module\n",
    "\n",
    "    Generates masks for separation.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Input feature dimension, <N>.\n",
    "        num_sources (int): The number of sources to separate.\n",
    "        kernel_size (int): The convolution kernel size of conv blocks, <P>.\n",
    "        num_featrs (int): Input/output feature dimenstion of conv blocks, <B, Sc>.\n",
    "        num_hidden (int): Intermediate feature dimention of conv blocks, <H>\n",
    "        num_layers (int): The number of conv blocks in one stack, <X>.\n",
    "        num_stacks (int): The number of conv block stacks, <R>.\n",
    "\n",
    "    Note:\n",
    "        This implementation corresponds to the \"non-causal\" setting in the paper.\n",
    "\n",
    "    References:\n",
    "        - Conv-TasNet: Surpassing Ideal Time--Frequency Magnitude Masking for Speech Separation\n",
    "          Luo, Yi and Mesgarani, Nima\n",
    "          https://arxiv.org/abs/1809.07454\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        num_sources: int,\n",
    "        kernel_size: int,\n",
    "        num_feats: int,\n",
    "        num_hidden: int,\n",
    "        num_layers: int,\n",
    "        num_stacks: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.num_sources = num_sources\n",
    "\n",
    "        self.input_norm = torch.nn.GroupNorm(\n",
    "            num_groups=1, num_channels=input_dim, eps=1e-8\n",
    "        )\n",
    "        self.input_conv = torch.nn.Conv1d(\n",
    "            in_channels=input_dim, out_channels=num_feats, kernel_size=1\n",
    "        )\n",
    "\n",
    "        self.receptive_field = 0\n",
    "        self.conv_layers = torch.nn.ModuleList([])\n",
    "        for s in range(num_stacks):\n",
    "            for l in range(num_layers):\n",
    "                multi = 2 ** l\n",
    "                self.conv_layers.append(\n",
    "                    ConvBlock(\n",
    "                        io_channels=num_feats,\n",
    "                        hidden_channels=num_hidden,\n",
    "                        kernel_size=kernel_size,\n",
    "                        dilation=multi,\n",
    "                        padding=multi,\n",
    "                        # The last ConvBlock does not need residual\n",
    "                        no_residual=(l == (num_layers - 1) and s == (num_stacks - 1)),\n",
    "                    )\n",
    "                )\n",
    "                self.receptive_field += (\n",
    "                    kernel_size if s == 0 and l == 0 else (kernel_size - 1) * multi\n",
    "                )\n",
    "        self.output_prelu = torch.nn.PReLU()\n",
    "        self.output_conv = torch.nn.Conv1d(\n",
    "            in_channels=num_feats, out_channels=input_dim * num_sources, kernel_size=1,\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Generate separation mask.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): 3D Tensor with shape [batch, features, frames]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: shape [batch, num_sources, features, frames]\n",
    "        \"\"\"\n",
    "        batch_size = input.shape[0]\n",
    "        feats = self.input_norm(input)\n",
    "        feats = self.input_conv(feats)\n",
    "        output = 0.0\n",
    "        for layer in self.conv_layers:\n",
    "            residual, skip = layer(feats)\n",
    "            if residual is not None:  # the last conv layer does not produce residual\n",
    "                feats = feats + residual\n",
    "            output = output + skip\n",
    "        output = self.output_prelu(output)\n",
    "        output = self.output_conv(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output.view(batch_size, self.num_sources, self.input_dim, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71924eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(torch.nn.Module):\n",
    "    \"\"\"1D Convolutional block.\n",
    "\n",
    "    Args:\n",
    "        io_channels (int): The number of input/output channels, <B, Sc>\n",
    "        hidden_channels (int): The number of channels in the internal layers, <H>.\n",
    "        kernel_size (int): The convolution kernel size of the middle layer, <P>.\n",
    "        padding (int): Padding value of the convolution in the middle layer.\n",
    "        dilation (int): Dilation value of the convolution in the middle layer.\n",
    "        no_redisual (bool): Disable residual block/output.\n",
    "\n",
    "    Note:\n",
    "        This implementation corresponds to the \"non-causal\" setting in the paper.\n",
    "\n",
    "    Reference:\n",
    "        - Conv-TasNet: Surpassing Ideal Time--Frequency Magnitude Masking for Speech Separation\n",
    "\n",
    "          Luo, Yi and Mesgarani, Nima\n",
    "\n",
    "          https://arxiv.org/abs/1809.07454\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        io_channels: int,\n",
    "        hidden_channels: int,\n",
    "        kernel_size: int,\n",
    "        padding: int,\n",
    "        dilation: int = 1,\n",
    "        no_residual: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=io_channels, out_channels=hidden_channels, kernel_size=1\n",
    "            ),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.GroupNorm(num_groups=1, num_channels=hidden_channels, eps=1e-08),\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=hidden_channels,\n",
    "                out_channels=hidden_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                dilation=dilation,\n",
    "                groups=hidden_channels,\n",
    "            ),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.GroupNorm(num_groups=1, num_channels=hidden_channels, eps=1e-08),\n",
    "        )\n",
    "\n",
    "        self.res_out = (\n",
    "            None\n",
    "            if no_residual\n",
    "            else torch.nn.Conv1d(\n",
    "                in_channels=hidden_channels, out_channels=io_channels, kernel_size=1\n",
    "            )\n",
    "        )\n",
    "        self.skip_out = torch.nn.Conv1d(\n",
    "            in_channels=hidden_channels, out_channels=io_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, input: torch.Tensor\n",
    "    ) -> Tuple[Optional[torch.Tensor], torch.Tensor]:\n",
    "        feature = self.conv_layers(input)\n",
    "        if self.res_out is None:\n",
    "            residual = None\n",
    "        else:\n",
    "            residual = self.res_out(feature)\n",
    "        skip_out = self.skip_out(feature)\n",
    "        return residual, skip_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab8ce076",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvTasNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc089f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvTasNet(\n",
       "  (encoder): Conv1d(1, 512, kernel_size=(16,), stride=(8,), padding=(8,), bias=False)\n",
       "  (mask_generator): MaskGenerator(\n",
       "    (input_norm): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "    (input_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (4): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (5): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (6): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (7): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (8): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (9): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (10): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (11): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (12): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (13): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (14): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (15): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (16): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (17): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (18): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (19): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (20): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (21): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (22): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (res_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (23): ConvBlock(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GroupNorm(1, 512, eps=1e-08, affine=True)\n",
       "        )\n",
       "        (skip_out): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (output_prelu): PReLU(num_parameters=1)\n",
       "    (output_conv): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (decoder): ConvTranspose1d(512, 1, kernel_size=(16,), stride=(8,), padding=(8,), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c608f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00372c32",
   "metadata": {},
   "outputs": [],
   "source": [
    " # pool of square window of size=3, stride=2\n",
    "m = nn.AvgPool2d(3, stride=2)\n",
    " # pool of non-square window\n",
    "m = nn.AvgPool2d((3, 2), stride=(2, 1))\n",
    "input = torch.randn(20, 16, 50, 32)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e58698a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16, 24, 31])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b592c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-20 22:03:21--  https://zenodo.org/record/3987831/files/Cnn14_mAP%3D0.431.pth?download=1\n",
      "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
      "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 327428481 (312M) [application/octet-stream]\n",
      "Saving to: ‘Cnn14_mAP=0.431.pth’\n",
      "\n",
      "Cnn14_mAP=0.431.pth 100%[===================>] 312.26M  1.16MB/s    in 8m 40s  \n",
      "\n",
      "2021-05-20 22:12:03 (615 KB/s) - ‘Cnn14_mAP=0.431.pth’ saved [327428481/327428481]\n",
      "\n",
      "python3: can't open file 'pytorch/inference.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH=\"Cnn14_mAP=0.431.pth\"\n",
    "!wget -O $CHECKPOINT_PATH https://zenodo.org/record/3987831/files/Cnn14_mAP%3D0.431.pth?download=1\n",
    "!MODEL_TYPE=\"Cnn14\"\n",
    "!CUDA_VISIBLE_DEVICES=0 python3 pytorch/inference.py audio_tagging --model_type=$MODEL_TYPE --checkpoint_path=$CHECKPOINT_PATH --audio_path=\"resources/R9_ZSCveAHg_7s.wav\" --cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c272fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"Cnn14_mAP=0.431.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b333d83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iteration': 660000,\n",
       " 'model': OrderedDict([('spectrogram_extractor.stft.conv_real.weight',\n",
       "               tensor([[[ 0.0000e+00,  9.4124e-06,  3.7649e-05,  ...,  8.4709e-05,\n",
       "                          3.7649e-05,  9.4124e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00,  9.4122e-06,  3.7646e-05,  ...,  8.4695e-05,\n",
       "                          3.7646e-05,  9.4122e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00,  9.4117e-06,  3.7638e-05,  ...,  8.4652e-05,\n",
       "                          3.7638e-05,  9.4117e-06]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4117e-06,  3.7638e-05,  ..., -8.4652e-05,\n",
       "                          3.7638e-05, -9.4117e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4122e-06,  3.7646e-05,  ..., -8.4695e-05,\n",
       "                          3.7646e-05, -9.4122e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4124e-06,  3.7649e-05,  ..., -8.4709e-05,\n",
       "                          3.7649e-05, -9.4124e-06]]], device='cuda:0')),\n",
       "              ('spectrogram_extractor.stft.conv_imag.weight',\n",
       "               tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -5.7753e-08, -4.6201e-07,  ...,  1.5592e-06,\n",
       "                          4.6201e-07,  5.7753e-08]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1550e-07, -9.2395e-07,  ...,  3.1179e-06,\n",
       "                          9.2395e-07,  1.1550e-07]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1550e-07,  9.2395e-07,  ...,  3.1179e-06,\n",
       "                         -9.2395e-07,  1.1550e-07]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -5.7753e-08,  4.6201e-07,  ...,  1.5592e-06,\n",
       "                         -4.6201e-07,  5.7753e-08]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1527e-21,  9.2214e-21,  ..., -1.7514e-17,\n",
       "                          1.2470e-17, -8.8136e-21]]], device='cuda:0')),\n",
       "              ('logmel_extractor.melW',\n",
       "               tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0043, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       ...,\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "                      device='cuda:0')),\n",
       "              ('bn0.weight',\n",
       "               tensor([1.1320, 1.1177, 1.0762, 1.0642, 1.0528, 1.0432, 1.0312, 1.0325, 1.0179,\n",
       "                       1.0202, 1.0227, 1.0202, 1.0122, 1.0062, 1.0045, 1.0089, 0.9956, 1.0049,\n",
       "                       1.0091, 1.0115, 1.0137, 1.0190, 1.0227, 1.0214, 1.0323, 1.0345, 1.0397,\n",
       "                       1.0460, 1.0446, 1.0567, 1.0622, 1.0641, 1.0701, 1.0816, 1.0779, 1.0810,\n",
       "                       1.0845, 1.0886, 1.0917, 1.0962, 1.1054, 1.1088, 1.1155, 1.1431, 1.1706,\n",
       "                       1.1884, 1.1996, 1.2079, 1.2108, 1.2301, 1.2602, 1.2582, 1.2637, 1.2565,\n",
       "                       1.2466, 1.2535, 1.2581, 1.2666, 1.2596, 1.2662, 1.2675, 1.2755, 1.2605,\n",
       "                       1.2360], device='cuda:0')),\n",
       "              ('bn0.bias',\n",
       "               tensor([ 0.1571,  0.1276,  0.1479,  0.1625,  0.1588,  0.1553,  0.1583,  0.1526,\n",
       "                        0.1295,  0.1385,  0.1241,  0.1108,  0.1078,  0.0908,  0.0864,  0.0728,\n",
       "                        0.0587,  0.0744,  0.0698,  0.0769,  0.0764,  0.0734,  0.0834,  0.0732,\n",
       "                        0.0852,  0.0898,  0.0862,  0.0914,  0.0925,  0.0998,  0.0985,  0.1030,\n",
       "                        0.1112,  0.1020,  0.1170,  0.1125,  0.1141,  0.1243,  0.1283,  0.1334,\n",
       "                        0.1325,  0.1215,  0.1057,  0.0668,  0.0478,  0.0405,  0.0304,  0.0251,\n",
       "                        0.0158, -0.0188, -0.0175, -0.0241, -0.0151, -0.0178, -0.0125, -0.0239,\n",
       "                       -0.0258, -0.0207, -0.0214, -0.0607, -0.1060, -0.1113, -0.1011, -0.1507],\n",
       "                      device='cuda:0')),\n",
       "              ('bn0.running_mean',\n",
       "               tensor([-14.6716, -13.5016, -13.4848, -13.6293, -14.3204, -14.5562, -15.3186,\n",
       "                       -15.6736, -16.1506, -16.6857, -17.3202, -17.9466, -18.1833, -18.8924,\n",
       "                       -19.2544, -19.9988, -20.3022, -20.8746, -21.2155, -21.4020, -21.8007,\n",
       "                       -22.0300, -22.3793, -22.8539, -23.0242, -23.3607, -23.8569, -24.1430,\n",
       "                       -24.8221, -24.8972, -25.3594, -25.6744, -26.0364, -26.5703, -26.9660,\n",
       "                       -27.6044, -28.2146, -28.4758, -28.9608, -29.5054, -30.2099, -31.0475,\n",
       "                       -31.9498, -33.2155, -34.3192, -35.2828, -36.3154, -37.3812, -38.5081,\n",
       "                       -39.6744, -40.7715, -41.6523, -42.4917, -43.5376, -44.6829, -45.6406,\n",
       "                       -46.6226, -47.7345, -48.9766, -51.2940, -53.2976, -54.7853, -56.6125,\n",
       "                       -58.6723], device='cuda:0')),\n",
       "              ('bn0.running_var',\n",
       "               tensor([562.6836, 538.2888, 523.5983, 512.2266, 508.1508, 505.7111, 498.9277,\n",
       "                       493.7249, 492.7387, 494.3791, 492.4423, 491.3661, 492.7037, 486.5675,\n",
       "                       482.8276, 479.0324, 474.3574, 471.8389, 466.2073, 467.3459, 467.3168,\n",
       "                       465.6601, 465.0703, 459.8588, 459.3958, 460.0753, 459.0511, 456.9366,\n",
       "                       447.3957, 447.4801, 448.0446, 447.1147, 447.5915, 443.2527, 444.5135,\n",
       "                       439.2311, 438.1524, 439.1017, 436.5105, 435.1298, 431.6063, 429.3687,\n",
       "                       432.6924, 448.3938, 465.6433, 473.9764, 479.8025, 489.4444, 493.2933,\n",
       "                       511.0590, 526.2554, 531.6984, 528.9656, 525.3799, 527.2983, 524.2160,\n",
       "                       522.8007, 521.0366, 512.1818, 517.4718, 525.3675, 518.8182, 515.4367,\n",
       "                       504.3748], device='cuda:0')),\n",
       "              ('bn0.num_batches_tracked', tensor(660000, device='cuda:0')),\n",
       "              ('conv_block1.conv1.weight',\n",
       "               tensor([[[[-0.1157, -0.0409,  0.2871],\n",
       "                         [-0.1708, -0.2117,  0.2982],\n",
       "                         [-0.0491, -0.1317,  0.1859]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2801, -0.3807, -0.2811],\n",
       "                         [ 0.0549, -0.0849, -0.0575],\n",
       "                         [ 0.2567,  0.4331,  0.3460]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2524,  0.2830,  0.0480],\n",
       "                         [-0.2276,  0.3030, -0.0378],\n",
       "                         [-0.2848,  0.2227, -0.0920]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.4562, -0.2414, -0.1083],\n",
       "                         [ 0.0203,  0.2097, -0.1762],\n",
       "                         [ 0.3866,  0.2056,  0.0057]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.8599,  0.1073,  0.0449],\n",
       "                         [-0.1429, -0.1713, -0.0413],\n",
       "                         [-0.7229,  0.0996, -0.0161]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2473, -0.4351,  0.0153],\n",
       "                         [ 0.3256, -0.3661,  0.1124],\n",
       "                         [ 0.3105, -0.2917,  0.1389]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2159,  0.0819,  0.0793],\n",
       "                         [ 0.1459, -0.0305,  0.0346],\n",
       "                         [-0.0654, -0.2300, -0.0103]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1025, -0.1338,  0.0851],\n",
       "                         [-0.0809, -0.1444,  0.1262],\n",
       "                         [ 0.0040, -0.1499,  0.0886]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0404, -0.0614, -0.2333],\n",
       "                         [ 0.1032, -0.0540, -0.1472],\n",
       "                         [ 0.2342,  0.1791, -0.0012]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2254, -0.0125,  0.1341],\n",
       "                         [-0.0999,  0.0126,  0.1157],\n",
       "                         [-0.1024, -0.2471, -0.0289]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0755, -0.2547, -0.0644],\n",
       "                         [-0.1238, -0.1506,  0.1127],\n",
       "                         [ 0.0677, -0.1242,  0.1649]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1558, -0.3158,  0.2138],\n",
       "                         [ 0.0564, -0.2753,  0.1341],\n",
       "                         [ 0.0769, -0.2209,  0.1780]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1673, -0.0438, -0.0691],\n",
       "                         [ 0.4606,  0.2341, -0.1148],\n",
       "                         [-0.0201,  0.2288, -0.2158]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1536,  0.0732,  0.3182],\n",
       "                         [-0.1690, -0.2065,  0.3014],\n",
       "                         [-0.1656, -0.1580,  0.1418]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1658, -0.0776, -0.3623],\n",
       "                         [ 0.4581, -0.0780, -0.3655],\n",
       "                         [ 0.4299,  0.0422, -0.2160]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2734, -0.4561, -0.0098],\n",
       "                         [ 0.0340, -0.1423,  0.1696],\n",
       "                         [ 0.0904,  0.0498,  0.3623]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2412, -0.2049,  0.1304],\n",
       "                         [-0.1857, -0.0197,  0.2695],\n",
       "                         [-0.0437, -0.1220,  0.2432]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.3511,  0.3086, -0.0429],\n",
       "                         [-0.2909,  0.3346, -0.0069],\n",
       "                         [-0.2629,  0.3210, -0.0132]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2246,  0.2543,  0.2566],\n",
       "                         [-0.2391,  0.0425, -0.0548],\n",
       "                         [-0.0458, -0.0244,  0.0359]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0330, -0.3215,  0.4203],\n",
       "                         [-0.0198, -0.2766,  0.3009],\n",
       "                         [-0.0170, -0.3787,  0.2505]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2142, -0.4263, -0.0857],\n",
       "                         [ 0.7674, -0.0807, -0.0343],\n",
       "                         [-0.3831,  0.1036, -0.0528]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.5368,  0.6537,  0.1528],\n",
       "                         [-0.1262, -0.0604,  0.0492],\n",
       "                         [-0.3840, -0.5282, -0.1845]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1350,  0.5900, -0.3574],\n",
       "                         [-0.0324,  0.4830, -0.3281],\n",
       "                         [-0.0772,  0.1368, -0.2605]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1863, -0.0577, -0.0013],\n",
       "                         [ 0.3851, -0.2484, -0.0985],\n",
       "                         [ 0.2075, -0.2966, -0.0924]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1026, -0.4270, -0.0460],\n",
       "                         [-0.0606, -0.2422,  0.2103],\n",
       "                         [ 0.1655,  0.2054,  0.2914]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1034,  0.1289,  0.5429],\n",
       "                         [-0.1179, -0.1162,  0.2641],\n",
       "                         [-0.1404, -0.3369, -0.1318]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.5702, -0.1745,  0.0518],\n",
       "                         [ 0.1762, -0.1056, -0.0240],\n",
       "                         [-0.0318, -0.2576, -0.0831]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2020, -0.5972,  0.0303],\n",
       "                         [-0.1264,  0.7590,  0.0706],\n",
       "                         [-0.1551, -0.0168, -0.1676]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.3863,  0.2240,  0.0623],\n",
       "                         [-0.1045,  0.0265, -0.0301],\n",
       "                         [ 0.5047, -0.2133, -0.0831]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0806, -0.3936,  0.1802],\n",
       "                         [ 0.1682, -0.3419,  0.1687],\n",
       "                         [ 0.2499, -0.3232,  0.2042]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2562, -0.1667, -0.3382],\n",
       "                         [ 0.4438, -0.0654, -0.3722],\n",
       "                         [ 0.4407,  0.0365, -0.2193]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.3152,  0.0873,  0.3031],\n",
       "                         [ 0.0610, -0.1660,  0.2242],\n",
       "                         [-0.1884, -0.5412, -0.1346]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.3688, -0.0639, -0.1786],\n",
       "                         [ 0.3062, -0.0948, -0.2386],\n",
       "                         [ 0.2653, -0.1683, -0.2635]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.7828,  0.0577, -0.0940],\n",
       "                         [-0.7568, -0.2451,  0.0398],\n",
       "                         [-0.0092,  0.1886,  0.0483]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.3420,  0.3370,  0.0109],\n",
       "                         [-0.0290, -0.0404,  0.0482],\n",
       "                         [ 0.3715, -0.2758, -0.0872]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.7236,  0.5018,  0.2026],\n",
       "                         [-0.1227, -0.1799,  0.0677],\n",
       "                         [-0.5344, -0.6191, -0.2751]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0602,  0.6762, -0.0204],\n",
       "                         [ 0.1561,  0.1110, -0.1010],\n",
       "                         [-0.0647, -0.1790, -0.1988]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2791,  0.1729,  0.1869],\n",
       "                         [-0.0362, -0.1143,  0.1504],\n",
       "                         [-0.2574, -0.3654, -0.0730]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.3528, -0.3889,  0.0065],\n",
       "                         [-0.0991, -0.2684,  0.3252],\n",
       "                         [ 0.2106,  0.0989,  0.4745]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0099, -0.3886,  0.1743],\n",
       "                         [ 0.0686, -0.3331,  0.3094],\n",
       "                         [ 0.1569, -0.3243,  0.3138]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0860,  0.0374, -0.0422],\n",
       "                         [ 0.0598, -0.0854,  0.0050],\n",
       "                         [-0.0691,  0.0150, -0.1811]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.3442, -0.3261, -0.2653],\n",
       "                         [-0.0055,  0.0878,  0.0698],\n",
       "                         [-0.3644,  0.2903,  0.1612]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1661, -0.2233, -0.0200],\n",
       "                         [ 0.0016, -0.0335, -0.0131],\n",
       "                         [ 0.1602,  0.0966,  0.1737]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.3232,  0.2657,  0.2109],\n",
       "                         [-0.1425, -0.2329, -0.1423],\n",
       "                         [-0.2553, -0.0518, -0.1291]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1715, -0.0563, -0.1561],\n",
       "                         [ 0.0369,  0.1372,  0.0355],\n",
       "                         [ 0.0140,  0.2927,  0.0350]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1341, -0.0226,  0.1774],\n",
       "                         [-0.2099, -0.1773,  0.2238],\n",
       "                         [-0.1297, -0.1363,  0.1363]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.4165,  0.6610,  0.1256],\n",
       "                         [-0.1004,  0.0228, -0.0908],\n",
       "                         [-0.4585, -0.4517, -0.0872]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0555, -0.0712, -0.0282],\n",
       "                         [ 0.1571, -0.0017, -0.1062],\n",
       "                         [ 0.0776, -0.0243,  0.0384]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.5395, -0.0456, -0.1604],\n",
       "                         [ 0.5013,  0.0056, -0.1901],\n",
       "                         [-0.0680, -0.1741, -0.1085]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.3031, -0.6419, -0.3307],\n",
       "                         [-0.1248, -0.0218, -0.0455],\n",
       "                         [ 0.3839,  0.9088,  0.3798]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2267,  0.2769, -0.2835],\n",
       "                         [-0.1544,  0.5151, -0.2584],\n",
       "                         [-0.0947,  0.3758, -0.1394]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.3603, -0.3314,  0.0306],\n",
       "                         [ 0.2805, -0.2418,  0.0026],\n",
       "                         [ 0.2711, -0.3200, -0.0434]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1139,  0.1009, -0.0064],\n",
       "                         [ 0.0681,  0.0885,  0.0538],\n",
       "                         [ 0.0051,  0.1189, -0.0303]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.3268, -0.4008, -0.1548],\n",
       "                         [ 0.0412, -0.0306,  0.0747],\n",
       "                         [ 0.2473,  0.3988,  0.0220]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0372, -0.1914,  0.4420],\n",
       "                         [-0.2043, -0.2510,  0.4840],\n",
       "                         [-0.1368, -0.1469,  0.1775]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2146, -0.3354,  0.2823],\n",
       "                         [ 0.0927, -0.3353,  0.1551],\n",
       "                         [ 0.1572, -0.3828,  0.1795]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0980,  0.3031, -0.1369],\n",
       "                         [-0.0929,  0.4221, -0.0349],\n",
       "                         [-0.2566,  0.2240, -0.1506]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2023, -0.3688,  0.1302],\n",
       "                         [ 0.1748, -0.3024,  0.1465],\n",
       "                         [ 0.1679, -0.3206,  0.1753]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2543,  0.4120,  0.2431],\n",
       "                         [-0.2804,  0.1385, -0.0435],\n",
       "                         [-0.2638,  0.0622,  0.0067]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0122, -0.1674,  0.0883],\n",
       "                         [-0.0740, -0.1433,  0.0313],\n",
       "                         [-0.5172, -0.0494, -0.2105]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.2360, -0.3057, -0.0491],\n",
       "                         [-0.1089, -0.1574,  0.3111],\n",
       "                         [ 0.1428, -0.1198,  0.5193]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2242, -0.3921, -0.0244],\n",
       "                         [ 0.3311, -0.2490, -0.0360],\n",
       "                         [ 0.2455, -0.1948, -0.0187]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0763, -0.1031, -0.0343],\n",
       "                         [-0.0407, -0.1148, -0.0647],\n",
       "                         [ 0.1558,  0.2946,  0.1935]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1831, -0.2059,  0.5172],\n",
       "                         [-0.0928, -0.2154,  0.6640],\n",
       "                         [-0.1192, -0.3552,  0.3409]]]], device='cuda:0')),\n",
       "              ('conv_block1.conv2.weight',\n",
       "               tensor([[[[-4.9142e-02,  2.5395e-02, -1.1938e-01],\n",
       "                         [ 3.1104e-02, -1.9601e-02, -1.4443e-01],\n",
       "                         [ 4.9013e-03, -4.2269e-02,  1.2695e-02]],\n",
       "               \n",
       "                        [[ 1.6848e-01,  1.7858e-01, -7.5409e-03],\n",
       "                         [-2.2699e-02,  1.0027e-01,  2.1982e-02],\n",
       "                         [ 9.0394e-02, -2.8429e-02, -1.7272e-01]],\n",
       "               \n",
       "                        [[ 3.4617e-02, -8.0521e-02, -4.7544e-02],\n",
       "                         [ 1.7783e-02, -9.3200e-02, -1.0402e-02],\n",
       "                         [ 9.5905e-02, -7.7851e-02, -6.2054e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.6402e-03, -5.4282e-02, -2.2198e-01],\n",
       "                         [-4.2101e-02, -1.5230e-01, -3.8506e-01],\n",
       "                         [ 9.7056e-02, -2.0368e-01, -3.7699e-01]],\n",
       "               \n",
       "                        [[-2.6223e-03,  9.7682e-02, -1.0615e-03],\n",
       "                         [ 5.3786e-02, -1.9051e-04,  9.4447e-02],\n",
       "                         [ 1.6493e-02,  9.1679e-05,  1.4170e-01]],\n",
       "               \n",
       "                        [[-1.6367e-01,  1.4342e-02,  9.6053e-02],\n",
       "                         [-1.0429e-01,  2.0125e-02,  1.3272e-01],\n",
       "                         [-1.2712e-01, -2.7255e-02,  2.0107e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.7905e-03, -8.0560e-02,  1.6520e-01],\n",
       "                         [-5.8656e-02, -2.1610e-02,  7.9970e-02],\n",
       "                         [-5.6487e-02,  2.6337e-02, -1.2944e-02]],\n",
       "               \n",
       "                        [[ 4.4658e-01,  2.2412e-01, -2.3566e-01],\n",
       "                         [ 3.7599e-01,  1.4846e-01, -3.8348e-01],\n",
       "                         [ 5.0294e-01,  1.2520e-01, -4.4280e-01]],\n",
       "               \n",
       "                        [[ 4.6803e-03, -1.7430e-01, -2.0625e-01],\n",
       "                         [ 6.7611e-02, -6.9134e-02, -5.7049e-02],\n",
       "                         [ 1.5613e-01, -6.8043e-02, -5.8559e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.2296e-01, -9.6071e-02,  1.5896e-01],\n",
       "                         [ 3.2587e-01,  1.7658e-01,  1.9829e-02],\n",
       "                         [ 3.9674e-01,  5.8369e-01, -5.6292e-02]],\n",
       "               \n",
       "                        [[ 1.2132e-01,  4.4118e-02,  9.4236e-02],\n",
       "                         [-2.1494e-02,  2.4964e-02, -6.7713e-02],\n",
       "                         [ 6.2850e-02,  4.1711e-02, -2.9142e-02]],\n",
       "               \n",
       "                        [[-9.2182e-02, -1.2293e-01,  3.8064e-02],\n",
       "                         [-6.7095e-02, -4.5995e-02, -5.4118e-02],\n",
       "                         [-1.0773e-01, -2.0553e-02,  1.1409e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6422e-02, -2.0897e-01, -9.4710e-02],\n",
       "                         [-2.1810e-01, -1.9515e-01, -1.9115e-01],\n",
       "                         [-2.5376e-01, -4.5040e-02, -1.1375e-01]],\n",
       "               \n",
       "                        [[ 2.8983e-01, -4.9649e-02,  1.1354e-02],\n",
       "                         [-4.0081e-01, -6.1337e-01, -1.9118e-01],\n",
       "                         [ 1.3166e-01,  1.0581e-01,  1.5476e-01]],\n",
       "               \n",
       "                        [[-4.4238e-02,  4.6834e-02, -4.0094e-01],\n",
       "                         [ 1.0765e-01, -5.1774e-03, -3.6008e-01],\n",
       "                         [-1.3136e-02, -1.8998e-01, -2.4459e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.7489e-02, -1.8753e-02,  8.5318e-02],\n",
       "                         [ 1.0794e-01,  9.6893e-02, -4.0238e-02],\n",
       "                         [ 2.0089e-01,  1.1195e-01, -1.5733e-01]],\n",
       "               \n",
       "                        [[-1.6400e-02, -4.4544e-02, -1.4530e-02],\n",
       "                         [ 2.5545e-02,  5.3679e-02, -2.1843e-02],\n",
       "                         [ 7.8771e-02, -5.5159e-04,  1.3203e-01]],\n",
       "               \n",
       "                        [[ 5.2856e-02,  3.7675e-03, -7.3751e-02],\n",
       "                         [-6.4802e-02, -1.0590e-01, -1.0422e-01],\n",
       "                         [-1.4485e-01, -1.2933e-01, -3.8974e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-6.0228e-02, -7.8443e-02, -4.0069e-02],\n",
       "                         [-7.5711e-02, -1.0034e-01, -6.5003e-02],\n",
       "                         [ 9.2252e-02, -1.8502e-01, -1.2955e-01]],\n",
       "               \n",
       "                        [[ 4.5576e-01,  5.4267e-01,  9.7538e-02],\n",
       "                         [ 3.8984e-01,  2.9511e-01, -1.0169e-01],\n",
       "                         [ 1.6395e-01,  3.7995e-01,  9.7455e-02]],\n",
       "               \n",
       "                        [[-7.1889e-02, -6.8337e-02, -1.2392e-02],\n",
       "                         [ 1.7342e-02, -9.0599e-02, -2.0795e-01],\n",
       "                         [ 1.9666e-01,  1.1666e-01, -1.3498e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.7172e-02, -6.0703e-02,  2.8473e-02],\n",
       "                         [ 8.2005e-02,  5.6431e-03,  1.3377e-01],\n",
       "                         [ 1.3985e-01,  1.6690e-01,  1.6775e-01]],\n",
       "               \n",
       "                        [[ 2.0542e-02,  4.1517e-02,  1.0908e-02],\n",
       "                         [-8.4146e-03, -2.8939e-02, -5.2199e-02],\n",
       "                         [-2.1683e-02,  2.0720e-02,  1.5443e-03]],\n",
       "               \n",
       "                        [[ 6.2209e-03,  9.9380e-03, -7.9384e-02],\n",
       "                         [-3.0906e-04, -6.0291e-02,  1.1197e-02],\n",
       "                         [ 1.9034e-01,  1.0153e-01,  6.8644e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.3745e-02,  3.3226e-02, -1.2253e-01],\n",
       "                         [-5.4531e-02, -6.6365e-02, -1.4015e-01],\n",
       "                         [-5.3385e-02, -1.1101e-02, -8.9380e-02]],\n",
       "               \n",
       "                        [[-1.3943e-01, -7.6192e-01, -2.9488e-01],\n",
       "                         [-8.7030e-03, -6.4911e-01, -1.4065e-01],\n",
       "                         [-6.1784e-02, -2.6685e-01, -9.1178e-02]],\n",
       "               \n",
       "                        [[ 2.1112e-02, -8.2293e-02,  1.2613e-02],\n",
       "                         [-1.4596e-03, -1.0094e-01,  4.2988e-02],\n",
       "                         [ 5.4357e-04, -1.4447e-01,  6.3499e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.1333e-02, -4.3643e-01,  2.1323e-01],\n",
       "                         [ 8.6056e-02, -2.4346e-01,  2.6528e-02],\n",
       "                         [ 3.1853e-03, -1.8193e-01,  4.9609e-02]],\n",
       "               \n",
       "                        [[ 2.7808e-02, -1.5840e-02, -2.1024e-02],\n",
       "                         [-4.6308e-02, -5.9673e-02,  2.6165e-02],\n",
       "                         [-1.7404e-02, -3.2959e-02, -5.4088e-03]],\n",
       "               \n",
       "                        [[ 8.8206e-02,  6.4904e-02,  5.2724e-02],\n",
       "                         [-7.5373e-03,  1.6628e-01,  2.2451e-02],\n",
       "                         [-1.9987e-01,  2.0131e-03, -2.0417e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.1974e-02, -1.1486e-02,  1.7563e-01],\n",
       "                         [-5.1751e-02,  9.5833e-02,  2.2483e-01],\n",
       "                         [-2.8633e-02, -1.4564e-02,  2.6062e-01]],\n",
       "               \n",
       "                        [[ 2.1309e-02,  2.3268e-01,  2.1430e-01],\n",
       "                         [-3.8198e-01, -5.8423e-03,  6.0071e-02],\n",
       "                         [ 2.0712e-01,  1.4787e-01,  1.4930e-02]],\n",
       "               \n",
       "                        [[-1.3061e-01, -8.7126e-02,  1.3318e-01],\n",
       "                         [-2.2243e-01, -8.3264e-02,  2.1545e-01],\n",
       "                         [-1.7890e-01, -3.3045e-02,  3.0904e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.0294e-02, -2.2844e-01, -5.6481e-01],\n",
       "                         [-8.8579e-02, -2.5791e-01, -6.0626e-01],\n",
       "                         [ 1.0055e-02, -2.7297e-01, -6.8893e-01]],\n",
       "               \n",
       "                        [[ 3.6905e-02,  2.0349e-02, -2.2957e-03],\n",
       "                         [ 9.0113e-02,  5.8137e-02,  2.8834e-03],\n",
       "                         [ 1.0236e-01,  9.4707e-03,  1.1769e-01]],\n",
       "               \n",
       "                        [[-5.0298e-02, -5.9892e-02,  6.2037e-02],\n",
       "                         [-3.3029e-02, -1.5833e-01,  1.3209e-01],\n",
       "                         [-1.0213e-01, -6.7442e-02,  1.5417e-01]]]], device='cuda:0')),\n",
       "              ('conv_block1.bn1.weight',\n",
       "               tensor([0.6553, 1.4447, 0.9701, 0.5960, 1.8854, 0.6393, 0.2262, 0.5936, 0.4509,\n",
       "                       0.9444, 0.7513, 0.6152, 0.3758, 0.8656, 0.7464, 0.5782, 0.9586, 1.5850,\n",
       "                       0.4633, 0.8007, 0.9564, 1.2425, 1.1804, 0.6789, 0.6813, 0.7212, 0.8243,\n",
       "                       3.0827, 1.0387, 0.9261, 0.8606, 0.7329, 0.7342, 2.6411, 2.0561, 0.8993,\n",
       "                       0.4356, 0.3511, 0.7569, 1.0115, 0.4750, 1.5733, 0.4363, 0.6112, 0.4263,\n",
       "                       0.0483, 0.8879, 0.1698, 0.5692, 0.9532, 1.2465, 1.1441, 0.4972, 1.9180,\n",
       "                       0.6249, 0.9143, 0.7840, 1.6627, 0.5318, 1.3797, 1.0482, 0.9568, 0.3897,\n",
       "                       0.4526], device='cuda:0')),\n",
       "              ('conv_block1.bn1.bias',\n",
       "               tensor([ 3.9102e-02,  8.4704e-01,  4.0932e-02,  1.4111e-01,  6.3425e-01,\n",
       "                        4.8805e-02, -4.9594e-01, -7.5827e-01,  4.2271e-02, -1.2514e+00,\n",
       "                       -2.4498e-01,  2.0688e-03, -2.9545e-04,  1.7675e-02,  2.7359e-02,\n",
       "                        1.6175e-01,  8.5287e-03,  7.3221e-02,  2.0140e-02,  4.0643e-01,\n",
       "                       -4.8491e-04,  1.2706e-01,  1.7983e-01,  7.9201e-02,  3.7533e-02,\n",
       "                        1.4491e-01,  9.2963e-04,  9.5956e-01,  7.0543e-02,  7.9944e-03,\n",
       "                        3.3280e-02, -5.6804e-01,  2.1030e-02,  1.3534e-02, -1.4394e-02,\n",
       "                        2.6375e-02, -1.7705e-01,  4.3081e-02,  2.0442e-02,  1.5813e-01,\n",
       "                       -3.5657e-01,  1.2814e-01, -5.0947e-01,  1.9751e-01, -3.0249e-01,\n",
       "                       -3.7700e-01, -2.3522e-01, -8.4090e-02, -4.3160e-01,  1.1493e-01,\n",
       "                        6.5336e-02,  2.9330e-02, -6.4337e-01,  7.8146e-02, -2.7211e-01,\n",
       "                        1.6056e-02, -8.4296e-01,  2.3115e-02,  8.5323e-02,  2.8212e-01,\n",
       "                        1.6381e-01,  5.2664e-02, -5.2534e-01,  3.2656e-02], device='cuda:0')),\n",
       "              ('conv_block1.bn1.running_mean',\n",
       "               tensor([-3.0592e-04,  2.8138e-04, -3.3488e-03, -6.0907e-03,  8.4234e-04,\n",
       "                        3.9319e-03,  9.8627e-03, -1.4041e-02,  4.2418e-03, -4.9714e-04,\n",
       "                       -1.2892e-02, -2.1562e-04,  2.8759e-02, -3.5341e-03,  4.4057e-03,\n",
       "                       -8.8784e-03, -9.8800e-03, -2.3166e-03, -1.5857e-03, -2.2854e-03,\n",
       "                        2.7584e-03,  4.7124e-03,  2.0419e-03,  1.7152e-03, -1.1610e-03,\n",
       "                       -2.6852e-03,  6.9535e-03, -1.8980e-04,  1.5370e-04, -2.8489e-04,\n",
       "                        5.4008e-03, -1.9554e-03,  9.2105e-04,  8.0559e-04, -2.1455e-04,\n",
       "                       -9.6898e-03,  1.9601e-02, -2.9515e-03, -1.9890e-03, -2.4660e-03,\n",
       "                       -1.4370e-02, -3.5334e-04, -1.2827e-03, -6.4170e-03,  6.9038e-03,\n",
       "                       -1.3784e-02,  1.3584e-03,  4.9966e-03,  1.6011e-02,  8.5637e-03,\n",
       "                        5.7386e-04,  2.5906e-03,  1.1828e-02, -5.4713e-03,  2.4695e-03,\n",
       "                        9.5391e-04,  1.5817e-02,  5.8647e-04, -1.4631e-03,  6.5204e-05,\n",
       "                       -2.3316e-03, -2.6770e-03,  8.7598e-03,  1.0552e-02], device='cuda:0')),\n",
       "              ('conv_block1.bn1.running_var',\n",
       "               tensor([0.0615, 0.0395, 0.0490, 0.0394, 0.0346, 0.0703, 0.0381, 0.0790, 0.0315,\n",
       "                       0.0098, 0.0728, 0.0320, 0.3044, 0.0733, 0.1736, 0.0685, 0.0797, 0.0702,\n",
       "                       0.0288, 0.0851, 0.0397, 0.0697, 0.0896, 0.0572, 0.0348, 0.0661, 0.0524,\n",
       "                       0.0086, 0.0054, 0.0508, 0.1867, 0.0450, 0.1201, 0.0148, 0.0036, 0.1242,\n",
       "                       0.1656, 0.0280, 0.0847, 0.0663, 0.0761, 0.0066, 0.0095, 0.0323, 0.0304,\n",
       "                       0.0969, 0.0548, 0.0127, 0.1507, 0.1205, 0.0646, 0.0703, 0.0567, 0.0358,\n",
       "                       0.1232, 0.0510, 0.1358, 0.0438, 0.0630, 0.0510, 0.0701, 0.0730, 0.0361,\n",
       "                       0.2631], device='cuda:0')),\n",
       "              ('conv_block1.bn1.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('conv_block1.bn2.weight',\n",
       "               tensor([0.8587, 0.9704, 1.3056, 0.7613, 1.1892, 1.0331, 1.2325, 0.6618, 1.0574,\n",
       "                       0.9424, 0.8996, 1.1131, 0.9843, 0.7583, 0.7273, 0.7195, 0.6503, 1.0389,\n",
       "                       1.5975, 0.6125, 0.8826, 0.4833, 0.8731, 1.2290, 0.8372, 0.9082, 1.0973,\n",
       "                       0.8108, 1.2184, 1.1153, 1.7855, 1.1705, 1.4667, 1.1013, 0.6332, 1.1646,\n",
       "                       0.8341, 1.0502, 1.2837, 1.4732, 1.0801, 1.0316, 0.7010, 1.1494, 0.6073,\n",
       "                       0.8261, 1.1545, 0.7609, 1.4792, 0.8261, 0.9575, 1.4568, 1.6160, 1.1732,\n",
       "                       0.8168, 1.1276, 0.8832, 1.1139, 0.8861, 1.1987, 0.6639, 0.5606, 0.8099,\n",
       "                       1.3036], device='cuda:0')),\n",
       "              ('conv_block1.bn2.bias',\n",
       "               tensor([-0.4448, -0.5225, -0.8067, -0.3565, -0.5041, -0.4967, -0.7807, -0.2311,\n",
       "                       -0.3567, -0.7498, -0.2369, -0.5954, -0.3276, -0.3618, -0.4151, -0.3005,\n",
       "                       -0.2256, -0.6227, -1.0262, -0.6006, -0.3833, -0.0854, -0.4663, -0.9039,\n",
       "                       -0.6290, -0.3083, -0.5985, -0.2983, -0.7576, -0.6182, -0.7921, -0.6240,\n",
       "                       -0.6120, -0.4508, -0.1827, -0.8516, -0.3769, -0.4128, -0.5706, -1.1526,\n",
       "                       -0.6603, -0.6124, -0.1744, -0.5998, -0.3872, -0.2883, -0.6186, -0.3605,\n",
       "                       -0.8478, -0.2933, -0.2694, -0.8218, -0.9612, -0.7445, -0.2912, -0.4928,\n",
       "                       -0.3532, -0.6766, -0.4406, -0.6267, -0.3206, -0.2539, -0.2869, -0.6072],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn2.running_mean',\n",
       "               tensor([-5.7398e+00, -4.3365e+00, -8.1248e+00, -5.7168e+00, -5.1071e+00,\n",
       "                       -5.8539e+00, -5.9982e+00, -1.5113e+00, -4.7692e+00, -3.5862e+00,\n",
       "                       -5.2765e+00, -7.4514e+00, -5.6395e+00, -5.7641e+00, -1.3357e+00,\n",
       "                       -8.6189e+00, -1.7679e-01, -6.0508e+00, -5.2457e+00,  3.3312e+00,\n",
       "                       -2.5444e+00, -6.1859e+00, -3.5819e+00, -5.6910e+00,  1.8635e+00,\n",
       "                       -8.9760e+00, -6.1609e+00, -3.3239e+00, -9.4108e+00, -3.5501e+00,\n",
       "                       -8.7460e+00, -7.1782e+00, -6.0650e+00, -5.2711e+00,  1.5605e+00,\n",
       "                       -4.1849e+00, -9.0497e+00, -4.6816e+00, -4.7707e+00, -5.5746e+00,\n",
       "                       -2.5759e+00, -1.2453e+01, -4.6790e+00, -6.7140e+00, -1.0220e-02,\n",
       "                       -3.5938e+00, -2.7784e+00, -6.1097e+00, -1.0700e+01, -4.4241e+00,\n",
       "                       -5.0203e+00, -2.6869e+00, -3.6751e+00, -6.1454e+00, -1.2842e+01,\n",
       "                       -8.4179e+00, -4.1720e+00, -5.8070e+00, -2.9029e+00, -6.5555e+00,\n",
       "                       -9.6669e+00, -5.4431e+00, -6.7816e+00, -7.1270e+00], device='cuda:0')),\n",
       "              ('conv_block1.bn2.running_var',\n",
       "               tensor([ 46.4199,  42.1192,  86.8460,  47.5814,  64.3981,  54.1500,  46.7986,\n",
       "                        33.0753,  81.6310,  13.9879,  33.2186,  88.7937,  98.2933,  44.5807,\n",
       "                        11.5334,  39.6013,  22.8973,  48.5208,  81.7247,  45.2987,  25.8292,\n",
       "                        86.0630,  23.2142,  48.5346,  15.7777, 126.4694,  56.9320,  31.7835,\n",
       "                        93.8972,  24.2247, 245.4235,  87.8127, 147.7630,  34.4062,  28.8566,\n",
       "                        24.8651, 127.2659,  47.4192,  66.9541,  42.7648,  24.1481, 136.8358,\n",
       "                        49.3115,  83.7059,  51.2297,  62.4318,  29.1565,  26.8023, 234.3195,\n",
       "                        43.3504,  70.4468,  29.0490,  34.1461,  44.8933, 115.3081, 189.3707,\n",
       "                        85.2027,  43.2920,  32.6473,  89.9137, 125.2333,  83.6581,  97.8155,\n",
       "                       229.3917], device='cuda:0')),\n",
       "              ('conv_block1.bn2.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('conv_block2.conv1.weight',\n",
       "               tensor([[[[-1.5110e-01,  1.3503e-01, -1.0102e-01],\n",
       "                         [ 9.7553e-02,  3.1854e-01, -1.2843e-01],\n",
       "                         [-6.1337e-01,  2.5019e-01,  8.4160e-02]],\n",
       "               \n",
       "                        [[ 2.0339e-01, -1.1274e-02, -3.5133e-01],\n",
       "                         [ 4.3284e-01, -2.1179e-02, -5.7952e-02],\n",
       "                         [-2.1718e-01,  1.6343e-01,  8.4145e-02]],\n",
       "               \n",
       "                        [[-1.9224e-01,  1.6789e-03,  1.1744e-01],\n",
       "                         [ 4.4394e-02, -7.4914e-02, -9.7350e-02],\n",
       "                         [-1.6682e-01,  9.3457e-02,  3.5095e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.4826e-02, -4.8181e-01, -2.6025e-01],\n",
       "                         [ 3.4583e-01, -3.6386e-02,  2.6422e-02],\n",
       "                         [-3.3564e-02, -2.7353e-01, -1.8137e-01]],\n",
       "               \n",
       "                        [[-1.9673e-02,  5.2423e-02,  1.0784e-01],\n",
       "                         [-1.6963e-01, -1.9776e-01, -1.8046e-01],\n",
       "                         [-2.2464e-02, -6.0388e-02, -2.1563e-01]],\n",
       "               \n",
       "                        [[ 5.0165e-02, -1.2229e-01, -8.4337e-02],\n",
       "                         [-4.9170e-02, -1.2559e-01, -1.0655e-01],\n",
       "                         [-1.4511e-01,  8.3476e-02, -1.6425e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.9726e-02, -6.3504e-02, -1.2227e-01],\n",
       "                         [ 4.4030e-02,  2.2068e-01,  3.2973e-02],\n",
       "                         [-1.6700e-01, -6.1817e-02,  1.4027e-02]],\n",
       "               \n",
       "                        [[-2.4147e-02, -7.0568e-02, -3.6102e-01],\n",
       "                         [-3.9529e-01, -2.0079e-01,  1.0545e-01],\n",
       "                         [-5.0595e-01, -3.7398e-01, -8.5883e-02]],\n",
       "               \n",
       "                        [[ 3.3949e-03, -5.6692e-01, -1.9232e-01],\n",
       "                         [ 1.7410e-01,  1.5078e-03, -4.9469e-02],\n",
       "                         [-3.9548e-01, -3.6804e-02, -8.3537e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.9415e-01, -1.9231e-01, -4.5976e-01],\n",
       "                         [-5.5332e-01,  1.2117e-01,  7.3299e-03],\n",
       "                         [-1.0217e-02, -6.9638e-02,  1.0716e-01]],\n",
       "               \n",
       "                        [[ 1.3195e-01,  1.3666e-01,  3.4602e-02],\n",
       "                         [ 8.0504e-02, -3.2054e-02, -2.8811e-01],\n",
       "                         [ 1.2295e-01,  1.0401e-02, -1.1944e-01]],\n",
       "               \n",
       "                        [[ 1.7167e-01,  4.7451e-02,  8.9339e-02],\n",
       "                         [ 8.4860e-02,  8.8208e-02,  1.2865e-02],\n",
       "                         [-7.3349e-03, -2.8073e-03,  2.2170e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.4400e-01,  2.0376e-01,  6.3798e-02],\n",
       "                         [-1.2965e-02,  2.8779e-02, -1.2671e-01],\n",
       "                         [ 1.4557e-01,  6.3578e-03, -5.6230e-02]],\n",
       "               \n",
       "                        [[-1.4252e-02,  9.5044e-02,  2.6917e-01],\n",
       "                         [-1.1161e-01, -8.8523e-02, -1.1338e-01],\n",
       "                         [ 1.3448e-03, -1.1073e-01, -9.2584e-02]],\n",
       "               \n",
       "                        [[-3.5019e-01,  1.8951e-02, -1.3619e-01],\n",
       "                         [-1.2177e-01, -7.2601e-03, -1.6653e-02],\n",
       "                         [ 7.8704e-03,  1.0822e-01,  6.3137e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.4017e-02,  1.2986e-01, -5.3525e-02],\n",
       "                         [-7.2693e-02, -4.3268e-02, -1.3314e-01],\n",
       "                         [ 8.7017e-02,  7.6350e-02, -1.8972e-02]],\n",
       "               \n",
       "                        [[-1.3353e-01,  7.0051e-02,  2.1111e-02],\n",
       "                         [-1.3496e-01, -7.9272e-02, -3.6497e-02],\n",
       "                         [-1.1907e-01,  1.2515e-02, -7.5224e-02]],\n",
       "               \n",
       "                        [[ 4.0777e-02, -2.5794e-02,  6.5573e-02],\n",
       "                         [ 6.1300e-02,  1.9028e-02,  1.3536e-01],\n",
       "                         [ 1.8407e-02,  3.5518e-02,  5.7093e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 8.1359e-02,  4.4479e-02,  4.8502e-02],\n",
       "                         [ 3.1730e-02, -1.5356e-04,  5.6755e-02],\n",
       "                         [ 3.4925e-02, -3.0876e-02,  6.7755e-02]],\n",
       "               \n",
       "                        [[-7.9658e-02,  1.5074e-01,  6.7361e-02],\n",
       "                         [-6.9093e-02, -1.0542e-02,  4.8134e-02],\n",
       "                         [-1.2800e-01, -2.9678e-03, -3.4286e-02]],\n",
       "               \n",
       "                        [[-1.2514e-01,  3.5646e-02, -1.4526e-02],\n",
       "                         [-7.9003e-02,  1.0573e-01,  6.1554e-02],\n",
       "                         [-1.0636e-02,  1.1965e-01,  4.9152e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.2308e-02, -7.1824e-02, -8.9665e-02],\n",
       "                         [-8.0287e-04, -4.4449e-02, -5.8730e-03],\n",
       "                         [-1.2068e-01, -2.0864e-02, -6.7787e-02]],\n",
       "               \n",
       "                        [[ 3.6990e-02,  3.9649e-02, -4.2124e-02],\n",
       "                         [ 1.0475e-01,  7.5673e-02,  4.9471e-02],\n",
       "                         [ 5.3236e-02,  9.3618e-02, -1.7393e-02]],\n",
       "               \n",
       "                        [[-6.1092e-02, -1.8631e-01, -1.4665e-01],\n",
       "                         [-9.4728e-03, -1.7765e-01, -1.6757e-01],\n",
       "                         [-3.1130e-02, -6.9184e-02, -8.9206e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.4683e-01,  2.2816e-03,  8.3461e-03],\n",
       "                         [-6.9661e-01, -3.1495e-01, -2.1644e-01],\n",
       "                         [-4.4841e-01, -2.2396e-01, -1.4007e-01]],\n",
       "               \n",
       "                        [[-2.0258e-01,  9.9890e-02, -1.1240e-01],\n",
       "                         [-3.9299e-01, -1.0584e-01, -3.9719e-02],\n",
       "                         [-1.1935e-01, -8.5893e-02,  1.1398e-02]],\n",
       "               \n",
       "                        [[ 1.5359e-02,  4.1312e-02, -8.1840e-02],\n",
       "                         [-8.4533e-02,  2.1932e-02, -7.2170e-02],\n",
       "                         [-7.0572e-02,  9.2711e-03, -3.7969e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.3857e-01,  1.5983e-02, -1.1157e-01],\n",
       "                         [-1.5709e-01, -1.6580e-01, -9.9468e-03],\n",
       "                         [-7.8369e-03, -1.9027e-01,  6.2960e-02]],\n",
       "               \n",
       "                        [[ 7.6012e-02, -7.9495e-03,  5.8566e-02],\n",
       "                         [ 1.1096e-01, -3.0222e-01,  7.8107e-02],\n",
       "                         [-1.5229e-02, -1.9138e-01, -1.0883e-01]],\n",
       "               \n",
       "                        [[ 3.1952e-01,  6.4331e-02, -1.3258e-01],\n",
       "                         [-4.3449e-02,  4.6787e-02, -2.2557e-01],\n",
       "                         [ 1.5991e-01,  1.4433e-01, -1.9999e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.8379e-01,  1.0894e-01,  3.6723e-02],\n",
       "                         [ 1.5722e-01,  1.4035e-01,  1.4989e-01],\n",
       "                         [ 3.2281e-01,  1.0939e-01,  1.3618e-01]],\n",
       "               \n",
       "                        [[-2.9397e-01,  1.3120e-01, -2.3556e-01],\n",
       "                         [-5.7988e-01,  1.0786e-01, -1.4613e-01],\n",
       "                         [-3.5738e-01,  5.1252e-04, -2.1530e-02]],\n",
       "               \n",
       "                        [[-1.1438e-01,  3.3724e-02, -2.0976e-01],\n",
       "                         [-3.7379e-01,  3.6457e-02, -1.5471e-01],\n",
       "                         [-8.3097e-02, -7.7792e-03, -1.3956e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.0867e-01,  2.1979e-01,  1.0463e-01],\n",
       "                         [-1.3832e-01,  2.3746e-01,  1.8706e-01],\n",
       "                         [ 1.4285e-01,  2.6500e-02,  7.7543e-02]],\n",
       "               \n",
       "                        [[ 2.7106e-01,  8.9446e-02, -4.5626e-02],\n",
       "                         [ 3.6687e-01,  5.5231e-02,  1.5870e-02],\n",
       "                         [ 1.2033e-01, -3.5803e-03, -3.5746e-01]],\n",
       "               \n",
       "                        [[ 2.6022e-01,  3.5473e-02, -1.4612e-01],\n",
       "                         [ 1.3475e-01, -4.7419e-02, -2.0802e-01],\n",
       "                         [ 6.5647e-01,  1.2689e-01, -1.0744e-01]]]], device='cuda:0')),\n",
       "              ('conv_block2.conv2.weight',\n",
       "               tensor([[[[ 0.0797, -0.3871,  0.5035],\n",
       "                         [-0.2373, -0.0787,  0.2153],\n",
       "                         [-0.1183, -0.2157,  0.3208]],\n",
       "               \n",
       "                        [[-0.0686,  0.3516, -0.2898],\n",
       "                         [ 0.0087,  0.2189, -0.1356],\n",
       "                         [ 0.0517,  0.1688, -0.1237]],\n",
       "               \n",
       "                        [[ 0.0030,  0.1728,  0.0477],\n",
       "                         [-0.1796,  0.0897,  0.0118],\n",
       "                         [-0.1988, -0.0262,  0.0624]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1444,  0.0239,  0.0125],\n",
       "                         [-0.0925,  0.0422,  0.0391],\n",
       "                         [-0.1047,  0.1023, -0.0581]],\n",
       "               \n",
       "                        [[-0.0468,  0.1002,  0.1916],\n",
       "                         [-0.0624,  0.2386,  0.2517],\n",
       "                         [-0.1446,  0.1494,  0.2475]],\n",
       "               \n",
       "                        [[-0.0966,  0.2884, -0.4524],\n",
       "                         [-0.1268,  0.3346, -0.2175],\n",
       "                         [-0.0740,  0.1566, -0.1751]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1284, -0.0303,  0.0225],\n",
       "                         [-0.0252, -0.0076,  0.0151],\n",
       "                         [-0.1621, -0.2828,  0.1166]],\n",
       "               \n",
       "                        [[-0.0044,  0.0978, -0.0438],\n",
       "                         [-0.1729,  0.0405, -0.0230],\n",
       "                         [-0.2114,  0.1906, -0.0518]],\n",
       "               \n",
       "                        [[-0.1388, -0.0682, -0.1021],\n",
       "                         [-0.1586, -0.0376,  0.0043],\n",
       "                         [-0.0128, -0.0024,  0.0436]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0421, -0.0517,  0.0128],\n",
       "                         [ 0.0432, -0.0314,  0.0379],\n",
       "                         [ 0.0409,  0.0295,  0.0043]],\n",
       "               \n",
       "                        [[ 0.0495, -0.0550,  0.0072],\n",
       "                         [-0.0060, -0.0473,  0.0175],\n",
       "                         [-0.0156, -0.1210, -0.0551]],\n",
       "               \n",
       "                        [[ 0.4114,  0.1922, -0.1124],\n",
       "                         [ 0.1185,  0.0129, -0.4638],\n",
       "                         [ 0.2652,  0.2713, -0.0477]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1424,  0.0649, -0.2431],\n",
       "                         [-0.1870,  0.1177,  0.0712],\n",
       "                         [-0.0155, -0.1642,  0.4759]],\n",
       "               \n",
       "                        [[ 0.0413, -0.0774,  0.0206],\n",
       "                         [-0.0279,  0.2316,  0.0538],\n",
       "                         [-0.1423,  0.3639,  0.1203]],\n",
       "               \n",
       "                        [[-0.0900, -0.0133,  0.0699],\n",
       "                         [-0.0525, -0.0764, -0.0410],\n",
       "                         [ 0.1294, -0.0695, -0.0105]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0821, -0.0837, -0.0200],\n",
       "                         [ 0.0601, -0.0396, -0.1105],\n",
       "                         [-0.0523,  0.0348,  0.0440]],\n",
       "               \n",
       "                        [[-0.0578, -0.0975, -0.0058],\n",
       "                         [ 0.1001, -0.2627, -0.1528],\n",
       "                         [ 0.3450,  0.0607, -0.0994]],\n",
       "               \n",
       "                        [[-0.0161, -0.1702, -0.0764],\n",
       "                         [-0.0285,  0.0592, -0.1216],\n",
       "                         [-0.1549,  0.0483,  0.0363]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-0.0231, -0.0543, -0.0007],\n",
       "                         [-0.0492, -0.0366, -0.0205],\n",
       "                         [-0.0358,  0.0342,  0.0288]],\n",
       "               \n",
       "                        [[-0.0778, -0.1418, -0.1752],\n",
       "                         [ 0.0278, -0.0811, -0.1143],\n",
       "                         [ 0.0019, -0.0756, -0.0591]],\n",
       "               \n",
       "                        [[ 0.0567,  0.0313,  0.1154],\n",
       "                         [-0.0307, -0.0224, -0.0297],\n",
       "                         [-0.0523, -0.0485,  0.0594]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0369,  0.0246,  0.0163],\n",
       "                         [ 0.0076, -0.0387,  0.0074],\n",
       "                         [ 0.0304,  0.0167, -0.0222]],\n",
       "               \n",
       "                        [[-0.0467,  0.0240, -0.0145],\n",
       "                         [-0.1613, -0.1165, -0.0286],\n",
       "                         [-0.1176, -0.2201, -0.2743]],\n",
       "               \n",
       "                        [[-0.0315, -0.0845,  0.0885],\n",
       "                         [-0.0614, -0.0593, -0.0716],\n",
       "                         [ 0.0536, -0.0150, -0.1346]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1593,  0.1238,  0.2519],\n",
       "                         [ 0.0645,  0.1702,  0.0885],\n",
       "                         [ 0.0346,  0.1523,  0.0077]],\n",
       "               \n",
       "                        [[-0.3018, -0.0646, -0.2673],\n",
       "                         [-0.6602,  0.0502,  0.2141],\n",
       "                         [-0.2111,  0.0541,  0.2559]],\n",
       "               \n",
       "                        [[-0.1972,  0.1716,  0.0871],\n",
       "                         [-0.1216,  0.2636,  0.3183],\n",
       "                         [-0.0168,  0.1901,  0.2926]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0608,  0.0780, -0.0209],\n",
       "                         [-0.0174,  0.1029,  0.0251],\n",
       "                         [ 0.0625,  0.1221, -0.0031]],\n",
       "               \n",
       "                        [[-0.0735, -0.2186, -0.2051],\n",
       "                         [-0.0981, -0.1618, -0.1645],\n",
       "                         [-0.0628, -0.1308,  0.1866]],\n",
       "               \n",
       "                        [[ 0.5273,  0.1040, -0.1305],\n",
       "                         [-0.1214, -0.3617, -0.1028],\n",
       "                         [-0.6668, -0.5498,  0.0355]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.0758, -0.2308, -0.0406],\n",
       "                         [-0.1231, -0.1019,  0.0389],\n",
       "                         [-0.0008,  0.0102,  0.1287]],\n",
       "               \n",
       "                        [[ 0.0366, -0.3016,  0.0376],\n",
       "                         [ 0.0452, -0.2435,  0.1378],\n",
       "                         [ 0.4957,  0.1947,  0.4788]],\n",
       "               \n",
       "                        [[-0.2224, -0.2306,  0.0041],\n",
       "                         [-0.0273, -0.0785,  0.1272],\n",
       "                         [-0.0843, -0.2468, -0.1096]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0803, -0.0073,  0.0982],\n",
       "                         [ 0.1519, -0.0470,  0.0242],\n",
       "                         [ 0.1086,  0.0479,  0.0547]],\n",
       "               \n",
       "                        [[ 0.1747,  0.2013,  0.0624],\n",
       "                         [ 0.1020,  0.1047, -0.1400],\n",
       "                         [ 0.0945,  0.0114, -0.0861]],\n",
       "               \n",
       "                        [[ 0.2003,  0.1190,  0.0771],\n",
       "                         [ 0.0303,  0.0949,  0.0738],\n",
       "                         [-0.0213,  0.0166, -0.0702]]]], device='cuda:0')),\n",
       "              ('conv_block2.bn1.weight',\n",
       "               tensor([0.9333, 1.3117, 1.0064, 1.1902, 1.2580, 1.1070, 0.7400, 0.6683, 1.1058,\n",
       "                       0.7843, 0.8634, 0.6649, 1.0229, 0.9739, 1.1344, 1.2514, 0.9304, 0.8597,\n",
       "                       0.8270, 0.8555, 0.8859, 1.1646, 1.1771, 0.9417, 1.1203, 0.3909, 1.1477,\n",
       "                       0.8333, 0.5321, 1.2610, 1.3263, 0.8746, 1.1299, 1.0619, 1.1533, 0.6593,\n",
       "                       1.2325, 1.3450, 0.7902, 0.8904, 1.3208, 1.1881, 0.9805, 0.9504, 0.8138,\n",
       "                       0.9455, 1.0619, 0.8078, 0.9678, 0.3681, 0.7779, 1.3958, 0.9578, 1.1503,\n",
       "                       1.0190, 1.0396, 1.1622, 1.1699, 0.9783, 0.8104, 0.8871, 1.4934, 0.8819,\n",
       "                       1.3788, 1.3836, 1.2289, 1.0448, 0.7249, 1.2897, 1.1332, 1.0075, 0.5817,\n",
       "                       0.6852, 1.1921, 1.1319, 0.7448, 1.0434, 0.9752, 0.6360, 1.4134, 1.2608,\n",
       "                       0.9091, 0.9421, 0.9905, 0.9649, 1.6889, 0.8706, 1.2084, 1.2491, 0.9672,\n",
       "                       1.0387, 0.8248, 0.9659, 0.5598, 1.2549, 1.0637, 1.1366, 1.1338, 1.0275,\n",
       "                       1.0829, 1.4310, 0.8750, 1.3612, 1.1565, 1.1270, 1.0064, 1.1299, 0.6905,\n",
       "                       1.0858, 1.2049, 1.1659, 0.7669, 1.3817, 1.3682, 1.4582, 1.0517, 0.8336,\n",
       "                       1.2199, 0.9837, 1.1531, 1.1891, 1.6512, 1.1635, 1.0491, 0.7430, 0.8552,\n",
       "                       0.8882, 0.8604], device='cuda:0')),\n",
       "              ('conv_block2.bn1.bias',\n",
       "               tensor([ 0.2046, -0.3843, -0.7180, -0.4804, -0.5526, -0.4407, -0.4571, -0.2030,\n",
       "                       -0.2647, -0.5744, -0.1887, -0.2392, -0.4655, -0.5098, -0.7115, -0.2514,\n",
       "                       -0.6326, -0.5320, -0.4235,  1.0628, -0.3897, -0.5310, -0.3274,  0.1692,\n",
       "                       -0.4381, -0.1100, -0.5517, -0.8487, -0.2616, -0.1480, -0.6864, -0.1624,\n",
       "                       -0.5747, -0.2562, -0.4154, -0.7018, -0.4028, -0.2358, -0.1142, -0.7853,\n",
       "                       -0.7085, -0.6953, -0.3770, -0.6254, -0.2948, -0.9695, -0.0988, -0.2806,\n",
       "                       -0.4663,  0.0348, -0.5522,  0.0299, -0.1829, -0.1758, -0.3393,  0.0064,\n",
       "                       -1.0844, -0.6388, -0.6373, -0.8985, -0.6587, -0.6774, -0.1981, -0.7275,\n",
       "                       -0.5321, -1.7811, -0.0098, -0.3322, -0.6925, -0.0170, -0.1630, -0.1494,\n",
       "                        0.2793, -0.4638, -0.2338, -0.4690, -0.6534, -0.2212, -0.3258, -1.2226,\n",
       "                       -0.2307, -0.3708, -0.1794, -0.4172, -0.1977, -2.2159, -0.5076, -0.4029,\n",
       "                       -0.3232, -0.9295, -0.1670, -0.3123, -0.2329, -0.6574,  0.0604, -0.7209,\n",
       "                       -0.3639, -0.2349, -0.4163, -0.5154, -0.8322, -0.5202, -0.1775, -0.6088,\n",
       "                       -0.5479, -0.8332, -0.4693,  0.4462, -0.6285, -1.0444, -0.0081, -0.7946,\n",
       "                       -0.5242, -0.7978, -1.0212, -0.1782, -0.5085, -0.8286, -0.4592, -0.6703,\n",
       "                       -0.3796, -0.8652, -0.3797, -0.8148, -0.9630, -1.0912, -0.4927, -0.1822],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.running_mean',\n",
       "               tensor([-1.3859, -1.6866, -1.8652, -0.4663, -2.0757, -2.6752,  0.1180, -1.7302,\n",
       "                       -0.9804, -0.6873, -0.9187, -1.6970, -0.5509, -0.1107, -1.8497, -1.8334,\n",
       "                       -2.3273, -0.3002,  0.0962, -2.6266, -0.8715, -0.5707, -3.2133, -1.5963,\n",
       "                       -2.5621, -0.4674, -0.5045,  0.3840, -1.5164, -1.6512, -0.6097, -2.4698,\n",
       "                       -1.2845, -0.7744, -1.7214,  2.1628, -1.8506, -1.3805, -0.7214,  1.1448,\n",
       "                       -1.6712, -1.4251, -2.3814, -1.2359,  0.6016, -1.8500, -0.5886, -0.1566,\n",
       "                       -1.0596,  0.6178, -1.0551, -1.2369, -0.4769, -1.6470, -1.4601, -2.7201,\n",
       "                       -1.7761, -1.5893, -1.4597, -1.2787, -1.1191, -1.8598, -1.5894, -1.4126,\n",
       "                       -1.3955, -1.7443, -0.9146, -2.1831, -2.0840, -1.6225, -0.7467, -0.1052,\n",
       "                       -0.7411, -1.1667, -3.1216, -1.6980, -0.6078, -0.9798,  0.6699, -1.5450,\n",
       "                       -1.3040, -0.4572, -1.2525, -0.6055, -0.2427, -0.6538, -0.6007, -0.7253,\n",
       "                       -1.2379, -0.5438, -1.5133, -0.3759, -1.2275, -0.4799, -1.9311, -0.6307,\n",
       "                       -0.4377, -0.4722, -0.6076, -2.0668, -2.5519, -1.0706, -1.9640, -2.0175,\n",
       "                       -2.3049, -0.6890, -2.3250, -0.9242, -0.4154, -2.0492, -1.5492, -0.4940,\n",
       "                       -0.9571, -1.9696, -1.9298, -3.2423, -0.3399, -1.4103, -1.0639, -0.4764,\n",
       "                       -0.7077, -3.8586, -1.2353, -1.9120, -0.3728, -0.2988, -2.6787, -0.9085],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.running_var',\n",
       "               tensor([ 2.4387,  4.4098,  3.7103,  0.8814,  7.6579,  4.2610,  0.3769,  2.8435,\n",
       "                        0.8979,  1.3557,  3.1373,  3.1868,  0.7006,  0.9512,  3.1183,  5.1244,\n",
       "                        2.9639,  0.7168,  0.2497, 12.3714,  1.9849,  1.2979, 10.0594,  7.4952,\n",
       "                        7.1781,  1.5642,  1.3094,  0.5600,  4.4137,  6.0322,  0.6966,  3.1222,\n",
       "                        1.2118,  0.9359,  2.1505,  1.8964,  2.2795,  1.8802,  0.8539,  0.6649,\n",
       "                        2.0668,  1.5715,  5.9139,  0.6458,  0.5213,  2.4468,  0.6000,  2.3179,\n",
       "                        2.7289,  6.2990,  1.6526,  6.9815,  0.6089,  9.7465,  4.0116,  3.2234,\n",
       "                        1.2788,  2.7086,  2.1092,  1.1735,  2.0457,  2.7161,  2.6395,  3.9574,\n",
       "                        2.5935,  2.1538,  1.0770,  3.6015,  2.8705,  8.6046,  0.4368,  1.7570,\n",
       "                        5.5298,  3.8491,  6.8588,  3.2597,  0.5369,  5.2923,  0.7033,  1.7189,\n",
       "                        2.0224,  0.7310,  2.2425,  0.6036,  3.4983,  1.4823,  0.4497,  1.6666,\n",
       "                        0.9415,  0.3554,  5.5660,  1.9032,  1.4063,  0.3885,  6.5221,  2.5425,\n",
       "                        1.8085,  1.8028,  1.2295,  1.2515,  5.7116,  1.9196,  7.5368,  3.2321,\n",
       "                        2.5906,  0.7385,  4.5713,  1.5906,  0.7428,  1.1987,  4.4036,  0.4242,\n",
       "                        2.5738,  3.7638,  3.2943,  5.1213,  0.5879,  1.8340,  1.8038,  0.9996,\n",
       "                        4.4730, 13.8315,  0.9923,  2.9313,  0.3817,  0.3756,  2.9846,  2.9147],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('conv_block2.bn2.weight',\n",
       "               tensor([1.0066, 0.4100, 1.7164, 1.1277, 0.8272, 0.9867, 0.5988, 0.8024, 1.0251,\n",
       "                       0.9320, 0.8544, 0.9330, 1.2280, 0.9666, 1.0752, 0.9720, 0.9487, 0.8981,\n",
       "                       1.4839, 0.8564, 1.1588, 0.9244, 0.9466, 1.2744, 1.0465, 0.5224, 0.6880,\n",
       "                       0.9732, 1.1102, 1.1101, 0.8381, 1.3644, 0.7172, 0.8170, 0.8807, 0.9567,\n",
       "                       0.9122, 0.9918, 0.6228, 0.5879, 0.8023, 1.0163, 1.3057, 1.3444, 1.0669,\n",
       "                       0.6356, 0.6080, 0.8562, 1.2794, 1.0988, 0.7308, 1.0479, 0.8984, 1.1486,\n",
       "                       1.2955, 0.9109, 1.1311, 0.8693, 0.9686, 1.1794, 1.0197, 0.7892, 0.8340,\n",
       "                       0.6519, 1.1806, 1.0043, 1.4562, 0.7642, 0.8790, 1.1944, 0.7891, 1.8198,\n",
       "                       0.9613, 1.0385, 0.7661, 1.5542, 0.9355, 0.9096, 1.1708, 0.8560, 0.8988,\n",
       "                       0.9124, 1.2346, 0.7402, 1.2465, 1.3351, 1.0376, 0.6495, 0.6642, 0.7827,\n",
       "                       1.2118, 0.9574, 0.4798, 1.1120, 0.7713, 0.7519, 1.0056, 1.0861, 0.6364,\n",
       "                       0.8034, 1.2217, 1.1314, 0.9592, 0.6981, 0.9836, 1.1057, 1.0085, 1.4028,\n",
       "                       0.5599, 0.8448, 0.8540, 0.9662, 1.0883, 0.7955, 1.0959, 0.8229, 0.8033,\n",
       "                       1.1390, 1.1482, 1.0457, 0.9219, 1.0685, 1.3285, 0.9082, 0.7614, 0.9403,\n",
       "                       0.9730, 0.8665], device='cuda:0')),\n",
       "              ('conv_block2.bn2.bias',\n",
       "               tensor([-0.8154, -0.1750, -1.8140, -1.0216, -0.6380, -0.6456, -0.2892, -0.3298,\n",
       "                       -0.8747, -0.6278, -0.4250, -0.5866, -1.1571, -0.5693, -0.5757, -0.6209,\n",
       "                       -0.6798, -0.5411, -1.3094, -0.2169, -0.7614, -0.5043, -0.5666, -1.0997,\n",
       "                       -0.5570, -1.0125, -0.2651, -0.4773, -0.4544, -0.8425, -0.4825, -0.8457,\n",
       "                       -0.5153, -0.9855, -0.7380, -0.4064, -0.6138, -0.6662, -0.2278, -0.4534,\n",
       "                       -0.4179, -0.6972, -0.7489, -0.8817, -1.0188, -0.3815, -0.3008, -0.7476,\n",
       "                       -1.3416, -0.9051, -0.3977, -0.8386, -0.5618, -1.2095, -0.9028, -0.4054,\n",
       "                       -1.0320, -0.3610, -0.8206, -1.0103, -0.5700, -0.2233, -0.5939, -0.3044,\n",
       "                       -1.0898, -0.9609, -1.4279, -1.3182, -0.4892, -1.1064, -0.3667, -1.5231,\n",
       "                       -0.6425, -0.9104, -0.4191, -1.4314, -0.4916, -0.4108, -0.8623, -0.9150,\n",
       "                       -1.1753, -0.6181, -1.2020, -0.3796, -1.3067, -1.3553, -0.9111, -0.2383,\n",
       "                       -0.4091, -0.3708, -0.8416, -0.3925, -0.2483, -0.7500, -0.4549, -0.4144,\n",
       "                       -0.4986, -0.8924, -0.3309, -0.3848, -1.0893, -0.8781, -0.3750, -0.2804,\n",
       "                       -0.9060, -0.7595, -0.3554, -1.8001, -0.2590, -0.6035, -0.5533, -0.5921,\n",
       "                       -0.4868, -0.5027, -0.8257, -0.5894, -0.6348, -0.7042, -1.0804, -0.8627,\n",
       "                       -0.5274, -0.8283, -1.1508, -0.9107, -0.4534, -0.5167, -0.5222, -0.5753],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn2.running_mean',\n",
       "               tensor([-5.6127, -1.1336, -4.7324, -1.7579, -2.1815, -0.4734, -3.9349, -4.7680,\n",
       "                       -5.1366, -2.0316, -1.9268,  3.7418, -3.6715, -4.2893, -3.6573, -2.1572,\n",
       "                       -3.1783, -2.0258, -7.5119, -1.0376, -1.5964, -0.2021, -0.0448, -4.0112,\n",
       "                       -0.9899,  2.2924, -0.1794, -3.1211, -1.1253, -6.0720, -6.8144, -2.6835,\n",
       "                       -0.4424, -3.9510, -2.0067, -4.6779, -7.0774, -5.3648, -3.1149, -2.6272,\n",
       "                       -5.7150, -6.5214, -2.2669, -2.3024, -5.7667, -2.5683, -3.5424, -3.4403,\n",
       "                       -5.4891, -6.2041, -2.8108, -3.9734, -5.4959, -6.2490, -2.8921, -0.4838,\n",
       "                       -3.1032, -3.0342, -3.7720, -4.5167, -1.1562, -5.5489, -2.6628, -5.8333,\n",
       "                       -6.7298, -4.8145, -3.9988, -2.7493, -2.6393, -4.8195, -4.6314, -3.8363,\n",
       "                       -3.0385, -1.2108, -1.1937, -2.8474, -5.5200, -3.4375, -2.0722, -1.6897,\n",
       "                       -2.8776, -4.0249, -3.0269, -3.2575, -5.1171, -3.4216, -1.2461, -3.3018,\n",
       "                       -2.3104, -2.3704, -4.3531, -2.7796, -6.1184, -1.9883, -3.8308, -1.0182,\n",
       "                       -7.2246, -2.4675, -3.5514, -4.1304, -3.9897, -1.8567, -7.5615,  0.8199,\n",
       "                       -4.7377, -1.6088, -6.7365, -4.2388, -7.4258, -2.0139, -5.2095, -4.8773,\n",
       "                       -2.3524, -1.0918, -3.1215, -0.0545, -3.5351, -2.4582, -3.9097, -4.1800,\n",
       "                       -2.3348, -1.4077, -5.2603, -3.1846, -2.5143, -2.5921, -4.3393, -2.6162],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn2.running_var',\n",
       "               tensor([19.9622, 20.7447, 18.6903,  8.4513, 12.7544,  5.8736, 19.7839, 11.0215,\n",
       "                       33.3220,  3.7233, 14.7236, 21.8511,  8.9645, 13.3843,  9.3502, 19.9689,\n",
       "                       21.0140,  4.6844, 49.6805,  8.4942, 14.7977, 20.6256,  8.6847,  9.9482,\n",
       "                       46.4597,  4.7395, 10.5849, 11.0141,  5.8818, 11.1570, 32.1708, 16.5871,\n",
       "                        5.9943, 10.5220,  2.9150, 14.2136, 15.4630, 15.0471, 10.4453, 21.3648,\n",
       "                       19.8511, 43.4166, 18.0180, 16.6693,  6.4953,  7.9625, 26.8720, 11.0355,\n",
       "                       24.3580, 14.2542, 17.6870, 21.6451, 34.2536, 14.8519, 21.6811,  8.5273,\n",
       "                       31.0433, 34.2623,  7.6977, 11.3523,  9.7018, 16.3361, 12.0962, 22.2383,\n",
       "                       19.4619, 28.3237, 30.8343,  6.5997,  7.8400, 18.9480, 16.7497, 18.3810,\n",
       "                        6.3752, 21.0846,  6.8941, 10.5530, 20.3565,  7.4070, 14.9480, 16.0058,\n",
       "                        5.0784, 12.1082, 11.3008, 20.7669,  9.0140,  7.3698,  7.2880, 29.8676,\n",
       "                       30.4760, 20.3107, 32.9364, 26.9324, 16.0707,  6.2132, 11.4088, 13.9511,\n",
       "                       18.7250, 13.7249, 43.9724, 19.5613, 23.1975,  8.4566, 30.6417,  7.1456,\n",
       "                       12.2467,  9.9208, 20.2014,  8.2166, 20.5963, 12.7245,  7.0594,  9.8897,\n",
       "                        7.5909, 35.4599, 15.7236,  5.9032, 17.1718, 28.5123, 15.2075, 22.5582,\n",
       "                        6.2119,  7.1089, 64.1657, 11.0195,  7.1562,  7.5451, 26.3417, 23.7388],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn2.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('conv_block3.conv1.weight',\n",
       "               tensor([[[[-1.7752e-02,  9.2355e-02,  4.9380e-02],\n",
       "                         [-8.4075e-02,  3.3512e-02, -7.8005e-02],\n",
       "                         [ 5.3629e-02, -6.0631e-02, -8.1552e-02]],\n",
       "               \n",
       "                        [[-3.4598e-02, -6.5774e-02, -5.0224e-02],\n",
       "                         [-5.6276e-02, -1.2053e-01, -1.6493e-01],\n",
       "                         [ 1.0007e-01,  2.0845e-01,  1.1068e-01]],\n",
       "               \n",
       "                        [[ 5.8583e-02,  8.0984e-02,  7.6533e-02],\n",
       "                         [-1.3693e-01, -1.4156e-02,  5.6025e-02],\n",
       "                         [-1.8063e-01, -5.8859e-02, -7.4429e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.5463e-01,  5.2419e-02, -1.0024e-01],\n",
       "                         [ 1.1795e-01,  9.2307e-02, -5.6470e-02],\n",
       "                         [ 9.0162e-02,  3.0833e-01, -3.6292e-02]],\n",
       "               \n",
       "                        [[-6.2062e-02, -1.8207e-01, -1.4854e-01],\n",
       "                         [-1.5040e-01, -7.8846e-02,  3.0701e-03],\n",
       "                         [ 1.9074e-01,  3.5022e-01,  2.4956e-01]],\n",
       "               \n",
       "                        [[ 9.0233e-02, -7.0155e-02, -1.7533e-01],\n",
       "                         [-2.5781e-02, -6.0356e-02, -1.0078e-02],\n",
       "                         [-2.1599e-01, -1.0531e-01,  7.0564e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.5222e-02,  1.4381e-02, -2.5773e-03],\n",
       "                         [ 6.0513e-02, -5.0362e-02, -1.5976e-02],\n",
       "                         [ 6.1695e-03,  3.3436e-02, -2.9676e-02]],\n",
       "               \n",
       "                        [[-3.7253e-02, -2.9519e-02,  4.1661e-02],\n",
       "                         [-1.0173e-01, -7.5208e-02, -5.1548e-02],\n",
       "                         [-5.0942e-02, -1.4410e-01, -4.0560e-02]],\n",
       "               \n",
       "                        [[-3.4453e-02, -3.6778e-02, -1.9024e-02],\n",
       "                         [ 2.8266e-02,  6.7484e-03,  5.1905e-03],\n",
       "                         [-2.5232e-04, -1.0144e-02, -3.2405e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.0071e-02, -3.3461e-02, -2.5602e-02],\n",
       "                         [ 3.4286e-03,  2.8658e-02,  2.6146e-02],\n",
       "                         [ 4.1681e-02,  2.6987e-02,  1.9850e-02]],\n",
       "               \n",
       "                        [[ 1.2974e-02,  3.5114e-02,  1.9380e-02],\n",
       "                         [ 6.4100e-03,  2.0554e-02,  3.2970e-04],\n",
       "                         [-5.0646e-02, -3.8781e-03, -3.0584e-02]],\n",
       "               \n",
       "                        [[-1.3567e-01,  4.0223e-02,  1.7589e-01],\n",
       "                         [-6.5701e-02,  1.3517e-01,  3.7565e-01],\n",
       "                         [-1.9752e-01,  2.5241e-01,  1.7646e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1145e-02,  1.3033e-01,  2.2332e-01],\n",
       "                         [ 2.2561e-01,  1.0868e-01,  2.3384e-01],\n",
       "                         [ 7.9654e-02,  6.8911e-02,  1.3876e-01]],\n",
       "               \n",
       "                        [[-2.3135e-01, -9.2945e-02, -2.1496e-01],\n",
       "                         [ 2.8467e-02,  5.8121e-02,  5.3562e-02],\n",
       "                         [ 9.5068e-02,  6.9675e-02,  7.4527e-02]],\n",
       "               \n",
       "                        [[ 6.9424e-02, -5.2159e-02,  3.8614e-02],\n",
       "                         [ 1.4603e-01,  3.2642e-01,  1.5971e-01],\n",
       "                         [-1.7997e-01,  2.4631e-01,  1.7224e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.1817e-02,  3.5655e-02, -2.1303e-01],\n",
       "                         [-4.5383e-02,  7.3664e-02, -2.6779e-01],\n",
       "                         [-9.2553e-02, -5.8377e-02, -1.2902e-01]],\n",
       "               \n",
       "                        [[ 1.8418e-01,  4.2695e-01,  1.9766e-02],\n",
       "                         [ 2.1031e-01,  2.0082e-01, -8.6490e-02],\n",
       "                         [ 5.0629e-01,  2.9072e-01, -1.5805e-01]],\n",
       "               \n",
       "                        [[-1.7724e-01, -3.4512e-01, -3.0843e-01],\n",
       "                         [ 3.0489e-01,  1.2677e-01,  5.7080e-02],\n",
       "                         [ 6.6819e-01,  1.8420e-01,  6.5781e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 6.8691e-02,  8.5358e-02,  1.1641e-01],\n",
       "                         [ 2.5151e-01,  2.5533e-02,  3.1685e-01],\n",
       "                         [ 2.0820e-01,  3.3026e-02,  1.4704e-01]],\n",
       "               \n",
       "                        [[ 2.3994e-02,  1.9901e-01, -2.0392e-02],\n",
       "                         [-2.6953e-02, -3.1628e-02, -4.8794e-01],\n",
       "                         [-4.3063e-02, -2.1111e-02, -1.9829e-01]],\n",
       "               \n",
       "                        [[ 3.9558e-01,  2.4819e-01, -1.8220e-01],\n",
       "                         [ 5.7797e-01,  2.4215e-01,  7.2830e-02],\n",
       "                         [ 1.3334e-01,  4.2241e-01,  1.1250e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.5685e-01, -9.3112e-02, -2.7615e-01],\n",
       "                         [ 1.6508e-01,  7.8675e-02, -3.6857e-01],\n",
       "                         [ 6.5873e-02,  2.0360e-01, -4.6942e-03]],\n",
       "               \n",
       "                        [[-1.9521e-03,  6.2539e-02,  3.0535e-02],\n",
       "                         [-7.2786e-02, -3.5484e-01, -1.7965e-02],\n",
       "                         [-1.7936e-01, -6.5792e-02,  4.8187e-02]],\n",
       "               \n",
       "                        [[ 6.1850e-01,  2.9430e-02, -3.7988e-02],\n",
       "                         [ 1.1525e-01,  7.7113e-02, -1.8296e-01],\n",
       "                         [ 6.1072e-02,  2.0753e-02,  9.0086e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.6580e-01, -1.2193e-01, -4.7474e-02],\n",
       "                         [ 2.2647e-02, -2.1492e-01, -2.3911e-02],\n",
       "                         [ 4.1714e-01, -2.4886e-01, -9.2541e-02]],\n",
       "               \n",
       "                        [[-2.7359e-02, -3.5760e-02,  3.7160e-02],\n",
       "                         [ 5.0605e-02,  6.9195e-02,  4.3621e-02],\n",
       "                         [-1.5355e-02,  6.6321e-02, -4.9362e-02]],\n",
       "               \n",
       "                        [[ 3.0249e-02,  1.7397e-01,  1.1052e-01],\n",
       "                         [-1.3885e-01,  9.1319e-02,  2.3844e-01],\n",
       "                         [-2.5978e-01, -3.0275e-01, -5.5976e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.4389e-02, -6.2956e-03,  7.3341e-03],\n",
       "                         [-1.1833e-01, -8.6154e-02, -9.6537e-02],\n",
       "                         [-4.7005e-02, -2.6912e-03, -1.4434e-01]],\n",
       "               \n",
       "                        [[ 6.8759e-02, -8.8094e-02, -1.8027e-04],\n",
       "                         [-3.4884e-02, -2.3265e-01,  2.7016e-01],\n",
       "                         [-1.2363e+00, -3.8352e-01,  2.5288e-01]],\n",
       "               \n",
       "                        [[ 4.5255e-02, -4.7895e-03, -1.2721e-03],\n",
       "                         [-7.8398e-02, -2.3319e-01, -5.2042e-02],\n",
       "                         [-1.6601e-01, -3.6612e-02,  2.5491e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.3595e-02, -5.1574e-02, -3.4791e-02],\n",
       "                         [ 4.8958e-02,  1.1233e-03, -2.2938e-02],\n",
       "                         [ 5.9336e-02,  2.6671e-02, -2.1939e-02]],\n",
       "               \n",
       "                        [[-1.0389e-01, -2.1559e-01, -1.0915e-01],\n",
       "                         [ 6.6449e-02,  4.2306e-02,  6.9468e-02],\n",
       "                         [-6.1373e-02,  6.9169e-02,  3.6722e-02]],\n",
       "               \n",
       "                        [[-3.5430e-02,  4.1236e-02, -3.6138e-02],\n",
       "                         [ 4.2225e-02, -4.7786e-02, -1.0079e-01],\n",
       "                         [ 1.5657e-02,  6.9301e-02,  2.8160e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.2499e-02,  6.9929e-03, -2.3165e-02],\n",
       "                         [-4.0616e-02, -9.4174e-04,  4.1610e-02],\n",
       "                         [ 8.8193e-03, -5.3214e-02, -1.3345e-02]],\n",
       "               \n",
       "                        [[-4.2947e-02, -5.9899e-02,  1.4109e-02],\n",
       "                         [-3.8311e-02, -3.1659e-02,  1.8515e-02],\n",
       "                         [ 1.6438e-02,  5.6835e-02,  8.7405e-02]],\n",
       "               \n",
       "                        [[-7.3815e-02, -6.5056e-02, -1.1542e-01],\n",
       "                         [ 5.0774e-02, -7.4736e-02, -1.0618e-01],\n",
       "                         [-4.8161e-03,  3.4538e-02, -1.8875e-03]]]], device='cuda:0')),\n",
       "              ('conv_block3.conv2.weight',\n",
       "               tensor([[[[ 6.4714e-02,  1.7262e-02, -1.0788e-02],\n",
       "                         [ 1.4593e-01,  8.6630e-02,  2.5507e-02],\n",
       "                         [ 4.2481e-02, -6.6730e-03, -5.6759e-03]],\n",
       "               \n",
       "                        [[ 2.7709e-01,  2.9769e-01,  6.6724e-02],\n",
       "                         [ 3.7329e-01,  1.5840e-01,  8.9610e-02],\n",
       "                         [ 8.4590e-02,  1.6684e-01,  8.0443e-02]],\n",
       "               \n",
       "                        [[-4.9506e-02, -2.7487e-02, -6.6249e-02],\n",
       "                         [-5.1710e-02, -7.8700e-02, -6.5738e-02],\n",
       "                         [ 3.9334e-02, -3.2215e-02,  2.3797e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.3062e-01, -4.6048e-02, -5.8226e-02],\n",
       "                         [ 5.3103e-02,  1.2442e-02, -3.4725e-02],\n",
       "                         [ 2.2690e-01,  2.0515e-02, -4.4539e-02]],\n",
       "               \n",
       "                        [[-1.8807e-02, -6.3503e-02,  2.9799e-02],\n",
       "                         [ 1.0190e-01, -7.1038e-02, -4.9561e-03],\n",
       "                         [ 2.7469e-01,  1.6355e-02, -3.6970e-02]],\n",
       "               \n",
       "                        [[ 3.4937e-02,  2.1754e-02,  1.1048e-01],\n",
       "                         [-2.7033e-03, -2.3019e-04, -8.2689e-03],\n",
       "                         [-1.8120e-02, -2.1477e-02, -4.4254e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.3840e-02, -6.7350e-02, -8.4865e-02],\n",
       "                         [-2.7614e-02, -4.6381e-02, -1.7262e-02],\n",
       "                         [ 5.8662e-02,  1.0394e-01, -9.2205e-03]],\n",
       "               \n",
       "                        [[ 3.9992e-02,  8.0832e-04, -3.9716e-02],\n",
       "                         [-2.2202e-02, -3.1483e-03, -2.4329e-02],\n",
       "                         [-4.7323e-02, -4.3006e-02,  1.0441e-02]],\n",
       "               \n",
       "                        [[-9.1673e-03, -3.1765e-01, -3.0044e-01],\n",
       "                         [-3.4384e-01, -4.0116e-01, -1.6732e-01],\n",
       "                         [-4.0193e-01, -5.9058e-01, -5.4515e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.1017e-02,  9.1739e-02,  4.3363e-01],\n",
       "                         [ 1.0038e-01,  4.1863e-02,  5.7576e-01],\n",
       "                         [ 1.1728e-01,  1.1771e-02, -1.9416e-01]],\n",
       "               \n",
       "                        [[ 1.4902e-01,  4.7517e-01,  3.1520e-01],\n",
       "                         [-1.6456e-03,  6.3820e-01,  1.3292e-01],\n",
       "                         [-1.7663e-02, -2.0358e-01,  1.7088e-01]],\n",
       "               \n",
       "                        [[-8.1655e-03, -1.5024e-02, -3.7398e-02],\n",
       "                         [-1.9024e-02, -4.4205e-04, -3.1801e-02],\n",
       "                         [ 2.0825e-02,  1.1987e-02,  4.8478e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.0393e-02,  4.3426e-02,  8.5178e-02],\n",
       "                         [ 8.2255e-03,  9.3040e-02,  7.6621e-02],\n",
       "                         [ 1.3745e-01,  1.3346e-01,  1.0256e-01]],\n",
       "               \n",
       "                        [[-4.3817e-02, -1.2494e-01, -4.7759e-03],\n",
       "                         [-6.0370e-02, -6.0462e-02, -3.2937e-02],\n",
       "                         [ 1.0949e-02,  6.3623e-03,  3.0123e-03]],\n",
       "               \n",
       "                        [[-1.8139e-01, -1.4995e-01, -4.1387e-01],\n",
       "                         [-1.4607e-01, -7.8822e-02,  8.3721e-02],\n",
       "                         [-6.1714e-01, -1.5167e-01,  1.7607e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.3630e-01,  5.0519e-01,  4.7783e-02],\n",
       "                         [ 5.5222e-02, -1.1785e-01,  3.2503e-02],\n",
       "                         [ 7.4370e-02, -1.6093e-01, -1.1112e-01]],\n",
       "               \n",
       "                        [[ 1.3996e-01,  1.8402e-01,  1.0972e-01],\n",
       "                         [ 1.7437e-01, -2.4215e-02, -2.5640e-02],\n",
       "                         [ 1.0818e+00,  4.7826e-01,  8.8132e-02]],\n",
       "               \n",
       "                        [[ 1.8755e-03, -5.1620e-02,  6.9656e-02],\n",
       "                         [-3.8884e-03, -7.5764e-02,  1.4098e-02],\n",
       "                         [ 1.5910e-02,  5.0674e-02,  7.7162e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-8.0123e-02, -6.3020e-02, -3.8814e-02],\n",
       "                         [-6.3896e-02,  1.6163e-02, -2.1092e-02],\n",
       "                         [-1.4258e-01, -5.8085e-03, -1.1717e-02]],\n",
       "               \n",
       "                        [[ 3.0225e-01,  1.4650e-01, -6.5677e-02],\n",
       "                         [ 4.1833e-01,  6.7850e-02, -4.2827e-02],\n",
       "                         [ 2.9875e-01,  6.9620e-03, -7.2011e-02]],\n",
       "               \n",
       "                        [[-8.6484e-02, -4.7018e-02, -3.5578e-01],\n",
       "                         [ 7.8615e-03, -2.6889e-02, -1.7497e-01],\n",
       "                         [-3.4336e-02,  1.6023e-02, -1.3624e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.1267e-02,  6.7783e-02,  1.1590e-02],\n",
       "                         [ 1.2139e-03,  8.0327e-02, -1.7572e-02],\n",
       "                         [-3.7839e-02, -2.0667e-02, -7.7754e-02]],\n",
       "               \n",
       "                        [[-5.8316e-02,  8.5984e-03, -6.9062e-03],\n",
       "                         [-3.7476e-02, -1.3281e-01, -1.1085e-01],\n",
       "                         [-1.4605e-01, -1.6514e-02, -1.0649e-01]],\n",
       "               \n",
       "                        [[-5.8412e-02, -8.1479e-02, -1.6382e-02],\n",
       "                         [-5.1446e-02, -1.0229e-01, -2.8513e-02],\n",
       "                         [-1.4643e-01, -5.0317e-02,  2.7531e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.2098e-01, -1.7585e-01, -3.5911e-01],\n",
       "                         [-5.4084e-02,  3.5825e-02,  4.3575e-02],\n",
       "                         [ 2.5138e-01,  2.2060e-01,  2.7327e-01]],\n",
       "               \n",
       "                        [[-1.4656e-01, -3.5928e-02, -7.5843e-02],\n",
       "                         [-1.3830e-01, -1.4088e-01, -2.7525e-01],\n",
       "                         [-1.1957e-01, -8.9622e-02, -2.6442e-01]],\n",
       "               \n",
       "                        [[-2.6082e-01, -5.2277e-02, -2.0917e-01],\n",
       "                         [-5.2837e-01, -7.3021e-02, -2.0065e-01],\n",
       "                         [-2.4721e-01, -8.6720e-02, -1.7627e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.5258e-01, -9.0307e-02,  2.6732e-01],\n",
       "                         [-4.1899e-02, -1.6308e-01, -3.6498e-02],\n",
       "                         [-1.2373e-02,  1.0886e-02, -5.7119e-02]],\n",
       "               \n",
       "                        [[-8.1114e-03,  4.8641e-02, -6.3707e-02],\n",
       "                         [ 8.0142e-02,  6.6198e-03, -2.8452e-02],\n",
       "                         [-4.3843e-03,  5.2891e-02,  5.8596e-03]],\n",
       "               \n",
       "                        [[-3.1780e-02,  1.1751e-03, -2.3513e-04],\n",
       "                         [-6.4673e-02,  2.4999e-02,  5.4257e-02],\n",
       "                         [-6.7086e-02, -2.5710e-02, -3.0900e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.8457e-02,  5.8144e-02, -2.9124e-02],\n",
       "                         [-1.1060e-01, -8.7814e-02, -8.0215e-02],\n",
       "                         [ 1.1469e-02, -7.4911e-04, -6.7513e-03]],\n",
       "               \n",
       "                        [[-5.5765e-02, -5.2550e-02,  3.9489e-03],\n",
       "                         [-2.3201e-02,  2.1627e-02, -2.1499e-02],\n",
       "                         [-7.0744e-02,  4.8855e-03,  2.9414e-02]],\n",
       "               \n",
       "                        [[-1.5498e-01, -1.2841e-01,  4.6725e-02],\n",
       "                         [-3.7894e-01, -1.7567e-03,  1.5084e-01],\n",
       "                         [-1.9412e-01, -2.4404e-01,  1.3337e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.0285e-01, -4.8073e-03,  2.5009e-02],\n",
       "                         [-9.2197e-02, -5.6349e-02,  5.0811e-02],\n",
       "                         [-1.7267e-02, -4.5378e-03,  4.9366e-02]],\n",
       "               \n",
       "                        [[-1.1441e-01, -2.9691e-01, -1.4767e-01],\n",
       "                         [ 1.2831e-02, -3.9784e-02, -7.2162e-02],\n",
       "                         [-2.7360e-02, -8.1368e-02, -5.1388e-02]],\n",
       "               \n",
       "                        [[ 1.9799e-02, -7.1837e-02, -9.4981e-04],\n",
       "                         [ 2.9914e-02, -3.5440e-02, -4.5497e-02],\n",
       "                         [-3.5957e-02, -6.7128e-02, -8.1971e-02]]]], device='cuda:0')),\n",
       "              ('conv_block3.bn1.weight',\n",
       "               tensor([1.0331, 0.9053, 0.9436, 1.0024, 1.0312, 1.3362, 1.1249, 1.1689, 0.9417,\n",
       "                       0.9963, 0.9991, 1.0964, 0.9063, 1.1813, 0.4950, 1.3847, 1.1069, 1.1349,\n",
       "                       0.6670, 0.9534, 1.5092, 1.0149, 0.7757, 1.4907, 1.3224, 1.0342, 0.9513,\n",
       "                       1.1509, 0.8734, 1.1480, 0.7769, 1.2348, 0.9979, 1.3107, 1.1877, 1.1382,\n",
       "                       0.9067, 0.8446, 0.9376, 1.0466, 1.0798, 1.2780, 1.1341, 0.9131, 1.1230,\n",
       "                       1.1357, 1.0243, 1.1687, 0.7533, 0.9781, 1.4350, 0.8676, 1.1722, 1.0525,\n",
       "                       1.0624, 1.0038, 1.1116, 1.3202, 1.1213, 0.9693, 1.1337, 0.8257, 1.1036,\n",
       "                       1.2595, 1.1306, 1.1265, 1.0250, 1.0644, 0.9390, 1.2897, 0.8825, 0.9696,\n",
       "                       0.9882, 1.1232, 1.0251, 0.8274, 1.1768, 0.9586, 1.1068, 1.2929, 0.9425,\n",
       "                       0.5342, 1.2241, 1.1519, 1.1072, 1.0675, 1.1157, 1.1687, 0.9197, 0.8598,\n",
       "                       0.9862, 0.9162, 0.8684, 0.8934, 1.3286, 1.1877, 1.0883, 0.4555, 1.5324,\n",
       "                       0.9593, 1.0458, 1.2442, 0.9790, 0.8556, 0.9669, 1.0646, 0.9929, 1.0675,\n",
       "                       1.1199, 1.0880, 0.8932, 1.1915, 1.0622, 1.2081, 0.9342, 1.2530, 0.8551,\n",
       "                       0.7728, 1.0338, 1.1771, 0.9075, 1.1642, 0.6511, 0.9076, 0.8853, 0.9869,\n",
       "                       1.2199, 1.0421, 0.9719, 1.0283, 0.7323, 1.0069, 0.9685, 1.2582, 0.9870,\n",
       "                       0.9176, 1.0811, 0.9061, 0.9762, 0.8507, 1.1184, 1.0592, 1.2103, 0.7265,\n",
       "                       1.2232, 1.0220, 0.8416, 1.1734, 1.1814, 1.0135, 1.0113, 0.9087, 0.9687,\n",
       "                       2.1330, 1.1259, 1.0129, 1.1311, 0.9281, 1.3112, 0.9303, 1.1310, 0.9401,\n",
       "                       0.8729, 0.9398, 1.0880, 1.1129, 0.8684, 1.1950, 1.1503, 1.1380, 1.2285,\n",
       "                       1.3873, 0.6793, 1.0853, 1.1503, 1.2339, 1.1021, 0.9706, 1.0984, 1.1335,\n",
       "                       0.8602, 1.2144, 0.7322, 1.1747, 1.0687, 1.1351, 0.9809, 1.2085, 1.0621,\n",
       "                       1.0394, 0.8410, 1.1524, 1.0466, 0.5013, 1.3919, 1.1763, 1.1967, 0.8505,\n",
       "                       1.0842, 0.8230, 1.4123, 1.0366, 1.1494, 1.1018, 1.0898, 1.0706, 0.7851,\n",
       "                       0.8816, 0.7944, 0.9768, 1.0357, 0.9303, 0.3814, 1.1703, 0.7787, 0.8971,\n",
       "                       1.0559, 0.8940, 0.5644, 1.5277, 0.8877, 1.0645, 0.8176, 0.5224, 0.9845,\n",
       "                       1.1482, 1.1682, 1.1723, 1.0762, 0.9640, 1.2100, 1.1318, 1.2116, 1.1783,\n",
       "                       1.0512, 1.1662, 0.8639, 1.4476, 1.0977, 0.8336, 1.1994, 1.1209, 0.9361,\n",
       "                       0.5538, 0.9911, 0.9830, 0.9264, 1.1142, 1.0730, 1.0104, 1.0228, 0.8695,\n",
       "                       1.1407, 0.9405, 0.7757, 1.1062], device='cuda:0')),\n",
       "              ('conv_block3.bn1.bias',\n",
       "               tensor([-6.8019e-01, -3.9265e-01, -7.8855e-01,  2.1899e-02, -8.2269e-01,\n",
       "                       -2.7785e-01, -2.6681e-01, -2.5257e-02, -3.4607e-02, -3.7976e-01,\n",
       "                       -4.5366e-01, -1.1566e-01, -2.1147e-01, -9.8734e-02, -1.0372e+00,\n",
       "                       -1.1906e+00, -6.7866e-01, -3.3606e-01, -2.2873e-01, -4.3406e-01,\n",
       "                       -6.3555e-01, -5.1331e-01, -1.7360e-01, -6.9747e-01, -4.3672e-01,\n",
       "                       -6.1111e-01, -5.5508e-01, -5.0157e-01, -3.0858e-01, -8.7039e-01,\n",
       "                        1.7280e-01, -4.3813e-01, -6.1297e-01, -6.3786e-01, -5.2862e-01,\n",
       "                       -1.7538e-01, -2.8858e-01,  4.8668e-01, -4.5800e-01,  7.9430e-04,\n",
       "                       -3.4461e-01, -4.3441e-01, -4.5190e-01,  7.4020e-02, -3.2968e-01,\n",
       "                       -8.5188e-01, -5.8970e-01, -3.7237e-01, -8.9521e-01, -5.6441e-01,\n",
       "                       -7.4297e-01, -3.3451e-01, -5.5729e-01, -4.4748e-01, -6.9357e-01,\n",
       "                       -2.1936e-01, -4.8095e-01, -3.1891e-01, -2.4927e-01, -3.7864e-01,\n",
       "                       -5.6655e-01, -1.7982e-01, -3.9757e-01, -5.7355e-01, -1.9070e-01,\n",
       "                       -2.6020e-01, -4.8626e-01, -7.5261e-01, -4.8666e-01, -4.7701e-01,\n",
       "                       -4.2298e-01, -5.2119e-01, -5.6295e-01, -7.2714e-01, -5.7541e-01,\n",
       "                       -1.3775e-01, -5.9072e-01, -5.6128e-01, -4.2702e-01, -7.3847e-01,\n",
       "                       -3.1109e-01, -1.1736e+00, -3.6733e-01, -5.6332e-01, -4.9999e-01,\n",
       "                       -6.1813e-01, -6.9793e-01, -3.4694e-01, -5.9732e-01, -5.7573e-02,\n",
       "                       -1.6166e-01, -2.4997e-01, -5.1964e-01, -2.8732e-02, -7.1483e-01,\n",
       "                       -1.8383e-01, -3.7317e-01, -7.4328e-01, -9.1996e-01,  7.1738e-02,\n",
       "                       -4.0436e-01, -6.0901e-01, -4.9790e-01, -2.8449e-01, -3.5381e-01,\n",
       "                       -7.3781e-01, -3.7727e-01,  1.8199e-02, -3.9671e-01, -5.9666e-01,\n",
       "                       -2.2233e-01, -5.8113e-01, -4.6125e-01, -7.2003e-01, -3.6072e-01,\n",
       "                       -2.9851e-01, -5.3648e-01,  1.7147e-01, -2.2436e-01, -3.9592e-01,\n",
       "                       -4.2279e-01, -9.7680e-01, -1.5859e-01, -7.0680e-01, -3.6527e-01,\n",
       "                       -8.1315e-01, -2.2078e-01, -3.6677e-01, -4.4945e-01, -5.5510e-01,\n",
       "                       -2.3709e-01, -3.4390e-01, -6.5772e-01, -1.8991e+00, -4.8190e-01,\n",
       "                       -5.7382e-01, -4.2527e-01, -4.9577e-01, -4.4672e-01, -5.9556e-01,\n",
       "                       -1.1654e+00, -5.6949e-01, -4.9185e-01, -2.7836e-01, -6.8998e-01,\n",
       "                       -6.9339e-01, -3.6895e-01, -1.3841e-01, -6.2767e-01, -3.4697e-01,\n",
       "                        1.0120e-01, -1.7090e-01, -7.0161e-01, -2.7295e+00, -3.4410e-01,\n",
       "                       -1.9958e-01, -7.9961e-01, -3.5631e-01, -6.0469e-01, -2.2223e-01,\n",
       "                       -5.6454e-01, -2.5602e-01, -2.1235e-01, -5.3310e-01, -2.9153e-01,\n",
       "                       -8.1942e-01, -9.4803e-02, -1.8927e-01, -4.5705e-01, -3.5826e-01,\n",
       "                       -1.4636e+00, -4.7619e-01, -8.7114e-01, -1.0782e+00, -6.3383e-01,\n",
       "                       -6.4467e-01, -4.1681e-01, -1.0619e-01, -8.7760e-01, -4.4293e-01,\n",
       "                       -1.8871e-01, -4.6421e-01, -1.6240e-02, -5.0230e-01, -6.4453e-01,\n",
       "                       -8.1054e-02, -3.2748e-01, -5.5847e-01, -4.1535e-01, -1.6809e-01,\n",
       "                       -1.5998e-01, -2.1644e-01, -5.0740e-01, -9.6191e-01, -1.0291e-01,\n",
       "                       -3.9459e-01, -4.2316e-01,  1.4488e-01, -2.9990e-01, -2.4049e-01,\n",
       "                       -7.9860e-01, -1.7016e-01, -6.7162e-01, -8.7504e-03, -7.0447e-01,\n",
       "                       -5.7392e-01, -7.2829e-01, -7.2209e-01, -1.0816e-01, -4.5699e-01,\n",
       "                        1.6310e-04, -4.0299e-01, -1.0153e+00, -3.7792e-01, -4.0429e-01,\n",
       "                       -1.7811e-01, -7.5552e-01,  3.9404e-02, -6.9028e-01, -8.4236e-01,\n",
       "                       -2.9020e-01, -1.9899e-01, -6.6717e-01, -6.0744e-01, -7.5602e-01,\n",
       "                       -6.8406e-01, -3.9969e-01, -4.1614e-01, -1.0809e+00, -5.0495e-01,\n",
       "                       -1.9940e+00, -7.2343e-02, -2.0982e-01, -9.4686e-02, -3.6148e-01,\n",
       "                        1.2766e-02, -2.5190e-01, -1.0477e+00, -5.5421e-01, -4.2081e-01,\n",
       "                       -7.9442e-01, -2.4566e-01, -4.7112e-01, -6.4571e-01, -3.5467e-01,\n",
       "                       -1.3204e-01, -5.8592e-01, -5.9717e-01, -4.8701e-01, -3.4796e-01,\n",
       "                       -3.3898e-01, -4.2957e-01, -5.4296e-01,  8.8731e-02, -6.6105e-02,\n",
       "                       -3.3020e-01], device='cuda:0')),\n",
       "              ('conv_block3.bn1.running_mean',\n",
       "               tensor([ 0.3468, -0.7827,  3.5285, -2.7371, -2.4034, -2.5371, -2.4728, -3.0312,\n",
       "                       -2.7323, -0.7855, -2.8477, -5.0031, -4.1857, -1.9302,  0.3045, -2.8086,\n",
       "                       -2.7451, -3.3363, -1.2986, -0.5043, -0.8952, -4.5599, -3.0716, -3.0053,\n",
       "                       -5.3080, -0.8876, -3.3721, -1.9479, -1.9520, -1.1913, -0.1158, -2.9273,\n",
       "                       -1.7332, -2.9759, -3.3273, -4.1017, -1.6671, -1.2639, -2.2677, -2.3467,\n",
       "                       -0.2801, -3.0390, -2.0946, -1.7916, -1.3699, -2.9697, -2.3818, -2.8369,\n",
       "                       -3.1152, -3.3134, -3.7982,  0.6917, -2.0321,  0.1436, -0.6168, -1.7925,\n",
       "                       -1.5212, -1.8894, -2.7396, -5.0422, -1.5413, -2.3038, -3.9370, -1.4118,\n",
       "                       -1.3023, -2.9790, -0.4622, -0.4936, -2.1521, -1.1867, -2.8023, -1.8816,\n",
       "                       -2.1631, -2.0622,  0.5640, -1.8002, -3.1830, -3.2445, -0.7820, -3.0424,\n",
       "                       -0.3906,  0.4860, -2.6776, -5.8208, -1.2904, -1.4640, -2.4674, -1.0518,\n",
       "                        0.6175, -3.1097, -2.6810, -1.8475, -3.6014, -1.6496, -3.1140, -0.3645,\n",
       "                       -1.0802, -3.2781, -3.3775, -2.4834, -6.7034, -1.5495, -1.0867,  1.9685,\n",
       "                       -0.9789, -2.0970, -1.8485, -3.9269, -0.9068, -2.9905, -2.9132, -3.4213,\n",
       "                       -5.6938, -0.5057, -1.6775, -1.1176, -4.1916, -1.2140, -2.9515, -2.9839,\n",
       "                       -0.2548, -0.6302, -2.0767,  0.1372, -0.5228,  0.5705, -2.5819, -1.7861,\n",
       "                       -0.6415, -2.9976, -2.8841, -2.7745,  0.8572, -4.9184, -1.4718, -0.1828,\n",
       "                       -0.9172, -2.6223, -2.1280,  0.1261, -2.5242, -0.6352, -1.8736, -3.7635,\n",
       "                       -1.8345, -2.2329, -3.5443, -3.3945, -1.3171, -0.8855, -2.8168, -1.3771,\n",
       "                        0.1290, -3.9647, -5.7232, -2.2075, -2.0913, -1.8402, -1.1492, -3.4781,\n",
       "                       -1.5710, -3.0472, -0.3046,  0.5912, -3.0656, -2.9953, -4.5213, -1.0520,\n",
       "                       -2.5335, -2.5675,  3.1694, -2.7262,  1.2927, -1.0756, -1.1934, -2.0392,\n",
       "                       -1.2521, -2.0476, -0.8488, -2.9575, -1.3193, -2.6570, -2.5191, -1.7274,\n",
       "                       -1.1963, -2.6978,  0.1892, -5.8713, -3.0714, -0.5857, -3.7476, -1.2816,\n",
       "                       -2.1885,  1.5192, -1.1508, -2.6244, -0.9569, -2.7825, -2.4941, -2.9574,\n",
       "                       -2.2160, -3.4311, -0.9651, -5.3983, -0.1685, -1.3053, -0.8997, -0.7384,\n",
       "                       -4.2900, -1.6045, -1.1595, -4.0527, -0.4234, -3.6881, -1.5176, -1.8890,\n",
       "                       -3.6460, -2.4865, -1.2091, -2.6393, -4.7550, -2.0731,  1.0611, -0.7312,\n",
       "                       -2.7657, -2.1446, -4.3197, -3.5788,  1.9298, -0.5074, -5.5455, -1.6541,\n",
       "                       -0.3548, -1.0281, -0.3842, -2.1086, -6.9460, -2.5475, -7.3024, -1.3094,\n",
       "                       -1.1536, -1.8389, -0.6797, -1.0107, -1.2425, -2.2504, -0.8266,  0.4841,\n",
       "                       -0.4377, -1.9970, -4.9770, -1.3513, -2.6053, -0.8063, -3.2349, -1.1783],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.running_var',\n",
       "               tensor([ 3.5206,  1.6583, 14.1641,  8.6613,  8.6964, 15.2891,  7.3722, 16.4912,\n",
       "                        5.9808,  5.0570, 17.6879, 23.4357, 11.6155,  2.7424,  1.1761,  3.8390,\n",
       "                        6.5393, 13.6125,  4.2148,  1.8267,  5.6599,  6.7852, 14.0765,  6.1685,\n",
       "                       23.1976,  3.2168,  4.7758,  7.4759, 11.4420,  7.9190,  6.3448,  3.9671,\n",
       "                        7.0309, 14.0678,  7.8776, 13.2406,  7.2132,  6.3503,  5.7318, 17.7202,\n",
       "                        4.5652, 11.6720,  4.5517,  8.4638,  4.6800,  5.0770,  7.1152,  6.4788,\n",
       "                        7.2593,  5.7700, 16.6580,  3.6579,  2.8318,  2.9917,  5.1812,  3.4722,\n",
       "                        2.7563, 10.4485,  5.4320, 10.4526,  4.1345,  6.9262, 13.5287, 12.7609,\n",
       "                        8.5453, 20.4162,  3.9538,  9.8817,  7.0179,  4.2630, 11.2436,  6.1893,\n",
       "                        3.0384,  7.3200,  3.4705,  9.5466,  6.8121,  7.2527,  2.9509,  6.1530,\n",
       "                        2.4737,  1.4921, 10.0300, 14.9645,  7.6966,  3.7651,  3.4097,  4.6527,\n",
       "                       12.5473, 25.9726,  4.8241,  6.3321, 10.1494,  4.7229, 22.6928,  3.5379,\n",
       "                        7.0245,  2.5245,  6.6694,  7.3645, 26.5058,  5.3683,  2.2144,  6.5624,\n",
       "                        1.3297,  2.1446, 13.2244, 15.7576,  2.4421, 14.8256, 10.4880, 15.2281,\n",
       "                        9.2134,  3.0482,  4.3696,  3.0461,  8.3554,  8.5430, 15.0750,  5.4489,\n",
       "                        0.9558,  5.7973, 11.7282,  2.2682,  8.5018,  3.5334,  6.5081,  4.3134,\n",
       "                        3.4906,  3.0148,  7.8710, 10.5646,  1.2775,  6.5258,  4.0118,  3.1045,\n",
       "                        3.5855,  4.7645,  9.8368,  0.9375,  4.0115,  5.2574,  5.7066, 12.5960,\n",
       "                        6.0884,  6.3133, 13.6448, 14.6202,  4.8539,  1.5118,  8.9872,  2.4774,\n",
       "                        2.3310,  8.0230, 16.8822, 10.2587,  3.9441,  7.8070,  2.1352, 14.0750,\n",
       "                        8.1996,  4.5388, 11.0445,  5.7263,  5.3410, 12.7823, 13.6923,  5.6292,\n",
       "                        4.6081,  6.1872,  3.5766,  8.9078,  1.1113,  6.3893,  2.5795,  6.3419,\n",
       "                        3.0444,  6.9650,  4.9177, 10.6627, 10.9385,  5.7586,  6.7340,  3.0453,\n",
       "                        3.0221,  8.3847,  1.8798, 17.2081, 10.9959,  3.4054, 10.4597,  3.7506,\n",
       "                        3.4891,  1.1262,  4.0500,  4.5611,  3.1997, 11.6037, 16.8162,  8.6293,\n",
       "                       11.0329,  9.2196,  2.5738, 36.7972, 11.0265,  3.3518,  4.2711,  4.1502,\n",
       "                        6.9442,  9.0226,  6.5697, 12.0677,  0.4661,  6.4939,  3.7310, 10.7921,\n",
       "                        5.7806,  8.2623,  1.3577,  7.7084, 24.6521,  5.3140,  2.8355,  0.6051,\n",
       "                        9.4652,  6.4703, 19.3617, 13.4676,  5.0610,  2.0527,  8.0986,  8.7927,\n",
       "                       11.3337,  6.1094,  3.1968,  6.4429, 17.1646,  7.8674, 15.5745,  3.4408,\n",
       "                       10.0812,  3.2867,  1.8204,  1.5603, 16.9121,  6.0509,  3.8719,  3.9296,\n",
       "                        4.0739,  5.6451, 11.6429,  5.4288,  5.2336, 12.3821, 11.9749,  2.0810],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('conv_block3.bn2.weight',\n",
       "               tensor([0.7362, 1.1672, 1.1105, 0.8248, 0.7071, 0.7927, 1.1698, 1.0843, 0.8831,\n",
       "                       1.5088, 1.0895, 0.9356, 0.7143, 1.0257, 0.9820, 0.9963, 0.9308, 1.4196,\n",
       "                       0.9519, 1.1939, 1.0850, 1.0512, 1.0027, 1.0770, 0.8128, 1.1655, 0.9128,\n",
       "                       0.9931, 0.8370, 1.0409, 0.8291, 0.9838, 1.0105, 0.9968, 1.1133, 1.1132,\n",
       "                       0.9740, 1.0974, 1.2451, 1.2402, 1.3479, 1.1176, 1.1396, 0.8118, 1.2443,\n",
       "                       1.3027, 0.9919, 0.9734, 0.7310, 0.9049, 1.1447, 1.1987, 0.9680, 0.8699,\n",
       "                       1.4310, 1.1366, 0.8049, 1.0670, 1.2827, 1.1943, 0.8216, 0.8155, 0.9494,\n",
       "                       0.9228, 0.9080, 1.3402, 0.8647, 1.0063, 1.3156, 1.0427, 0.8690, 1.0009,\n",
       "                       0.8840, 0.9172, 0.9957, 0.8706, 1.0382, 1.0177, 0.7120, 1.0225, 1.1272,\n",
       "                       0.8666, 1.4019, 0.8368, 1.1886, 0.9773, 0.9442, 1.0591, 1.0307, 0.9228,\n",
       "                       1.0067, 0.9041, 0.9061, 0.8346, 0.8746, 0.9756, 0.9020, 0.7627, 1.1740,\n",
       "                       0.6769, 0.8832, 1.4244, 0.9972, 0.9427, 1.1120, 1.1669, 1.0526, 1.1411,\n",
       "                       0.8268, 0.8853, 0.8684, 0.8592, 0.7556, 0.5646, 1.1000, 1.3836, 0.6514,\n",
       "                       0.9047, 1.0136, 1.1324, 1.0198, 1.2174, 0.8609, 0.7758, 1.1333, 1.3213,\n",
       "                       1.3526, 0.8729, 1.2265, 1.4281, 1.0025, 0.9096, 0.5936, 1.0440, 0.7529,\n",
       "                       1.0658, 0.8060, 1.2527, 1.1543, 0.9109, 0.8403, 0.7166, 1.1587, 0.8276,\n",
       "                       0.9699, 0.7912, 0.8171, 1.2048, 1.0345, 1.1737, 0.9776, 0.7506, 0.9725,\n",
       "                       1.3895, 1.1274, 1.0983, 1.0834, 1.3717, 1.1187, 0.9659, 0.4079, 0.9775,\n",
       "                       0.9780, 0.7750, 0.7721, 0.9084, 1.1988, 1.1269, 0.8670, 0.8405, 0.8395,\n",
       "                       0.8020, 1.1717, 0.5869, 1.1139, 0.8671, 1.1580, 0.7899, 1.2165, 1.0048,\n",
       "                       0.6134, 0.8460, 0.8959, 0.9015, 0.8910, 1.0492, 0.8752, 1.1999, 0.7041,\n",
       "                       1.0321, 1.0832, 0.6703, 0.7013, 1.0637, 1.3494, 1.1234, 0.9038, 0.7997,\n",
       "                       1.1006, 0.8966, 0.9153, 1.2295, 0.8846, 0.7957, 1.5849, 0.9610, 1.0173,\n",
       "                       0.9195, 0.9809, 0.7959, 1.0843, 0.8072, 1.5003, 0.9987, 0.8492, 0.8629,\n",
       "                       0.9166, 0.7513, 1.0123, 0.7724, 0.8659, 1.0754, 0.9618, 0.9389, 1.1090,\n",
       "                       0.9388, 0.8923, 1.2634, 0.5698, 1.0492, 1.1069, 1.2166, 0.8178, 1.0731,\n",
       "                       1.2074, 1.1822, 0.6685, 0.9966, 1.2647, 1.0778, 1.0994, 0.9460, 1.0876,\n",
       "                       0.6952, 1.0731, 0.9049, 0.9065, 1.0833, 1.0752, 1.1560, 0.8226, 1.1158,\n",
       "                       0.9831, 0.8765, 0.7936, 0.9977], device='cuda:0')),\n",
       "              ('conv_block3.bn2.bias',\n",
       "               tensor([-0.3447, -1.0111, -1.0263, -0.3839, -0.4709, -0.6176, -1.0174, -0.7006,\n",
       "                       -0.5888, -1.5784, -0.5848, -0.6323, -0.4783, -0.6916, -0.8651, -0.7132,\n",
       "                       -0.5354, -1.4393, -0.8265, -0.9962, -0.8385, -0.8789, -0.5543, -0.8877,\n",
       "                       -0.3918, -1.1878, -0.6674, -0.5267, -0.6107, -0.9409, -0.5954, -0.4848,\n",
       "                       -0.8988, -0.7519, -0.9004, -0.9628, -0.9136, -0.7790, -1.3124, -0.8836,\n",
       "                       -1.1315, -0.5390, -0.8837, -0.6706, -1.2878, -1.2384, -0.4968, -0.5329,\n",
       "                       -0.3080, -0.6346, -1.2339, -0.8892, -0.5585, -0.7501, -1.3652, -0.9185,\n",
       "                       -0.4508, -0.8461, -1.1940, -1.1114, -0.5222, -0.6672, -0.8557, -0.7891,\n",
       "                       -0.7803, -1.2064, -0.6009, -0.9387, -1.2432, -0.6982, -0.7042, -0.8412,\n",
       "                       -0.2364, -0.7934, -0.6790, -0.3253, -0.5075, -0.8497, -0.6150, -0.7708,\n",
       "                       -0.9791, -0.5353, -1.3899, -0.8502, -1.0455, -0.7934, -0.7693, -0.7290,\n",
       "                       -0.8651, -0.8047, -0.6968, -0.5923, -0.4387, -0.3710, -0.5184, -0.6027,\n",
       "                       -0.6897, -0.3814, -0.8405, -0.4683, -0.7368, -1.1553, -0.4458, -0.6646,\n",
       "                       -1.0647, -0.8257, -0.9248, -0.8891, -0.6665, -0.6617, -0.5781, -0.6430,\n",
       "                       -0.3903, -0.9442, -0.6161, -1.0172, -0.4154, -0.6672, -0.8541, -0.7734,\n",
       "                       -0.9861, -0.6957, -0.7206, -0.4731, -0.9843, -1.3741, -1.5465, -0.5140,\n",
       "                       -1.3164, -1.5371, -0.8696, -0.5152, -0.4380, -0.8916, -0.4013, -0.7070,\n",
       "                       -0.0829, -1.2649, -0.9195, -0.4602, -0.5690, -0.3859, -0.9872, -0.5043,\n",
       "                       -0.7303, -0.5346, -0.5761, -1.3016, -0.9830, -0.8601, -0.6621, -0.4050,\n",
       "                       -0.6653, -1.0999, -0.8888, -0.7114, -0.8746, -1.3541, -1.0047, -0.7185,\n",
       "                       -1.0306, -0.6835, -0.3828, -0.4672, -0.4306, -0.4007, -0.9167, -0.9040,\n",
       "                       -0.5204, -0.7813, -0.4514, -0.5322, -1.0599, -0.2478, -0.8258, -0.7393,\n",
       "                       -1.2178, -0.5055, -1.3255, -0.6838, -0.2296, -0.6616, -0.4388, -0.6082,\n",
       "                       -0.6968, -0.5102, -0.5002, -1.1876, -0.4553, -0.9203, -0.6361, -0.3064,\n",
       "                       -0.6916, -0.9011, -1.2617, -1.1579, -0.7394, -0.3526, -0.8356, -0.4288,\n",
       "                       -0.6837, -0.8724, -0.5281, -0.5275, -1.5048, -0.7500, -0.6719, -0.6321,\n",
       "                       -0.5012, -0.4445, -0.5749, -0.4818, -1.5025, -0.6124, -0.4856, -0.6606,\n",
       "                       -0.4295, -0.3847, -0.9937, -0.6799, -0.4981, -0.6492, -0.9808, -0.4547,\n",
       "                       -0.8853, -0.7740, -0.7489, -0.9128, -0.2053, -0.7935, -1.2807, -1.1597,\n",
       "                       -0.4327, -1.1971, -1.1048, -1.2620, -0.4729, -0.9052, -1.1114, -0.8441,\n",
       "                       -0.8827, -0.7090, -1.1702, -0.4418, -0.8893, -0.4334, -0.4596, -0.9540,\n",
       "                       -0.2798, -0.7473, -0.5134, -0.6936, -0.5622, -0.6581, -0.7326, -0.9532],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn2.running_mean',\n",
       "               tensor([ -1.4702,  -7.5261,  -9.0960,  -4.1244, -15.8437,   0.0601, -13.9861,\n",
       "                       -10.4648,  -7.9656, -10.9215,  -6.4915,  -7.4606,  -9.5311, -16.9865,\n",
       "                        -8.4892, -10.4522,  -1.9626,  -9.8937,  -6.6647,  -5.8785,  -4.0965,\n",
       "                        -5.0333,  -3.0136, -13.0450,  -7.0458,  -9.7579, -10.3586,  -2.7180,\n",
       "                        -8.4666, -10.6291,  -6.5348,  -4.7565,  -6.9567,  -6.9580,  -8.6993,\n",
       "                        -9.6710, -14.4614,  -7.0638,  -6.7070,  -2.8827,  -4.6731,  -8.4960,\n",
       "                        -8.5850,  -1.3421, -10.1174,  -8.4068,  -4.2469,  -0.5439, -19.7474,\n",
       "                        -8.4067,  -7.4392,  -7.0142,  -4.1293, -11.4068,  -3.6506,  -6.9777,\n",
       "                         1.1502,  -8.5512,  -5.3328,  -7.5615,  -4.6111,  -7.3255,   4.4726,\n",
       "                        -9.2145,  -9.8175,  -9.4531, -12.2555, -13.7996,  -6.8109,  -5.8520,\n",
       "                        -2.4793,  -8.9689,  -2.1367,  -6.9250,  -3.7762,  -3.6740,  -5.8788,\n",
       "                       -10.3415,   1.3295,  -7.3619,  -6.0016,  -6.8544, -12.8972,  -4.3063,\n",
       "                        -7.0067,  -3.3848,  -3.1851,  -5.4246, -10.8809,  -5.6635,  -2.5603,\n",
       "                        -9.8886,  -5.1033, -15.7689, -25.8754,  -3.4586, -12.5538, -11.3070,\n",
       "                       -10.5685,  -6.0311,  -6.8175,  -7.0794,  -0.8138,  -7.3253,  -5.0412,\n",
       "                        -4.7882, -13.4649,  -3.6828,  -1.3459,  -9.1314,  -1.3486,  -6.7120,\n",
       "                        -9.3007,  -1.0152,  -8.9602,  -5.2989,  -4.8791,  -8.8622, -15.2891,\n",
       "                        -3.9245, -15.3539,  -3.8454,  -7.4117,  -9.3453,  -9.5243,  -6.8217,\n",
       "                       -10.7367, -10.2432,  -7.7965,  -8.0813,  -7.7520,  -8.3832,  -9.2845,\n",
       "                        -8.7456,  -8.5718,  -9.5200, -10.9150,  -5.8378,  -8.3746,  -8.6841,\n",
       "                       -15.6432, -11.9312, -14.2457, -10.1337, -14.1260,  -1.6100,  -5.4394,\n",
       "                        -9.9503,  -4.2216, -10.8353, -13.0583,  -2.7815,  -1.7743,  -5.0838,\n",
       "                        -8.1573,  -4.4856,  -3.6634,  -6.0500,  -5.9483,   0.6658,  -1.8242,\n",
       "                       -11.3591,  -3.6431,  -9.8716,  -7.4856,  -3.6998,  -4.4391,  -3.5694,\n",
       "                        -6.7318,  -4.9573,  -2.8916,   2.2297,  -4.4468,  -6.7488,  -2.4973,\n",
       "                       -17.0730, -15.7020,   0.8610,  -8.9913,  -2.5871,  -3.4357,  -7.3534,\n",
       "                        -8.2018,  -3.2681,  -4.6487,  -6.4143,  -5.9811,  -6.8900,  -3.7506,\n",
       "                       -13.6989,  -4.4421,  -4.5888,   3.5258,  -8.5477,  -4.5585,  -8.9651,\n",
       "                       -10.2545,  -3.8572,  -8.8788, -19.9023,  -9.6251,  -6.0464,  -7.3997,\n",
       "                        -6.3586,  -8.2662, -20.2288,  -7.7977,  -7.7204,  -1.1585, -16.4594,\n",
       "                        -4.4503,  -6.8667, -10.5185,  -5.8069, -13.9427,  -6.8192,  -3.2164,\n",
       "                        -7.0238,  -6.6468, -13.3483,  -7.9135, -17.6997,  -5.8214,  -5.8938,\n",
       "                        -8.4038,  -8.0926,  -7.5690,  -6.3242,   2.5601,  -3.1584, -11.3321,\n",
       "                        -7.1829, -16.4834,  -5.9734, -10.1909, -10.3939,  -4.9588, -14.5848,\n",
       "                        -6.1288,  -4.9455,  -5.6991, -12.6711, -11.7644,  -4.9079, -13.2423,\n",
       "                       -10.7634,  -3.4840, -14.7149, -13.6210,  -6.9997,  -4.8761,  -6.4500,\n",
       "                        -2.1640,  -7.8403,  -8.5216,  -7.6493], device='cuda:0')),\n",
       "              ('conv_block3.bn2.running_var',\n",
       "               tensor([ 59.8419,  46.6864,  55.3771,  34.7278,  64.4680,   7.8799,  34.1689,\n",
       "                        26.9337,  53.1511,  37.1646,  38.1185,  40.4804,  39.0917,  76.3287,\n",
       "                        30.4272,  63.1503,  24.5585,  84.9440,  24.9018,  55.2465, 182.7599,\n",
       "                        28.0385,  28.9231,  39.8621,  28.4355,  40.8507,  60.5825,  31.9665,\n",
       "                        47.7517,  44.8826,  62.6481,  34.2635,  39.0404,  36.1486,  94.6646,\n",
       "                        28.1211,  50.6996,  65.7853,  32.9192,  26.4433,  28.3732,  58.9241,\n",
       "                        22.6677,  29.3474,  70.0667,  34.0691,  22.5286,  15.8769,  68.5004,\n",
       "                        25.1693,  38.0410,  32.2456,  55.7811,  61.3049,  18.2502,  20.8262,\n",
       "                        39.9201,  71.6527,  42.1144,  33.9847,  28.6949,  68.4117,  25.6952,\n",
       "                        23.0342,  39.4047,  88.6352,  58.2498,  70.3978,  69.6812,  41.4912,\n",
       "                        26.9795,  55.4636,  32.0680, 126.1729,  37.2506,  19.2954,  18.9907,\n",
       "                        53.1693,  22.8391,  71.3640,  50.3768,  49.9865,  30.8662,   6.1223,\n",
       "                        34.7939,  30.2270,  22.2285,  31.5911,  63.0889,  52.5883,  51.5320,\n",
       "                        33.4029,  26.0355,  28.5027, 133.2492,  37.4598,  46.6714,  47.3565,\n",
       "                        27.9024,  43.9909,  32.3756,  45.4458,  23.5504,  58.1548,  40.2606,\n",
       "                        18.5325,  55.9243,  38.3704,  35.1260,  49.5195,  30.5532,  56.4863,\n",
       "                        86.0398,  16.7380,  32.7265,  38.0343,  16.2883,  39.8262,  39.5395,\n",
       "                        24.1407,  60.5865,  30.5723,  34.2461,  54.2818,  68.4435,  47.7465,\n",
       "                        57.8525,  42.9859,  23.3004,  40.0225,  25.6599,  31.8987,  83.6048,\n",
       "                        50.0678,  51.7656,  56.2813,  96.1417,  20.7157,  38.0868,  23.4276,\n",
       "                        50.7810, 103.9076, 107.7219,  64.4746,  84.6721,  37.5603,  21.2836,\n",
       "                        36.5941,  84.3289,  50.0158,  78.2771,  29.3240,  26.7829,  40.8485,\n",
       "                        41.8393,  33.1868,  22.6663,  49.8420,  43.2384,  25.5908,   9.6605,\n",
       "                        86.6599,  36.2392, 127.7149,  39.3601,  27.7295,  50.8344,  76.4676,\n",
       "                        31.3997,  48.4627,  21.3381,  29.6824, 110.5609,  73.1441,  28.9639,\n",
       "                        51.0216,  60.7324,  91.5960,  57.8948,  24.0942,  46.2351,  62.6246,\n",
       "                        32.0127,  19.1971,  49.1264,  25.6590,  26.4579,  34.6806,  26.6324,\n",
       "                        37.4899,  32.2766,  52.7123,  23.9831,  58.8390,  83.8176,  43.2987,\n",
       "                        57.4446,  25.2534,  59.4769, 128.2198,  58.8309,  30.2886,  59.5462,\n",
       "                        44.6400,  68.2253,  89.6362,  26.3164,  17.0455,  23.6609,  59.9073,\n",
       "                        30.6726,  32.9372,  62.9316,  31.6858,  37.8728,  46.1366,  31.4953,\n",
       "                        39.3507,  24.2542,  27.9862,  52.2325,  65.8136,  45.2822,  23.5275,\n",
       "                        87.0662,  36.4273,  15.8369,  24.9422,  58.6485,  22.4227,  53.8353,\n",
       "                        50.3004, 102.8278,  35.8391,  43.6215,  41.7931,  47.4556,  46.1561,\n",
       "                        45.7388,  64.8240,  21.0445,  39.0325,  52.5393,  59.5230,  51.4119,\n",
       "                        43.8038,  13.5917,  63.1492, 184.7574,  19.9137,  29.5233,  34.8415,\n",
       "                        23.4548,  65.9048,  50.7978,  19.1666], device='cuda:0')),\n",
       "              ('conv_block3.bn2.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('conv_block4.conv1.weight',\n",
       "               tensor([[[[-7.3527e-02, -5.8330e-02, -4.1906e-01],\n",
       "                         [ 6.6424e-02, -1.8634e-01, -9.2805e-02],\n",
       "                         [-2.8199e-02, -2.5484e-01, -9.7002e-02]],\n",
       "               \n",
       "                        [[ 8.2591e-02,  3.5903e-02, -2.6009e-01],\n",
       "                         [ 5.4143e-02,  1.1681e-02, -5.6037e-01],\n",
       "                         [ 8.1350e-02,  1.1125e-01, -1.2322e-01]],\n",
       "               \n",
       "                        [[ 2.4850e-02,  1.8085e-02, -1.6559e-02],\n",
       "                         [ 3.4763e-01, -1.5919e-01, -1.1163e-01],\n",
       "                         [ 3.3212e-01, -9.6552e-03,  4.6978e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.9762e-01,  1.7379e-01,  7.4672e-02],\n",
       "                         [-6.0021e-02,  3.8102e-01,  4.1522e-02],\n",
       "                         [-2.2095e-01,  1.8759e-01,  4.2613e-02]],\n",
       "               \n",
       "                        [[ 1.2402e-01, -6.6150e-02,  6.0455e-03],\n",
       "                         [ 1.1466e-01, -8.8066e-02,  3.5236e-01],\n",
       "                         [-6.2941e-02, -9.5322e-02,  5.3060e-01]],\n",
       "               \n",
       "                        [[-9.5082e-02, -4.6542e-02, -8.6630e-02],\n",
       "                         [-2.6230e-02, -1.8135e-01, -3.3520e-01],\n",
       "                         [-2.0784e-01, -2.2576e-02, -2.1084e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.1566e-01,  2.0588e-02,  6.6263e-02],\n",
       "                         [-8.5111e-02, -2.6206e-01, -1.0777e-01],\n",
       "                         [ 1.0268e-01, -3.1780e-01, -2.2440e-01]],\n",
       "               \n",
       "                        [[-5.4370e-02, -7.6778e-02,  2.2761e-01],\n",
       "                         [-1.1858e-01, -1.0433e-01,  7.1867e-02],\n",
       "                         [-4.8879e-02,  6.1202e-04,  1.3718e-02]],\n",
       "               \n",
       "                        [[ 1.5320e-01,  2.3033e-01, -9.7995e-01],\n",
       "                         [-2.8964e-02,  7.7473e-01, -3.8120e-01],\n",
       "                         [ 4.0766e-01, -9.2223e-03, -1.7238e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.0447e-02, -3.3284e-02, -3.0926e-02],\n",
       "                         [ 1.2921e-01, -1.9922e-02, -1.0855e-01],\n",
       "                         [ 5.8102e-01, -1.0821e-02,  2.9675e-03]],\n",
       "               \n",
       "                        [[ 7.0895e-04, -5.6785e-02, -1.3908e-01],\n",
       "                         [-2.1263e-01, -1.5605e-01,  9.7485e-02],\n",
       "                         [-1.6832e-01, -4.5466e-02,  3.1026e-01]],\n",
       "               \n",
       "                        [[-1.3067e-01, -3.6953e-02,  4.6768e-02],\n",
       "                         [-1.4219e-01,  1.4849e-02,  9.7629e-02],\n",
       "                         [-8.7640e-02,  2.7529e-02,  8.6749e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0418e-01, -1.7852e-02, -1.0183e-02],\n",
       "                         [ 9.3492e-03,  5.6304e-03,  5.9368e-03],\n",
       "                         [-6.5123e-02, -8.2705e-03,  1.7285e-03]],\n",
       "               \n",
       "                        [[ 7.8422e-03,  7.3660e-02,  5.5407e-02],\n",
       "                         [-1.1473e-02, -5.4608e-02,  6.2363e-03],\n",
       "                         [-1.0343e-01, -9.1966e-02, -4.7206e-02]],\n",
       "               \n",
       "                        [[-2.0025e-02, -4.8098e-03, -3.1223e-02],\n",
       "                         [-2.7892e-02, -6.6204e-02, -3.0356e-02],\n",
       "                         [ 1.6297e-02, -2.2219e-02, -6.7848e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.3567e-01,  3.6722e-02,  1.9490e-02],\n",
       "                         [ 4.8407e-02,  5.0103e-03, -1.3020e-01],\n",
       "                         [ 1.8656e-02, -1.7606e-01, -3.9249e-01]],\n",
       "               \n",
       "                        [[-7.7295e-02, -4.7363e-01, -1.5023e-01],\n",
       "                         [ 1.9588e-03, -7.9943e-02, -2.9832e-01],\n",
       "                         [-1.3880e-02, -6.5036e-02, -7.2043e-02]],\n",
       "               \n",
       "                        [[ 8.4254e-02,  6.6534e-02, -4.5067e-02],\n",
       "                         [ 6.5078e-03, -1.9782e-02, -5.2631e-02],\n",
       "                         [ 3.3731e-01,  3.8689e-02, -2.2818e-01]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.5988e-01,  1.3477e-01,  2.8558e-02],\n",
       "                         [-3.2831e-01, -1.4822e-01, -7.9835e-02],\n",
       "                         [-1.4925e-01, -4.5345e-01, -6.9098e-02]],\n",
       "               \n",
       "                        [[-3.1530e-02,  1.3007e-02,  1.9100e-03],\n",
       "                         [ 1.9567e-02,  1.3877e-01,  1.1804e-02],\n",
       "                         [-7.6040e-03,  8.4362e-02, -7.0716e-02]],\n",
       "               \n",
       "                        [[-3.0689e-01, -8.3242e-02, -4.3421e-02],\n",
       "                         [-1.3225e-01,  7.7386e-02,  2.1925e-02],\n",
       "                         [ 9.5136e-02,  8.1359e-02,  1.2255e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-9.2764e-02,  1.6576e-01,  9.9318e-02],\n",
       "                         [ 2.7673e-02,  4.3835e-02, -4.9196e-02],\n",
       "                         [ 2.8249e-02,  3.2986e-02, -6.5558e-02]],\n",
       "               \n",
       "                        [[-1.0286e-01,  1.3720e-02,  2.7706e-02],\n",
       "                         [-1.4617e-01,  4.3941e-02,  3.6095e-01],\n",
       "                         [ 1.4585e-01,  6.4106e-02,  2.3770e-01]],\n",
       "               \n",
       "                        [[ 2.7619e-02,  3.0040e-02, -9.6906e-02],\n",
       "                         [ 7.4337e-02,  2.1320e-01, -2.8724e-02],\n",
       "                         [ 2.7672e-03,  7.9251e-02, -9.0972e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.8610e-02, -1.7429e-01, -4.4300e-02],\n",
       "                         [-3.3551e-02, -4.9542e-02,  1.4652e-02],\n",
       "                         [-3.3479e-02, -7.0980e-02, -8.0356e-02]],\n",
       "               \n",
       "                        [[-2.7756e-02, -7.9452e-02, -7.5759e-02],\n",
       "                         [-1.1666e-01, -8.9993e-02, -1.0247e-01],\n",
       "                         [-6.9104e-02, -3.4757e-02, -8.4282e-03]],\n",
       "               \n",
       "                        [[ 4.0796e-01,  1.9680e-01,  3.7854e-02],\n",
       "                         [ 1.0637e-01,  8.7017e-02,  1.5622e-01],\n",
       "                         [-2.1268e-01,  1.1225e-02,  2.2826e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.8156e-02, -4.1926e-02, -4.9100e-02],\n",
       "                         [-1.2655e-01, -2.9428e-02,  2.8235e-02],\n",
       "                         [-2.9040e-01, -2.6950e-01, -4.4532e-02]],\n",
       "               \n",
       "                        [[-3.8187e-01, -4.6918e-01,  7.8374e-02],\n",
       "                         [-9.1141e-02, -9.1839e-02,  3.1614e-01],\n",
       "                         [-1.3928e-01, -1.2413e-01, -6.7637e-03]],\n",
       "               \n",
       "                        [[ 2.9741e-02,  8.0867e-02,  2.1040e-01],\n",
       "                         [ 6.3685e-02,  7.0383e-02,  1.3725e-01],\n",
       "                         [ 9.6390e-02,  1.2109e-01,  3.0972e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.1954e-02, -2.2063e-02, -7.8171e-02],\n",
       "                         [-5.0511e-02, -3.7596e-02,  8.6448e-04],\n",
       "                         [ 3.3163e-02, -1.2497e-02, -7.2381e-02]],\n",
       "               \n",
       "                        [[-1.1597e-02,  1.0720e-01, -6.4285e-02],\n",
       "                         [ 5.4946e-03, -4.3051e-02,  4.2967e-02],\n",
       "                         [-4.8722e-01, -7.3827e-02, -1.6862e-02]],\n",
       "               \n",
       "                        [[-1.9065e-02,  6.6082e-02,  1.8377e-02],\n",
       "                         [-1.6972e-01,  3.0106e-02,  7.5643e-02],\n",
       "                         [ 1.0057e-02,  2.0472e-02,  1.9458e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.9282e-02,  1.4396e-01,  1.7568e-01],\n",
       "                         [ 6.9846e-02,  2.3479e-02,  8.5786e-02],\n",
       "                         [ 1.1289e-01,  5.0129e-02,  4.2139e-02]],\n",
       "               \n",
       "                        [[-5.4125e-02,  5.7920e-02, -5.3636e-02],\n",
       "                         [ 6.6780e-02,  5.0452e-02,  1.6591e-01],\n",
       "                         [ 1.0528e-01, -8.7322e-03,  6.8157e-02]],\n",
       "               \n",
       "                        [[-6.9756e-02, -1.0653e-01, -2.5235e-01],\n",
       "                         [ 3.7206e-02, -3.0671e-03, -6.3005e-01],\n",
       "                         [ 7.2816e-02, -6.9111e-02, -3.9688e-01]]]], device='cuda:0')),\n",
       "              ('conv_block4.conv2.weight',\n",
       "               tensor([[[[-9.0594e-02, -4.3171e-02,  2.8623e-02],\n",
       "                         [-1.3577e-02, -1.2656e-01,  6.5320e-03],\n",
       "                         [-2.8144e-02, -2.9893e-02,  3.1068e-02]],\n",
       "               \n",
       "                        [[-1.5769e-02, -3.1000e-02,  2.6751e-03],\n",
       "                         [ 1.2341e-02, -3.9842e-02, -6.9435e-03],\n",
       "                         [-1.3230e-02, -1.9250e-02,  2.2650e-02]],\n",
       "               \n",
       "                        [[ 5.3186e-03,  4.9352e-02,  4.0648e-01],\n",
       "                         [ 1.0962e-02,  3.1386e-02,  1.1191e-01],\n",
       "                         [ 4.4109e-02,  1.7720e-02,  1.1943e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.4560e-02,  1.8407e-02,  4.9955e-03],\n",
       "                         [ 1.6846e-02,  2.7284e-02, -1.6889e-02],\n",
       "                         [ 2.5725e-02,  2.5390e-02, -5.9905e-03]],\n",
       "               \n",
       "                        [[ 3.9072e-02,  2.6164e-02,  6.4606e-02],\n",
       "                         [-2.1238e-02,  2.5817e-02, -3.7977e-02],\n",
       "                         [-3.2179e-02,  4.1690e-02,  3.1052e-02]],\n",
       "               \n",
       "                        [[-5.3536e-02, -1.1477e-02,  1.0834e-01],\n",
       "                         [-2.3124e-02,  2.3634e-02,  7.2487e-02],\n",
       "                         [-1.5903e-02,  2.7700e-02,  6.2532e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.6606e-01, -4.3486e-02, -2.6403e-02],\n",
       "                         [ 5.8114e-02, -7.1829e-02, -1.2364e-02],\n",
       "                         [ 5.4259e-02, -1.7733e-01, -1.2283e-02]],\n",
       "               \n",
       "                        [[-2.7243e-01, -1.0436e-01, -7.1485e-02],\n",
       "                         [-1.8838e-01, -8.1788e-02, -8.7119e-02],\n",
       "                         [-9.1314e-02, -6.5466e-03, -4.4797e-02]],\n",
       "               \n",
       "                        [[ 6.1952e-01,  6.2601e-01, -1.0997e-01],\n",
       "                         [ 2.7434e-01,  6.1268e-02, -2.6221e-01],\n",
       "                         [ 1.2477e-01,  9.0290e-02, -2.5043e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.6373e-02,  3.4080e-02,  6.3482e-02],\n",
       "                         [-4.2793e-03,  1.9319e-02, -2.9321e-04],\n",
       "                         [-6.1149e-02, -4.6297e-02,  3.1782e-03]],\n",
       "               \n",
       "                        [[-4.7103e-03,  1.6766e-01,  1.4134e-01],\n",
       "                         [-4.2198e-02,  6.3756e-02,  6.1153e-02],\n",
       "                         [-5.9143e-03,  9.5157e-02,  1.0626e-02]],\n",
       "               \n",
       "                        [[ 1.2429e-03,  2.6856e-02,  7.9434e-02],\n",
       "                         [ 2.5057e-02,  4.9677e-03,  9.5547e-02],\n",
       "                         [ 7.1949e-02,  7.5469e-02,  2.1050e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.2555e-01,  1.2924e-01,  4.0623e-02],\n",
       "                         [-1.7662e-01, -7.7994e-02,  5.5243e-03],\n",
       "                         [-2.0137e-01,  8.4179e-03,  9.0826e-03]],\n",
       "               \n",
       "                        [[ 9.9615e-02,  1.6309e-02,  4.1251e-03],\n",
       "                         [ 1.6637e-01,  1.4672e-01,  3.4422e-02],\n",
       "                         [ 9.0552e-02,  7.7632e-02,  1.9416e-02]],\n",
       "               \n",
       "                        [[-5.9614e-02,  4.2547e-02,  3.1013e-03],\n",
       "                         [ 7.8067e-02,  8.1066e-02, -3.1375e-03],\n",
       "                         [ 1.6085e-01,  1.4215e-02, -2.5787e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.2138e-01,  5.3601e-02,  1.4537e-01],\n",
       "                         [ 6.9985e-02,  9.1685e-02,  1.8300e-01],\n",
       "                         [ 8.4148e-02,  3.1086e-02,  4.2757e-01]],\n",
       "               \n",
       "                        [[-1.0844e-01, -8.2102e-02, -9.0195e-02],\n",
       "                         [-1.2375e-01, -1.0580e-01, -4.5260e-02],\n",
       "                         [-3.0341e-01, -3.3563e-02, -3.0141e-02]],\n",
       "               \n",
       "                        [[ 5.0400e-01, -1.6527e-01, -1.3059e-01],\n",
       "                         [-2.3419e-01, -1.1138e-01,  7.2042e-03],\n",
       "                         [-1.3846e-04,  5.0807e-02,  3.4115e-01]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-1.1320e-02, -1.8050e-02, -9.4476e-02],\n",
       "                         [-9.0761e-03,  1.8728e-02, -5.9730e-02],\n",
       "                         [-1.6507e-02, -8.2820e-03, -8.4360e-02]],\n",
       "               \n",
       "                        [[-7.8567e-02, -4.6781e-01, -1.4743e-02],\n",
       "                         [-6.1208e-02, -6.9234e-02, -1.0619e-02],\n",
       "                         [-2.2101e-01, -4.5399e-02, -2.6702e-01]],\n",
       "               \n",
       "                        [[-5.8043e-01, -6.3010e-01, -1.7806e-02],\n",
       "                         [-6.0091e-03, -1.8259e-01, -1.8872e-01],\n",
       "                         [-5.9107e-02, -1.4406e-02,  1.2415e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.4559e-04,  4.1308e-02, -1.5204e-01],\n",
       "                         [ 1.5748e-02, -2.0472e-01, -6.0047e-02],\n",
       "                         [-7.4156e-03, -1.8409e-02, -2.1522e-02]],\n",
       "               \n",
       "                        [[ 9.1478e-02,  3.2214e-02,  8.7190e-03],\n",
       "                         [ 1.2215e-02,  7.2067e-04, -1.2806e-01],\n",
       "                         [ 2.1093e-01,  4.0460e-01, -2.0300e-02]],\n",
       "               \n",
       "                        [[-3.4421e-02,  1.8934e-02, -9.3179e-02],\n",
       "                         [-5.1956e-02, -8.4250e-03,  5.7349e-03],\n",
       "                         [-3.0382e-02, -1.6247e-01,  9.9505e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.6745e-02, -6.2207e-02,  5.3540e-02],\n",
       "                         [ 4.8245e-02, -2.2446e-02,  7.4984e-02],\n",
       "                         [ 4.1261e-02, -4.4252e-02, -1.4486e-02]],\n",
       "               \n",
       "                        [[ 4.9889e-03, -3.4463e-02,  6.6025e-02],\n",
       "                         [ 1.0247e-01,  5.9934e-02,  4.8657e-04],\n",
       "                         [ 1.9177e-02, -5.5665e-02, -1.1431e-02]],\n",
       "               \n",
       "                        [[-1.0862e-02, -1.1666e-01, -8.7180e-02],\n",
       "                         [-8.7191e-02, -1.4834e-01, -9.6446e-02],\n",
       "                         [-2.2343e-01, -4.0510e-01, -6.9859e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.8848e-02,  7.6528e-02,  3.8838e-02],\n",
       "                         [-2.0346e-02,  8.7434e-03, -7.8230e-05],\n",
       "                         [ 2.9221e-03,  3.5395e-02,  6.3049e-03]],\n",
       "               \n",
       "                        [[-3.8498e-02, -6.5145e-02, -4.3182e-01],\n",
       "                         [-3.6867e-02, -5.1406e-02, -1.9798e-01],\n",
       "                         [-2.8174e-02, -3.8790e-03, -1.1054e-01]],\n",
       "               \n",
       "                        [[ 3.1057e-02, -9.1596e-02,  2.4799e-02],\n",
       "                         [-4.2729e-02, -1.1368e-01, -2.4714e-02],\n",
       "                         [-8.7929e-02,  5.7666e-02, -1.4645e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.9982e-02,  3.6203e-02, -1.3663e-02],\n",
       "                         [-8.5053e-02,  4.7016e-02,  7.5140e-02],\n",
       "                         [ 2.1906e-02,  8.4971e-02,  9.1872e-03]],\n",
       "               \n",
       "                        [[-1.2463e-01, -8.2890e-02, -2.2605e-01],\n",
       "                         [-2.4425e-02,  6.0611e-03, -6.1916e-01],\n",
       "                         [-4.0392e-02,  7.1317e-03, -1.6963e-01]],\n",
       "               \n",
       "                        [[-3.5403e-02, -1.0577e-02, -1.2909e-02],\n",
       "                         [-7.3299e-02, -1.0403e-01, -7.5843e-02],\n",
       "                         [ 8.2496e-02, -6.5073e-02, -3.5948e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.6055e-02, -1.6427e-02, -9.8965e-03],\n",
       "                         [-1.2685e-01, -5.2859e-02,  2.9457e-02],\n",
       "                         [-2.7126e-01, -1.0239e-01, -1.1121e-01]],\n",
       "               \n",
       "                        [[ 1.6249e-01, -1.7248e-02, -4.1401e-02],\n",
       "                         [ 2.2340e-01, -4.6004e-02, -5.9627e-02],\n",
       "                         [ 2.0007e-01,  1.0695e-01,  1.3299e-01]],\n",
       "               \n",
       "                        [[-8.4458e-03, -4.1423e-02, -1.3292e-01],\n",
       "                         [-5.3076e-02, -2.0036e-03, -1.0982e-02],\n",
       "                         [ 3.7487e-03,  6.2089e-03, -5.6483e-03]]]], device='cuda:0')),\n",
       "              ('conv_block4.bn1.weight',\n",
       "               tensor([1.0934, 1.2118, 1.0997, 1.1651, 0.9556, 1.0499, 1.0468, 1.6791, 0.8397,\n",
       "                       1.4631, 1.1803, 1.2100, 1.0100, 1.0326, 1.0685, 1.3371, 1.2549, 1.1321,\n",
       "                       1.0191, 1.0819, 1.0996, 1.0423, 1.2175, 0.6478, 1.1581, 1.1645, 1.1383,\n",
       "                       0.8087, 1.0514, 1.3228, 1.0235, 0.9431, 1.0795, 0.9983, 1.3079, 1.3322,\n",
       "                       1.0884, 1.2506, 1.4043, 1.0524, 0.8295, 1.0653, 1.0956, 0.9815, 1.4049,\n",
       "                       1.0583, 1.0289, 1.2519, 1.1278, 1.2560, 0.8546, 1.0865, 1.0848, 1.0682,\n",
       "                       1.1871, 1.1801, 1.0131, 1.2457, 1.0094, 1.4135, 1.1908, 1.0862, 1.1074,\n",
       "                       1.2927, 1.0888, 1.1173, 1.1418, 1.1787, 1.2679, 1.0827, 0.9503, 1.1370,\n",
       "                       1.0547, 1.1450, 1.3884, 0.7686, 0.7991, 1.0920, 1.0299, 1.3662, 1.0680,\n",
       "                       1.1644, 1.4693, 0.9884, 1.4838, 0.8536, 1.1441, 0.7452, 1.1168, 0.9902,\n",
       "                       1.0768, 1.1516, 1.4887, 1.0346, 1.0907, 1.0534, 1.3777, 1.2569, 1.1673,\n",
       "                       0.6395, 1.1523, 1.1936, 1.2374, 1.0653, 0.9966, 1.1087, 1.2060, 1.0975,\n",
       "                       1.3378, 1.0990, 1.2123, 1.4141, 1.1195, 1.2939, 1.1196, 0.9210, 0.9689,\n",
       "                       1.0712, 1.1250, 1.1275, 1.2344, 0.9098, 1.0490, 1.3138, 1.0310, 0.9341,\n",
       "                       1.0702, 1.3528, 1.1336, 1.0334, 0.9543, 1.1796, 0.7753, 1.1459, 1.2717,\n",
       "                       1.0935, 1.1606, 1.1292, 0.9941, 1.1146, 1.1282, 1.1237, 1.0255, 1.0468,\n",
       "                       1.1060, 1.2063, 1.1067, 1.0392, 1.0333, 1.2439, 1.0751, 1.4233, 0.4336,\n",
       "                       0.9155, 1.1470, 0.9003, 1.0466, 1.2331, 1.0186, 0.8789, 1.3974, 1.1223,\n",
       "                       0.9638, 0.7288, 1.3806, 1.1737, 1.2771, 0.9620, 1.4051, 0.8939, 1.1509,\n",
       "                       0.8734, 0.8943, 1.0782, 0.9358, 1.0474, 1.1177, 1.2397, 0.9491, 0.4330,\n",
       "                       1.2491, 0.7807, 1.0697, 0.9668, 1.0377, 1.0833, 1.2604, 0.9567, 1.1956,\n",
       "                       1.2210, 1.2006, 1.3791, 0.9413, 1.0952, 1.2765, 1.4256, 1.0201, 1.1834,\n",
       "                       0.9488, 1.1815, 0.8673, 1.0811, 0.7457, 0.7848, 1.0943, 1.1707, 1.0110,\n",
       "                       1.1734, 0.9905, 1.0215, 1.0994, 0.6644, 1.1290, 0.8403, 1.1600, 0.8307,\n",
       "                       1.0786, 1.0712, 1.0278, 1.2475, 1.1164, 1.0934, 0.9838, 0.9209, 1.3015,\n",
       "                       1.0108, 1.1112, 1.0901, 1.2189, 0.9021, 1.0121, 1.0198, 1.1926, 1.3276,\n",
       "                       1.0855, 1.2293, 1.2117, 1.0494, 0.8866, 1.0659, 1.3383, 0.7597, 0.9876,\n",
       "                       1.1420, 1.0195, 1.1312, 1.0511, 1.2097, 1.3916, 0.9538, 1.0354, 1.1795,\n",
       "                       1.0310, 0.5911, 1.3090, 1.1229, 1.2459, 1.2349, 1.0130, 1.5033, 0.4951,\n",
       "                       1.4281, 1.1679, 1.3152, 1.0300, 1.1538, 1.0675, 0.9603, 1.1430, 0.9676,\n",
       "                       0.9974, 1.3411, 0.9493, 1.3682, 1.2149, 0.9030, 0.7117, 1.1353, 1.2089,\n",
       "                       1.2629, 1.2649, 0.9893, 1.1690, 1.1100, 1.2150, 1.0017, 1.0014, 0.9801,\n",
       "                       1.1921, 0.8247, 1.1226, 1.0720, 1.2914, 1.2870, 1.1213, 0.9548, 0.4392,\n",
       "                       1.0094, 0.7913, 1.1313, 1.2601, 1.3016, 1.0375, 1.1167, 1.4943, 1.2842,\n",
       "                       1.0548, 1.1134, 1.3424, 0.8495, 0.9882, 1.1660, 1.2609, 1.3132, 1.2326,\n",
       "                       0.9937, 1.1875, 1.1749, 0.8979, 1.5811, 1.1088, 1.0500, 1.0597, 1.1438,\n",
       "                       1.1214, 1.0477, 0.6908, 1.1349, 1.0166, 1.0676, 1.2726, 0.9296, 0.9954,\n",
       "                       0.9272, 0.7861, 1.2890, 1.2466, 0.4386, 1.0987, 1.1821, 1.3075, 1.2576,\n",
       "                       1.1726, 1.0406, 1.3856, 1.1358, 0.9838, 1.0175, 0.9020, 0.7806, 1.0185,\n",
       "                       1.1862, 1.1995, 1.2348, 1.2606, 1.0653, 1.1699, 1.0533, 1.1005, 0.9642,\n",
       "                       1.1266, 1.0285, 1.2220, 1.0239, 0.9823, 0.8254, 1.2622, 0.9511, 1.4241,\n",
       "                       0.8431, 1.0184, 0.9478, 1.3224, 1.1730, 1.1140, 1.1674, 1.1226, 0.9391,\n",
       "                       1.1084, 0.9542, 0.9287, 1.1368, 1.4738, 1.4761, 0.7583, 1.3612, 1.0543,\n",
       "                       1.2059, 1.1912, 1.4951, 1.1249, 1.0023, 1.3957, 1.0687, 1.1025, 1.0065,\n",
       "                       1.2643, 1.1189, 1.0819, 0.9310, 1.2104, 0.8203, 1.2420, 0.9849, 1.3451,\n",
       "                       1.0008, 1.4298, 1.0700, 1.1470, 0.8283, 1.0982, 1.5118, 1.0072, 1.0312,\n",
       "                       1.1545, 1.0001, 1.1992, 0.9705, 0.9506, 1.0551, 1.1225, 0.5881, 1.2736,\n",
       "                       1.0370, 1.0166, 1.3557, 1.0009, 0.9541, 1.5203, 1.4053, 0.7987, 0.8513,\n",
       "                       1.0740, 0.8883, 0.5664, 1.2001, 1.2428, 0.8890, 1.2917, 1.0651, 1.0447,\n",
       "                       1.1669, 1.1238, 1.1924, 1.2416, 0.9523, 1.0549, 0.8811, 1.2200, 1.0615,\n",
       "                       1.0588, 0.9525, 1.1485, 1.0688, 0.9856, 1.0181, 1.0344, 1.0528, 0.4611,\n",
       "                       1.3397, 1.3058, 1.6077, 1.1131, 0.9831, 1.0411, 1.0494, 1.1970, 1.3324,\n",
       "                       1.2814, 1.1883, 1.0854, 1.0475, 1.2356, 0.3708, 1.1433, 1.3900, 1.3344,\n",
       "                       1.3390, 1.0398, 0.5689, 1.0799, 0.9223, 0.9293, 1.0345, 1.3106, 0.9048,\n",
       "                       1.1962, 1.3054, 1.1769, 1.0413, 1.0596, 1.1239, 1.3215, 1.1642, 0.3945,\n",
       "                       1.2451, 1.0795, 1.1239, 1.1625, 1.5971, 1.1279, 1.0491, 1.0490, 1.0158,\n",
       "                       1.0870, 0.8737, 1.4776, 1.0336, 1.0189, 1.1414, 1.2207, 0.9556],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.bias',\n",
       "               tensor([-0.8670, -1.0515, -0.7967, -0.9039, -0.6109, -0.4819, -0.4677, -1.1168,\n",
       "                       -0.8981, -1.0872, -0.4848, -1.0015, -0.7594, -0.4826, -0.9361, -0.4358,\n",
       "                       -0.9968, -0.5406, -0.5462, -0.5878, -0.8460, -0.8826, -0.9557, -1.2344,\n",
       "                       -0.7743, -0.9339, -0.8860, -0.1491, -0.8338, -0.7229, -0.6345, -0.7934,\n",
       "                       -0.7802, -0.4296, -0.8907, -1.2380, -0.8919, -0.8755, -1.0000, -0.8351,\n",
       "                       -0.6019, -0.8339, -0.7901, -0.4828, -0.8359, -0.7534, -0.8633, -0.7791,\n",
       "                       -0.3888, -1.0025, -0.6442, -0.5911, -0.3670, -0.5566, -0.9644, -0.9247,\n",
       "                       -0.4550, -0.7070, -0.3960, -0.9458, -0.9019, -0.8911, -0.7683, -1.1542,\n",
       "                       -0.8646, -0.7810, -0.9508, -0.4666, -0.8045, -0.7485, -0.4894, -0.6673,\n",
       "                       -0.6387, -0.8416, -1.1887, -0.4545, -0.4158, -0.8619, -0.6572, -0.8469,\n",
       "                       -0.9019, -0.9003, -2.3536, -0.4737, -1.3645, -0.3549, -0.9044, -0.4122,\n",
       "                       -0.5526, -0.5089, -0.9127, -0.3423, -1.1394, -0.7960, -1.2435, -0.6848,\n",
       "                       -0.7521, -0.9188, -0.7067, -1.1327, -0.6613, -0.5623, -0.9903, -0.8377,\n",
       "                       -0.7669, -0.8501, -0.8111, -0.6238, -1.3971, -0.8209, -0.7796, -1.0666,\n",
       "                       -1.0437, -1.2046, -0.8824, -0.6002, -0.3942, -0.7175, -0.7329, -0.8077,\n",
       "                       -0.7405, -0.2542, -0.7581, -1.2455, -0.5842, -0.5979, -0.6771, -0.9809,\n",
       "                       -0.9924, -0.5107, -0.7086, -0.4262, -0.4839, -0.6774, -1.2142, -0.6687,\n",
       "                       -0.7448, -1.2198, -0.7156, -0.7290, -0.4919, -0.8271, -0.5451, -0.5303,\n",
       "                       -0.7432, -0.8362, -0.9599, -1.0737, -0.4507, -0.9651, -0.6233, -0.9245,\n",
       "                       -0.7969, -0.5292, -1.0121, -0.5489, -0.6708, -0.8819, -0.6914, -0.6003,\n",
       "                       -0.7735, -0.8641, -0.9489, -0.3975, -0.7387, -0.8070, -0.6544, -0.5712,\n",
       "                       -1.0174, -0.5614, -0.6426, -0.4852, -0.5315, -0.7164, -0.4268, -0.7625,\n",
       "                       -0.5504, -0.9694, -0.4933, -1.2205, -0.7170, -0.3671, -0.7537, -0.4950,\n",
       "                       -0.7685, -0.5964, -0.9691, -0.6962, -0.7394, -1.4089, -0.8302, -0.8799,\n",
       "                       -0.4712, -0.5843, -0.7009, -0.8085, -0.5588, -0.5129, -0.4848, -0.7053,\n",
       "                       -0.4311, -0.8442, -0.7153, -0.3376, -0.8043, -0.8080, -0.3989, -0.7671,\n",
       "                       -0.6730, -0.7547, -0.6015, -0.9697, -0.6020, -0.3885, -0.6168, -0.2425,\n",
       "                       -0.4559, -0.4919, -0.6797, -0.8800, -0.9579, -0.4667, -0.7061, -0.4641,\n",
       "                       -0.9038, -0.9516, -0.6133, -0.6444, -0.9073, -0.4442, -0.5229, -0.4198,\n",
       "                       -1.0247, -0.9276, -0.7662, -0.9671, -1.5339, -0.5897, -0.6957, -0.8626,\n",
       "                       -1.4325, -0.1342, -0.4175, -0.7137, -0.8496, -0.9527, -0.5995, -0.4727,\n",
       "                       -1.0764, -0.7110, -0.6501, -0.7447, -0.8594, -0.1626, -0.9479, -0.6115,\n",
       "                       -0.4600, -1.5309, -1.0071, -0.8682, -1.1240, -0.8243, -0.6410, -0.5810,\n",
       "                       -0.6680, -0.5226, -0.7564, -0.8543, -0.9731, -0.8138, -0.5715, -0.8615,\n",
       "                       -0.2826, -1.0435, -0.9783, -0.5533, -0.5214, -0.6873, -1.0980, -0.4598,\n",
       "                       -0.7001, -0.5862, -0.8216, -0.6704, -0.8650, -0.4872, -0.4855, -0.7847,\n",
       "                       -0.7508, -0.5639, -0.6794, -0.8212, -1.0493, -0.5139, -0.9576, -0.4686,\n",
       "                       -0.7992, -0.5359, -0.4811, -0.9435, -0.7083, -0.8657, -0.5199, -0.7149,\n",
       "                       -0.8437, -0.7211, -0.5653, -1.0153, -1.3695, -0.3345, -0.9941, -0.6498,\n",
       "                       -1.0313, -0.6784, -0.9837, -0.4278, -0.6595, -0.7029, -0.5055, -1.2729,\n",
       "                       -0.7007, -0.4577, -0.5360, -0.6276, -0.6420, -1.0335, -0.3535, -0.6923,\n",
       "                       -0.6867, -0.7489, -1.2583, -0.7546, -0.7017, -0.6569, -0.3603, -0.9398,\n",
       "                       -1.0973, -1.0110, -0.6674, -0.9192, -0.8255, -0.7914, -0.7397, -0.8545,\n",
       "                       -0.6678, -0.8508, -0.7993, -0.5436, -0.3154, -0.5173, -0.9903, -0.6526,\n",
       "                       -0.8355, -1.1440, -1.1652, -0.5798, -0.5114, -0.3725, -1.1412, -0.8006,\n",
       "                       -0.6979, -0.8008, -0.9574, -0.7387, -0.6867, -0.4015, -0.9854, -0.9017,\n",
       "                       -1.0270, -0.4744, -0.6078, -0.5420, -0.7364, -0.8517, -0.8828, -0.6642,\n",
       "                       -0.7378, -0.4371, -0.6936, -0.7272, -0.4750, -0.8688, -0.9083, -0.9105,\n",
       "                       -0.2541, -0.9836, -0.6798, -1.1928, -1.1367, -1.2528, -0.7414, -0.6135,\n",
       "                       -0.9373, -0.7936, -0.5311, -0.6513, -0.9561, -1.0607, -0.6977, -0.5352,\n",
       "                       -0.6878, -0.3796, -0.7188, -0.5826, -1.0510, -0.5715, -1.1299, -1.1674,\n",
       "                       -0.7418, -0.4024, -0.7691, -1.1355, -0.4781, -0.7007, -0.8244, -0.6112,\n",
       "                       -1.1802, -0.5212, -0.4786, -0.7940, -0.7272, -1.0968, -0.8925, -0.7695,\n",
       "                       -0.8478, -0.7787, -0.8470, -0.3396, -1.3441, -1.3165, -0.5961, -0.4991,\n",
       "                       -0.5205, -0.7054, -0.0933, -1.1431, -1.3340, -0.8031, -0.9781, -0.8050,\n",
       "                       -0.7596, -0.7724, -0.7861, -1.0849, -1.1519, -0.5198, -0.6650, -0.4450,\n",
       "                       -1.1317, -0.6758, -1.0329, -0.9787, -0.5724, -0.6152, -0.6820, -0.6245,\n",
       "                       -0.4019, -0.7174, -1.1302, -0.7183, -0.9667, -0.7031, -0.9060, -0.4979,\n",
       "                       -0.6615, -0.7683, -0.8465, -1.5263, -1.1103, -1.0494, -0.9423, -0.4797,\n",
       "                       -1.0082, -0.8080, -0.7034, -1.1421, -0.7871, -0.8133, -0.6548, -0.6763,\n",
       "                       -0.8536, -0.2895, -0.4932, -0.5494, -0.9216, -0.4968, -1.0667, -0.7216,\n",
       "                       -0.7821, -0.4629, -0.4260, -0.6543, -0.7557, -0.7007, -1.0302, -0.7837,\n",
       "                       -0.9631, -0.8807, -0.5527, -1.2953, -0.8765, -0.7579, -1.0614, -0.6944,\n",
       "                       -0.8381, -0.6380, -1.6335, -0.5420, -0.6893, -0.6283, -1.1571, -0.5195],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.running_mean',\n",
       "               tensor([-3.1300e+00, -3.3905e+00, -2.3145e+00, -3.0423e+00, -4.0562e+00,\n",
       "                       -4.1347e+00, -5.5920e+00, -5.7609e+00, -9.0976e-01, -2.9478e+00,\n",
       "                       -3.1021e+00, -1.2967e+00,  1.5767e-01, -2.3516e+00, -1.5741e+00,\n",
       "                       -5.9341e+00, -4.7321e+00, -2.2293e+00, -3.3710e+00, -3.2709e+00,\n",
       "                       -1.5804e+00, -2.0819e+00, -3.4748e+00,  4.9656e-01, -3.3082e+00,\n",
       "                       -1.8829e+00, -2.5663e+00, -3.9651e+00,  2.0447e-01, -5.3695e+00,\n",
       "                       -2.6682e+00, -5.6443e-01, -6.2054e+00, -3.1731e+00, -3.9471e+00,\n",
       "                       -3.1622e+00, -1.9335e+00, -1.7395e+00, -8.0149e-01, -2.1857e+00,\n",
       "                       -7.2340e+00, -2.1293e+00,  3.3923e-01, -3.4248e+00, -5.5493e+00,\n",
       "                       -1.9455e+00, -2.5818e+00, -4.4343e+00, -4.2988e+00, -6.9637e+00,\n",
       "                       -4.7505e+00, -2.1335e+00, -2.4486e+00,  6.0715e-02, -8.0557e-01,\n",
       "                       -3.5771e-01, -2.3439e+00, -4.8666e+00, -4.6354e+00, -4.9233e+00,\n",
       "                       -1.2529e+00, -3.8606e+00, -3.7778e+00,  3.7712e-01, -1.3176e+00,\n",
       "                       -5.0076e+00,  7.9718e-01, -1.7494e+00, -4.6553e+00, -3.1529e+00,\n",
       "                       -9.2973e-01, -3.9609e+00, -3.3435e+00, -5.4165e+00, -2.7524e+00,\n",
       "                       -4.1314e+00, -6.6125e+00, -3.5242e+00, -3.5383e+00, -4.2065e+00,\n",
       "                       -5.3041e+00, -4.5977e+00,  3.5289e+00, -3.7484e+00, -3.6666e+00,\n",
       "                       -5.4761e+00, -1.3002e+00, -2.1869e+00, -2.5921e+00, -4.7990e+00,\n",
       "                        5.6286e-01, -4.8935e+00, -6.2909e-01, -5.0455e+00, -3.9942e+00,\n",
       "                       -4.0004e+00, -1.4496e+00, -2.0045e+00, -9.1035e-01, -3.2671e-01,\n",
       "                       -8.1679e-01, -4.5617e+00, -2.4655e+00, -1.3234e+00, -5.2131e+00,\n",
       "                       -5.9463e+00, -2.3325e+00, -1.8149e+00, -2.4753e+00, -3.4544e+00,\n",
       "                       -5.6820e+00, -4.8025e+00, -5.2141e-01, -4.8561e+00, -4.1490e+00,\n",
       "                       -4.8545e+00, -4.5329e+00, -2.7851e+00, -1.5148e+00, -4.3165e+00,\n",
       "                       -1.7785e+00, -3.2373e+00, -3.2857e+00, -2.3175e+00, -2.2833e+00,\n",
       "                       -1.0586e+00, -1.5082e+00, -5.0935e+00, -1.6113e+00, -3.4852e+00,\n",
       "                       -6.7751e+00, -2.8004e+00, -6.5013e-01, -6.0590e+00, -6.5131e+00,\n",
       "                       -1.4172e+00, -4.7258e+00, -4.5982e-01, -5.9248e+00, -5.0737e+00,\n",
       "                       -4.4513e+00, -3.7426e+00, -5.4794e+00, -1.8153e+00, -4.8805e+00,\n",
       "                       -6.4029e+00,  4.8426e-02, -4.7175e+00, -3.9106e+00, -3.5778e+00,\n",
       "                       -3.3981e+00, -3.0456e+00,  1.8027e+00, -2.2424e+00, -2.9638e+00,\n",
       "                       -6.1016e+00, -6.6257e+00, -2.1282e+00, -4.1428e+00, -2.2306e+00,\n",
       "                       -2.6915e+00, -3.0215e+00, -1.0194e+00, -6.7495e+00, -2.1065e+00,\n",
       "                       -2.3759e+00, -6.9979e+00, -7.0364e+00, -3.7866e+00, -5.7792e+00,\n",
       "                       -2.8825e+00, -7.3869e+00, -7.1711e+00, -5.2317e+00, -7.6586e+00,\n",
       "                       -1.7571e+00, -7.6497e+00, -3.5380e+00, -6.3390e+00,  1.8422e-01,\n",
       "                       -1.3735e+00, -3.0111e+00, -2.9353e+00, -5.3768e+00, -2.8531e+00,\n",
       "                       -4.4987e+00, -6.1691e+00, -5.0320e+00, -2.0414e+00,  4.1987e+00,\n",
       "                       -4.3485e+00, -3.0041e+00, -3.1862e+00, -2.4991e+00, -2.1508e+00,\n",
       "                       -2.1051e+00, -4.7996e+00, -2.2472e+00, -2.8222e+00,  9.2203e-01,\n",
       "                       -5.9343e-01, -2.8558e+00,  3.2222e-01, -3.0476e+00, -3.0600e+00,\n",
       "                       -3.1292e+00, -4.6524e+00, -2.7228e+00, -3.1568e+00, -6.3685e-01,\n",
       "                       -7.7999e-01, -5.0095e-01, -3.7823e+00, -3.9875e+00, -1.9054e+00,\n",
       "                       -3.9328e+00, -2.8082e+00, -4.2932e+00, -1.8392e+00, -8.1447e+00,\n",
       "                       -4.0581e+00, -8.1852e-01, -1.0484e+00, -2.2064e+00, -5.3037e+00,\n",
       "                       -6.1181e+00, -2.9224e+00, -2.6833e+00, -2.2864e+00, -6.7781e+00,\n",
       "                       -3.5556e+00, -1.6910e+00, -3.2869e+00, -1.5842e+00, -3.1140e-01,\n",
       "                       -1.6137e+00,  1.1005e+00, -3.5441e+00, -5.2245e+00, -7.4734e+00,\n",
       "                       -2.0071e-01, -5.0081e+00, -6.2457e+00, -6.1483e+00,  5.4679e-01,\n",
       "                       -7.6490e-02, -6.5202e+00, -4.3091e+00, -7.5703e+00, -4.9300e+00,\n",
       "                       -4.0763e+00, -2.4430e+00, -9.9187e+00, -7.2522e+00, -5.7593e+00,\n",
       "                       -4.0905e+00, -3.7696e+00,  2.4143e+00, -1.0614e+00, -4.3077e+00,\n",
       "                        1.6449e-01, -4.2404e+00, -5.6533e-01, -5.1388e+00, -1.1602e+00,\n",
       "                       -4.0711e+00, -8.1669e+00, -7.9224e-01, -3.6106e+00, -2.8863e+00,\n",
       "                       -4.0039e+00, -5.9323e+00, -4.2021e+00, -6.1053e+00, -1.2576e+00,\n",
       "                       -5.8127e+00, -8.7419e-03, -4.3169e+00, -6.8846e+00, -3.1404e+00,\n",
       "                       -5.6954e+00,  5.5798e-01, -4.7442e+00, -2.6804e+00, -2.7316e+00,\n",
       "                       -3.6489e+00, -4.6171e+00, -2.5302e+00, -7.9222e-01, -1.4191e+00,\n",
       "                       -2.6891e+00, -1.6369e+00, -2.4383e+00, -1.2746e+00, -2.3070e+00,\n",
       "                       -3.5055e+00,  2.5269e+00, -6.7937e+00, -2.8812e+00, -2.6479e+00,\n",
       "                       -3.0300e+00, -1.2753e+00, -2.1728e+00, -5.5616e+00, -4.7007e+00,\n",
       "                       -3.1983e+00, -3.5810e+00, -4.2300e+00,  3.2349e+00, -3.1476e+00,\n",
       "                        1.6562e+00, -2.1902e+00, -3.0210e+00, -1.9096e+00, -3.0159e-02,\n",
       "                        4.5489e-01, -7.1606e+00, -8.7382e+00, -6.9241e+00, -7.0205e+00,\n",
       "                       -4.1419e+00, -4.8182e+00, -3.5031e+00, -2.4199e+00, -6.9245e+00,\n",
       "                       -3.3435e+00, -4.1215e+00, -3.5744e+00, -1.9011e+00, -6.8122e-01,\n",
       "                       -5.8140e+00, -2.3194e+00, -7.2015e-01, -7.5381e+00, -3.5200e+00,\n",
       "                       -2.8006e+00,  2.1261e+00,  2.3816e+00, -3.4576e+00, -4.2519e+00,\n",
       "                       -3.4234e+00, -1.2112e+00, -2.2343e+00, -1.7823e+00, -4.2101e+00,\n",
       "                       -4.7792e+00, -3.2202e+00, -5.3318e+00, -4.8591e+00, -5.9518e+00,\n",
       "                       -4.6476e+00, -3.1120e+00, -1.9557e+00, -3.2095e+00, -7.8318e-01,\n",
       "                       -2.5993e+00, -2.9961e+00, -7.5285e+00, -2.9590e-01, -5.3271e+00,\n",
       "                       -1.0620e+00,  1.5973e+00, -1.5590e+00, -3.6269e+00, -2.9976e-01,\n",
       "                       -8.8450e+00, -4.4740e+00,  2.5859e+00, -5.8198e+00, -1.3088e-01,\n",
       "                       -1.8628e+00, -1.4640e+00, -5.3563e+00, -3.7222e+00, -9.1534e-01,\n",
       "                       -2.2617e+00, -4.0298e+00, -3.9305e+00, -3.6876e+00, -7.5135e-01,\n",
       "                       -4.5840e+00, -1.6885e+00, -6.6714e+00, -7.8406e+00, -3.8527e+00,\n",
       "                       -6.9874e+00, -2.6632e+00, -3.6727e-01, -4.6213e+00, -5.2430e+00,\n",
       "                       -4.8205e+00, -6.3411e+00, -4.0519e+00,  3.4956e-01, -5.0309e+00,\n",
       "                       -3.9501e-01, -3.8105e+00, -3.4003e+00, -3.3505e+00, -3.6168e+00,\n",
       "                       -3.1822e+00, -5.3891e+00, -3.6820e+00, -5.1442e+00, -3.9628e+00,\n",
       "                       -4.5930e+00, -3.6927e+00, -4.9927e+00, -5.9257e+00, -5.3588e+00,\n",
       "                       -4.5778e+00, -4.1438e+00, -2.6058e+00, -4.0820e+00, -1.5459e+00,\n",
       "                       -3.1340e+00, -6.2930e+00, -6.3204e+00, -2.9120e+00, -5.3945e+00,\n",
       "                       -5.2271e+00,  1.5975e-01, -4.8914e+00,  2.6340e+00, -3.5437e+00,\n",
       "                       -5.5692e+00, -1.2304e+01, -6.8723e+00, -4.7717e+00, -7.6192e-01,\n",
       "                       -3.5461e+00, -4.0783e+00, -4.2519e+00, -2.7205e+00, -3.9565e+00,\n",
       "                       -2.4980e+00, -2.8228e+00, -2.1038e+00, -3.5245e+00, -9.2648e+00,\n",
       "                       -4.5788e+00, -3.9271e+00, -4.8877e+00, -6.5881e+00, -5.6820e+00,\n",
       "                       -4.5163e+00, -6.4405e-01,  1.2771e+00, -5.6429e+00,  1.4197e+00,\n",
       "                        1.8638e+00,  1.7337e+00, -3.4856e+00, -1.7573e-01, -1.5830e+00,\n",
       "                       -4.4278e+00, -1.2222e+00, -2.2990e+00, -6.6352e-01, -3.2503e+00,\n",
       "                       -5.4191e+00, -7.4250e+00, -2.2212e+00, -5.5770e+00, -9.5765e-01,\n",
       "                       -4.0389e+00, -3.7462e+00, -1.0532e+00, -4.9198e+00, -5.7410e+00,\n",
       "                       -8.8044e+00, -3.4169e+00, -2.0092e+00,  5.8694e-01,  3.2581e-01,\n",
       "                       -4.9128e+00, -3.7271e+00, -3.8923e+00, -1.0164e+00,  3.1455e-01,\n",
       "                       -7.2309e+00, -7.1714e+00, -6.2041e+00, -4.4813e+00, -2.1777e+00,\n",
       "                       -4.0415e+00, -3.0545e-01, -5.3522e+00, -4.1150e+00, -5.3354e+00,\n",
       "                       -5.9531e+00, -4.1337e+00, -3.4273e+00, -5.0044e+00, -3.4041e+00,\n",
       "                       -4.0171e+00, -4.6239e+00, -4.7713e+00, -4.8237e+00, -6.9651e+00,\n",
       "                       -3.6134e+00, -3.7799e+00,  5.9047e-01, -5.7405e+00, -2.1190e+00,\n",
       "                       -5.8786e-02, -4.8984e+00, -5.2115e+00, -4.0545e+00, -1.2510e+00,\n",
       "                       -1.9442e+00, -5.7048e+00], device='cuda:0')),\n",
       "              ('conv_block4.bn1.running_var',\n",
       "               tensor([16.2490,  7.2846,  9.5777, 11.3631,  9.1639, 14.3346, 16.6534, 32.9906,\n",
       "                        5.4652, 14.9390, 30.3631,  7.6495,  4.5403,  6.6563, 27.1401, 50.6826,\n",
       "                        8.4583,  4.4831,  9.0100, 16.6108, 11.2772, 10.3045, 11.9732,  6.1897,\n",
       "                       10.8725,  9.0628,  8.7775, 18.4304,  4.5135, 23.3932, 14.6473,  3.9167,\n",
       "                       15.4499,  7.3724, 14.1716,  7.7923, 10.7528, 14.2682,  4.3208, 10.8910,\n",
       "                       18.5312,  6.3160, 15.0892, 29.7694, 13.5446,  7.7142,  6.0020, 20.9761,\n",
       "                       12.9938, 36.9302, 17.7244,  8.8077,  4.6043,  4.2024,  6.2257,  7.5328,\n",
       "                        8.9920, 17.9596, 12.7944, 11.2199,  9.8698, 27.5909, 17.1619,  7.5465,\n",
       "                       19.5989, 25.8005,  6.9382, 10.6722, 13.1705, 23.2234, 10.7521, 11.0157,\n",
       "                       18.0483,  7.6381,  9.9533, 21.9131, 12.1995, 16.4658,  4.7297, 13.9231,\n",
       "                        7.0346, 13.7730,  7.2791,  7.3860, 14.9156, 21.7459,  4.5373, 12.6359,\n",
       "                        7.7970, 12.4676, 13.8461, 10.5168, 13.5595, 19.5380, 10.4353, 11.1688,\n",
       "                       20.6607,  6.6041, 14.1823,  2.8367,  9.9970,  8.2428, 19.6683,  8.0787,\n",
       "                       13.5889, 19.8207, 11.6720, 11.1313, 17.6782,  9.7351, 15.6038,  9.6998,\n",
       "                       14.1313, 17.4119, 18.8435, 13.8633,  8.5880, 23.2144,  5.6207, 18.6502,\n",
       "                        8.9340, 12.6050, 16.4383,  6.9416,  9.9014, 13.6501,  9.7032, 34.9042,\n",
       "                        4.5637, 17.6135, 21.2522, 10.2722,  0.9733, 14.9963, 16.5014, 10.8613,\n",
       "                       14.0091,  8.5142, 15.1327, 17.4614, 10.9654, 14.6580, 13.3099, 10.7413,\n",
       "                       11.7826, 15.1395,  8.5705, 12.2246,  4.7738,  7.5489, 13.3421,  6.0535,\n",
       "                        3.8158, 10.7465, 14.2254, 16.1070, 25.0648, 15.1056, 19.8251, 12.2217,\n",
       "                       14.8172,  6.1069,  6.9094, 24.0017, 11.4379, 15.3326, 60.9388, 23.6923,\n",
       "                        8.1709, 23.7517,  9.0436, 17.2145, 15.4438, 18.3960, 19.0767, 15.1297,\n",
       "                       19.4897, 10.1875, 17.2590,  1.8289, 22.0120, 12.1399, 17.1923, 37.5687,\n",
       "                       26.1845,  7.8282, 25.6413, 10.5569,  6.5087,  5.0497,  6.8594,  9.7184,\n",
       "                       20.9492,  5.9238,  8.5648, 14.8345, 13.5780,  8.5314,  9.3884,  5.6852,\n",
       "                        2.2771, 16.0686, 12.7387, 10.2201, 10.1460,  6.4495,  7.0681,  9.8236,\n",
       "                        8.2106,  4.3159,  5.6754,  2.6613,  8.8732,  9.0167,  6.2603,  5.7982,\n",
       "                       10.3354, 21.3947,  8.0171, 17.2598,  7.9643,  5.1989, 18.8477, 16.6038,\n",
       "                       13.9150, 13.4469, 10.8861,  5.9560, 10.1703, 13.6394, 10.9890,  2.4502,\n",
       "                       10.6366, 21.8044,  4.2647,  5.1979, 18.2548, 19.3708, 22.4303, 33.1909,\n",
       "                        9.1366,  8.6216, 24.4579, 11.0494,  3.9864,  8.8312, 16.1064,  9.0300,\n",
       "                       17.9210, 18.8480, 13.0226, 13.7461, 29.3858, 34.5594, 17.3259, 17.3916,\n",
       "                       13.7205,  6.4595,  6.9600, 14.7882,  3.6908, 31.4788,  8.7265, 11.9039,\n",
       "                        8.4390, 30.4676, 22.1118, 17.4579, 22.0499, 17.7585,  8.3363, 35.7791,\n",
       "                       12.0746, 26.6057,  7.0519, 17.3683,  1.3504, 13.0184, 20.6520, 10.8274,\n",
       "                       10.8196,  3.5806, 18.5034,  6.1635,  7.9539, 21.4653, 12.6932, 16.9974,\n",
       "                        4.3525, 11.3380,  6.3260,  5.6914, 13.7803,  7.2292,  4.4633, 21.2414,\n",
       "                        5.5068, 15.1281,  9.5576, 11.0066, 17.5868, 14.8835, 11.6332, 21.0427,\n",
       "                       30.7133, 29.5480, 24.1431, 19.0737,  8.6061, 18.7986, 12.4535, 12.2609,\n",
       "                       12.0985,  8.9649,  6.1844,  3.1300, 30.8220, 27.8430, 11.8715, 15.8952,\n",
       "                       10.4083,  8.4776, 12.0731, 10.3817, 32.5324, 21.3901, 15.7112, 17.3737,\n",
       "                       17.4119,  5.1495, 16.9893, 22.3193,  6.9266, 16.8431, 25.8258,  8.8589,\n",
       "                       14.6623,  5.0208, 26.9627, 11.8390, 16.0125,  5.0638, 10.4135,  4.0168,\n",
       "                        9.6669,  7.8814, 12.7736, 21.2410,  9.8097, 18.0714,  9.7158,  6.7313,\n",
       "                        7.9796,  5.8007, 17.2790,  6.3128, 13.9074, 23.2066, 10.8451, 19.1016,\n",
       "                        7.2473,  7.3669,  7.1156, 15.9592, 10.1277, 37.1465, 20.3397,  4.6011,\n",
       "                       27.1404, 10.8334,  3.7504,  3.5902, 16.9543, 16.3831, 12.6583, 12.5773,\n",
       "                       23.7430, 33.0437, 10.1543,  4.5240, 15.9702,  6.9760, 38.2437, 20.2118,\n",
       "                       12.5715, 15.5966,  5.3739, 12.6981,  7.8980, 16.3014, 16.9397, 17.1382,\n",
       "                       16.4431,  5.0657,  9.4201, 13.4778, 13.8066, 10.2913, 21.5963, 31.3052,\n",
       "                        7.7018, 11.5899, 15.7412, 29.0349, 26.4635,  9.5554, 16.4110, 14.3863,\n",
       "                       30.3980, 11.3376, 18.1557, 15.3885, 12.7744, 13.1301,  8.5754, 40.9582,\n",
       "                       17.1876, 15.5699, 28.5431, 17.5472, 19.4080,  3.2560, 11.1073,  6.8335,\n",
       "                       21.3303, 14.0882, 32.9931, 24.2386, 16.2371,  9.0940, 14.1389, 20.9983,\n",
       "                       22.7007, 19.1199, 28.0911,  9.7277,  4.5722, 11.4747, 12.7151, 28.8827,\n",
       "                       23.4426,  6.0437, 15.1421, 11.2604, 16.5514, 37.0129,  4.5445, 10.3485,\n",
       "                       17.9801, 34.8807,  4.8628,  5.8914,  6.8942,  4.4754,  2.5850, 18.8758,\n",
       "                        2.9671, 15.2788,  2.9628,  9.4442, 10.8733, 37.1223,  8.0591,  9.4730,\n",
       "                        2.4788, 24.9134, 15.2089,  7.7809, 12.0131, 20.6307, 18.2814,  8.8474,\n",
       "                        6.4293,  3.1210,  8.7188,  9.8421, 11.5541, 22.2615,  3.5968,  1.5125,\n",
       "                       15.2731, 46.7073, 15.8160,  6.3322, 13.3529, 19.5034, 11.9422, 10.7190,\n",
       "                       10.9323, 13.1163, 25.1346, 21.1344, 10.5187, 23.2545,  6.5046,  7.7189,\n",
       "                       14.2358, 12.3720,  7.7003, 24.6330, 16.8586, 12.5088,  9.8300, 15.5125,\n",
       "                       16.8697,  4.4964,  6.9812, 21.0509, 23.7045,  7.1495,  8.0065, 13.8471],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('conv_block4.bn2.weight',\n",
       "               tensor([0.7628, 0.7964, 1.1448, 1.1990, 1.1205, 0.7934, 1.0491, 0.9269, 0.7315,\n",
       "                       1.0806, 1.2035, 1.1989, 1.1108, 1.1249, 0.9331, 1.1976, 0.9179, 0.7799,\n",
       "                       0.8850, 1.0031, 1.2293, 0.8399, 1.0119, 0.8418, 0.8997, 1.0287, 1.0382,\n",
       "                       1.0003, 1.3023, 0.9256, 1.3747, 1.4205, 0.9725, 1.0934, 1.3342, 0.8606,\n",
       "                       0.9217, 1.2257, 1.0052, 0.9962, 0.9887, 0.8273, 1.1347, 0.8122, 0.7745,\n",
       "                       0.8183, 1.1497, 0.7152, 1.0367, 1.5995, 0.9195, 1.0779, 1.1960, 1.1532,\n",
       "                       1.0262, 0.9500, 0.8388, 1.1223, 0.8604, 0.6225, 1.1247, 0.7728, 1.0679,\n",
       "                       1.2176, 0.9571, 0.9389, 1.0938, 0.8602, 1.0999, 1.2322, 0.8977, 0.8469,\n",
       "                       0.9471, 0.7858, 0.9947, 1.0217, 1.1389, 0.9646, 0.9973, 1.0087, 0.7371,\n",
       "                       1.0098, 1.2660, 0.9398, 0.9325, 1.0432, 1.2612, 1.0233, 0.7644, 1.0441,\n",
       "                       1.1643, 0.8228, 0.7236, 1.1910, 0.8149, 1.1215, 1.0049, 1.0424, 1.1968,\n",
       "                       1.2296, 0.8888, 1.1702, 0.6953, 1.0204, 1.1609, 1.0303, 0.8376, 1.1036,\n",
       "                       1.0290, 0.7988, 1.0603, 1.1372, 0.6595, 0.9573, 1.2293, 0.9766, 1.2445,\n",
       "                       1.0179, 1.0125, 0.8509, 0.6154, 0.8763, 1.0979, 1.2599, 0.8349, 0.9958,\n",
       "                       0.8787, 0.8455, 0.9767, 0.9973, 0.9759, 1.4886, 0.8487, 1.0250, 1.0401,\n",
       "                       1.1446, 1.0743, 1.1808, 0.9744, 0.9943, 0.4529, 0.8442, 0.9949, 1.1210,\n",
       "                       1.0199, 0.8653, 0.9385, 1.1623, 0.9926, 1.0954, 0.9626, 1.0546, 0.8737,\n",
       "                       1.0312, 0.8552, 0.8751, 1.0869, 1.1055, 0.8115, 0.9785, 0.7497, 0.9191,\n",
       "                       1.2296, 1.1976, 1.0226, 1.0491, 0.9863, 0.9350, 1.0790, 0.4981, 0.4181,\n",
       "                       0.8896, 0.9664, 0.9657, 1.1124, 0.8759, 0.9258, 1.1530, 1.2547, 0.9564,\n",
       "                       1.0362, 0.8034, 1.2625, 1.0664, 0.8533, 0.8095, 1.3456, 0.9378, 0.9237,\n",
       "                       0.8478, 0.8442, 0.9750, 1.0034, 1.0464, 1.0525, 0.9846, 0.9442, 0.9358,\n",
       "                       0.9192, 1.0925, 1.0959, 1.0112, 0.9919, 0.6995, 0.9361, 1.1604, 1.0582,\n",
       "                       1.0108, 0.8404, 1.2212, 1.1735, 1.0863, 1.0519, 0.8616, 1.2708, 1.0385,\n",
       "                       1.2399, 0.8502, 1.1036, 1.0802, 0.9371, 0.8500, 1.0245, 0.9436, 0.9419,\n",
       "                       1.0661, 0.9565, 1.0592, 1.2874, 0.9363, 1.1823, 0.9337, 0.9021, 1.1561,\n",
       "                       0.6610, 1.2206, 0.9787, 1.0090, 0.8622, 1.1404, 1.1617, 0.9825, 0.6908,\n",
       "                       1.0188, 0.9450, 1.0644, 0.8321, 1.1929, 0.9382, 0.8468, 0.9354, 1.0031,\n",
       "                       1.1529, 1.0314, 0.9962, 1.2703, 0.9004, 0.9222, 1.0129, 1.3790, 0.9211,\n",
       "                       1.0628, 1.0196, 0.8779, 1.1098, 0.9996, 1.2415, 1.0753, 1.2124, 0.8296,\n",
       "                       1.3477, 1.0791, 1.0084, 0.8764, 0.9149, 1.0014, 1.0672, 0.9700, 0.9505,\n",
       "                       0.8861, 0.1713, 0.7596, 0.9551, 0.9216, 0.6963, 0.9293, 1.0741, 0.8471,\n",
       "                       0.9329, 1.0124, 1.2375, 0.9070, 0.9062, 1.1705, 0.8045, 0.7281, 1.2426,\n",
       "                       0.9078, 0.9309, 1.0479, 0.9355, 1.0879, 0.5853, 0.7657, 1.5225, 0.8603,\n",
       "                       0.9878, 0.9513, 1.0558, 0.6829, 1.0770, 1.3757, 0.9665, 1.0041, 0.3218,\n",
       "                       0.9511, 0.9146, 1.1523, 1.2250, 0.8231, 1.3244, 0.9777, 0.7023, 1.1754,\n",
       "                       0.7425, 0.9122, 1.2293, 1.2411, 1.0561, 0.9331, 1.1389, 0.8758, 1.1247,\n",
       "                       1.0636, 1.4558, 1.0144, 1.0434, 1.0811, 0.9154, 1.1014, 0.6937, 0.9203,\n",
       "                       1.1773, 1.0146, 0.7751, 0.9256, 1.0788, 1.2199, 0.7843, 1.0410, 1.0692,\n",
       "                       0.9094, 0.8513, 1.0900, 1.0638, 0.9060, 1.1837, 0.9329, 1.0620, 0.7269,\n",
       "                       1.1451, 0.9884, 1.0529, 1.1956, 0.8431, 1.0130, 0.9111, 1.1135, 1.2920,\n",
       "                       0.7534, 1.0044, 0.8759, 0.8682, 0.9767, 0.8859, 0.8209, 0.9706, 0.8667,\n",
       "                       1.0433, 0.9392, 0.7635, 0.9715, 0.9853, 1.3195, 1.2488, 0.9767, 0.9744,\n",
       "                       0.9803, 0.8013, 0.7558, 1.2689, 1.2959, 1.3950, 1.1928, 0.8418, 0.9721,\n",
       "                       0.9382, 0.8003, 0.9639, 0.9485, 1.1351, 0.8503, 1.1171, 0.8815, 1.2645,\n",
       "                       0.9131, 0.8256, 0.9361, 0.9361, 0.9321, 1.3269, 0.8988, 0.8768, 0.9939,\n",
       "                       0.6636, 0.7570, 1.0451, 0.9260, 1.0886, 1.0050, 0.8244, 1.2025, 0.8961,\n",
       "                       0.3905, 1.1722, 0.9274, 1.1397, 0.9808, 0.9915, 0.8902, 0.8849, 1.2590,\n",
       "                       0.9127, 1.0160, 1.0433, 0.9369, 0.8895, 0.8883, 0.7890, 1.1519, 1.2036,\n",
       "                       0.9833, 0.9871, 0.8409, 0.8872, 0.7682, 0.9733, 0.8100, 0.9846, 1.1250,\n",
       "                       1.0726, 1.0917, 1.2260, 1.1943, 1.1928, 1.3066, 1.2678, 0.9270, 1.0489,\n",
       "                       0.9766, 1.0801, 1.0028, 1.1354, 0.9804, 1.1060, 0.5414, 0.9859, 0.7354,\n",
       "                       1.0640, 0.7596, 0.9490, 1.1334, 0.9953, 0.9665, 0.9889, 1.1856, 0.8342,\n",
       "                       1.4062, 1.1407, 0.9226, 0.8933, 1.0876, 1.1772, 0.8174, 0.9685, 1.2333,\n",
       "                       1.1341, 0.8424, 0.8983, 0.9510, 1.0566, 0.9647, 1.1096, 1.0425, 0.9706,\n",
       "                       0.7099, 0.9029, 0.8105, 1.1832, 0.9438, 0.7627, 1.0310, 0.7751, 0.8782,\n",
       "                       0.9947, 0.9968, 0.8975, 1.1936, 0.6997, 0.6514, 0.8361, 1.1714],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn2.bias',\n",
       "               tensor([-0.8967, -0.7132, -1.0438, -1.3076, -1.3841, -0.5336, -0.7505, -0.8064,\n",
       "                       -0.7240, -0.8607, -1.4095, -1.3212, -1.0149, -1.0444, -0.6427, -1.1504,\n",
       "                       -0.8853, -0.7413, -0.8032, -0.9176, -1.4060, -0.7406, -0.8496, -0.6140,\n",
       "                       -0.6183, -0.9297, -0.9737, -0.7508, -1.1412, -0.9713, -1.5636, -1.7092,\n",
       "                       -0.8299, -0.9835, -1.5174, -0.8241, -0.8371, -1.3774, -0.7195, -0.7833,\n",
       "                       -0.8533, -0.4965, -1.2025, -0.6990, -0.5405, -0.6715, -1.1576, -0.5190,\n",
       "                       -0.8390, -1.7736, -0.5242, -0.8674, -1.1427, -0.9812, -0.8095, -0.5508,\n",
       "                       -0.6364, -1.2831, -0.6552, -0.3456, -1.0607, -0.6252, -0.8830, -1.1101,\n",
       "                       -0.5548, -0.7719, -0.9709, -0.6936, -0.7660, -1.0268, -0.6983, -0.6900,\n",
       "                       -0.9306, -0.5891, -0.7923, -0.8934, -1.0674, -0.8052, -0.8689, -1.0160,\n",
       "                       -0.4236, -0.5480, -1.5339, -0.8057, -0.8251, -0.9015, -1.1331, -0.9615,\n",
       "                       -0.5716, -0.9931, -1.1187, -0.7910, -0.5723, -0.9711, -0.4790, -1.0568,\n",
       "                       -0.8832, -1.1967, -1.6032, -1.2779, -0.8876, -1.2233, -0.5154, -1.0236,\n",
       "                       -1.3123, -0.9796, -0.6711, -1.0396, -1.0995, -0.8289, -0.6717, -0.9585,\n",
       "                       -0.2715, -0.8792, -1.2994, -0.6528, -1.4047, -1.2309, -0.9226, -0.7575,\n",
       "                       -0.2712, -0.8494, -0.8645, -1.1767, -0.6386, -0.9567, -0.8636, -0.7796,\n",
       "                       -0.8463, -0.8185, -0.8790, -1.7744, -0.8146, -0.7478, -1.0059, -1.2132,\n",
       "                       -1.2541, -1.2049, -0.9702, -1.0579, -1.5478, -0.5301, -1.0617, -0.8739,\n",
       "                       -1.0031, -0.8901, -0.8659, -1.0109, -0.9247, -0.8843, -1.0365, -1.0612,\n",
       "                       -0.5960, -0.7431, -0.6983, -0.7672, -1.0511, -1.0632, -0.5391, -0.8554,\n",
       "                       -0.6285, -0.7847, -1.3751, -1.2373, -0.5771, -1.0745, -1.0861, -0.7953,\n",
       "                       -0.8220, -1.4060, -1.4677, -0.9265, -1.0684, -1.0352, -1.1075, -0.7351,\n",
       "                       -0.6174, -1.1331, -1.4337, -0.6692, -0.8031, -0.5891, -1.2622, -1.1196,\n",
       "                       -0.8850, -0.7523, -1.0917, -0.8270, -0.9050, -0.6799, -0.7055, -1.0011,\n",
       "                       -0.9760, -1.0157, -0.8039, -0.7423, -0.7361, -1.0374, -0.9168, -1.1139,\n",
       "                       -1.3269, -0.8784, -1.0165, -0.4220, -0.7486, -1.1407, -1.0877, -0.8782,\n",
       "                       -0.6013, -0.9792, -1.1165, -1.2561, -0.9998, -0.8214, -0.9640, -0.8608,\n",
       "                       -1.4834, -0.6340, -1.4418, -1.1550, -0.7232, -0.5676, -1.2207, -0.6788,\n",
       "                       -0.8410, -0.9472, -0.7880, -0.6994, -1.1619, -0.9436, -1.0962, -0.7970,\n",
       "                       -0.8184, -1.1767, -0.4487, -1.2756, -0.8451, -1.0390, -0.5790, -1.1340,\n",
       "                       -1.1479, -0.8791, -0.4277, -0.9437, -1.0207, -0.9291, -0.5797, -0.7572,\n",
       "                       -0.8031, -0.9464, -0.8372, -0.8856, -1.2096, -1.0580, -0.7046, -1.4392,\n",
       "                       -0.8366, -0.9302, -0.8542, -1.2945, -0.8075, -0.9730, -0.8899, -0.8764,\n",
       "                       -1.1212, -1.0163, -1.2747, -0.7749, -1.1612, -0.4589, -1.2108, -0.8754,\n",
       "                       -0.8757, -0.6177, -0.5914, -0.9605, -1.0459, -0.8200, -0.8624, -0.7919,\n",
       "                       -0.3609, -0.8051, -0.8665, -0.8028, -0.5079, -0.8536, -0.9503, -0.6198,\n",
       "                       -0.8773, -0.8238, -1.4404, -0.8329, -0.8257, -1.1025, -0.5530, -0.6476,\n",
       "                       -1.3420, -0.6459, -0.6425, -1.0068, -0.8465, -1.1378, -1.5305, -0.3895,\n",
       "                       -1.6372, -0.7022, -1.0553, -0.7327, -0.9565, -0.4087, -0.7937, -1.5977,\n",
       "                       -0.7658, -1.0484, -1.1793, -0.8508, -0.9172, -1.3296, -1.0790, -0.8253,\n",
       "                       -1.1821, -0.7363, -0.4067, -1.1204, -0.5023, -0.5538, -1.0139, -1.3885,\n",
       "                       -0.9132, -0.7740, -0.9402, -0.8589, -1.2238, -1.0330, -1.4032, -0.9567,\n",
       "                       -0.9126, -0.8037, -1.1163, -1.0873, -0.6608, -0.8338, -1.1618, -0.7586,\n",
       "                       -0.5684, -0.7037, -0.9467, -1.4875, -0.6695, -1.1015, -0.8697, -0.9140,\n",
       "                       -0.7312, -1.0970, -0.9846, -0.7731, -0.9866, -1.0221, -0.9487, -0.6246,\n",
       "                       -0.8423, -0.9155, -1.1254, -1.0641, -0.7310, -0.8185, -0.5721, -1.1623,\n",
       "                       -1.3122, -0.4620, -0.6123, -0.6233, -0.9284, -0.7804, -0.6805, -0.5047,\n",
       "                       -0.8190, -0.6452, -1.0151, -0.7084, -0.4334, -0.8351, -0.9213, -1.4277,\n",
       "                       -1.2516, -0.9710, -0.7829, -0.7869, -0.7233, -0.4981, -1.2283, -1.6007,\n",
       "                       -1.3695, -1.0348, -0.6181, -1.0865, -0.8831, -0.4953, -0.9265, -0.7055,\n",
       "                       -1.1031, -0.8485, -1.2847, -0.6733, -1.3500, -0.6975, -0.8620, -0.7659,\n",
       "                       -0.9488, -0.9458, -1.4173, -0.6657, -0.5181, -0.8812, -0.5532, -0.7696,\n",
       "                       -0.8141, -0.6723, -1.0297, -0.9992, -0.6258, -1.2755, -0.6624, -1.2232,\n",
       "                       -1.0282, -1.0578, -1.1208, -0.7870, -0.7818, -0.6329, -0.5819, -1.2876,\n",
       "                       -0.8085, -1.1006, -0.9252, -0.8744, -0.7274, -0.5352, -0.7014, -0.9643,\n",
       "                       -1.2763, -0.7554, -0.9888, -0.5047, -0.7841, -0.5041, -1.0044, -0.4670,\n",
       "                       -0.9397, -1.3048, -0.8465, -0.8810, -1.1993, -1.0926, -1.1339, -1.1145,\n",
       "                       -1.2288, -0.6534, -0.9580, -0.9594, -0.8297, -1.0731, -1.1626, -1.1722,\n",
       "                       -0.9922, -1.4071, -0.8630, -0.4133, -1.0201, -0.6992, -1.0339, -1.0417,\n",
       "                       -0.7777, -1.0088, -0.8676, -0.9439, -0.4020, -1.3447, -1.1631, -0.7467,\n",
       "                       -0.8923, -0.9767, -1.3966, -0.5381, -1.1595, -1.1124, -1.0051, -0.7058,\n",
       "                       -0.6062, -0.7215, -0.9889, -0.7058, -0.9132, -0.9059, -0.7860, -0.4504,\n",
       "                       -0.8446, -0.4706, -0.9488, -0.7387, -0.4935, -0.9523, -0.5573, -0.8712,\n",
       "                       -0.8235, -0.9476, -0.7569, -1.0712, -0.3494, -0.5463, -0.6395, -1.2501],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn2.running_mean',\n",
       "               tensor([ 3.0198e+00, -2.9434e+00, -8.9154e+00, -1.3225e+01, -1.9969e+01,\n",
       "                       -9.1160e+00, -7.4190e+00, -1.1327e+00, -1.2266e+01, -1.0153e+01,\n",
       "                       -8.4130e+00, -1.0754e+01, -3.6736e+00, -1.6887e+01,  6.6044e-01,\n",
       "                       -5.1028e+00, -1.1249e+01, -3.5525e+00, -1.5268e+01, -8.4734e+00,\n",
       "                       -3.8948e+00, -1.0024e+01, -7.6112e+00,  2.3856e+00, -6.7577e+00,\n",
       "                       -4.1050e+00, -7.3580e+00, -4.5883e+00, -1.3479e+00, -1.1502e+01,\n",
       "                       -1.8113e+01, -1.0892e+01, -1.5077e+01, -9.2835e+00, -1.4230e+01,\n",
       "                       -8.1133e+00, -5.6260e+00, -1.1434e+01, -1.3009e+01, -7.2768e+00,\n",
       "                       -9.8380e+00, -1.1942e+01, -1.3902e+01, -1.6080e+01, -9.0728e+00,\n",
       "                       -1.6532e+01, -1.4431e+01, -6.1568e+00, -1.8173e+01, -1.3573e+01,\n",
       "                       -1.4023e+01, -6.4460e+00, -7.9375e+00, -3.5361e+00, -1.4617e+01,\n",
       "                       -1.0838e+01, -8.4012e+00, -9.9714e+00, -5.2957e+00, -5.5077e+00,\n",
       "                       -9.3606e+00, -1.0648e+01, -6.7646e+00, -7.9533e+00, -9.7598e+00,\n",
       "                       -2.0110e+00,  1.8674e+00, -5.3228e-01, -6.3036e+00, -3.4793e+00,\n",
       "                       -7.2772e+00, -9.6813e+00,  1.4320e+00, -4.6422e+00, -9.6044e+00,\n",
       "                       -1.2473e+01, -6.2010e+00, -8.7325e+00, -1.0760e+01, -1.2709e+01,\n",
       "                       -4.8521e+00, -5.3224e+00, -4.1643e+00, -1.9513e+00, -1.1639e+01,\n",
       "                       -7.7602e+00, -9.1146e+00, -2.6265e+00, -6.3721e+00, -9.7278e+00,\n",
       "                       -1.1883e+01, -6.9984e+00, -9.2847e+00, -6.6031e+00, -1.0593e+01,\n",
       "                       -9.3006e+00, -1.4130e+01, -1.2825e+01, -8.3481e+00, -1.4573e+01,\n",
       "                       -5.0110e+00, -8.3452e+00, -5.9359e+00, -6.3904e+00, -1.2352e+01,\n",
       "                       -4.0070e+00, -7.6584e+00, -4.0841e+00, -3.6692e+00, -6.9539e+00,\n",
       "                       -6.7608e+00, -9.7790e+00, -3.3525e+00, -6.1640e+00, -1.2694e+01,\n",
       "                       -4.1944e+00, -1.2121e+01, -1.9240e+01, -7.4283e+00, -1.1925e+01,\n",
       "                       -4.9067e+00, -1.3514e+01, -2.3182e+00, -1.0754e+01, -1.3620e+01,\n",
       "                       -8.8357e+00, -1.0973e+01, -8.3085e+00, -1.5023e+01, -7.7972e+00,\n",
       "                       -7.9833e+00, -1.5078e+01, -4.8600e+00, -8.3985e-01, -8.1643e+00,\n",
       "                       -1.0476e+01,  3.5872e-01, -1.5033e+01, -1.0980e+01,  4.9595e+00,\n",
       "                       -6.9281e+00, -4.3709e+00, -1.0908e+01, -1.3521e+01, -7.6675e+00,\n",
       "                       -1.1720e+01, -1.9920e+00, -1.1322e+01, -6.8223e+00, -5.5942e+00,\n",
       "                       -1.5433e+01, -1.0473e+01, -9.4782e+00, -4.9079e+00, -6.2245e+00,\n",
       "                       -9.8793e+00, -1.0046e+01, -9.8009e+00, -8.7472e+00, -1.4203e+01,\n",
       "                       -6.5156e+00, -5.2704e+00, -5.9504e+00, -8.1275e+00, -9.0053e+00,\n",
       "                       -1.1434e+01, -1.4944e+01, -1.5856e+01, -7.0030e+00,  1.0651e+00,\n",
       "                       -2.8848e+00, -8.1953e+00, -1.1327e+01, -1.6660e+01, -1.3412e+01,\n",
       "                       -9.5791e+00, -1.0744e+01, -5.8383e+00, -1.5593e+01, -1.4767e+01,\n",
       "                       -3.1605e+00, -7.2868e+00, -1.1331e+01, -4.1374e+00, -5.0394e-03,\n",
       "                       -7.0179e+00, -1.6355e+00, -7.8425e+00, -2.5138e+00, -8.3200e+00,\n",
       "                       -9.4470e+00, -1.3087e+01, -1.4921e+01, -1.0667e+01, -1.0198e+01,\n",
       "                       -9.8084e+00, -5.9923e+00, -5.0873e+00, -1.2160e+00, -6.2995e+00,\n",
       "                       -1.3518e+01, -4.5075e+00,  3.7272e+00, -7.2208e+00, -3.7430e+00,\n",
       "                       -1.2006e+01, -5.7810e+00, -1.1241e+01, -4.3220e+00, -5.4142e+00,\n",
       "                       -6.9934e+00, -1.1073e+01, -9.0275e+00, -8.3512e+00, -2.1367e+00,\n",
       "                       -4.9117e+00, -1.4172e+01, -7.8584e+00,  1.8613e+00, -1.3893e+01,\n",
       "                       -3.3329e+00,  2.0532e+00, -9.0830e+00, -5.6085e+00, -2.6306e-01,\n",
       "                       -1.2483e+01, -1.0784e+01, -1.0235e+01, -6.2347e+00, -1.0313e+01,\n",
       "                       -1.9862e+00, -1.2232e+01, -2.9492e+00, -1.6303e+01, -2.2138e+00,\n",
       "                       -1.0947e+01, -1.3365e+01, -1.3233e+01, -1.3995e+01, -1.1138e+01,\n",
       "                       -1.0021e+01, -6.3252e+00, -4.6964e+00, -6.9031e+00, -4.6921e+00,\n",
       "                       -3.4764e+00, -1.3305e+01, -1.0203e+01, -1.6124e+01,  1.2952e+00,\n",
       "                       -6.2305e+00, -1.4217e+01, -2.1623e+01, -1.1931e+01, -3.3700e+00,\n",
       "                       -1.3990e+01, -1.7940e+00, -8.6340e+00, -2.7225e+00, -8.5026e+00,\n",
       "                       -1.1304e+01, -1.2822e+01, -1.2791e+00, -1.3894e+01, -1.3086e+01,\n",
       "                       -1.2608e+01, -1.7726e+01, -8.9358e+00, -1.1119e+01,  1.2272e+00,\n",
       "                       -1.1311e+01, -8.5219e+00, -6.1549e+00, -6.8071e+00, -1.8260e+00,\n",
       "                       -1.3464e+00, -1.6063e+01, -9.4353e+00, -1.0187e+01, -5.6166e+00,\n",
       "                       -2.9755e-01,  5.1642e+00, -9.0873e+00, -4.9262e+00, -5.2774e+00,\n",
       "                       -7.0622e+00, -1.5649e+01, -1.0053e+01, -1.5161e+01, -5.3013e+00,\n",
       "                       -1.5302e+01, -1.0959e+01, -4.9322e+00, -6.9606e+00, -9.5967e+00,\n",
       "                       -9.3940e+00, -1.2799e+01, -9.2781e+00, -1.0970e+01, -1.2063e+01,\n",
       "                       -7.5280e+00, -1.5595e+01, -6.4524e+00, -5.8597e+00, -8.3269e+00,\n",
       "                       -1.2734e+01, -1.0998e+01, -3.8231e-01, -1.3135e+01, -1.2414e+01,\n",
       "                       -8.0329e+00, -7.9012e+00, -1.2060e+01, -1.0666e+01, -1.7246e+00,\n",
       "                       -4.8282e+00, -1.5515e+01, -2.0334e+01, -8.0053e+00, -6.1453e+00,\n",
       "                       -5.8340e+00, -1.2121e+01, -1.6798e+01,  2.5277e+00, -6.7520e+00,\n",
       "                       -9.2796e+00, -6.7304e+00, -1.3012e+01, -3.1986e+00, -7.4028e+00,\n",
       "                       -2.3210e+00, -7.8045e+00, -1.1888e+01, -2.5731e+00, -1.0805e+01,\n",
       "                       -1.0150e+00, -2.1886e+00, -1.0538e+01,  6.3253e+00, -1.2095e+01,\n",
       "                       -2.2786e+00, -1.0243e+01, -1.3903e+01, -4.3010e+00, -9.8760e+00,\n",
       "                       -1.2492e+01, -7.6364e+00, -1.3535e+01, -7.4682e+00, -1.0651e+01,\n",
       "                       -1.0600e+00, -6.8408e+00, -1.5365e+01, -1.1049e+01, -1.2120e+01,\n",
       "                       -1.0755e+01, -6.1311e+00, -1.1968e+01, -8.4022e+00, -7.4325e+00,\n",
       "                       -1.0239e+01, -1.2581e+01, -1.0442e+01, -1.1154e+01, -1.0132e+01,\n",
       "                       -1.1107e+01, -9.6741e+00, -1.8765e+01, -1.6064e+01, -8.5946e+00,\n",
       "                       -2.9244e+00, -3.3842e+00,  2.2662e+00, -1.1041e+01, -9.4812e+00,\n",
       "                        2.7519e+00, -7.3599e+00, -6.1677e+00,  2.7163e+00, -1.2124e+00,\n",
       "                       -1.6143e+01, -1.3539e+01, -8.8163e+00, -1.5015e+01, -6.0285e+00,\n",
       "                       -1.0576e+01, -9.9628e+00, -6.6206e+00, -8.9800e+00, -9.2174e+00,\n",
       "                       -1.2206e+01, -5.3181e+00, -9.5347e+00, -4.9996e+00, -1.3986e+01,\n",
       "                       -1.3972e+01, -4.5926e+00, -6.0979e+00, -6.5337e+00, -6.0051e+00,\n",
       "                       -9.8214e+00, -1.0363e+01, -9.2892e+00, -6.5592e+00, -1.1144e+01,\n",
       "                       -2.5159e+00, -1.2639e+01, -6.9263e+00, -8.6278e+00, -1.4425e+01,\n",
       "                       -1.1738e+01, -2.9951e+00, -1.5621e+01, -7.0573e+00, -7.2652e+00,\n",
       "                       -5.7854e+00, -7.5556e+00, -9.4701e-01, -1.0454e+01, -1.2186e+01,\n",
       "                       -6.4071e+00, -9.0318e+00, -5.0145e+00,  7.5070e-01, -1.4077e+01,\n",
       "                       -2.5451e+00, -1.0389e+01, -3.2572e+00, -1.4454e+01, -9.1840e+00,\n",
       "                       -7.0117e+00, -1.4814e+01, -1.3200e+01, -6.8197e+00, -1.0143e+01,\n",
       "                       -1.1238e+01, -6.5500e+00, -9.0151e+00,  9.1656e-01, -7.5804e+00,\n",
       "                       -1.0427e+01, -8.8539e+00, -1.0393e+01, -6.3214e+00, -1.5101e+01,\n",
       "                       -2.6706e+00, -7.0551e+00, -5.5684e+00, -1.0397e+01, -1.2028e+01,\n",
       "                       -1.2121e+01, -4.0085e+00, -1.5004e+01, -1.5110e+01, -6.5115e+00,\n",
       "                       -1.0600e+01, -6.5164e+00, -7.9241e+00, -9.3802e+00, -1.3501e+01,\n",
       "                       -7.4531e+00, -6.2422e+00, -8.7672e+00, -1.1636e+01, -9.9595e+00,\n",
       "                        3.2459e-01, -1.4050e+01, -1.6173e+01, -1.5430e+01, -1.1072e+00,\n",
       "                       -1.1640e+01, -1.2326e+01, -8.9185e+00, -6.6961e+00, -1.0618e+01,\n",
       "                       -5.2592e+00, -7.9924e+00, -9.4805e+00, -1.7360e+01, -1.5071e+01,\n",
       "                       -6.4959e+00, -1.3956e+01, -1.1500e+01, -5.6394e-01, -1.2645e+01,\n",
       "                       -1.2334e+01, -1.7402e+01, -1.2918e+01, -5.8564e+00, -1.7648e+01,\n",
       "                       -7.5547e+00,  9.7566e-01, -8.1419e+00, -2.9840e+00, -1.1524e+01,\n",
       "                       -2.1215e+00, -7.4147e+00, -8.4545e+00, -2.7061e+00, -6.4326e+00,\n",
       "                       -7.7514e+00, -3.8586e+00, -6.9997e+00, -1.1667e+01, -1.4082e+01,\n",
       "                       -9.2473e+00, -6.5463e+00, -8.5109e+00, -7.4938e+00, -5.8003e+00,\n",
       "                       -1.2547e+01, -1.3107e+01], device='cuda:0')),\n",
       "              ('conv_block4.bn2.running_var',\n",
       "               tensor([ 11.1928,  53.3017,  51.0669,  52.2867,  80.0786,  74.3442,  48.2583,\n",
       "                        34.0121,  62.5212,  36.9132,  30.6323,  83.5912,  22.1438, 109.2607,\n",
       "                        21.8107,  85.6416, 100.8924,  11.9242, 118.4059,  44.4059,  38.3203,\n",
       "                        60.7572,  51.8448,  36.3950,  41.5863,  14.8931,  47.9334,  59.9898,\n",
       "                        47.8094,  45.2200,  94.6671,  44.5500,  95.3717,  84.9833,  98.1159,\n",
       "                        61.6392,  55.7003,  61.5076,  59.7739,  13.8111,  90.4101,  59.8583,\n",
       "                        99.7951,  56.2587,  39.2533,  80.6158, 111.8627,  49.7142,  82.4205,\n",
       "                        56.7479,  33.9304,  50.2885,  75.2360,  38.7465,  71.8488,  52.6811,\n",
       "                        38.6235,  58.4284,  43.2303,  40.1573,  67.9711,  39.2375,  42.2339,\n",
       "                        47.3080,  75.6820,  19.2721,  40.4011,  43.0540,  71.9403,  47.5431,\n",
       "                        62.0605,  43.4029,  47.5813,  39.7316,  63.8351,  39.8420,  38.1693,\n",
       "                        59.1478,  85.2539,  57.1253,  30.2273,  51.8096,  59.1155,  15.5869,\n",
       "                        83.8124,  47.2703,  76.8758,  30.7585,  60.8699,  53.4352, 102.7433,\n",
       "                        63.5001,  52.3672,  37.0522,  49.0127,  43.4978,  81.1971,  76.4235,\n",
       "                        45.9230,  81.9586,  50.3384,  43.0485,  46.8188,  61.5738,  61.6368,\n",
       "                        50.6147,  36.5680,  27.8634,  39.1568,  40.9340,  44.8391,  82.8282,\n",
       "                        33.4690,  49.5795,  86.2933,  31.3178, 118.9870, 100.9886,  60.2612,\n",
       "                        59.8416,  49.7938,  90.7881,  26.7131,  44.5669,  73.6197,  71.4574,\n",
       "                        84.1493,  58.5012,  62.9278,  47.0253,  56.1249,  91.0492,  42.3154,\n",
       "                        33.1562,  55.4098,  65.9441,  47.9223,  89.3867,  83.5900,  25.0208,\n",
       "                        18.3570,  18.2900,  48.8747,  69.8588,  48.1104,  43.2323,  59.6621,\n",
       "                        56.4917,  43.4385,  43.8049,  81.6386, 100.8001,  40.5706,  40.2936,\n",
       "                        41.7756,  63.1442,  28.3143,  37.2046,  45.6980,  62.6066,  36.0572,\n",
       "                        41.8511,  65.1100,  84.7540,  36.0899,  70.4986,  82.2356, 152.8418,\n",
       "                        23.7137,   3.6221,  14.1293,  67.2717,  53.1725,  90.4444,  61.7455,\n",
       "                        64.7622,  65.0832,  57.6191,  82.3690,  94.1736,  23.1594,  54.4779,\n",
       "                        99.9592,  24.5537,  33.5033,  45.7281,  59.4613,  80.9626,  13.5906,\n",
       "                        48.6335,  54.8876,  88.8959, 102.5087, 106.1508,  48.6915,  63.5540,\n",
       "                        45.0910,  55.3420,  44.1995,  37.8055,  74.2478,  37.8189,  30.0285,\n",
       "                        51.2988,  48.8009,  77.4679,  17.2461,  63.4621,  40.4324,  54.0451,\n",
       "                        50.6870,  57.5285,  31.7208,  58.0162,  45.3611,  40.5543,  78.3325,\n",
       "                        35.0172,  38.4266,  70.5270,  14.0015,  45.1467,  90.8740,  47.4933,\n",
       "                        58.2117,  87.9746,  59.5720,  95.5331,  47.9632,  74.9783,  41.2004,\n",
       "                        60.3699,  71.2798,  93.5758,  50.6061,  96.9061,  70.5143,  83.0922,\n",
       "                        68.2654,  90.9998,  67.5539,  33.4626,  57.2000,  47.6523,  34.2744,\n",
       "                        48.1786,  65.7850,  50.5441, 106.6408,   8.1503,  62.6719, 102.7069,\n",
       "                       114.9361,  73.4213,  21.4549,  99.0273,  44.5524,  56.1305,  39.4360,\n",
       "                        62.1714,  55.4273,  78.5655,  35.5676,  87.7615,  72.4988,  81.8910,\n",
       "                        95.8232,  60.1173,  58.3811,  16.9838,  40.9968,  39.5271,  72.5095,\n",
       "                        49.3971,  11.4117,  54.8967,  92.5113,  43.9219,  53.2106,  48.5834,\n",
       "                         2.9526,  68.8296,  63.5734, 155.7335,  28.4232,  40.4323,  84.1472,\n",
       "                        80.2775, 110.1258,  22.5277,  89.1954,  85.6091,  65.5027,  34.9781,\n",
       "                        48.7764,  64.6939,  93.2365,  80.3628,  55.8026,  69.9191,  78.3424,\n",
       "                        62.2637,  15.5063,  23.7107,  74.7847,  47.7538,  82.3494,  26.6709,\n",
       "                        70.9965,  53.3871,  70.5160,  99.0725,  54.8642,  86.5070,  16.5190,\n",
       "                        39.9201,  92.2942,  78.0589,  53.2567,  62.9373,  41.7328,  67.9383,\n",
       "                        40.8174,  34.5561,  51.6187,  34.2148,  55.4327,  70.3147,  36.7174,\n",
       "                        46.4953,  45.3549,  78.0500,  84.1940,  46.9333,  46.9945,  74.4081,\n",
       "                        34.8301,  42.5034,  17.9436,  66.1403,  60.7466,  76.6276, 119.4225,\n",
       "                        38.1936,  43.4453,  55.9602,  50.0913,  69.2016,  39.3175,  60.2690,\n",
       "                        38.1557, 106.0116,  79.2110,  58.6853,  84.3018,  72.0509,  39.5623,\n",
       "                       115.5835,  64.3536,  51.3300,  46.6341, 101.9641,  56.5856,  76.5907,\n",
       "                        45.8184,  58.3037,  47.6432,  91.0885,  64.4356,  59.6343,  36.9506,\n",
       "                        64.3504,  51.6090,  56.5320,  73.2130,  23.6270,  68.3700,  67.5480,\n",
       "                        44.1436,  43.6108,  78.5045,  83.4083,  58.2217, 103.6786,  31.9860,\n",
       "                        74.2403,  67.3879,  39.8229,  32.4913,  32.6768,  91.5966,  45.3605,\n",
       "                       108.8235,  32.8082,  50.5934,  91.6739,  16.1244,  35.7590,  45.0954,\n",
       "                        30.9777,  63.2997,  97.4187,  84.9518,  40.0544,  75.9549,  46.7344,\n",
       "                        69.7373,  35.1221,  80.2730,  66.9634,  56.1092,  45.0030,  71.9980,\n",
       "                        42.8451,  60.2079,  28.2633,  53.9199,  45.6116,  96.5842,  92.0539,\n",
       "                        54.1927,  69.5643,  56.8316,   2.1505,  53.6798,  18.2630,  64.8197,\n",
       "                        44.6015,  71.2333,  40.7053,  47.1735,  58.7793,  72.7223,  19.9319,\n",
       "                        66.7617,  76.8800,  69.8396,  43.0561,  65.1307,  50.2485,  66.2522,\n",
       "                        57.2574,  69.3703,  31.5527,  78.2469,  37.8475,  63.7912,  41.7869,\n",
       "                       105.6840,  63.0001,  52.5453,  29.5774, 162.5009,  94.4659,  56.8452,\n",
       "                        61.6458,  61.5811,  44.4748,  88.0564, 112.7112,  44.1612,  88.8550,\n",
       "                        67.0239,  73.5724,  66.0749,   3.4181,  82.5609,  41.3850,  88.4571,\n",
       "                        27.8282,  73.2655,  85.5286,  62.6283,  41.7645,  81.5717,  32.2696,\n",
       "                        52.0161,  96.4026, 140.6467,  65.5367,  95.1845, 107.5330,  58.4106,\n",
       "                        21.4762,  66.5329,  54.0200,  80.9177,  66.2836,  46.3554,  60.3257,\n",
       "                        78.9885,  23.4113,  46.2026,  66.3076,  55.8540,  29.5310,  66.5583,\n",
       "                        49.7555,  84.8976,  52.7074,  34.1636,  73.6272,  38.0968,  73.0299,\n",
       "                        98.0650, 141.9720,  57.8938,  64.3860,  45.7366,  51.8045,  58.0539,\n",
       "                        59.2296], device='cuda:0')),\n",
       "              ('conv_block4.bn2.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('conv_block5.conv1.weight',\n",
       "               tensor([[[[-2.7977e-01, -8.6348e-03, -1.4918e-02],\n",
       "                         [ 1.5644e-02, -1.7228e-02, -9.3875e-03],\n",
       "                         [-1.4924e-01,  5.9687e-02,  1.1857e-02]],\n",
       "               \n",
       "                        [[-4.0786e-02,  6.6816e-02,  3.1094e-02],\n",
       "                         [-6.1462e-02, -6.5763e-02, -4.9224e-03],\n",
       "                         [-3.9178e-02,  4.6533e-02,  9.4947e-02]],\n",
       "               \n",
       "                        [[-4.3985e-01, -7.9792e-03, -4.3415e-02],\n",
       "                         [-3.7417e-02, -3.4026e-02, -1.2469e-02],\n",
       "                         [-1.7177e-02,  5.3482e-02,  6.3374e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.2442e-02, -5.1796e-01, -4.4666e-02],\n",
       "                         [ 3.5432e-04, -1.6222e-01, -3.0396e-03],\n",
       "                         [ 1.0332e-01, -4.4458e-01, -9.5123e-03]],\n",
       "               \n",
       "                        [[-2.0125e-02, -1.0326e-01, -6.5799e-02],\n",
       "                         [-1.9511e-01, -5.9861e-02, -2.4001e-01],\n",
       "                         [-2.0728e-02,  2.0578e-01, -3.3643e-02]],\n",
       "               \n",
       "                        [[ 1.2754e-01,  8.8958e-02,  6.8358e-02],\n",
       "                         [ 1.7682e-02,  4.0875e-02,  2.0377e-01],\n",
       "                         [ 6.3279e-03, -1.3566e-02,  4.7470e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8818e-03,  8.4728e-03, -9.2496e-03],\n",
       "                         [ 1.7659e-02, -4.1299e-02, -3.0729e-02],\n",
       "                         [ 4.3033e-02,  9.5601e-04,  3.2370e-02]],\n",
       "               \n",
       "                        [[-7.9352e-02,  5.0941e-02,  1.3615e-01],\n",
       "                         [-6.4191e-02,  5.0081e-02,  1.6404e-01],\n",
       "                         [-1.8239e-01, -1.8916e-02,  1.7448e-01]],\n",
       "               \n",
       "                        [[-1.1869e-02, -1.7185e-03,  3.4742e-02],\n",
       "                         [ 9.1027e-03,  9.5013e-04, -9.2604e-03],\n",
       "                         [ 2.2659e-03, -3.6688e-02,  2.5610e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.2377e-02,  1.1801e-02,  3.2740e-02],\n",
       "                         [-1.1626e-01, -2.5292e-02, -1.7750e-03],\n",
       "                         [-1.4246e-02, -3.6980e-03,  1.4723e-02]],\n",
       "               \n",
       "                        [[-6.0860e-02, -2.2492e-02,  1.3338e-03],\n",
       "                         [ 1.1482e-02,  3.4881e-03, -2.2906e-02],\n",
       "                         [ 2.6100e-03, -1.4585e-02, -7.9230e-03]],\n",
       "               \n",
       "                        [[-2.2837e-02,  1.3509e-03, -5.4051e-02],\n",
       "                         [ 8.1078e-03, -4.1517e-01,  2.5832e-02],\n",
       "                         [-1.0350e-01, -3.8965e-02, -3.6931e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.0300e-02, -1.7104e-02, -1.6026e-02],\n",
       "                         [-3.4283e-03, -5.7159e-04, -2.2902e-01],\n",
       "                         [-2.1872e-04, -7.9645e-02, -3.3224e-02]],\n",
       "               \n",
       "                        [[ 2.7049e-01, -2.5256e-02,  5.2139e-02],\n",
       "                         [ 4.4698e-01, -1.4424e-01,  3.6792e-02],\n",
       "                         [ 2.8850e-01, -4.3300e-04,  9.6227e-02]],\n",
       "               \n",
       "                        [[ 1.1139e-02,  5.8669e-03,  2.9106e-03],\n",
       "                         [-5.9462e-03, -3.1749e-02, -1.3963e-01],\n",
       "                         [ 3.4871e-03, -6.2868e-02, -1.1610e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-9.8615e-02, -5.5468e-02, -1.0829e-01],\n",
       "                         [-3.2670e-01, -1.5040e-01, -1.2119e-02],\n",
       "                         [-5.0692e-03, -5.9274e-02,  1.4865e-02]],\n",
       "               \n",
       "                        [[ 7.0753e-02,  3.6821e-02,  1.6290e-02],\n",
       "                         [ 5.6020e-02,  3.1329e-02,  1.4218e-02],\n",
       "                         [ 1.4653e-02, -1.1729e-02,  1.2755e-02]],\n",
       "               \n",
       "                        [[ 8.1736e-02, -3.2734e-02, -1.3159e-01],\n",
       "                         [ 1.2848e-01, -1.0234e-01, -5.6513e-02],\n",
       "                         [ 2.5515e-02, -1.5261e-01, -5.2302e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-2.3847e-02, -9.6773e-02, -2.7652e-02],\n",
       "                         [-3.7151e-02, -3.7347e-03, -5.5829e-03],\n",
       "                         [ 1.5995e-02,  5.8832e-02,  4.7416e-02]],\n",
       "               \n",
       "                        [[ 6.2028e-02,  2.8177e-01,  1.4061e-01],\n",
       "                         [ 7.2023e-02,  3.1166e-01,  1.2157e-02],\n",
       "                         [ 6.2906e-02,  9.2240e-02, -1.0616e-02]],\n",
       "               \n",
       "                        [[-4.4827e-01,  5.5112e-03,  2.9530e-02],\n",
       "                         [-1.7534e-01,  9.5240e-03,  7.8405e-02],\n",
       "                         [-1.6474e-01, -2.6512e-02,  6.5356e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.6736e-01, -1.4971e-01,  8.2863e-02],\n",
       "                         [-4.0001e-02, -1.0600e-01, -4.7968e-02],\n",
       "                         [-1.7995e-01, -2.1657e-01,  9.4587e-02]],\n",
       "               \n",
       "                        [[-7.2027e-02, -5.5677e-02, -1.0789e-01],\n",
       "                         [-4.0297e-02, -7.4462e-02, -7.5607e-02],\n",
       "                         [-1.0550e-01, -1.5231e-01, -1.2515e-01]],\n",
       "               \n",
       "                        [[-6.4836e-03, -2.2145e-01, -2.6774e-01],\n",
       "                         [-5.8917e-02, -4.6336e-02, -1.0489e-01],\n",
       "                         [-8.4868e-02, -1.7269e-01, -8.3245e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.6379e-03, -2.5842e-02, -1.9895e-01],\n",
       "                         [ 6.9678e-03,  2.9225e-02, -4.9938e-02],\n",
       "                         [ 1.0113e-01,  1.1487e-02, -5.8743e-02]],\n",
       "               \n",
       "                        [[-8.8332e-02, -1.9949e-02,  3.9691e-03],\n",
       "                         [-1.6495e-01, -7.0597e-02,  1.7399e-02],\n",
       "                         [-1.1016e-01, -1.8932e-02, -8.6032e-03]],\n",
       "               \n",
       "                        [[-2.0379e-02, -8.8357e-02, -1.2859e-02],\n",
       "                         [-3.4775e-01, -1.0969e-01, -1.2325e-01],\n",
       "                         [-4.8268e-02, -7.7125e-02,  4.6515e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-7.3263e-02, -7.1055e-03,  3.8885e-01],\n",
       "                         [-5.5494e-02, -2.6857e-02,  9.5741e-02],\n",
       "                         [-1.7641e-01,  5.6021e-02,  4.1789e-02]],\n",
       "               \n",
       "                        [[-3.2549e-01,  4.9957e-03, -3.5458e-02],\n",
       "                         [-4.7726e-01,  2.7424e-02, -4.6383e-02],\n",
       "                         [-3.6691e-01,  5.1198e-03, -1.7908e-02]],\n",
       "               \n",
       "                        [[ 3.0240e-02, -4.0516e-02,  3.9077e-02],\n",
       "                         [ 9.3347e-02, -8.3198e-02, -5.4307e-02],\n",
       "                         [-9.3373e-03, -1.0296e-01,  1.1075e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.8480e-02, -4.4945e-02,  1.5108e-01],\n",
       "                         [-6.1841e-02, -6.6630e-02,  2.4185e-03],\n",
       "                         [-1.6105e-02, -5.0720e-02,  7.8629e-02]],\n",
       "               \n",
       "                        [[-1.7008e-01, -3.7473e-02,  1.7339e-01],\n",
       "                         [-2.7513e-01, -1.9919e-01, -1.0788e-01],\n",
       "                         [-1.8990e-02, -1.1651e-01, -3.2683e-01]],\n",
       "               \n",
       "                        [[-2.4307e-02,  3.5724e-02,  9.4917e-03],\n",
       "                         [ 9.7081e-03,  3.8416e-01,  7.7876e-02],\n",
       "                         [-3.9643e-02,  3.4017e-02,  1.1596e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.0253e-01, -7.0376e-02, -5.0396e-02],\n",
       "                         [ 5.1121e-02, -1.7583e-01, -3.0042e-02],\n",
       "                         [ 1.5281e-02, -8.7759e-04, -3.3949e-01]],\n",
       "               \n",
       "                        [[ 3.5166e-03, -1.4725e-01,  2.2899e-02],\n",
       "                         [ 2.6572e-01,  1.5916e-01,  1.2075e-01],\n",
       "                         [ 6.9275e-02,  1.8557e-01,  1.1392e-01]],\n",
       "               \n",
       "                        [[-2.5713e-02, -3.3582e-01, -1.6106e-01],\n",
       "                         [-5.7959e-02, -9.6171e-02, -8.6770e-02],\n",
       "                         [-4.1506e-02, -1.5657e-01, -2.6601e-01]]]], device='cuda:0')),\n",
       "              ('conv_block5.conv2.weight',\n",
       "               tensor([[[[-2.1228e-02, -9.1362e-03,  3.3545e-02],\n",
       "                         [-5.9352e-03, -2.0469e-02,  2.9194e-02],\n",
       "                         [-2.8893e-03, -6.1311e-02, -3.4882e-03]],\n",
       "               \n",
       "                        [[-4.5351e-02, -5.6860e-02, -5.9442e-03],\n",
       "                         [-2.1822e-01, -1.4585e-01, -1.4114e-01],\n",
       "                         [-1.4001e-01, -8.7811e-02, -9.1355e-04]],\n",
       "               \n",
       "                        [[ 4.1296e-02, -2.7658e-02,  1.3773e-02],\n",
       "                         [ 7.9491e-02,  7.3248e-03,  9.2028e-03],\n",
       "                         [ 5.9982e-02, -7.9922e-02, -4.1965e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.8994e-02,  1.7157e-01,  2.6285e-03],\n",
       "                         [-8.2328e-02,  3.3287e-02, -8.6816e-02],\n",
       "                         [-1.2840e-02,  4.4523e-03, -2.5935e-01]],\n",
       "               \n",
       "                        [[ 4.7935e-02,  1.7613e-02, -5.2538e-02],\n",
       "                         [ 8.5103e-02,  9.2679e-02, -7.9353e-02],\n",
       "                         [ 1.1667e-01,  8.5298e-02, -8.9534e-02]],\n",
       "               \n",
       "                        [[-7.4912e-02,  3.9714e-02, -2.2907e-01],\n",
       "                         [-1.1437e-01, -1.9158e-02, -3.7680e-02],\n",
       "                         [-5.2791e-02, -3.4422e-01, -8.7367e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.2048e-02, -3.0071e-01, -1.3725e-02],\n",
       "                         [-1.1325e-01, -7.9250e-02, -1.0485e-02],\n",
       "                         [ 2.3565e-02,  4.0674e-03,  4.5443e-03]],\n",
       "               \n",
       "                        [[-1.5036e-02, -4.1054e-01,  3.9623e-02],\n",
       "                         [-1.4755e-01, -9.5011e-02, -8.5039e-02],\n",
       "                         [-6.2292e-02, -2.3099e-01, -8.3986e-02]],\n",
       "               \n",
       "                        [[-4.3589e-02, -1.1124e-01, -2.1167e-02],\n",
       "                         [-3.5809e-02, -3.9300e-02, -6.4816e-02],\n",
       "                         [-4.2643e-02, -5.5354e-01, -4.3190e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.6317e-03,  5.1136e-02,  2.5500e-01],\n",
       "                         [-6.5648e-02,  3.7849e-02,  5.2609e-02],\n",
       "                         [ 1.6340e-02,  2.8051e-01,  2.3561e-01]],\n",
       "               \n",
       "                        [[ 4.4304e-02,  7.4285e-03,  1.1901e-01],\n",
       "                         [ 1.3715e-01, -4.9740e-02,  8.9753e-02],\n",
       "                         [ 1.8575e-01,  1.3149e-02,  1.0262e-01]],\n",
       "               \n",
       "                        [[ 3.6475e-02,  1.2730e-01,  1.1540e-02],\n",
       "                         [ 1.9027e-01,  1.7933e-02, -1.7377e-02],\n",
       "                         [ 4.3663e-02,  2.9562e-02, -2.0904e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6863e-02,  1.2325e-02, -2.9855e-02],\n",
       "                         [-2.0898e-01, -2.7276e-02, -2.5206e-03],\n",
       "                         [-6.1097e-02, -2.1162e-02,  1.0875e-03]],\n",
       "               \n",
       "                        [[ 5.4355e-02, -5.5239e-02, -3.9947e-02],\n",
       "                         [ 6.2244e-02, -8.0952e-04,  3.4021e-02],\n",
       "                         [ 2.1602e-02, -1.4956e-01,  3.9301e-02]],\n",
       "               \n",
       "                        [[-4.8429e-03, -4.3145e-02, -5.4846e-02],\n",
       "                         [ 9.5357e-02, -2.9976e-01, -5.2246e-02],\n",
       "                         [ 1.5302e-02, -8.3928e-02, -1.4179e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.6549e-02,  6.6517e-02, -1.3477e-01],\n",
       "                         [-8.0200e-02,  7.2316e-02, -5.2523e-02],\n",
       "                         [-4.7087e-03,  4.9951e-03, -1.5083e-01]],\n",
       "               \n",
       "                        [[-2.1935e-02,  1.2588e-02,  9.0459e-02],\n",
       "                         [-5.0256e-02, -6.2785e-02,  2.5397e-01],\n",
       "                         [-1.1459e-01, -4.3177e-02,  2.3758e-01]],\n",
       "               \n",
       "                        [[ 6.4675e-03, -3.0047e-02,  4.7641e-02],\n",
       "                         [ 3.0940e-02,  7.2147e-02,  2.7377e-02],\n",
       "                         [ 9.3369e-02,  9.0332e-01,  6.4215e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 2.6369e-02,  1.2674e-02,  7.2153e-02],\n",
       "                         [ 2.1936e-02, -5.3641e-02,  7.5729e-04],\n",
       "                         [ 2.9831e-02, -2.1029e-02, -1.2191e-02]],\n",
       "               \n",
       "                        [[-8.4878e-02, -3.7904e-02,  3.4141e-01],\n",
       "                         [-9.6944e-02,  3.4184e-03,  7.7674e-02],\n",
       "                         [-1.9508e-01, -2.2251e-02,  6.0539e-01]],\n",
       "               \n",
       "                        [[-2.6139e-03, -1.7930e-01, -4.9512e-02],\n",
       "                         [ 1.7750e-03, -5.1229e-02, -3.6207e-02],\n",
       "                         [ 8.7608e-03, -9.3177e-02, -3.4375e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.5493e-02, -5.5068e-01, -4.6839e-02],\n",
       "                         [ 5.9947e-01, -8.2642e-02,  2.6020e-02],\n",
       "                         [ 7.2719e-01, -5.9925e-01, -6.2334e-02]],\n",
       "               \n",
       "                        [[ 7.8688e-02, -1.5266e-02,  1.1651e-02],\n",
       "                         [ 6.8176e-02, -7.1400e-02, -4.6038e-02],\n",
       "                         [ 1.9115e-02, -3.0247e-02,  4.9163e-02]],\n",
       "               \n",
       "                        [[ 5.2403e-02,  3.3361e-02,  5.7577e-02],\n",
       "                         [ 1.0988e-01,  3.1325e-02, -5.6070e-03],\n",
       "                         [ 2.5417e-02,  2.0964e-03,  2.5235e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.3899e-02,  3.3073e-02,  1.2087e-02],\n",
       "                         [ 3.1145e-02,  1.7010e-02,  2.9034e-03],\n",
       "                         [ 3.7103e-02,  2.3106e-02,  3.2070e-03]],\n",
       "               \n",
       "                        [[-3.2718e-02, -1.6799e-02, -7.6067e-02],\n",
       "                         [-7.9419e-02, -1.6570e-02, -1.7519e-02],\n",
       "                         [-2.4191e-02,  4.7625e-02, -6.0944e-03]],\n",
       "               \n",
       "                        [[ 3.8416e-01,  1.8449e-02,  3.5448e-02],\n",
       "                         [ 3.8787e-02,  2.7065e-02,  2.5651e-01],\n",
       "                         [ 2.6909e-02,  4.0640e-02, -1.3312e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.7161e-03,  1.0113e-02,  2.5717e-01],\n",
       "                         [ 2.8215e-03,  6.9803e-02,  7.9101e-02],\n",
       "                         [-2.5632e-01,  1.8092e-02,  4.0833e-02]],\n",
       "               \n",
       "                        [[-4.0198e-03,  5.0910e-02,  5.1720e-01],\n",
       "                         [-4.2597e-02,  4.6442e-02,  8.6091e-02],\n",
       "                         [-2.7837e-02,  8.8779e-02,  6.2744e-02]],\n",
       "               \n",
       "                        [[-1.6712e-01, -5.4959e-02,  4.8002e-03],\n",
       "                         [-5.7366e-02, -1.9845e-02, -2.3488e-02],\n",
       "                         [-4.3248e-02, -5.4078e-02,  2.4655e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.5797e-01, -5.9760e-02, -1.6195e-01],\n",
       "                         [-2.8142e-02, -3.4901e-02, -2.7200e-02],\n",
       "                         [ 1.4257e-01, -2.2896e-01,  9.6334e-04]],\n",
       "               \n",
       "                        [[-2.0788e-01, -1.2213e-01, -1.1134e-02],\n",
       "                         [-4.2324e-01, -5.6907e-01,  2.8656e-02],\n",
       "                         [-2.2292e-01, -1.3829e-01,  3.6055e-01]],\n",
       "               \n",
       "                        [[-6.5037e-03, -6.9748e-02, -8.2095e-03],\n",
       "                         [-8.1513e-02, -1.2842e-01, -6.1657e-02],\n",
       "                         [-5.4953e-02, -2.3856e-01, -1.6105e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.2883e-02, -3.4567e-02, -5.2350e-01],\n",
       "                         [ 7.3019e-02, -3.2010e-01, -5.4951e-02],\n",
       "                         [ 1.6097e-01, -1.1643e-01, -2.1452e-01]],\n",
       "               \n",
       "                        [[ 3.3527e-02, -1.1150e-02, -1.0038e-01],\n",
       "                         [ 1.5498e-02, -2.8439e-02, -3.1238e-02],\n",
       "                         [ 2.2277e-01, -2.1597e-03, -4.9671e-02]],\n",
       "               \n",
       "                        [[-1.8141e-01, -7.7247e-02, -6.6011e-02],\n",
       "                         [-6.1141e-02, -5.7440e-02,  6.4761e-03],\n",
       "                         [-4.6483e-02,  5.2010e-04, -1.1125e-02]]]], device='cuda:0')),\n",
       "              ('conv_block5.bn1.weight',\n",
       "               tensor([0.9305, 1.2697, 1.0094,  ..., 1.0985, 1.0980, 1.1403], device='cuda:0')),\n",
       "              ('conv_block5.bn1.bias',\n",
       "               tensor([-0.6293, -1.0801, -0.8402,  ..., -1.2165, -1.0656, -0.9965],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block5.bn1.running_mean',\n",
       "               tensor([-3.2257, -5.7612, -4.0930,  ..., -6.2988, -4.9929, -8.8982],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block5.bn1.running_var',\n",
       "               tensor([ 9.8653, 17.3442, 11.4716,  ..., 20.5684, 19.4696, 23.6167],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block5.bn1.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('conv_block5.bn2.weight',\n",
       "               tensor([1.1649, 1.0677, 1.2120,  ..., 1.0317, 0.9516, 1.1016], device='cuda:0')),\n",
       "              ('conv_block5.bn2.bias',\n",
       "               tensor([-1.3333, -0.9682, -1.1125,  ..., -1.0031, -0.9700, -1.1586],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block5.bn2.running_mean',\n",
       "               tensor([ -7.2414,  -9.3559, -11.6898,  ..., -13.5102,  -6.1452, -15.5509],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block5.bn2.running_var',\n",
       "               tensor([52.8302, 56.7370, 58.6006,  ..., 83.6676, 35.9651, 87.4294],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block5.bn2.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('conv_block6.conv1.weight',\n",
       "               tensor([[[[-4.3826e-02, -8.4802e-02,  1.4432e-02],\n",
       "                         [-2.2459e-02, -6.7034e-02,  2.4530e-02],\n",
       "                         [ 8.2638e-02,  2.3008e-01,  1.3330e-01]],\n",
       "               \n",
       "                        [[-1.9665e-03,  3.7833e-02,  1.9396e-01],\n",
       "                         [ 1.8940e-02, -6.9509e-02, -8.5170e-03],\n",
       "                         [ 3.8757e-02, -5.6799e-02, -5.7250e-02]],\n",
       "               \n",
       "                        [[ 6.5437e-04, -2.2148e-02,  1.3119e-01],\n",
       "                         [ 5.0454e-02, -2.1378e-02,  1.8384e-02],\n",
       "                         [ 2.0842e-01, -1.7431e-02,  1.2492e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.8783e-02, -9.7272e-02,  8.8465e-02],\n",
       "                         [-3.7197e-02, -2.6275e-02,  1.0380e-01],\n",
       "                         [-7.6484e-02, -5.5016e-02,  1.7879e-01]],\n",
       "               \n",
       "                        [[ 2.0003e-03, -2.8427e-02, -4.5092e-02],\n",
       "                         [-2.1250e-02, -2.0192e-02, -2.5495e-01],\n",
       "                         [ 2.3438e-02, -5.4457e-02, -8.1841e-02]],\n",
       "               \n",
       "                        [[-3.5626e-02, -9.4087e-02,  9.5350e-03],\n",
       "                         [-2.9649e-02, -9.5534e-02,  4.8516e-02],\n",
       "                         [-4.7880e-02, -4.9178e-02,  4.4558e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.5443e-02,  4.0963e-02,  4.3013e-02],\n",
       "                         [ 9.6221e-03, -5.3677e-03,  1.6366e-02],\n",
       "                         [-4.0777e-03,  2.1077e-02,  1.0687e-02]],\n",
       "               \n",
       "                        [[ 3.1341e-02,  1.1936e-02,  7.0192e-04],\n",
       "                         [ 1.7776e-02,  1.9009e-02, -8.0664e-04],\n",
       "                         [ 1.7752e-02,  1.9448e-03, -6.6930e-03]],\n",
       "               \n",
       "                        [[-1.6584e-01,  7.7719e-02, -4.3312e-03],\n",
       "                         [-4.1405e-01,  9.2018e-01, -1.4130e-03],\n",
       "                         [-1.6653e-01,  3.0179e-02, -5.6295e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.9110e-02,  1.6668e-02, -1.6240e-02],\n",
       "                         [-3.7076e-02, -1.0661e-01, -7.8650e-03],\n",
       "                         [-2.3204e-02,  1.3290e-02,  1.2552e-03]],\n",
       "               \n",
       "                        [[ 5.0690e-02,  6.7750e-02,  4.1306e-02],\n",
       "                         [ 2.3798e-01,  7.8438e-02,  2.9537e-02],\n",
       "                         [ 6.2446e-02, -1.9739e-01,  5.2625e-02]],\n",
       "               \n",
       "                        [[ 1.8760e-02,  3.8413e-03,  1.7486e-02],\n",
       "                         [ 3.3771e-02, -2.0990e-02,  2.4419e-02],\n",
       "                         [ 3.3314e-02,  3.7877e-02,  3.4195e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.6070e-02, -9.8782e-02, -5.3322e-02],\n",
       "                         [ 9.5640e-02,  2.2400e-02, -2.9183e-02],\n",
       "                         [ 4.5256e-02,  1.4944e-02, -1.6193e-02]],\n",
       "               \n",
       "                        [[-1.1354e+00, -2.0247e-02, -1.2900e-02],\n",
       "                         [-2.1624e-01, -3.2054e-02, -1.5823e-02],\n",
       "                         [-5.0151e-02, -1.9571e-01, -1.5922e-02]],\n",
       "               \n",
       "                        [[-4.7022e-02, -6.8370e-02, -1.2625e-02],\n",
       "                         [-5.4546e-02, -1.5951e-01,  4.7652e-02],\n",
       "                         [-1.0003e-01, -1.2564e-01,  2.6743e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.4067e-02, -7.8027e-02, -3.5294e-03],\n",
       "                         [ 8.1396e-02,  2.3006e-02,  1.2164e-02],\n",
       "                         [ 6.1505e-02, -1.1562e-02,  1.2297e-01]],\n",
       "               \n",
       "                        [[-2.9751e-01,  2.1548e-02, -5.3265e-03],\n",
       "                         [-1.6712e-01, -1.2092e-01,  7.8343e-03],\n",
       "                         [-2.3779e-01,  1.0046e-02, -7.4165e-03]],\n",
       "               \n",
       "                        [[-1.1175e-03,  9.0096e-02, -5.7716e-03],\n",
       "                         [ 8.4220e-02,  3.7386e-02, -2.3486e-02],\n",
       "                         [ 4.9086e-01, -2.1775e-03, -3.8526e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-2.6021e-03, -3.0697e-02,  4.1756e-03],\n",
       "                         [ 8.9995e-03, -4.2114e-02,  1.8803e-03],\n",
       "                         [-1.1006e-02, -3.5823e-02, -1.2171e-01]],\n",
       "               \n",
       "                        [[-9.5467e-04,  1.3604e-01,  1.1566e-01],\n",
       "                         [ 3.3408e-03, -5.0979e-03,  9.0022e-02],\n",
       "                         [ 2.3099e-03, -1.3582e-02, -2.5981e-02]],\n",
       "               \n",
       "                        [[-1.3331e-02,  2.2935e-02,  1.0200e-01],\n",
       "                         [-1.3143e-02,  2.6181e-02,  1.1047e-01],\n",
       "                         [-3.9828e-04, -1.2226e-02,  3.1641e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.4768e-03,  1.2559e-01, -9.1833e-03],\n",
       "                         [ 5.4936e-02,  2.4563e-02,  8.3393e-02],\n",
       "                         [ 2.3909e-02,  5.3298e-01,  2.3102e-02]],\n",
       "               \n",
       "                        [[ 1.1202e-02, -2.2244e-03,  6.7818e-02],\n",
       "                         [ 2.6693e-03,  2.5669e-05,  4.9058e-02],\n",
       "                         [-3.6267e-01, -2.6246e-02,  5.7777e-02]],\n",
       "               \n",
       "                        [[ 1.0076e-02,  2.1667e-01, -9.7842e-02],\n",
       "                         [-4.2885e-03,  4.0014e-02,  1.6735e-02],\n",
       "                         [ 4.3417e-03,  6.0405e-02, -2.1785e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.4990e-03,  1.8251e-01,  1.6796e-01],\n",
       "                         [-1.4383e-02,  6.3113e-01, -8.5350e-02],\n",
       "                         [ 4.9774e-02,  8.9784e-01, -3.3440e-01]],\n",
       "               \n",
       "                        [[ 4.9477e-02,  3.0398e-01,  6.9230e-02],\n",
       "                         [ 2.7517e-02, -2.9702e-02,  6.3860e-02],\n",
       "                         [ 3.3913e-02, -1.2781e-01,  3.0749e-02]],\n",
       "               \n",
       "                        [[ 1.9912e-01,  1.5520e-01,  2.0724e-01],\n",
       "                         [ 1.3614e-02, -3.8268e-02,  1.0786e-01],\n",
       "                         [ 1.2057e-02, -2.7979e-01,  1.2682e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.8654e-01,  3.2405e-02,  4.9204e-01],\n",
       "                         [-2.8349e-01,  3.1431e-03,  1.0100e-01],\n",
       "                         [-4.6285e-02,  2.9788e-01,  2.5757e-01]],\n",
       "               \n",
       "                        [[-6.1499e-02, -8.6628e-02, -2.9340e-02],\n",
       "                         [-4.2013e-02, -3.8655e-02, -7.8722e-02],\n",
       "                         [-2.0363e-02, -1.1308e-01, -9.1692e-02]],\n",
       "               \n",
       "                        [[-6.3498e-03, -4.7607e-02,  1.0180e-01],\n",
       "                         [-5.3765e-01, -6.2912e-02,  1.2447e-01],\n",
       "                         [-7.5518e-02, -1.0989e-01,  1.3928e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.2126e-02,  8.7431e-03, -2.7015e-02],\n",
       "                         [ 1.0657e-01, -3.4825e-03,  5.4367e-03],\n",
       "                         [ 2.7986e-02, -1.0736e-02,  2.6640e-02]],\n",
       "               \n",
       "                        [[ 2.8801e-02,  6.5827e-03, -3.8587e-03],\n",
       "                         [ 1.1724e-02,  2.9733e-02,  4.2473e-02],\n",
       "                         [ 2.2640e-02, -4.3669e-03,  9.7395e-03]],\n",
       "               \n",
       "                        [[-3.2553e-02,  7.5313e-03,  8.0286e-03],\n",
       "                         [-1.5501e-02,  5.7795e-02,  9.8663e-02],\n",
       "                         [-3.8821e-02,  5.0681e-02,  3.1343e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.5742e-01, -1.8825e-01, -5.0616e-02],\n",
       "                         [-5.7554e-01, -7.6606e-01, -5.5475e-02],\n",
       "                         [-3.0395e-01, -2.7166e-01,  1.6749e-02]],\n",
       "               \n",
       "                        [[-3.8865e-02,  8.4528e-03, -8.9390e-03],\n",
       "                         [-2.0142e-02, -1.5666e-02, -3.9598e-03],\n",
       "                         [-8.5971e-02,  3.9320e-03, -9.1738e-03]],\n",
       "               \n",
       "                        [[-9.6054e-02,  1.4638e-02, -1.7490e-01],\n",
       "                         [-4.5224e-02, -5.9250e-02, -2.9963e-02],\n",
       "                         [-4.5139e-02, -3.3477e-02, -2.0746e-02]]]], device='cuda:0')),\n",
       "              ('conv_block6.conv2.weight',\n",
       "               tensor([[[[ 6.2378e-02,  1.8758e-02, -2.2512e-02],\n",
       "                         [-1.4354e-01, -2.2323e-01,  4.3051e-02],\n",
       "                         [-4.0613e-02, -1.2258e-02,  5.8613e-02]],\n",
       "               \n",
       "                        [[ 2.0403e-04, -1.0632e-02,  7.3799e-02],\n",
       "                         [-5.4414e-03, -1.2146e-02, -6.2924e-02],\n",
       "                         [-2.5301e-03,  2.8377e-02, -6.2418e-03]],\n",
       "               \n",
       "                        [[-1.4727e-02,  1.4253e-02, -2.5533e-02],\n",
       "                         [-1.6638e-02,  1.0506e-02,  1.1061e-02],\n",
       "                         [-5.8143e-03,  1.8455e-01,  1.2023e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.0070e-02, -6.1114e-03, -5.9798e-03],\n",
       "                         [-9.1783e-03, -3.2180e-02, -1.9256e-02],\n",
       "                         [-1.3183e-02,  7.6920e-03, -6.1538e-03]],\n",
       "               \n",
       "                        [[-1.1998e-02, -5.9682e-02, -2.7001e-02],\n",
       "                         [-7.2286e-02, -1.4301e-01, -1.7862e-01],\n",
       "                         [-7.0753e-02, -7.0473e-02, -4.7264e-02]],\n",
       "               \n",
       "                        [[-5.7885e-03, -1.1765e-02, -9.2426e-03],\n",
       "                         [-3.1164e-03,  5.5812e-03,  4.1889e-02],\n",
       "                         [-1.3666e-02, -1.5337e-02,  2.1118e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0649e-02,  4.6067e-04,  2.8205e-02],\n",
       "                         [ 2.2678e-01, -3.3703e-02,  4.4724e-02],\n",
       "                         [ 1.7583e-01,  6.2330e-03, -2.7550e-02]],\n",
       "               \n",
       "                        [[ 5.3437e-02,  2.7666e-02, -1.9205e-01],\n",
       "                         [-3.0071e-03, -4.8969e-03, -7.4914e-02],\n",
       "                         [-2.6477e-02, -1.4997e-02,  1.0693e-02]],\n",
       "               \n",
       "                        [[ 3.3328e-03,  8.9059e-03,  1.6313e-02],\n",
       "                         [-2.5810e-01,  3.1949e-02,  5.3238e-02],\n",
       "                         [-1.8774e-01,  1.4315e-02, -6.9758e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.2893e-02,  1.5120e-01,  6.0878e-03],\n",
       "                         [ 5.2519e-02, -6.9227e-03, -1.7821e-02],\n",
       "                         [ 5.4344e-02, -2.3619e-02,  9.1962e-04]],\n",
       "               \n",
       "                        [[-4.8327e-02, -3.8301e-02, -1.2528e-01],\n",
       "                         [-6.0159e-03, -7.3667e-03, -4.0289e-02],\n",
       "                         [-2.0429e-02, -1.8000e-02, -5.0362e-02]],\n",
       "               \n",
       "                        [[ 4.2498e-02, -3.4162e-03,  5.7056e-01],\n",
       "                         [ 2.2785e-02,  1.4886e-02,  5.8760e-01],\n",
       "                         [ 2.1621e-02,  3.6195e-02,  2.1404e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.0071e-02, -2.3483e-02,  1.5503e-01],\n",
       "                         [-4.1347e-02, -8.4909e-02,  5.9295e-02],\n",
       "                         [ 8.6283e-03, -6.8355e-02,  2.1727e-02]],\n",
       "               \n",
       "                        [[-2.1453e-02,  3.3065e-03,  1.5108e-02],\n",
       "                         [-2.1748e-02,  8.8089e-02, -2.2444e-02],\n",
       "                         [-2.6951e-02,  4.1091e-02,  2.1364e-02]],\n",
       "               \n",
       "                        [[ 3.3134e-03, -1.3460e-01, -2.0617e-01],\n",
       "                         [-4.0294e-02, -1.3882e-02, -1.3049e-01],\n",
       "                         [-7.7549e-02, -8.9640e-02, -9.0979e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 2.7877e-01,  6.0229e-02, -3.5421e-02],\n",
       "                         [ 2.1354e-01,  5.0316e-02,  1.2692e-02],\n",
       "                         [ 7.3465e-02,  9.6028e-02,  6.4655e-02]],\n",
       "               \n",
       "                        [[-4.5907e-02, -5.7231e-02,  1.5356e-01],\n",
       "                         [-1.7944e-01, -7.5590e-02,  1.2512e-01],\n",
       "                         [-5.3724e-03, -1.1310e-01,  1.2122e-01]],\n",
       "               \n",
       "                        [[ 1.2149e-03,  5.5371e-02,  7.2490e-02],\n",
       "                         [-1.4439e-02, -3.3266e-03,  1.3038e-02],\n",
       "                         [-1.3167e-02, -2.4417e-03, -3.7956e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-3.2490e-02, -1.2473e-02, -2.1267e-02],\n",
       "                         [-1.5693e-01, -7.6336e-02, -2.5219e-02],\n",
       "                         [ 4.4903e-02, -3.2372e-02, -3.7985e-02]],\n",
       "               \n",
       "                        [[-2.6388e-02, -9.7179e-03, -8.7452e-02],\n",
       "                         [-1.9217e-01, -1.0060e-01, -8.7030e-02],\n",
       "                         [-1.1183e-02,  5.2038e-03, -3.2500e-02]],\n",
       "               \n",
       "                        [[-2.5966e-02, -2.2687e-02, -1.8817e-02],\n",
       "                         [ 3.0426e-02,  1.3242e-02,  1.4162e-01],\n",
       "                         [ 1.8603e-03, -9.9175e-03,  2.2542e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.0331e-02, -1.7675e-02, -1.1954e-02],\n",
       "                         [-7.9355e-02, -8.9027e-02, -3.1435e-02],\n",
       "                         [-1.5182e-01,  1.1379e-02, -5.0776e-03]],\n",
       "               \n",
       "                        [[ 2.5093e-01, -1.1889e-01,  4.0383e-02],\n",
       "                         [ 5.7763e-01, -5.9891e-02,  8.1490e-02],\n",
       "                         [ 5.6396e-02, -2.1181e-02,  2.0845e-02]],\n",
       "               \n",
       "                        [[-2.0619e-02, -1.6648e-01, -7.7556e-02],\n",
       "                         [-7.1754e-02, -1.5399e-01, -4.1835e-01],\n",
       "                         [-2.0748e-02, -3.0312e-02,  2.9256e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0504e-01, -1.7495e-03,  6.1624e-02],\n",
       "                         [-1.2714e-01, -3.9878e-02,  2.3823e-02],\n",
       "                         [ 7.2240e-02, -3.5144e-02,  1.5306e-01]],\n",
       "               \n",
       "                        [[-1.9953e-02, -7.5750e-03,  9.7932e-03],\n",
       "                         [-2.7858e-02, -4.2192e-03, -1.2368e-02],\n",
       "                         [-1.9979e-02,  4.9069e-03,  8.6792e-02]],\n",
       "               \n",
       "                        [[ 3.7019e-02,  8.5581e-02,  8.8406e-02],\n",
       "                         [-3.4315e-02, -2.3413e-02, -2.0229e-02],\n",
       "                         [-1.7261e-02, -1.4989e-01,  7.9314e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.5366e-03, -4.7272e-03,  9.9217e-03],\n",
       "                         [ 3.5222e-02, -7.6757e-02, -1.4232e-02],\n",
       "                         [ 6.4430e-02, -7.2829e-02,  1.2333e-02]],\n",
       "               \n",
       "                        [[-2.5764e-02,  1.7931e-02, -3.5332e-02],\n",
       "                         [-3.2196e-02, -3.2662e-02, -1.3743e-01],\n",
       "                         [-1.4265e-01, -3.8172e-02, -2.4118e-01]],\n",
       "               \n",
       "                        [[-1.0370e-02,  2.0496e-02, -9.6309e-02],\n",
       "                         [ 1.7074e-03,  2.8337e-02,  7.9267e-02],\n",
       "                         [-1.0506e-02, -1.5525e-02,  4.3832e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.5096e-02, -4.2592e-02,  6.3018e-03],\n",
       "                         [-4.3436e-02,  5.7229e-02, -8.5072e-03],\n",
       "                         [ 5.2415e-02,  1.7740e-01,  5.0273e-03]],\n",
       "               \n",
       "                        [[-2.0337e-01, -2.2240e-03, -5.0168e-02],\n",
       "                         [-2.3016e-03, -2.9411e-02, -1.6485e-02],\n",
       "                         [-2.0835e-02, -4.2425e-02, -1.4463e-01]],\n",
       "               \n",
       "                        [[ 2.0884e-02, -3.4521e-02, -4.7142e-01],\n",
       "                         [ 2.9250e-02, -2.4125e-02, -7.5823e-02],\n",
       "                         [ 6.6010e-02,  4.9845e-02, -7.7228e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.3496e-03,  1.8332e-02,  1.4721e-02],\n",
       "                         [ 4.7489e-02, -8.4716e-03, -1.1506e-02],\n",
       "                         [ 2.4723e-02,  7.7044e-03,  9.9024e-03]],\n",
       "               \n",
       "                        [[-1.5488e-01, -7.3238e-02, -1.3500e-02],\n",
       "                         [-8.4583e-02, -2.2742e-01, -6.1626e-02],\n",
       "                         [-4.9571e-02, -6.7549e-02, -8.7529e-02]],\n",
       "               \n",
       "                        [[-8.7840e-03, -4.5914e-02, -2.6383e-02],\n",
       "                         [-8.6369e-03, -1.8113e-02, -5.5146e-02],\n",
       "                         [-8.8909e-03, -1.7645e-02, -1.1369e-01]]]], device='cuda:0')),\n",
       "              ('conv_block6.bn1.weight',\n",
       "               tensor([0.8026, 0.6781, 1.0348,  ..., 0.8370, 1.3061, 0.9036], device='cuda:0')),\n",
       "              ('conv_block6.bn1.bias',\n",
       "               tensor([-0.4069, -0.4264, -0.9135,  ..., -0.7269, -1.2944, -0.5085],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block6.bn1.running_mean',\n",
       "               tensor([-7.4349, -1.0577, -6.7876,  ..., -3.3957, -5.8083, -3.1970],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block6.bn1.running_var',\n",
       "               tensor([28.6562,  6.5089, 19.9695,  ...,  5.7933, 21.3165,  7.4073],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block6.bn1.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('conv_block6.bn2.weight',\n",
       "               tensor([0.8234, 0.9212, 0.9373,  ..., 1.0178, 1.1215, 0.8380], device='cuda:0')),\n",
       "              ('conv_block6.bn2.bias',\n",
       "               tensor([-0.2892, -0.3146, -0.3084,  ..., -0.3623, -0.3918, -0.2973],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block6.bn2.running_mean',\n",
       "               tensor([-23.5747, -20.3367, -20.9109,  ..., -25.5469, -22.4999, -23.3265],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block6.bn2.running_var',\n",
       "               tensor([2554.6399, 2603.9236, 3080.2637,  ..., 4098.6372, 3663.4102,\n",
       "                       2992.8418], device='cuda:0')),\n",
       "              ('conv_block6.bn2.num_batches_tracked',\n",
       "               tensor(660000, device='cuda:0')),\n",
       "              ('fc1.weight',\n",
       "               tensor([[-0.0166,  0.0072,  0.0075,  ...,  0.0294, -0.0072,  0.0291],\n",
       "                       [-0.0481, -0.1074,  0.0131,  ...,  0.0525,  0.0444, -0.0384],\n",
       "                       [-0.0254,  0.0033, -0.0411,  ...,  0.0068,  0.0132, -0.0258],\n",
       "                       ...,\n",
       "                       [ 0.0137, -0.0280, -0.0154,  ..., -0.0432,  0.0138,  0.0302],\n",
       "                       [-0.0497, -0.1598,  0.0419,  ...,  0.0793,  0.0229,  0.0504],\n",
       "                       [ 0.0136, -0.0421,  0.0012,  ..., -0.0030, -0.0055, -0.0378]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc1.bias',\n",
       "               tensor([-0.0132,  0.3372, -0.0043,  ...,  0.1521,  0.5909, -0.0059],\n",
       "                      device='cuda:0')),\n",
       "              ('fc_audioset.weight',\n",
       "               tensor([[ 0.0044, -0.2994,  0.0006,  ...,  0.0473,  0.0231,  0.0286],\n",
       "                       [-0.0541, -0.0041,  0.0214,  ..., -0.0071,  0.1176, -0.0266],\n",
       "                       [ 0.0326,  0.0989,  0.0170,  ...,  0.0337,  0.0723,  0.0134],\n",
       "                       ...,\n",
       "                       [-0.0409, -0.0946, -0.0224,  ...,  0.0416,  0.0435,  0.0137],\n",
       "                       [-0.0237, -0.0271,  0.0390,  ...,  0.0784,  0.0064, -0.0015],\n",
       "                       [ 0.0410, -0.0290, -0.0081,  ...,  0.0040,  0.1143, -0.0410]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc_audioset.bias',\n",
       "               tensor([ 0.0490, -0.4742, -0.3735, -0.6907, -0.4029, -0.4597, -0.3774, -0.3368,\n",
       "                       -0.4221, -0.4252, -0.4350, -0.3061, -0.5172, -0.3934, -0.2794, -0.3573,\n",
       "                       -0.6604, -0.3010, -0.2746, -0.3826, -0.2164, -0.3721, -0.3065, -0.3931,\n",
       "                       -0.4410, -0.3120, -0.3148, -0.6283, -0.4895, -0.3656, -0.2804, -0.3472,\n",
       "                       -0.3853, -0.2600, -0.3052, -0.2642, -0.2148, -0.2326, -0.3406, -0.1649,\n",
       "                       -0.3591, -0.3355, -0.6377, -0.4048, -0.3889, -0.2888, -0.5866, -0.3522,\n",
       "                       -0.2783, -0.3024, -0.5947, -0.1936, -0.2043, -0.2267, -0.3836, -0.2372,\n",
       "                       -0.1794, -0.2558, -0.1788, -0.2693, -0.2231, -0.2427, -0.2165, -0.3690,\n",
       "                       -0.5058, -0.5287, -0.4212, -0.2765, -0.2024, -0.5295, -0.3384, -0.1470,\n",
       "                       -0.5296, -0.4859, -0.4454, -0.3206, -0.4291, -0.2077, -0.5047, -0.4262,\n",
       "                       -0.5712, -0.5893, -0.4219, -0.3362, -0.2958, -0.4477, -0.6120, -0.4930,\n",
       "                       -0.4861, -0.2274, -0.2580, -0.4849, -0.2946, -0.3436, -0.3462, -0.2300,\n",
       "                       -0.2178, -0.3074, -0.4224, -0.5244, -0.5430, -0.2941, -0.4655, -0.4833,\n",
       "                       -0.5003, -0.4099, -0.2725, -0.4846, -0.2880, -0.4082, -0.2577, -0.4892,\n",
       "                       -0.4830, -0.3751, -0.2316, -0.4105, -0.4284, -0.4538, -0.3043, -0.3296,\n",
       "                       -0.2111, -0.2125, -0.5254, -0.2376, -0.2828, -0.5404, -0.6088, -0.3434,\n",
       "                       -0.2487, -0.4375, -0.2218, -0.5718, -0.4881, -0.4573, -0.4010, -0.3027,\n",
       "                       -0.1976,  0.1975, -0.5603, -0.4253, -0.3970, -0.5028, -0.3764, -0.4115,\n",
       "                       -0.2813, -0.2206, -0.4149, -0.3066, -0.3521, -0.4462, -0.3480, -0.2202,\n",
       "                       -0.3966, -0.4818, -0.4947, -0.2719, -0.2546, -0.4707, -0.4370, -0.3083,\n",
       "                       -0.4753, -0.4005, -0.3160, -0.2089, -0.3411, -0.2015, -0.2293, -0.2349,\n",
       "                       -0.3511, -0.3267, -0.4168, -0.4500, -0.5291, -0.2814, -0.2713, -0.2416,\n",
       "                       -0.2832, -0.2195, -0.3027, -0.3605, -0.3715, -0.3043, -0.3254, -0.3563,\n",
       "                       -0.5964, -0.3533, -0.5389, -0.4177, -0.3632, -0.5409, -0.4722, -0.4955,\n",
       "                       -0.5164, -0.3215, -0.3467, -0.4998, -0.2067, -0.3317, -0.3735, -0.3884,\n",
       "                       -0.3633, -0.2334, -0.4176, -0.1806, -0.3323, -0.3307, -0.4927, -0.2446,\n",
       "                       -0.2858, -0.2186, -0.2589, -0.3833, -0.1774, -0.1645, -0.3042, -0.1363,\n",
       "                       -0.3616, -0.4121, -0.1217, -0.6755, -0.3700, -0.3517, -0.3655, -0.3352,\n",
       "                       -0.5213, -0.4534, -0.3515, -0.4062, -0.2800, -0.4507, -0.4318, -0.4715,\n",
       "                       -0.7282, -0.5289, -0.3077, -0.7215, -0.4480, -0.5495, -0.2373, -0.4435,\n",
       "                       -0.4319, -0.3877, -0.3380, -0.3224, -0.2572, -0.2884, -0.3361, -0.3315,\n",
       "                       -0.3163, -0.3719, -0.2915, -0.7739, -0.4007, -0.3652, -0.4296, -0.3826,\n",
       "                       -0.2942, -0.3744, -0.4048, -0.3718, -0.4526, -0.4013, -0.2667, -0.3044,\n",
       "                       -0.5583, -0.3825, -0.8427, -0.3741, -0.3112, -0.3968, -0.4018, -0.6201,\n",
       "                       -0.2922, -0.6323, -0.4479, -0.2809, -0.4232, -0.3513, -0.4560, -0.3471,\n",
       "                       -0.3721, -0.2498, -0.1522, -0.5420, -0.3724, -0.4525, -0.3327, -0.4301,\n",
       "                       -0.4636, -0.4975, -0.2787, -0.4511, -0.4525, -0.3333, -0.4791, -0.5981,\n",
       "                       -0.2043, -0.6982, -0.3077, -0.3909, -0.2497, -0.4465, -0.5105, -0.3445,\n",
       "                       -0.3286, -0.4684, -0.6847, -0.4114, -0.3233, -0.3417, -0.2901, -0.2095,\n",
       "                       -0.3186, -0.2482, -0.3850, -0.2653, -0.7123, -0.4970, -0.1784, -0.2805,\n",
       "                       -0.2580, -0.2694, -0.3508, -0.3299, -0.2736, -0.3310, -0.3621, -0.2693,\n",
       "                       -0.3725, -0.3862, -0.3392, -0.3086, -0.4130, -0.4802, -0.5485, -0.4046,\n",
       "                       -0.3729, -0.2756, -0.3795, -0.3059, -0.3606, -0.3680, -0.2266, -0.5580,\n",
       "                       -0.3050, -0.3541, -0.2742, -0.2735, -0.5805, -0.3973, -0.2648, -0.3379,\n",
       "                       -0.5076, -0.4157, -0.4335, -0.1580, -0.5195, -0.3638, -0.3570, -0.3332,\n",
       "                       -0.2631, -0.3196, -0.3385, -0.2788, -0.3844, -0.3170, -0.2524, -0.3649,\n",
       "                       -0.2769, -0.1179, -0.3307, -0.3471, -0.5100, -0.3737, -0.2021, -0.4875,\n",
       "                       -0.2752, -0.2087, -0.3974, -0.3068, -0.2987, -0.5006, -0.2429, -0.3857,\n",
       "                       -0.5652, -0.2954, -0.3305, -0.2493, -0.3636, -0.3115, -0.3327, -0.4280,\n",
       "                       -0.4263, -0.2802, -0.4102, -0.2778, -0.3690, -0.2716, -0.2406, -0.4240,\n",
       "                       -0.4413, -0.1933, -0.2901, -0.2006, -0.6819, -0.5876, -0.2750, -0.5770,\n",
       "                       -0.3808, -0.6028, -0.4044, -0.3090, -0.2166, -0.4117, -0.3015, -0.4468,\n",
       "                       -0.5581, -0.3947, -0.4057, -0.2782, -0.2627, -0.2539, -0.2743, -0.2735,\n",
       "                       -0.2182, -0.1746, -0.3594, -0.3030, -0.2451, -0.4575, -0.2318, -0.2329,\n",
       "                       -0.3549, -0.1614, -0.3326, -0.3498, -0.2502, -0.5221, -0.3613, -0.3458,\n",
       "                       -0.2795, -0.6149, -0.3373, -0.1736, -0.3654, -0.4497, -0.3450, -0.4327,\n",
       "                       -0.2969, -0.2111, -0.5714, -0.2825, -0.2777, -0.2634, -0.5885, -0.3807,\n",
       "                       -0.4891, -0.2753, -0.3897, -0.3300, -0.2394, -0.1569, -0.3122, -0.4385,\n",
       "                       -0.2749, -0.3218, -0.5472, -0.2773, -0.3979, -0.2417, -0.2110, -0.3099,\n",
       "                       -0.4180, -0.4228, -0.2240, -0.2487, -0.3731, -0.6175, -0.2644, -0.4343,\n",
       "                       -0.4394, -0.1845, -0.3115, -0.3485, -0.5963, -0.3170, -0.3890, -0.4772,\n",
       "                       -0.2634, -0.4906, -0.3343, -0.2447, -0.3440, -0.2463, -0.3028, -0.3201,\n",
       "                       -0.4343, -0.2631, -0.1983, -0.2361, -0.4339, -0.4312, -0.3790, -0.3563,\n",
       "                       -0.7031, -0.5352, -0.8727, -0.9086, -0.4023, -0.7341, -0.8891, -0.6499,\n",
       "                       -0.4007, -0.2704, -0.2699, -0.2607, -0.4189, -0.3180, -0.2652, -0.2379,\n",
       "                       -0.4172, -0.2898, -0.3019, -0.4014, -0.3223, -0.1735, -0.3010],\n",
       "                      device='cuda:0'))])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395bf03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d623f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ac503e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting config\n",
      "  Downloading config-0.5.0.post0-py2.py3-none-any.whl (20 kB)\n",
      "Installing collected packages: config\n",
      "Successfully installed config-0.5.0.post0\n"
     ]
    }
   ],
   "source": [
    "!pip install config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d41dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../utils'))\n",
    "import numpy as np\n",
    "import argparse\n",
    "import h5py\n",
    "import math\n",
    "import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark=True\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    " \n",
    "#rom utilities import get_filename\n",
    "from models import *\n",
    "import config\n",
    "\n",
    "classes_num=300\n",
    "\n",
    "class Transfer_Cnn14(nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n",
    "        fmax, classes_num, freeze_base):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_Cnn14, self).__init__()\n",
    "        audioset_classes_num = 527\n",
    "        \n",
    "        self.base = Cnn14(sample_rate, window_size, hop_size, mel_bins, fmin, \n",
    "            fmax, audioset_classes_num)\n",
    "\n",
    "        # Transfer to another task layer\n",
    "        self.fc_transfer = nn.Linear(2048, classes_num, bias=True)\n",
    "\n",
    "        if freeze_base:\n",
    "            # Freeze AudioSet pretrained layers\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.fc_transfer)\n",
    "\n",
    "    def load_from_pretrain(self, pretrained_checkpoint_path):\n",
    "        checkpoint = torch.load(pretrained_checkpoint_path)\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        output_dict = self.base(input, mixup_lambda)\n",
    "        embedding = output_dict['embedding']\n",
    "\n",
    "        clipwise_output =  torch.log_softmax(self.fc_transfer(embedding), dim=-1)\n",
    "        output_dict['clipwise_output'] = clipwise_output\n",
    " \n",
    "        return output_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d557ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1516a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting utilities-package\n",
      "  Downloading utilities-package-0.0.8.tar.gz (28 kB)\n",
      "Requirement already satisfied: scipy in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (1.4.1)\n",
      "Requirement already satisfied: setuptools in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (52.0.0.post20210125)\n",
      "Requirement already satisfied: six in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (1.15.0)\n",
      "Collecting bash\n",
      "  Downloading bash-0.6.tar.gz (2.8 kB)\n",
      "Collecting configparser\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting uritools\n",
      "  Downloading uritools-3.0.2-py3-none-any.whl (12 kB)\n",
      "Collecting simplejson\n",
      "  Downloading simplejson-3.17.2-cp37-cp37m-manylinux2010_x86_64.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tailer\n",
      "  Downloading tailer-0.4.1.tar.gz (7.5 kB)\n",
      "Requirement already satisfied: pytz in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (2021.1)\n",
      "Requirement already satisfied: termcolor in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (1.1.0)\n",
      "Requirement already satisfied: texttable in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (1.6.3)\n",
      "Collecting schedule\n",
      "  Downloading schedule-1.1.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: python-dateutil in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (2.8.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (4.9.3)\n",
      "Collecting cssutils\n",
      "  Downloading cssutils-2.2.0-py3-none-any.whl (405 kB)\n",
      "\u001b[K     |████████████████████████████████| 405 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting base58\n",
      "  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\n",
      "Collecting bcrypt\n",
      "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 180 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (3.7.4)\n",
      "Requirement already satisfied: requests in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (2.22.0)\n",
      "Requirement already satisfied: tornado in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (6.1)\n",
      "Collecting cherrypy\n",
      "  Downloading CherryPy-18.6.0-py2.py3-none-any.whl (419 kB)\n",
      "\u001b[K     |████████████████████████████████| 419 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bottle\n",
      "  Downloading bottle-0.12.19-py3-none-any.whl (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 780 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: flask in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (1.1.2)\n",
      "Requirement already satisfied: click in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (7.1.2)\n",
      "Requirement already satisfied: Jinja2 in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (2.11.3)\n",
      "Requirement already satisfied: coverage in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (5.5)\n",
      "Collecting pycontracts\n",
      "  Downloading PyContracts-1.8.12.tar.gz (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytest in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (5.3.5)\n",
      "Requirement already satisfied: pytest-cov in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (2.11.1)\n",
      "Collecting pytest-mock\n",
      "  Downloading pytest_mock-3.6.1-py3-none-any.whl (12 kB)\n",
      "Collecting pytest-click\n",
      "  Downloading pytest_click-1.0.2-py3-none-any.whl (4.0 kB)\n",
      "Collecting pytest-pylint\n",
      "  Downloading pytest_pylint-0.18.0-py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: black in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (19.10b0)\n",
      "Requirement already satisfied: flake8 in /home/hj20/anaconda3/lib/python3.7/site-packages (from utilities-package) (3.9.0)\n",
      "Collecting radon\n",
      "  Downloading radon-4.5.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 36 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cli-passthrough\n",
      "  Downloading CLI_passthrough-0.1.3-py2.py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /home/hj20/anaconda3/lib/python3.7/site-packages (from aiohttp->utilities-package) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /home/hj20/anaconda3/lib/python3.7/site-packages (from aiohttp->utilities-package) (3.7.4.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/hj20/anaconda3/lib/python3.7/site-packages (from aiohttp->utilities-package) (5.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/hj20/anaconda3/lib/python3.7/site-packages (from aiohttp->utilities-package) (20.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/hj20/anaconda3/lib/python3.7/site-packages (from aiohttp->utilities-package) (1.5.1)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /home/hj20/anaconda3/lib/python3.7/site-packages (from aiohttp->utilities-package) (3.0.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/hj20/anaconda3/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->utilities-package) (2.8)\n",
      "Requirement already satisfied: cffi>=1.1 in /home/hj20/anaconda3/lib/python3.7/site-packages (from bcrypt->utilities-package) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/hj20/anaconda3/lib/python3.7/site-packages (from cffi>=1.1->bcrypt->utilities-package) (2.20)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/hj20/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->utilities-package) (2.2.1)\n",
      "Requirement already satisfied: typed-ast>=1.4.0 in /home/hj20/anaconda3/lib/python3.7/site-packages (from black->utilities-package) (1.4.2)\n",
      "Requirement already satisfied: toml>=0.9.4 in /home/hj20/anaconda3/lib/python3.7/site-packages (from black->utilities-package) (0.10.2)\n",
      "Requirement already satisfied: regex in /home/hj20/anaconda3/lib/python3.7/site-packages (from black->utilities-package) (2021.4.4)\n",
      "Requirement already satisfied: appdirs in /home/hj20/anaconda3/lib/python3.7/site-packages (from black->utilities-package) (1.4.4)\n",
      "Requirement already satisfied: pathspec<1,>=0.6 in /home/hj20/anaconda3/lib/python3.7/site-packages (from black->utilities-package) (0.7.0)\n",
      "Collecting zc.lockfile\n",
      "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting portend>=2.1.1\n",
      "  Downloading portend-2.7.1-py3-none-any.whl (5.3 kB)\n",
      "Collecting cheroot>=8.2.1\n",
      "  Downloading cheroot-8.5.2-py2.py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 744 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: more-itertools in /home/hj20/anaconda3/lib/python3.7/site-packages (from cherrypy->utilities-package) (8.7.0)\n",
      "Collecting jaraco.collections\n",
      "  Downloading jaraco.collections-3.3.0-py3-none-any.whl (9.9 kB)\n",
      "Collecting jaraco.functools\n",
      "  Downloading jaraco.functools-3.3.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting tempora>=1.8\n",
      "  Downloading tempora-4.0.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/hj20/anaconda3/lib/python3.7/site-packages (from cssutils->utilities-package) (3.10.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /home/hj20/anaconda3/lib/python3.7/site-packages (from flake8->utilities-package) (0.6.1)\n",
      "Collecting pyflakes<2.4.0,>=2.3.0\n",
      "  Downloading pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 758 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycodestyle<2.8.0,>=2.7.0\n",
      "  Downloading pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 57 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: itsdangerous>=0.24 in /home/hj20/anaconda3/lib/python3.7/site-packages (from flask->utilities-package) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /home/hj20/anaconda3/lib/python3.7/site-packages (from flask->utilities-package) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/hj20/anaconda3/lib/python3.7/site-packages (from Jinja2->utilities-package) (1.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /home/hj20/anaconda3/lib/python3.7/site-packages (from importlib-metadata->cssutils->utilities-package) (3.4.1)\n",
      "Collecting jaraco.classes\n",
      "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting jaraco.text\n",
      "  Downloading jaraco.text-3.5.0-py3-none-any.whl (8.1 kB)\n",
      "Requirement already satisfied: pyparsing in /home/hj20/anaconda3/lib/python3.7/site-packages (from pycontracts->utilities-package) (2.4.7)\n",
      "Requirement already satisfied: decorator in /home/hj20/anaconda3/lib/python3.7/site-packages (from pycontracts->utilities-package) (4.4.2)\n",
      "Requirement already satisfied: future in /home/hj20/anaconda3/lib/python3.7/site-packages (from pycontracts->utilities-package) (0.18.2)\n",
      "Requirement already satisfied: py>=1.5.0 in /home/hj20/anaconda3/lib/python3.7/site-packages (from pytest->utilities-package) (1.10.0)\n",
      "Requirement already satisfied: packaging in /home/hj20/anaconda3/lib/python3.7/site-packages (from pytest->utilities-package) (20.1)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /home/hj20/anaconda3/lib/python3.7/site-packages (from pytest->utilities-package) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in /home/hj20/anaconda3/lib/python3.7/site-packages (from pytest->utilities-package) (0.2.5)\n",
      "Collecting pytest\n",
      "  Downloading pytest-6.2.4-py3-none-any.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pylint>=2.3.0 in /home/hj20/anaconda3/lib/python3.7/site-packages (from pytest-pylint->utilities-package) (2.4.4)\n",
      "Requirement already satisfied: astroid<2.4,>=2.3.0 in /home/hj20/anaconda3/lib/python3.7/site-packages (from pylint>=2.3.0->pytest-pylint->utilities-package) (2.3.3)\n",
      "Requirement already satisfied: isort<5,>=4.2.5 in /home/hj20/anaconda3/lib/python3.7/site-packages (from pylint>=2.3.0->pytest-pylint->utilities-package) (4.3.21)\n",
      "Collecting lazy-object-proxy==1.4.*\n",
      "  Downloading lazy_object_proxy-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 559 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt==1.11.*\n",
      "  Downloading wrapt-1.11.2.tar.gz (27 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting mando<0.7,>=0.6\n",
      "  Downloading mando-0.6.4-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: colorama>=0.4.1 in /home/hj20/anaconda3/lib/python3.7/site-packages (from radon->utilities-package) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hj20/anaconda3/lib/python3.7/site-packages (from requests->utilities-package) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/hj20/anaconda3/lib/python3.7/site-packages (from requests->utilities-package) (1.25.8)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/hj20/anaconda3/lib/python3.7/site-packages (from scipy->utilities-package) (1.19.5)\n",
      "Building wheels for collected packages: utilities-package, bash, pycontracts, wrapt, tailer\n",
      "  Building wheel for utilities-package (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for utilities-package: filename=utilities_package-0.0.8-py3-none-any.whl size=38424 sha256=2a0bdc04e35bbe68fb3c822c4ae536779fc4abf09f03f5990a39b60df5fe9d46\n",
      "  Stored in directory: /home/hj20/.cache/pip/wheels/db/c9/ec/c1bd617fa13dc781120945ec12c68e3f6d36dbf3652f588de1\n",
      "  Building wheel for bash (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bash: filename=bash-0.6-py3-none-any.whl size=3000 sha256=59c9da497c977f6472dcd8bf679cb25536790127dd56176f75aab3db3d260d92\n",
      "  Stored in directory: /home/hj20/.cache/pip/wheels/ba/50/5c/cf776045ee6baa7d0afff83c93c53ded8185fae2e4da006117\n",
      "  Building wheel for pycontracts (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycontracts: filename=PyContracts-1.8.12-py3-none-any.whl size=89638 sha256=5d8ae4ea80bb4af0579fa40d85c1a46cb60f576327af47acba1d93c8c13782f9\n",
      "  Stored in directory: /home/hj20/.cache/pip/wheels/98/f8/7c/350d5f1ca70fe678b88d854f5077bdf28196dd6dafd121c19c\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.11.2-cp37-cp37m-linux_x86_64.whl size=70765 sha256=5b783acb03321e6b3c98fb026df66817e0fb5b7502d60fffd85b7ada89d336ec\n",
      "  Stored in directory: /home/hj20/.cache/pip/wheels/23/5f/62/304b411f20be41821465a82bc98baabc5e68c3cdd1eb99db71\n",
      "  Building wheel for tailer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tailer: filename=tailer-0.4.1-py3-none-any.whl size=5399 sha256=10dccadeb446760fa82fd7e2ec95b912e48e5b7e25e7a53719435967cd0a25c8\n",
      "  Stored in directory: /home/hj20/.cache/pip/wheels/48/d5/2f/7e3ee58a2d87b52abe8eceb63c17c6d9fa0b792b0432aa2a1b\n",
      "Successfully built utilities-package bash pycontracts wrapt tailer\n",
      "Installing collected packages: wrapt, lazy-object-proxy, jaraco.functools, tempora, jaraco.text, jaraco.classes, iniconfig, zc.lockfile, pytest, pyflakes, pycodestyle, portend, mando, jaraco.collections, cheroot, uritools, unidecode, tailer, simplejson, schedule, radon, pytest-pylint, pytest-mock, pytest-click, pycontracts, cssutils, configparser, cli-passthrough, cherrypy, bottle, bcrypt, bash, base58, utilities-package\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.12.1\n",
      "    Uninstalling wrapt-1.12.1:\n",
      "      Successfully uninstalled wrapt-1.12.1\n",
      "  Attempting uninstall: lazy-object-proxy\n",
      "    Found existing installation: lazy-object-proxy 1.6.0\n",
      "    Uninstalling lazy-object-proxy-1.6.0:\n",
      "      Successfully uninstalled lazy-object-proxy-1.6.0\n",
      "  Attempting uninstall: pytest\n",
      "    Found existing installation: pytest 5.3.5\n",
      "    Uninstalling pytest-5.3.5:\n",
      "      Successfully uninstalled pytest-5.3.5\n",
      "  Attempting uninstall: pyflakes\n",
      "    Found existing installation: pyflakes 2.2.0\n",
      "    Uninstalling pyflakes-2.2.0:\n",
      "      Successfully uninstalled pyflakes-2.2.0\n",
      "  Attempting uninstall: pycodestyle\n",
      "    Found existing installation: pycodestyle 2.6.0\n",
      "    Uninstalling pycodestyle-2.6.0:\n",
      "      Successfully uninstalled pycodestyle-2.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.1 requires grpcio~=1.32.0, but you have grpcio 1.36.1 which is incompatible.\n",
      "tensorflow 2.4.1 requires wrapt~=1.12.1, but you have wrapt 1.11.2 which is incompatible.\u001b[0m\n",
      "Successfully installed base58-2.1.0 bash-0.6 bcrypt-3.2.0 bottle-0.12.19 cheroot-8.5.2 cherrypy-18.6.0 cli-passthrough-0.1.3 configparser-5.0.2 cssutils-2.2.0 iniconfig-1.1.1 jaraco.classes-3.2.1 jaraco.collections-3.3.0 jaraco.functools-3.3.0 jaraco.text-3.5.0 lazy-object-proxy-1.4.3 mando-0.6.4 portend-2.7.1 pycodestyle-2.7.0 pycontracts-1.8.12 pyflakes-2.3.1 pytest-6.2.4 pytest-click-1.0.2 pytest-mock-3.6.1 pytest-pylint-0.18.0 radon-4.5.1 schedule-1.1.0 simplejson-3.17.2 tailer-0.4.1 tempora-4.0.2 unidecode-1.2.0 uritools-3.0.2 utilities-package-0.0.8 wrapt-1.11.2 zc.lockfile-2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install utilities-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ce821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "\n",
    "    # Arugments & parameters\n",
    "    sample_rate = args.sample_rate\n",
    "    window_size = args.window_size\n",
    "    hop_size = args.hop_size\n",
    "    mel_bins = args.mel_bins\n",
    "    fmin = args.fmin\n",
    "    fmax = args.fmax\n",
    "    model_type = args.model_type\n",
    "    pretrained_checkpoint_path = args.pretrained_checkpoint_path\n",
    "    freeze_base = args.freeze_base\n",
    "    device = 'cuda' if (args.cuda and torch.cuda.is_available()) else 'cpu'\n",
    "\n",
    "    classes_num = config.classes_num\n",
    "    pretrain = True if pretrained_checkpoint_path else False\n",
    "    \n",
    "    # Model\n",
    "    Model = eval(model_type)\n",
    "    model = Model(sample_rate, window_size, hop_size, mel_bins, fmin, fmax, \n",
    "        classes_num, freeze_base)\n",
    "\n",
    "    # Load pretrained model\n",
    "    if pretrain:\n",
    "        logging.info('Load pretrained model from {}'.format(pretrained_checkpoint_path))\n",
    "        model.load_from_pretrain(pretrained_checkpoint_path)\n",
    "\n",
    "    # Parallel\n",
    "    print('GPU number: {}'.format(torch.cuda.device_count()))\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "    if 'cuda' in device:\n",
    "        model.to(device)\n",
    "\n",
    "    print('Load pretrained model successfully!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Example of parser. ')\n",
    "    subparsers = parser.add_subparsers(dest='mode')\n",
    "\n",
    "    # Train\n",
    "    parser_train = subparsers.add_parser('train')\n",
    "    parser_train.add_argument('--sample_rate', type=int, required=True)\n",
    "    parser_train.add_argument('--window_size', type=int, required=True)\n",
    "    parser_train.add_argument('--hop_size', type=int, required=True)\n",
    "    parser_train.add_argument('--mel_bins', type=int, required=True)\n",
    "    parser_train.add_argument('--fmin', type=int, required=True)\n",
    "    parser_train.add_argument('--fmax', type=int, required=True) \n",
    "    parser_train.add_argument('--model_type', type=str, required=True)\n",
    "    parser_train.add_argument('--pretrained_checkpoint_path', type=str)\n",
    "    parser_train.add_argument('--freeze_base', action='store_true', default=False)\n",
    "    parser_train.add_argument('--cuda', action='store_true', default=False)\n",
    "\n",
    "    # Parse arguments\n",
    "    args = parser.parse_args()\n",
    "    args.filename = get_filename(__file__)\n",
    "\n",
    "    if args.mode == 'train':\n",
    "        train(args)\n",
    "\n",
    "    else:\n",
    "        raise Exception('Error argument!')\n",
    "© 2021 GitHub, Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67794fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6f971e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fdeae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee17b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3133c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb860b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
