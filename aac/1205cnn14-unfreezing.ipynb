{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72c6aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\n",
      "       usage information.\n",
      "\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\n",
      "       usage information.\n",
      "\n",
      "Mon Feb 14 16:50:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 35%   33C    P8    21W / 260W |   6553MiB / 11016MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1483      G   /usr/lib/xorg/Xorg                 18MiB |\n",
      "|    0   N/A  N/A      2948      G   /usr/bin/gnome-shell               17MiB |\n",
      "|    0   N/A  N/A      7440      G   /usr/lib/xorg/Xorg                 36MiB |\n",
      "|    0   N/A  N/A      7578      G   /usr/bin/gnome-shell              152MiB |\n",
      "|    0   N/A  N/A      9051      C   ...hj20/anaconda3/bin/python     1637MiB |\n",
      "|    0   N/A  N/A      9339      C   ...hj20/anaconda3/bin/python     4057MiB |\n",
      "|    0   N/A  N/A     10718      G   /usr/lib/xorg/Xorg                170MiB |\n",
      "|    0   N/A  N/A     10859      G   /usr/bin/gnome-shell              167MiB |\n",
      "|    0   N/A  N/A     11307      G   ...AAAAAAAAA= --shared-files       50MiB |\n",
      "|    0   N/A  N/A     11402      G   ...AAAAAAAAA= --shared-files      169MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9446af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 29878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f52a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58059f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn14,Cnn10,init_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5214a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a900f95",
   "metadata": {},
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abbeed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transfer_Cnn14(nn.Module):\n",
    "    def __init__(self, freeze_base=True, pretrain_checkpoint=None):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_Cnn14, self).__init__()\n",
    "\n",
    "        audioset_classes_num = 527\n",
    "        self.base = Cnn14()\n",
    "\n",
    "        #self.init_weights()\n",
    "\n",
    "        if pretrain_checkpoint:\n",
    "            self.load_from_pretrain(pretrain_checkpoint)\n",
    "            \n",
    "        #self.base.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        # 안쓰이는이유는 multi-class clasification을 생략하기 때문,\n",
    "\n",
    "        if freeze_base:\n",
    "            # 2단계 freeze / 3단계 freeze X\n",
    "            # Freeze AudioSet pretrained layers\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    #def init_weights(self):\n",
    "        #init_layer(self.fc_transfer)\n",
    "\n",
    "    def load_from_pretrain(self, pretrained_checkpoint):\n",
    "        pretrained_checkpoint=\"/home/hj20/dcase_2020_T6/models/Cnn14_mAP=0.431.pth\"\n",
    "        checkpoint = torch.load(pretrained_checkpoint)\n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_imag.weight')#가중치 삭제  \n",
    "        checkpoint['model'].pop('spectrogram_extractor.stft.conv_real.weight')#가중치 삭제\n",
    "        checkpoint['model'].pop('logmel_extractor.melW')#가중치 삭제\n",
    "        #checkpoint['model'].pop('fc1.weight')\n",
    "        #checkpoint['model'].pop('fc1.bias')\n",
    "        #checkpoint['model'].pop('fc_audioset.weight')\n",
    "        #checkpoint['model'].pop('fc_audioset.bias')\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        output = self.base(input)\n",
    "\n",
    "        #embedding = output_dict['embedding']\n",
    "        #clipwise_output = output_dict['clipwise_output']\n",
    "\n",
    "        return output #, clipwise_output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6219f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_checkpoint='Cnn10_mAP=0.380.pth'\n",
    "checkpoint = torch.load(pretrained_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bd7f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_checkpoint=\"cnn_ti1_0.model\"\n",
    "checkpoint = torch.load(pretrained_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9313fb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bn0.weight',\n",
       "              tensor([0.9918, 0.9929, 1.0100, 1.0110, 1.0018, 0.9889], device='cuda:0')),\n",
       "             ('bn0.bias',\n",
       "              tensor([-0.0003, -0.0011,  0.0044, -0.0017, -0.0044,  0.0023], device='cuda:0')),\n",
       "             ('bn0.running_mean',\n",
       "              tensor([-12.5365, -16.0105, -34.8800, -40.6616, -43.3891, -48.1511],\n",
       "                     device='cuda:0')),\n",
       "             ('bn0.running_var',\n",
       "              tensor([394.9461, 349.7737, 346.6600, 280.5127, 244.0654, 275.8673],\n",
       "                     device='cuda:0')),\n",
       "             ('bn0.num_batches_tracked', tensor(345, device='cuda:0')),\n",
       "             ('conv_block1.conv1.weight',\n",
       "              tensor([[[[ 0.0394, -0.0694,  0.0662],\n",
       "                        [ 0.1061, -0.0163, -0.0123],\n",
       "                        [ 0.0470,  0.0099, -0.0317]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0842,  0.0520, -0.0255],\n",
       "                        [ 0.0864,  0.1011, -0.0036],\n",
       "                        [-0.0978,  0.0378,  0.0039]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0493,  0.0330,  0.0947],\n",
       "                        [-0.0680, -0.0133,  0.0756],\n",
       "                        [-0.0390, -0.0260,  0.0085]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0019,  0.0543,  0.0659],\n",
       "                        [ 0.0813,  0.0037, -0.0675],\n",
       "                        [ 0.0366, -0.0287, -0.0071]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0275, -0.0569, -0.0752],\n",
       "                        [ 0.0453,  0.0909,  0.0157],\n",
       "                        [-0.0055, -0.0529, -0.0358]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0805, -0.0296, -0.0549],\n",
       "                        [-0.0919,  0.0788, -0.0243],\n",
       "                        [ 0.0339, -0.0766,  0.0338]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0915,  0.0542, -0.0133],\n",
       "                        [-0.0264,  0.0243,  0.0334],\n",
       "                        [-0.0267,  0.0511,  0.0021]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0520,  0.0485,  0.0825],\n",
       "                        [ 0.0420,  0.0392,  0.0958],\n",
       "                        [-0.0900,  0.0756,  0.0094]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0802, -0.0299,  0.0421],\n",
       "                        [-0.0968,  0.0644,  0.0249],\n",
       "                        [-0.0768, -0.0525,  0.0307]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0961,  0.0832,  0.0419],\n",
       "                        [-0.0811, -0.0828,  0.0114],\n",
       "                        [ 0.0608,  0.0837,  0.0346]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0715,  0.0456,  0.0154],\n",
       "                        [-0.0277, -0.0424, -0.0591],\n",
       "                        [-0.0691,  0.0767,  0.0095]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0118,  0.0809, -0.0072],\n",
       "                        [-0.0869,  0.0416,  0.0213],\n",
       "                        [-0.0735,  0.0447, -0.0585]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0065, -0.0954, -0.0786],\n",
       "                        [ 0.0217, -0.0153, -0.0022],\n",
       "                        [-0.0229, -0.0748, -0.0263]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0247, -0.0529, -0.0829],\n",
       "                        [-0.0484, -0.1047, -0.0410],\n",
       "                        [ 0.0260, -0.0334, -0.0876]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0374, -0.0638, -0.0059],\n",
       "                        [-0.0155, -0.0374, -0.0532],\n",
       "                        [ 0.0124,  0.0291,  0.0838]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0506,  0.1014,  0.0808],\n",
       "                        [ 0.0573, -0.0317,  0.0487],\n",
       "                        [-0.0672,  0.0679, -0.0341]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0738,  0.0797,  0.0903],\n",
       "                        [-0.0677, -0.0508,  0.0221],\n",
       "                        [-0.0568, -0.0113,  0.0637]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0366,  0.0396,  0.0606],\n",
       "                        [-0.0417,  0.0288, -0.0615],\n",
       "                        [ 0.0961,  0.0151, -0.0215]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0544, -0.0442, -0.0361],\n",
       "                        [ 0.0151,  0.0510,  0.0355],\n",
       "                        [-0.0645,  0.0392, -0.0144]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0728,  0.0994, -0.0621],\n",
       "                        [ 0.0978,  0.0420,  0.0424],\n",
       "                        [ 0.0104, -0.0073,  0.0722]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0778, -0.0861,  0.0279],\n",
       "                        [ 0.0702,  0.0316,  0.0515],\n",
       "                        [-0.0264,  0.0783, -0.0617]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0570, -0.0381,  0.0145],\n",
       "                        [-0.0905,  0.0940,  0.0418],\n",
       "                        [-0.0573,  0.1048, -0.0538]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0842, -0.0617, -0.0319],\n",
       "                        [-0.0889, -0.0152,  0.0900],\n",
       "                        [-0.0436, -0.0956,  0.0449]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0658, -0.0005, -0.0291],\n",
       "                        [-0.1002, -0.0647,  0.0699],\n",
       "                        [ 0.0945,  0.0092,  0.0916]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0269, -0.0655,  0.0403],\n",
       "                        [-0.0928, -0.1068,  0.0096],\n",
       "                        [-0.0656, -0.0666,  0.0084]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0719,  0.0845, -0.0956],\n",
       "                        [ 0.0803, -0.0782,  0.0177],\n",
       "                        [-0.0412, -0.0200,  0.0194]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0909,  0.0420, -0.0875],\n",
       "                        [-0.0230, -0.0440, -0.0925],\n",
       "                        [ 0.0633,  0.0120,  0.0375]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0278,  0.0651,  0.0077],\n",
       "                        [-0.0066, -0.0345,  0.0349],\n",
       "                        [-0.0633,  0.0452, -0.0865]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0717,  0.0173, -0.0099],\n",
       "                        [-0.0170,  0.0360, -0.0506],\n",
       "                        [ 0.0613,  0.0971, -0.0399]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0158,  0.0859, -0.0058],\n",
       "                        [ 0.0652, -0.0767, -0.0251],\n",
       "                        [ 0.0564, -0.0455, -0.0796]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0192,  0.0655,  0.0117],\n",
       "                        [-0.0083,  0.0896,  0.0159],\n",
       "                        [-0.0859, -0.0664,  0.0484]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0104,  0.0013,  0.0293],\n",
       "                        [-0.0141,  0.0378, -0.0818],\n",
       "                        [ 0.0409, -0.0554, -0.0960]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0368, -0.0052, -0.0161],\n",
       "                        [ 0.0877,  0.0462, -0.0856],\n",
       "                        [ 0.0931, -0.0854, -0.0719]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0773,  0.0232,  0.0260],\n",
       "                        [ 0.0935,  0.0523, -0.0980],\n",
       "                        [-0.0384,  0.0381, -0.0445]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1021, -0.0387,  0.0960],\n",
       "                        [-0.0065,  0.0649,  0.0192],\n",
       "                        [ 0.0699, -0.0837, -0.0604]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0768, -0.0207, -0.0197],\n",
       "                        [ 0.0013, -0.0538,  0.0395],\n",
       "                        [-0.0804,  0.0681, -0.0582]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0773,  0.0246, -0.0738],\n",
       "                        [-0.0615, -0.0085,  0.0022],\n",
       "                        [-0.0647, -0.1063, -0.0708]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0547, -0.0831, -0.0601],\n",
       "                        [-0.0615, -0.0539,  0.0214],\n",
       "                        [ 0.0315, -0.0529, -0.0635]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0626,  0.0591,  0.0549],\n",
       "                        [ 0.0563,  0.0709, -0.0562],\n",
       "                        [-0.0804,  0.0501, -0.0984]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0279, -0.0360, -0.0276],\n",
       "                        [-0.0033, -0.0593,  0.0608],\n",
       "                        [-0.0722,  0.0403,  0.0304]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0482, -0.0939,  0.0488],\n",
       "                        [-0.0101, -0.0654,  0.0296],\n",
       "                        [-0.0869,  0.0596, -0.0516]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0653,  0.0431,  0.0229],\n",
       "                        [ 0.0898,  0.0711, -0.0430],\n",
       "                        [ 0.0060, -0.0182,  0.0755]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0299, -0.0328, -0.0787],\n",
       "                        [ 0.0863, -0.0807,  0.0257],\n",
       "                        [-0.0980, -0.0901,  0.0374]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0334,  0.0316, -0.0500],\n",
       "                        [-0.0370,  0.0078,  0.1006],\n",
       "                        [-0.0736, -0.0206,  0.0055]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0724,  0.0339, -0.1026],\n",
       "                        [ 0.0035,  0.0794,  0.0621],\n",
       "                        [-0.0582,  0.0107, -0.0806]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0431,  0.0238],\n",
       "                        [-0.0695,  0.0664,  0.0172],\n",
       "                        [-0.0706,  0.0017,  0.0890]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0221,  0.0895,  0.0834],\n",
       "                        [ 0.0321,  0.0972,  0.0923],\n",
       "                        [-0.0052, -0.0720,  0.0626]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0947,  0.0997,  0.0834],\n",
       "                        [-0.0585, -0.0263,  0.0413],\n",
       "                        [-0.0690,  0.0320, -0.0274]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0500,  0.0163,  0.0369],\n",
       "                        [-0.0980, -0.0619, -0.0788],\n",
       "                        [ 0.0744, -0.0513,  0.0267]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0749, -0.0018,  0.0653],\n",
       "                        [ 0.0330, -0.0987,  0.0678],\n",
       "                        [-0.0402,  0.0973,  0.1025]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0341, -0.0543,  0.0477],\n",
       "                        [ 0.0317,  0.0276,  0.0857],\n",
       "                        [ 0.0266, -0.0237, -0.0640]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0323, -0.0589,  0.0680],\n",
       "                        [-0.0723, -0.0264,  0.0824],\n",
       "                        [ 0.0072, -0.0060,  0.0450]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0111, -0.0187,  0.0931],\n",
       "                        [-0.0430,  0.0861, -0.0755],\n",
       "                        [ 0.0595,  0.0346,  0.0402]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0180, -0.0928,  0.0595],\n",
       "                        [-0.0785, -0.0672, -0.0237],\n",
       "                        [-0.0714,  0.1030,  0.0693]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0146,  0.0487, -0.0591],\n",
       "                        [ 0.0129,  0.0032, -0.0932],\n",
       "                        [-0.0744, -0.0230, -0.0783]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0670, -0.0345,  0.0734],\n",
       "                        [-0.0163, -0.0096,  0.0405],\n",
       "                        [-0.0234, -0.0084, -0.0277]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0511,  0.0607,  0.0465],\n",
       "                        [ 0.0144, -0.0494, -0.0068],\n",
       "                        [-0.0546,  0.0631, -0.0519]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0716, -0.0538, -0.0137],\n",
       "                        [-0.0122,  0.0023,  0.0004],\n",
       "                        [ 0.0320, -0.0192,  0.0341]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0774,  0.0663, -0.0602],\n",
       "                        [-0.0119, -0.0878,  0.0924],\n",
       "                        [ 0.0474,  0.0722, -0.0329]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0362,  0.0818,  0.0790],\n",
       "                        [-0.0026, -0.0082, -0.0613],\n",
       "                        [-0.0457,  0.0598,  0.0323]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0277,  0.0103, -0.0912],\n",
       "                        [-0.0226, -0.0862,  0.0698],\n",
       "                        [-0.0394,  0.0672,  0.0553]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0471,  0.0130,  0.0489],\n",
       "                        [-0.0107, -0.0121, -0.0891],\n",
       "                        [ 0.0368,  0.0968,  0.0512]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0681,  0.0235,  0.0324],\n",
       "                        [ 0.0249,  0.0187,  0.0139],\n",
       "                        [-0.0356,  0.0345, -0.0660]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0072, -0.0472,  0.0667],\n",
       "                        [ 0.0976,  0.0771,  0.0679],\n",
       "                        [ 0.0482, -0.0752, -0.0064]]]], device='cuda:0')),\n",
       "             ('conv_block1.conv2.weight',\n",
       "              tensor([[[[ 0.0699, -0.0597,  0.0107],\n",
       "                        [ 0.0714,  0.0503, -0.0424],\n",
       "                        [ 0.0468,  0.0148,  0.0493]],\n",
       "              \n",
       "                       [[-0.0276,  0.0230,  0.0591],\n",
       "                        [-0.0503, -0.0206, -0.0619],\n",
       "                        [ 0.0003, -0.0443,  0.0177]],\n",
       "              \n",
       "                       [[ 0.0320, -0.0421, -0.0649],\n",
       "                        [-0.0586, -0.0572,  0.0122],\n",
       "                        [-0.0111, -0.0405, -0.0459]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0019,  0.0677,  0.0552],\n",
       "                        [ 0.0559, -0.0214, -0.0414],\n",
       "                        [ 0.0020, -0.0345,  0.0223]],\n",
       "              \n",
       "                       [[-0.0590, -0.0545,  0.0634],\n",
       "                        [ 0.0084, -0.0553,  0.0642],\n",
       "                        [ 0.0029,  0.0353, -0.0035]],\n",
       "              \n",
       "                       [[ 0.0037,  0.0458,  0.0373],\n",
       "                        [-0.0582, -0.0052,  0.0126],\n",
       "                        [ 0.0051, -0.0457, -0.0230]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0531, -0.0601,  0.0682],\n",
       "                        [ 0.0144,  0.0121, -0.0647],\n",
       "                        [-0.0021, -0.0301, -0.0201]],\n",
       "              \n",
       "                       [[-0.0596, -0.0147,  0.0406],\n",
       "                        [-0.0563, -0.0360, -0.0530],\n",
       "                        [-0.0577, -0.0487,  0.0594]],\n",
       "              \n",
       "                       [[-0.0732, -0.0277,  0.0311],\n",
       "                        [-0.0116,  0.0176, -0.0297],\n",
       "                        [-0.0297,  0.0192, -0.0462]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0301, -0.0493,  0.0021],\n",
       "                        [ 0.0351,  0.0272,  0.0540],\n",
       "                        [ 0.0023,  0.0667, -0.0028]],\n",
       "              \n",
       "                       [[-0.0468, -0.0508, -0.0235],\n",
       "                        [ 0.0397,  0.0502, -0.0025],\n",
       "                        [ 0.0370,  0.0431,  0.0006]],\n",
       "              \n",
       "                       [[-0.0713,  0.0457,  0.0607],\n",
       "                        [-0.0633, -0.0006,  0.0689],\n",
       "                        [ 0.0110, -0.0261, -0.0095]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0630,  0.0065, -0.0521],\n",
       "                        [ 0.0093, -0.0243,  0.0262],\n",
       "                        [ 0.0482,  0.0375, -0.0502]],\n",
       "              \n",
       "                       [[-0.0521,  0.0102,  0.0295],\n",
       "                        [ 0.0485,  0.0158, -0.0152],\n",
       "                        [-0.0490,  0.0643, -0.0261]],\n",
       "              \n",
       "                       [[-0.0644,  0.0661,  0.0466],\n",
       "                        [-0.0429,  0.0247,  0.0537],\n",
       "                        [ 0.0373, -0.0406, -0.0177]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0594, -0.0107, -0.0623],\n",
       "                        [-0.0697, -0.0025,  0.0468],\n",
       "                        [ 0.0535,  0.0186,  0.0292]],\n",
       "              \n",
       "                       [[-0.0314,  0.0046, -0.0192],\n",
       "                        [-0.0169, -0.0322,  0.0109],\n",
       "                        [ 0.0422, -0.0532,  0.0633]],\n",
       "              \n",
       "                       [[ 0.0140,  0.0603, -0.0310],\n",
       "                        [-0.0300, -0.0210,  0.0678],\n",
       "                        [ 0.0583, -0.0687,  0.0477]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0629,  0.0094, -0.0062],\n",
       "                        [-0.0252,  0.0344,  0.0230],\n",
       "                        [ 0.0045, -0.0579,  0.0727]],\n",
       "              \n",
       "                       [[-0.0277, -0.0584,  0.0254],\n",
       "                        [-0.0486, -0.0094, -0.0686],\n",
       "                        [-0.0010, -0.0206,  0.0170]],\n",
       "              \n",
       "                       [[-0.0683, -0.0642,  0.0389],\n",
       "                        [-0.0076,  0.0003,  0.0325],\n",
       "                        [-0.0510,  0.0524,  0.0021]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0437,  0.0570, -0.0477],\n",
       "                        [-0.0210,  0.0481,  0.0225],\n",
       "                        [-0.0023, -0.0046,  0.0346]],\n",
       "              \n",
       "                       [[-0.0290, -0.0004,  0.0096],\n",
       "                        [-0.0286,  0.0021, -0.0490],\n",
       "                        [ 0.0459,  0.0212, -0.0290]],\n",
       "              \n",
       "                       [[ 0.0197, -0.0495,  0.0667],\n",
       "                        [ 0.0653,  0.0651, -0.0178],\n",
       "                        [-0.0463, -0.0481,  0.0331]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0691, -0.0444, -0.0123],\n",
       "                        [ 0.0706, -0.0584,  0.0677],\n",
       "                        [ 0.0668, -0.0533, -0.0303]],\n",
       "              \n",
       "                       [[-0.0445,  0.0045, -0.0718],\n",
       "                        [ 0.0604,  0.0175,  0.0529],\n",
       "                        [ 0.0533, -0.0155,  0.0238]],\n",
       "              \n",
       "                       [[ 0.0543,  0.0712, -0.0146],\n",
       "                        [-0.0606,  0.0247,  0.0470],\n",
       "                        [-0.0403,  0.0199, -0.0529]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0047, -0.0310,  0.0732],\n",
       "                        [ 0.0258,  0.0390,  0.0072],\n",
       "                        [-0.0603,  0.0659,  0.0640]],\n",
       "              \n",
       "                       [[ 0.0619,  0.0253,  0.0376],\n",
       "                        [ 0.0268, -0.0242,  0.0451],\n",
       "                        [ 0.0011,  0.0609,  0.0535]],\n",
       "              \n",
       "                       [[ 0.0659,  0.0364,  0.0459],\n",
       "                        [ 0.0340, -0.0286,  0.0727],\n",
       "                        [-0.0298, -0.0321, -0.0323]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0380, -0.0734, -0.0676],\n",
       "                        [-0.0621, -0.0484,  0.0306],\n",
       "                        [-0.0533,  0.0283, -0.0002]],\n",
       "              \n",
       "                       [[ 0.0103, -0.0687,  0.0628],\n",
       "                        [-0.0026, -0.0731, -0.0336],\n",
       "                        [-0.0589, -0.0572,  0.0172]],\n",
       "              \n",
       "                       [[ 0.0241, -0.0190,  0.0059],\n",
       "                        [-0.0415,  0.0018, -0.0220],\n",
       "                        [ 0.0563, -0.0640,  0.0661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0254, -0.0211,  0.0636],\n",
       "                        [-0.0298,  0.0371, -0.0426],\n",
       "                        [ 0.0262,  0.0218,  0.0161]],\n",
       "              \n",
       "                       [[ 0.0572, -0.0520,  0.0412],\n",
       "                        [-0.0233, -0.0647,  0.0275],\n",
       "                        [-0.0350, -0.0055, -0.0043]],\n",
       "              \n",
       "                       [[-0.0374,  0.0113,  0.0430],\n",
       "                        [ 0.0670, -0.0494, -0.0508],\n",
       "                        [ 0.0260, -0.0294, -0.0209]]]], device='cuda:0')),\n",
       "             ('conv_block1.bn1.weight',\n",
       "              tensor([1.0011, 0.9967, 1.0038, 0.9993, 1.0038, 0.9919, 1.0067, 1.0002, 1.0010,\n",
       "                      0.9987, 0.9945, 1.0017, 0.9989, 0.9960, 0.9982, 0.9954, 1.0075, 0.9987,\n",
       "                      0.9958, 0.9960, 0.9964, 1.0025, 1.0005, 1.0027, 1.0001, 1.0003, 1.0080,\n",
       "                      0.9985, 1.0016, 1.0088, 1.0035, 1.0009, 1.0136, 1.0006, 0.9903, 0.9943,\n",
       "                      0.9987, 0.9986, 1.0098, 0.9971, 0.9950, 0.9987, 0.9986, 1.0026, 0.9972,\n",
       "                      0.9993, 1.0001, 0.9953, 0.9966, 1.0006, 0.9977, 1.0087, 1.0003, 0.9980,\n",
       "                      0.9977, 0.9981, 0.9957, 1.0012, 0.9976, 0.9999, 1.0022, 0.9997, 0.9939,\n",
       "                      0.9984], device='cuda:0')),\n",
       "             ('conv_block1.bn1.bias',\n",
       "              tensor([-0.0013, -0.0002,  0.0040,  0.0013,  0.0037, -0.0076, -0.0016, -0.0026,\n",
       "                       0.0003, -0.0062, -0.0061,  0.0034, -0.0007, -0.0071, -0.0028, -0.0055,\n",
       "                       0.0024, -0.0064, -0.0047, -0.0033,  0.0017,  0.0063, -0.0016,  0.0047,\n",
       "                      -0.0084, -0.0043,  0.0056, -0.0007,  0.0049,  0.0044,  0.0021,  0.0006,\n",
       "                       0.0048,  0.0001, -0.0083, -0.0070, -0.0010, -0.0011,  0.0070, -0.0004,\n",
       "                      -0.0014, -0.0031,  0.0007,  0.0015,  0.0014, -0.0018, -0.0027, -0.0037,\n",
       "                      -0.0033,  0.0002,  0.0016, -0.0034,  0.0002,  0.0026, -0.0025, -0.0031,\n",
       "                      -0.0082, -0.0030, -0.0017,  0.0015,  0.0062, -0.0033, -0.0057,  0.0008],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_block1.bn1.running_mean',\n",
       "              tensor([ 2.7656e-04,  6.9632e-06, -2.0774e-04,  1.3353e-04,  1.3998e-04,\n",
       "                       2.5244e-05, -2.0019e-04, -2.3799e-04, -2.2015e-04, -1.7368e-04,\n",
       "                      -1.0499e-04, -2.8481e-04,  1.0986e-04,  6.8996e-05,  1.3464e-05,\n",
       "                      -1.7303e-04, -3.4707e-04,  2.0612e-05, -1.0262e-04,  1.6791e-04,\n",
       "                       1.0550e-05, -2.8921e-04, -2.4052e-04, -6.2542e-05, -1.7999e-04,\n",
       "                       4.5981e-06,  1.9415e-04, -1.2288e-04,  1.2630e-05,  1.8910e-04,\n",
       "                      -2.2664e-04,  5.4895e-05,  3.5205e-04,  1.3808e-04, -1.5540e-05,\n",
       "                      -1.6653e-04, -8.1436e-05,  9.8692e-05, -1.4371e-04, -7.6037e-05,\n",
       "                      -1.5986e-04,  1.5054e-04,  6.7444e-05, -2.2051e-04, -1.4804e-05,\n",
       "                      -1.6003e-04, -8.4375e-05, -2.2132e-04, -6.0069e-05, -1.1815e-05,\n",
       "                       1.0115e-04, -1.5174e-04, -8.9873e-07, -1.9133e-04, -3.9872e-05,\n",
       "                      -3.0050e-05, -6.6828e-05,  1.2542e-04,  1.0093e-04, -1.8153e-04,\n",
       "                      -9.5474e-05,  6.1328e-05, -1.0791e-04,  1.7689e-04], device='cuda:0')),\n",
       "             ('conv_block1.bn1.running_var',\n",
       "              tensor([0.0183, 0.0530, 0.0219, 0.0166, 0.0065, 0.0053, 0.0059, 0.0578, 0.0115,\n",
       "                      0.0128, 0.0057, 0.0095, 0.0513, 0.1359, 0.0150, 0.0282, 0.0182, 0.0070,\n",
       "                      0.0062, 0.0936, 0.0083, 0.0127, 0.0637, 0.0187, 0.0796, 0.0092, 0.0126,\n",
       "                      0.0067, 0.0091, 0.0131, 0.0130, 0.0211, 0.0210, 0.0254, 0.0075, 0.0260,\n",
       "                      0.0586, 0.0505, 0.0102, 0.0051, 0.0348, 0.0658, 0.0309, 0.0090, 0.0100,\n",
       "                      0.0136, 0.1202, 0.0349, 0.0350, 0.0559, 0.0137, 0.0125, 0.0224, 0.0202,\n",
       "                      0.0460, 0.0069, 0.0097, 0.0026, 0.0180, 0.0101, 0.0119, 0.0197, 0.0027,\n",
       "                      0.0422], device='cuda:0')),\n",
       "             ('conv_block1.bn1.num_batches_tracked',\n",
       "              tensor(345, device='cuda:0')),\n",
       "             ('conv_block1.bn2.weight',\n",
       "              tensor([1.0007, 0.9966, 1.0021, 0.9982, 1.0002, 1.0002, 1.0021, 1.0009, 1.0043,\n",
       "                      0.9992, 0.9986, 0.9995, 1.0008, 0.9998, 0.9983, 0.9992, 1.0013, 1.0079,\n",
       "                      0.9981, 0.9964, 0.9969, 1.0030, 0.9958, 0.9983, 0.9934, 1.0001, 1.0000,\n",
       "                      1.0001, 0.9997, 0.9934, 1.0042, 0.9986, 0.9943, 1.0031, 1.0019, 1.0019,\n",
       "                      0.9975, 1.0055, 1.0030, 1.0043, 1.0038, 1.0001, 0.9981, 1.0009, 0.9973,\n",
       "                      1.0057, 1.0082, 1.0069, 0.9943, 0.9968, 0.9980, 1.0089, 1.0001, 0.9944,\n",
       "                      0.9994, 0.9998, 0.9999, 0.9984, 0.9944, 1.0039, 1.0041, 0.9958, 0.9985,\n",
       "                      0.9967], device='cuda:0')),\n",
       "             ('conv_block1.bn2.bias',\n",
       "              tensor([-6.1342e-03,  8.0313e-04,  1.1993e-04, -3.1870e-03, -4.1693e-03,\n",
       "                      -2.2597e-04,  1.9791e-03, -8.1532e-03,  2.1901e-03, -5.2857e-03,\n",
       "                      -2.8396e-03, -2.8941e-04,  1.7632e-03, -9.9296e-04,  1.0154e-03,\n",
       "                       2.1012e-04,  3.2360e-03, -3.8049e-03, -1.0924e-02, -4.6076e-03,\n",
       "                      -6.3342e-03,  3.5989e-03, -4.6662e-03,  4.0264e-04, -2.9783e-03,\n",
       "                       3.6988e-03, -1.6243e-03,  1.3576e-03, -4.5712e-03, -7.4638e-03,\n",
       "                      -2.4835e-03, -5.6233e-03, -5.9279e-03,  8.0332e-04, -4.1192e-03,\n",
       "                      -3.7934e-03,  9.6419e-04, -1.6930e-03, -1.0365e-03, -7.3108e-05,\n",
       "                      -2.0703e-04, -3.6611e-03, -4.7073e-03, -4.1772e-04, -5.1561e-03,\n",
       "                       1.8854e-03,  1.7515e-03,  2.2535e-03, -5.7703e-03, -5.4719e-03,\n",
       "                      -9.5334e-04, -1.2486e-03, -2.1659e-03, -2.5486e-03, -2.8256e-03,\n",
       "                      -2.3359e-03, -1.5287e-03,  7.4184e-04, -3.1938e-03, -7.5569e-04,\n",
       "                       5.7372e-03, -9.3357e-03, -3.6641e-03, -3.6182e-03], device='cuda:0')),\n",
       "             ('conv_block1.bn2.running_mean',\n",
       "              tensor([ 0.8672, -0.7633,  0.3305,  0.0178,  0.4098,  0.3293, -0.3850,  0.2544,\n",
       "                       0.3141,  0.6651, -0.8472, -0.1832, -0.6757,  0.1228,  0.1233, -0.1769,\n",
       "                      -0.2802, -0.0720,  0.1515,  0.6029,  0.1391,  0.6118, -0.0366, -0.6789,\n",
       "                       0.5320,  0.4049,  0.3442,  0.3921,  0.4106, -0.5820,  0.4123,  0.5214,\n",
       "                      -0.3624,  0.2827,  0.0576, -0.3891, -0.7191,  0.2209, -0.1690,  0.0886,\n",
       "                       0.1816,  0.2413,  0.3707, -0.4172,  0.0342, -0.0636,  0.2637,  0.0545,\n",
       "                      -0.7896,  0.0340,  0.4959, -0.0166, -0.4916, -0.3350,  0.2893,  0.1663,\n",
       "                      -0.0739,  0.1341, -0.5228, -0.0702, -0.5994,  0.7875,  0.4930, -0.0057],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_block1.bn2.running_var',\n",
       "              tensor([0.7521, 0.3947, 0.5184, 0.2769, 0.3043, 0.2397, 0.5224, 0.2228, 0.3151,\n",
       "                      0.5540, 0.5412, 0.3395, 0.4140, 0.6707, 0.5162, 0.3826, 0.2191, 0.4578,\n",
       "                      0.3628, 0.4251, 0.3257, 0.2769, 0.4241, 0.4657, 0.4550, 0.3826, 0.2691,\n",
       "                      0.4046, 0.2844, 0.4182, 0.3851, 0.3623, 0.2777, 0.3661, 0.2916, 0.2873,\n",
       "                      0.6028, 0.3221, 0.2623, 0.1732, 0.4277, 0.6558, 0.5017, 0.5796, 0.3389,\n",
       "                      0.4379, 0.3037, 0.4175, 0.3724, 0.4016, 0.3143, 0.4726, 0.3498, 0.3750,\n",
       "                      0.7550, 0.5127, 0.3722, 0.2114, 0.9342, 0.3815, 0.4233, 0.7992, 0.2487,\n",
       "                      0.1855], device='cuda:0')),\n",
       "             ('conv_block1.bn2.num_batches_tracked',\n",
       "              tensor(345, device='cuda:0')),\n",
       "             ('conv_block2.conv1.weight',\n",
       "              tensor([[[[ 7.8653e-03, -4.2695e-03, -5.2734e-02],\n",
       "                        [ 5.0158e-03, -2.4160e-02,  2.1537e-02],\n",
       "                        [ 9.4802e-03,  4.2375e-02,  3.8429e-02]],\n",
       "              \n",
       "                       [[ 4.2269e-02,  3.9468e-02, -4.8648e-03],\n",
       "                        [-5.7805e-02,  5.5320e-02,  2.3822e-02],\n",
       "                        [-2.2519e-02, -5.1018e-03,  1.2347e-02]],\n",
       "              \n",
       "                       [[-5.3009e-03, -4.8119e-02, -1.2428e-02],\n",
       "                        [ 5.2059e-03,  5.2914e-02, -2.4903e-02],\n",
       "                        [-1.9431e-02, -3.2922e-02, -3.5399e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.4581e-02, -5.9639e-02, -2.6189e-02],\n",
       "                        [-5.2651e-02, -4.4395e-02,  2.2126e-02],\n",
       "                        [-4.1045e-02, -3.4841e-02, -4.6093e-02]],\n",
       "              \n",
       "                       [[ 1.5383e-02, -6.0074e-02,  3.8854e-02],\n",
       "                        [ 2.5891e-02, -1.6975e-02,  1.7512e-02],\n",
       "                        [-2.5969e-02,  1.2356e-02,  4.6275e-02]],\n",
       "              \n",
       "                       [[ 5.7902e-03,  1.6075e-02, -4.4655e-03],\n",
       "                        [-3.8767e-02, -4.3394e-02,  3.9892e-03],\n",
       "                        [ 3.5314e-02,  3.1720e-02, -2.2041e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4709e-02,  5.1938e-02, -2.4734e-02],\n",
       "                        [ 2.2037e-02, -3.9341e-02,  4.3517e-02],\n",
       "                        [-3.8057e-02,  1.3876e-02, -3.5446e-02]],\n",
       "              \n",
       "                       [[ 4.5762e-02,  1.7057e-02, -7.2579e-03],\n",
       "                        [-2.2130e-02,  2.7751e-02,  5.7057e-02],\n",
       "                        [-4.3500e-02, -3.8510e-02,  4.5031e-02]],\n",
       "              \n",
       "                       [[ 3.1649e-02,  2.4457e-02,  2.6364e-03],\n",
       "                        [ 5.4624e-02,  3.4633e-02, -3.3717e-02],\n",
       "                        [-3.1738e-02, -4.2946e-02, -2.9272e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.4836e-03, -2.6901e-02,  7.0572e-03],\n",
       "                        [-1.2910e-02, -4.4434e-02,  5.2934e-02],\n",
       "                        [-4.8145e-02, -4.7487e-04,  7.4535e-04]],\n",
       "              \n",
       "                       [[-1.4776e-02, -4.5599e-02,  6.1668e-02],\n",
       "                        [ 4.8498e-02, -3.5715e-02,  3.6546e-02],\n",
       "                        [ 7.6664e-03,  4.0379e-02, -3.4765e-02]],\n",
       "              \n",
       "                       [[ 1.5964e-03,  1.6789e-02,  2.5456e-02],\n",
       "                        [ 1.2590e-02, -1.6098e-02,  2.3684e-02],\n",
       "                        [ 1.4617e-02, -3.3992e-03, -4.4932e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8469e-02, -5.2771e-02,  9.8615e-03],\n",
       "                        [-2.2479e-02, -7.2105e-03,  2.6312e-02],\n",
       "                        [ 7.5519e-03,  1.7604e-02, -1.1434e-02]],\n",
       "              \n",
       "                       [[-1.3609e-05, -1.6567e-02, -3.0388e-02],\n",
       "                        [-1.1022e-02, -3.5965e-02,  4.2589e-02],\n",
       "                        [-3.3487e-02, -2.8425e-02, -4.1105e-02]],\n",
       "              \n",
       "                       [[-3.5883e-02, -2.9782e-02,  3.2780e-03],\n",
       "                        [-3.1865e-02, -1.7310e-02,  1.4711e-02],\n",
       "                        [-6.5132e-03, -4.5843e-02, -4.2276e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.2309e-02,  5.5355e-02,  4.1481e-02],\n",
       "                        [-2.3253e-02,  1.1250e-03, -4.4829e-02],\n",
       "                        [-1.5751e-02, -1.1150e-02,  3.7183e-02]],\n",
       "              \n",
       "                       [[ 4.8224e-02,  1.1102e-02, -4.2681e-02],\n",
       "                        [-2.3019e-02,  1.3592e-02, -5.4723e-02],\n",
       "                        [ 5.5151e-02, -1.4568e-02,  5.8163e-02]],\n",
       "              \n",
       "                       [[ 1.3176e-02,  3.4492e-02,  2.3262e-02],\n",
       "                        [-4.8591e-02, -3.9735e-02,  2.8588e-02],\n",
       "                        [-1.6880e-02,  2.6496e-03, -5.5410e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5402e-02,  4.1998e-02,  1.5190e-03],\n",
       "                        [ 4.9368e-02,  1.1329e-02,  2.1552e-02],\n",
       "                        [ 5.2183e-02, -8.6905e-03, -4.4535e-02]],\n",
       "              \n",
       "                       [[-4.7486e-03, -4.0265e-02,  4.9734e-02],\n",
       "                        [ 3.5434e-03, -4.2382e-02, -4.0081e-02],\n",
       "                        [ 3.5430e-02,  1.8671e-02, -3.3006e-02]],\n",
       "              \n",
       "                       [[-1.5276e-02, -2.9598e-02,  1.8096e-02],\n",
       "                        [ 3.9775e-03,  1.5286e-03,  5.6229e-04],\n",
       "                        [-5.2303e-02, -4.4921e-02, -5.2500e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.7842e-02, -3.2042e-02, -3.4543e-02],\n",
       "                        [ 1.6825e-02, -6.1279e-03,  4.8135e-02],\n",
       "                        [ 7.1512e-03, -4.7259e-02,  3.4781e-02]],\n",
       "              \n",
       "                       [[-4.0577e-02,  2.0796e-02,  4.8319e-02],\n",
       "                        [ 9.5236e-03, -2.0143e-02,  4.4366e-02],\n",
       "                        [ 6.0512e-02,  4.2095e-02,  4.2377e-02]],\n",
       "              \n",
       "                       [[-4.9534e-03, -2.8157e-02,  3.7570e-02],\n",
       "                        [-3.1876e-02, -2.2148e-02,  4.7147e-02],\n",
       "                        [-1.0950e-02,  1.6596e-03,  1.7097e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.8575e-02, -3.2998e-02, -3.3837e-02],\n",
       "                        [-4.0440e-02, -2.0269e-02,  2.0533e-02],\n",
       "                        [-2.0935e-02, -2.7403e-02, -1.5523e-02]],\n",
       "              \n",
       "                       [[ 4.2418e-02, -3.5091e-03, -3.0317e-02],\n",
       "                        [-7.0736e-03,  3.6971e-03,  5.7097e-02],\n",
       "                        [-4.3373e-03,  1.1670e-02,  3.3977e-02]],\n",
       "              \n",
       "                       [[ 3.9710e-02,  1.6476e-02,  5.3654e-03],\n",
       "                        [-3.3602e-02, -3.7513e-02,  5.3211e-02],\n",
       "                        [-1.2886e-02, -4.7030e-02,  1.4844e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.5052e-02, -5.0109e-02, -1.0124e-02],\n",
       "                        [-3.4667e-02, -3.6028e-02, -5.9993e-02],\n",
       "                        [ 2.4590e-02, -2.7012e-02,  4.3082e-02]],\n",
       "              \n",
       "                       [[-7.5007e-04, -2.1672e-03,  1.0788e-02],\n",
       "                        [-9.8281e-03, -1.3994e-02, -1.5049e-02],\n",
       "                        [ 9.7459e-03, -4.4660e-02,  4.5181e-02]],\n",
       "              \n",
       "                       [[ 4.5438e-02,  1.0844e-02,  2.4757e-02],\n",
       "                        [-2.0757e-02,  2.5434e-02, -4.3901e-02],\n",
       "                        [-3.0645e-02,  4.9236e-02, -5.3648e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.6435e-02, -5.5589e-03, -4.0679e-02],\n",
       "                        [ 3.8615e-02, -5.7057e-02, -5.9543e-02],\n",
       "                        [ 3.8322e-02, -4.5064e-02,  9.3403e-03]],\n",
       "              \n",
       "                       [[-1.6156e-02, -2.6945e-02, -4.1226e-03],\n",
       "                        [ 1.0515e-02, -1.7362e-02,  5.1733e-02],\n",
       "                        [ 6.0572e-03, -1.8677e-02, -2.5272e-02]],\n",
       "              \n",
       "                       [[ 4.0837e-02, -1.8100e-02,  3.6677e-02],\n",
       "                        [-8.7069e-03,  4.0150e-02,  1.2012e-02],\n",
       "                        [ 1.9556e-02,  4.4031e-02, -2.7780e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.7729e-02, -1.1374e-02,  3.2828e-02],\n",
       "                        [ 5.1567e-02,  2.0058e-02,  5.8641e-03],\n",
       "                        [-5.2551e-02,  2.0093e-02, -5.0337e-02]],\n",
       "              \n",
       "                       [[ 3.6105e-02,  8.0477e-03, -1.2339e-02],\n",
       "                        [ 5.1526e-02, -1.0564e-02,  3.7509e-02],\n",
       "                        [-1.8220e-02, -2.7094e-02,  9.8157e-03]],\n",
       "              \n",
       "                       [[-3.5959e-02,  1.3631e-02, -2.9457e-03],\n",
       "                        [-2.2336e-02, -3.4515e-02, -1.6063e-02],\n",
       "                        [ 4.6658e-02, -1.6669e-02, -4.1560e-02]]]], device='cuda:0')),\n",
       "             ('conv_block2.conv2.weight',\n",
       "              tensor([[[[ 2.1326e-02,  4.2300e-02,  7.8618e-04],\n",
       "                        [-3.6984e-02,  1.6666e-02, -1.1637e-02],\n",
       "                        [ 4.4167e-02, -2.1631e-02,  3.7109e-02]],\n",
       "              \n",
       "                       [[-2.4339e-02, -3.1734e-03, -2.1196e-02],\n",
       "                        [-9.0616e-03, -5.0539e-03,  4.3713e-02],\n",
       "                        [ 9.9966e-03,  4.0525e-02, -3.7540e-02]],\n",
       "              \n",
       "                       [[ 2.1929e-02,  4.6723e-02, -4.6370e-02],\n",
       "                        [ 2.8137e-02, -4.1448e-02, -3.5481e-02],\n",
       "                        [-3.7322e-02,  6.9523e-03,  2.0446e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.0733e-02,  1.0055e-02, -8.2790e-03],\n",
       "                        [ 5.1243e-02,  3.7323e-02,  2.5327e-02],\n",
       "                        [-8.9032e-03,  6.8761e-03,  4.0218e-02]],\n",
       "              \n",
       "                       [[-9.4574e-03,  4.9128e-02, -1.3549e-02],\n",
       "                        [-4.6301e-02, -9.3629e-03, -1.9552e-02],\n",
       "                        [ 6.2115e-03,  4.9306e-02, -3.2112e-02]],\n",
       "              \n",
       "                       [[ 4.6046e-02, -4.2345e-02,  2.5354e-03],\n",
       "                        [ 1.9023e-02,  1.9018e-02, -4.6619e-02],\n",
       "                        [ 4.1961e-03, -6.5098e-03, -2.0809e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.1344e-02,  4.2367e-02, -2.3927e-03],\n",
       "                        [-1.7275e-02, -4.4180e-03,  3.3009e-02],\n",
       "                        [ 3.2182e-02, -2.7184e-02, -2.5277e-03]],\n",
       "              \n",
       "                       [[-4.1254e-03, -3.2643e-02,  4.7863e-02],\n",
       "                        [-4.1949e-02, -1.9063e-02,  8.1315e-03],\n",
       "                        [-4.1994e-03,  9.1893e-03, -1.1559e-02]],\n",
       "              \n",
       "                       [[ 3.7119e-02,  3.8569e-02,  2.5009e-02],\n",
       "                        [ 4.3665e-02, -1.1316e-02,  5.0932e-02],\n",
       "                        [-1.3251e-02, -2.9562e-02,  1.9653e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.1454e-02,  2.4364e-02,  2.7755e-02],\n",
       "                        [-8.3316e-03,  4.7306e-02, -4.8100e-02],\n",
       "                        [-3.6365e-02, -2.1103e-02, -3.4533e-02]],\n",
       "              \n",
       "                       [[ 2.6411e-02,  4.6382e-02,  4.0904e-02],\n",
       "                        [-4.3543e-03, -3.1212e-02, -2.9442e-02],\n",
       "                        [-2.1360e-02, -1.7055e-02, -2.4835e-02]],\n",
       "              \n",
       "                       [[-3.6065e-02, -5.0242e-02, -5.0804e-02],\n",
       "                        [-4.6775e-02,  3.0013e-02,  1.2182e-02],\n",
       "                        [-5.0454e-02, -1.1420e-02,  1.4508e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6303e-02,  3.7283e-02,  2.2850e-02],\n",
       "                        [ 1.8311e-02, -2.5093e-02, -2.0442e-02],\n",
       "                        [-2.5592e-02,  1.1544e-02,  2.3626e-02]],\n",
       "              \n",
       "                       [[-3.5244e-02,  1.6488e-02,  3.7374e-02],\n",
       "                        [ 3.4812e-02, -3.1168e-02,  1.0104e-02],\n",
       "                        [-2.3250e-02, -1.9685e-02,  6.6748e-03]],\n",
       "              \n",
       "                       [[ 1.1916e-03,  1.1136e-02, -3.0064e-02],\n",
       "                        [ 1.8798e-02,  1.3962e-02,  4.3144e-02],\n",
       "                        [ 3.7374e-02, -3.3449e-03,  1.9090e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.6162e-02,  2.1172e-02,  1.3856e-02],\n",
       "                        [-2.9341e-02,  3.1080e-02,  4.7807e-02],\n",
       "                        [-1.5159e-02, -4.5193e-02,  1.7334e-02]],\n",
       "              \n",
       "                       [[-2.2192e-02,  2.2539e-02,  1.4278e-02],\n",
       "                        [ 1.3476e-02,  2.3137e-02, -5.6063e-03],\n",
       "                        [-3.3382e-02,  3.0327e-02,  1.4554e-02]],\n",
       "              \n",
       "                       [[-3.9174e-02,  1.3373e-03, -1.8850e-02],\n",
       "                        [-2.4212e-02,  6.4317e-03,  2.4169e-02],\n",
       "                        [-3.9425e-02, -2.1702e-02,  2.3620e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.8630e-03, -2.1085e-02, -5.9029e-03],\n",
       "                        [-1.3827e-02,  2.6119e-02, -2.0946e-02],\n",
       "                        [ 5.6479e-03,  3.2718e-02,  3.4269e-02]],\n",
       "              \n",
       "                       [[ 5.7453e-03, -4.4094e-02,  4.3716e-02],\n",
       "                        [ 2.5863e-02,  3.7657e-02, -1.4208e-02],\n",
       "                        [-1.8882e-02,  2.8040e-02, -3.7252e-02]],\n",
       "              \n",
       "                       [[ 4.3731e-02, -2.7835e-02, -1.8348e-02],\n",
       "                        [ 2.4375e-02, -8.9562e-03,  3.7701e-02],\n",
       "                        [-4.1467e-02, -3.6514e-02, -1.5769e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.4872e-02,  1.6875e-02,  3.1784e-02],\n",
       "                        [-4.3110e-03,  8.1647e-03, -3.6573e-02],\n",
       "                        [-4.3463e-02,  1.0953e-02, -4.4351e-02]],\n",
       "              \n",
       "                       [[-3.7627e-02, -3.3203e-02, -2.6026e-02],\n",
       "                        [ 3.7988e-02, -2.6332e-02,  2.5247e-02],\n",
       "                        [-1.0031e-02, -3.8345e-02, -3.2272e-02]],\n",
       "              \n",
       "                       [[ 3.2378e-02, -1.5436e-02,  3.2080e-02],\n",
       "                        [-1.9518e-02,  4.2283e-02, -6.1430e-03],\n",
       "                        [ 1.9409e-02,  1.8008e-02,  2.2323e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.9701e-02,  3.1038e-02, -3.5471e-02],\n",
       "                        [-3.9849e-02, -5.3258e-02, -3.5971e-02],\n",
       "                        [ 2.7946e-03, -4.4667e-02, -4.4644e-02]],\n",
       "              \n",
       "                       [[-3.1791e-02, -9.1333e-03,  1.8630e-03],\n",
       "                        [ 2.5439e-02,  4.1440e-02, -2.3539e-02],\n",
       "                        [ 4.7888e-02,  4.6238e-02,  3.4581e-02]],\n",
       "              \n",
       "                       [[ 1.6943e-02,  5.8727e-03, -3.6300e-02],\n",
       "                        [ 5.0767e-02, -4.3125e-02,  8.6354e-04],\n",
       "                        [ 2.6975e-02,  9.9047e-03,  9.2747e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.2509e-02,  4.8602e-02,  2.2679e-02],\n",
       "                        [-3.1941e-02,  2.8968e-02,  1.7507e-02],\n",
       "                        [-2.2021e-02, -3.9881e-03, -1.4097e-02]],\n",
       "              \n",
       "                       [[ 1.5376e-02, -3.8719e-02, -4.8445e-02],\n",
       "                        [ 1.3770e-02, -2.1411e-02, -3.0850e-02],\n",
       "                        [ 2.6964e-02,  4.0647e-02,  4.8888e-02]],\n",
       "              \n",
       "                       [[-1.8418e-02, -2.6113e-02, -8.8693e-03],\n",
       "                        [-5.0586e-02,  3.9250e-02,  3.9172e-02],\n",
       "                        [ 9.1234e-03, -3.1741e-02, -3.9692e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.4924e-02, -6.3730e-03, -9.8679e-03],\n",
       "                        [ 4.0730e-02,  4.2810e-03,  1.6616e-02],\n",
       "                        [-2.9722e-02,  1.9742e-03, -3.5111e-03]],\n",
       "              \n",
       "                       [[ 3.5771e-02,  1.2960e-02,  4.3710e-02],\n",
       "                        [ 3.0892e-02,  8.5767e-03, -2.2525e-02],\n",
       "                        [-9.5931e-03,  7.9006e-03, -1.6188e-02]],\n",
       "              \n",
       "                       [[ 1.1149e-05, -1.6505e-02,  5.2561e-02],\n",
       "                        [ 4.1850e-02,  3.8415e-02, -3.3189e-03],\n",
       "                        [ 4.2710e-02,  2.5673e-02, -1.2898e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0503e-02, -1.1105e-02, -1.9712e-02],\n",
       "                        [-4.4307e-02, -4.3468e-02, -3.9991e-02],\n",
       "                        [ 5.4330e-02,  1.3461e-02,  3.3820e-02]],\n",
       "              \n",
       "                       [[-2.9179e-02,  2.3585e-02, -3.2238e-02],\n",
       "                        [-5.0266e-02, -3.3465e-02, -2.2381e-02],\n",
       "                        [ 2.7822e-02, -3.4001e-02,  3.9548e-02]],\n",
       "              \n",
       "                       [[-1.7410e-02, -2.2578e-02,  2.7955e-02],\n",
       "                        [ 1.8781e-02,  1.7328e-02, -3.3878e-02],\n",
       "                        [-1.0931e-02, -2.4042e-02, -1.5205e-02]]]], device='cuda:0')),\n",
       "             ('conv_block2.bn1.weight',\n",
       "              tensor([0.9963, 1.0060, 0.9981, 1.0008, 0.9953, 0.9994, 0.9985, 0.9971, 1.0000,\n",
       "                      1.0010, 0.9987, 0.9981, 1.0073, 0.9949, 0.9919, 1.0008, 1.0021, 1.0030,\n",
       "                      1.0000, 0.9997, 0.9992, 1.0008, 1.0068, 1.0056, 1.0030, 1.0022, 1.0049,\n",
       "                      0.9975, 0.9986, 1.0010, 0.9997, 0.9973, 1.0009, 1.0046, 0.9985, 1.0037,\n",
       "                      0.9994, 1.0012, 0.9987, 1.0013, 0.9970, 0.9954, 0.9973, 0.9992, 1.0003,\n",
       "                      1.0000, 0.9950, 1.0064, 1.0027, 1.0061, 0.9951, 1.0032, 1.0027, 0.9999,\n",
       "                      0.9950, 1.0013, 1.0012, 0.9978, 0.9988, 0.9983, 1.0056, 0.9964, 1.0025,\n",
       "                      1.0031, 1.0004, 0.9967, 1.0007, 1.0039, 1.0047, 0.9975, 1.0011, 1.0027,\n",
       "                      0.9928, 0.9938, 0.9987, 0.9991, 1.0062, 0.9973, 0.9936, 1.0051, 0.9997,\n",
       "                      0.9988, 0.9978, 0.9975, 1.0012, 1.0019, 1.0060, 1.0038, 0.9974, 0.9975,\n",
       "                      0.9999, 0.9946, 1.0009, 1.0011, 1.0065, 0.9986, 0.9950, 0.9936, 0.9944,\n",
       "                      0.9988, 0.9978, 0.9989, 1.0002, 1.0036, 0.9990, 0.9992, 0.9997, 1.0038,\n",
       "                      0.9989, 0.9980, 0.9972, 0.9933, 0.9954, 1.0048, 1.0023, 0.9979, 0.9935,\n",
       "                      1.0017, 0.9998, 1.0040, 0.9993, 0.9963, 1.0057, 0.9987, 0.9987, 1.0008,\n",
       "                      0.9964, 1.0001], device='cuda:0')),\n",
       "             ('conv_block2.bn1.bias',\n",
       "              tensor([-7.0734e-04,  3.0702e-03, -2.6879e-03,  1.5650e-03, -4.6165e-03,\n",
       "                       1.4192e-03, -5.1743e-05,  2.2443e-03,  2.0332e-03,  1.4375e-03,\n",
       "                      -5.3953e-03, -1.2943e-03,  6.9747e-03, -8.3513e-03, -7.4289e-03,\n",
       "                       4.7465e-04, -4.0050e-04,  6.1980e-03,  1.2169e-04, -2.4915e-03,\n",
       "                       7.4629e-04, -2.2622e-03,  5.7096e-03,  2.6654e-03,  3.0571e-03,\n",
       "                       3.2293e-03,  2.6873e-03, -6.3493e-04,  2.2790e-03,  1.6998e-03,\n",
       "                       8.2051e-04, -4.1928e-03,  2.1591e-03,  5.0360e-03, -1.7601e-03,\n",
       "                      -1.8267e-03, -6.8079e-03, -1.8633e-04,  1.1775e-03,  1.6953e-03,\n",
       "                      -3.7032e-03, -2.9714e-03, -2.1433e-03, -8.1791e-04, -5.7295e-03,\n",
       "                       1.8929e-03, -5.4410e-03,  4.5032e-04,  1.6452e-03,  7.8240e-03,\n",
       "                      -7.1430e-03,  1.0666e-03, -7.3133e-04,  2.1344e-05, -4.0058e-03,\n",
       "                       5.9401e-03,  3.9877e-03, -5.0015e-03, -3.0391e-03, -2.5099e-03,\n",
       "                       4.7615e-03,  1.6959e-03, -1.0919e-04,  4.3397e-03, -3.3642e-03,\n",
       "                      -8.5107e-04, -1.3844e-03,  4.3462e-03, -4.2066e-03, -4.7590e-03,\n",
       "                       9.5064e-04,  3.1682e-03, -6.2428e-03, -8.8623e-03, -4.2894e-03,\n",
       "                       2.8547e-03,  1.0192e-03,  2.5058e-03, -3.2170e-03,  7.3641e-03,\n",
       "                      -1.4609e-03, -2.2346e-03, -2.1730e-03, -4.3905e-04, -3.1015e-03,\n",
       "                       1.4496e-03,  5.1743e-03,  2.9912e-03, -1.7599e-03, -6.7142e-03,\n",
       "                      -3.0544e-03, -8.6424e-03,  3.3059e-03, -5.4720e-03,  2.1689e-04,\n",
       "                      -2.3220e-03, -2.1922e-03, -4.5314e-03, -8.1354e-04, -3.3637e-03,\n",
       "                      -1.5682e-03,  2.8867e-03,  3.3554e-03, -5.3317e-03,  4.4063e-04,\n",
       "                       4.1312e-04,  1.7245e-03,  4.4208e-03, -3.8332e-03,  7.7261e-04,\n",
       "                      -3.1794e-03, -6.1954e-03, -1.0275e-03,  3.8241e-03, -2.9153e-03,\n",
       "                      -5.1166e-03, -6.3883e-03, -1.0170e-03, -3.3238e-03,  1.5019e-03,\n",
       "                      -8.5572e-04, -3.8988e-03,  2.6678e-03, -2.5304e-03,  7.3405e-04,\n",
       "                      -6.7276e-03, -3.7338e-03,  3.6667e-03], device='cuda:0')),\n",
       "             ('conv_block2.bn1.running_mean',\n",
       "              tensor([-0.1028,  0.1192,  0.1635, -0.6617,  0.6639, -0.3334, -0.3633, -0.6911,\n",
       "                       0.3673, -0.0487,  0.3565, -0.0902,  0.2828,  0.5454,  0.2432, -0.1477,\n",
       "                      -0.0801, -0.5882,  0.1452,  0.4161, -0.5636,  0.2833, -0.0106, -0.2551,\n",
       "                      -0.1488, -0.4550, -0.0926,  0.0960,  0.1125, -0.0520,  0.3813,  0.1053,\n",
       "                       0.0942, -0.5026,  0.0622,  0.0580,  0.4070, -0.2093, -0.2610,  0.2208,\n",
       "                       0.5360, -0.1696, -0.1878, -0.2877,  0.1909, -0.1383,  0.2457, -0.1589,\n",
       "                      -0.0767, -0.2265,  0.1537,  0.1134,  0.0733, -0.1522,  0.0507, -0.4083,\n",
       "                      -0.0701,  0.0614,  0.3611,  0.2853,  0.0712,  0.1734,  0.5243,  0.1802,\n",
       "                       0.3656, -0.0254, -0.2705,  0.4132,  1.2528,  0.1050, -0.4427, -0.2127,\n",
       "                      -0.0288,  0.4473,  0.2019, -0.1730,  0.0124, -0.3379, -0.5181, -0.4866,\n",
       "                       0.3538,  0.3325,  0.1174,  0.0830, -0.1645,  0.5867,  0.4685, -0.1229,\n",
       "                      -0.2197,  0.0955, -0.1985,  0.0503,  0.1778,  0.2200,  0.1107, -0.1833,\n",
       "                      -0.3089, -0.5060, -0.2336, -0.1680, -0.5006, -0.1555, -0.7201,  0.7034,\n",
       "                       0.0245, -0.3494, -0.5236, -0.1956,  0.5280, -0.2454,  0.0421,  0.1424,\n",
       "                      -0.4985, -0.0074,  0.1287,  0.4581, -0.2446, -0.1412,  0.5911,  0.2329,\n",
       "                       0.0716, -0.1942, -0.1686, -0.0881,  0.0418,  0.9958, -0.0455, -0.5347],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_block2.bn1.running_var',\n",
       "              tensor([0.3525, 0.4014, 0.4820, 0.5463, 0.4433, 0.2921, 0.3309, 0.6445, 0.4004,\n",
       "                      0.2152, 0.3826, 0.3035, 0.4621, 0.2459, 0.2289, 0.3191, 0.3699, 0.3943,\n",
       "                      0.4458, 0.6213, 0.4539, 0.3114, 0.3684, 0.4554, 0.3602, 0.2317, 0.3521,\n",
       "                      0.3612, 0.2646, 0.3247, 0.3672, 0.3072, 0.3172, 0.4559, 0.3485, 0.5203,\n",
       "                      0.3408, 0.3591, 0.3335, 0.4390, 0.4527, 0.2371, 0.2578, 0.2873, 0.3990,\n",
       "                      0.2847, 0.2452, 0.4796, 0.4512, 0.3209, 0.2541, 0.3317, 0.3814, 0.2411,\n",
       "                      0.3731, 0.3218, 0.2764, 0.3226, 0.2955, 0.5510, 0.2784, 0.2011, 0.4675,\n",
       "                      0.2987, 0.4820, 0.2902, 0.4098, 0.6014, 0.9534, 0.1895, 0.4278, 0.3206,\n",
       "                      0.3177, 0.2757, 0.4441, 0.1908, 0.4714, 0.2939, 0.3535, 0.4309, 0.7217,\n",
       "                      0.4022, 0.3519, 0.2505, 0.4066, 0.3936, 0.2936, 0.4304, 0.1837, 0.3529,\n",
       "                      0.1855, 0.2156, 0.4550, 0.3860, 0.5856, 0.2116, 0.3068, 0.2936, 0.3035,\n",
       "                      0.4375, 0.4029, 0.3053, 0.5226, 0.4182, 0.2853, 0.3423, 0.3452, 0.3948,\n",
       "                      0.2989, 0.3252, 0.3433, 0.2943, 0.4760, 0.5291, 0.4568, 0.3410, 0.2867,\n",
       "                      0.2596, 0.2990, 0.3722, 0.2590, 0.4624, 0.2581, 0.4038, 0.4423, 0.9354,\n",
       "                      0.2516, 0.3598], device='cuda:0')),\n",
       "             ('conv_block2.bn1.num_batches_tracked',\n",
       "              tensor(345, device='cuda:0')),\n",
       "             ('conv_block2.bn2.weight',\n",
       "              tensor([1.0007, 1.0053, 1.0018, 1.0005, 0.9973, 0.9963, 0.9987, 1.0027, 1.0022,\n",
       "                      0.9960, 1.0018, 1.0038, 0.9968, 1.0095, 1.0072, 0.9949, 1.0015, 1.0012,\n",
       "                      1.0003, 1.0037, 0.9990, 0.9987, 1.0020, 0.9997, 1.0012, 0.9985, 1.0026,\n",
       "                      1.0070, 0.9998, 1.0044, 1.0020, 0.9993, 1.0055, 1.0027, 0.9979, 0.9997,\n",
       "                      1.0016, 0.9943, 1.0004, 0.9964, 1.0012, 1.0000, 1.0008, 0.9962, 1.0011,\n",
       "                      1.0006, 0.9960, 1.0007, 1.0001, 1.0033, 0.9955, 1.0051, 1.0012, 1.0011,\n",
       "                      0.9984, 1.0020, 1.0003, 1.0028, 0.9984, 0.9952, 0.9974, 1.0047, 0.9969,\n",
       "                      0.9959, 0.9987, 0.9978, 1.0021, 0.9945, 0.9983, 0.9997, 0.9965, 0.9992,\n",
       "                      1.0018, 1.0058, 1.0059, 0.9994, 0.9945, 0.9995, 0.9941, 1.0011, 1.0018,\n",
       "                      0.9974, 1.0007, 1.0010, 0.9977, 1.0040, 0.9936, 1.0058, 1.0037, 1.0004,\n",
       "                      1.0109, 0.9962, 0.9989, 1.0023, 0.9978, 0.9965, 0.9966, 0.9951, 0.9987,\n",
       "                      0.9964, 0.9973, 0.9985, 0.9996, 0.9992, 1.0018, 1.0015, 0.9982, 0.9972,\n",
       "                      1.0049, 0.9989, 0.9982, 0.9964, 0.9993, 0.9947, 0.9974, 1.0003, 0.9965,\n",
       "                      0.9963, 0.9978, 0.9973, 1.0007, 1.0008, 0.9991, 0.9966, 0.9959, 1.0036,\n",
       "                      1.0010, 1.0081], device='cuda:0')),\n",
       "             ('conv_block2.bn2.bias',\n",
       "              tensor([-1.7107e-03,  4.7040e-03,  3.4460e-03,  2.1823e-03, -4.2954e-03,\n",
       "                      -5.0486e-03, -2.1809e-03,  2.2406e-03,  3.5178e-03, -2.7317e-03,\n",
       "                       5.6444e-03,  2.1115e-03, -5.0552e-03,  5.4127e-03,  8.4850e-04,\n",
       "                      -4.0270e-03, -2.1371e-03, -6.9752e-04,  1.7323e-04,  3.3466e-03,\n",
       "                      -4.0249e-03, -2.7446e-03,  7.2487e-03, -2.0630e-03,  6.3866e-04,\n",
       "                      -1.9348e-04, -1.1528e-03,  1.0834e-03,  4.7050e-04,  1.0420e-05,\n",
       "                       3.7427e-05,  1.5182e-04,  1.0643e-03,  1.0510e-03, -3.7727e-03,\n",
       "                      -4.3350e-03,  1.0554e-03, -1.0067e-02, -3.1432e-05, -3.7755e-03,\n",
       "                       3.9583e-04,  2.2970e-03,  4.4354e-03, -2.7581e-03, -2.4283e-03,\n",
       "                       3.1723e-03, -1.6907e-03,  8.4321e-04, -1.0120e-03,  7.1583e-03,\n",
       "                      -9.2106e-03,  4.2876e-03, -2.1429e-03,  3.3346e-03, -1.4859e-03,\n",
       "                       1.3175e-03,  5.6677e-04,  2.8071e-03, -1.2331e-03, -4.9174e-03,\n",
       "                      -9.9184e-04,  8.5764e-05, -2.8224e-03, -9.1594e-03,  2.4728e-03,\n",
       "                       6.0196e-04,  2.6422e-03, -3.6465e-03,  1.0336e-03, -1.8806e-03,\n",
       "                      -2.2141e-03, -2.5947e-03,  1.6563e-03,  1.2070e-03,  4.5059e-03,\n",
       "                      -4.0090e-03, -4.5908e-03, -4.7905e-03, -7.4504e-03,  2.4500e-03,\n",
       "                      -1.0629e-03, -1.9611e-03,  7.3871e-05,  2.0790e-03, -4.7808e-04,\n",
       "                       5.2359e-03, -5.4780e-03,  9.5160e-03, -1.9541e-04, -3.9223e-03,\n",
       "                       1.3419e-02, -3.0946e-03, -7.3149e-04,  1.4634e-03,  2.6349e-03,\n",
       "                      -4.2101e-03, -1.6264e-03, -6.4966e-03, -3.8779e-04, -1.4100e-03,\n",
       "                      -2.6447e-03, -5.6163e-04,  4.0173e-04,  9.0515e-04,  5.8113e-04,\n",
       "                      -2.3958e-03, -3.0139e-03, -3.4474e-03,  5.0415e-03,  1.3576e-03,\n",
       "                      -1.3782e-03, -3.2297e-03, -2.0681e-03, -4.1282e-03, -4.1337e-03,\n",
       "                      -7.8224e-04, -4.4935e-03, -2.1192e-03, -8.8081e-04, -3.0405e-03,\n",
       "                       1.5065e-03, -2.3959e-03, -1.3025e-03, -1.6186e-03, -4.0927e-03,\n",
       "                       5.5301e-03,  5.6129e-04,  2.3473e-03], device='cuda:0')),\n",
       "             ('conv_block2.bn2.running_mean',\n",
       "              tensor([ 0.0787, -0.3392,  0.9887, -0.0120,  0.0379, -0.2758,  0.3734, -1.0299,\n",
       "                      -0.9293, -0.8329,  0.1096, -0.1198,  0.0472,  0.5440, -0.1297, -0.6881,\n",
       "                      -0.3286, -0.6120, -0.7667,  0.3771,  0.1914,  0.1670,  0.2462, -0.3797,\n",
       "                      -0.3764, -0.2502,  0.2948, -0.0381, -0.1266, -0.1852,  0.2036, -0.3266,\n",
       "                      -0.1938, -0.1868,  0.1745,  0.7424, -0.5169, -0.9934, -0.5299, -0.3540,\n",
       "                      -1.2102, -0.2220,  0.1102,  0.2094, -0.2366, -0.2040, -0.1564, -0.2843,\n",
       "                       0.1434, -0.4698, -0.3554, -0.0161, -0.1376, -0.5427,  0.1636, -0.8184,\n",
       "                      -0.2947, -0.5394,  0.2673, -0.1146, -0.0578, -0.7040, -0.1373,  0.7743,\n",
       "                      -0.2828,  0.2629, -0.8661, -0.2155, -0.4336, -0.0410, -0.3684,  0.4700,\n",
       "                       0.3489, -0.1559, -1.0038,  0.6018, -0.0353,  0.9907, -0.2128, -0.3150,\n",
       "                      -0.2603,  0.4278,  0.5059,  0.3908, -0.3520, -0.6548, -0.7267, -0.4603,\n",
       "                       0.6471,  0.1901, -0.7523, -0.2155, -0.2427,  0.6567,  0.7394, -1.0949,\n",
       "                       0.2669,  0.0961, -0.2852, -0.0686, -0.1040, -0.5096, -0.0880,  0.8213,\n",
       "                      -0.1352, -0.5466,  0.3201, -0.0670, -0.3511,  0.0519, -0.0086, -0.1134,\n",
       "                       0.0702, -0.2410, -0.1100, -0.2740, -0.1763,  0.5063,  0.4388,  0.5478,\n",
       "                      -0.5568,  0.4872, -0.0593, -1.1621,  0.0728, -0.9718,  0.3674, -0.2162],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_block2.bn2.running_var',\n",
       "              tensor([0.7330, 0.5678, 1.1715, 0.4782, 0.4686, 0.5216, 0.3350, 1.2146, 0.9990,\n",
       "                      1.0496, 0.7548, 0.7577, 0.4922, 0.9669, 0.3779, 0.7950, 0.5425, 0.9305,\n",
       "                      0.7434, 1.1276, 0.4505, 0.4076, 0.8056, 0.3646, 0.6358, 0.6615, 0.5224,\n",
       "                      0.5974, 0.7564, 0.6278, 0.5166, 0.7495, 0.6722, 0.6486, 0.5451, 0.6001,\n",
       "                      0.5033, 0.8076, 0.8784, 0.4937, 1.6839, 0.4552, 0.4402, 0.2818, 0.5994,\n",
       "                      0.8094, 0.3102, 0.4322, 0.5776, 0.4961, 0.3376, 0.7421, 0.5340, 0.6162,\n",
       "                      0.3882, 1.2846, 0.7574, 0.6297, 0.2994, 0.6044, 0.6953, 0.8418, 0.4623,\n",
       "                      0.6480, 0.7149, 0.4563, 1.2692, 0.4831, 0.9190, 0.4831, 0.5076, 0.3999,\n",
       "                      0.5995, 0.5706, 0.9303, 0.6489, 0.6034, 0.5140, 0.3637, 0.7457, 0.3060,\n",
       "                      0.3869, 0.7885, 0.8952, 0.6239, 1.1471, 0.6329, 0.5006, 0.5063, 0.4692,\n",
       "                      0.9663, 0.7278, 0.4960, 0.3629, 1.1614, 0.9601, 0.4972, 0.3935, 0.4377,\n",
       "                      0.5104, 0.7495, 0.7362, 0.6635, 0.5967, 0.6295, 0.5446, 0.5568, 0.2928,\n",
       "                      0.6089, 0.4303, 0.4581, 0.3841, 0.3882, 0.7135, 0.7779, 0.3618, 0.3073,\n",
       "                      0.4171, 0.5354, 0.5524, 0.5801, 0.3608, 0.3834, 1.3001, 0.4314, 1.4506,\n",
       "                      1.0582, 0.6044], device='cuda:0')),\n",
       "             ('conv_block2.bn2.num_batches_tracked',\n",
       "              tensor(345, device='cuda:0')),\n",
       "             ('conv_block3.conv1.weight',\n",
       "              tensor([[[[ 0.0090, -0.0207, -0.0325],\n",
       "                        [-0.0403, -0.0387, -0.0142],\n",
       "                        [ 0.0065,  0.0044, -0.0105]],\n",
       "              \n",
       "                       [[-0.0323, -0.0357, -0.0004],\n",
       "                        [ 0.0048, -0.0371, -0.0298],\n",
       "                        [ 0.0387,  0.0247, -0.0138]],\n",
       "              \n",
       "                       [[-0.0360,  0.0372, -0.0297],\n",
       "                        [ 0.0171,  0.0142, -0.0326],\n",
       "                        [-0.0369,  0.0087,  0.0238]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0349,  0.0215,  0.0052],\n",
       "                        [ 0.0163, -0.0266,  0.0283],\n",
       "                        [ 0.0403,  0.0332,  0.0330]],\n",
       "              \n",
       "                       [[ 0.0272, -0.0167,  0.0073],\n",
       "                        [-0.0042, -0.0056, -0.0204],\n",
       "                        [-0.0194,  0.0172,  0.0287]],\n",
       "              \n",
       "                       [[-0.0198,  0.0333, -0.0372],\n",
       "                        [ 0.0016,  0.0257,  0.0131],\n",
       "                        [-0.0191,  0.0096, -0.0065]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0060,  0.0158, -0.0035],\n",
       "                        [ 0.0343, -0.0351,  0.0231],\n",
       "                        [ 0.0196,  0.0132,  0.0401]],\n",
       "              \n",
       "                       [[ 0.0184,  0.0074,  0.0458],\n",
       "                        [ 0.0150,  0.0107, -0.0088],\n",
       "                        [-0.0095,  0.0320, -0.0139]],\n",
       "              \n",
       "                       [[-0.0235,  0.0070,  0.0322],\n",
       "                        [ 0.0406,  0.0033, -0.0279],\n",
       "                        [ 0.0013,  0.0010,  0.0295]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0025,  0.0136, -0.0282],\n",
       "                        [-0.0052, -0.0453,  0.0018],\n",
       "                        [-0.0390,  0.0317, -0.0114]],\n",
       "              \n",
       "                       [[ 0.0212,  0.0156,  0.0260],\n",
       "                        [-0.0214,  0.0121, -0.0357],\n",
       "                        [ 0.0275,  0.0043, -0.0320]],\n",
       "              \n",
       "                       [[ 0.0271, -0.0014,  0.0188],\n",
       "                        [-0.0017,  0.0186, -0.0004],\n",
       "                        [ 0.0335, -0.0078, -0.0299]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.0152,  0.0114],\n",
       "                        [-0.0230,  0.0310, -0.0039],\n",
       "                        [ 0.0424,  0.0150,  0.0120]],\n",
       "              \n",
       "                       [[-0.0377, -0.0292, -0.0322],\n",
       "                        [-0.0181,  0.0203,  0.0205],\n",
       "                        [ 0.0222, -0.0286, -0.0169]],\n",
       "              \n",
       "                       [[ 0.0343,  0.0309,  0.0202],\n",
       "                        [ 0.0395, -0.0069,  0.0069],\n",
       "                        [ 0.0118, -0.0240,  0.0397]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0376, -0.0049, -0.0227],\n",
       "                        [-0.0052,  0.0415,  0.0258],\n",
       "                        [-0.0390, -0.0158,  0.0168]],\n",
       "              \n",
       "                       [[-0.0159, -0.0050, -0.0139],\n",
       "                        [-0.0309, -0.0121, -0.0174],\n",
       "                        [ 0.0398, -0.0132, -0.0381]],\n",
       "              \n",
       "                       [[ 0.0133,  0.0086,  0.0321],\n",
       "                        [-0.0045, -0.0192,  0.0288],\n",
       "                        [ 0.0313, -0.0170, -0.0250]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0175, -0.0180, -0.0233],\n",
       "                        [-0.0171, -0.0427, -0.0091],\n",
       "                        [-0.0215, -0.0047, -0.0040]],\n",
       "              \n",
       "                       [[-0.0261, -0.0296,  0.0464],\n",
       "                        [-0.0409, -0.0323, -0.0071],\n",
       "                        [ 0.0245, -0.0264,  0.0241]],\n",
       "              \n",
       "                       [[ 0.0039,  0.0283,  0.0082],\n",
       "                        [-0.0209, -0.0152,  0.0042],\n",
       "                        [ 0.0172, -0.0138,  0.0351]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0214,  0.0123, -0.0458],\n",
       "                        [-0.0077, -0.0360, -0.0109],\n",
       "                        [ 0.0405, -0.0157, -0.0199]],\n",
       "              \n",
       "                       [[-0.0379,  0.0365, -0.0042],\n",
       "                        [ 0.0307, -0.0029,  0.0449],\n",
       "                        [-0.0381, -0.0213,  0.0333]],\n",
       "              \n",
       "                       [[-0.0220,  0.0060, -0.0160],\n",
       "                        [-0.0039, -0.0336, -0.0273],\n",
       "                        [ 0.0217,  0.0348,  0.0263]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0169, -0.0399,  0.0248],\n",
       "                        [ 0.0328,  0.0403, -0.0046],\n",
       "                        [-0.0309, -0.0027, -0.0235]],\n",
       "              \n",
       "                       [[-0.0064,  0.0169,  0.0300],\n",
       "                        [ 0.0097, -0.0222,  0.0299],\n",
       "                        [ 0.0203,  0.0126,  0.0094]],\n",
       "              \n",
       "                       [[ 0.0153,  0.0195,  0.0032],\n",
       "                        [-0.0230,  0.0108,  0.0348],\n",
       "                        [-0.0281,  0.0117,  0.0141]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0194, -0.0083, -0.0201],\n",
       "                        [ 0.0080, -0.0068, -0.0246],\n",
       "                        [ 0.0363, -0.0150, -0.0300]],\n",
       "              \n",
       "                       [[-0.0321, -0.0196, -0.0072],\n",
       "                        [-0.0061,  0.0326, -0.0203],\n",
       "                        [ 0.0179,  0.0021, -0.0027]],\n",
       "              \n",
       "                       [[-0.0079, -0.0323, -0.0179],\n",
       "                        [-0.0290, -0.0291,  0.0134],\n",
       "                        [-0.0322,  0.0187, -0.0434]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0449,  0.0205, -0.0313],\n",
       "                        [-0.0208,  0.0300,  0.0018],\n",
       "                        [ 0.0350, -0.0330,  0.0207]],\n",
       "              \n",
       "                       [[-0.0289,  0.0338,  0.0339],\n",
       "                        [-0.0138,  0.0070, -0.0262],\n",
       "                        [-0.0056,  0.0236, -0.0348]],\n",
       "              \n",
       "                       [[-0.0024, -0.0024,  0.0328],\n",
       "                        [-0.0077, -0.0269,  0.0374],\n",
       "                        [ 0.0006, -0.0285, -0.0182]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0065,  0.0054, -0.0287],\n",
       "                        [-0.0325, -0.0117,  0.0126],\n",
       "                        [-0.0129, -0.0352,  0.0028]],\n",
       "              \n",
       "                       [[-0.0125,  0.0083,  0.0448],\n",
       "                        [ 0.0198, -0.0333,  0.0228],\n",
       "                        [-0.0105,  0.0288,  0.0193]],\n",
       "              \n",
       "                       [[ 0.0225,  0.0195,  0.0114],\n",
       "                        [-0.0077,  0.0361, -0.0347],\n",
       "                        [-0.0115, -0.0328,  0.0158]]]], device='cuda:0')),\n",
       "             ('conv_block3.conv2.weight',\n",
       "              tensor([[[[-0.0277,  0.0046, -0.0256],\n",
       "                        [-0.0253, -0.0071,  0.0132],\n",
       "                        [ 0.0241,  0.0054, -0.0131]],\n",
       "              \n",
       "                       [[ 0.0276,  0.0248, -0.0139],\n",
       "                        [ 0.0339,  0.0181,  0.0016],\n",
       "                        [-0.0211,  0.0058, -0.0310]],\n",
       "              \n",
       "                       [[ 0.0370,  0.0211, -0.0036],\n",
       "                        [-0.0157, -0.0135, -0.0263],\n",
       "                        [-0.0226,  0.0139,  0.0163]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0169, -0.0163,  0.0190],\n",
       "                        [ 0.0233,  0.0161, -0.0038],\n",
       "                        [ 0.0161,  0.0211, -0.0310]],\n",
       "              \n",
       "                       [[ 0.0280, -0.0169, -0.0028],\n",
       "                        [-0.0331, -0.0289, -0.0258],\n",
       "                        [-0.0264, -0.0203, -0.0153]],\n",
       "              \n",
       "                       [[-0.0211,  0.0187,  0.0006],\n",
       "                        [ 0.0239, -0.0229, -0.0198],\n",
       "                        [-0.0356,  0.0233, -0.0174]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0097,  0.0320, -0.0238],\n",
       "                        [ 0.0186,  0.0252, -0.0330],\n",
       "                        [-0.0084,  0.0258, -0.0338]],\n",
       "              \n",
       "                       [[ 0.0285, -0.0360, -0.0209],\n",
       "                        [-0.0081,  0.0199, -0.0122],\n",
       "                        [-0.0028, -0.0124, -0.0220]],\n",
       "              \n",
       "                       [[-0.0129,  0.0308,  0.0383],\n",
       "                        [ 0.0291, -0.0280, -0.0301],\n",
       "                        [ 0.0098,  0.0171, -0.0339]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0367,  0.0145,  0.0234],\n",
       "                        [-0.0085,  0.0139,  0.0248],\n",
       "                        [-0.0300,  0.0154, -0.0223]],\n",
       "              \n",
       "                       [[-0.0220,  0.0020,  0.0355],\n",
       "                        [ 0.0320, -0.0106, -0.0238],\n",
       "                        [-0.0329, -0.0286, -0.0246]],\n",
       "              \n",
       "                       [[-0.0288, -0.0038,  0.0034],\n",
       "                        [ 0.0055,  0.0144, -0.0108],\n",
       "                        [ 0.0129, -0.0254,  0.0194]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0127,  0.0136, -0.0282],\n",
       "                        [ 0.0120,  0.0144,  0.0166],\n",
       "                        [ 0.0140,  0.0157,  0.0351]],\n",
       "              \n",
       "                       [[ 0.0081, -0.0174, -0.0156],\n",
       "                        [ 0.0167,  0.0160, -0.0342],\n",
       "                        [-0.0154, -0.0119,  0.0069]],\n",
       "              \n",
       "                       [[ 0.0257, -0.0063,  0.0268],\n",
       "                        [ 0.0286,  0.0090,  0.0095],\n",
       "                        [-0.0213, -0.0324, -0.0102]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0213,  0.0051,  0.0054],\n",
       "                        [-0.0305, -0.0151,  0.0237],\n",
       "                        [ 0.0256, -0.0114,  0.0226]],\n",
       "              \n",
       "                       [[ 0.0138, -0.0016, -0.0293],\n",
       "                        [-0.0003, -0.0193, -0.0392],\n",
       "                        [ 0.0295,  0.0196, -0.0111]],\n",
       "              \n",
       "                       [[-0.0313,  0.0249,  0.0296],\n",
       "                        [-0.0039, -0.0324, -0.0224],\n",
       "                        [-0.0268, -0.0074,  0.0063]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0038, -0.0400,  0.0008],\n",
       "                        [ 0.0028,  0.0154,  0.0307],\n",
       "                        [-0.0364,  0.0276,  0.0039]],\n",
       "              \n",
       "                       [[ 0.0226, -0.0218,  0.0195],\n",
       "                        [ 0.0278, -0.0003, -0.0110],\n",
       "                        [-0.0155,  0.0307,  0.0239]],\n",
       "              \n",
       "                       [[ 0.0222, -0.0266,  0.0196],\n",
       "                        [ 0.0051, -0.0064,  0.0320],\n",
       "                        [-0.0277, -0.0162, -0.0166]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0091,  0.0247, -0.0202],\n",
       "                        [-0.0291, -0.0246,  0.0131],\n",
       "                        [-0.0264,  0.0250, -0.0038]],\n",
       "              \n",
       "                       [[-0.0284, -0.0015, -0.0259],\n",
       "                        [-0.0039,  0.0224,  0.0218],\n",
       "                        [ 0.0284, -0.0116, -0.0338]],\n",
       "              \n",
       "                       [[-0.0290, -0.0103,  0.0166],\n",
       "                        [ 0.0155,  0.0253,  0.0209],\n",
       "                        [-0.0139, -0.0304,  0.0076]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0192,  0.0290,  0.0188],\n",
       "                        [-0.0204,  0.0192,  0.0126],\n",
       "                        [ 0.0213, -0.0203,  0.0035]],\n",
       "              \n",
       "                       [[-0.0355, -0.0056,  0.0112],\n",
       "                        [ 0.0007,  0.0131,  0.0286],\n",
       "                        [-0.0151,  0.0020,  0.0363]],\n",
       "              \n",
       "                       [[ 0.0107, -0.0319,  0.0095],\n",
       "                        [ 0.0047,  0.0092,  0.0361],\n",
       "                        [ 0.0077, -0.0002,  0.0030]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0216,  0.0077,  0.0269],\n",
       "                        [-0.0280,  0.0228,  0.0100],\n",
       "                        [ 0.0243,  0.0179, -0.0295]],\n",
       "              \n",
       "                       [[-0.0206,  0.0253, -0.0301],\n",
       "                        [ 0.0075,  0.0085,  0.0284],\n",
       "                        [-0.0190, -0.0231,  0.0056]],\n",
       "              \n",
       "                       [[ 0.0241,  0.0045, -0.0170],\n",
       "                        [-0.0113, -0.0074,  0.0016],\n",
       "                        [ 0.0087, -0.0122,  0.0227]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0179,  0.0359,  0.0203],\n",
       "                        [ 0.0227, -0.0174,  0.0226],\n",
       "                        [-0.0287, -0.0244,  0.0153]],\n",
       "              \n",
       "                       [[-0.0066, -0.0084, -0.0252],\n",
       "                        [ 0.0105, -0.0141,  0.0328],\n",
       "                        [-0.0293, -0.0273, -0.0340]],\n",
       "              \n",
       "                       [[ 0.0247,  0.0135,  0.0067],\n",
       "                        [-0.0025, -0.0148, -0.0356],\n",
       "                        [-0.0250, -0.0177,  0.0312]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0166,  0.0262, -0.0203],\n",
       "                        [-0.0433,  0.0192,  0.0117],\n",
       "                        [-0.0032, -0.0113,  0.0129]],\n",
       "              \n",
       "                       [[ 0.0183, -0.0179,  0.0296],\n",
       "                        [-0.0347, -0.0187,  0.0279],\n",
       "                        [ 0.0088, -0.0095, -0.0097]],\n",
       "              \n",
       "                       [[ 0.0047,  0.0315,  0.0339],\n",
       "                        [-0.0037,  0.0231,  0.0337],\n",
       "                        [-0.0053, -0.0050,  0.0087]]]], device='cuda:0')),\n",
       "             ('conv_block3.bn1.weight',\n",
       "              tensor([1.0015, 1.0006, 0.9981, 0.9979, 1.0029, 0.9967, 0.9965, 1.0008, 1.0004,\n",
       "                      0.9989, 0.9963, 0.9962, 1.0040, 0.9999, 1.0025, 1.0022, 1.0041, 1.0059,\n",
       "                      1.0015, 1.0001, 1.0035, 1.0048, 0.9982, 1.0022, 0.9964, 1.0018, 1.0029,\n",
       "                      0.9959, 0.9974, 0.9965, 1.0011, 0.9977, 0.9979, 1.0021, 0.9967, 1.0003,\n",
       "                      1.0067, 1.0031, 0.9944, 0.9975, 0.9978, 0.9971, 1.0007, 0.9997, 0.9979,\n",
       "                      0.9998, 1.0071, 1.0018, 1.0058, 1.0021, 0.9967, 0.9963, 0.9999, 1.0020,\n",
       "                      0.9980, 1.0025, 1.0002, 0.9981, 0.9961, 1.0007, 0.9967, 1.0019, 1.0001,\n",
       "                      0.9992, 1.0031, 0.9984, 0.9959, 0.9935, 1.0023, 0.9995, 1.0013, 0.9994,\n",
       "                      0.9976, 0.9974, 0.9995, 0.9975, 1.0070, 1.0003, 1.0042, 1.0059, 1.0018,\n",
       "                      1.0010, 1.0051, 1.0045, 1.0031, 1.0045, 1.0030, 1.0055, 1.0031, 1.0015,\n",
       "                      1.0038, 1.0073, 0.9973, 0.9964, 1.0049, 0.9995, 0.9933, 1.0021, 1.0013,\n",
       "                      0.9990, 1.0035, 0.9982, 0.9946, 0.9967, 0.9964, 1.0019, 1.0042, 0.9951,\n",
       "                      0.9928, 1.0062, 0.9979, 0.9987, 1.0004, 0.9977, 1.0023, 1.0036, 1.0045,\n",
       "                      0.9983, 0.9997, 0.9963, 1.0001, 1.0074, 1.0061, 1.0023, 1.0041, 0.9986,\n",
       "                      1.0004, 0.9989, 1.0022, 1.0044, 0.9995, 1.0056, 0.9963, 1.0028, 0.9981,\n",
       "                      0.9952, 0.9972, 0.9956, 0.9994, 1.0009, 1.0053, 0.9948, 1.0032, 1.0046,\n",
       "                      1.0016, 0.9986, 0.9968, 0.9978, 0.9952, 1.0032, 0.9972, 0.9994, 0.9978,\n",
       "                      1.0005, 0.9985, 0.9991, 1.0003, 0.9996, 1.0035, 1.0035, 1.0034, 1.0012,\n",
       "                      0.9976, 0.9941, 0.9967, 0.9999, 1.0008, 0.9993, 0.9953, 0.9998, 0.9963,\n",
       "                      0.9982, 0.9998, 1.0026, 0.9996, 1.0006, 0.9984, 1.0041, 1.0017, 1.0049,\n",
       "                      0.9965, 0.9985, 1.0062, 0.9964, 1.0009, 0.9968, 0.9946, 1.0041, 0.9991,\n",
       "                      0.9964, 1.0030, 0.9998, 0.9960, 0.9972, 1.0005, 1.0014, 0.9975, 0.9939,\n",
       "                      0.9954, 1.0079, 0.9981, 1.0027, 0.9987, 1.0060, 0.9994, 0.9968, 0.9979,\n",
       "                      0.9998, 0.9954, 0.9923, 1.0075, 1.0096, 0.9980, 0.9976, 0.9948, 0.9946,\n",
       "                      1.0055, 1.0021, 1.0022, 1.0034, 0.9957, 1.0009, 0.9975, 0.9980, 0.9977,\n",
       "                      0.9930, 0.9989, 0.9965, 1.0053, 1.0007, 0.9977, 0.9954, 0.9983, 0.9989,\n",
       "                      0.9973, 1.0003, 0.9992, 1.0005, 1.0000, 0.9942, 1.0019, 1.0023, 0.9978,\n",
       "                      1.0026, 0.9996, 0.9991, 0.9965, 0.9996, 1.0099, 0.9981, 0.9973, 0.9949,\n",
       "                      0.9998, 1.0012, 1.0022, 0.9971], device='cuda:0')),\n",
       "             ('conv_block3.bn1.bias',\n",
       "              tensor([ 1.2912e-03, -9.3598e-04, -2.6885e-03, -3.5617e-04,  3.4844e-03,\n",
       "                      -1.7860e-03, -4.6282e-03,  1.0714e-03,  3.7731e-03, -2.0079e-04,\n",
       "                      -5.3514e-03,  1.8985e-03,  4.9797e-03,  1.3149e-03,  7.5465e-03,\n",
       "                       1.5367e-03,  5.4168e-03,  3.1211e-03,  5.8660e-04, -1.3118e-03,\n",
       "                       5.6496e-03,  5.5119e-03,  1.1735e-04,  1.4067e-05, -1.5028e-03,\n",
       "                      -3.1683e-04,  5.2196e-03,  1.4962e-03,  1.1699e-03, -2.1321e-03,\n",
       "                       3.5937e-03, -8.2972e-04,  3.2888e-03, -1.7922e-03, -4.4020e-03,\n",
       "                       7.0141e-03,  2.9561e-03,  1.9372e-03, -1.2044e-03, -2.6528e-03,\n",
       "                       2.1553e-03, -2.4512e-03,  3.7229e-03,  3.2711e-03,  3.4516e-04,\n",
       "                       1.7542e-03,  3.1237e-03,  1.6776e-03,  4.4252e-03,  2.5039e-03,\n",
       "                      -6.5605e-03, -2.5634e-03,  1.3904e-03,  7.0755e-03, -1.0789e-03,\n",
       "                      -2.5853e-04,  1.8146e-03, -5.0577e-04, -6.2537e-03,  2.0227e-03,\n",
       "                      -3.7880e-03, -9.7212e-04,  8.7891e-04, -3.9115e-04,  1.9344e-03,\n",
       "                      -2.9380e-03, -4.5047e-03, -3.9907e-03,  3.9895e-03,  8.0920e-04,\n",
       "                       1.0236e-03, -1.4501e-03, -1.7182e-03, -1.2971e-03, -1.4697e-03,\n",
       "                      -2.3804e-03,  4.6011e-03,  5.2649e-04,  6.2106e-03,  1.3142e-03,\n",
       "                       1.0900e-02,  1.6844e-03,  4.6093e-03,  4.8413e-05,  4.1394e-03,\n",
       "                       3.4993e-03,  1.0005e-03,  7.2335e-03,  1.3060e-03, -3.4814e-04,\n",
       "                       4.1341e-03,  3.2629e-03, -1.0278e-03, -2.0380e-03,  4.1056e-03,\n",
       "                       3.1977e-03, -5.1558e-03,  3.7415e-04,  3.0519e-03,  3.6445e-04,\n",
       "                       1.2844e-03, -7.1239e-04, -2.8172e-03, -3.8337e-03, -4.2367e-03,\n",
       "                       2.0177e-03,  2.5124e-03, -3.0612e-03, -6.5534e-03,  1.8871e-03,\n",
       "                      -4.0172e-04,  4.9915e-04,  2.3502e-03, -1.6405e-03,  4.5041e-03,\n",
       "                       5.7501e-03,  4.0602e-03, -4.2183e-04,  1.0002e-03, -2.2408e-03,\n",
       "                       1.7939e-03,  5.7732e-03,  5.2615e-03, -3.6709e-04,  3.9039e-03,\n",
       "                       5.5763e-03,  5.9195e-04, -6.2621e-04, -2.3146e-04,  1.6082e-03,\n",
       "                      -3.9314e-04,  6.8980e-03, -1.5744e-03,  2.8834e-03, -3.0867e-04,\n",
       "                      -1.9961e-03, -2.4570e-03, -3.5208e-03,  6.7074e-04,  1.5775e-03,\n",
       "                       6.7339e-03, -6.2790e-04, -8.4975e-04, -8.2642e-04,  2.8638e-03,\n",
       "                      -4.5212e-04, -4.8050e-03, -1.4594e-03,  1.3709e-03,  4.2986e-03,\n",
       "                      -3.5338e-03,  2.3508e-03, -3.4068e-03,  4.4456e-03,  5.6273e-04,\n",
       "                       9.2233e-04,  1.5416e-03,  1.9954e-03,  1.2013e-03,  2.5732e-04,\n",
       "                      -6.2422e-04,  5.7516e-03, -1.2179e-03, -4.1958e-03, -4.4083e-03,\n",
       "                       1.8883e-03,  2.3311e-03,  1.4367e-04, -4.4841e-03, -2.0323e-03,\n",
       "                      -3.4242e-03, -1.3718e-03,  4.3262e-03,  3.6131e-03,  1.6797e-04,\n",
       "                       4.1042e-03, -1.2659e-03,  1.0388e-03,  8.7718e-04,  1.5719e-03,\n",
       "                      -2.9654e-03,  1.4808e-03,  2.5411e-03, -2.9716e-03, -3.1119e-04,\n",
       "                      -2.9416e-04, -3.4005e-03,  3.8597e-03, -8.8429e-04, -2.6622e-03,\n",
       "                       2.4768e-03, -1.3007e-03, -2.2778e-03, -4.2267e-03, -4.2948e-04,\n",
       "                       5.6071e-04, -2.4728e-03, -7.1332e-03, -4.3363e-03,  4.7800e-03,\n",
       "                      -3.3334e-04,  6.2282e-04,  8.9455e-05,  3.1720e-03,  2.8810e-04,\n",
       "                      -1.0478e-03,  3.2516e-04, -8.1833e-04, -2.8285e-03, -6.2078e-03,\n",
       "                       3.6903e-03,  7.7729e-03,  2.2551e-03, -2.7296e-03, -3.1375e-03,\n",
       "                      -3.8015e-03, -6.8790e-04, -4.6023e-04,  2.1730e-03, -3.0768e-04,\n",
       "                      -2.1663e-03,  3.6187e-03, -4.1200e-04,  2.0327e-04, -2.7527e-04,\n",
       "                      -5.8363e-03,  4.1367e-03, -7.0624e-04,  1.8592e-04,  3.0650e-03,\n",
       "                      -2.3391e-03, -2.8959e-03,  1.0027e-03, -6.9029e-04,  9.2897e-04,\n",
       "                      -2.9104e-03,  4.4369e-04,  3.0288e-03,  1.9328e-03, -4.4830e-03,\n",
       "                      -3.0201e-04,  1.6034e-03,  5.7371e-04, -4.8656e-05,  1.9224e-04,\n",
       "                       2.5373e-04, -4.1612e-03, -4.5286e-03,  7.9598e-03,  2.2064e-03,\n",
       "                      -5.9824e-04, -1.1124e-02,  9.2630e-04,  1.5837e-03,  1.6942e-03,\n",
       "                      -4.5575e-04], device='cuda:0')),\n",
       "             ('conv_block3.bn1.running_mean',\n",
       "              tensor([-0.8521,  0.6258, -0.4810, -0.2563, -0.3001,  0.0138, -0.0609, -0.0400,\n",
       "                       0.3124, -0.2306,  0.0283, -0.3136, -0.6078,  0.4889,  0.0995, -0.8192,\n",
       "                      -0.5139, -1.1498, -0.0929,  0.2262, -0.3780, -0.5639, -0.5734, -0.3297,\n",
       "                      -0.1809,  0.1033, -0.4062,  0.0777, -0.1393, -1.0889,  0.3239, -0.3587,\n",
       "                       0.0191, -0.4616, -0.1135,  0.2345, -0.1517,  0.0843, -0.7094,  0.0684,\n",
       "                      -0.1443,  0.0381, -0.5096, -0.0358, -0.5150,  0.0337, -1.0908,  0.4435,\n",
       "                      -0.6546, -0.3782,  0.2033, -0.1748,  0.0566, -0.2502, -0.1288, -0.5372,\n",
       "                       0.0315, -0.9068, -0.3209, -0.5144, -0.2510,  0.0148, -0.0658, -0.3859,\n",
       "                      -0.5167, -0.0072, -0.4300, -0.2382, -0.3605,  0.3258,  0.0539, -0.4560,\n",
       "                       0.5143, -0.4624,  0.0110, -0.3261, -0.1149, -0.7273, -0.4574, -0.5341,\n",
       "                       0.1894, -1.1455, -0.3974, -0.7913, -0.0937, -0.2063, -0.6998, -0.2162,\n",
       "                      -0.7036, -0.6094, -0.6686, -0.2408,  0.3778, -0.2151, -0.5509, -0.1095,\n",
       "                      -0.6086, -0.4169, -0.7056, -0.2024, -0.4556, -0.3755, -0.4744,  0.4448,\n",
       "                       0.0429, -0.3552,  0.1123,  0.0918, -0.2500,  0.0532, -0.3838,  0.0667,\n",
       "                       0.1136, -0.4975, -0.4984, -0.1119,  0.2062, -0.4720, -0.2939,  0.4039,\n",
       "                      -0.4712, -0.3124, -0.0471, -0.8368, -0.4846,  0.1053, -0.1521, -0.2224,\n",
       "                      -0.3234, -0.2777, -0.3355, -0.1319,  0.0295, -0.8133,  0.1999, -0.3629,\n",
       "                       0.3047,  0.0835, -0.2726, -0.3759, -0.4365, -0.0249, -0.4631, -0.3960,\n",
       "                      -0.6430,  0.4699,  0.7556,  0.0838, -0.2714, -0.4940, -0.2586, -0.5014,\n",
       "                       0.0923,  0.3970,  0.2878,  0.7122, -0.3710, -0.2670, -0.3823, -0.6634,\n",
       "                      -0.2909, -0.3523, -0.6176, -0.0974, -0.2037,  0.0151, -0.4890,  0.4022,\n",
       "                       0.0380, -0.0161,  0.0710, -0.8991, -0.2423, -0.3495,  0.6624, -0.5424,\n",
       "                      -0.1234,  0.2248, -0.4296, -0.4221,  0.0154, -0.6089, -0.2380, -0.0122,\n",
       "                       0.4380, -0.0734,  0.3143, -0.5971,  0.8320,  0.3823, -0.4730,  0.1397,\n",
       "                      -0.0387,  0.0495, -0.4472, -0.7486, -0.2697,  0.1144, -0.2079, -0.5611,\n",
       "                      -0.4085,  0.0545, -0.5277, -0.9413,  0.3432, -0.0738, -0.8520, -0.1573,\n",
       "                      -0.0158, -0.8829, -0.9830,  0.0869, -0.2424,  0.1691, -0.1289, -0.2818,\n",
       "                      -0.4927, -0.5299, -0.4180,  0.0852, -0.5007,  0.1459, -0.6692, -0.2263,\n",
       "                       0.1187,  0.1650, -0.2248,  0.0491, -0.8257,  0.4655, -0.0351, -0.0975,\n",
       "                      -0.2949, -0.0728, -0.0714,  0.2658, -0.4310, -0.4308, -0.0035,  0.3724,\n",
       "                      -0.1454, -0.2054, -0.5764, -0.0859,  0.4677, -0.2561,  0.1118,  0.0723,\n",
       "                      -0.4569, -0.1375, -0.6667,  0.4907,  0.1908, -0.6864, -0.3847,  0.2156],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_block3.bn1.running_var',\n",
       "              tensor([0.6691, 0.5650, 0.2344, 0.3814, 0.2417, 0.2792, 0.2395, 0.2692, 0.3257,\n",
       "                      0.5118, 0.2681, 0.3214, 0.4007, 0.2895, 0.5646, 0.8810, 0.6048, 0.8375,\n",
       "                      0.4043, 0.4346, 0.6002, 0.5268, 0.2413, 0.6582, 0.4041, 0.3277, 0.4842,\n",
       "                      0.3166, 0.3181, 0.6157, 0.3428, 0.3581, 0.2952, 0.4957, 0.7510, 0.5161,\n",
       "                      0.5400, 0.2534, 0.4177, 0.3150, 0.3299, 0.2784, 0.3822, 0.2805, 0.4472,\n",
       "                      0.3312, 0.7982, 0.4786, 0.6923, 0.5407, 0.2528, 0.4680, 0.2535, 0.4906,\n",
       "                      0.4535, 0.7276, 0.3874, 0.8897, 0.3507, 0.4130, 0.5812, 0.3762, 0.2615,\n",
       "                      0.3789, 0.7615, 0.3197, 0.2631, 0.2564, 0.4596, 0.3438, 0.3877, 0.6696,\n",
       "                      0.4498, 0.4814, 0.2674, 0.3334, 0.5528, 0.4919, 0.3308, 0.4287, 0.3987,\n",
       "                      1.0069, 0.4785, 0.8989, 0.3026, 0.3542, 0.6578, 0.5966, 0.8562, 1.1519,\n",
       "                      0.5131, 0.4183, 0.4024, 0.2932, 0.3504, 0.2531, 0.3957, 0.3759, 0.6627,\n",
       "                      0.3942, 0.6924, 0.6241, 0.4947, 0.3275, 0.3678, 0.6238, 0.4049, 0.4521,\n",
       "                      0.2131, 0.8538, 0.2109, 0.2998, 0.4001, 0.5064, 0.2701, 0.4342, 0.3527,\n",
       "                      0.3517, 0.5479, 0.5286, 0.5141, 0.4465, 0.7599, 0.7362, 0.4796, 0.2501,\n",
       "                      0.4645, 0.4508, 0.4396, 0.5041, 0.2926, 0.4872, 0.3475, 0.7430, 0.6199,\n",
       "                      0.3553, 0.6607, 0.2980, 0.3995, 0.3804, 0.4728, 0.3861, 0.6102, 0.5933,\n",
       "                      0.4640, 0.3615, 0.2525, 0.2153, 0.3160, 0.3591, 0.2764, 0.6168, 0.2718,\n",
       "                      0.4190, 0.2588, 0.3902, 0.3909, 0.2743, 0.4442, 0.6069, 0.3299, 0.3722,\n",
       "                      0.3662, 0.3200, 0.3085, 0.4597, 0.6355, 0.2357, 0.4266, 0.4161, 0.2583,\n",
       "                      0.6579, 0.2997, 0.5662, 0.3985, 0.4523, 0.3331, 0.5449, 0.5246, 0.7489,\n",
       "                      0.3624, 0.5205, 0.4234, 0.1829, 0.2959, 0.5775, 0.5991, 0.5368, 0.5820,\n",
       "                      0.2491, 0.4326, 0.3811, 0.4254, 0.3271, 0.3964, 0.9208, 0.4484, 0.2118,\n",
       "                      0.2919, 0.3917, 0.2806, 0.4838, 0.2614, 0.9219, 0.4554, 0.2059, 0.3419,\n",
       "                      0.3773, 0.3129, 0.4266, 0.6669, 0.3952, 0.3171, 0.2983, 0.3950, 0.2468,\n",
       "                      0.4565, 0.5666, 0.2442, 0.5041, 0.3643, 0.3741, 0.2478, 0.4641, 0.4169,\n",
       "                      0.1762, 0.4115, 0.2431, 0.8043, 0.6592, 0.2902, 0.2191, 0.4768, 0.4004,\n",
       "                      0.3320, 0.2940, 0.4848, 0.3895, 0.3309, 0.2770, 0.5680, 0.3831, 0.4271,\n",
       "                      0.3596, 0.2084, 0.2521, 0.3676, 0.3534, 0.6597, 0.4806, 0.4291, 0.2881,\n",
       "                      0.4055, 0.3615, 0.3178, 0.2204], device='cuda:0')),\n",
       "             ('conv_block3.bn1.num_batches_tracked',\n",
       "              tensor(345, device='cuda:0')),\n",
       "             ('conv_block3.bn2.weight',\n",
       "              tensor([0.9992, 1.0026, 1.0019, 0.9987, 0.9997, 0.9954, 0.9977, 0.9929, 0.9919,\n",
       "                      0.9994, 0.9975, 1.0015, 0.9974, 1.0009, 0.9957, 0.9983, 1.0075, 1.0099,\n",
       "                      0.9962, 1.0057, 0.9924, 0.9984, 0.9961, 1.0026, 0.9998, 0.9963, 0.9946,\n",
       "                      1.0017, 0.9998, 1.0046, 0.9972, 0.9982, 0.9972, 0.9983, 1.0045, 0.9969,\n",
       "                      1.0003, 1.0052, 0.9996, 0.9984, 0.9951, 0.9947, 1.0006, 1.0050, 1.0028,\n",
       "                      0.9990, 0.9984, 1.0008, 1.0015, 0.9951, 1.0014, 0.9974, 1.0031, 0.9957,\n",
       "                      1.0004, 1.0060, 0.9986, 1.0016, 0.9988, 1.0012, 0.9971, 1.0001, 1.0051,\n",
       "                      0.9922, 0.9968, 1.0013, 1.0011, 1.0035, 1.0002, 0.9972, 0.9994, 1.0028,\n",
       "                      1.0051, 0.9970, 1.0009, 1.0069, 0.9970, 1.0018, 1.0035, 1.0043, 1.0035,\n",
       "                      1.0002, 0.9993, 1.0054, 0.9986, 1.0029, 1.0040, 0.9994, 1.0002, 0.9974,\n",
       "                      1.0002, 0.9962, 1.0038, 0.9971, 0.9974, 0.9981, 0.9992, 1.0034, 0.9956,\n",
       "                      0.9984, 0.9971, 0.9994, 0.9949, 0.9996, 0.9971, 1.0052, 0.9980, 0.9968,\n",
       "                      1.0019, 1.0038, 0.9964, 1.0034, 0.9964, 0.9994, 1.0027, 1.0012, 0.9972,\n",
       "                      1.0043, 0.9992, 1.0072, 1.0019, 0.9969, 1.0016, 0.9973, 0.9976, 1.0002,\n",
       "                      1.0000, 0.9992, 1.0010, 1.0032, 0.9978, 1.0015, 1.0055, 1.0008, 1.0071,\n",
       "                      1.0014, 0.9999, 0.9970, 1.0073, 0.9978, 0.9962, 0.9956, 0.9946, 0.9958,\n",
       "                      1.0004, 0.9994, 1.0019, 1.0020, 0.9984, 0.9961, 1.0059, 1.0064, 0.9939,\n",
       "                      1.0023, 1.0054, 1.0023, 1.0082, 1.0076, 1.0008, 0.9995, 1.0010, 1.0016,\n",
       "                      0.9965, 1.0020, 0.9996, 0.9979, 1.0058, 0.9993, 1.0030, 0.9960, 0.9999,\n",
       "                      1.0055, 1.0020, 0.9975, 0.9953, 1.0009, 0.9942, 0.9963, 0.9999, 1.0019,\n",
       "                      1.0007, 1.0030, 0.9969, 0.9976, 1.0009, 0.9961, 1.0046, 0.9939, 0.9913,\n",
       "                      1.0058, 0.9997, 0.9942, 0.9994, 0.9979, 0.9948, 1.0046, 1.0002, 0.9961,\n",
       "                      1.0013, 1.0006, 1.0042, 0.9971, 0.9978, 0.9955, 1.0034, 0.9966, 1.0055,\n",
       "                      0.9980, 0.9991, 0.9987, 0.9964, 0.9977, 1.0032, 0.9964, 1.0049, 0.9993,\n",
       "                      0.9981, 1.0002, 1.0008, 0.9978, 1.0013, 1.0005, 1.0037, 1.0058, 1.0032,\n",
       "                      0.9963, 1.0035, 0.9989, 0.9957, 1.0021, 1.0000, 1.0019, 1.0051, 1.0037,\n",
       "                      0.9990, 0.9986, 1.0020, 0.9956, 0.9954, 1.0086, 1.0024, 1.0017, 0.9954,\n",
       "                      0.9962, 0.9999, 1.0029, 1.0024, 1.0041, 1.0019, 1.0029, 1.0019, 0.9990,\n",
       "                      1.0065, 0.9981, 1.0041, 1.0033], device='cuda:0')),\n",
       "             ('conv_block3.bn2.bias',\n",
       "              tensor([-4.1248e-03,  5.9894e-04, -2.5059e-03,  3.6934e-03, -2.8438e-03,\n",
       "                      -2.0902e-03, -3.0854e-03, -8.2733e-03, -6.1897e-03,  8.5059e-04,\n",
       "                      -3.7719e-03, -5.0302e-03,  1.2049e-03,  2.3958e-03, -1.2595e-03,\n",
       "                      -3.3506e-03,  2.5789e-03,  5.2191e-03, -6.6453e-03,  2.1512e-03,\n",
       "                      -8.4907e-03,  2.9153e-04, -4.7535e-03,  2.1115e-03,  1.0893e-03,\n",
       "                      -3.6257e-03, -5.1998e-03,  2.6384e-03, -8.1855e-04,  2.9253e-03,\n",
       "                      -2.1460e-03,  1.6369e-03, -1.7408e-03, -2.7085e-03,  7.3122e-03,\n",
       "                      -3.7318e-03,  2.1839e-03,  1.6294e-03,  1.0393e-03,  2.3115e-03,\n",
       "                      -5.1376e-03, -7.0440e-03,  3.4596e-03,  1.3782e-03, -8.2202e-04,\n",
       "                       1.1087e-04, -6.1010e-05, -2.3181e-03,  2.9002e-03, -4.7096e-03,\n",
       "                       1.1585e-03, -1.9022e-03,  4.1462e-03, -3.2561e-03,  5.0371e-03,\n",
       "                       1.1090e-02, -6.6178e-04, -6.2897e-04, -1.8918e-03,  1.8297e-03,\n",
       "                      -3.7821e-03,  6.3178e-04,  2.8702e-04, -6.9529e-03, -4.5309e-03,\n",
       "                      -3.5315e-03, -2.9438e-04,  2.5528e-03,  3.9874e-03, -2.7743e-03,\n",
       "                      -2.8664e-03,  9.3269e-04,  2.1088e-04, -9.3654e-04,  4.3383e-03,\n",
       "                       1.3488e-03, -6.8143e-03,  3.8719e-04,  3.5255e-03,  2.1588e-03,\n",
       "                      -1.5190e-03,  2.5899e-05,  3.1370e-03,  3.9431e-03, -3.0003e-03,\n",
       "                       5.6681e-03, -4.2502e-03,  2.2264e-03,  6.6050e-04, -5.8613e-03,\n",
       "                       1.1251e-03, -1.2100e-02,  2.0521e-03, -4.3470e-03, -6.4711e-03,\n",
       "                       5.4116e-04,  3.1742e-03,  6.9883e-04, -2.4207e-03, -4.9277e-04,\n",
       "                      -4.2041e-03,  1.8005e-03, -2.0960e-03, -4.9467e-03,  1.3653e-03,\n",
       "                       3.6024e-03,  1.3193e-04,  1.6370e-03,  1.6724e-03, -3.7187e-04,\n",
       "                      -5.0664e-03,  4.4422e-04, -6.7363e-03, -5.7466e-05, -3.3629e-04,\n",
       "                       5.0012e-04, -3.3139e-03, -2.7508e-03,  2.4160e-03, -6.6513e-04,\n",
       "                      -8.2108e-04, -4.2335e-03, -2.4540e-03, -5.3659e-04, -3.3970e-03,\n",
       "                       1.4113e-03, -7.7199e-04,  2.7527e-03,  2.5754e-03,  1.7090e-03,\n",
       "                      -6.6515e-03, -4.9991e-03,  9.2229e-04, -6.8900e-04, -3.3734e-03,\n",
       "                       5.5108e-03, -4.2979e-04, -9.0354e-04,  4.4465e-03, -5.3390e-04,\n",
       "                      -2.0129e-03, -3.7368e-03, -1.0783e-02, -2.9845e-03, -3.1239e-03,\n",
       "                      -2.4796e-03,  9.4780e-04, -5.1192e-03,  3.5294e-03, -5.6165e-03,\n",
       "                       1.4797e-03,  4.7676e-03, -4.8358e-03,  2.0597e-03,  8.4959e-03,\n",
       "                       6.9953e-03,  1.7164e-03,  2.9933e-03, -1.2378e-03,  9.6051e-04,\n",
       "                       2.4834e-03,  3.2778e-03, -5.3461e-03,  4.5867e-03,  8.7926e-04,\n",
       "                       1.2074e-03,  6.7203e-03, -2.6171e-03,  7.3322e-03, -4.9683e-03,\n",
       "                       4.9937e-03,  2.0208e-03, -3.1553e-03,  9.5146e-04, -3.7444e-03,\n",
       "                       2.5078e-03, -6.6097e-03, -3.4634e-03,  1.0104e-03,  3.9153e-03,\n",
       "                       6.5540e-04,  2.7070e-03, -4.9656e-03, -1.3037e-03,  2.6790e-03,\n",
       "                      -1.2999e-03,  7.5138e-03, -9.7520e-03, -7.0555e-03,  5.8536e-03,\n",
       "                       2.5613e-03, -1.0584e-02,  2.6848e-03, -2.9643e-03, -5.0703e-03,\n",
       "                       6.9830e-03, -2.1393e-04, -3.4262e-03, -4.0881e-03,  2.2914e-03,\n",
       "                      -2.6057e-03, -2.7508e-03,  3.6397e-03, -6.7332e-03,  2.4788e-03,\n",
       "                       2.4171e-05,  2.9412e-03, -1.1008e-03, -2.7521e-04, -1.1172e-03,\n",
       "                       4.6938e-05, -4.5466e-03,  5.8479e-03,  1.3214e-03, -7.2292e-04,\n",
       "                      -2.6839e-03, -2.3630e-03,  3.6045e-04, -6.6775e-04, -1.9429e-03,\n",
       "                       3.2699e-03, -9.9076e-04,  8.2526e-03,  1.7788e-03, -2.0847e-04,\n",
       "                      -1.9842e-03,  3.6714e-03,  1.3100e-04, -5.3701e-03, -4.2524e-04,\n",
       "                      -1.0145e-03,  5.6569e-03,  4.8833e-03, -2.2337e-05,  1.2303e-03,\n",
       "                      -3.2765e-03,  7.2428e-04, -6.9315e-03, -1.9758e-03,  6.1938e-03,\n",
       "                       4.9396e-03,  7.5099e-05, -5.3220e-03, -4.2052e-03,  2.2159e-03,\n",
       "                       4.0999e-03, -1.3795e-03,  4.4861e-03,  4.5482e-03,  1.1663e-03,\n",
       "                      -1.9209e-03,  3.3038e-03, -3.6966e-03, -1.6084e-03, -9.9916e-05,\n",
       "                       1.2729e-03], device='cuda:0')),\n",
       "             ('conv_block3.bn2.running_mean',\n",
       "              tensor([-2.4936e-02, -5.1588e-01, -2.7368e-01, -4.1709e-01, -5.2422e-01,\n",
       "                      -1.6179e+00,  4.2950e-01, -3.7600e-01,  7.4941e-02, -5.0331e-01,\n",
       "                      -1.2658e+00, -5.9163e-01, -3.1835e-01, -7.4379e-01,  7.6591e-01,\n",
       "                      -8.9033e-01, -1.0105e+00, -1.4326e+00, -6.8252e-01, -3.2050e-01,\n",
       "                      -9.1290e-01, -1.1268e-01, -7.3259e-01, -5.1475e-01, -1.1130e+00,\n",
       "                      -6.4882e-01,  2.8636e-01, -6.0012e-01, -6.7725e-01, -3.1182e-01,\n",
       "                      -8.4294e-01, -1.2294e-01, -4.2072e-01,  7.3466e-01, -1.1662e+00,\n",
       "                       2.6381e-01, -4.5001e-01, -4.5862e-01, -4.0647e-01, -2.6939e-01,\n",
       "                      -8.1027e-01,  2.2996e-01, -1.5985e-01, -1.1986e-01, -9.5222e-01,\n",
       "                      -2.6416e-01, -9.9985e-01, -4.3624e-01, -8.5028e-01, -3.6025e-01,\n",
       "                      -9.8885e-01, -5.3394e-01, -9.2612e-01, -1.5955e-01, -6.9785e-01,\n",
       "                      -7.9409e-01,  5.1435e-01, -9.3262e-01, -7.0724e-02,  3.0585e-01,\n",
       "                       6.1432e-01, -3.0922e-01, -2.8733e-01, -4.2268e-01, -5.5275e-01,\n",
       "                      -2.3861e-01, -6.3384e-01, -8.7855e-01, -4.9957e-01, -6.5090e-01,\n",
       "                       2.6251e-01, -7.6223e-01, -2.5290e-01,  3.2235e-01, -7.4967e-01,\n",
       "                      -9.0596e-01, -1.1333e+00, -3.0800e-01, -6.2384e-01, -1.2790e+00,\n",
       "                      -7.7235e-01,  4.0349e-01, -1.0929e-01, -3.3925e-01,  1.1187e-01,\n",
       "                      -1.4806e-01, -7.7138e-01, -7.0771e-01, -1.0180e+00,  5.7352e-01,\n",
       "                       3.5517e-01,  1.5430e+00, -7.5973e-01,  8.8514e-01, -6.5835e-01,\n",
       "                      -7.6709e-01, -5.6977e-01, -4.1381e-01, -7.1464e-01, -8.1043e-01,\n",
       "                      -7.7710e-01, -1.1071e-01, -1.0984e+00, -1.7341e-01, -4.0087e-01,\n",
       "                      -3.4742e-01, -6.5889e-01, -1.3499e-01,  5.0818e-01, -1.0087e+00,\n",
       "                      -1.5258e+00, -7.8488e-01,  1.0937e+00,  5.1690e-01, -3.7784e-01,\n",
       "                      -1.1034e+00, -3.0825e-01, -4.3233e-01, -3.8569e-01, -3.9959e-01,\n",
       "                      -3.2478e-01,  5.9287e-01, -1.1829e-01, -7.7809e-01, -5.4937e-02,\n",
       "                      -6.9682e-01, -5.5283e-01, -9.0019e-01,  1.2096e-01, -4.8121e-01,\n",
       "                      -5.4483e-01, -3.5161e-01, -8.0529e-01, -2.9739e-01, -8.0601e-02,\n",
       "                      -3.5650e-01, -7.2960e-01, -1.1909e+00, -4.3521e-01,  5.5656e-01,\n",
       "                      -1.6122e+00,  1.9932e-01, -6.9625e-01, -3.4903e-01, -9.3794e-01,\n",
       "                      -1.4432e-01, -8.3289e-01, -2.7646e-01,  2.0223e-01, -5.4662e-01,\n",
       "                      -5.1025e-01, -6.1962e-01,  2.2659e-01, -9.2318e-01, -4.5061e-02,\n",
       "                      -9.6320e-01, -4.3677e-01, -4.6334e-01, -7.3379e-01,  5.7628e-01,\n",
       "                       7.5964e-02, -1.6089e-01, -3.9879e-01, -3.6885e-01, -9.6621e-01,\n",
       "                      -9.5816e-01, -5.7447e-01, -2.5028e-02, -5.9036e-01,  4.3447e-01,\n",
       "                      -2.1717e-01, -2.8644e-01, -1.0720e-01, -8.9452e-01,  4.1474e-01,\n",
       "                      -8.9076e-01, -7.4972e-01, -3.6538e-02, -9.8779e-01,  8.4604e-02,\n",
       "                      -1.5959e-01, -6.4458e-01, -3.3960e-01, -7.8661e-01, -7.1266e-01,\n",
       "                      -5.7874e-02, -4.7877e-01,  3.3355e-01, -8.3780e-01, -3.5191e-01,\n",
       "                      -5.4561e-01,  5.5593e-01, -4.3863e-01, -1.0737e+00, -5.9714e-01,\n",
       "                      -1.1878e+00, -7.5143e-01, -2.8373e-01, -2.7329e-01, -3.5019e-01,\n",
       "                      -4.5660e-01, -1.0805e+00, -1.0456e+00,  6.3098e-01, -6.4620e-01,\n",
       "                      -1.1486e+00, -4.2511e-01,  2.5515e-02,  1.2295e-01, -2.5897e-01,\n",
       "                      -4.9462e-02, -4.9141e-01, -7.3448e-01, -8.7293e-01, -1.3395e-01,\n",
       "                      -7.1552e-01, -4.3522e-01, -1.1443e+00, -7.5240e-01, -5.5630e-01,\n",
       "                      -7.5777e-01,  1.2662e+00, -1.8671e-01, -3.1838e-01, -4.7753e-01,\n",
       "                      -9.5293e-01, -5.7674e-01,  3.7395e-01,  2.9918e-01, -2.3180e-01,\n",
       "                      -7.5406e-01, -5.0830e-01, -4.0175e-04, -3.9121e-01,  4.0738e-02,\n",
       "                      -1.3882e+00, -1.7194e-01, -2.5895e-01, -6.7938e-01, -1.8355e-01,\n",
       "                      -9.6376e-01, -1.8492e-01, -1.0317e+00,  6.4763e-01, -1.0738e+00,\n",
       "                      -9.9281e-01, -2.5719e-01, -1.0625e+00, -4.5330e-01, -4.0895e-01,\n",
       "                      -7.7532e-01,  2.1302e-01,  1.3848e-02, -6.8122e-01, -5.4703e-01,\n",
       "                      -6.3299e-01], device='cuda:0')),\n",
       "             ('conv_block3.bn2.running_var',\n",
       "              tensor([1.2633, 0.9497, 1.0542, 1.2069, 1.0460, 0.8039, 0.9286, 0.7584, 0.6047,\n",
       "                      0.5781, 1.6009, 1.0522, 0.8949, 1.0608, 0.8196, 0.5761, 1.1432, 1.5537,\n",
       "                      0.8579, 1.8117, 0.6161, 0.8262, 0.8674, 0.8772, 1.0512, 0.9795, 1.2602,\n",
       "                      0.9131, 0.9281, 1.2078, 1.0133, 0.6716, 0.7617, 0.6994, 0.7432, 1.6158,\n",
       "                      1.2487, 0.9849, 1.5891, 1.4624, 1.2085, 0.7254, 0.6751, 1.0282, 1.7048,\n",
       "                      1.2554, 0.8478, 1.1574, 1.2215, 0.7386, 0.6472, 0.6725, 1.0399, 0.6331,\n",
       "                      0.7652, 1.7497, 1.1543, 0.6353, 0.8616, 0.6079, 0.9118, 1.0839, 1.4067,\n",
       "                      0.6541, 0.7686, 1.5864, 0.8861, 0.9814, 1.4920, 1.1121, 1.0229, 0.9013,\n",
       "                      1.6398, 1.2570, 0.4578, 1.2101, 1.2163, 0.9123, 1.5228, 0.8184, 1.4410,\n",
       "                      1.1394, 1.5759, 1.1004, 0.5940, 1.1760, 1.7437, 0.7005, 0.8631, 0.9752,\n",
       "                      1.3542, 0.8535, 0.9238, 0.3160, 0.6836, 0.6632, 0.7732, 0.9023, 1.0936,\n",
       "                      1.0353, 0.8191, 0.8916, 0.5319, 1.0327, 1.0747, 0.9891, 0.8514, 0.6532,\n",
       "                      1.0541, 1.4814, 1.6885, 1.2336, 0.7298, 1.3791, 1.0853, 1.4155, 1.3330,\n",
       "                      1.2806, 0.6675, 1.4513, 1.1617, 0.6965, 1.8915, 0.7048, 1.0662, 0.9363,\n",
       "                      0.9807, 1.1390, 1.3614, 1.2799, 1.0217, 0.7576, 1.1754, 1.2840, 1.3033,\n",
       "                      1.4828, 1.2137, 0.7409, 1.6957, 0.8834, 1.2788, 0.8041, 0.9777, 1.0086,\n",
       "                      0.9231, 0.8228, 0.6090, 1.2189, 1.2013, 0.7769, 1.0241, 0.7713, 1.3273,\n",
       "                      1.2053, 1.9012, 0.8578, 1.2200, 1.6646, 0.7871, 1.6299, 0.6559, 1.4011,\n",
       "                      1.0841, 0.9463, 0.8969, 0.8931, 1.4797, 0.8940, 1.0926, 0.9184, 1.7247,\n",
       "                      1.1471, 1.2299, 0.8349, 0.7394, 0.4817, 0.9672, 0.7791, 1.1891, 0.7879,\n",
       "                      0.7297, 0.8812, 1.2665, 0.5989, 0.9926, 0.7584, 1.3491, 0.4694, 0.9340,\n",
       "                      0.9396, 0.9699, 0.7831, 1.0719, 0.8368, 0.6229, 1.4585, 2.0138, 0.6721,\n",
       "                      1.2115, 0.8847, 1.1226, 0.8177, 0.7322, 0.5712, 0.9745, 0.8342, 1.5787,\n",
       "                      1.2099, 0.6385, 1.1034, 1.2213, 0.7602, 0.7544, 0.5796, 0.7681, 0.9169,\n",
       "                      0.7765, 1.1627, 0.9086, 1.0301, 0.8496, 1.1596, 0.9149, 1.4730, 0.7903,\n",
       "                      0.8171, 0.9190, 0.5702, 1.0001, 1.3432, 1.3699, 1.0278, 1.1330, 1.4986,\n",
       "                      0.7763, 0.7597, 0.9055, 0.9568, 0.7309, 1.8624, 0.9486, 1.0088, 0.8084,\n",
       "                      0.8699, 1.0471, 0.8386, 1.8398, 0.9932, 1.0877, 0.7111, 1.5913, 0.8559,\n",
       "                      1.4242, 0.8380, 0.9553, 1.1908], device='cuda:0')),\n",
       "             ('conv_block3.bn2.num_batches_tracked',\n",
       "              tensor(345, device='cuda:0')),\n",
       "             ('conv_block4.conv1.weight',\n",
       "              tensor([[[[-3.2227e-02,  1.4146e-03, -2.3756e-03],\n",
       "                        [-9.4339e-03,  5.8236e-05, -9.7479e-03],\n",
       "                        [-5.8599e-03,  1.6807e-02, -1.2654e-02]],\n",
       "              \n",
       "                       [[-3.0301e-02,  1.7280e-02,  9.7471e-03],\n",
       "                        [ 2.5020e-02, -2.9675e-02, -3.6770e-03],\n",
       "                        [ 2.4286e-02,  1.3799e-02, -1.7176e-02]],\n",
       "              \n",
       "                       [[-1.4962e-02, -1.8614e-02, -2.7883e-02],\n",
       "                        [-1.4416e-02,  1.0218e-02,  6.4477e-04],\n",
       "                        [-8.3292e-03,  2.2489e-02,  2.4465e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-9.6414e-03, -2.3272e-02, -3.0263e-03],\n",
       "                        [ 1.6577e-02,  6.4827e-03,  2.0282e-02],\n",
       "                        [-2.6074e-02,  2.2389e-02,  1.6167e-03]],\n",
       "              \n",
       "                       [[ 1.7632e-02,  2.5863e-02,  2.1397e-02],\n",
       "                        [-1.0403e-02, -2.2617e-02,  2.5800e-02],\n",
       "                        [ 1.2846e-02, -2.9110e-03, -3.1188e-02]],\n",
       "              \n",
       "                       [[-3.2633e-03, -2.8463e-02, -8.8589e-03],\n",
       "                        [ 7.3473e-03,  1.7836e-02, -1.2337e-02],\n",
       "                        [-1.2298e-03, -2.5857e-02,  2.1890e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1010e-02,  7.1533e-04,  2.9377e-03],\n",
       "                        [-2.8995e-02,  1.4403e-02, -2.1989e-02],\n",
       "                        [-1.7710e-02,  1.9138e-02, -2.5882e-02]],\n",
       "              \n",
       "                       [[-1.1728e-02,  2.8336e-02,  1.6591e-03],\n",
       "                        [ 2.6904e-02,  2.8018e-03, -3.1420e-02],\n",
       "                        [-6.5211e-03,  8.9799e-03, -3.5308e-03]],\n",
       "              \n",
       "                       [[ 1.4166e-02, -2.0899e-02, -2.3763e-02],\n",
       "                        [ 1.3660e-02, -1.4693e-02,  1.5179e-02],\n",
       "                        [ 1.9283e-02,  1.1946e-02, -6.9908e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.8721e-03,  1.1423e-02, -2.1865e-02],\n",
       "                        [-2.9589e-02, -2.5019e-02,  1.1829e-02],\n",
       "                        [ 3.6191e-03, -8.7145e-03, -2.7728e-02]],\n",
       "              \n",
       "                       [[-1.1030e-02, -1.9294e-04, -5.7309e-03],\n",
       "                        [ 3.8769e-03,  2.2207e-02,  1.8115e-02],\n",
       "                        [-3.2110e-03,  2.3688e-02, -2.7980e-02]],\n",
       "              \n",
       "                       [[ 4.7681e-03, -2.7638e-02, -1.7589e-02],\n",
       "                        [ 2.9941e-02, -1.2690e-02,  1.3158e-02],\n",
       "                        [ 1.8117e-02, -2.4394e-02,  1.3490e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4519e-02, -2.4086e-02, -7.7748e-03],\n",
       "                        [ 1.3493e-02,  1.0294e-02,  2.5448e-02],\n",
       "                        [-2.2655e-02,  1.2586e-02, -2.3290e-02]],\n",
       "              \n",
       "                       [[-2.8534e-02,  3.0817e-03, -3.4209e-02],\n",
       "                        [-1.0476e-02,  4.6846e-03,  2.2671e-02],\n",
       "                        [-3.1298e-02, -1.8559e-02, -1.1320e-02]],\n",
       "              \n",
       "                       [[-1.2683e-02,  2.4517e-02, -1.5693e-02],\n",
       "                        [-2.3858e-02, -4.9103e-03,  2.0288e-02],\n",
       "                        [-1.3726e-02, -2.8121e-02,  2.9203e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.6349e-02, -1.8010e-02,  3.3909e-03],\n",
       "                        [-1.9235e-04, -5.4999e-03, -2.7740e-02],\n",
       "                        [ 1.8521e-02,  3.5620e-03,  1.3523e-02]],\n",
       "              \n",
       "                       [[ 6.9694e-03,  1.5516e-02,  1.3171e-02],\n",
       "                        [-1.3921e-02,  1.9859e-02,  1.5425e-02],\n",
       "                        [-1.1327e-02, -1.4019e-02, -1.5383e-03]],\n",
       "              \n",
       "                       [[ 5.2981e-03,  2.2374e-02,  4.8753e-03],\n",
       "                        [ 3.0782e-03, -1.6850e-02,  2.8760e-03],\n",
       "                        [ 1.8025e-02, -6.2018e-03, -1.8631e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2972e-02, -1.4093e-03, -1.0589e-03],\n",
       "                        [-2.4138e-02, -1.9537e-03,  7.4368e-03],\n",
       "                        [ 7.2102e-03, -1.3312e-02, -2.1645e-02]],\n",
       "              \n",
       "                       [[-1.5680e-02, -8.8449e-03,  1.1404e-02],\n",
       "                        [ 1.3442e-02,  2.3259e-02, -1.2344e-02],\n",
       "                        [-1.5646e-02, -2.7412e-02,  1.8440e-02]],\n",
       "              \n",
       "                       [[-4.4973e-03, -2.7509e-02,  3.9913e-04],\n",
       "                        [ 1.7087e-02,  1.2929e-02, -1.5944e-02],\n",
       "                        [-2.6571e-02, -2.6075e-02, -1.2785e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.4376e-02, -2.7013e-02,  5.5569e-03],\n",
       "                        [ 2.0486e-02, -2.0256e-02,  5.6229e-03],\n",
       "                        [-1.7744e-02,  2.0186e-02,  1.8709e-02]],\n",
       "              \n",
       "                       [[ 2.4443e-02,  2.9761e-02, -1.4959e-02],\n",
       "                        [ 6.1173e-03, -2.2447e-02,  1.6960e-02],\n",
       "                        [ 2.2442e-02, -2.2722e-02,  8.3623e-03]],\n",
       "              \n",
       "                       [[ 2.7179e-02, -4.2823e-04,  2.8010e-02],\n",
       "                        [-1.9582e-02,  1.2518e-02, -5.6962e-03],\n",
       "                        [-2.0385e-02,  1.1986e-02, -1.6286e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0933e-02,  1.5831e-02, -2.4267e-02],\n",
       "                        [-2.7464e-02, -2.5870e-02,  3.0044e-03],\n",
       "                        [-2.5895e-02,  2.1554e-02, -6.5854e-03]],\n",
       "              \n",
       "                       [[-2.3199e-03, -9.5303e-03,  9.3265e-03],\n",
       "                        [ 1.5818e-02,  2.3101e-02, -4.3522e-03],\n",
       "                        [-2.2935e-02,  2.0290e-02, -1.1574e-02]],\n",
       "              \n",
       "                       [[-1.7867e-02,  2.4589e-02,  2.6258e-02],\n",
       "                        [-2.0498e-02,  2.6606e-03,  6.2052e-03],\n",
       "                        [-1.5152e-02,  2.0247e-02,  3.0533e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0492e-02,  1.0912e-02,  1.4425e-02],\n",
       "                        [ 1.0661e-02, -3.2709e-03, -2.1953e-02],\n",
       "                        [-2.4295e-02,  8.7317e-03, -9.4750e-03]],\n",
       "              \n",
       "                       [[-1.6347e-02, -1.3974e-02,  2.8065e-02],\n",
       "                        [-2.5236e-02,  2.3493e-02,  5.7868e-03],\n",
       "                        [-2.9804e-02, -5.0073e-04, -2.9036e-02]],\n",
       "              \n",
       "                       [[-2.2634e-03,  2.6783e-02, -2.4223e-03],\n",
       "                        [ 1.6092e-02, -2.3260e-02,  1.9960e-02],\n",
       "                        [ 1.1904e-02, -2.8787e-02, -1.8256e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5221e-02, -4.0207e-03,  1.2077e-02],\n",
       "                        [ 1.6572e-02,  2.9754e-02, -9.8189e-03],\n",
       "                        [-1.4731e-02,  5.1503e-03, -1.1594e-02]],\n",
       "              \n",
       "                       [[-4.5653e-03, -2.7143e-02,  6.4737e-04],\n",
       "                        [-4.8753e-03, -1.0191e-03,  2.9807e-02],\n",
       "                        [-1.4116e-03, -2.4940e-02,  1.6666e-02]],\n",
       "              \n",
       "                       [[ 1.4358e-02, -2.6934e-02, -1.8330e-02],\n",
       "                        [-2.9030e-02, -1.2796e-02, -1.4217e-02],\n",
       "                        [-2.5548e-02, -5.8329e-03, -1.3242e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.9150e-02,  1.5213e-03,  1.2081e-03],\n",
       "                        [-1.4199e-02, -2.4718e-02,  2.3922e-02],\n",
       "                        [ 1.1131e-02, -1.9632e-02,  1.1709e-02]],\n",
       "              \n",
       "                       [[-1.4171e-02, -1.9195e-02,  4.4042e-03],\n",
       "                        [-4.3469e-03, -1.1523e-03, -2.8728e-02],\n",
       "                        [ 1.6604e-02,  2.5183e-02,  6.0388e-03]],\n",
       "              \n",
       "                       [[-1.8676e-02,  2.8930e-03,  7.4336e-03],\n",
       "                        [-5.5992e-03,  2.7227e-02,  2.5253e-02],\n",
       "                        [-1.0558e-02, -8.5010e-03,  1.7189e-02]]]], device='cuda:0')),\n",
       "             ('conv_block4.conv2.weight',\n",
       "              tensor([[[[ 1.6875e-02,  2.4629e-02, -1.5262e-02],\n",
       "                        [-1.9007e-02,  1.4541e-02,  1.3800e-02],\n",
       "                        [ 8.9440e-03, -1.1572e-02, -1.1703e-03]],\n",
       "              \n",
       "                       [[ 2.1637e-02,  9.1454e-03, -1.8056e-02],\n",
       "                        [ 6.5420e-03, -1.4011e-02, -2.2744e-03],\n",
       "                        [ 7.1497e-03, -1.0890e-02,  2.4875e-02]],\n",
       "              \n",
       "                       [[-2.8301e-02,  3.0929e-04, -3.1996e-03],\n",
       "                        [ 3.5949e-03,  1.9537e-02,  5.0147e-03],\n",
       "                        [ 1.6779e-02, -1.0890e-02, -4.7139e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.4228e-02, -7.5144e-03,  9.0177e-03],\n",
       "                        [ 5.7863e-03,  1.0646e-02, -1.3667e-02],\n",
       "                        [-1.6442e-02, -1.2609e-02, -2.8473e-03]],\n",
       "              \n",
       "                       [[-1.7376e-03, -2.2805e-02,  3.3383e-03],\n",
       "                        [ 1.1012e-02,  3.6871e-03, -9.5880e-03],\n",
       "                        [ 1.0915e-02,  9.8690e-03, -6.4859e-03]],\n",
       "              \n",
       "                       [[ 1.7125e-03,  1.9805e-02,  8.4318e-03],\n",
       "                        [ 3.2757e-03,  2.4893e-02,  9.2818e-03],\n",
       "                        [-1.3430e-02,  4.9846e-03,  3.6261e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.8346e-02, -1.8603e-03,  1.4393e-02],\n",
       "                        [ 7.5447e-03,  1.7998e-02,  2.0331e-02],\n",
       "                        [ 2.4309e-02, -1.3373e-03,  3.9902e-03]],\n",
       "              \n",
       "                       [[ 1.1244e-02, -2.3078e-02,  2.6428e-02],\n",
       "                        [-1.2719e-02, -2.1215e-02, -8.8075e-03],\n",
       "                        [-1.6543e-03,  1.5170e-02,  7.3795e-03]],\n",
       "              \n",
       "                       [[-1.2955e-03,  1.3000e-02, -2.7656e-03],\n",
       "                        [ 1.4089e-02,  1.3436e-02,  7.4102e-03],\n",
       "                        [ 4.8458e-03,  1.9638e-02, -1.8307e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.8774e-02,  7.1299e-03,  2.0775e-02],\n",
       "                        [-1.8528e-02,  3.5551e-03,  1.8373e-02],\n",
       "                        [-1.1129e-02,  1.7335e-02, -8.9444e-03]],\n",
       "              \n",
       "                       [[ 1.6557e-02,  1.9802e-02,  1.3984e-02],\n",
       "                        [ 2.7611e-03,  1.9556e-02,  2.1937e-02],\n",
       "                        [ 2.4883e-02,  1.2022e-02, -2.4147e-02]],\n",
       "              \n",
       "                       [[-4.1551e-03, -2.8041e-02,  1.1001e-02],\n",
       "                        [ 1.5872e-02,  1.6025e-02, -1.9651e-02],\n",
       "                        [ 5.1927e-03, -2.2155e-02,  5.4073e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2076e-02,  6.5427e-03,  1.6970e-02],\n",
       "                        [ 2.0701e-02, -8.1630e-03, -9.8001e-03],\n",
       "                        [-1.9512e-02,  3.8062e-03,  1.5860e-02]],\n",
       "              \n",
       "                       [[ 1.3406e-02,  9.2400e-03,  1.3249e-02],\n",
       "                        [-2.6922e-02,  7.0491e-03,  2.2902e-02],\n",
       "                        [ 1.1672e-02, -2.1906e-02,  2.4269e-02]],\n",
       "              \n",
       "                       [[-1.3633e-02,  2.6655e-03, -7.2263e-03],\n",
       "                        [-1.5959e-02, -1.2804e-02,  8.6869e-03],\n",
       "                        [-2.5591e-02,  4.7178e-03, -2.6502e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3824e-02, -4.9705e-03, -8.4710e-03],\n",
       "                        [ 2.3504e-02,  2.0772e-02,  4.6310e-03],\n",
       "                        [-4.1801e-03, -7.0276e-04,  9.9194e-03]],\n",
       "              \n",
       "                       [[-2.3939e-03,  9.4284e-03,  1.8528e-02],\n",
       "                        [ 2.1475e-02, -5.3205e-03, -1.7068e-02],\n",
       "                        [ 2.0469e-02,  2.1107e-02, -1.0142e-03]],\n",
       "              \n",
       "                       [[-1.2419e-02, -1.1579e-02, -1.4678e-02],\n",
       "                        [ 1.4147e-02,  2.9391e-02,  9.8106e-04],\n",
       "                        [ 2.6892e-02, -2.3845e-03, -4.0786e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1055e-02, -2.2616e-02, -7.5858e-04],\n",
       "                        [-1.9315e-02, -2.0734e-02,  1.8278e-03],\n",
       "                        [ 6.6853e-03,  5.0067e-03, -6.9816e-03]],\n",
       "              \n",
       "                       [[ 1.4923e-02, -1.2252e-02, -4.3187e-03],\n",
       "                        [-1.8199e-02,  1.9702e-02, -1.6014e-02],\n",
       "                        [ 1.7136e-02,  3.4862e-03,  8.3085e-03]],\n",
       "              \n",
       "                       [[-3.0843e-03,  1.0162e-02, -7.5588e-03],\n",
       "                        [-8.8636e-03,  8.5829e-03, -1.1189e-02],\n",
       "                        [-1.1346e-02, -2.5799e-02, -1.2859e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.8370e-03, -2.3822e-03, -8.7743e-03],\n",
       "                        [ 3.8765e-03,  1.8832e-02,  7.2645e-03],\n",
       "                        [ 2.7734e-02,  2.1006e-02, -1.5169e-02]],\n",
       "              \n",
       "                       [[ 9.5130e-03,  1.0928e-02, -1.2086e-02],\n",
       "                        [-5.6175e-03, -9.6391e-03,  6.6227e-03],\n",
       "                        [ 1.6391e-02,  1.4265e-02, -2.1747e-02]],\n",
       "              \n",
       "                       [[-1.8171e-02, -1.6902e-02, -8.4491e-03],\n",
       "                        [-2.0006e-02,  2.5133e-02, -2.2297e-02],\n",
       "                        [ 2.4290e-02, -6.0625e-03, -3.1320e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7070e-03, -5.4578e-03, -1.3254e-02],\n",
       "                        [ 6.3159e-03,  5.8388e-03, -1.8173e-02],\n",
       "                        [-1.9678e-02,  7.1542e-03, -1.7842e-02]],\n",
       "              \n",
       "                       [[-1.9171e-02, -1.8741e-02, -1.7121e-02],\n",
       "                        [-1.0001e-02, -4.9556e-05, -1.6875e-02],\n",
       "                        [ 1.2751e-02,  2.3203e-02,  1.9201e-02]],\n",
       "              \n",
       "                       [[-1.4846e-02, -1.2104e-02,  8.0869e-03],\n",
       "                        [-1.0764e-02, -1.9526e-02,  2.6202e-02],\n",
       "                        [ 1.1963e-02, -1.8524e-02,  2.6695e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0734e-02, -2.3524e-02, -9.0190e-03],\n",
       "                        [-1.0975e-02,  4.2388e-03, -6.8110e-03],\n",
       "                        [ 1.5404e-02,  9.0614e-03, -2.4326e-02]],\n",
       "              \n",
       "                       [[ 1.8624e-03,  7.2147e-03,  5.2583e-03],\n",
       "                        [ 8.5940e-03, -1.1634e-02,  1.3319e-02],\n",
       "                        [ 1.5579e-02, -5.7335e-03, -5.2226e-03]],\n",
       "              \n",
       "                       [[ 9.5596e-03, -2.6708e-02, -1.4909e-02],\n",
       "                        [-1.2054e-02, -2.1797e-02, -2.8213e-02],\n",
       "                        [-1.8540e-02, -2.9056e-02, -2.3722e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.6142e-03, -2.7891e-02, -3.1048e-04],\n",
       "                        [ 9.6284e-03, -1.5584e-02, -1.7312e-02],\n",
       "                        [-2.1548e-03, -2.1661e-02, -1.5825e-02]],\n",
       "              \n",
       "                       [[-6.5719e-03, -1.2096e-02,  2.2395e-02],\n",
       "                        [-4.4669e-03, -7.0508e-03, -9.3805e-03],\n",
       "                        [ 6.7914e-04,  2.4313e-02,  2.0360e-02]],\n",
       "              \n",
       "                       [[-1.4953e-02,  8.9137e-03,  7.2113e-03],\n",
       "                        [ 2.8612e-02,  9.1409e-03, -5.0686e-03],\n",
       "                        [ 1.0825e-03,  2.7697e-02,  2.6037e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.6322e-02,  2.7366e-02,  2.1583e-02],\n",
       "                        [-1.9235e-02, -2.1176e-02,  2.1643e-02],\n",
       "                        [ 2.3139e-02, -1.8843e-02, -1.3659e-02]],\n",
       "              \n",
       "                       [[-2.2756e-02, -2.4674e-02, -2.2341e-02],\n",
       "                        [-2.4070e-02,  1.4260e-02,  1.6651e-02],\n",
       "                        [ 8.3240e-03,  1.2021e-02, -1.4278e-02]],\n",
       "              \n",
       "                       [[ 2.5939e-02,  2.2545e-02,  2.1278e-02],\n",
       "                        [-1.0451e-02, -9.2145e-03,  2.0553e-02],\n",
       "                        [ 7.8456e-03, -7.2603e-03,  2.3895e-02]]]], device='cuda:0')),\n",
       "             ('conv_block4.bn1.weight',\n",
       "              tensor([0.9955, 0.9973, 1.0005, 0.9981, 1.0035, 1.0008, 1.0028, 1.0011, 0.9998,\n",
       "                      0.9993, 0.9994, 1.0034, 1.0033, 1.0038, 0.9961, 1.0034, 0.9987, 0.9975,\n",
       "                      1.0092, 1.0027, 1.0020, 1.0097, 0.9998, 0.9983, 1.0017, 1.0023, 0.9998,\n",
       "                      1.0066, 0.9987, 0.9965, 0.9990, 0.9993, 0.9952, 0.9987, 0.9986, 0.9972,\n",
       "                      0.9959, 1.0088, 0.9930, 0.9990, 1.0011, 0.9988, 0.9978, 0.9999, 1.0004,\n",
       "                      0.9998, 1.0013, 0.9976, 1.0034, 1.0026, 1.0035, 1.0008, 0.9998, 1.0054,\n",
       "                      0.9994, 1.0028, 0.9979, 0.9988, 1.0001, 0.9958, 1.0122, 0.9980, 1.0017,\n",
       "                      0.9969, 0.9970, 0.9984, 0.9945, 0.9992, 0.9976, 1.0019, 0.9975, 1.0009,\n",
       "                      1.0005, 1.0043, 1.0006, 0.9973, 1.0027, 0.9995, 1.0021, 0.9958, 0.9989,\n",
       "                      1.0001, 1.0045, 0.9931, 1.0003, 0.9975, 0.9978, 0.9982, 1.0044, 0.9988,\n",
       "                      1.0006, 1.0027, 0.9959, 1.0000, 0.9964, 1.0011, 0.9997, 0.9983, 0.9980,\n",
       "                      0.9956, 1.0017, 1.0109, 1.0033, 1.0009, 1.0032, 0.9974, 0.9990, 1.0096,\n",
       "                      1.0012, 1.0041, 0.9997, 1.0019, 1.0015, 1.0000, 1.0003, 0.9954, 1.0004,\n",
       "                      0.9924, 1.0003, 1.0012, 1.0010, 1.0022, 1.0009, 1.0077, 0.9966, 1.0021,\n",
       "                      0.9988, 0.9960, 0.9957, 0.9984, 1.0019, 0.9987, 0.9996, 0.9995, 0.9985,\n",
       "                      1.0017, 0.9996, 0.9954, 1.0017, 0.9952, 0.9979, 0.9985, 1.0017, 1.0007,\n",
       "                      0.9971, 0.9960, 0.9970, 1.0001, 0.9975, 1.0060, 0.9995, 0.9984, 0.9976,\n",
       "                      1.0073, 1.0081, 0.9982, 0.9990, 0.9994, 1.0047, 0.9932, 0.9992, 0.9955,\n",
       "                      0.9997, 1.0070, 0.9986, 0.9990, 0.9987, 1.0012, 0.9959, 0.9978, 1.0109,\n",
       "                      1.0009, 1.0018, 0.9970, 1.0051, 0.9947, 0.9935, 0.9980, 0.9998, 0.9938,\n",
       "                      0.9963, 0.9955, 1.0047, 0.9975, 1.0108, 1.0012, 0.9992, 0.9978, 0.9997,\n",
       "                      0.9979, 0.9946, 0.9984, 0.9989, 1.0013, 0.9986, 0.9952, 1.0074, 1.0035,\n",
       "                      0.9983, 0.9991, 0.9947, 1.0165, 0.9985, 0.9932, 1.0028, 1.0004, 0.9997,\n",
       "                      0.9981, 1.0012, 1.0014, 1.0040, 0.9984, 0.9960, 1.0003, 1.0011, 1.0002,\n",
       "                      1.0005, 0.9990, 1.0015, 1.0016, 0.9997, 0.9966, 0.9939, 1.0018, 1.0068,\n",
       "                      1.0005, 0.9967, 0.9995, 1.0004, 0.9970, 0.9991, 0.9995, 0.9963, 1.0010,\n",
       "                      0.9986, 1.0118, 1.0083, 0.9949, 0.9991, 1.0019, 0.9984, 0.9943, 0.9999,\n",
       "                      0.9996, 1.0092, 0.9916, 1.0051, 0.9939, 1.0018, 0.9964, 1.0003, 0.9995,\n",
       "                      1.0037, 1.0032, 0.9966, 1.0016, 0.9978, 0.9960, 0.9968, 0.9905, 0.9967,\n",
       "                      1.0054, 0.9995, 1.0015, 1.0033, 1.0005, 0.9983, 1.0030, 0.9940, 0.9977,\n",
       "                      1.0013, 1.0050, 1.0040, 0.9968, 1.0043, 0.9946, 1.0009, 1.0039, 1.0049,\n",
       "                      1.0035, 1.0112, 1.0017, 0.9988, 0.9981, 1.0056, 1.0024, 1.0056, 0.9959,\n",
       "                      1.0011, 0.9988, 1.0094, 0.9992, 1.0036, 0.9993, 1.0086, 1.0052, 1.0063,\n",
       "                      1.0045, 0.9952, 0.9978, 0.9960, 0.9992, 1.0017, 1.0014, 1.0019, 1.0035,\n",
       "                      0.9975, 0.9971, 0.9988, 0.9937, 0.9954, 1.0038, 0.9990, 1.0037, 1.0015,\n",
       "                      1.0008, 0.9962, 0.9972, 0.9967, 1.0038, 0.9951, 1.0018, 0.9964, 0.9982,\n",
       "                      0.9995, 0.9981, 0.9989, 0.9970, 1.0037, 0.9987, 0.9988, 1.0105, 0.9955,\n",
       "                      0.9987, 0.9942, 1.0024, 1.0008, 1.0194, 1.0020, 1.0090, 1.0033, 1.0005,\n",
       "                      0.9968, 0.9993, 0.9989, 1.0032, 0.9986, 1.0045, 0.9970, 0.9973, 0.9956,\n",
       "                      0.9973, 0.9994, 1.0060, 0.9969, 1.0000, 0.9967, 0.9999, 0.9981, 0.9968,\n",
       "                      1.0000, 0.9972, 1.0058, 0.9990, 0.9993, 0.9960, 0.9943, 0.9981, 0.9971,\n",
       "                      0.9978, 0.9960, 0.9980, 1.0008, 1.0014, 1.0018, 1.0208, 1.0018, 0.9943,\n",
       "                      1.0020, 0.9994, 1.0013, 0.9964, 0.9996, 0.9993, 0.9971, 0.9988, 1.0042,\n",
       "                      1.0073, 1.0008, 1.0016, 0.9984, 0.9983, 0.9964, 1.0002, 0.9995, 0.9977,\n",
       "                      1.0046, 0.9948, 1.0028, 0.9988, 0.9981, 1.0001, 0.9961, 0.9960, 1.0062,\n",
       "                      0.9954, 1.0010, 1.0012, 1.0033, 1.0002, 1.0016, 1.0164, 0.9999, 1.0060,\n",
       "                      0.9974, 0.9957, 1.0012, 0.9953, 0.9996, 0.9983, 0.9987, 1.0101, 1.0004,\n",
       "                      0.9988, 1.0015, 0.9984, 0.9989, 0.9961, 0.9975, 1.0021, 0.9972, 0.9978,\n",
       "                      0.9978, 0.9951, 1.0059, 1.0010, 1.0013, 0.9978, 0.9978, 0.9967, 1.0014,\n",
       "                      0.9957, 1.0000, 1.0000, 0.9976, 0.9972, 0.9978, 1.0011, 0.9987, 0.9989,\n",
       "                      1.0032, 0.9993, 0.9986, 0.9908, 0.9945, 0.9993, 0.9944, 0.9975, 1.0098,\n",
       "                      0.9975, 1.0020, 0.9999, 1.0121, 0.9968, 0.9998, 0.9979, 0.9962, 1.0018,\n",
       "                      0.9999, 0.9990, 0.9967, 0.9971, 0.9984, 0.9993, 0.9968, 0.9975, 1.0023,\n",
       "                      0.9992, 1.0023, 1.0014, 0.9986, 0.9978, 0.9986, 0.9980, 0.9976, 0.9956,\n",
       "                      0.9980, 0.9979, 1.0011, 0.9981, 0.9982, 1.0026, 0.9990, 0.9995, 1.0038,\n",
       "                      0.9993, 1.0030, 1.0035, 0.9968, 0.9932, 1.0021, 1.0014, 1.0012, 0.9991,\n",
       "                      1.0045, 1.0044, 1.0067, 0.9999, 0.9994, 0.9967, 0.9961, 1.0014],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_block4.bn1.bias',\n",
       "              tensor([-2.4744e-03, -2.4281e-03, -5.4639e-03, -7.2329e-03, -2.8472e-03,\n",
       "                      -4.1399e-03,  4.4095e-04,  1.1175e-03, -1.2339e-03, -3.5548e-03,\n",
       "                      -2.7130e-04,  1.9673e-03, -5.1492e-03, -5.1223e-03, -3.5227e-03,\n",
       "                       3.2237e-03, -2.7806e-03, -2.8955e-03, -3.3792e-03, -2.2028e-03,\n",
       "                      -6.4628e-03, -1.0665e-02, -2.3737e-03, -1.3565e-04,  9.1898e-05,\n",
       "                      -9.6460e-03, -4.0652e-03, -5.9237e-03, -2.6566e-03, -7.3950e-03,\n",
       "                      -4.5940e-03,  8.7481e-04, -1.7923e-03, -4.0546e-03, -5.1698e-03,\n",
       "                      -4.0221e-03, -2.9562e-03, -1.9342e-03, -8.5065e-03, -2.2659e-03,\n",
       "                      -1.3716e-03, -2.4218e-03, -5.2375e-03, -2.7040e-03, -9.3624e-04,\n",
       "                      -1.5198e-03, -1.5381e-03, -2.8015e-04, -9.4101e-04, -2.6977e-03,\n",
       "                       2.5950e-04, -3.0080e-03, -4.4627e-03, -4.4997e-03, -6.4112e-03,\n",
       "                      -3.0552e-03, -1.5264e-03, -3.2660e-03, -4.4288e-04, -5.3603e-03,\n",
       "                       2.8294e-03, -7.1879e-03, -4.3167e-04, -5.0491e-03, -4.0683e-03,\n",
       "                      -7.6789e-03, -7.6816e-03, -4.6217e-03, -5.8889e-03,  7.1289e-05,\n",
       "                      -1.1659e-03,  2.1271e-03, -1.7708e-03, -1.6395e-03, -8.1839e-04,\n",
       "                      -6.9211e-04,  3.5056e-03, -3.4944e-03, -1.3304e-03, -2.7509e-03,\n",
       "                      -2.3208e-03,  2.8886e-04, -1.3032e-03, -4.1872e-03, -1.2457e-03,\n",
       "                      -2.7620e-03, -6.0788e-04, -7.8844e-04, -4.3097e-03, -4.5527e-03,\n",
       "                      -2.9925e-03, -2.5279e-03, -2.4877e-03, -4.3618e-03, -4.9149e-03,\n",
       "                      -2.1143e-03, -2.9165e-03, -1.2088e-03, -1.7999e-03, -7.5659e-03,\n",
       "                      -1.2057e-03,  2.4304e-03,  1.3866e-03, -8.6154e-04, -2.4663e-03,\n",
       "                      -3.4776e-03, -3.3382e-03, -7.2180e-03, -2.3932e-03, -3.1395e-03,\n",
       "                       7.3682e-04,  2.1301e-03, -2.9936e-03,  5.4035e-04, -6.3903e-04,\n",
       "                      -5.7523e-03,  1.2582e-03, -5.7104e-03, -1.9757e-03,  1.2380e-04,\n",
       "                      -2.7166e-03, -4.8262e-03,  2.3884e-03, -6.0548e-04, -3.7652e-03,\n",
       "                      -1.2719e-03, -4.9385e-03, -5.1741e-03, -2.8851e-03, -6.0415e-03,\n",
       "                      -1.0961e-03, -2.1198e-03, -1.9770e-03, -3.3532e-03, -6.9085e-03,\n",
       "                      -6.1107e-03, -1.8955e-03, -3.5183e-03, -4.3787e-03, -5.0064e-03,\n",
       "                      -3.8391e-03, -4.6999e-03, -3.0877e-03,  1.1284e-03, -5.0118e-03,\n",
       "                      -4.5534e-03, -2.2248e-03, -6.2463e-03, -2.9510e-03, -4.3264e-03,\n",
       "                      -3.0590e-03,  9.5355e-04, -6.9887e-03, -1.3815e-03, -1.8001e-03,\n",
       "                      -1.6507e-03, -3.3657e-03,  6.7785e-04, -8.7356e-04, -4.7028e-03,\n",
       "                      -4.4410e-03, -2.9276e-03, -2.5939e-03, -3.0939e-03, -3.2095e-03,\n",
       "                      -5.8053e-03, -8.3051e-03, -1.1946e-03, -7.8599e-03, -3.9088e-03,\n",
       "                      -5.5458e-03, -1.9210e-05, -7.3421e-03, -1.2493e-03,  7.0884e-05,\n",
       "                      -6.1197e-03, -7.0946e-03, -3.1391e-03,  6.1693e-04, -5.6309e-03,\n",
       "                      -7.6774e-03, -2.7794e-03, -6.9301e-03, -5.0975e-03, -6.6893e-03,\n",
       "                       7.4246e-04, -1.9083e-03, -3.2334e-03, -3.1273e-03, -5.4250e-03,\n",
       "                      -6.5864e-03, -2.9211e-03, -1.0328e-03, -4.3974e-03,  2.2122e-03,\n",
       "                      -4.0102e-03, -3.5462e-03,  9.6597e-04, -9.0065e-04, -5.7395e-04,\n",
       "                      -5.0723e-03, -3.8884e-03, -4.0449e-03, -5.6762e-03,  9.7592e-05,\n",
       "                      -1.3009e-03, -1.9869e-03, -1.5705e-04, -1.6619e-03,  4.9425e-04,\n",
       "                      -3.5160e-03, -5.3037e-03, -1.4308e-03, -4.1389e-04,  2.7010e-03,\n",
       "                      -9.0070e-04,  1.0307e-03,  4.1360e-04,  1.7151e-03,  2.4638e-03,\n",
       "                      -1.5011e-03, -3.1273e-03, -3.2405e-03, -2.0537e-03,  8.3208e-07,\n",
       "                       4.3936e-04, -6.0426e-03, -3.0103e-03, -1.6064e-03, -5.8965e-03,\n",
       "                       6.3213e-04, -7.2343e-04, -5.1680e-03, -3.2277e-03, -1.2250e-04,\n",
       "                       2.5512e-03, -4.7445e-03, -4.1828e-03, -1.9723e-03, -4.2466e-03,\n",
       "                      -7.1665e-04, -5.0961e-03, -3.9924e-03, -1.6748e-03, -1.9969e-03,\n",
       "                      -4.8721e-03,  1.4710e-03, -5.7829e-03, -1.8927e-03, -5.9539e-03,\n",
       "                      -1.7179e-03, -5.3473e-03, -6.7942e-03, -2.2559e-03, -2.8620e-03,\n",
       "                       1.6226e-03,  1.4637e-04, -6.1221e-03,  4.3986e-05, -9.8842e-03,\n",
       "                      -3.9283e-03,  3.0044e-03,  1.2962e-04, -1.1765e-03, -1.5220e-03,\n",
       "                      -1.1025e-03, -3.7868e-03, -1.8805e-04, -4.2323e-03, -1.9880e-03,\n",
       "                      -3.3384e-03, -3.8369e-03, -5.4749e-03, -3.6988e-03, -8.2382e-04,\n",
       "                      -4.4623e-03, -5.1025e-03,  1.1541e-03, -3.1200e-03, -2.8446e-03,\n",
       "                      -3.1623e-03, -2.1102e-03, -1.1486e-03, -6.8645e-03, -1.2127e-03,\n",
       "                       1.6244e-03, -3.8866e-03, -3.3114e-03, -1.8880e-03, -4.1314e-03,\n",
       "                      -2.0649e-03, -9.0191e-06, -8.1174e-04, -6.0149e-03, -6.2364e-03,\n",
       "                      -4.4591e-03, -5.3194e-04, -3.2109e-03, -8.1659e-03, -1.1217e-03,\n",
       "                      -3.0756e-03, -4.2801e-03, -7.2104e-03, -2.5594e-03,  4.6169e-03,\n",
       "                      -6.5538e-03, -1.4827e-03, -3.1705e-03, -5.0206e-03, -7.5748e-03,\n",
       "                      -2.4484e-03, -1.4265e-03, -4.8980e-03, -4.1519e-03,  2.6746e-03,\n",
       "                       2.4753e-03, -3.7305e-03, -6.5244e-05, -1.5559e-03, -1.4327e-03,\n",
       "                      -6.7771e-03, -4.9383e-03, -2.2417e-03, -2.5207e-03, -4.3674e-03,\n",
       "                      -2.0925e-03, -3.9914e-03, -2.6871e-03, -5.4771e-03, -1.7250e-03,\n",
       "                      -2.6506e-03, -1.9715e-03, -5.6896e-03, -3.9358e-03, -3.5628e-03,\n",
       "                       3.0238e-03, -2.9176e-03, -4.2541e-03, -2.5183e-03, -3.0492e-03,\n",
       "                      -4.1792e-03, -1.5896e-03, -1.5051e-03,  2.1448e-03, -5.5044e-04,\n",
       "                      -6.4729e-03, -4.3483e-03,  2.8632e-05, -4.5511e-03, -2.9497e-03,\n",
       "                      -5.8791e-03, -3.4683e-03, -4.5380e-03, -5.1729e-03, -6.7348e-03,\n",
       "                      -4.0035e-04, -5.4438e-03, -2.8714e-03, -1.4446e-03, -5.9444e-03,\n",
       "                       1.5010e-03, -1.2291e-03, -4.4495e-03, -4.1354e-03, -5.3172e-03,\n",
       "                      -4.4731e-03, -3.7867e-03, -6.0398e-03, -3.6973e-03, -7.0620e-03,\n",
       "                      -6.2508e-03, -4.8430e-03, -3.8048e-03, -3.5058e-04,  8.2620e-04,\n",
       "                      -4.5928e-03,  2.1638e-03, -7.8623e-03,  1.2709e-03, -2.4767e-03,\n",
       "                      -4.0575e-03, -8.2723e-03, -9.1241e-04, -1.7799e-03, -2.2738e-03,\n",
       "                      -2.5370e-03, -7.7126e-05, -7.5471e-04, -1.6692e-03,  2.8596e-04,\n",
       "                      -4.5985e-04, -6.1162e-03, -2.9526e-03,  4.6170e-03,  2.4044e-05,\n",
       "                      -5.8089e-03, -9.5559e-03, -4.3397e-03, -4.1107e-03, -8.5963e-04,\n",
       "                      -2.5158e-03, -1.7460e-04, -2.1272e-03, -2.2703e-03,  5.8573e-03,\n",
       "                      -6.7603e-03, -1.2150e-03,  1.6754e-04, -3.6719e-03, -3.5271e-03,\n",
       "                      -7.2136e-04, -9.6055e-03, -4.7476e-03, -2.7462e-03, -6.1811e-03,\n",
       "                       9.5222e-04, -2.4836e-03, -3.7507e-03, -4.5597e-03, -1.2935e-04,\n",
       "                      -2.2060e-03, -8.0177e-03, -6.1562e-03, -1.3791e-03, -1.6579e-03,\n",
       "                      -5.9579e-03, -4.8009e-03, -4.0794e-03, -1.9704e-03, -1.5754e-03,\n",
       "                      -3.6096e-03, -2.4971e-03, -5.4458e-04, -2.1675e-03, -6.5757e-03,\n",
       "                      -3.5460e-03, -1.6151e-03, -4.1209e-03, -3.0288e-03, -2.6657e-03,\n",
       "                       1.6868e-03, -6.1383e-03, -3.8403e-03, -3.5558e-03,  4.0045e-04,\n",
       "                      -8.8241e-03, -2.3115e-03,  3.8001e-03, -2.3007e-03,  7.5722e-04,\n",
       "                       2.7589e-04, -1.0411e-03,  8.8925e-04, -8.9987e-03, -4.0803e-03,\n",
       "                      -3.7898e-03, -4.1136e-03, -9.2905e-04,  7.6756e-04, -3.8995e-03,\n",
       "                      -1.6425e-03, -8.1028e-03, -8.6888e-03, -2.3153e-03, -2.5316e-03,\n",
       "                      -7.1614e-03, -6.5530e-03,  2.2454e-05, -3.8364e-03, -2.9556e-03,\n",
       "                      -3.7608e-03, -4.9099e-03, -3.9202e-03, -2.7291e-03, -5.0968e-03,\n",
       "                      -7.5807e-04, -7.8144e-03, -1.7042e-03, -5.1102e-03,  4.5904e-04,\n",
       "                      -1.7512e-03, -2.1990e-03, -1.2936e-03, -4.3866e-03, -5.3865e-03,\n",
       "                      -4.3241e-04, -5.4231e-03, -2.9163e-03, -3.7560e-03, -3.1435e-03,\n",
       "                      -2.6670e-03, -6.5269e-03, -8.6844e-04, -3.7131e-03,  9.7067e-04,\n",
       "                      -3.6346e-03, -1.8245e-03, -6.1368e-03, -2.6408e-03, -7.7286e-03,\n",
       "                       2.5858e-05, -2.1483e-03, -3.1011e-03, -1.4676e-03,  8.6585e-04,\n",
       "                      -4.1995e-03, -6.7391e-04, -1.1005e-03,  1.6824e-04, -4.4442e-03,\n",
       "                      -5.2027e-03,  5.4618e-04], device='cuda:0')),\n",
       "             ('conv_block4.bn1.running_mean',\n",
       "              tensor([-1.1485e+00, -9.0140e-01, -6.5493e-01,  4.2809e-01, -2.5238e-01,\n",
       "                      -3.6241e-01,  1.4692e+00, -1.0894e-01, -4.7014e-01,  3.5695e-01,\n",
       "                      -8.3479e-01, -8.6378e-01, -5.7968e-01, -1.0611e-01, -7.2078e-01,\n",
       "                       1.9738e-01, -6.0990e-02,  2.0815e-01,  8.6358e-02, -1.2837e+00,\n",
       "                       3.7358e-01,  2.4927e-01, -5.7151e-02, -6.0337e-01,  1.0793e+00,\n",
       "                      -5.8017e-01,  5.2576e-01, -1.9941e-01, -1.0608e+00,  8.2193e-01,\n",
       "                       7.0360e-01,  1.0487e-01, -1.2395e+00,  5.5161e-01,  6.2050e-01,\n",
       "                      -8.2253e-01, -5.5509e-01, -8.8989e-02, -8.1521e-01,  4.9459e-01,\n",
       "                      -8.7340e-02,  8.1409e-01, -1.6256e-02,  3.6779e-01,  3.7544e-01,\n",
       "                       8.6684e-01,  2.8167e-01,  1.4872e-01, -3.1271e-01, -8.9247e-01,\n",
       "                       8.0707e-02, -1.1071e+00,  1.8997e-01, -2.3226e-01, -6.9513e-01,\n",
       "                      -2.3939e-01, -7.3408e-01, -1.3049e+00, -1.1472e-01, -2.3376e-01,\n",
       "                       4.8658e-01,  5.4031e-01, -2.8346e-01,  6.3671e-01, -6.7361e-01,\n",
       "                       1.0546e+00, -8.8189e-02,  5.4851e-01, -1.2276e-01,  5.6895e-01,\n",
       "                      -9.3165e-01, -1.1776e-01,  1.1981e+00, -8.1271e-01, -6.3160e-01,\n",
       "                      -4.0302e-01, -3.0469e-01,  1.0388e+00, -6.2173e-01,  5.3145e-01,\n",
       "                       2.7752e-01,  2.5638e-01,  1.3363e-01,  3.0100e-01,  2.6460e-01,\n",
       "                      -8.4664e-01, -7.4894e-01, -5.7539e-01, -5.4188e-01,  1.1469e+00,\n",
       "                      -7.4719e-01,  3.0968e-01, -4.0302e-01,  5.7118e-01, -4.2698e-01,\n",
       "                      -7.4331e-01,  7.8336e-01, -3.8149e-01, -9.1018e-01,  6.4788e-02,\n",
       "                       3.0754e-01,  4.5508e-01,  7.3243e-01, -1.4652e-01, -2.4546e-01,\n",
       "                       4.2027e-01,  5.0237e-01,  2.1355e-01,  1.3241e+00,  5.6169e-01,\n",
       "                      -1.2787e-01, -2.8022e-01,  1.0274e-01, -2.5698e-01,  1.1408e+00,\n",
       "                       7.4977e-01,  4.2875e-01, -5.7096e-01,  4.0203e-01, -2.2494e-01,\n",
       "                       8.3227e-01, -4.8923e-01, -1.2097e-01,  1.4024e-01, -3.7751e-01,\n",
       "                      -6.7290e-01, -7.1534e-01,  1.3043e-01, -1.2692e+00,  7.7563e-01,\n",
       "                       1.2625e-01, -8.5470e-01, -5.4835e-01, -4.0503e-01,  9.0712e-01,\n",
       "                       4.2988e-01, -1.0848e+00, -6.6470e-01,  1.6550e-01,  3.8779e-02,\n",
       "                      -1.0246e+00, -5.5716e-01, -4.0551e-01,  5.1332e-01, -5.3239e-01,\n",
       "                      -1.2768e+00,  9.1683e-01, -4.5735e-02, -4.9375e-02,  5.2054e-02,\n",
       "                      -7.2304e-01, -6.9594e-01,  8.7595e-01,  4.2404e-02, -8.0138e-01,\n",
       "                       7.7031e-01, -3.6011e-01,  2.0387e-01, -7.5316e-01,  4.1285e-01,\n",
       "                       4.6353e-01, -5.1450e-01,  2.7516e-01,  4.0411e-01, -8.3175e-01,\n",
       "                       9.7499e-01, -6.3298e-01,  6.7026e-01, -6.1253e-01,  4.5528e-02,\n",
       "                      -1.7863e-01, -8.0705e-01,  8.0462e-01, -8.5460e-01,  8.0364e-01,\n",
       "                       4.9973e-01,  2.5042e-01, -2.5801e-03,  3.8384e-02, -2.8333e-01,\n",
       "                       7.2618e-01, -1.1294e+00,  1.6474e-02, -1.7346e-01, -2.3229e-01,\n",
       "                      -6.4840e-01, -3.3606e-01, -1.0424e+00,  1.4037e+00,  4.8374e-01,\n",
       "                      -8.9360e-01, -6.4177e-01,  1.1514e-01, -1.8813e-01, -1.7458e-02,\n",
       "                       2.8005e-01, -2.3431e-01, -8.1458e-02, -7.3864e-02, -1.0874e+00,\n",
       "                      -5.7850e-01, -1.6469e-02, -2.1168e-01, -8.4658e-01,  3.4649e-01,\n",
       "                       5.4716e-02,  1.6040e+00, -5.9046e-01,  2.4644e-01,  1.5617e+00,\n",
       "                      -9.5945e-02,  2.2702e-01, -1.4966e+00, -1.9050e-01,  2.4082e-01,\n",
       "                       2.0752e-01,  1.0353e+00, -5.9448e-01,  1.0038e+00,  6.1917e-01,\n",
       "                      -1.2726e-01, -7.7599e-01, -5.6362e-01, -5.2497e-01, -1.4358e-01,\n",
       "                       4.4269e-01, -4.8027e-01,  6.8553e-01, -1.9758e-01,  3.5864e-01,\n",
       "                      -1.0014e-01,  1.5472e-02, -9.8400e-01, -9.5206e-01, -1.0204e+00,\n",
       "                       2.7951e-01, -3.4532e-01, -7.5410e-02, -3.5852e-01, -3.1044e-01,\n",
       "                      -1.1889e+00, -6.4516e-01,  1.4669e+00, -2.9208e-01, -2.0315e-01,\n",
       "                      -3.8667e-01,  1.6740e-01, -2.4514e-01, -7.4535e-02, -2.4039e-01,\n",
       "                       4.3790e-01, -1.1940e+00, -2.2471e-01,  2.8404e-01,  8.5390e-02,\n",
       "                       1.3751e-01, -2.5511e-01,  1.0687e-01, -1.4413e-01, -4.1377e-01,\n",
       "                      -4.9600e-01,  5.2419e-01,  2.4202e-01,  8.7894e-01, -2.8476e-02,\n",
       "                       1.1342e+00, -2.6630e-01, -6.0861e-01, -9.7074e-01, -7.9150e-01,\n",
       "                      -2.1104e-02, -4.6221e-01, -9.7114e-01, -8.6790e-01,  6.4677e-01,\n",
       "                      -5.8810e-02, -6.1332e-01, -8.9037e-01, -3.1482e-01, -5.9708e-01,\n",
       "                      -2.4914e-01, -5.7997e-02, -5.9918e-01,  5.4155e-01,  5.2671e-03,\n",
       "                      -9.5256e-01, -7.4866e-01, -6.4807e-01,  1.2012e-01, -4.2593e-01,\n",
       "                       2.2389e-01, -3.0624e-01, -5.3961e-01,  1.2861e+00, -1.4985e-01,\n",
       "                      -6.9455e-01, -2.5955e-01, -5.1897e-01, -7.3630e-02, -1.4113e+00,\n",
       "                      -1.1684e+00,  9.6616e-01, -5.4951e-01,  1.2294e+00, -3.0932e-03,\n",
       "                      -6.2617e-01, -2.6229e-01, -1.1330e+00,  3.0727e-01, -2.3924e-01,\n",
       "                      -5.9880e-01, -8.1151e-01,  6.5236e-02, -4.9682e-01,  5.9734e-01,\n",
       "                      -5.6038e-01, -1.7364e-01, -1.1761e+00, -1.6748e+00, -1.5274e-01,\n",
       "                      -7.0383e-01,  7.3108e-01, -1.2559e+00, -1.0087e+00, -2.8684e-01,\n",
       "                      -4.3522e-01,  3.5377e-01, -4.1589e-01, -2.0911e-01,  2.4728e-02,\n",
       "                      -4.1163e-01,  5.3851e-02, -3.2278e-01,  5.9244e-01, -9.8042e-01,\n",
       "                       9.9108e-01,  6.8773e-01, -3.5970e-01, -3.0041e-01, -5.4651e-02,\n",
       "                       2.1891e-01,  2.2636e-01, -9.7117e-01, -5.0148e-01,  6.6526e-02,\n",
       "                      -4.1396e-02,  5.0398e-01, -9.3874e-01, -3.5130e-01, -2.4415e-01,\n",
       "                      -8.4154e-01, -2.6239e-01, -2.5401e-01, -6.4963e-01, -3.8858e-01,\n",
       "                      -6.5240e-01, -4.9306e-01,  3.0959e-02, -5.4444e-01, -2.9262e-01,\n",
       "                      -3.0838e-01, -4.7842e-01, -1.1750e-01, -7.2285e-01,  6.6512e-01,\n",
       "                      -2.2389e-01, -4.1767e-01,  3.2902e-01, -4.0698e-01, -5.2555e-02,\n",
       "                       4.7054e-01,  4.1638e-01,  5.1816e-01, -3.7840e-01,  5.0603e-01,\n",
       "                      -2.0731e-01, -4.1423e-01, -1.2908e+00,  8.0158e-02,  2.4097e-02,\n",
       "                      -2.7367e-01, -1.8630e-01,  1.3705e-01,  8.1445e-01, -1.0150e+00,\n",
       "                       6.9675e-01, -2.1578e-02,  8.1430e-02, -7.7113e-01,  1.2220e+00,\n",
       "                       3.9238e-02, -4.7469e-01, -9.7238e-01, -2.9411e-01,  3.9779e-01,\n",
       "                      -7.8565e-01, -3.9845e-01, -8.1456e-02, -8.2934e-01, -1.1758e+00,\n",
       "                      -7.4447e-01, -2.6629e-01, -1.2039e+00, -9.7180e-01, -5.3300e-02,\n",
       "                      -4.2053e-01, -3.6616e-01,  5.0499e-03, -2.0101e-01, -8.4327e-01,\n",
       "                      -7.2356e-01, -2.2217e-01, -6.8089e-01, -3.5575e-01, -5.7072e-02,\n",
       "                      -8.5106e-01, -4.4889e-01, -6.3334e-01,  8.6068e-01, -1.1251e+00,\n",
       "                      -3.4239e-01, -2.5339e-01,  5.9271e-01, -6.0774e-01,  2.5212e-01,\n",
       "                       1.0990e-01, -8.2164e-02, -1.1655e+00, -8.5764e-01, -4.5197e-01,\n",
       "                       2.2001e-01, -3.9250e-01, -2.7186e-01, -7.7954e-01, -5.0418e-01,\n",
       "                      -4.0304e-01,  1.6431e-01, -3.7079e-01,  7.3801e-01, -9.3916e-02,\n",
       "                      -3.3482e-01,  5.7235e-01, -5.6819e-02, -7.3894e-01, -7.0949e-01,\n",
       "                       9.1164e-01,  7.7152e-01,  2.3760e-01, -8.3231e-01,  8.4552e-02,\n",
       "                      -1.0300e-01,  3.8032e-01, -1.1490e-01, -5.9431e-02, -1.0228e+00,\n",
       "                       1.1552e+00, -4.9029e-01, -5.0895e-01, -3.0124e-01,  1.1402e-01,\n",
       "                       3.3663e-01, -3.5290e-01,  5.4587e-02,  1.9123e-01, -4.6296e-01,\n",
       "                       7.4102e-01, -2.9714e-01,  8.2330e-02,  3.8961e-01, -6.6252e-01,\n",
       "                      -4.0321e-01, -6.6214e-01, -5.8649e-01, -5.0488e-01, -4.0269e-01,\n",
       "                      -1.4988e+00, -3.8347e-01,  5.3059e-01, -2.4452e-01, -3.6854e-01,\n",
       "                      -9.7840e-02, -8.9617e-01, -1.3442e+00,  1.6492e-01,  5.5784e-01,\n",
       "                      -6.6380e-01, -9.4207e-02,  1.6057e-01, -6.0724e-02, -2.7329e-01,\n",
       "                      -2.6983e-01, -2.9786e-01, -3.3347e-03,  3.8037e-01, -1.7877e-01,\n",
       "                       7.0914e-01,  4.2519e-01,  5.9838e-01, -2.5419e-01, -3.8523e-01,\n",
       "                      -4.3807e-01,  1.4904e-01, -3.9878e-01, -1.4996e-01, -7.8929e-01,\n",
       "                       1.2379e-02, -2.4082e-01,  5.9837e-01, -5.9704e-01, -4.1579e-01,\n",
       "                      -3.8849e-04, -2.6872e-01], device='cuda:0')),\n",
       "             ('conv_block4.bn1.running_var',\n",
       "              tensor([0.5964, 0.6029, 0.7334, 0.4387, 0.8522, 0.6867, 1.0758, 0.6813, 0.7040,\n",
       "                      0.6017, 0.9181, 1.0378, 0.7244, 0.6953, 0.5344, 0.8473, 0.7294, 0.4831,\n",
       "                      0.8513, 1.1807, 0.8751, 0.8006, 0.5648, 0.5932, 1.1369, 0.8652, 1.0356,\n",
       "                      1.0074, 1.0098, 0.5445, 0.7728, 0.4396, 0.4913, 0.9871, 0.8052, 0.7492,\n",
       "                      0.4625, 0.6878, 0.3366, 0.6825, 0.9078, 0.5228, 0.4546, 0.8661, 0.3600,\n",
       "                      0.9438, 0.7372, 0.3782, 1.4541, 0.8480, 0.8402, 0.6536, 0.4121, 1.2640,\n",
       "                      0.8965, 0.6247, 0.5204, 1.0890, 0.6590, 0.4822, 0.8921, 0.8093, 1.3520,\n",
       "                      0.7206, 0.7461, 0.6564, 0.9792, 0.3745, 0.8884, 0.5256, 0.5637, 1.0504,\n",
       "                      1.0113, 1.0103, 0.6503, 0.8314, 0.8081, 1.0852, 1.0805, 1.0650, 0.8909,\n",
       "                      0.6814, 0.9635, 0.6978, 1.0347, 0.4199, 0.8514, 0.5582, 0.7622, 0.9547,\n",
       "                      0.6924, 1.1551, 0.7325, 0.6554, 0.5360, 0.9212, 0.5830, 1.3235, 0.6393,\n",
       "                      0.4404, 0.8104, 1.8239, 0.7754, 1.0390, 0.9273, 0.3664, 0.4531, 0.8684,\n",
       "                      0.8365, 1.2780, 0.8560, 0.6299, 1.1047, 0.8038, 1.2490, 0.6857, 0.6551,\n",
       "                      0.7611, 0.8740, 1.4193, 1.1043, 0.9169, 0.7595, 0.6685, 0.6788, 0.8795,\n",
       "                      0.3471, 0.3513, 0.6355, 0.6905, 0.5956, 0.5320, 0.6185, 1.0068, 0.5871,\n",
       "                      0.8653, 1.1302, 0.4673, 0.5531, 0.4147, 1.3823, 0.9895, 0.7029, 1.2965,\n",
       "                      0.4082, 1.0328, 0.7414, 0.6455, 0.8847, 0.9756, 0.9456, 0.4074, 0.6484,\n",
       "                      1.2552, 0.8837, 0.6998, 0.7491, 0.8591, 0.7505, 0.5910, 0.9014, 0.4575,\n",
       "                      0.8808, 0.6221, 0.4271, 0.8401, 0.6438, 0.8732, 0.3899, 0.8112, 0.9160,\n",
       "                      1.0471, 0.8184, 0.8557, 1.2267, 0.5961, 0.4008, 0.6222, 1.1082, 0.4428,\n",
       "                      0.7578, 0.6041, 0.6664, 0.3962, 0.9114, 0.7088, 0.6413, 0.7413, 1.0903,\n",
       "                      0.5980, 0.5864, 0.7212, 0.4594, 0.6125, 0.4383, 0.5202, 0.7399, 1.5686,\n",
       "                      0.5888, 0.3940, 0.5875, 0.9022, 0.4213, 0.4829, 0.9550, 0.7968, 1.1319,\n",
       "                      0.5749, 0.7957, 1.2449, 0.7541, 0.7178, 0.7841, 0.8305, 1.1250, 0.7136,\n",
       "                      1.1635, 0.4434, 0.9711, 1.4079, 0.6806, 0.5453, 0.4865, 0.5969, 0.8127,\n",
       "                      0.5307, 0.3904, 0.9747, 0.5386, 0.6813, 0.6997, 1.2301, 0.5878, 0.8490,\n",
       "                      0.6281, 1.2045, 0.5876, 0.7156, 0.8278, 0.6544, 0.5970, 0.4177, 0.9589,\n",
       "                      0.5301, 0.8980, 0.4363, 0.8383, 0.4462, 0.4857, 0.4413, 0.6761, 0.5553,\n",
       "                      0.8355, 0.6219, 0.7567, 0.6918, 0.8304, 0.5159, 0.4925, 0.5934, 0.6140,\n",
       "                      0.9877, 0.7721, 0.6459, 0.3224, 0.9815, 0.8113, 0.9874, 0.8678, 0.4318,\n",
       "                      1.0545, 0.7491, 1.0610, 0.8498, 1.2510, 0.7098, 0.8418, 1.2203, 0.9078,\n",
       "                      1.0565, 0.8424, 0.7050, 0.5180, 0.8031, 0.8164, 0.6485, 0.8965, 0.3215,\n",
       "                      0.6010, 0.6445, 0.7692, 0.6203, 0.9306, 0.6160, 0.8568, 1.1570, 1.0802,\n",
       "                      0.7559, 0.5585, 0.8024, 0.4208, 1.0456, 0.9949, 0.4240, 0.7258, 0.7777,\n",
       "                      0.5692, 1.0829, 0.3464, 0.8824, 0.5557, 1.0301, 0.4880, 1.0867, 1.5598,\n",
       "                      0.8903, 0.7557, 0.8427, 1.1807, 0.6001, 0.4562, 0.7658, 0.8199, 0.7145,\n",
       "                      0.5904, 0.8626, 0.9239, 0.4271, 0.6561, 0.4130, 0.7884, 1.0738, 0.3421,\n",
       "                      0.9216, 0.8080, 0.7679, 1.1725, 1.2203, 0.7234, 0.8805, 0.6868, 0.7657,\n",
       "                      0.8348, 0.9015, 0.6979, 0.7142, 0.6234, 0.9236, 0.4918, 0.3913, 0.9968,\n",
       "                      0.5700, 0.6879, 1.0780, 0.6390, 0.4998, 0.5697, 0.8094, 0.7123, 0.4053,\n",
       "                      0.7195, 0.7174, 0.9869, 0.5801, 1.1183, 0.6550, 0.4940, 0.4211, 0.4920,\n",
       "                      0.5321, 0.3935, 0.8514, 0.8286, 0.7786, 0.7242, 0.9930, 0.6837, 0.6945,\n",
       "                      0.7931, 0.5987, 0.5337, 0.7781, 0.6825, 0.7746, 0.6818, 0.5483, 1.1648,\n",
       "                      1.4569, 0.5861, 0.7170, 0.3716, 0.6226, 0.9103, 0.9677, 0.8801, 0.7089,\n",
       "                      1.1956, 0.4248, 1.0993, 0.7786, 0.7269, 1.2289, 1.0057, 0.9220, 1.0161,\n",
       "                      0.5753, 0.4784, 0.7044, 0.9276, 0.8792, 1.0439, 1.0141, 0.7299, 0.7082,\n",
       "                      0.4764, 0.7450, 0.6408, 0.6583, 0.9292, 0.6827, 0.6031, 0.8110, 0.7886,\n",
       "                      0.7454, 0.5766, 0.9232, 0.8677, 0.9206, 0.4967, 0.8183, 0.5238, 0.7617,\n",
       "                      0.4281, 0.8598, 0.7779, 0.9164, 0.9263, 0.6776, 0.8109, 0.2759, 0.9835,\n",
       "                      0.7161, 0.7892, 1.0277, 0.4158, 0.6633, 1.1483, 1.0812, 0.5156, 0.4030,\n",
       "                      0.9590, 0.8771, 0.6963, 0.3763, 0.5049, 0.9297, 0.4356, 0.7804, 1.2797,\n",
       "                      0.3951, 0.9141, 1.0266, 0.8152, 0.6128, 0.6216, 0.5823, 0.5596, 0.8789,\n",
       "                      1.0479, 0.7271, 0.8479, 1.1416, 0.9364, 0.8446, 0.4570, 0.8503, 0.7068,\n",
       "                      0.6494, 0.7594, 0.9360, 0.6588, 1.1217, 0.6634, 0.6576, 0.4880, 0.7847,\n",
       "                      0.4194, 0.9809, 0.9617, 0.5881, 0.9225, 0.9878, 0.4811, 1.0106, 1.1256,\n",
       "                      0.5640, 1.3338, 0.8707, 0.3603, 0.3554, 0.8999, 0.4656, 1.1270, 0.8930,\n",
       "                      0.8431, 0.9281, 0.8672, 0.8748, 0.6814, 0.4334, 0.5035, 0.9673],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_block4.bn1.num_batches_tracked',\n",
       "              tensor(345, device='cuda:0')),\n",
       "             ('conv_block4.bn2.weight',\n",
       "              tensor([1.0012, 1.0010, 0.9970, 0.9972, 1.0059, 0.9961, 0.9998, 0.9994, 0.9990,\n",
       "                      0.9940, 0.9949, 0.9973, 0.9986, 1.0008, 0.9971, 0.9981, 1.0023, 0.9967,\n",
       "                      1.0008, 0.9952, 0.9994, 0.9980, 0.9981, 1.0006, 0.9943, 0.9961, 0.9966,\n",
       "                      1.0001, 0.9969, 0.9994, 0.9920, 0.9989, 0.9964, 1.0012, 1.0033, 0.9973,\n",
       "                      1.0002, 0.9998, 0.9986, 0.9981, 0.9936, 0.9975, 0.9985, 0.9964, 0.9996,\n",
       "                      1.0022, 0.9946, 0.9962, 0.9999, 0.9986, 0.9969, 1.0007, 0.9994, 0.9989,\n",
       "                      0.9938, 0.9998, 1.0007, 0.9908, 1.0021, 0.9939, 0.9975, 0.9999, 0.9964,\n",
       "                      0.9986, 0.9919, 0.9985, 1.0002, 0.9960, 0.9958, 1.0022, 0.9942, 0.9994,\n",
       "                      0.9999, 0.9965, 0.9985, 1.0007, 0.9980, 0.9970, 0.9974, 0.9978, 0.9970,\n",
       "                      0.9976, 0.9998, 1.0005, 0.9972, 0.9979, 1.0073, 1.0031, 0.9961, 1.0010,\n",
       "                      0.9988, 0.9959, 0.9986, 0.9994, 0.9955, 1.0021, 0.9990, 0.9990, 0.9993,\n",
       "                      0.9989, 0.9941, 1.0006, 1.0003, 0.9960, 0.9970, 0.9973, 0.9999, 0.9941,\n",
       "                      0.9971, 0.9992, 0.9953, 1.0005, 0.9992, 1.0010, 0.9970, 1.0020, 1.0010,\n",
       "                      0.9985, 0.9995, 0.9965, 1.0019, 0.9980, 0.9968, 1.0000, 0.9976, 0.9966,\n",
       "                      0.9979, 0.9946, 0.9984, 1.0012, 0.9970, 0.9983, 0.9974, 0.9957, 0.9972,\n",
       "                      0.9983, 0.9971, 0.9915, 0.9994, 0.9964, 0.9994, 1.0009, 0.9913, 0.9955,\n",
       "                      0.9998, 0.9986, 1.0000, 0.9957, 0.9994, 0.9967, 0.9959, 1.0004, 0.9978,\n",
       "                      0.9993, 1.0006, 0.9966, 1.0015, 0.9973, 0.9992, 1.0020, 1.0001, 0.9959,\n",
       "                      0.9951, 0.9988, 0.9939, 1.0006, 0.9952, 0.9949, 1.0005, 1.0009, 0.9957,\n",
       "                      0.9983, 1.0020, 0.9974, 0.9980, 0.9954, 0.9959, 0.9938, 0.9983, 0.9964,\n",
       "                      1.0000, 0.9978, 0.9971, 0.9942, 0.9982, 1.0004, 0.9947, 0.9996, 0.9963,\n",
       "                      0.9949, 0.9963, 1.0003, 0.9990, 0.9942, 0.9963, 0.9990, 0.9969, 0.9925,\n",
       "                      0.9981, 0.9963, 1.0002, 1.0001, 0.9948, 0.9965, 0.9962, 0.9983, 0.9921,\n",
       "                      1.0020, 0.9953, 0.9969, 0.9994, 0.9999, 0.9979, 1.0006, 0.9975, 0.9943,\n",
       "                      0.9945, 0.9972, 0.9980, 0.9971, 0.9958, 0.9978, 1.0009, 0.9970, 0.9906,\n",
       "                      0.9978, 0.9995, 0.9985, 0.9963, 0.9984, 0.9976, 0.9932, 1.0003, 0.9981,\n",
       "                      0.9964, 0.9978, 1.0017, 1.0002, 1.0000, 0.9976, 0.9957, 0.9972, 0.9979,\n",
       "                      1.0006, 0.9994, 1.0005, 1.0029, 0.9951, 0.9983, 0.9984, 0.9952, 0.9968,\n",
       "                      0.9955, 1.0010, 0.9979, 0.9980, 1.0009, 0.9955, 1.0008, 0.9974, 0.9987,\n",
       "                      0.9991, 0.9944, 0.9991, 0.9939, 0.9981, 0.9996, 0.9997, 0.9981, 0.9983,\n",
       "                      1.0015, 0.9942, 0.9978, 0.9957, 1.0002, 0.9957, 0.9983, 0.9956, 0.9998,\n",
       "                      0.9996, 1.0044, 0.9975, 0.9962, 0.9999, 1.0002, 0.9976, 0.9983, 0.9956,\n",
       "                      0.9925, 0.9990, 0.9977, 0.9962, 0.9971, 0.9964, 0.9961, 0.9995, 0.9986,\n",
       "                      0.9960, 0.9923, 0.9984, 1.0002, 0.9983, 0.9971, 0.9986, 0.9988, 0.9983,\n",
       "                      0.9937, 0.9964, 0.9989, 0.9962, 0.9975, 0.9963, 0.9974, 0.9977, 0.9986,\n",
       "                      1.0008, 1.0005, 0.9966, 0.9968, 0.9995, 0.9992, 0.9954, 0.9966, 1.0002,\n",
       "                      1.0002, 0.9994, 1.0000, 1.0000, 1.0010, 1.0023, 0.9982, 0.9980, 0.9971,\n",
       "                      1.0015, 0.9934, 0.9969, 0.9928, 1.0007, 0.9972, 0.9993, 0.9915, 1.0005,\n",
       "                      0.9984, 0.9947, 0.9993, 0.9982, 0.9994, 0.9985, 0.9971, 0.9940, 0.9966,\n",
       "                      0.9929, 0.9976, 1.0009, 0.9989, 0.9967, 0.9936, 0.9991, 1.0000, 0.9999,\n",
       "                      0.9983, 1.0001, 0.9985, 0.9970, 0.9962, 0.9936, 1.0022, 0.9964, 1.0002,\n",
       "                      0.9912, 1.0038, 1.0054, 0.9992, 0.9995, 0.9975, 0.9989, 1.0011, 0.9990,\n",
       "                      0.9980, 0.9971, 0.9991, 0.9954, 0.9990, 0.9978, 0.9976, 0.9988, 0.9975,\n",
       "                      1.0007, 0.9986, 0.9901, 0.9994, 0.9959, 0.9951, 0.9979, 0.9986, 0.9969,\n",
       "                      0.9992, 0.9971, 0.9966, 0.9929, 0.9979, 0.9984, 0.9985, 0.9989, 0.9972,\n",
       "                      0.9955, 1.0013, 0.9980, 0.9999, 0.9972, 0.9986, 1.0001, 1.0021, 0.9986,\n",
       "                      0.9969, 0.9998, 0.9954, 0.9945, 0.9961, 0.9987, 0.9987, 0.9959, 0.9993,\n",
       "                      0.9988, 1.0012, 0.9936, 1.0001, 0.9986, 0.9974, 0.9945, 1.0001, 0.9973,\n",
       "                      0.9966, 0.9999, 1.0017, 0.9948, 0.9989, 0.9981, 0.9930, 0.9990, 0.9977,\n",
       "                      0.9981, 0.9939, 0.9997, 0.9959, 0.9970, 0.9995, 0.9985, 0.9987, 0.9986,\n",
       "                      0.9999, 0.9972, 0.9995, 1.0007, 0.9994, 0.9983, 0.9990, 0.9982, 0.9964,\n",
       "                      0.9996, 1.0013, 0.9929, 0.9976, 0.9877, 1.0006, 0.9974, 0.9995, 0.9954,\n",
       "                      0.9963, 0.9980, 0.9972, 1.0028, 0.9977, 0.9973, 0.9971, 0.9998, 0.9984,\n",
       "                      1.0039, 0.9969, 0.9986, 0.9946, 0.9976, 0.9985, 1.0009, 0.9994, 0.9998,\n",
       "                      0.9972, 0.9991, 0.9999, 0.9984, 0.9930, 0.9980, 0.9989, 0.9981, 0.9994,\n",
       "                      0.9979, 0.9983, 1.0004, 0.9993, 0.9967, 0.9962, 0.9999, 0.9965, 0.9992,\n",
       "                      0.9967, 0.9971, 1.0011, 1.0036, 0.9928, 1.0014, 0.9996, 1.0001],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_block4.bn2.bias',\n",
       "              tensor([ 1.4014e-03, -8.8227e-04, -9.1565e-04, -2.7466e-03,  4.8261e-03,\n",
       "                      -5.1536e-03, -4.8194e-03,  1.1337e-03, -6.4848e-03, -2.9187e-03,\n",
       "                      -5.7784e-03, -2.3393e-03,  3.1783e-04,  2.3976e-04, -2.3254e-03,\n",
       "                      -7.9688e-04,  1.1482e-03, -2.5146e-03, -3.1052e-03, -4.9517e-03,\n",
       "                      -8.9653e-04, -8.3237e-05,  5.5974e-04, -2.4100e-03, -3.6467e-03,\n",
       "                      -3.5174e-03, -4.1071e-03, -1.4007e-03, -1.5549e-03, -4.3548e-04,\n",
       "                      -6.6642e-03, -3.6918e-05, -2.7991e-03,  4.1683e-03,  1.8100e-03,\n",
       "                      -2.5828e-03, -9.5412e-04,  5.4939e-04, -3.4740e-03, -2.2173e-03,\n",
       "                      -6.0717e-03, -4.5910e-03, -3.2266e-03, -1.5557e-03,  1.5688e-03,\n",
       "                       2.1353e-03, -2.6796e-03, -4.9099e-03, -2.4642e-03, -2.2491e-03,\n",
       "                      -3.8942e-03,  6.0523e-04,  1.8815e-03, -4.3452e-03, -5.4178e-03,\n",
       "                      -4.3091e-04,  2.3982e-03, -7.4052e-03, -1.3617e-03, -3.9753e-03,\n",
       "                      -3.4757e-03, -4.6566e-04, -3.5354e-03, -2.3460e-03, -4.8580e-03,\n",
       "                      -4.4978e-03, -3.2923e-04, -4.2953e-03, -3.2723e-03, -1.0958e-03,\n",
       "                      -4.6110e-03, -2.6780e-03, -1.3790e-03, -4.2559e-03,  9.8514e-04,\n",
       "                      -8.3980e-04, -2.9879e-03, -8.8940e-04, -1.4162e-03, -4.5592e-03,\n",
       "                      -2.2103e-03,  4.2874e-04, -2.7369e-03,  3.8270e-04, -3.6758e-03,\n",
       "                      -3.7950e-03,  1.9866e-03,  2.0169e-03, -4.1326e-03, -3.3328e-04,\n",
       "                      -8.2826e-04, -4.8100e-03, -2.6072e-03,  3.9857e-03, -2.4624e-03,\n",
       "                      -4.0884e-04, -4.8172e-03, -7.8740e-04, -4.0248e-03, -2.9223e-03,\n",
       "                      -4.1684e-03,  8.6301e-04,  8.9467e-04, -2.3350e-03, -4.8135e-03,\n",
       "                      -4.0674e-03, -4.5394e-03, -4.2455e-03, -2.2270e-03, -1.2564e-03,\n",
       "                      -2.5886e-03,  4.3380e-04, -3.4058e-03,  6.1555e-05, -3.3269e-03,\n",
       "                      -4.1288e-04,  1.4134e-03, -1.1726e-03, -1.1847e-03, -3.2211e-03,\n",
       "                       3.5201e-03, -1.9100e-03, -4.7763e-03, -1.5977e-03, -7.1030e-05,\n",
       "                      -4.1592e-03, -2.0377e-03, -2.7856e-03, -1.9151e-03, -2.4913e-04,\n",
       "                      -5.3123e-03, -1.9275e-03, -7.9378e-03, -2.4374e-03, -6.4406e-03,\n",
       "                      -1.1590e-03, -5.5920e-03, -5.7150e-03, -1.1118e-04, -2.7163e-03,\n",
       "                      -1.6787e-04,  1.8234e-03, -6.8863e-03, -2.9903e-03, -5.0222e-04,\n",
       "                      -1.9195e-04, -3.6662e-03, -3.6367e-03,  3.3316e-03, -2.5362e-03,\n",
       "                      -2.9119e-03,  3.1626e-04, -6.0689e-03,  4.8607e-04,  1.4931e-03,\n",
       "                      -3.7661e-03,  2.6209e-03, -3.3761e-03, -3.0629e-03, -3.9842e-03,\n",
       "                      -8.1858e-04, -3.0266e-03, -4.5827e-03, -2.6258e-03, -4.6397e-03,\n",
       "                       4.1740e-03, -5.3394e-03, -6.4570e-03, -2.4418e-03, -1.0176e-03,\n",
       "                      -3.0657e-03, -6.9438e-03,  2.4117e-03, -4.2744e-03, -3.1115e-03,\n",
       "                      -5.3547e-03, -2.3957e-03, -6.3796e-03, -4.1832e-04, -2.7474e-03,\n",
       "                      -1.6024e-03, -3.0389e-03, -3.3686e-03, -5.3496e-03, -2.4578e-03,\n",
       "                      -1.7414e-03, -6.0544e-03, -2.2687e-03, -3.5449e-03, -4.5191e-03,\n",
       "                      -2.3771e-03,  8.2025e-04, -1.2106e-03, -4.8597e-03, -5.0230e-03,\n",
       "                      -3.3846e-03, -4.6014e-03, -7.6955e-03, -4.7942e-04, -3.5140e-03,\n",
       "                       1.2566e-03, -8.6611e-04, -4.7884e-03, -2.0596e-03, -3.5219e-03,\n",
       "                      -1.6526e-03, -6.4469e-03, -3.7947e-03, -6.2272e-03, -3.1436e-03,\n",
       "                      -4.6073e-03,  3.5361e-04, -1.9702e-03, -9.5626e-04, -4.3179e-03,\n",
       "                      -5.2919e-03, -5.8653e-03, -1.4483e-03, -6.7714e-04, -5.2400e-03,\n",
       "                      -5.6830e-03, -5.2073e-03, -3.2163e-03, -2.7713e-03, -6.9666e-03,\n",
       "                      -2.2467e-03, -9.0969e-04, -3.3442e-03, -4.0379e-03, -3.0116e-04,\n",
       "                      -4.6238e-03, -7.7541e-03, -5.0949e-04, -1.9608e-03, -1.5473e-03,\n",
       "                      -2.8489e-03,  1.3288e-03, -2.4636e-05, -1.9943e-03, -3.5276e-03,\n",
       "                      -1.8353e-03, -3.0223e-03, -3.3304e-03,  1.7811e-03, -4.0211e-04,\n",
       "                      -7.2715e-04,  1.0978e-03, -4.7072e-03, -4.5083e-04, -2.6000e-03,\n",
       "                      -4.7945e-03, -1.3850e-03, -3.0458e-03,  1.2358e-03, -4.0398e-03,\n",
       "                      -2.5625e-03,  3.7307e-04, -3.2366e-03, -1.5050e-04, -2.9917e-03,\n",
       "                      -2.4160e-03, -8.5272e-04, -4.3068e-03, -7.7808e-04, -3.7555e-03,\n",
       "                      -9.8603e-04, -1.0336e-03,  5.9265e-05, -2.7001e-03, -1.7474e-03,\n",
       "                       1.5760e-03, -5.4472e-03, -1.0269e-03, -5.6967e-03, -3.4828e-03,\n",
       "                      -4.2557e-03, -3.0920e-03, -6.4539e-03, -1.5240e-03, -1.9362e-03,\n",
       "                       1.9502e-04, -2.4076e-03, -2.2951e-03, -2.6634e-04, -5.8695e-04,\n",
       "                      -1.7203e-03, -3.3453e-04, -5.3498e-03, -7.6296e-03, -1.9136e-04,\n",
       "                      -2.5867e-03, -5.3834e-03, -1.4443e-03, -5.7589e-03, -3.2257e-03,\n",
       "                      -6.6864e-04, -1.2269e-03, -4.3733e-03, -6.4058e-03, -4.7452e-03,\n",
       "                       1.4916e-03, -3.4163e-03, -3.4842e-03, -1.5446e-03, -2.2465e-03,\n",
       "                      -4.0833e-03, -4.6468e-03, -2.4445e-03, -4.7985e-04, -6.5354e-03,\n",
       "                      -5.2766e-03, -5.5892e-03, -5.1182e-04, -1.6852e-03, -4.3797e-04,\n",
       "                       1.9920e-03,  1.0789e-03, -3.2736e-03, -1.7605e-03, -9.6054e-05,\n",
       "                      -3.2140e-03, -3.5340e-03, -3.2165e-03, -4.2151e-03, -4.9702e-03,\n",
       "                      -1.1838e-04, -3.3476e-03, -1.4952e-03, -1.4529e-03,  2.0862e-03,\n",
       "                      -5.2471e-04,  3.5409e-04, -1.1418e-03, -1.0688e-03, -5.7740e-03,\n",
       "                      -2.8939e-04, -5.2889e-03,  2.2923e-03, -3.2006e-03,  3.7062e-05,\n",
       "                      -6.3593e-03, -2.5362e-03, -2.4206e-03, -5.4342e-03,  2.6809e-04,\n",
       "                      -3.1168e-03,  4.4570e-04, -3.9438e-04, -1.6033e-03, -5.4556e-03,\n",
       "                      -2.5918e-03, -6.2324e-03, -2.6257e-03,  1.4885e-03, -6.5695e-04,\n",
       "                      -1.6077e-03, -4.9245e-03, -1.0473e-03,  2.0335e-03, -6.5559e-04,\n",
       "                      -1.2685e-03, -2.7096e-03, -1.3661e-03, -1.4856e-03, -2.9959e-03,\n",
       "                      -5.3775e-03, -1.7756e-03, -3.9067e-03,  1.1275e-03, -8.3625e-03,\n",
       "                       5.0529e-03,  6.3628e-03, -2.0474e-03, -1.4824e-03, -5.3277e-03,\n",
       "                       7.8116e-04, -1.5638e-03, -6.8844e-04, -3.4516e-04, -2.5742e-03,\n",
       "                      -1.0258e-03, -4.3199e-03,  8.7718e-05, -4.3016e-03, -1.0312e-03,\n",
       "                       1.1937e-03, -2.2609e-03, -4.7769e-04, -1.4548e-03, -8.8054e-03,\n",
       "                      -2.7508e-03, -2.2502e-03, -5.4206e-03, -7.3251e-04, -7.5633e-04,\n",
       "                      -6.5052e-03,  2.3773e-04, -2.1442e-03, -4.1379e-03, -5.4830e-03,\n",
       "                       5.1224e-04, -2.8868e-03, -1.0733e-03, -4.8977e-03, -4.1213e-03,\n",
       "                      -6.7855e-03,  6.1264e-06, -4.6718e-03, -9.4973e-04, -1.0247e-03,\n",
       "                      -1.6619e-03,  8.3499e-05,  6.6529e-04,  5.8953e-04, -3.8747e-03,\n",
       "                       1.1937e-03, -5.4084e-03, -9.7381e-03, -2.9016e-03, -9.0928e-04,\n",
       "                      -3.8353e-03, -5.1019e-03, -5.1533e-04, -1.6020e-03, -1.4248e-04,\n",
       "                      -7.4057e-03,  2.3759e-03, -1.1993e-03, -1.1995e-03, -5.6573e-03,\n",
       "                       3.4680e-03, -5.8658e-04, -3.3008e-03, -9.2791e-04,  7.9037e-04,\n",
       "                      -4.2518e-03, -3.3497e-03, -2.4296e-03, -6.0665e-03, -2.8104e-03,\n",
       "                      -3.2047e-03, -1.0844e-03, -4.2632e-03,  1.3185e-03, -2.4785e-03,\n",
       "                      -4.0743e-03, -1.3418e-03,  5.5351e-04, -1.9565e-03, -2.7079e-03,\n",
       "                      -1.2434e-03, -3.3903e-03,  1.6550e-04, -3.3557e-03, -1.3036e-03,\n",
       "                      -2.3928e-03,  5.3404e-04, -1.4056e-03, -2.8614e-03,  6.5356e-03,\n",
       "                       4.6942e-04, -7.0990e-03, -3.5705e-03, -1.1415e-02, -1.2217e-03,\n",
       "                      -8.5591e-04,  1.5488e-03, -4.5871e-03, -2.3571e-03, -5.1641e-03,\n",
       "                      -2.7738e-03,  1.5098e-03, -9.6279e-04, -5.2755e-03, -3.9358e-03,\n",
       "                      -3.6692e-04, -1.7753e-03,  3.9094e-04, -2.6177e-03, -3.5392e-03,\n",
       "                      -6.9444e-03, -4.6347e-03, -3.7686e-03,  1.2902e-03,  9.4645e-04,\n",
       "                      -7.2787e-04, -5.7440e-03,  1.4052e-04,  1.6344e-03, -1.4475e-03,\n",
       "                      -5.9516e-03, -2.2922e-04,  9.9534e-05, -2.1616e-03, -3.3255e-04,\n",
       "                      -7.2131e-04, -1.5098e-03,  5.0326e-03,  4.4213e-04, -1.9861e-03,\n",
       "                      -5.5895e-03,  1.0246e-03, -4.7450e-03, -2.2936e-03, -1.0773e-03,\n",
       "                      -6.9269e-04,  1.6599e-03,  3.9868e-03, -4.6716e-03, -2.6005e-04,\n",
       "                      -1.8958e-04, -1.9968e-03], device='cuda:0')),\n",
       "             ('conv_block4.bn2.running_mean',\n",
       "              tensor([-1.1180e+00,  1.3543e+00, -1.2431e+00, -1.5101e+00, -1.9684e-01,\n",
       "                      -8.3063e-01,  3.8366e-01,  7.6812e-01,  3.1318e+00, -1.4961e+00,\n",
       "                       1.1190e-01, -2.6080e+00, -1.3691e+00,  4.4479e-02,  8.0369e-01,\n",
       "                      -6.7648e-01,  7.8175e-01,  4.0187e-01,  1.2500e+00,  2.8421e-01,\n",
       "                      -1.6976e+00, -2.3261e+00, -8.6192e-01,  2.2806e+00, -9.1801e-01,\n",
       "                      -1.0152e+00,  1.0117e-02,  1.1991e-02, -8.7605e-01,  1.9479e+00,\n",
       "                       4.6299e-02, -1.5035e+00, -2.0066e+00,  1.3812e+00,  1.3140e+00,\n",
       "                       5.0341e-01,  6.1858e-01,  1.6386e+00,  8.7632e-01, -1.6481e+00,\n",
       "                      -9.4094e-01, -1.6417e-01, -6.5579e-01, -1.1734e+00, -1.7689e+00,\n",
       "                       9.6843e-01, -1.5846e+00, -4.7988e-01,  3.1284e+00,  3.2860e-02,\n",
       "                       1.7869e+00,  9.0253e-01, -1.7816e+00,  2.0977e+00, -1.1093e+00,\n",
       "                       2.2164e-01, -1.3161e+00, -4.0044e-01,  2.0027e+00, -2.3621e+00,\n",
       "                      -7.6441e-01, -2.7165e-01,  1.4267e+00,  7.8431e-01, -2.8570e+00,\n",
       "                       7.6682e-01, -1.2263e+00,  2.0161e-01,  1.5602e+00,  2.3385e+00,\n",
       "                      -2.0114e+00,  2.4422e+00, -8.3755e-01, -1.1185e+00,  1.6951e+00,\n",
       "                       2.3953e+00,  2.1906e+00, -2.3350e-01, -1.1430e+00, -4.9882e-01,\n",
       "                       1.2192e+00,  1.8452e-01,  6.1044e-01, -1.5137e+00,  1.0863e+00,\n",
       "                      -5.8412e-01,  4.6228e-01,  1.8091e+00, -1.4052e+00,  2.2692e+00,\n",
       "                       1.1049e-01, -3.5790e-01, -2.2083e+00, -8.6440e-01, -2.3714e+00,\n",
       "                      -2.9232e-01,  6.3117e-02,  1.7882e+00, -5.9637e-01,  6.7273e-01,\n",
       "                      -2.6285e+00,  1.8803e-01, -1.7930e-01, -7.9577e-01,  4.9810e-01,\n",
       "                       1.0156e+00,  1.3727e+00, -2.8214e+00, -2.5338e+00,  1.6325e+00,\n",
       "                      -1.4325e+00, -1.1280e+00,  1.3658e+00, -4.8898e-02, -8.6425e-01,\n",
       "                       1.1370e+00, -7.2323e-01, -1.2874e+00, -1.5150e+00,  4.1010e-03,\n",
       "                       1.2925e+00, -2.0475e+00, -5.0989e-01,  2.7719e+00,  3.2386e-01,\n",
       "                      -2.7847e+00,  1.7152e-01,  1.8403e+00,  1.3872e+00,  6.6093e-01,\n",
       "                       2.2851e+00, -2.9775e-01,  1.9835e+00, -1.8240e+00,  2.1353e+00,\n",
       "                       5.2190e-01,  1.3941e-01, -2.1547e+00, -2.4960e+00,  5.3866e-01,\n",
       "                      -1.8645e+00,  1.4203e-01, -2.5281e+00, -2.9152e+00,  6.9922e-01,\n",
       "                      -4.5139e-01,  2.3887e+00, -5.0625e-01, -7.9165e-02, -2.0531e+00,\n",
       "                       1.4875e+00,  1.9150e-01,  2.4998e+00,  2.8547e-02, -8.8356e-01,\n",
       "                      -3.5055e-02, -5.8084e-01,  2.3129e-01,  1.6293e+00,  7.7294e-01,\n",
       "                       2.9955e+00, -1.1161e+00, -2.0307e+00,  1.5895e+00,  1.4785e+00,\n",
       "                      -1.9431e-01, -1.5848e+00,  9.5623e-01,  8.1633e-01,  1.3886e+00,\n",
       "                      -1.2130e+00, -9.3540e-02, -2.2673e+00,  1.9120e+00,  1.3650e+00,\n",
       "                       8.7468e-01,  6.8821e-01,  1.8556e-01, -5.8923e-01, -1.0442e+00,\n",
       "                       1.9135e+00,  1.7458e+00, -1.4987e-01, -1.6033e+00,  6.6461e-01,\n",
       "                       2.1628e+00, -3.4093e-01, -2.8960e-02,  7.7065e-01, -1.4003e+00,\n",
       "                      -2.2836e+00,  1.4017e+00,  1.4325e+00, -2.7918e+00,  1.1791e-01,\n",
       "                       2.6443e+00, -8.1665e-01, -1.2925e+00,  1.8884e+00,  1.0719e+00,\n",
       "                      -2.2914e+00,  1.2619e-01, -3.1845e-02, -2.8612e+00, -1.4673e+00,\n",
       "                       1.8077e+00, -2.5481e+00, -3.8680e-01,  1.4741e+00, -4.6938e-01,\n",
       "                      -4.4970e-01,  1.4636e-03, -3.8982e-01,  1.6237e-01, -4.4014e-01,\n",
       "                      -7.8339e-01, -7.1213e-01, -2.9902e+00,  1.5778e+00,  5.4177e-01,\n",
       "                       1.7152e-01,  2.1575e+00,  3.6451e+00, -7.8727e-01, -1.5494e+00,\n",
       "                      -3.3974e-01,  8.7819e-01, -3.1161e-01, -5.2865e-01,  1.6246e+00,\n",
       "                       7.2494e-01, -8.2181e-02,  2.0823e+00, -8.0761e-01,  6.8453e-01,\n",
       "                      -9.8630e-01, -1.8774e-01,  1.3030e+00,  1.9128e+00,  5.0645e-01,\n",
       "                       1.5316e+00, -3.7289e-01,  2.5935e+00,  9.6505e-01,  1.0247e+00,\n",
       "                      -1.9098e-01,  1.1030e+00, -1.5331e+00,  5.0514e-02,  1.3959e-01,\n",
       "                       1.5121e-01,  1.5170e+00, -2.5751e+00, -1.1421e-01, -2.1182e-01,\n",
       "                       1.6048e+00,  1.4166e+00, -3.5825e-01, -8.2257e-01, -1.7249e+00,\n",
       "                       1.1484e+00, -1.8773e+00, -7.9022e-01, -5.5516e-01, -3.6827e+00,\n",
       "                      -2.4344e+00,  2.3569e+00, -1.8276e-01,  1.7995e+00,  1.0770e+00,\n",
       "                      -9.6210e-01, -2.1370e-01, -7.1432e-01,  1.4039e+00, -6.5567e-01,\n",
       "                      -1.2934e+00, -9.5666e-01,  8.3368e-01,  1.2313e-01,  2.8692e-01,\n",
       "                      -6.8257e-02,  1.2845e+00, -1.6072e+00,  6.5420e-01,  4.1576e-01,\n",
       "                      -1.8747e+00, -2.1668e+00,  8.6079e-01,  4.9323e-01, -1.7237e+00,\n",
       "                      -6.5996e-01, -6.0589e-01, -1.2719e+00,  9.6303e-01, -3.1268e-01,\n",
       "                       3.3383e-01,  3.2916e-01, -8.4399e-01, -2.9365e+00, -6.9016e-01,\n",
       "                       8.7714e-01,  2.4998e+00,  1.6355e+00,  1.2685e+00,  1.9912e+00,\n",
       "                       5.0197e-01, -2.9195e+00, -1.9157e+00, -1.7143e+00,  1.3565e+00,\n",
       "                      -6.1840e-01, -3.2716e-01, -2.3204e+00,  2.5287e-02,  2.1688e+00,\n",
       "                       9.0959e-01,  2.5049e-01, -1.8820e+00, -1.4510e+00, -1.1853e+00,\n",
       "                       1.3860e+00,  1.3282e+00,  1.1732e+00,  2.7880e+00,  9.0303e-01,\n",
       "                       1.0495e-01,  2.0725e+00,  2.5324e+00,  1.4783e+00,  1.2455e+00,\n",
       "                      -2.3225e+00, -2.6764e-01,  2.3144e-01,  1.6707e+00, -2.7101e+00,\n",
       "                       2.9008e-02,  5.2940e-01, -1.3555e+00, -6.0803e-01, -1.6577e+00,\n",
       "                      -1.0784e+00,  2.3143e+00,  1.8531e+00,  1.6013e+00,  1.2719e+00,\n",
       "                       1.6276e+00, -1.0141e+00,  1.7941e+00, -1.4499e+00, -6.1410e-01,\n",
       "                      -5.9454e-01, -1.1683e+00, -1.4562e+00, -9.8186e-01,  1.5502e+00,\n",
       "                      -6.6418e-01, -1.1811e+00,  2.0523e+00, -1.7225e+00,  7.2864e-01,\n",
       "                       1.4456e+00, -6.2837e-01,  9.1800e-01,  1.1066e-01, -9.0201e-01,\n",
       "                      -1.7147e+00,  3.2369e-02, -1.3197e-01, -1.4412e+00, -1.2700e+00,\n",
       "                       7.4658e-01,  1.8900e+00,  7.3753e-01,  5.5269e-02,  2.3773e-01,\n",
       "                      -7.7879e-01,  3.0559e-01, -2.2633e-01, -7.6486e-01, -1.5892e+00,\n",
       "                       1.9161e+00, -1.7583e+00, -2.9836e+00,  4.5668e-01, -1.9834e-01,\n",
       "                       1.0127e+00, -1.7651e+00,  1.7044e+00, -1.3337e+00, -6.4349e-01,\n",
       "                       6.4206e-02,  6.2712e-02, -3.9717e-01, -2.3686e+00, -4.0933e-02,\n",
       "                       2.2501e+00, -1.7296e+00,  5.5417e-01, -1.0191e+00, -2.1756e+00,\n",
       "                       4.3203e-01,  5.4804e-01, -1.7894e-01,  4.1606e-01,  1.1460e+00,\n",
       "                       5.8740e-01,  1.2543e+00,  1.1318e-01,  2.4377e-01, -1.4275e-01,\n",
       "                       4.0395e-01, -1.8390e+00,  2.5688e+00, -6.3185e-03, -5.4180e-01,\n",
       "                       7.7073e-01,  2.4383e-02, -1.7105e-02,  2.6435e-01,  8.8495e-01,\n",
       "                      -6.1438e-01,  1.9084e-02,  1.1718e-01,  6.8448e-01,  2.2215e-02,\n",
       "                      -6.4737e-01,  1.7295e-01, -1.3673e-02, -5.8376e-01, -2.7886e-01,\n",
       "                       1.0206e+00, -2.8793e+00, -3.9370e-01,  1.7462e-01,  2.2782e+00,\n",
       "                       7.5077e-01,  2.2654e+00,  1.4842e+00, -2.0906e+00,  1.7724e+00,\n",
       "                       1.2115e+00,  2.4630e+00, -1.7579e+00, -6.3838e-01, -1.4639e+00,\n",
       "                       1.0422e+00,  6.6067e-01, -2.9104e+00,  1.7539e+00,  2.4060e+00,\n",
       "                       2.9274e+00,  1.9132e+00, -1.9480e+00,  2.0672e-01,  1.5811e+00,\n",
       "                       1.9246e+00, -5.9145e-01, -3.1833e+00, -8.6773e-02, -6.7480e-01,\n",
       "                       1.4073e+00, -2.4421e+00, -5.4671e-01, -1.0288e+00,  1.1172e+00,\n",
       "                      -7.7995e-01, -1.8997e+00, -8.3653e-01,  1.2850e-01,  2.2578e+00,\n",
       "                      -1.1431e+00, -4.9658e-01,  1.6204e+00, -7.7273e-02, -1.1514e-01,\n",
       "                      -1.6883e+00,  9.5885e-03,  1.7721e+00,  2.4048e+00,  2.7925e+00,\n",
       "                      -1.6336e+00, -7.9648e-02,  1.8704e+00, -8.3581e-01,  1.1447e+00,\n",
       "                       7.0254e-01, -2.8229e-01,  1.3794e+00,  7.3072e-01,  2.0080e+00,\n",
       "                      -3.5691e-01, -1.4734e+00,  1.1274e-02,  2.5147e-01,  1.6748e+00,\n",
       "                       1.4232e-01, -8.0852e-01, -6.0240e-01, -1.5570e+00, -1.3303e+00,\n",
       "                       7.4399e-01,  8.3319e-01,  6.4446e-01,  2.2039e+00, -6.2903e-01,\n",
       "                      -5.9824e-01,  1.6673e-01,  2.1699e+00, -2.5340e+00,  1.8594e+00,\n",
       "                      -1.2355e+00,  2.7811e+00], device='cuda:0')),\n",
       "             ('conv_block4.bn2.running_var',\n",
       "              tensor([ 3.2902,  2.9242,  3.1599,  4.2189,  1.7976,  1.3736,  2.9504,  1.4237,\n",
       "                       4.5511,  3.6207,  2.8630,  1.7450,  2.9711,  1.9593,  1.0512,  3.7917,\n",
       "                       2.3749,  3.2959,  4.3585,  2.0761,  2.2930,  4.6585,  4.2762,  6.2961,\n",
       "                       5.9837,  3.5145,  1.9899,  2.9043,  2.3367,  4.5913,  6.4770,  3.6221,\n",
       "                       3.0573,  7.4631,  5.4473,  4.1625,  1.7148,  1.4173,  2.6519,  1.4461,\n",
       "                       6.1634,  2.6484,  4.5411,  2.5601,  4.3010,  1.7474,  3.1074,  3.4238,\n",
       "                       3.7631,  0.9268,  5.1361,  2.0759,  2.6870,  6.3533,  2.2756,  1.0714,\n",
       "                       3.2051,  3.5959,  6.2169,  2.9441,  1.4103,  2.7360,  2.2110,  3.8242,\n",
       "                       4.2261,  3.5516,  3.4969,  3.8337,  5.5806,  3.3007,  2.8004,  2.1613,\n",
       "                       3.3061,  2.9364,  5.8811,  3.4412,  6.3965,  6.0390,  5.1125,  3.3014,\n",
       "                       6.2115,  4.1783,  1.9828,  2.7097,  1.7512,  1.8468,  9.9574,  3.4401,\n",
       "                       3.1212,  5.9961,  2.0402,  2.9482,  5.7405,  3.0268,  7.5525,  2.0372,\n",
       "                       1.5811,  3.4252,  2.1990,  1.2564,  4.6478,  4.6309,  3.7789,  4.8663,\n",
       "                       4.3437,  1.7213,  3.8744,  2.6232,  7.3641,  5.7762,  4.0279,  2.0759,\n",
       "                       1.6373,  5.5989,  2.3972,  4.1931,  0.9505,  2.3478,  1.8539,  3.5227,\n",
       "                       3.8667,  3.6254,  1.1008,  5.3569,  3.8137,  2.0604,  3.6148,  3.8671,\n",
       "                       4.4527,  1.7202,  1.4157,  1.3754,  4.6668,  1.9116,  3.0310,  4.0219,\n",
       "                       1.5417,  2.1128,  4.8622,  6.0392,  3.9227,  5.6233,  7.7933,  4.3060,\n",
       "                       5.3202,  2.7156,  8.9420,  3.1511,  2.7890,  1.5701,  5.7684,  3.1607,\n",
       "                       3.4145,  1.4027,  3.5487,  2.6245,  3.6938,  4.6177,  7.0230,  1.7939,\n",
       "                       3.0186,  1.4586,  5.5240,  4.3283,  3.7509,  3.8297,  4.8032,  2.2482,\n",
       "                       2.2431,  2.3774,  3.7979,  2.1208,  2.3146,  3.4618,  1.8476,  4.3978,\n",
       "                       4.4713,  4.7326,  2.3311,  2.4120,  4.1942,  8.1453,  6.6958,  2.8743,\n",
       "                       3.3819,  4.6171,  2.9390,  1.4520,  1.9870,  2.5075,  4.6362,  1.5010,\n",
       "                       5.5427,  4.7416,  1.8334,  7.2249,  2.6713,  4.9972,  2.3579,  1.7058,\n",
       "                       4.8408,  3.3923,  3.3770,  7.4802,  4.0186,  5.1087,  4.4593,  1.9886,\n",
       "                       4.9313,  1.7833,  1.8079,  2.6140,  5.9602,  5.1664,  1.1929,  4.2753,\n",
       "                       1.1318,  4.5901,  3.0495,  2.6852,  2.9037,  6.3023,  4.1195,  2.6173,\n",
       "                       7.7458,  1.4912,  1.6927,  2.5598,  2.3788,  5.0618,  1.2848,  2.3642,\n",
       "                       5.4482,  5.2623,  4.3799,  2.9601,  2.0914,  1.8953,  2.4259,  4.6228,\n",
       "                       1.6272,  3.7555,  8.7791,  1.6782,  3.5279,  1.3829,  3.7071,  3.5357,\n",
       "                       3.0415,  1.3105,  3.4385,  4.0179,  3.2083,  4.1712,  1.6896,  3.1886,\n",
       "                       2.6759,  1.6983,  2.0551,  1.8912,  1.6598,  2.0594,  4.1741,  4.4149,\n",
       "                      11.6259,  8.0944,  1.6729,  0.9149,  4.2854,  4.1769,  2.3194,  2.0062,\n",
       "                       4.1191,  3.6810,  1.1047,  2.5295,  1.3816,  2.3575,  1.7464,  1.6873,\n",
       "                       2.8863,  5.4072,  2.1688,  1.5236,  1.6017,  1.3287,  3.3059,  2.0753,\n",
       "                       2.5510,  1.7464,  2.2680,  2.0767,  4.5766,  3.3629,  3.0584,  2.3148,\n",
       "                       3.4616,  2.6422,  7.1869,  1.7914,  6.9369,  5.0138,  3.2691,  6.2783,\n",
       "                       6.9120,  2.0367,  5.9872,  6.5978,  6.8153,  2.2322,  1.6401,  1.8375,\n",
       "                       3.4974,  1.7678,  4.9408,  3.7502,  4.8358,  1.4345,  5.2795,  7.0332,\n",
       "                       2.9007,  3.2074,  2.3406,  3.3298,  3.2754,  2.3282,  5.7362,  6.1995,\n",
       "                       3.1486,  8.7421,  2.5935,  2.9111,  3.5468,  2.5545,  8.3941,  5.2668,\n",
       "                       1.9217,  2.0796,  1.1921,  2.8331,  5.7370,  6.0965,  5.5864,  4.3109,\n",
       "                       3.4315,  2.8884,  1.6506,  6.7315,  5.0529,  1.4211,  4.4151,  6.4903,\n",
       "                       2.4724,  3.0100,  2.2614,  1.7272,  6.8136,  6.0096,  2.7584,  3.6759,\n",
       "                       4.3408,  1.2062,  3.2795,  3.0692,  4.0832,  3.1113,  2.0211,  3.6727,\n",
       "                       2.8112,  6.7246,  0.7899,  2.2343,  1.8770,  2.3110,  2.0674,  2.0576,\n",
       "                       2.2393,  1.3355,  2.5332,  2.4317,  3.7299,  3.2878,  4.0679,  2.2766,\n",
       "                       6.1897,  4.6314,  2.3888,  2.5484,  4.8477,  3.4913,  3.5106,  3.0799,\n",
       "                       1.3306,  2.1790,  1.5501,  5.5115,  1.5191,  1.8271,  3.5871,  3.9709,\n",
       "                       5.7165,  3.2794,  2.2566,  3.8498,  5.2200,  2.2167,  1.3100,  1.0479,\n",
       "                       3.5847,  3.1000,  2.9781,  6.2311,  2.6438,  4.4046,  1.7109,  3.1362,\n",
       "                       1.1009,  6.6522,  3.1679,  7.3218,  1.7730,  2.3496,  4.8751,  3.1551,\n",
       "                       1.2968,  0.8313,  5.4236,  1.5597,  2.8513,  3.6401,  4.5152,  4.9490,\n",
       "                       3.2379,  6.8167,  7.2549,  1.8572,  4.8202,  1.9736,  2.9182,  7.0801,\n",
       "                       1.8491,  7.8223,  3.7211,  1.1330,  3.2207,  1.7615,  2.4226,  7.1647,\n",
       "                       2.9866,  5.2015,  3.2238,  3.1909,  4.6778,  1.2758,  2.1099,  8.0888,\n",
       "                       2.8563,  3.0064,  4.2396,  1.9544,  5.1512,  7.9999,  2.0439,  6.0777,\n",
       "                       1.6682,  4.0886,  4.5905,  2.6876,  4.8713,  6.4376,  2.4923,  3.3351,\n",
       "                       1.5532,  2.9089,  2.1339,  3.0104,  2.7631,  3.0899, 11.1554,  8.0015,\n",
       "                       3.2057,  2.6993,  6.3141,  2.4383,  3.5305,  3.4163,  1.9258,  3.2462,\n",
       "                       2.2831,  2.8383,  9.0393,  2.6726,  4.0773,  1.2082,  1.1597,  1.3085,\n",
       "                       2.0652,  3.0735,  5.2262,  4.5155,  2.9483,  2.1960,  4.5239,  6.5793,\n",
       "                       2.7267,  2.6547,  3.0178,  4.2360,  3.1046,  2.9502,  4.1210,  3.4785],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_block4.bn2.num_batches_tracked',\n",
       "              tensor(345, device='cuda:0')),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 0.0294, -0.0453,  0.0037,  ..., -0.0475, -0.0092, -0.0762],\n",
       "                      [-0.0092,  0.0496,  0.0160,  ..., -0.0325,  0.0120,  0.0422],\n",
       "                      [-0.0595, -0.0666, -0.0034,  ..., -0.0320,  0.0630, -0.0191],\n",
       "                      ...,\n",
       "                      [ 0.0052, -0.0472,  0.0336,  ...,  0.0193,  0.0385,  0.0342],\n",
       "                      [ 0.0578,  0.0297, -0.0116,  ...,  0.0370,  0.0741, -0.0441],\n",
       "                      [-0.0404, -0.0710,  0.0527,  ...,  0.0138, -0.0047, -0.0122]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([-3.4194e-03, -2.1624e-03, -3.1226e-04, -5.8361e-05,  6.5616e-04,\n",
       "                      -1.9084e-03,  8.7399e-04, -1.0081e-03, -3.7128e-03, -2.1400e-03,\n",
       "                      -1.1899e-03, -2.1534e-03, -3.8330e-03,  6.5384e-04, -1.9327e-03,\n",
       "                      -4.1778e-03, -3.0638e-03, -1.6578e-03, -3.6465e-03, -2.1111e-03,\n",
       "                      -1.0045e-03, -1.2436e-03, -2.0097e-03, -5.3703e-03,  2.5015e-03,\n",
       "                      -5.3278e-04, -2.1037e-03, -3.9258e-03, -2.9298e-03, -9.3726e-04,\n",
       "                      -1.2818e-03, -2.2916e-03, -2.1174e-04, -3.2120e-03, -5.9527e-04,\n",
       "                      -1.6870e-03, -1.8368e-03, -2.8064e-04,  8.0622e-04, -1.8001e-03,\n",
       "                      -1.5985e-03,  1.1156e-03,  9.6161e-05,  1.6155e-03, -1.0492e-03,\n",
       "                      -2.6672e-03, -4.8140e-03, -2.3183e-03, -3.2558e-03, -5.1111e-04,\n",
       "                      -1.6648e-03,  1.0821e-03, -1.7815e-03,  1.1679e-03, -1.4452e-03,\n",
       "                      -1.9343e-03,  5.3384e-04, -3.0284e-04, -1.5171e-03, -1.0367e-03,\n",
       "                      -8.6397e-04, -2.8277e-03, -1.0031e-03, -3.1707e-03, -4.0920e-03,\n",
       "                       2.0776e-03, -3.2997e-04, -2.7661e-04, -1.2155e-03, -2.3206e-03,\n",
       "                      -5.2166e-04,  2.4618e-03, -2.0233e-03,  8.6507e-04, -2.9030e-03,\n",
       "                       8.3251e-04, -2.1923e-03, -1.1394e-03, -7.0597e-05, -1.4517e-04,\n",
       "                      -3.6523e-03, -2.4549e-03, -2.9920e-03,  9.0109e-04, -2.1480e-03,\n",
       "                      -4.5215e-03, -4.9720e-04, -6.5069e-04, -5.4251e-04,  9.8292e-04,\n",
       "                      -2.7782e-03,  2.2483e-03, -1.1078e-03, -2.4430e-03, -1.0536e-03,\n",
       "                      -2.5782e-03, -1.4600e-03, -5.3138e-04, -1.0955e-03, -1.5688e-03,\n",
       "                      -3.3126e-03, -3.9212e-03, -3.6158e-04,  1.1884e-03, -3.7280e-03,\n",
       "                      -2.0213e-03, -2.9607e-04,  1.2123e-03, -9.4881e-04, -1.3696e-03,\n",
       "                       6.6677e-04, -3.8370e-03,  5.5508e-04,  2.2193e-03, -1.6424e-04,\n",
       "                      -3.1806e-03,  1.8292e-03, -4.6299e-03, -2.2625e-04, -6.8094e-04,\n",
       "                      -1.5418e-03,  2.3304e-03, -2.1921e-03, -3.4491e-03, -2.7798e-03,\n",
       "                       1.5248e-04,  3.8724e-03, -5.7719e-04,  2.8926e-03, -3.0378e-03,\n",
       "                      -1.6973e-03, -1.7850e-03,  2.4423e-04, -4.2179e-03, -4.1416e-03,\n",
       "                      -1.2902e-03, -4.8700e-04, -4.4965e-04, -2.5789e-03,  6.6443e-04,\n",
       "                      -2.2327e-03, -2.4944e-03,  3.6365e-05, -6.5247e-04,  2.7367e-03,\n",
       "                      -5.4368e-04,  8.3361e-05, -3.2559e-03, -3.8928e-03, -6.4611e-04,\n",
       "                      -8.1635e-04,  3.4271e-04, -2.8309e-04, -1.0289e-03, -1.9101e-03,\n",
       "                      -1.4718e-03,  9.3283e-04,  1.1597e-03,  3.0864e-03, -1.0849e-03,\n",
       "                      -2.5817e-03,  8.5271e-04,  2.9064e-04, -1.1058e-03, -9.7454e-04,\n",
       "                      -1.2213e-03, -1.0410e-03, -1.5474e-03, -9.7210e-05, -3.9130e-03,\n",
       "                      -1.8320e-03,  2.4708e-03,  4.5080e-04, -1.7552e-04,  2.1441e-04,\n",
       "                      -3.7486e-03, -2.6342e-03, -4.1508e-04, -8.0397e-04, -7.8469e-04,\n",
       "                      -5.0072e-03, -4.6511e-04, -1.0710e-03, -5.7070e-03, -1.7429e-03,\n",
       "                      -2.7696e-03, -1.0126e-03, -3.3844e-03,  4.6893e-04,  1.8968e-04,\n",
       "                      -1.7923e-03,  2.5195e-03, -1.5066e-03, -3.0165e-03, -2.1543e-04,\n",
       "                      -1.9821e-03, -5.1322e-04,  1.2591e-03, -1.4496e-03,  1.9377e-03,\n",
       "                       6.7048e-04, -5.7673e-04, -2.8865e-04, -7.9415e-04,  4.2771e-04,\n",
       "                      -6.7367e-04, -3.8906e-03, -7.6336e-04, -1.1722e-03, -3.7974e-03,\n",
       "                      -2.5149e-04, -6.1295e-04, -1.1112e-03, -7.3799e-04, -3.0305e-03,\n",
       "                      -2.3825e-03, -5.0945e-03, -2.4846e-03, -2.1752e-03, -9.0297e-06,\n",
       "                      -4.8442e-03, -3.2776e-03,  2.1512e-03, -2.0779e-03, -5.6320e-04,\n",
       "                      -1.8819e-03, -2.6442e-03,  5.7942e-04,  1.7317e-03, -4.2081e-04,\n",
       "                      -4.2484e-03, -9.3264e-04,  4.6209e-04, -1.3900e-03, -7.1183e-04,\n",
       "                      -6.7636e-05, -4.7871e-03, -3.8156e-03,  1.4616e-03,  6.3522e-05,\n",
       "                      -1.2747e-03, -1.5711e-03, -1.6134e-03, -1.6286e-03,  8.5303e-04,\n",
       "                      -2.5236e-03,  5.3403e-04, -7.0288e-04, -3.9874e-03,  1.7028e-03,\n",
       "                      -1.9346e-03, -1.2143e-03,  8.0647e-04, -1.2794e-03,  2.2889e-03,\n",
       "                      -1.1996e-03, -3.1596e-03, -1.4189e-04, -1.9465e-04,  4.4577e-06,\n",
       "                      -1.4533e-03, -1.6431e-06,  1.3023e-05, -9.5719e-04,  1.2108e-03,\n",
       "                      -8.9429e-04, -2.5535e-04,  1.3224e-03,  2.9613e-04, -4.2178e-03,\n",
       "                      -3.1311e-03,  3.0216e-04, -1.5304e-03, -1.1163e-03,  1.1192e-03,\n",
       "                       1.0405e-03,  1.1778e-03,  3.5486e-04,  9.1229e-04, -2.2544e-03,\n",
       "                      -3.6250e-03, -3.2898e-03, -1.8443e-03, -1.2558e-03, -5.6226e-04,\n",
       "                       1.6550e-03, -1.1507e-03,  1.0392e-03, -1.1303e-03,  1.3474e-03,\n",
       "                      -2.8958e-03, -3.8611e-03, -7.2218e-04, -1.1306e-03, -5.5297e-04,\n",
       "                      -2.3096e-03, -2.9898e-03,  5.0670e-04, -1.4791e-03, -1.7237e-03,\n",
       "                      -1.7648e-03,  1.8043e-03,  4.5562e-04,  6.4109e-04, -2.3190e-05,\n",
       "                      -2.0196e-03, -2.2188e-03, -4.9406e-04, -7.8130e-04, -3.4613e-03,\n",
       "                       4.2363e-04,  8.2417e-04, -1.7167e-03, -6.0007e-04, -1.3903e-03,\n",
       "                      -9.7577e-04, -2.1888e-03, -4.4241e-03, -1.3991e-03, -2.6688e-03,\n",
       "                      -2.6975e-03, -4.1662e-03,  2.5043e-03,  1.2918e-03, -4.2634e-03,\n",
       "                      -3.7495e-03,  1.5587e-03, -6.4034e-04, -1.1316e-03, -1.8822e-03,\n",
       "                       8.3091e-04,  1.2009e-04, -1.6882e-03, -1.4204e-03,  4.2861e-04,\n",
       "                      -2.2134e-04,  9.6633e-05, -3.0023e-03, -4.1965e-04, -1.1564e-03,\n",
       "                      -1.2643e-03,  1.7581e-04, -5.7305e-04, -1.2942e-03, -2.7837e-03,\n",
       "                      -1.6763e-04, -1.9597e-04, -8.2454e-04, -2.3781e-03, -2.1334e-03,\n",
       "                      -2.9932e-03, -1.5303e-03, -2.3201e-05,  1.7289e-04, -2.6111e-03,\n",
       "                      -1.3484e-03,  1.2183e-03, -7.5892e-04, -1.7702e-03, -1.8247e-03,\n",
       "                      -3.6116e-03, -2.0741e-03,  6.6752e-04, -9.0839e-04, -2.1356e-03,\n",
       "                       7.1378e-04,  8.2844e-04,  2.7097e-04,  1.6002e-03,  8.9775e-04,\n",
       "                       2.9719e-03, -2.6413e-03, -2.5694e-03, -1.1866e-03, -5.0660e-04,\n",
       "                      -2.9354e-03, -1.3731e-03, -1.0460e-03, -1.9888e-03, -2.5442e-03,\n",
       "                       2.0774e-05,  3.2833e-03, -1.4914e-03,  4.2311e-04, -3.9604e-03,\n",
       "                      -2.1855e-03, -3.4809e-04, -7.0514e-04, -8.8461e-04,  1.7821e-04,\n",
       "                      -2.3991e-03,  4.9547e-03,  2.3897e-03, -2.9800e-03, -1.1873e-03,\n",
       "                       1.4455e-04, -2.9563e-03,  1.6791e-03, -1.2611e-03,  1.0182e-04,\n",
       "                      -2.9989e-03, -1.2302e-03, -3.4352e-03,  4.3285e-04, -3.8377e-03,\n",
       "                       3.6641e-04,  2.3568e-04,  4.7836e-04,  1.3482e-03, -3.3447e-03,\n",
       "                       3.9782e-05, -2.6308e-05, -4.8371e-03, -3.3172e-03, -2.3979e-03,\n",
       "                      -1.1803e-03,  7.4208e-04,  2.4566e-03, -2.2155e-03, -3.6864e-03,\n",
       "                       1.7606e-03,  6.0545e-05, -1.8044e-03, -2.0749e-03,  1.4476e-04,\n",
       "                      -9.5261e-05,  4.7998e-04, -1.8975e-05, -4.2986e-03, -2.2521e-03,\n",
       "                      -2.3333e-03, -3.2242e-03,  1.4524e-03, -1.0722e-03,  7.5260e-04,\n",
       "                       8.8104e-04, -1.0920e-03,  4.2848e-03,  2.2873e-04, -2.2048e-03,\n",
       "                      -2.6950e-03, -1.4712e-03,  1.3256e-03, -2.8321e-03, -9.4544e-04,\n",
       "                      -3.3305e-03, -2.0105e-03, -1.3876e-03, -7.5933e-04, -2.7972e-04,\n",
       "                      -2.8945e-03, -1.0846e-03, -2.8158e-03, -1.5193e-03, -1.3362e-03,\n",
       "                      -2.1447e-03, -2.1817e-03, -7.4420e-04, -1.0488e-03, -6.4694e-04,\n",
       "                       1.2223e-03, -5.2248e-03, -3.6590e-03, -4.9465e-04,  1.4253e-04,\n",
       "                      -7.3770e-04, -6.2701e-04, -1.2182e-03,  1.4637e-03, -1.0837e-03,\n",
       "                       2.7008e-03, -1.5770e-03, -1.2716e-03, -2.3091e-03,  2.7302e-04,\n",
       "                      -4.5188e-03,  2.3150e-04,  8.9133e-04, -1.4142e-03, -1.5307e-03,\n",
       "                      -5.5031e-04,  2.0799e-03, -2.9647e-03,  1.8816e-03,  2.9660e-04,\n",
       "                      -1.7620e-03, -1.9028e-03, -4.0303e-03,  2.1182e-03, -1.6907e-03,\n",
       "                      -5.7277e-04, -8.0765e-04, -5.1002e-04, -1.4682e-03,  8.6554e-04,\n",
       "                      -3.0561e-03, -3.0600e-03,  2.2848e-03, -1.9628e-03, -2.6082e-03,\n",
       "                       9.7056e-04,  1.9566e-03, -3.4171e-04, -8.8381e-05,  1.7664e-03,\n",
       "                      -1.2883e-03, -2.5551e-03, -9.6025e-04, -1.5804e-03,  2.6246e-03,\n",
       "                       1.3737e-03,  1.2057e-03], device='cuda:0')),\n",
       "             ('fc_audioset.weight',\n",
       "              tensor([[ 5.6342e-02,  4.8208e-02, -7.8213e-02,  7.2249e-02, -3.4814e-02,\n",
       "                        8.4575e-02, -1.2265e-02, -5.7277e-02,  7.4383e-02, -5.4404e-02,\n",
       "                        9.5161e-02, -3.8021e-02,  1.3907e-02,  3.3371e-02,  3.7425e-02,\n",
       "                        7.0724e-02,  8.5340e-02,  8.6171e-02,  5.0432e-02,  5.1629e-02,\n",
       "                        7.2340e-03,  9.1341e-02, -2.4920e-02,  5.2238e-02, -2.5575e-02,\n",
       "                        2.1166e-02, -1.0051e-01, -1.1998e-03,  7.0793e-02,  9.9442e-02,\n",
       "                        5.3564e-02,  4.3101e-02, -2.8960e-02,  3.2873e-03,  7.2718e-02,\n",
       "                       -6.2957e-02,  7.7808e-02, -3.6937e-03, -6.2714e-02, -2.0431e-02,\n",
       "                        6.6986e-02, -8.8019e-02, -8.1592e-03,  4.5234e-02,  2.2425e-02,\n",
       "                        3.8937e-02,  5.2665e-02,  3.2965e-02,  9.9627e-02,  3.6106e-02,\n",
       "                        6.9423e-02, -8.2052e-03, -1.7090e-02, -6.1411e-02,  1.7521e-02,\n",
       "                        9.6118e-02, -2.5666e-02, -1.4921e-02,  4.0439e-03, -9.4095e-02,\n",
       "                        5.3168e-02,  9.0378e-02,  5.2794e-03,  7.9132e-03, -9.8469e-02,\n",
       "                       -6.1335e-02, -1.2676e-02,  8.5033e-02,  3.0507e-02,  8.0860e-02,\n",
       "                        2.8736e-04, -8.0149e-02,  9.0168e-02, -9.7338e-02,  8.7821e-02,\n",
       "                       -2.6260e-02,  4.8857e-02,  1.7265e-02, -5.3922e-02, -5.5423e-03,\n",
       "                        9.0993e-02, -3.1131e-02,  2.3022e-02, -6.0006e-02,  9.1361e-02,\n",
       "                       -2.2725e-04, -1.9974e-02,  8.2820e-02,  9.0912e-02, -8.0623e-03,\n",
       "                        7.3079e-02, -8.8995e-02,  5.2816e-02,  4.8420e-02, -5.3419e-02,\n",
       "                        7.3931e-02,  7.8150e-02, -8.6221e-02,  8.3139e-02,  1.0177e-01,\n",
       "                        3.6397e-02,  1.6403e-03, -7.7557e-03, -5.8227e-02,  6.6641e-02,\n",
       "                        9.1981e-02, -3.0588e-02, -1.5978e-02, -8.7468e-02, -6.3558e-02,\n",
       "                       -3.5162e-02,  8.2870e-02, -7.5797e-02, -5.3782e-02,  7.0535e-02,\n",
       "                        6.6508e-02, -3.2436e-02,  5.1525e-05,  2.1532e-02,  6.9108e-02,\n",
       "                        2.7726e-02,  7.8172e-02,  1.5879e-02, -9.7374e-03,  2.8045e-02,\n",
       "                       -7.6351e-03, -9.4509e-03,  6.1156e-02, -6.5270e-02,  7.1228e-02,\n",
       "                        4.7044e-02,  9.8997e-03, -2.4272e-02,  5.7565e-02,  6.5531e-02,\n",
       "                       -4.4602e-02,  1.3485e-02,  7.9593e-02,  8.4771e-02, -1.5563e-02,\n",
       "                        9.1880e-02,  6.3393e-03, -2.7859e-02,  3.2168e-02, -6.3862e-02,\n",
       "                       -4.4259e-02,  8.0954e-02,  4.2064e-03,  5.3968e-02, -7.6178e-02,\n",
       "                       -6.6046e-02, -1.0022e-01, -1.0294e-01,  5.7481e-02,  8.8402e-02,\n",
       "                        7.0923e-02,  4.0757e-02, -6.6753e-02, -1.2360e-02,  9.9023e-02,\n",
       "                        3.3994e-02,  2.3637e-02, -9.2688e-03, -7.7820e-03, -4.3459e-02,\n",
       "                        2.4698e-02, -8.1997e-02, -1.4806e-02, -5.3052e-02,  3.4383e-02,\n",
       "                       -5.6924e-02, -2.3958e-02, -7.0175e-02, -6.3142e-04, -5.2626e-02,\n",
       "                        8.2318e-02,  7.5225e-02,  1.0301e-02,  7.8519e-02, -6.4169e-02,\n",
       "                        9.6662e-02,  2.6241e-02, -7.2808e-02,  1.3831e-02, -9.1633e-02,\n",
       "                        4.8673e-02, -4.0936e-03,  2.7022e-02, -7.9242e-03, -3.7109e-02,\n",
       "                        6.2861e-02, -7.5559e-02,  6.1153e-02,  1.0170e-01, -9.4068e-02,\n",
       "                       -6.6609e-02,  6.8230e-03, -7.7524e-02, -4.0258e-02, -8.3859e-02,\n",
       "                       -9.9099e-02, -2.2858e-02,  1.0606e-01, -1.0530e-01, -9.3260e-02,\n",
       "                        5.0698e-02,  6.1333e-02,  6.1266e-02,  4.7838e-02,  1.1052e-03,\n",
       "                        8.6000e-02, -4.2337e-02,  1.0228e-01, -9.2568e-02,  1.0520e-01,\n",
       "                        6.7444e-03,  5.6712e-02,  5.2531e-02,  1.1491e-02, -4.0368e-03,\n",
       "                        3.5985e-02,  7.9090e-02, -5.8770e-02, -7.3783e-02, -9.9873e-02,\n",
       "                        3.2187e-02,  1.8156e-03, -2.8568e-02, -6.6166e-02, -3.1859e-02,\n",
       "                        9.2189e-02, -3.5184e-03, -7.8600e-02,  7.6076e-02, -8.8944e-02,\n",
       "                       -6.8382e-02,  7.9687e-02,  7.5547e-02, -5.5216e-02,  6.1170e-02,\n",
       "                        7.4479e-02,  2.4871e-02,  1.0077e-01,  1.0385e-01, -1.3149e-02,\n",
       "                        9.6319e-02, -3.6901e-02,  6.3597e-02,  9.3138e-02, -2.9386e-02,\n",
       "                        4.0511e-02, -2.1012e-03, -4.0276e-02,  2.1335e-02, -3.8836e-02,\n",
       "                        1.0346e-01,  1.0429e-01, -4.1527e-02, -8.6455e-02, -5.7898e-02,\n",
       "                       -1.2791e-02, -9.2252e-02, -3.0186e-02,  4.6533e-02, -4.4240e-02,\n",
       "                       -1.2942e-02, -2.3815e-02, -6.9495e-02, -9.3782e-02,  2.9334e-04,\n",
       "                       -5.7490e-02,  7.8853e-02,  8.9025e-02, -6.6062e-03, -3.0719e-02,\n",
       "                        6.1730e-02, -1.0037e-01, -9.3309e-02, -2.7783e-02,  1.0682e-01,\n",
       "                        6.8960e-02,  8.2157e-02,  9.6533e-02,  1.0006e-01, -6.7828e-02,\n",
       "                       -5.3661e-02, -1.0385e-01, -1.0135e-01, -1.6924e-03, -2.8388e-02,\n",
       "                        5.9208e-02,  9.3262e-02, -2.8001e-02,  1.3928e-02, -8.9766e-02,\n",
       "                       -7.9838e-02,  4.9845e-02,  1.6080e-02, -4.9346e-03, -2.5148e-02,\n",
       "                        8.3785e-02,  2.7266e-02, -6.9276e-03, -1.0242e-01, -9.3767e-02,\n",
       "                       -6.3676e-02,  1.9775e-02, -3.2442e-02, -2.0909e-02,  6.2979e-02,\n",
       "                        2.9096e-02, -7.1889e-02, -2.5744e-02, -8.1127e-02, -1.0322e-01,\n",
       "                       -9.8485e-02,  1.0626e-04,  6.5698e-02,  1.0549e-01,  6.2722e-02,\n",
       "                        5.5615e-02,  1.0141e-01,  8.3357e-02, -1.8520e-02,  9.5767e-02,\n",
       "                        4.3875e-02, -5.3106e-02,  1.5552e-03, -1.0067e-02,  9.3553e-02,\n",
       "                       -8.3118e-02, -8.1169e-02,  2.0777e-02,  4.5027e-02, -2.2468e-02,\n",
       "                       -8.6762e-03,  5.7282e-02,  9.7707e-02,  9.1423e-02,  4.1241e-03,\n",
       "                       -8.9348e-02, -1.4417e-03,  2.0541e-02, -2.0736e-03, -5.6633e-02,\n",
       "                        5.9407e-02, -5.4614e-02,  1.2406e-02,  1.9145e-02,  3.8815e-02,\n",
       "                        4.8286e-03,  7.8424e-02, -5.9840e-02, -2.6229e-02, -2.4138e-04,\n",
       "                        8.3647e-02, -1.0359e-01,  6.8927e-02,  4.3496e-03,  4.6407e-02,\n",
       "                        5.4532e-02, -6.0587e-02, -5.2160e-02,  9.2475e-02,  8.6542e-02,\n",
       "                        1.2430e-02, -4.0530e-02, -3.6985e-02, -6.1686e-02, -1.1923e-02,\n",
       "                       -3.3622e-02,  8.4611e-02,  1.1315e-02,  6.3773e-02,  1.7822e-02,\n",
       "                        2.0505e-02,  7.9261e-02, -9.9691e-02,  2.6267e-02, -3.8745e-02,\n",
       "                       -6.3766e-02, -2.4777e-02,  9.0044e-03, -5.3835e-02,  2.0040e-03,\n",
       "                        3.7332e-02, -3.5070e-02, -7.8264e-02,  4.8404e-02, -3.5349e-02,\n",
       "                        3.8276e-03, -6.1135e-02, -2.4510e-02,  4.4080e-02,  3.7872e-02,\n",
       "                       -4.1436e-02, -5.9857e-02, -9.5671e-02,  5.6214e-02, -5.6618e-02,\n",
       "                        6.0250e-04,  1.0345e-01,  2.4390e-03, -6.2677e-02,  3.9719e-02,\n",
       "                       -5.8417e-02, -1.3152e-02, -9.7588e-04, -4.3766e-02,  1.5407e-02,\n",
       "                        1.0070e-02, -6.5663e-02,  5.5691e-02, -3.1756e-02,  7.0691e-02,\n",
       "                       -3.2285e-03, -3.3359e-02, -3.4641e-02,  2.4886e-02,  8.8398e-02,\n",
       "                       -2.1583e-02, -8.9074e-02,  4.7765e-02,  6.5377e-02, -7.3586e-02,\n",
       "                       -2.2539e-02, -6.8931e-02, -4.5507e-02, -8.6248e-03,  9.9636e-02,\n",
       "                       -1.0969e-03, -9.3727e-02, -1.9996e-02, -6.9498e-03, -1.0381e-01,\n",
       "                       -6.0031e-02, -1.0280e-01, -9.6437e-03, -3.0235e-03,  4.7794e-02,\n",
       "                       -1.1310e-02,  2.4243e-02, -5.1000e-02,  5.2113e-02, -1.9326e-02,\n",
       "                        7.2584e-02,  1.0022e-01, -1.0801e-02,  7.3593e-02, -7.4289e-02,\n",
       "                        4.1899e-02,  7.2405e-03,  8.3539e-02, -5.1355e-02, -5.5968e-02,\n",
       "                        1.3256e-02,  1.7111e-02,  1.8934e-02,  1.2011e-02,  2.5799e-02,\n",
       "                       -4.1593e-02,  9.4837e-02,  9.0368e-03,  2.4383e-02, -8.2185e-02,\n",
       "                       -6.5313e-02,  2.9131e-02,  4.0399e-02,  1.0373e-01,  8.5661e-02,\n",
       "                       -1.0684e-01,  9.5704e-02,  6.6033e-03,  7.0866e-02, -6.6572e-02,\n",
       "                        9.3535e-02, -3.4487e-02, -8.9758e-03,  2.3707e-02,  2.8559e-02,\n",
       "                       -2.9578e-02, -8.8519e-02,  3.3965e-02, -9.8224e-02, -9.9861e-02,\n",
       "                        9.1411e-02,  2.8634e-02,  5.9999e-02, -9.5792e-02,  8.6367e-02,\n",
       "                       -1.7660e-02, -8.1779e-03, -9.5854e-02,  5.0663e-02, -2.0102e-02,\n",
       "                        6.8239e-02,  3.9907e-02, -6.3651e-02, -4.4163e-02, -1.0113e-01,\n",
       "                       -1.8391e-02, -4.8391e-02, -4.0414e-02, -1.7953e-03, -6.3966e-02,\n",
       "                        3.9783e-02,  6.4742e-02, -7.5763e-02,  2.5465e-02,  9.0425e-03,\n",
       "                       -2.4207e-02, -1.0032e-01]], device='cuda:0')),\n",
       "             ('fc_audioset.bias', tensor([-0.0011], device='cuda:0'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a54a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb78fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30aa9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27498311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cedefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2be575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabf785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe61897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe1287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efddf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c2840e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hj20/dcase_2020_T6/models/Cnn14_mAP=0.431.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4b16501a24f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpretrained_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/hj20/dcase_2020_T6/models/Cnn14_mAP=0.431.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hj20/dcase_2020_T6/models/Cnn14_mAP=0.431.pth'"
     ]
    }
   ],
   "source": [
    "pretrained_checkpoint=\"/home/hj20/dcase_2020_T6/models/Cnn14_mAP=0.431.pth\"\n",
    "checkpoint = torch.load(pretrained_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4cfe7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iteration': 440000,\n",
       " 'model': OrderedDict([('spectrogram_extractor.stft.conv_real.weight',\n",
       "               tensor([[[ 0.0000e+00,  9.4124e-06,  3.7649e-05,  ...,  8.4709e-05,\n",
       "                          3.7649e-05,  9.4124e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00,  9.4122e-06,  3.7646e-05,  ...,  8.4695e-05,\n",
       "                          3.7646e-05,  9.4122e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00,  9.4117e-06,  3.7638e-05,  ...,  8.4652e-05,\n",
       "                          3.7638e-05,  9.4117e-06]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4117e-06,  3.7638e-05,  ..., -8.4652e-05,\n",
       "                          3.7638e-05, -9.4117e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4122e-06,  3.7646e-05,  ..., -8.4695e-05,\n",
       "                          3.7646e-05, -9.4122e-06]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -9.4124e-06,  3.7649e-05,  ..., -8.4709e-05,\n",
       "                          3.7649e-05, -9.4124e-06]]], device='cuda:0')),\n",
       "              ('spectrogram_extractor.stft.conv_imag.weight',\n",
       "               tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -5.7753e-08, -4.6201e-07,  ...,  1.5592e-06,\n",
       "                          4.6201e-07,  5.7753e-08]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1550e-07, -9.2395e-07,  ...,  3.1179e-06,\n",
       "                          9.2395e-07,  1.1550e-07]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1550e-07,  9.2395e-07,  ...,  3.1179e-06,\n",
       "                         -9.2395e-07,  1.1550e-07]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -5.7753e-08,  4.6201e-07,  ...,  1.5592e-06,\n",
       "                         -4.6201e-07,  5.7753e-08]],\n",
       "               \n",
       "                       [[ 0.0000e+00, -1.1527e-21,  9.2214e-21,  ..., -1.7514e-17,\n",
       "                          1.2470e-17, -8.8136e-21]]], device='cuda:0')),\n",
       "              ('logmel_extractor.melW',\n",
       "               tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0043, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       ...,\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "                      device='cuda:0')),\n",
       "              ('bn0.weight',\n",
       "               tensor([1.2579, 1.2287, 1.1752, 1.1472, 1.1341, 1.1017, 1.0914, 1.0787, 1.0651,\n",
       "                       1.0756, 1.0683, 1.0589, 1.0478, 1.0323, 1.0432, 1.0094, 1.0038, 1.0202,\n",
       "                       1.0210, 1.0268, 1.0409, 1.0565, 1.0200, 1.0603, 1.0618, 1.0505, 1.0631,\n",
       "                       1.0512, 1.0770, 1.0790, 1.0833, 1.0788, 1.0826, 1.0741, 1.0893, 1.0994,\n",
       "                       1.1181, 1.1037, 1.1052, 1.1233, 1.1174, 1.1264, 1.1512, 1.1866, 1.2267,\n",
       "                       1.2610, 1.2632, 1.3015, 1.2884, 1.3413, 1.3513, 1.3659, 1.3383, 1.3445,\n",
       "                       1.3790, 1.3468, 1.3447, 1.3394, 1.2890, 1.2610, 1.2722, 1.2695, 1.2540,\n",
       "                       1.2942], device='cuda:0')),\n",
       "              ('bn0.bias',\n",
       "               tensor([ 0.1418,  0.1614,  0.2051,  0.2250,  0.2054,  0.2128,  0.2234,  0.2539,\n",
       "                        0.2251,  0.2122,  0.2185,  0.2002,  0.2017,  0.1822,  0.1683,  0.1444,\n",
       "                        0.1269,  0.1714,  0.1422,  0.1387,  0.1513,  0.1419,  0.1510,  0.1334,\n",
       "                        0.1520,  0.1332,  0.1163,  0.1276,  0.1073,  0.1257,  0.1314,  0.1131,\n",
       "                        0.1414,  0.1328,  0.1064,  0.1035,  0.0991,  0.1022,  0.1113,  0.1031,\n",
       "                        0.0918,  0.0667,  0.0340,  0.0058, -0.0343, -0.0510, -0.0735, -0.0952,\n",
       "                       -0.1210, -0.1620, -0.1719, -0.1713, -0.1978, -0.1898, -0.2296, -0.2104,\n",
       "                       -0.2010, -0.2143, -0.1837, -0.2698, -0.2991, -0.3428, -0.3216, -0.2706],\n",
       "                      device='cuda:0')),\n",
       "              ('bn0.running_mean',\n",
       "               tensor([-14.7698, -13.6179, -13.6138, -13.7430, -14.3962, -14.5996, -15.4520,\n",
       "                       -15.8805, -16.5379, -17.0350, -17.5244, -18.0900, -18.3324, -19.0569,\n",
       "                       -19.5501, -20.2974, -20.4803, -21.0466, -21.3381, -21.5437, -22.0068,\n",
       "                       -22.1964, -22.6461, -23.1714, -23.2960, -23.5023, -23.8864, -24.1805,\n",
       "                       -24.8282, -24.9183, -25.4159, -25.7884, -26.1122, -26.6204, -27.0275,\n",
       "                       -27.5277, -28.0286, -28.3588, -28.8325, -29.3342, -30.0424, -30.7998,\n",
       "                       -31.6253, -32.8063, -33.9453, -34.8903, -35.8278, -36.8257, -37.9765,\n",
       "                       -39.4108, -40.4666, -41.2937, -42.2061, -43.2223, -44.2648, -45.2302,\n",
       "                       -46.2764, -47.3646, -48.5596, -50.5382, -52.2995, -53.9504, -55.6551,\n",
       "                       -57.6545], device='cuda:0')),\n",
       "              ('bn0.running_var',\n",
       "               tensor([596.6601, 575.9350, 560.0305, 552.3881, 547.5211, 543.4526, 540.1447,\n",
       "                       537.5850, 537.4604, 537.6881, 536.0203, 530.9358, 531.9637, 525.5637,\n",
       "                       517.0662, 513.1134, 512.5848, 509.0781, 503.4427, 505.8644, 502.7238,\n",
       "                       499.5360, 499.5542, 495.1674, 495.0078, 492.7249, 487.0581, 484.2194,\n",
       "                       479.8156, 480.9565, 476.3221, 475.1716, 477.7686, 474.1192, 475.2479,\n",
       "                       472.0588, 468.3824, 464.7163, 466.6536, 467.5047, 463.1785, 460.5492,\n",
       "                       459.6526, 470.3666, 489.5420, 499.5362, 507.8021, 513.4002, 517.6402,\n",
       "                       540.6107, 557.5811, 558.7811, 560.7786, 561.4371, 562.8868, 558.7776,\n",
       "                       555.0521, 546.9778, 535.2908, 534.0878, 539.0059, 537.0637, 529.1208,\n",
       "                       521.8989], device='cuda:0')),\n",
       "              ('bn0.num_batches_tracked', tensor(440000, device='cuda:0')),\n",
       "              ('conv_block1.conv1.weight',\n",
       "               tensor([[[[-3.7039e-02, -4.2758e-01,  4.6078e-01],\n",
       "                         [-9.8838e-02, -4.7424e-01,  3.5086e-01],\n",
       "                         [ 5.4757e-02, -2.9605e-01,  4.8484e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.3487e-01, -2.7748e-01, -2.2969e-01],\n",
       "                         [-2.5529e-03, -1.0134e-01, -9.9216e-02],\n",
       "                         [ 8.8498e-02,  4.3399e-01,  3.1902e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.8117e-01,  2.1679e-01,  8.6598e-03],\n",
       "                         [-3.0433e-01,  4.2776e-01, -2.8384e-02],\n",
       "                         [-3.1323e-01,  3.7712e-01, -8.6349e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.1328e-01, -4.7214e-01, -1.5421e-01],\n",
       "                         [-7.4739e-03,  1.5373e-01, -9.9434e-02],\n",
       "                         [ 5.1257e-01,  3.8470e-01,  2.0314e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2202e-01,  1.1475e-01,  1.7375e-01],\n",
       "                         [ 4.6711e-02, -2.4738e-01, -1.1763e-01],\n",
       "                         [-1.2941e-01, -1.4176e-01, -8.9102e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.6680e-01, -5.6923e-01, -3.8833e-01],\n",
       "                         [ 7.2493e-01, -2.7824e-01,  9.7279e-03],\n",
       "                         [ 2.4725e-01, -1.6016e-01,  9.7753e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.4617e-01,  1.1877e-01,  9.5465e-02],\n",
       "                         [ 5.3723e-02,  1.6259e-02,  3.4303e-02],\n",
       "                         [-2.3713e-01, -1.7044e-01, -7.7720e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.7280e-01,  5.4870e-01, -3.0124e-01],\n",
       "                         [-3.1358e-01,  4.4885e-01, -2.8404e-01],\n",
       "                         [-1.4353e-01,  5.0320e-01, -2.3500e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.4014e-04, -6.3007e-02, -2.5290e-01],\n",
       "                         [-1.3695e-02, -7.0924e-02, -1.0243e-01],\n",
       "                         [ 1.5860e-01,  2.4922e-01,  7.3565e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2324e-01, -2.8807e-01,  7.9693e-01],\n",
       "                         [-2.5401e-01, -1.1556e-01,  2.5972e-01],\n",
       "                         [-2.0476e-01, -4.7462e-01, -3.4198e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.0406e-01,  5.1279e-02, -3.6834e-01],\n",
       "                         [-2.3591e-01,  2.6704e-01,  1.5689e-01],\n",
       "                         [-2.8982e-01, -2.9980e-02,  1.7038e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.3808e-02, -2.1475e-01,  2.4791e-01],\n",
       "                         [-1.5626e-01, -2.8334e-01,  9.1087e-02],\n",
       "                         [-8.4360e-02, -1.1746e-01,  1.6794e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.2985e-01, -1.6245e-01, -3.5523e-01],\n",
       "                         [ 5.0251e-01, -1.0382e-01, -3.8975e-01],\n",
       "                         [ 2.4276e-01,  5.4808e-02, -2.7259e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.4744e-01,  2.3009e-01,  8.3530e-01],\n",
       "                         [-1.4976e-01, -2.8275e-01,  2.4763e-01],\n",
       "                         [-1.9248e-01, -3.3660e-01, -1.4239e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.4622e-02, -5.6861e-02, -4.1197e-01],\n",
       "                         [ 5.7208e-01, -5.0864e-02, -4.3210e-01],\n",
       "                         [ 5.4853e-01,  5.0650e-02, -3.2082e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6556e-01, -5.3412e-01, -2.3066e-01],\n",
       "                         [-2.8875e-02,  2.4764e-02, -1.6386e-01],\n",
       "                         [-3.9200e-03,  5.5788e-01,  2.6252e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.1720e-01, -4.7870e-01,  1.1784e-01],\n",
       "                         [-2.0684e-01,  6.2280e-02,  4.1311e-01],\n",
       "                         [ 5.6433e-02,  4.4781e-02,  4.6758e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1200e-01,  2.7321e-01, -3.9600e-02],\n",
       "                         [-3.1901e-01,  3.1452e-01, -2.7479e-03],\n",
       "                         [-3.3993e-01,  3.6536e-01,  5.1426e-04]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.2003e-01,  1.8998e-01,  1.2129e-01],\n",
       "                         [-2.7666e-01,  9.2499e-02, -4.6375e-02],\n",
       "                         [-1.4448e-01,  6.8090e-02,  7.0098e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.7226e-02, -1.2127e-01,  2.3658e-01],\n",
       "                         [-2.4300e-01, -1.9383e-01,  1.1952e-01],\n",
       "                         [ 2.2897e-02, -8.7058e-02,  3.2172e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.3028e-02, -2.3576e-01,  4.1035e-02],\n",
       "                         [ 1.6508e-01, -1.1036e-01,  9.5125e-02],\n",
       "                         [-2.9840e-03,  1.8085e-01,  2.6306e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.4316e-01,  1.1665e+00, -4.3412e-01],\n",
       "                         [ 6.2403e-02, -5.5574e-01,  1.2445e-01],\n",
       "                         [ 5.2582e-02, -3.2262e-01,  1.8072e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.5395e-01,  6.7191e-01, -4.2608e-01],\n",
       "                         [ 1.4435e-01,  7.4019e-01, -1.7308e-01],\n",
       "                         [-2.6455e-01, -1.5263e-02, -2.0942e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.5521e-01, -2.1611e-01,  7.1947e-02],\n",
       "                         [ 3.0966e-01, -3.0091e-01, -7.8164e-03],\n",
       "                         [ 3.0483e-01, -3.1466e-01,  1.5690e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9823e-01, -4.2168e-01,  6.0279e-02],\n",
       "                         [-3.2808e-01, -3.3818e-01,  3.4307e-01],\n",
       "                         [-9.1788e-02,  2.4978e-01,  6.2914e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0916e-01, -1.0632e-02,  4.5488e-01],\n",
       "                         [ 1.1837e-02, -5.0426e-01,  5.5825e-02],\n",
       "                         [ 1.8273e-01, -5.3850e-01,  8.3406e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.7359e-01, -1.8598e-01,  2.1945e-02],\n",
       "                         [ 2.8800e-01, -1.5747e-01, -1.0243e-01],\n",
       "                         [ 1.2883e-01, -3.4466e-01, -1.4244e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.6872e-01, -1.4464e-01,  2.2020e-01],\n",
       "                         [-2.9175e-01,  2.2592e-01,  2.0379e-01],\n",
       "                         [-1.6604e-01,  2.6496e-01, -8.3792e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.5360e-02,  3.8966e-01,  1.4031e-01],\n",
       "                         [ 1.2257e-02,  2.1597e-02, -4.7005e-02],\n",
       "                         [ 9.1067e-02, -1.6526e-01, -1.9378e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0163e-01, -4.5580e-01,  3.1707e-01],\n",
       "                         [ 1.8935e-01, -4.5179e-01,  2.3650e-01],\n",
       "                         [ 2.7485e-01, -4.0986e-01,  2.1443e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.7262e-01, -1.0266e-01, -4.1695e-01],\n",
       "                         [ 4.8492e-01, -2.3177e-03, -4.4562e-01],\n",
       "                         [ 3.3022e-01,  6.2551e-02, -3.2547e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2101e-01,  1.0126e-01, -3.6913e-02],\n",
       "                         [ 1.4700e-01,  6.9705e-02, -3.9404e-02],\n",
       "                         [-5.5072e-02, -1.1184e-01, -6.6921e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.8531e-01, -4.7569e-02, -2.3400e-01],\n",
       "                         [ 3.4791e-01, -7.7497e-02, -2.4477e-01],\n",
       "                         [ 3.7497e-01, -1.4277e-01, -3.4089e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1033e+00,  1.2753e-01, -6.2010e-03],\n",
       "                         [-7.2243e-01, -4.6420e-01, -5.2412e-03],\n",
       "                         [-3.7374e-01,  4.0990e-01, -7.4779e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-6.1552e-01,  5.3512e-01,  8.1034e-02],\n",
       "                         [-1.1637e-01,  3.2702e-02,  9.7668e-03],\n",
       "                         [ 7.4868e-01, -5.4375e-01, -1.1775e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.5149e-01,  1.8367e-01,  5.9942e-01],\n",
       "                         [ 6.4945e-02, -3.3298e-01,  4.7456e-02],\n",
       "                         [-7.2457e-02, -6.4503e-01, -2.3545e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.3996e-01, -4.6708e-01,  6.5029e-02],\n",
       "                         [ 4.1431e-01, -5.8810e-01, -1.2947e-01],\n",
       "                         [ 6.3620e-01, -4.6198e-01,  8.9512e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.8400e-01,  6.0769e-01,  3.9696e-01],\n",
       "                         [-1.0041e-01, -5.5067e-02, -6.5041e-02],\n",
       "                         [-4.0160e-01, -5.5484e-01, -4.9943e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.7577e-01,  9.2406e-02,  9.8464e-02],\n",
       "                         [-2.4153e-01, -1.5672e-02,  1.2420e-01],\n",
       "                         [-6.3149e-01, -2.6339e-02,  4.9605e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.2362e-01, -4.3782e-01, -5.7199e-01],\n",
       "                         [ 5.7036e-02,  1.7327e-01,  5.8640e-02],\n",
       "                         [ 3.2428e-01,  2.6780e-01,  1.1553e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.2817e-02,  2.5345e-01, -2.3407e-01],\n",
       "                         [ 6.5310e-02,  1.0996e-01, -1.5513e-01],\n",
       "                         [-2.7904e-02,  2.7827e-01, -2.4337e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1770e-01,  3.1490e-01, -9.0855e-01],\n",
       "                         [-1.3766e-01,  3.3192e-03,  7.7066e-01],\n",
       "                         [-5.3093e-02, -3.6863e-01,  2.3213e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.5213e-02, -4.4828e-01,  6.2535e-02],\n",
       "                         [ 5.3619e-02, -4.0840e-01,  4.2392e-03],\n",
       "                         [ 2.0112e-01, -2.2866e-01,  3.0056e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.9792e-01,  2.0081e-01,  1.9037e-01],\n",
       "                         [-2.4127e-01, -3.5608e-01, -2.4821e-01],\n",
       "                         [-3.8929e-02,  1.7353e-01, -4.8857e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.0018e-01,  1.3077e-03, -2.7321e-01],\n",
       "                         [ 2.7165e-02,  3.3843e-02, -7.1168e-02],\n",
       "                         [ 5.3553e-02,  2.3183e-01, -4.2740e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.8983e-01, -3.7882e-02,  7.5205e-01],\n",
       "                         [-4.3510e-01, -2.7665e-01,  5.3879e-01],\n",
       "                         [-3.7065e-01, -1.9793e-01,  3.8153e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0559e-01,  3.1273e-01,  1.5594e-01],\n",
       "                         [ 1.7393e-01, -6.1596e-02, -2.1482e-01],\n",
       "                         [ 1.0072e-01, -3.6248e-01, -2.6370e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0709e-01, -2.5422e-01,  5.1832e-02],\n",
       "                         [ 2.1006e-01, -1.3040e-01, -6.3120e-02],\n",
       "                         [ 6.7084e-02, -9.1186e-02,  8.9826e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.0937e-01,  3.9595e-01,  2.2122e-01],\n",
       "                         [-1.6386e-01,  2.8206e-02, -1.7149e-01],\n",
       "                         [-4.2785e-01, -1.2610e-01, -1.6499e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.4867e-01, -2.5180e-01, -3.5126e-01],\n",
       "                         [-1.1301e-01, -1.2536e-01, -8.0463e-02],\n",
       "                         [ 8.8822e-01,  3.9861e-01,  2.1695e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0753e-02,  4.4991e-02, -2.4421e-01],\n",
       "                         [ 9.5658e-03,  2.3654e-01, -2.5991e-01],\n",
       "                         [ 2.4366e-02,  3.8166e-01, -2.2451e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 8.7838e-01, -5.9983e-02,  1.4472e-01],\n",
       "                         [ 2.1890e-01, -8.2260e-02,  3.5236e-02],\n",
       "                         [-1.6305e-01, -5.5475e-01, -3.4149e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1640e-01,  7.8737e-02, -1.7762e-01],\n",
       "                         [-1.4516e-02,  1.3225e-01,  2.5413e-02],\n",
       "                         [-2.8115e-02,  1.8151e-01, -3.3639e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.3240e-01, -3.6960e-01, -1.5010e-01],\n",
       "                         [ 6.2620e-02,  2.2893e-02,  1.1247e-01],\n",
       "                         [ 2.6827e-01,  3.7458e-01, -8.5182e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.0860e-01,  1.1462e+00, -4.2346e-02],\n",
       "                         [-1.4127e-01,  3.0784e-01, -4.1399e-02],\n",
       "                         [-3.6094e-01, -1.9679e-01, -2.6113e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 4.3481e-01, -2.5167e-01,  3.8530e-01],\n",
       "                         [-1.3977e-01, -3.6216e-01,  1.1309e-03],\n",
       "                         [ 2.0413e-01, -4.5980e-01,  2.9574e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.7680e-02,  2.6627e-01, -2.8784e-01],\n",
       "                         [-3.3592e-01,  2.4736e-01, -1.2399e-01],\n",
       "                         [-2.8255e-01,  8.0267e-01, -4.0267e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.3659e-01, -5.6885e-01, -5.8263e-02],\n",
       "                         [ 2.3202e-01, -3.7275e-01,  4.3137e-02],\n",
       "                         [ 2.3751e-01, -1.1991e-01,  2.6967e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.7833e-01,  6.2141e-01,  4.1701e-01],\n",
       "                         [-9.2735e-02, -3.6468e-02, -3.5021e-01],\n",
       "                         [-5.1336e-02,  1.1924e-01, -1.3558e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.9185e-01,  2.7757e-01,  1.5429e-01],\n",
       "                         [ 2.0638e-01, -9.3221e-02, -4.2492e-02],\n",
       "                         [-3.6869e-01, -2.5070e-01, -3.6196e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.1912e-01, -3.4506e-01, -2.0505e-01],\n",
       "                         [-3.5524e-02,  5.3625e-02,  3.3577e-01],\n",
       "                         [ 1.5814e-01, -1.6911e-02,  5.5144e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-7.1422e-01, -9.4341e-02,  4.3752e-02],\n",
       "                         [ 1.3863e+00, -7.7188e-02,  1.9691e-02],\n",
       "                         [-3.5302e-01, -1.1650e-01, -4.4031e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.5821e-01,  1.7370e-01,  3.0065e-01],\n",
       "                         [-4.7475e-01, -6.5231e-01, -4.0496e-01],\n",
       "                         [ 1.6438e-01,  4.0722e-01,  1.4705e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.6765e-01, -3.5122e-01, -3.0718e-01],\n",
       "                         [-3.7997e-02, -1.8845e-01,  5.6407e-02],\n",
       "                         [ 2.3948e-01,  2.0316e-01,  6.8780e-01]]]], device='cuda:0')),\n",
       "              ('conv_block1.conv2.weight',\n",
       "               tensor([[[[ 3.7716e-02,  3.8377e-01, -2.6829e-02],\n",
       "                         [ 1.4405e-02, -2.7071e-02, -1.1790e-01],\n",
       "                         [ 3.1483e-02, -1.2675e-01,  1.0402e-01]],\n",
       "               \n",
       "                        [[-1.3191e-01,  5.1577e-02,  9.3906e-02],\n",
       "                         [-1.0973e-01,  1.2606e-01,  6.9330e-02],\n",
       "                         [-7.9789e-02,  1.4824e-01, -2.2891e-01]],\n",
       "               \n",
       "                        [[ 8.4112e-02, -6.5050e-02,  2.2053e-02],\n",
       "                         [-1.6003e-02,  3.6255e-02, -1.0961e-01],\n",
       "                         [ 2.1383e-03,  1.7355e-01, -2.0730e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.2900e-01, -9.4333e-02, -4.8292e-01],\n",
       "                         [ 1.5381e-01, -8.5188e-03,  2.9697e-02],\n",
       "                         [ 1.7547e-01,  5.9568e-02,  4.1180e-01]],\n",
       "               \n",
       "                        [[-6.4412e-02,  2.3372e-02, -8.3541e-02],\n",
       "                         [-5.3537e-02, -8.9693e-02, -1.3112e-02],\n",
       "                         [-5.3418e-02, -4.0995e-02,  1.0250e-01]],\n",
       "               \n",
       "                        [[-2.1671e-01,  2.8036e-02, -1.3197e-04],\n",
       "                         [-3.4290e-02,  5.9299e-02, -1.8906e-02],\n",
       "                         [-5.3243e-02, -4.2178e-02,  2.6321e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0785e+00, -2.0748e-01,  7.5568e-02],\n",
       "                         [ 2.0621e-01, -5.9543e-02,  6.3722e-02],\n",
       "                         [-6.5188e-01, -1.2228e-02,  1.1816e-01]],\n",
       "               \n",
       "                        [[-1.2173e-01,  1.9149e-01,  8.3929e-02],\n",
       "                         [ 8.3358e-02, -2.0013e-01, -1.1041e-02],\n",
       "                         [ 2.7151e-01, -3.6403e-01, -4.3889e-02]],\n",
       "               \n",
       "                        [[-1.7432e-01,  1.5744e-01, -2.0128e-01],\n",
       "                         [ 2.6894e-02, -1.1746e-01, -5.5749e-03],\n",
       "                         [ 2.9326e-01, -4.2377e-01,  5.7002e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.5385e-01, -8.2642e-01,  3.3079e-01],\n",
       "                         [-4.6052e-02, -1.7915e-01,  1.1808e-01],\n",
       "                         [-5.4963e-01,  1.0333e+00, -2.4473e-01]],\n",
       "               \n",
       "                        [[-6.9922e-02,  1.3253e-01,  8.7043e-02],\n",
       "                         [ 1.5732e-01,  1.6859e-01, -2.4649e-02],\n",
       "                         [ 4.5574e-02, -1.4071e-01, -1.5539e-01]],\n",
       "               \n",
       "                        [[ 1.2706e-01,  3.1828e-02,  1.1200e-01],\n",
       "                         [ 9.8312e-02,  3.1909e-02,  8.6010e-02],\n",
       "                         [ 1.4542e-02, -3.4562e-04,  8.4735e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 7.7297e-02, -1.1035e-01, -1.1087e-01],\n",
       "                         [-7.3131e-02, -9.5376e-02, -9.5487e-02],\n",
       "                         [-8.0729e-02, -9.2381e-04,  2.4190e-02]],\n",
       "               \n",
       "                        [[-1.7203e-01, -4.6300e-01,  2.5281e-01],\n",
       "                         [-1.5188e-01, -4.7515e-01, -3.0280e-02],\n",
       "                         [ 6.9937e-02, -1.2466e-01,  4.5305e-01]],\n",
       "               \n",
       "                        [[ 8.2297e-02,  1.0682e-01,  2.8612e-02],\n",
       "                         [ 1.3627e-01,  4.2858e-02, -3.2870e-02],\n",
       "                         [-3.5023e-02, -7.2602e-02, -2.1970e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 6.8166e-02,  1.6987e-01,  2.3324e-01],\n",
       "                         [ 2.0293e-01, -1.0903e-02, -1.6093e-01],\n",
       "                         [ 1.5683e-01, -1.1523e-01, -3.9176e-01]],\n",
       "               \n",
       "                        [[ 2.7918e-02, -5.2651e-02, -3.0204e-02],\n",
       "                         [-6.0518e-02, -1.3612e-01, -2.5142e-01],\n",
       "                         [ 8.2353e-02, -6.1556e-02,  5.9971e-02]],\n",
       "               \n",
       "                        [[-7.5691e-02, -5.9457e-03, -4.2270e-02],\n",
       "                         [-4.8160e-02, -3.5608e-02, -2.8247e-02],\n",
       "                         [-1.7834e-02, -7.6805e-02,  2.5366e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-4.9454e-02, -5.7105e-03, -8.8107e-02],\n",
       "                         [-3.6103e-02,  2.0379e-01,  3.4189e-01],\n",
       "                         [-4.2215e-02, -2.1860e-01, -2.4045e-01]],\n",
       "               \n",
       "                        [[-3.0638e-01, -1.8374e-01, -3.8692e-01],\n",
       "                         [ 4.3731e-01,  6.7990e-01,  3.9994e-01],\n",
       "                         [-3.8064e-01, -3.3509e-01, -6.1751e-01]],\n",
       "               \n",
       "                        [[-1.5306e-02, -1.0777e-02, -4.1142e-02],\n",
       "                         [-8.7511e-02, -1.0601e-01, -1.5231e-01],\n",
       "                         [-1.8568e-02,  3.6170e-02, -7.9173e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.1569e-01,  2.8898e-01,  3.5592e-01],\n",
       "                         [-1.0991e+00, -7.5708e-01, -8.5644e-01],\n",
       "                         [ 6.9730e-01,  1.2808e-01,  4.9305e-01]],\n",
       "               \n",
       "                        [[-6.9309e-02, -2.3946e-02, -6.7120e-02],\n",
       "                         [ 7.7438e-02,  7.9852e-02, -2.2187e-02],\n",
       "                         [-5.7858e-02, -7.3175e-03, -4.6205e-02]],\n",
       "               \n",
       "                        [[ 2.4485e-01,  3.5203e-01,  1.8942e-01],\n",
       "                         [-2.1788e-01, -1.4184e-01, -1.8707e-01],\n",
       "                         [-1.7722e-01, -9.8066e-02, -2.2995e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 2.2625e-02,  1.0379e-02, -8.0609e-02],\n",
       "                         [ 5.3149e-02, -9.3726e-02, -1.0543e-01],\n",
       "                         [ 4.8197e-02, -5.4563e-02, -4.1949e-02]],\n",
       "               \n",
       "                        [[ 1.4315e-02,  7.2706e-02, -6.4910e-02],\n",
       "                         [-3.9319e-02, -1.9981e-01, -9.3217e-02],\n",
       "                         [ 5.4948e-02,  7.2174e-02,  5.5379e-02]],\n",
       "               \n",
       "                        [[-2.6129e-02, -1.1373e-02, -1.9768e-02],\n",
       "                         [ 2.1967e-02,  6.3522e-02,  1.2756e-02],\n",
       "                         [ 9.7849e-02,  8.7106e-02,  4.9843e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.5595e-02, -1.5106e-01,  2.8897e-01],\n",
       "                         [ 9.5800e-02, -1.1059e-01,  1.5325e-01],\n",
       "                         [ 2.9394e-02, -2.9501e-02,  1.2501e-01]],\n",
       "               \n",
       "                        [[ 1.2613e-01,  6.3016e-02,  2.7176e-02],\n",
       "                         [-5.3751e-02, -8.8469e-02, -2.4307e-02],\n",
       "                         [ 7.0750e-02,  2.2604e-02,  1.4919e-02]],\n",
       "               \n",
       "                        [[ 2.6332e-02, -2.9871e-02,  7.3902e-02],\n",
       "                         [ 5.8938e-02,  8.6006e-02,  3.4223e-02],\n",
       "                         [-2.8744e-02,  8.2594e-03,  1.7609e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.7435e-01,  4.7874e-02,  7.0055e-02],\n",
       "                         [ 8.6948e-02,  3.3030e-01,  1.3110e-01],\n",
       "                         [ 1.5556e-01,  3.2963e-01,  1.5869e-01]],\n",
       "               \n",
       "                        [[-6.3539e-01, -6.0424e-01, -2.4252e-01],\n",
       "                         [-1.3502e-01, -1.3486e-01, -3.6140e-01],\n",
       "                         [-5.2280e-01, -4.7667e-01, -5.4187e-01]],\n",
       "               \n",
       "                        [[ 1.0034e-01, -3.9097e-01, -6.2816e-01],\n",
       "                         [-5.8587e-02, -3.5102e-01, -4.4382e-01],\n",
       "                         [-1.9356e-02, -2.9316e-01, -2.4458e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.3339e-01, -3.5807e-01, -7.3283e-03],\n",
       "                         [ 9.7241e-03, -1.2542e-01,  4.9291e-02],\n",
       "                         [ 2.5228e-01, -1.4051e-01, -8.6471e-02]],\n",
       "               \n",
       "                        [[-6.5190e-02, -1.7026e-01, -9.0556e-02],\n",
       "                         [ 1.3915e-01, -3.3030e-02, -7.1347e-02],\n",
       "                         [-2.2762e-05, -1.7184e-01, -1.6950e-02]],\n",
       "               \n",
       "                        [[ 7.2244e-02,  7.6516e-02, -2.7654e-03],\n",
       "                         [ 1.0507e-01, -4.3255e-04,  5.2007e-02],\n",
       "                         [ 2.0332e-02,  1.0466e-01,  5.0690e-02]]]], device='cuda:0')),\n",
       "              ('conv_block1.bn1.weight',\n",
       "               tensor([1.0147, 1.8317, 0.8301, 1.2968, 0.5953, 0.7233, 0.7475, 1.2259, 0.7721,\n",
       "                       1.0568, 1.3650, 0.3360, 0.4459, 0.6781, 0.6541, 0.3440, 0.5908, 1.0499,\n",
       "                       0.6292, 0.5092, 0.6707, 2.1327, 1.5605, 0.8525, 0.6335, 0.9048, 0.8897,\n",
       "                       0.6496, 1.0510, 1.3799, 0.9359, 0.6482, 0.5818, 1.7507, 2.3637, 0.6982,\n",
       "                       0.9968, 0.4719, 0.5994, 0.5357, 0.7040, 2.0022, 0.6293, 0.2890, 0.5688,\n",
       "                       0.9239, 0.6793, 0.5159, 0.4398, 0.5231, 0.6452, 0.8483, 0.5375, 1.9732,\n",
       "                       0.8341, 0.7305, 1.1377, 1.0964, 0.8403, 0.4709, 0.7815, 1.3541, 0.9502,\n",
       "                       1.0875], device='cuda:0')),\n",
       "              ('conv_block1.bn1.bias',\n",
       "               tensor([ 0.6754,  0.1345,  0.0220,  1.3368, -0.6749,  0.0839, -1.3812, -1.3433,\n",
       "                       -0.7652,  0.2082, -1.0769,  0.1627,  0.0673,  0.0511,  0.1200,  0.1681,\n",
       "                        0.0150,  0.0098, -0.7188, -0.5221, -0.8065,  0.4152,  0.2131, -1.1045,\n",
       "                        0.0147, -1.0571,  0.0904, -0.7248, -0.9289, -0.0724,  0.0621, -0.8089,\n",
       "                        0.0928,  0.1172,  0.0503,  0.1471,  0.6545,  0.1610, -0.4684,  0.0174,\n",
       "                       -0.8001,  0.3992, -0.6326,  0.1002, -0.7923,  0.0503, -0.4399, -0.1764,\n",
       "                       -1.0168,  0.0272, -0.1202,  0.1499, -0.9979,  0.2602, -0.7370,  0.1048,\n",
       "                        0.8390, -0.2476,  0.0871,  0.0680,  0.1174,  1.5486, -1.0039, -1.6553],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn1.running_mean',\n",
       "               tensor([-0.0030, -0.0002, -0.0097,  0.0008, -0.0108,  0.0094, -0.0018, -0.0032,\n",
       "                       -0.0002, -0.0022,  0.0009, -0.0213,  0.0035, -0.0077,  0.0031, -0.0275,\n",
       "                       -0.0161, -0.0078, -0.0127, -0.0061,  0.0220,  0.0024,  0.0018,  0.0035,\n",
       "                       -0.0123, -0.0039,  0.0027,  0.0010,  0.0109,  0.0010,  0.0048, -0.0150,\n",
       "                        0.0156,  0.0009,  0.0008,  0.0050,  0.0055, -0.0204, -0.0695, -0.0294,\n",
       "                        0.0018, -0.0023, -0.0279, -0.0122, -0.0161, -0.0047, -0.0007,  0.0002,\n",
       "                       -0.0074,  0.0328,  0.0009,  0.0095, -0.0117, -0.0013,  0.0422,  0.0078,\n",
       "                       -0.0017,  0.0020, -0.0008,  0.0251,  0.0097,  0.0051,  0.0014,  0.0013],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn1.running_var',\n",
       "               tensor([0.1543, 0.0237, 0.0862, 0.0526, 0.0313, 0.1704, 0.0081, 0.1066, 0.0159,\n",
       "                       0.1204, 0.0105, 0.0897, 0.2165, 0.1375, 0.2466, 0.1312, 0.1832, 0.0805,\n",
       "                       0.0449, 0.0544, 0.0787, 0.0197, 0.1028, 0.0528, 0.1611, 0.0675, 0.0803,\n",
       "                       0.0510, 0.0249, 0.0835, 0.2510, 0.1207, 0.1927, 0.0362, 0.0125, 0.0803,\n",
       "                       0.1997, 0.1383, 0.6347, 0.1720, 0.0371, 0.0157, 0.1682, 0.0286, 0.0476,\n",
       "                       0.3584, 0.0377, 0.0152, 0.0391, 0.1976, 0.0495, 0.1186, 0.0258, 0.0243,\n",
       "                       0.3662, 0.0665, 0.0868, 0.0709, 0.0456, 0.1456, 0.0848, 0.0315, 0.0196,\n",
       "                       0.0608], device='cuda:0')),\n",
       "              ('conv_block1.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block1.bn2.weight',\n",
       "               tensor([1.4841, 1.2917, 1.0752, 0.9392, 1.3012, 0.5648, 0.7395, 1.2967, 0.3735,\n",
       "                       1.2988, 1.5531, 1.1796, 1.5098, 0.8108, 0.5671, 1.0800, 1.0263, 1.2715,\n",
       "                       1.3641, 1.3163, 1.5201, 0.6631, 1.1183, 1.1883, 1.2024, 0.8789, 1.3421,\n",
       "                       0.3771, 1.0490, 1.4551, 1.1245, 1.5359, 0.6782, 1.5352, 0.9282, 1.1248,\n",
       "                       1.3073, 0.9236, 1.2908, 1.3024, 0.4935, 1.0720, 0.8583, 1.5085, 1.4076,\n",
       "                       1.4440, 0.6413, 0.6526, 1.0588, 0.5574, 0.6595, 1.0363, 0.7635, 1.3950,\n",
       "                       1.3622, 1.1709, 0.8593, 0.5827, 0.9331, 1.3578, 1.2215, 0.9420, 0.5712,\n",
       "                       0.5443], device='cuda:0')),\n",
       "              ('conv_block1.bn2.bias',\n",
       "               tensor([-0.8234, -0.8081, -0.4838, -0.5944, -0.8566, -0.2404, -0.5236, -0.9160,\n",
       "                       -0.0529, -0.3748, -0.7467, -0.8183, -1.0355, -0.2404, -0.3608, -0.5537,\n",
       "                       -0.6094, -0.5815, -0.5941, -0.8944, -0.6258, -0.1631, -0.5619, -0.8486,\n",
       "                       -0.4367, -0.3251, -0.8718, -0.0486, -0.5740, -0.9323, -0.6806, -0.7423,\n",
       "                       -0.9645, -1.0283, -0.6479, -0.5786, -0.9397, -0.1561, -0.6581, -0.7995,\n",
       "                       -0.1054, -0.5006, -0.2690, -0.9833, -0.6177, -1.0039, -0.5419, -0.7335,\n",
       "                       -0.4527, -0.3228, -0.2103, -0.3911, -0.2588, -0.8303, -0.6102, -0.4021,\n",
       "                       -0.2842, -0.4564, -0.4216, -0.6266, -0.8774, -0.5110, -0.9052, -0.2076],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block1.bn2.running_mean',\n",
       "               tensor([ -7.9719,  -3.7649,  -7.8810,  -7.6889, -10.5837,  -4.0918,  -5.6065,\n",
       "                        -6.6311,   2.5603,  -7.6045,  -5.1107,  -4.1815,  -5.9455,  -3.2822,\n",
       "                        -0.6395,  -6.0870,  -6.7635,  -9.0023, -10.2618,  -7.7644,  -7.4981,\n",
       "                       -10.6928,  -5.4010,  -5.7467,  -4.5544, -14.6207,  -9.4568,   0.4363,\n",
       "                        -6.0029,  -4.7520, -10.0777, -19.3728,   7.3312,  -3.9146,  -4.1213,\n",
       "                        -4.5376, -10.3372, -11.7089,  -8.8880,  -4.1784,  -8.7844, -13.1679,\n",
       "                        -5.4957,  -5.8013,  -6.2711,  -5.9831,  -0.4317,   2.0526, -11.5915,\n",
       "                         0.2059, -10.6473,  -4.9260,  -1.5417,  -6.0039,  -5.3137,  -8.6857,\n",
       "                        -5.8778,   0.5054,  -4.8357, -11.6665,  -6.8932,  -5.2246,   3.5649,\n",
       "                       -13.4528], device='cuda:0')),\n",
       "              ('conv_block1.bn2.running_var',\n",
       "               tensor([104.4665,  52.4385,  91.5131,  81.1477, 122.0083, 126.2023,  42.4414,\n",
       "                        56.1025,  49.7538, 172.0671,  49.8468,  42.4662,  61.2207,  86.6769,\n",
       "                        18.0178,  74.0177, 108.8776, 173.0154, 178.2723,  87.5935,  94.7047,\n",
       "                       169.9219, 103.4164,  34.5758,  53.0822, 284.2262, 160.3335,  48.1477,\n",
       "                        71.1743,  55.5738, 114.1072, 412.1122,  25.4355,  31.5929,  33.4811,\n",
       "                        55.7246, 103.4648, 273.7428, 177.9740,  32.0147,  52.4685, 176.6447,\n",
       "                        43.8073,  53.1339,  80.3319,  43.6741,  16.8771,  37.1667, 248.7390,\n",
       "                        23.0678, 106.6639,  45.7877,  36.2760,  64.4575, 116.5747, 174.5919,\n",
       "                       161.6967,  24.6345,  87.6809, 261.5728,  88.1909,  33.4879,  24.3092,\n",
       "                       194.4015], device='cuda:0')),\n",
       "              ('conv_block1.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block2.conv1.weight',\n",
       "               tensor([[[[-6.6612e-02, -5.9600e-02, -3.3646e-02],\n",
       "                         [-9.0082e-03, -3.4218e-02, -1.2638e-01],\n",
       "                         [-1.5268e-01, -5.2480e-02, -6.7372e-02]],\n",
       "               \n",
       "                        [[ 1.1773e-01,  1.3273e-01,  1.4331e-01],\n",
       "                         [ 1.5485e-02, -5.2641e-02,  6.5574e-02],\n",
       "                         [ 3.9865e-02,  6.6218e-02,  1.6867e-01]],\n",
       "               \n",
       "                        [[ 9.3612e-03, -3.2874e-03, -5.0931e-03],\n",
       "                         [ 1.0213e-02,  2.7881e-02,  5.9696e-02],\n",
       "                         [ 2.5336e-03,  5.3899e-02,  1.0334e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-5.3382e-02,  6.7181e-02,  6.3629e-02],\n",
       "                         [-8.2463e-03,  3.0971e-02,  3.6543e-02],\n",
       "                         [-3.2838e-02, -5.4525e-02, -1.0010e-01]],\n",
       "               \n",
       "                        [[ 5.8703e-03, -5.4488e-03, -7.4210e-03],\n",
       "                         [-8.8855e-03,  9.4491e-03, -2.4393e-02],\n",
       "                         [ 4.0046e-02,  2.7267e-02, -2.4605e-02]],\n",
       "               \n",
       "                        [[ 3.4274e-03, -1.7679e-02, -1.0506e-02],\n",
       "                         [-6.6787e-02, -2.9965e-02, -3.4468e-02],\n",
       "                         [-4.4432e-02, -1.3806e-02, -4.1295e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 5.9368e-02, -4.6169e-02, -3.1849e-02],\n",
       "                         [ 1.1523e-01,  1.7957e-01,  4.6607e-02],\n",
       "                         [ 5.8586e-03,  1.2307e-01,  1.4036e-02]],\n",
       "               \n",
       "                        [[-1.8446e-01, -2.0808e-01, -7.5956e-02],\n",
       "                         [-2.9685e-01, -2.9554e-01,  5.7040e-02],\n",
       "                         [-2.7504e-01,  6.5192e-02,  2.9643e-02]],\n",
       "               \n",
       "                        [[ 3.1143e-02,  5.7940e-02,  5.3295e-02],\n",
       "                         [-1.4687e-01, -2.6303e-01,  4.0375e-02],\n",
       "                         [ 8.0275e-02, -1.9773e-01,  7.4133e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.7884e-02, -6.6429e-02, -6.8187e-03],\n",
       "                         [-8.8455e-02, -2.1068e-01, -1.0393e-01],\n",
       "                         [ 4.0991e-02, -1.4381e-01, -1.1891e-01]],\n",
       "               \n",
       "                        [[ 3.8864e-02, -7.3408e-02, -1.0042e-01],\n",
       "                         [ 6.2543e-02, -1.5229e-02,  3.8400e-02],\n",
       "                         [-4.9299e-02, -1.4120e-01, -1.5871e-01]],\n",
       "               \n",
       "                        [[ 1.2304e-01,  1.6561e-01,  1.1603e-01],\n",
       "                         [-3.1976e-03,  1.5427e-01,  1.0683e-01],\n",
       "                         [ 1.0294e-01,  1.0579e-01,  1.8109e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.3461e-01,  3.3709e-01, -1.2679e-01],\n",
       "                         [-1.1710e-01, -1.9431e-01, -2.6899e-01],\n",
       "                         [ 1.2496e-01, -2.3303e-01, -3.0178e-01]],\n",
       "               \n",
       "                        [[-7.5645e-01, -1.8989e-02, -1.4834e-01],\n",
       "                         [-1.5400e+00, -1.4846e+00, -2.8898e-01],\n",
       "                         [-1.9606e+00, -1.8870e+00, -6.1143e-01]],\n",
       "               \n",
       "                        [[ 7.4252e-02, -3.6760e-02,  2.5229e-01],\n",
       "                         [-5.4651e-03, -4.8606e-01,  6.3125e-02],\n",
       "                         [ 1.1650e-01, -6.2473e-01,  9.7307e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.3681e-02,  1.0975e-01, -1.4098e-01],\n",
       "                         [-1.3643e-02, -1.8806e-02, -1.1949e-01],\n",
       "                         [-1.5424e-01,  2.1139e-02, -1.2501e-01]],\n",
       "               \n",
       "                        [[-2.0506e-01, -3.0328e-01, -7.0644e-03],\n",
       "                         [ 6.5120e-02, -1.5298e-02,  8.4776e-02],\n",
       "                         [ 9.8368e-02,  2.2104e-01,  4.7331e-02]],\n",
       "               \n",
       "                        [[ 1.0543e-02, -3.8799e-02,  1.2879e-01],\n",
       "                         [-1.4161e-03, -1.6089e-01, -1.1688e-01],\n",
       "                         [ 1.8923e-01,  2.9672e-02, -8.9577e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 2.5869e-01,  2.4997e-01,  1.0919e-01],\n",
       "                         [ 8.0202e-02, -7.0330e-02, -1.1587e-01],\n",
       "                         [-1.7754e-01, -9.0353e-02, -1.1497e-02]],\n",
       "               \n",
       "                        [[ 3.2115e-01,  2.9448e-01, -5.0417e-02],\n",
       "                         [ 1.6544e-01,  5.9469e-02,  1.6220e-02],\n",
       "                         [-3.3938e-02, -2.0441e-02,  2.2820e-01]],\n",
       "               \n",
       "                        [[-2.6324e-01, -2.1927e-01,  1.9276e-02],\n",
       "                         [-1.1829e-01, -9.9668e-02, -3.7246e-02],\n",
       "                         [-1.5414e-01, -3.0073e-01, -3.8076e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.8569e-01, -8.8609e-02, -2.7967e-01],\n",
       "                         [-1.7912e-01, -1.2283e-01, -1.4729e-01],\n",
       "                         [-1.1130e-01, -1.5198e-01, -4.9355e-02]],\n",
       "               \n",
       "                        [[-1.5297e-01, -6.4467e-02, -1.4488e-02],\n",
       "                         [ 8.3452e-02,  1.1420e-01,  1.4201e-01],\n",
       "                         [ 6.5947e-02,  7.5174e-02,  1.4104e-02]],\n",
       "               \n",
       "                        [[-3.9835e-01, -4.4832e-01,  4.2174e-02],\n",
       "                         [-4.3757e-02,  3.5249e-03,  1.9157e-01],\n",
       "                         [ 5.1002e-01,  2.7074e-01,  2.1804e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-2.0083e-01, -2.0754e-01, -1.2930e-01],\n",
       "                         [-4.3015e-02,  7.0285e-02,  3.9884e-02],\n",
       "                         [ 4.1164e-03, -1.0237e-02, -2.3977e-01]],\n",
       "               \n",
       "                        [[-2.5900e-01, -4.4998e-01,  1.5604e-01],\n",
       "                         [-1.7697e-01, -4.5872e-01,  2.1617e-01],\n",
       "                         [ 3.7660e-02, -7.4408e-01,  6.8443e-02]],\n",
       "               \n",
       "                        [[-1.1396e-01, -5.3961e-02, -3.6279e-01],\n",
       "                         [ 1.1854e-01, -1.2681e-01, -2.1725e-01],\n",
       "                         [ 2.6696e-01, -3.6346e-01, -9.5176e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.7260e-04, -6.8171e-02,  8.3130e-02],\n",
       "                         [-6.1544e-02, -1.0541e-01,  1.3370e-01],\n",
       "                         [-1.3495e-02, -3.3459e-01, -3.7672e-01]],\n",
       "               \n",
       "                        [[ 4.4782e-02, -4.8111e-02, -3.0118e-01],\n",
       "                         [ 7.5534e-02,  1.4195e-02, -9.2084e-02],\n",
       "                         [ 5.9530e-02,  2.4830e-01, -1.9449e-02]],\n",
       "               \n",
       "                        [[-5.6514e-02, -4.7786e-01, -5.4551e-01],\n",
       "                         [ 6.7129e-02, -1.0447e-01, -3.5393e-01],\n",
       "                         [ 2.0524e-01,  1.4802e-01, -1.2159e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.1755e-01,  1.8948e-01, -8.5609e-02],\n",
       "                         [ 1.8041e-03,  9.2940e-02,  4.3612e-03],\n",
       "                         [-2.8400e-02,  8.6866e-02,  5.8296e-02]],\n",
       "               \n",
       "                        [[ 1.5267e-01,  9.4688e-02,  1.0845e-01],\n",
       "                         [ 1.2109e-02,  1.7323e-02,  7.2662e-02],\n",
       "                         [ 1.5045e-01,  6.3335e-02,  1.3530e-01]],\n",
       "               \n",
       "                        [[-1.1404e-02, -6.6846e-05,  3.2670e-02],\n",
       "                         [ 1.3148e-02, -9.1374e-03,  7.4029e-02],\n",
       "                         [ 7.1019e-02, -1.2960e-02,  2.3726e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.7098e-02,  6.7599e-02,  1.4238e-02],\n",
       "                         [ 4.8238e-02,  1.3659e-02, -1.2117e-01],\n",
       "                         [ 1.4043e-02, -4.1660e-02, -1.5624e-01]],\n",
       "               \n",
       "                        [[ 7.8119e-02,  5.5463e-02, -4.3440e-02],\n",
       "                         [ 4.9839e-02,  1.5844e-02,  6.5254e-03],\n",
       "                         [-1.8330e-03,  3.8192e-02, -6.3780e-02]],\n",
       "               \n",
       "                        [[ 1.2015e-03, -5.0034e-02, -4.7408e-03],\n",
       "                         [-9.7093e-02, -1.0198e-01, -1.2352e-01],\n",
       "                         [-4.9896e-02, -4.3457e-02, -1.8967e-02]]]], device='cuda:0')),\n",
       "              ('conv_block2.conv2.weight',\n",
       "               tensor([[[[-1.2165e-01, -3.4758e-02, -3.1801e-02],\n",
       "                         [-2.2202e-01, -4.2053e-02, -8.9334e-03],\n",
       "                         [-2.1968e-01,  1.4105e-02, -7.2417e-02]],\n",
       "               \n",
       "                        [[-1.8230e-02,  4.9553e-02,  2.1746e-03],\n",
       "                         [-5.1542e-03,  1.5157e-01, -5.8213e-02],\n",
       "                         [-6.2584e-02,  8.8796e-02, -9.7473e-02]],\n",
       "               \n",
       "                        [[-7.6419e-02,  2.6815e-01, -4.1798e-01],\n",
       "                         [ 1.1087e-01,  1.8604e-01, -4.2441e-01],\n",
       "                         [ 6.6051e-01,  6.7546e-02, -2.2249e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.7164e-01,  6.9644e-02, -1.1054e-01],\n",
       "                         [-1.9934e-01,  1.2364e-01, -1.8217e-01],\n",
       "                         [ 1.9870e-01, -2.1927e-01, -4.7338e-01]],\n",
       "               \n",
       "                        [[ 6.0575e-01,  1.9189e-01, -3.9298e-01],\n",
       "                         [ 3.8937e-01, -5.2282e-01, -3.3441e-01],\n",
       "                         [ 5.0963e-02, -8.0754e-01,  2.1472e-01]],\n",
       "               \n",
       "                        [[-5.4394e-02, -4.4702e-02, -4.1633e-02],\n",
       "                         [-7.9942e-02,  2.0425e-02, -1.1764e-01],\n",
       "                         [-6.7712e-02, -4.8692e-02, -8.1700e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-8.8303e-02, -1.1456e-01, -6.3068e-02],\n",
       "                         [-3.1676e-02, -7.5469e-02, -8.8714e-02],\n",
       "                         [ 1.6190e-02, -1.3691e-01, -1.2982e-02]],\n",
       "               \n",
       "                        [[ 1.3800e-02,  4.3082e-02,  1.2921e-01],\n",
       "                         [-6.6615e-02,  3.9583e-02,  5.1345e-02],\n",
       "                         [-9.0941e-02, -3.3695e-02, -1.6292e-01]],\n",
       "               \n",
       "                        [[-2.9417e-01, -2.7346e-01, -2.8625e-01],\n",
       "                         [-4.8340e-01, -3.0853e-01, -2.9241e-01],\n",
       "                         [-4.6969e-01, -4.4771e-01, -2.2531e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.3768e-01, -1.3367e-01,  6.3965e-02],\n",
       "                         [-1.8034e-01, -1.0056e-01,  4.9152e-02],\n",
       "                         [ 6.9681e-02,  4.4886e-02, -1.5970e-02]],\n",
       "               \n",
       "                        [[ 6.3910e-02,  5.0630e-02, -1.5643e-01],\n",
       "                         [-1.2564e-02,  8.7770e-02, -2.5424e-01],\n",
       "                         [-1.5242e-01,  3.2650e-02, -3.4847e-01]],\n",
       "               \n",
       "                        [[-1.0796e-02, -6.4269e-02, -5.0478e-03],\n",
       "                         [-9.9691e-02, -6.7211e-02, -5.9294e-02],\n",
       "                         [-5.5320e-02, -4.8565e-02, -8.5714e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.3092e-01,  9.5969e-02,  1.5641e-01],\n",
       "                         [ 1.9266e-01,  1.9806e-01,  3.0072e-01],\n",
       "                         [ 1.0866e-01,  6.0311e-02,  1.0739e-01]],\n",
       "               \n",
       "                        [[-4.7209e-02, -7.3073e-02, -1.1407e-01],\n",
       "                         [ 3.4073e-02, -6.4070e-02,  7.7815e-02],\n",
       "                         [ 2.4749e-02, -6.8775e-02,  7.9206e-02]],\n",
       "               \n",
       "                        [[-2.8662e-02, -6.8921e-03, -1.5398e-01],\n",
       "                         [ 1.1468e-01,  1.0031e-01, -2.7129e-02],\n",
       "                         [ 1.9977e-01,  1.8576e-01,  5.5038e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-1.7789e-01, -1.6586e-01, -5.8020e-02],\n",
       "                         [-1.0732e-01, -1.4870e-01, -1.8783e-01],\n",
       "                         [ 1.1411e-01,  1.8217e-03,  6.5047e-03]],\n",
       "               \n",
       "                        [[ 5.4595e-02,  7.4122e-02, -2.3456e-01],\n",
       "                         [-1.3140e-01, -1.0850e-02, -2.9233e-01],\n",
       "                         [-3.5969e-02,  2.3044e-01, -1.8797e-01]],\n",
       "               \n",
       "                        [[ 1.4259e-01,  7.6576e-02,  9.8668e-02],\n",
       "                         [ 2.4371e-01,  1.9889e-01,  1.1936e-01],\n",
       "                         [ 1.4846e-01,  1.9596e-01,  1.3475e-01]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-2.1735e-02, -1.3602e-03, -6.8345e-03],\n",
       "                         [-3.9126e-02, -2.0053e-02, -6.9146e-02],\n",
       "                         [-4.7897e-02, -3.2232e-02, -3.0127e-02]],\n",
       "               \n",
       "                        [[-1.1223e-01, -2.3186e-03,  1.0385e-01],\n",
       "                         [-1.8395e-02, -9.9355e-03,  2.3772e-02],\n",
       "                         [ 9.9456e-03,  3.8746e-02,  3.2703e-02]],\n",
       "               \n",
       "                        [[ 5.2624e-01,  3.0441e-01, -2.7560e-02],\n",
       "                         [ 3.8298e-01,  3.3152e-01,  3.2366e-01],\n",
       "                         [-1.7045e-01, -1.2247e-01, -6.2685e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.2901e-01,  1.6458e-01, -5.7356e-02],\n",
       "                         [ 1.9583e-01,  1.6779e-01,  2.3444e-02],\n",
       "                         [-1.3751e-01, -1.7650e-01, -3.1298e-01]],\n",
       "               \n",
       "                        [[ 1.4263e-01, -1.8176e-01, -1.3101e-01],\n",
       "                         [-3.3003e-01, -1.7546e-01, -1.4912e-01],\n",
       "                         [-4.1653e-01, -2.7350e-01, -2.3506e-01]],\n",
       "               \n",
       "                        [[-3.4305e-03, -1.1950e-02, -2.6996e-02],\n",
       "                         [-3.5794e-02, -1.4185e-02, -2.9764e-02],\n",
       "                         [ 2.7390e-02, -6.2543e-02, -3.8219e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.0635e-02, -2.6808e-03, -9.0777e-02],\n",
       "                         [-3.8485e-02,  3.2833e-02, -1.6659e-02],\n",
       "                         [-1.8095e-02,  8.3388e-03,  1.3049e-02]],\n",
       "               \n",
       "                        [[-4.0688e-02, -2.1189e-01, -1.4189e-01],\n",
       "                         [-4.1159e-02, -1.1777e-01, -3.9503e-02],\n",
       "                         [ 4.0488e-02,  6.5073e-02, -1.2451e-01]],\n",
       "               \n",
       "                        [[-1.9807e-01, -1.4593e-01, -3.1981e-01],\n",
       "                         [-2.6858e-01, -9.8892e-02, -2.4597e-01],\n",
       "                         [-3.9285e-01, -2.7522e-02, -2.4347e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2200e-01, -2.3795e-01, -4.5053e-01],\n",
       "                         [-4.3874e-01, -2.1310e-02, -6.6127e-02],\n",
       "                         [ 1.4589e-01,  1.8029e-01, -2.1881e-01]],\n",
       "               \n",
       "                        [[ 1.2308e-02,  3.8618e-01,  4.7723e-02],\n",
       "                         [ 1.1494e-02,  2.0954e-01,  1.6211e-02],\n",
       "                         [-1.2337e-01, -1.7129e-01, -2.3508e-01]],\n",
       "               \n",
       "                        [[-2.2188e-03, -2.6811e-02, -4.6226e-03],\n",
       "                         [-7.3100e-02, -4.6282e-02, -5.9734e-02],\n",
       "                         [ 1.5354e-02, -7.1094e-02, -4.0344e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9619e-02, -1.3767e-02, -6.4492e-02],\n",
       "                         [ 7.0084e-02,  2.1040e-02, -1.6778e-02],\n",
       "                         [ 2.5448e-02, -2.0526e-02, -1.5553e-02]],\n",
       "               \n",
       "                        [[ 6.7199e-02,  5.4012e-02, -5.1086e-02],\n",
       "                         [-1.6294e-02,  2.6211e-03, -5.9751e-02],\n",
       "                         [ 1.1546e-01,  7.7307e-02, -3.1984e-02]],\n",
       "               \n",
       "                        [[-1.3045e-01,  4.2094e-01,  3.6570e-01],\n",
       "                         [ 5.6246e-02,  7.0460e-01,  5.7300e-01],\n",
       "                         [-8.8699e-02,  4.3950e-01,  6.2013e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.6621e-01, -1.4640e-01,  1.2067e-01],\n",
       "                         [ 3.1655e-02,  3.4726e-01,  4.2844e-01],\n",
       "                         [-4.9609e-02,  3.7723e-01,  2.6148e-01]],\n",
       "               \n",
       "                        [[ 1.0608e-02,  5.0214e-01,  1.0745e-01],\n",
       "                         [-1.9865e-01,  2.3390e-01,  7.7547e-03],\n",
       "                         [-1.2779e-01,  2.3408e-01, -2.2846e-02]],\n",
       "               \n",
       "                        [[ 2.3396e-02, -2.1005e-02, -6.9662e-03],\n",
       "                         [-2.6809e-02, -3.2222e-02, -9.1260e-03],\n",
       "                         [-5.6296e-04, -2.4745e-03, -5.7847e-02]]]], device='cuda:0')),\n",
       "              ('conv_block2.bn1.weight',\n",
       "               tensor([0.7172, 1.1233, 1.1306, 1.0778, 1.2900, 1.3358, 1.0254, 0.9637, 1.0924,\n",
       "                       1.9560, 1.1531, 1.0244, 0.9168, 0.9906, 1.3675, 1.0856, 1.0364, 1.4014,\n",
       "                       0.6489, 1.1420, 1.0177, 1.0153, 0.4829, 1.3125, 1.0182, 1.2070, 0.8518,\n",
       "                       1.1346, 1.0194, 1.0389, 0.6530, 1.6765, 1.3377, 1.0420, 1.1963, 1.4562,\n",
       "                       1.2257, 0.8529, 1.2123, 1.0886, 1.2572, 0.9541, 1.2606, 1.1860, 0.7690,\n",
       "                       1.0909, 0.8198, 1.6815, 1.5043, 0.9400, 0.9319, 1.2516, 1.2181, 0.7739,\n",
       "                       1.5223, 1.2250, 0.5551, 0.8316, 1.1723, 0.6180, 1.2489, 1.3083, 1.2504,\n",
       "                       1.1648, 0.9319, 0.8519, 1.1785, 1.1199, 1.0065, 1.0437, 0.8517, 0.9715,\n",
       "                       1.1117, 0.8660, 1.2616, 0.6270, 1.4886, 0.8508, 1.6452, 0.9375, 0.9837,\n",
       "                       0.9614, 0.9463, 0.9444, 1.3023, 0.9668, 0.9989, 0.8529, 1.2239, 1.2258,\n",
       "                       0.8677, 1.0991, 1.2224, 1.3239, 1.0160, 0.8423, 0.7899, 1.0761, 0.9532,\n",
       "                       1.1130, 1.0155, 1.4508, 0.9422, 0.4902, 1.3575, 1.2227, 0.6806, 1.0196,\n",
       "                       1.1379, 1.3348, 0.8498, 1.1620, 1.0342, 1.0171, 0.7932, 1.2207, 1.0058,\n",
       "                       1.1235, 0.9424, 0.7260, 1.1394, 1.4980, 0.9080, 1.0551, 0.7560, 1.6658,\n",
       "                       1.0238, 0.7015], device='cuda:0')),\n",
       "              ('conv_block2.bn1.bias',\n",
       "               tensor([-1.3539, -0.9176, -0.3358, -0.6793, -0.2511, -0.5147,  0.1780,  0.0788,\n",
       "                       -0.9521, -3.2531, -0.3384, -0.2269, -0.1342, -0.4940, -0.5501, -0.7990,\n",
       "                       -0.2480, -0.7214, -1.2223, -0.8328,  0.1423, -0.7698, -0.0695, -0.9567,\n",
       "                       -0.6748, -0.8609, -1.0909, -0.6635, -0.5919, -0.3254, -0.5232, -1.0573,\n",
       "                       -0.5956,  0.2500, -1.2381, -0.9972, -1.1012, -0.7308, -0.9487, -0.4341,\n",
       "                       -0.7429, -0.7259, -0.9874, -0.2327, -1.4147, -0.8253, -0.5465, -2.2435,\n",
       "                       -0.7619, -0.4607, -1.0012, -0.7680,  0.0576, -0.1711, -0.9545, -0.4789,\n",
       "                       -0.2734, -0.1463, -0.9236, -0.4300, -1.3015, -0.8899, -1.5931, -0.5611,\n",
       "                       -0.2354,  0.1681, -0.6901, -0.1235, -0.6812, -0.5706, -0.0539, -0.2259,\n",
       "                       -0.7704, -0.1603, -0.9158, -1.2511, -1.1759, -0.4254, -1.5772,  0.0548,\n",
       "                       -0.3023, -0.2560, -0.9098,  0.1258, -0.8445,  0.2932, -0.5789, -1.4806,\n",
       "                       -0.7398, -0.6939, -0.2297, -0.3205, -1.0558, -0.5916, -0.7359, -0.6250,\n",
       "                        0.0800, -0.9542, -0.1950, -0.3094, -0.5269, -0.8853, -0.4104, -0.0767,\n",
       "                       -0.9139, -0.6508, -0.2267, -0.5620, -0.0352, -0.6384,  0.3548, -0.7505,\n",
       "                       -0.5176, -0.8099, -0.5966, -0.7521, -1.1145, -0.2763, -0.7157, -0.2710,\n",
       "                       -0.5462, -0.9088, -0.2783, -0.7310,  0.0219, -0.8976, -0.0224, -1.1168],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.running_mean',\n",
       "               tensor([-2.4131, -0.8904, -4.9010, -1.7769, -2.2053, -2.7407, -1.1921, -3.0030,\n",
       "                       -0.4156, -0.3795, -2.3029, -1.2883, -0.4116, -0.1081, -3.7642, -1.0190,\n",
       "                       -2.0777, -3.3611, -0.0486, -3.1341, -2.4077, -1.1157, -0.8847, -2.7711,\n",
       "                       -1.7424, -3.3486,  2.1937, -2.5235, -1.8268, -2.8369,  0.6379, -2.1238,\n",
       "                       -3.7224, -0.4414, -1.3879, -3.3340, -3.3817,  0.3282, -2.7800, -1.5432,\n",
       "                       -2.6469, -1.0276, -3.0478, -2.0544, -3.2316, -2.2868, -1.4719, -1.4437,\n",
       "                       -1.1511, -3.5797, -2.7565, -2.2685, -1.4782, -2.8771, -2.0487, -1.7757,\n",
       "                       -0.8824, -1.3743, -1.8331, -1.9949, -0.8457, -2.1034, -0.5533, -1.3504,\n",
       "                       -1.4081, -2.1844, -1.0006, -2.2973, -2.6539, -2.2386, -1.4796, -1.1708,\n",
       "                       -2.5862, -0.4609, -3.5191, -1.9588, -0.6882, -1.3655, -1.3016, -1.3824,\n",
       "                       -1.6750, -0.4051, -1.0312, -2.7010, -2.5754, -1.1560, -0.3630,  0.7148,\n",
       "                       -1.6863, -2.2299, -0.1336, -2.4699, -2.1001, -1.5359, -1.5326,  0.7923,\n",
       "                       -1.0251,  0.2001, -2.3583, -1.4120, -0.1170, -1.8230, -2.2582,  1.4584,\n",
       "                       -3.3188, -0.8856,  0.3503, -1.2154, -2.1023, -1.5781, -3.0069, -1.1046,\n",
       "                       -1.3731, -1.0934,  1.5682, -2.0638, -0.9050, -3.8840, -1.0200, -1.9753,\n",
       "                       -4.2705, -4.1954, -3.8186, -2.5487, -0.3516, -1.8321, -2.5454, -1.9434],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.running_var',\n",
       "               tensor([ 0.9786,  1.5125,  9.5856,  1.8743,  8.2790,  4.4735,  7.8640, 10.5432,\n",
       "                        1.2490,  2.9350,  6.8486,  6.3948,  3.2540,  1.1393,  9.0964,  1.5334,\n",
       "                        8.2834,  4.2068,  0.9122,  3.0292,  8.1301,  1.0579,  6.6738,  4.5364,\n",
       "                        2.0355,  4.1773,  1.8325,  4.3999,  4.2481,  6.3098,  2.5068,  9.3283,\n",
       "                        6.4492,  3.0384,  1.8923,  5.8473,  3.0599,  0.8678,  2.7243,  5.1903,\n",
       "                        4.7960,  4.2547,  2.5376,  2.5142,  2.3388,  3.6344,  1.5592,  2.2303,\n",
       "                        4.9886,  6.1556,  2.0378,  2.1848,  3.8695,  7.8191,  6.6059,  3.8878,\n",
       "                        3.6203,  4.7165,  1.8168,  2.2955,  1.4972,  2.4463,  2.0767,  7.1414,\n",
       "                        3.5790,  7.7162,  1.4699, 15.7467,  2.9050,  5.4722,  4.5844,  3.5854,\n",
       "                        3.4569,  4.2376,  4.6873,  0.7987,  1.1326,  3.8485,  1.5644,  3.9909,\n",
       "                        5.1989,  2.9923,  1.4127,  3.8168,  3.5553,  3.1785,  3.8540,  0.9011,\n",
       "                        1.4663,  3.4107,  2.3478,  3.1561,  2.1672,  5.4370,  3.1052,  1.8797,\n",
       "                        5.6606,  1.1486,  5.1894,  4.4640,  2.9727,  1.8161,  7.0791,  5.8385,\n",
       "                        4.8354,  2.8537,  2.3023,  5.0950,  3.7036,  3.9769, 11.8580,  1.1699,\n",
       "                        6.9196,  2.8060,  3.8003,  5.5325,  1.3808,  5.8572,  1.1803,  5.3702,\n",
       "                        8.7443,  8.8479,  5.3295,  4.1233,  6.9519,  8.7936,  5.9418,  1.0971],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block2.bn2.weight',\n",
       "               tensor([1.3141, 0.9743, 0.9400, 0.9704, 1.1382, 1.0515, 0.7056, 0.8917, 1.2728,\n",
       "                       0.8739, 0.8869, 1.0483, 0.6003, 0.7180, 0.9838, 0.9419, 1.2941, 1.2745,\n",
       "                       1.1587, 1.3949, 0.7573, 0.7964, 1.2028, 1.1286, 0.5101, 1.5309, 1.7043,\n",
       "                       1.0253, 1.2643, 1.5136, 0.9687, 1.1254, 0.9008, 1.0613, 1.2545, 1.9371,\n",
       "                       1.0074, 1.1867, 0.6400, 0.8690, 1.2913, 1.1891, 1.5210, 1.2264, 1.1337,\n",
       "                       1.5098, 0.7860, 1.1929, 0.9391, 1.0299, 0.8509, 1.0739, 1.1180, 1.0300,\n",
       "                       1.1998, 0.9821, 0.9817, 1.3478, 0.9603, 0.9633, 0.6857, 0.6026, 0.7475,\n",
       "                       0.7358, 0.7933, 0.9335, 0.9808, 1.0397, 0.8151, 0.7391, 0.6320, 1.2441,\n",
       "                       1.0984, 1.2876, 0.8579, 1.6905, 0.7509, 0.7957, 0.7060, 1.0145, 0.9281,\n",
       "                       0.8951, 1.7811, 1.0739, 1.3654, 1.0729, 0.7540, 0.7065, 1.2138, 1.0745,\n",
       "                       0.9565, 0.9216, 1.0931, 0.6989, 1.1158, 0.9414, 0.7919, 1.2018, 1.0087,\n",
       "                       1.4503, 0.6382, 0.8017, 0.9373, 1.1921, 1.0555, 1.2000, 1.3124, 1.1891,\n",
       "                       0.8393, 1.0704, 0.7054, 1.2592, 0.7358, 0.9641, 1.1372, 0.8094, 1.0117,\n",
       "                       1.2514, 1.1951, 1.0004, 0.8262, 0.7046, 0.8043, 1.1598, 0.6865, 1.4700,\n",
       "                       0.8981, 0.9085], device='cuda:0')),\n",
       "              ('conv_block2.bn2.bias',\n",
       "               tensor([-1.3503, -0.4413, -0.6789, -0.9455, -1.0849, -0.4448, -0.5752, -0.7186,\n",
       "                       -0.8108, -0.2051, -0.4654, -0.7822, -0.4704, -0.3479, -0.7247, -0.6463,\n",
       "                       -1.1507, -0.8867, -0.7556, -0.8274, -0.4405, -0.4568, -0.9801, -0.6102,\n",
       "                       -1.2241, -1.2244, -1.5618, -0.8782, -0.5003, -0.9520, -0.5820, -1.1252,\n",
       "                       -0.9082, -0.9316, -1.0885, -1.7258, -0.9305, -0.9675, -0.2319, -0.6314,\n",
       "                       -0.8341, -1.1461, -0.9772, -0.9146, -0.7383, -1.1380, -0.6114, -0.9168,\n",
       "                       -1.1098, -0.8108, -0.2102, -0.8518, -0.5361, -0.4911, -0.9719, -0.7816,\n",
       "                       -0.7263, -1.1259, -0.3177, -0.4689, -0.2683, -0.5677, -0.5023, -0.3059,\n",
       "                       -0.5004, -0.7979, -0.7226, -0.8363, -0.3814, -0.5096, -2.4209, -1.0990,\n",
       "                       -0.7452, -1.0950, -0.4069, -1.6483, -0.4548, -0.4833, -0.4344, -0.7627,\n",
       "                       -0.5733, -0.4171, -1.7487, -1.0344, -0.9407, -0.8883, -0.0773, -0.2880,\n",
       "                       -1.0581, -0.7470, -0.6575, -0.5272, -0.7539, -0.3000, -0.6706, -0.6163,\n",
       "                       -0.3594, -0.7435, -2.1373, -1.4771, -0.2047, -0.3021, -0.4441, -0.8505,\n",
       "                       -0.7633, -1.0400, -0.6749, -0.8543, -0.2337, -0.7890, -0.1617, -0.7715,\n",
       "                       -0.4618, -0.8388, -0.8737, -0.8112, -0.6466, -0.8895, -0.7215, -0.9477,\n",
       "                       -0.6900, -0.5412, -0.4516, -1.3314, -0.2638, -1.1401, -0.6788, -0.7952],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn2.running_mean',\n",
       "               tensor([ -7.3961,  -4.5891,  -5.8213,  -1.0133,  -2.2580,  -1.8642,  -3.5694,\n",
       "                        -6.0996,  -5.6499,  -2.5031,  -5.9163,  -2.2057,  -0.3819,  -1.8356,\n",
       "                        -4.1744,  -2.8422, -10.6328,  -5.2309,  -5.7686,  -2.5634,  -3.7643,\n",
       "                        -3.3726,  -4.8321,  -2.0769,   0.1582,  -3.8061,  -2.4051,  -3.5277,\n",
       "                        -3.9691,  -9.3103,  -8.0612,  -8.9360,  -1.8765,  -2.2820,  -5.7356,\n",
       "                        -4.4611,  -4.0259,  -2.2542,  -3.3550,  -6.5327,  -2.8121,  -2.8097,\n",
       "                        -6.0242,  -4.6169,  -6.0128,  -5.0973,  -3.0608,  -5.6782,   3.8616,\n",
       "                        -6.4063,  -3.3098,  -3.8689,  -7.3669,  -8.6131,  -3.6852,  -1.7822,\n",
       "                        -0.8158,  -2.0991,  -3.4854,  -6.3265,  -0.7037,  -1.9551,  -3.9395,\n",
       "                        -8.3529,  -6.3534,  -5.0519,  -9.2046,  -5.9804,  -3.8782,  -6.5263,\n",
       "                        -5.4163,  -5.5368,  -4.0463,  -3.8354,  -5.0896,  -6.0110,  -7.0405,\n",
       "                        -3.0010,  -6.2386,  -4.0346,  -0.3754,  -7.8277,  -6.0818,  -7.8651,\n",
       "                        -6.4240,  -4.4329,  -5.6176, -10.5690,  -4.8338,  -7.8223,  -8.5971,\n",
       "                        -4.2706,  -1.2760,  -3.1160,  -5.2439,  -6.0792,  -2.8554,  -4.7671,\n",
       "                       -10.1972,  -5.3260,  -1.2649,  -6.3484,  -3.9511,  -3.6146,  -3.9128,\n",
       "                        -2.9004,  -4.7150,  -3.9410,  -6.3880,  -4.4866,  -2.6650,  -6.4564,\n",
       "                        -1.9117,  -7.6207,  -2.6397,  -1.2198,  -6.7517,  -3.4818,  -6.2508,\n",
       "                        -5.4821,  -5.1062,   0.5175,  -5.7855,  -2.5263,  -1.4931,  -2.2290,\n",
       "                        -8.5932,  -7.5575], device='cuda:0')),\n",
       "              ('conv_block2.bn2.running_var',\n",
       "               tensor([39.4738, 50.2512, 22.0735, 19.9018, 19.8698, 20.9728,  7.8593, 25.9285,\n",
       "                       26.7521, 35.7524, 28.5406, 15.7397, 21.2985, 16.1114, 29.1470, 16.3477,\n",
       "                       46.2311, 21.5170, 24.7272, 21.8895, 30.1096, 32.5887, 24.2733, 34.2261,\n",
       "                        2.8262, 31.3546, 27.2281, 20.9851, 38.9086, 58.9054, 41.3042, 36.1662,\n",
       "                       18.2157, 18.5176, 14.1306, 34.1359, 18.4572, 34.3251, 31.8396, 19.9072,\n",
       "                       38.5039, 25.1795, 49.3835, 22.4839, 21.6583, 44.9227, 16.7198, 26.6548,\n",
       "                       14.7740, 30.8616, 37.0285, 14.4538, 35.8281, 49.5567, 20.6141, 18.0857,\n",
       "                       14.2632, 17.1822, 18.9241, 24.8222, 26.1890, 18.4515, 18.8614, 24.9102,\n",
       "                       25.8328, 20.0000, 19.6624, 20.5221, 10.0361, 25.1925,  6.1014, 29.3661,\n",
       "                       23.9723, 16.6776, 31.6900, 38.0337, 37.4205, 19.9710, 23.4294, 23.7631,\n",
       "                       14.4114, 42.7463, 21.7828, 29.3276, 22.0355, 30.7823, 27.8870, 50.3067,\n",
       "                       46.6016, 24.0858, 23.1349, 26.0429, 17.0057, 16.8542, 30.9906, 31.5861,\n",
       "                       24.1196, 21.7915, 22.6303, 24.3610, 26.3884, 19.4191, 31.9319, 17.5472,\n",
       "                       32.2729, 14.9530, 39.7351, 40.5044, 42.4207, 27.4097, 28.9811, 23.9798,\n",
       "                       19.2014, 29.4878, 21.0382, 19.4690, 35.1844, 46.0242, 28.0500, 18.4765,\n",
       "                       14.6201, 15.6444, 29.0666, 13.7840, 45.7339, 16.2414, 32.2088, 29.5621],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block2.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block3.conv1.weight',\n",
       "               tensor([[[[ 0.1918,  0.2914,  0.2449],\n",
       "                         [ 0.1409,  0.4522,  0.5067],\n",
       "                         [-0.0884,  0.0737,  0.0301]],\n",
       "               \n",
       "                        [[ 0.1019,  0.0240,  0.1687],\n",
       "                         [ 0.1553,  0.1560,  0.1272],\n",
       "                         [ 0.3152,  0.1944,  0.5959]],\n",
       "               \n",
       "                        [[-0.0959,  0.0195, -0.0181],\n",
       "                         [ 0.1306,  0.3360,  0.2106],\n",
       "                         [ 0.0172,  0.2755,  0.1774]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.0589, -0.0836, -0.0707],\n",
       "                         [-0.0466, -0.0364, -0.0165],\n",
       "                         [-0.1360, -0.1182, -0.2067]],\n",
       "               \n",
       "                        [[ 0.1215, -0.0398,  0.0103],\n",
       "                         [ 0.2076,  0.1056,  0.0358],\n",
       "                         [ 0.2488,  0.1140,  0.0059]],\n",
       "               \n",
       "                        [[-0.1999,  0.1547, -0.0563],\n",
       "                         [ 0.0262,  0.1187,  0.0150],\n",
       "                         [-0.0092,  0.0139, -0.0758]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.2419,  0.0038,  0.0491],\n",
       "                         [ 0.1142,  0.1323,  0.0855],\n",
       "                         [ 0.0182,  0.1687,  0.1369]],\n",
       "               \n",
       "                        [[ 0.0632, -0.0132, -0.2317],\n",
       "                         [-0.0641,  0.1044, -0.1256],\n",
       "                         [-0.2285, -0.0290, -0.1301]],\n",
       "               \n",
       "                        [[ 0.1610,  0.1163, -0.5981],\n",
       "                         [-0.1550,  0.0303, -0.5493],\n",
       "                         [-0.0474,  0.0092, -0.9042]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.0083,  0.0083,  0.0075],\n",
       "                         [ 0.0145,  0.0950,  0.0511],\n",
       "                         [ 0.0830,  0.1164,  0.0494]],\n",
       "               \n",
       "                        [[ 0.2263,  0.1090,  0.0101],\n",
       "                         [ 0.1972,  0.0947,  0.0223],\n",
       "                         [ 0.2290,  0.0657,  0.0559]],\n",
       "               \n",
       "                        [[ 0.0564,  0.0782, -0.1155],\n",
       "                         [-0.0289,  0.0121, -0.1669],\n",
       "                         [-0.1572, -0.0734, -0.2753]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1550,  0.0760, -0.0711],\n",
       "                         [ 0.0081,  0.0031,  0.2342],\n",
       "                         [-0.0559, -0.0469,  0.0951]],\n",
       "               \n",
       "                        [[-0.2200, -0.1018,  0.0902],\n",
       "                         [-0.0272, -0.0195, -0.0870],\n",
       "                         [-0.0746,  0.0177, -0.0156]],\n",
       "               \n",
       "                        [[ 0.1937,  0.1846, -0.1088],\n",
       "                         [-0.0464, -0.0803, -0.1807],\n",
       "                         [-0.2460, -0.4201, -0.2906]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.2961,  0.0428,  0.0576],\n",
       "                         [-0.0060, -0.0896, -0.0119],\n",
       "                         [-0.0070, -0.1107, -0.0374]],\n",
       "               \n",
       "                        [[ 0.0958, -0.1339, -0.5265],\n",
       "                         [ 0.2807, -0.0662, -0.3240],\n",
       "                         [ 0.1958, -0.0395,  0.0079]],\n",
       "               \n",
       "                        [[-0.1234, -0.1167,  0.0425],\n",
       "                         [-0.1760, -0.0356,  0.1057],\n",
       "                         [ 0.0918,  0.0630,  0.0935]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 0.1052,  0.0447, -0.0383],\n",
       "                         [ 0.3132, -0.0677,  0.2181],\n",
       "                         [ 0.3347,  0.1222,  0.1651]],\n",
       "               \n",
       "                        [[-0.1390, -0.1263, -0.2003],\n",
       "                         [ 0.0697,  0.2888,  0.1418],\n",
       "                         [-0.1250,  0.1076, -0.2513]],\n",
       "               \n",
       "                        [[ 0.1868,  0.4712, -0.2973],\n",
       "                         [ 0.4597,  0.3130,  0.0224],\n",
       "                         [ 0.6202,  0.3876,  0.2023]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1832, -0.2164, -0.1429],\n",
       "                         [-1.0208, -0.7868, -0.6915],\n",
       "                         [ 0.0429, -0.0640,  0.0734]],\n",
       "               \n",
       "                        [[ 0.3000, -0.1256, -0.1552],\n",
       "                         [ 0.3883,  0.0413, -0.0672],\n",
       "                         [-0.0734, -0.2630, -0.1852]],\n",
       "               \n",
       "                        [[-0.0130, -0.1501, -0.0803],\n",
       "                         [-0.0735, -0.1439, -0.1835],\n",
       "                         [-0.0352, -0.1001, -0.0571]]],\n",
       "               \n",
       "               \n",
       "                       [[[-0.1292, -0.0475, -0.2751],\n",
       "                         [-0.0806, -0.0832, -0.1058],\n",
       "                         [-0.2897, -0.2348, -0.2851]],\n",
       "               \n",
       "                        [[ 0.3081, -0.0171,  0.0433],\n",
       "                         [ 0.3938, -0.0264,  0.0846],\n",
       "                         [-0.0721, -0.1088,  0.0143]],\n",
       "               \n",
       "                        [[-0.2201, -0.1279,  0.0128],\n",
       "                         [-0.0203, -0.0936,  0.2572],\n",
       "                         [-0.0513,  0.0027,  0.2839]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-0.1582,  0.0710, -0.0582],\n",
       "                         [-0.1213,  0.0654,  0.0037],\n",
       "                         [-0.0399,  0.0586, -0.0409]],\n",
       "               \n",
       "                        [[ 0.1604, -0.0942, -0.0826],\n",
       "                         [ 0.0975,  0.0810,  0.0280],\n",
       "                         [ 0.1393,  0.1117,  0.0537]],\n",
       "               \n",
       "                        [[-0.0604, -0.2456, -0.2025],\n",
       "                         [ 0.0392, -0.1012, -0.0784],\n",
       "                         [-0.0073, -0.2827, -0.0562]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 0.0430,  0.2113,  0.5149],\n",
       "                         [-0.0677,  0.0607,  0.4389],\n",
       "                         [-0.2325, -0.0065,  0.1742]],\n",
       "               \n",
       "                        [[-0.3542, -0.1437,  0.3854],\n",
       "                         [-0.2052, -0.2274,  0.2500],\n",
       "                         [-0.4057, -0.3395, -0.0143]],\n",
       "               \n",
       "                        [[-0.1930, -0.0256, -0.0375],\n",
       "                         [ 0.0103, -0.0207, -0.0794],\n",
       "                         [ 0.3867,  0.2394,  0.1966]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 0.1049,  0.0724, -0.0165],\n",
       "                         [ 0.0512,  0.0242, -0.0029],\n",
       "                         [ 0.0762,  0.0376,  0.0533]],\n",
       "               \n",
       "                        [[-0.0143,  0.0353,  0.0516],\n",
       "                         [-0.0515,  0.0574,  0.0636],\n",
       "                         [ 0.1108,  0.1316,  0.1324]],\n",
       "               \n",
       "                        [[ 0.2118, -0.2252,  0.0978],\n",
       "                         [ 0.4146, -0.1564,  0.0487],\n",
       "                         [ 0.1328, -0.3897, -0.1263]]]], device='cuda:0')),\n",
       "              ('conv_block3.conv2.weight',\n",
       "               tensor([[[[ 1.3757e-01,  4.3896e-02,  7.7711e-02],\n",
       "                         [ 3.9155e-02, -1.6810e-02, -5.3194e-03],\n",
       "                         [-7.1487e-02, -8.9337e-02, -9.6639e-02]],\n",
       "               \n",
       "                        [[ 1.0051e-01,  5.4529e-02,  2.5286e-01],\n",
       "                         [ 2.2643e-01,  1.0918e-01,  2.1707e-01],\n",
       "                         [ 2.2286e-01,  1.7694e-01,  1.8261e-01]],\n",
       "               \n",
       "                        [[ 1.0463e-01,  4.7260e-02,  1.4341e-01],\n",
       "                         [ 6.8646e-03,  3.5136e-02, -1.8568e-01],\n",
       "                         [ 1.4691e-02,  2.7523e-02, -8.4363e-03]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.6073e-02, -1.0391e-01, -5.4284e-01],\n",
       "                         [-1.1898e-01, -1.1015e-01, -2.7668e-01],\n",
       "                         [-1.6836e-01, -1.7446e-01, -4.8569e-01]],\n",
       "               \n",
       "                        [[-2.9016e-01, -1.0900e-01, -5.3641e-02],\n",
       "                         [-2.6679e-01, -1.2469e-01, -1.4308e-01],\n",
       "                         [-1.3673e-01, -1.5387e-02,  1.9499e-02]],\n",
       "               \n",
       "                        [[-3.0667e-02, -2.2987e-01, -2.8192e-01],\n",
       "                         [-1.4152e-01, -1.1759e-01, -1.8855e-01],\n",
       "                         [-1.6718e-01, -2.3168e-01, -2.6251e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8786e-01,  1.6873e-01,  1.3946e-01],\n",
       "                         [-1.7823e-01,  5.2950e-02,  1.0508e-01],\n",
       "                         [ 3.9748e-02,  1.1322e-01,  9.1565e-02]],\n",
       "               \n",
       "                        [[ 1.6513e-01,  7.0866e-02,  2.9959e-02],\n",
       "                         [ 1.8623e-01,  8.5402e-02,  1.0393e-01],\n",
       "                         [ 1.6429e-01,  6.0174e-02,  9.9975e-02]],\n",
       "               \n",
       "                        [[-2.9346e-02,  2.7225e-01,  4.5111e-03],\n",
       "                         [-1.6765e-01,  8.2408e-02, -6.9969e-02],\n",
       "                         [-3.3864e-01, -3.1999e-01, -4.8076e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 8.7067e-02,  3.7755e-02,  1.4875e-01],\n",
       "                         [ 1.3623e-01,  5.7685e-02,  1.2049e-01],\n",
       "                         [-4.3463e-02,  8.5667e-02,  2.6807e-01]],\n",
       "               \n",
       "                        [[ 3.3094e-02, -3.1364e-02, -9.8045e-02],\n",
       "                         [ 5.5394e-02,  1.4516e-01,  4.4614e-02],\n",
       "                         [ 1.2437e-01,  6.7197e-02,  2.6299e-01]],\n",
       "               \n",
       "                        [[ 1.3716e-02,  2.9617e-02, -8.5375e-03],\n",
       "                         [-5.4299e-02, -9.0567e-03, -3.2639e-02],\n",
       "                         [-3.9753e-02, -3.7975e-02,  1.0959e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2729e-02,  1.2983e-02, -1.1082e-03],\n",
       "                         [-1.0104e-02, -2.4775e-03, -1.8996e-03],\n",
       "                         [-6.1798e-02, -5.7441e-02, -7.8250e-02]],\n",
       "               \n",
       "                        [[-1.8100e-02, -8.1336e-02,  8.5607e-03],\n",
       "                         [ 2.4292e-02,  3.0190e-03,  6.1094e-03],\n",
       "                         [ 5.0470e-02, -2.3951e-03,  3.9983e-02]],\n",
       "               \n",
       "                        [[-1.2726e-02, -9.6699e-02, -1.3851e-01],\n",
       "                         [-2.9790e-02, -8.6112e-02, -1.5020e-01],\n",
       "                         [-7.4393e-02, -9.5068e-02, -1.3827e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-8.0869e-02, -7.1531e-02, -3.1412e-03],\n",
       "                         [-2.2586e-02, -4.4022e-03, -1.1555e-02],\n",
       "                         [-3.3323e-02, -7.2141e-02, -3.3744e-02]],\n",
       "               \n",
       "                        [[ 3.9286e-02,  2.1935e-02, -1.1812e-02],\n",
       "                         [ 8.7210e-02,  4.9117e-02,  3.8273e-02],\n",
       "                         [ 7.9813e-03,  2.1938e-02, -2.2139e-02]],\n",
       "               \n",
       "                        [[-1.0034e-01, -6.9140e-02, -9.8685e-02],\n",
       "                         [ 7.6026e-03,  5.4144e-04, -2.7368e-02],\n",
       "                         [ 2.0734e-02,  2.5915e-02, -4.8275e-02]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-3.3179e-03, -1.0582e-01, -7.0599e-02],\n",
       "                         [ 3.1258e-02,  2.8049e-02,  2.0656e-03],\n",
       "                         [ 1.3279e-01,  4.2829e-02,  9.6902e-02]],\n",
       "               \n",
       "                        [[-2.8050e-01, -2.3010e-01, -2.8824e-01],\n",
       "                         [-3.2654e-02,  7.5081e-02, -1.0713e-01],\n",
       "                         [ 2.2023e-01,  1.2251e-01, -3.1004e-02]],\n",
       "               \n",
       "                        [[-2.2567e-02, -1.0412e-01, -2.9561e-01],\n",
       "                         [-6.5547e-02, -1.8374e-01, -2.1960e-01],\n",
       "                         [ 4.5878e-02, -5.6491e-02, -1.8567e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2591e-01, -2.1784e-02, -4.0365e-02],\n",
       "                         [-5.7017e-02,  8.3478e-02, -3.8980e-02],\n",
       "                         [ 7.2135e-02,  1.7239e-01,  1.7608e-01]],\n",
       "               \n",
       "                        [[-3.4503e-01, -3.1989e-01, -3.2226e-01],\n",
       "                         [-1.6589e-01, -1.6011e-01, -1.2297e-01],\n",
       "                         [-7.5813e-02, -5.2137e-02, -5.5259e-02]],\n",
       "               \n",
       "                        [[-1.4890e-01,  1.2244e-02,  3.4804e-03],\n",
       "                         [ 9.9097e-02,  1.0039e-01,  1.1039e-01],\n",
       "                         [ 2.7918e-01,  2.4813e-01,  2.0999e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 3.2763e-02,  3.3710e-02,  9.8060e-02],\n",
       "                         [ 4.1523e-02,  1.0447e-01,  1.1888e-01],\n",
       "                         [ 9.0085e-02,  1.0030e-01,  1.2675e-01]],\n",
       "               \n",
       "                        [[-2.0796e-02,  1.4305e-01, -8.5851e-02],\n",
       "                         [ 9.9763e-02,  1.7328e-01,  1.0501e-01],\n",
       "                         [ 9.9091e-02,  1.1628e-01,  5.7350e-02]],\n",
       "               \n",
       "                        [[-1.8043e-01, -6.2085e-02, -4.5798e-02],\n",
       "                         [-8.4020e-02,  1.2727e-01,  9.6284e-02],\n",
       "                         [ 1.7993e-01,  1.3537e-01,  1.8061e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 9.6259e-02, -5.4515e-02,  1.0738e-01],\n",
       "                         [-1.6335e-01, -1.6188e-01, -4.7400e-02],\n",
       "                         [-4.4075e-01, -2.0570e-01, -2.3790e-01]],\n",
       "               \n",
       "                        [[ 6.3876e-02,  5.0798e-02,  3.0333e-02],\n",
       "                         [ 1.7889e-02,  1.8676e-02,  2.0114e-02],\n",
       "                         [ 3.7309e-03,  6.1642e-02,  1.0740e-01]],\n",
       "               \n",
       "                        [[ 7.5402e-02,  6.8505e-02,  1.2329e-02],\n",
       "                         [ 9.4484e-02,  1.3652e-01,  7.6856e-02],\n",
       "                         [ 2.4983e-01,  2.6860e-01,  1.3195e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-4.5039e-02,  3.9122e-02, -4.0369e-03],\n",
       "                         [-1.2478e-01, -5.6188e-02, -2.4111e-02],\n",
       "                         [-6.4421e-02, -1.1154e-02,  3.1546e-02]],\n",
       "               \n",
       "                        [[ 6.7863e-02, -1.7155e-02,  8.1381e-02],\n",
       "                         [-3.2866e-02, -1.4610e-01, -7.5981e-03],\n",
       "                         [-9.6189e-02, -1.5031e-01, -2.5742e-02]],\n",
       "               \n",
       "                        [[-6.0012e-02,  7.6986e-02,  5.3144e-01],\n",
       "                         [ 1.6253e-01,  2.6311e-02,  2.9028e-01],\n",
       "                         [ 2.8924e-01,  4.3638e-01,  9.5001e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.4443e-02,  8.4047e-02,  9.4683e-02],\n",
       "                         [ 7.5064e-02,  8.1519e-03,  9.3771e-02],\n",
       "                         [ 4.4937e-02,  1.1582e-02,  3.0661e-02]],\n",
       "               \n",
       "                        [[-4.2403e-02,  5.5279e-02,  7.3614e-02],\n",
       "                         [-1.4714e-01, -1.1489e-01, -1.1970e-01],\n",
       "                         [-2.2739e-01, -2.6858e-01, -2.7262e-01]],\n",
       "               \n",
       "                        [[ 5.3812e-02,  1.3348e-01,  9.6792e-02],\n",
       "                         [ 1.7793e-02,  9.1173e-02,  1.9585e-02],\n",
       "                         [ 7.9299e-03,  8.6664e-02,  1.0111e-02]]]], device='cuda:0')),\n",
       "              ('conv_block3.bn1.weight',\n",
       "               tensor([1.0210, 1.0682, 1.3787, 1.2665, 1.1524, 1.2183, 0.7760, 0.9235, 1.3536,\n",
       "                       1.1974, 1.3259, 1.0340, 0.7915, 1.4988, 1.3355, 1.0443, 1.5879, 1.0444,\n",
       "                       1.4216, 1.0978, 0.9139, 1.1532, 1.1720, 1.4551, 0.9114, 1.1548, 0.2007,\n",
       "                       0.9233, 0.9801, 1.4392, 1.2658, 1.2461, 1.2587, 0.9034, 1.2150, 0.9803,\n",
       "                       0.9793, 1.0596, 1.2942, 1.0567, 0.9321, 1.1342, 1.5601, 1.0315, 1.2391,\n",
       "                       1.0022, 0.9950, 1.2044, 1.0443, 1.0558, 1.0039, 1.3602, 1.1981, 1.2316,\n",
       "                       1.3122, 1.0064, 0.7829, 1.3809, 1.1030, 1.4282, 0.9289, 1.1313, 1.3792,\n",
       "                       0.9184, 1.0905, 1.0623, 1.2476, 1.4465, 1.1163, 1.2293, 1.0798, 1.3139,\n",
       "                       1.7250, 0.8172, 1.5012, 1.3231, 1.0144, 1.1767, 0.8729, 1.1869, 0.9012,\n",
       "                       1.0563, 0.7078, 1.3326, 1.0936, 1.0224, 1.3593, 0.9392, 1.0068, 0.9863,\n",
       "                       1.1849, 0.9958, 1.2248, 0.9927, 0.3141, 1.3952, 1.0526, 0.9720, 1.1495,\n",
       "                       1.1253, 0.9783, 1.0597, 1.0248, 1.4366, 1.3393, 1.2572, 0.9937, 1.1931,\n",
       "                       1.1437, 0.8957, 1.2098, 0.2566, 1.0649, 1.3017, 1.0800, 0.5224, 1.0450,\n",
       "                       1.1513, 1.1263, 0.8780, 1.3537, 1.1516, 1.5164, 1.1235, 0.9574, 0.9924,\n",
       "                       1.1335, 1.0409, 0.9817, 0.9195, 0.9063, 0.7173, 1.1560, 1.2215, 1.1700,\n",
       "                       1.4139, 1.2205, 0.9432, 1.0820, 1.4721, 1.3174, 1.0905, 1.2970, 0.8261,\n",
       "                       0.9812, 1.0475, 1.2826, 1.2452, 0.8185, 1.0462, 1.0750, 1.5156, 1.1132,\n",
       "                       1.3410, 1.1077, 1.1155, 1.2860, 0.9671, 0.5262, 1.1721, 0.9906, 1.1165,\n",
       "                       1.2943, 0.9292, 1.0349, 1.1765, 1.1188, 1.1820, 0.9491, 0.9734, 1.3175,\n",
       "                       1.2034, 1.2084, 0.9865, 1.2615, 0.8739, 0.7807, 1.1073, 0.7385, 0.9734,\n",
       "                       1.4519, 0.9854, 1.0787, 1.0790, 1.0758, 1.1872, 1.0594, 0.9354, 0.5785,\n",
       "                       1.2671, 0.6805, 1.1030, 1.2096, 1.1690, 0.8356, 0.8897, 1.0657, 1.2187,\n",
       "                       0.9070, 0.7119, 0.9653, 0.9849, 1.0520, 0.2849, 0.9442, 1.1167, 1.2524,\n",
       "                       1.0367, 1.4768, 1.2307, 1.2085, 0.8254, 1.2146, 1.1639, 0.2181, 1.2649,\n",
       "                       1.1123, 1.2077, 1.2347, 1.0788, 1.5626, 1.0067, 1.1525, 1.1592, 1.1814,\n",
       "                       1.2216, 1.1346, 0.6273, 1.3089, 1.5136, 1.1486, 0.7495, 1.3114, 0.9355,\n",
       "                       1.1059, 1.4022, 1.3204, 1.5235, 1.3346, 1.1735, 1.1633, 1.0751, 1.3056,\n",
       "                       1.0540, 1.0776, 0.9134, 0.7332, 1.1821, 0.9479, 0.8942, 1.1816, 1.1299,\n",
       "                       0.9147, 1.0555, 0.8702, 1.0005], device='cuda:0')),\n",
       "              ('conv_block3.bn1.bias',\n",
       "               tensor([-0.8982, -0.5593, -0.8299, -0.8870, -0.6938, -0.3829, -1.0505, -0.7719,\n",
       "                       -0.6779, -0.5489, -0.8549, -0.9675, -0.3858, -1.1915, -0.7939, -0.5287,\n",
       "                       -1.0818, -0.6826, -1.1990, -0.5504, -0.6985, -0.5265, -0.7031, -0.7221,\n",
       "                       -0.6240, -0.7923, -0.7477, -0.6211, -0.4847, -0.9305, -0.8672, -0.9640,\n",
       "                       -0.5970, -0.7963, -1.0095, -0.7041, -0.6201, -0.8272, -0.8642, -0.7149,\n",
       "                       -0.1486, -0.8913, -1.5533, -0.5700, -0.7954, -0.9663, -0.5202, -1.0395,\n",
       "                       -1.0383, -0.8046, -0.7002, -1.1470, -0.5868, -0.7367, -0.7754, -0.4929,\n",
       "                       -0.6644, -0.7077, -0.7026, -0.8174, -0.6611, -0.5234, -0.6234, -0.5961,\n",
       "                       -0.5143, -0.7454, -0.6751, -0.6286, -1.0052, -1.2545, -0.4291, -1.1618,\n",
       "                       -0.8726, -0.8077, -1.0296, -0.9257, -1.2397, -0.9032, -1.1586, -0.6834,\n",
       "                       -0.3203, -0.7832,  0.3590, -0.7680, -0.7617, -0.9250, -0.9485, -0.8702,\n",
       "                       -0.5869, -0.2732, -1.1147, -0.6329, -0.7087, -0.5849, -1.2142, -0.8736,\n",
       "                       -1.2073, -0.4033, -0.6485, -0.9067, -0.1779, -0.7485, -1.5761, -0.8470,\n",
       "                       -0.5936, -1.3240, -0.8528, -0.7504, -0.8944, -0.4018, -0.9139, -0.2481,\n",
       "                       -1.2777, -0.6512, -0.5649,  0.1888, -0.9627, -0.8056, -0.6371, -0.6132,\n",
       "                       -1.0691, -0.5870, -1.7209, -0.3129, -0.5256, -1.5523, -0.5553, -0.8495,\n",
       "                       -0.0422, -0.3014, -0.5068, -0.6025, -0.5146, -1.0281, -0.7575, -1.0009,\n",
       "                       -0.9620, -0.3392, -0.7340, -0.9131, -1.0636, -0.7621, -0.8121, -0.3924,\n",
       "                       -1.2843, -0.4223, -0.8621, -0.7582, -0.4664, -0.6746, -0.9525, -0.7069,\n",
       "                       -0.6494, -1.2329, -0.9510, -0.5987, -0.8122, -0.2585, -2.3511, -0.4336,\n",
       "                       -0.4982, -1.0574, -0.6793, -0.3944, -0.4837, -0.6630, -1.0718, -0.7356,\n",
       "                       -0.3307, -0.7226, -0.8178, -0.3179, -0.6890, -0.4605, -1.2686, -0.4719,\n",
       "                       -0.4427, -0.6833, -0.3259, -0.6951, -1.1053, -0.9664, -0.7898, -0.8774,\n",
       "                       -0.1740, -0.9885, -0.3770, -0.7380, -1.2202, -1.1224, -0.1347, -0.7182,\n",
       "                       -0.7212, -0.3407, -0.2000, -0.8056, -0.8408, -0.6210, -1.0593, -3.0333,\n",
       "                       -0.3586, -1.0164, -0.5091, -0.7474, -0.7502, -0.5594, -0.7063, -0.6198,\n",
       "                       -1.2757, -0.9516, -0.7334, -0.6935, -0.7772, -0.7707, -0.4082, -1.0337,\n",
       "                       -0.6719, -0.8486, -0.8674, -0.7073, -0.8083, -0.7788, -0.8789, -0.3953,\n",
       "                       -1.1115, -0.7206, -0.9332,  0.0890, -0.8098, -0.9703, -1.0459, -0.3908,\n",
       "                       -0.4484, -0.9225, -0.8505, -0.7879, -0.9284, -1.4579, -1.1448, -0.5124,\n",
       "                       -0.8017, -0.4046, -0.8617, -0.6982, -0.5067, -0.4861, -0.2880, -0.7619,\n",
       "                       -0.6610, -0.4801, -0.9662, -0.7079, -0.0607, -0.8820, -0.4338, -0.8083],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.running_mean',\n",
       "               tensor([-3.7360, -4.6233, -3.6557, -4.6322, -4.8712, -6.6473,  2.6305, -2.3720,\n",
       "                       -5.6320, -4.4953, -5.4183, -4.5167, -0.6653, -1.5994, -3.9121, -4.2781,\n",
       "                       -5.1403, -6.3913, -2.0675, -2.6454, -2.2475, -3.3489, -3.0543, -3.3195,\n",
       "                       -3.7124, -2.8566,  0.2100, -1.1776, -2.3026, -5.0968, -1.6714, -3.2174,\n",
       "                       -4.1996, -3.7995, -4.8007, -1.2997, -5.3567, -6.7394, -3.0238, -3.8048,\n",
       "                       -5.4116, -1.9124, -3.5887, -3.7645, -3.0835,  0.4196, -0.1750, -0.8241,\n",
       "                       -3.8663, -5.2823, -1.4541, -0.5725, -3.8569, -1.6381, -7.6170, -2.1444,\n",
       "                       -4.5620, -5.6154, -4.2468, -5.3433, -5.3010, -2.4488, -6.4545, -2.8165,\n",
       "                        0.4223, -3.1771, -4.7437, -3.0589, -3.0745, -5.9238, -3.7874, -2.2076,\n",
       "                       -3.5404,  0.2015, -1.2456, -3.9242,  0.0954, -3.9417,  2.5984, -3.5945,\n",
       "                       -5.9171, -6.4251, -2.2578, -7.8775, -4.0284, -1.5283, -4.6262, -4.2763,\n",
       "                       -3.8058, -3.8550,  1.3800, -4.1743, -2.1319, -3.8210,  0.2053, -6.9632,\n",
       "                        1.3226, -2.8647, -3.8293, -1.0065, -4.6257, -2.2867, -0.0156, -1.9057,\n",
       "                       -3.9294, -1.8285, -0.6933, -7.2701, -0.6164, -6.3500, -2.5230, -0.1673,\n",
       "                       -0.9316, -4.1876, -2.7565, -3.4657, -4.0930, -1.9206, -3.3713,  1.5430,\n",
       "                       -3.6946, -6.0348, -4.5280, -3.2375, -1.6931,  5.8075, -4.1949, -1.6370,\n",
       "                       -1.5397, -2.7168, -4.1562, -2.2200, -4.1181, -4.4697, -1.1916, -2.0798,\n",
       "                       -3.4317, -1.1386, -3.6220, -2.8417, -4.7057, -2.8248, -2.5854, -8.3990,\n",
       "                        5.7105, -3.2966, -4.7009, -3.6105, -1.5590, -3.8793, -4.2679, -4.7801,\n",
       "                       -3.7535, -1.4472, -1.8453, -3.9892, -3.5442, -4.9556,  0.1412, -5.7569,\n",
       "                       -2.0001, -2.6130, -3.2370, -3.9707, -3.0764, -7.3013, -3.8480, -2.5359,\n",
       "                       -0.9426, -2.6543, -2.9104, -2.9212, -2.5907, -3.6120, -8.9578, -5.6857,\n",
       "                       -0.9836, -5.1064, -5.8374, -5.6726, -4.7037,  0.2951, -4.0062, -3.3184,\n",
       "                       -2.3170, -4.5064, -6.1815, -0.9618,  0.3356,  1.5998, -6.5894, -3.6475,\n",
       "                       -1.6931, -4.1432, -2.0141, -4.7789, -0.4445, -3.1385, -0.5600, -1.2760,\n",
       "                       -5.1539,  0.3197, -2.1731,  0.3439, -0.0959, -4.5920, -3.5617, -1.3553,\n",
       "                       -4.1359, -2.9156, -3.2453,  0.2077, -2.4971, -4.5291,  0.4152, -5.2192,\n",
       "                       -4.4310, -4.0784, -3.5517, -2.5801, -3.5983,  1.2604, -2.5246, -2.3927,\n",
       "                       -3.4935, -2.9094, -2.1389, -1.9884, -3.0646, -8.0526, -1.8004, -0.2110,\n",
       "                       -2.6031,  2.8122, -1.1262, -3.0278, -4.2276, -5.0716, -3.3233, -3.3826,\n",
       "                       -5.1959, -0.9382, -2.2691, -0.8058, -2.6139, -5.5010, -5.3529, -1.8328,\n",
       "                       -3.7692, -0.9625, -3.4762, -3.4709, -3.0176, -3.5250, -4.4706, -1.3083],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.running_var',\n",
       "               tensor([ 6.1906, 10.7009, 24.1509, 10.8535, 20.8408, 33.6762,  5.2201,  9.7729,\n",
       "                       23.8067, 10.8420, 21.0792,  9.0527, 12.4375,  6.0220, 12.7975,  4.4165,\n",
       "                       19.1036, 15.9470,  6.0773,  5.3244,  5.8844, 15.2656, 13.7625, 17.2115,\n",
       "                        9.5323, 18.9623,  0.3134,  9.9714, 19.6615, 26.4770,  7.6843,  8.8536,\n",
       "                       19.2414, 11.6547, 12.2803, 10.6438, 12.2425, 16.1193, 18.3075, 13.7481,\n",
       "                       13.2419,  9.7243,  9.2443,  9.2479, 13.4569,  9.9631, 10.7243,  8.8279,\n",
       "                        9.7693,  7.5803,  3.7514,  7.1608, 17.4216,  5.2497, 14.5373,  5.3475,\n",
       "                       14.0407, 21.1500, 12.7579, 19.2692, 11.1483, 16.4439, 27.9443, 12.0953,\n",
       "                       11.8162, 16.3111, 16.5706, 20.7969,  6.6163, 11.7927, 11.9599,  6.9639,\n",
       "                       27.2784,  2.5325, 10.3721, 19.2093,  4.0294,  8.4838,  6.6247, 10.4096,\n",
       "                       14.7797, 14.9003, 15.6197, 22.0655,  6.7335,  4.0474, 13.0321,  4.2047,\n",
       "                       19.2052, 20.2889,  5.2874,  7.2998, 14.2664,  7.5100,  0.7746, 15.2723,\n",
       "                        2.8366, 10.4677,  9.4623, 10.7298, 16.2824, 14.4357,  8.2096,  7.2522,\n",
       "                        9.0731,  6.8159,  5.1362, 13.4172,  5.0952, 14.4018, 15.6126,  0.6714,\n",
       "                        5.5315,  9.3035,  9.0678, 10.5202,  8.3224,  7.0902, 10.3108, 14.5298,\n",
       "                       12.4740, 16.5915, 10.1835, 15.5011,  8.4438, 10.5427, 11.1548,  7.0762,\n",
       "                       11.7243,  7.0338, 14.6593,  7.7724, 11.6558, 15.6894, 10.9430, 10.4501,\n",
       "                        7.1322, 16.6671,  9.2184, 14.6290, 20.1197, 11.5443,  7.8513, 18.9911,\n",
       "                        4.9606, 12.3159, 28.1145, 11.0436,  9.8462, 14.1108,  6.0178, 29.4965,\n",
       "                       14.3037,  7.9433,  5.8518,  8.9415, 22.8256, 13.0112,  0.8590, 29.0803,\n",
       "                       15.0455,  6.8791, 29.8244, 16.2032, 26.9033, 13.4011,  7.0414, 14.9736,\n",
       "                       11.0406,  7.4606,  6.3046,  7.9925,  7.9554,  9.7872, 12.8046, 11.6541,\n",
       "                        3.6507,  9.7574, 16.0379, 10.1677, 17.7478,  4.3765, 11.2913, 11.3733,\n",
       "                       14.5081,  7.4594, 13.1381,  9.7234,  1.3204,  6.6638, 16.0777,  5.1876,\n",
       "                       14.0519, 19.1653, 14.3280,  9.4319,  8.8464,  7.8796,  2.3688,  1.8170,\n",
       "                       10.6819,  2.9820,  8.9859,  0.6444, 10.0688, 16.8911, 16.1451, 11.7682,\n",
       "                       10.2172, 14.2086,  7.7493, 10.2250,  7.0203, 14.0146,  0.5052, 16.7758,\n",
       "                        6.6086, 10.6471, 12.1595,  9.1270, 23.1104,  5.8590, 10.6717, 14.7882,\n",
       "                       10.8837,  7.7072,  8.7823, 14.0688, 11.8872, 14.3936,  9.7891, 13.1332,\n",
       "                       22.6213,  6.3628, 14.6721, 14.4389, 15.3946, 16.4688, 10.7773,  6.6466,\n",
       "                       21.1301, 10.7116,  6.1879,  8.1472,  7.0374, 16.1513, 11.5553,  6.8429,\n",
       "                       12.0741, 11.5021, 10.7611, 12.5017, 14.9984, 15.8575, 19.4742,  8.1398],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block3.bn2.weight',\n",
       "               tensor([0.9051, 0.9394, 0.3467, 1.0366, 1.0479, 1.1572, 1.6049, 1.1137, 0.9935,\n",
       "                       1.1752, 0.8874, 1.0937, 0.6876, 1.1102, 1.4864, 1.3248, 0.9897, 1.4706,\n",
       "                       1.4177, 0.2613, 1.1516, 0.9729, 1.2617, 0.2820, 1.0827, 0.2616, 1.4487,\n",
       "                       1.0664, 1.4253, 1.3209, 1.0332, 1.2626, 0.9325, 1.1220, 0.8981, 1.0424,\n",
       "                       0.9619, 1.2507, 1.3945, 1.1734, 0.9084, 0.8654, 1.2673, 1.0337, 1.0987,\n",
       "                       1.3766, 1.6624, 0.8357, 1.0707, 0.9537, 0.2633, 0.9885, 0.9755, 1.3231,\n",
       "                       1.2518, 1.4758, 1.3703, 1.1539, 1.1889, 1.1905, 1.4671, 1.0795, 0.8962,\n",
       "                       0.8735, 1.1473, 1.0061, 0.9262, 0.9056, 0.9279, 1.1607, 1.1400, 1.3418,\n",
       "                       0.2692, 1.0091, 1.3077, 0.5176, 0.9112, 0.9307, 1.0229, 0.8897, 1.0297,\n",
       "                       0.9391, 1.0971, 0.4626, 0.9116, 1.4098, 1.0808, 1.0182, 1.5772, 1.0186,\n",
       "                       1.0702, 0.9926, 1.3717, 0.9138, 1.1040, 1.0963, 0.8279, 1.0532, 1.3980,\n",
       "                       1.2943, 1.0913, 0.8435, 1.0859, 0.9802, 1.0216, 0.2935, 1.1645, 0.9617,\n",
       "                       1.4009, 1.1233, 0.9578, 0.6571, 1.0725, 0.7002, 1.0372, 1.1292, 1.2509,\n",
       "                       0.9716, 1.5299, 1.2976, 1.0172, 1.2507, 1.0353, 1.0831, 0.9625, 0.9419,\n",
       "                       1.1977, 1.0909, 1.2755, 0.8902, 1.2145, 1.3266, 0.8319, 0.9505, 0.9411,\n",
       "                       1.1432, 0.9254, 1.1651, 1.1642, 0.2505, 1.2972, 1.1613, 0.9954, 1.1288,\n",
       "                       1.1554, 1.1024, 1.4579, 0.8870, 1.1077, 1.3331, 1.1827, 1.0637, 0.9267,\n",
       "                       1.1762, 1.0574, 1.2458, 1.3292, 0.9216, 1.0776, 1.2446, 1.3153, 1.2265,\n",
       "                       1.1726, 1.0782, 0.2623, 0.8875, 0.2963, 1.2376, 1.4084, 1.0460, 1.2456,\n",
       "                       1.2219, 1.0095, 1.0642, 0.9782, 1.2341, 1.0097, 1.0705, 0.8490, 0.9098,\n",
       "                       1.0768, 1.0270, 1.1807, 1.2606, 1.3560, 1.4065, 1.1395, 1.1043, 1.0956,\n",
       "                       0.9400, 0.9232, 0.9482, 1.0033, 0.7078, 1.1307, 1.1774, 0.9191, 1.1546,\n",
       "                       0.9854, 0.8554, 1.0341, 0.8977, 0.8860, 0.9033, 1.0850, 1.0711, 1.1451,\n",
       "                       0.9898, 1.1208, 1.0563, 1.3754, 0.8993, 1.0484, 0.8753, 0.9922, 1.2163,\n",
       "                       1.0892, 1.1947, 0.7565, 0.9142, 1.3299, 0.9942, 1.0805, 1.3669, 0.8534,\n",
       "                       1.3016, 1.4345, 1.2004, 1.1323, 0.7956, 0.9888, 1.0292, 1.1574, 1.1866,\n",
       "                       1.1543, 1.0344, 1.4174, 0.3030, 1.4229, 1.2801, 0.2937, 0.9351, 0.9618,\n",
       "                       1.1582, 1.2652, 0.9315, 1.1234, 1.0876, 1.0357, 1.2522, 0.9250, 1.1716,\n",
       "                       1.2080, 1.2942, 1.3198, 1.2777], device='cuda:0')),\n",
       "              ('conv_block3.bn2.bias',\n",
       "               tensor([-0.6634, -0.5544, -0.0422, -0.6581, -0.8572, -0.9712, -1.6261, -0.5950,\n",
       "                       -0.7201, -1.2496, -0.5318, -0.7978, -0.1393, -0.6118, -1.3631, -1.3863,\n",
       "                       -0.6188, -1.2326, -1.6330, -0.1872, -0.8443, -0.7549, -1.2820, -0.0505,\n",
       "                       -1.1499, -0.0781, -1.2581, -1.0880, -1.3273, -1.2754, -0.6035, -0.7674,\n",
       "                       -0.4481, -1.0971, -0.9998, -0.6411, -0.5971, -1.3235, -1.3134, -0.8110,\n",
       "                       -0.5895, -0.6744, -0.8855, -1.1614, -1.0477, -1.3588, -1.3315, -0.6502,\n",
       "                       -1.0932, -0.7254, -0.3861, -0.5992, -1.0614, -1.1524, -1.2114, -1.0342,\n",
       "                       -1.3392, -0.7853, -0.7540, -0.9350, -1.7840, -0.9019, -0.7942, -0.5565,\n",
       "                       -1.1643, -0.6610, -0.6357, -0.4942, -0.7252, -1.0780, -0.9504, -1.2680,\n",
       "                       -0.0283, -0.9093, -1.0604,  0.0534, -0.5707, -0.8475, -0.7689, -0.7964,\n",
       "                       -1.0437, -0.7244, -0.6308, -0.0799, -0.6952, -1.1794, -0.9914, -0.9248,\n",
       "                       -1.2379, -0.8964, -1.0408, -0.6191, -1.2270, -0.5548, -0.9034, -1.1669,\n",
       "                       -0.6484, -0.8183, -1.1430, -1.5660, -0.9298, -0.2687, -0.6611, -0.5908,\n",
       "                       -0.7479, -0.0536, -1.2109, -0.8190, -1.3240, -0.9726, -0.5736, -0.2446,\n",
       "                       -0.9323, -0.2670, -0.8135, -0.9782, -1.0693, -0.8946, -1.2197, -1.2017,\n",
       "                       -0.8493, -1.0271, -0.7801, -0.9973, -0.5407, -0.5843, -0.8183, -0.9339,\n",
       "                       -1.1637, -0.6353, -0.8803, -1.1417, -0.6053, -0.5750, -0.9905, -1.1236,\n",
       "                       -0.7335, -0.7768, -1.1079, -0.0484, -1.5820, -1.2682, -0.9510, -0.8856,\n",
       "                       -1.1036, -1.2498, -1.1422, -0.8046, -0.9191, -1.1010, -0.9548, -0.9208,\n",
       "                       -0.7223, -0.7993, -0.9130, -0.6914, -1.4146, -0.8214, -0.7783, -0.7009,\n",
       "                       -1.1782, -0.8517, -0.7981, -1.0004, -0.0658, -0.6777,  0.1841, -0.9849,\n",
       "                       -1.3402, -0.8736, -0.5267, -0.7914, -0.9291, -1.1181, -0.5579, -0.9340,\n",
       "                       -1.1616, -1.0515, -0.6710, -0.8138, -0.8020, -0.6899, -1.1364, -1.0139,\n",
       "                       -0.7805, -1.3099, -0.3936, -0.8767, -0.4665, -0.8453, -0.6968, -0.5989,\n",
       "                       -0.8351, -0.6806, -0.9338, -1.0715, -0.7662, -1.4438, -0.6182, -0.7659,\n",
       "                       -1.0537, -0.5319, -0.5135, -0.9045, -0.5828, -0.8373, -0.9134, -0.7420,\n",
       "                       -1.1932, -0.9939, -0.7015, -0.5463, -1.0515, -0.5218, -0.5948, -0.8505,\n",
       "                       -1.0803, -0.9453, -0.5138, -0.3713, -1.3711, -0.6823, -0.7744, -1.3687,\n",
       "                       -0.5889, -0.9297, -1.4539, -0.9427, -0.8768, -0.5206, -1.0093, -0.6510,\n",
       "                       -0.8140, -1.1389, -1.1334, -0.8144, -1.4738,  0.0231, -1.1460, -1.0632,\n",
       "                       -0.0401, -0.7883, -0.5025, -0.6524, -1.0350, -0.7857, -0.7549, -0.8493,\n",
       "                       -0.7969, -0.8876, -0.9356, -0.6092, -1.0583, -1.3752, -1.4297, -1.2696],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn2.running_mean',\n",
       "               tensor([-3.4911e+00, -9.6107e+00, -5.3826e+00, -1.6101e+01, -5.5888e+00,\n",
       "                       -8.8130e+00, -9.5321e+00, -6.3366e+00, -8.2244e+00, -8.4098e+00,\n",
       "                       -3.3756e+00, -7.0694e+00, -4.1885e+00, -8.6844e+00, -7.0230e+00,\n",
       "                       -1.5198e+01, -1.1964e+01, -7.8929e+00, -3.9568e+00, -3.9354e+00,\n",
       "                       -1.1699e+01,  2.0371e+00, -9.2795e+00,  5.9330e-02, -5.3359e+00,\n",
       "                        1.4149e-02, -6.5833e+00, -4.7250e-01, -1.2001e+01, -5.9918e+00,\n",
       "                       -1.3095e+01, -6.4204e+00, -2.2617e+00, -1.1366e+01, -6.1231e+00,\n",
       "                       -9.6574e+00, -1.2655e+01, -3.6809e+00, -6.0819e+00, -2.5524e+00,\n",
       "                        4.1935e+00, -3.6395e+00, -4.0330e+00, -4.5607e+00, -5.9919e+00,\n",
       "                       -1.3055e+01, -4.4051e+00, -4.5932e+00, -7.9964e+00, -6.3563e+00,\n",
       "                        7.8042e-02, -8.5461e+00, -4.2503e+00, -7.0154e+00, -8.0652e+00,\n",
       "                       -7.5181e+00, -9.9843e+00, -1.2088e+01, -8.2631e+00, -1.6709e+01,\n",
       "                       -8.9786e+00, -3.2740e+00, -3.0352e+00, -5.7816e+00, -1.0367e+00,\n",
       "                       -9.6153e+00, -1.2270e+00, -6.9112e+00, -5.0506e+00, -1.1475e+01,\n",
       "                       -7.0857e+00, -9.1037e+00, -2.5610e-02, -6.9558e+00, -8.9153e+00,\n",
       "                       -1.1920e+00, -9.7330e+00, -1.3303e+01, -1.0187e+01, -3.5070e+00,\n",
       "                       -3.8751e+00, -6.2426e+00, -7.3738e+00, -7.2214e+00, -7.7449e+00,\n",
       "                       -1.9124e+00, -4.3638e+00, -2.4460e+00, -8.4248e+00, -7.2303e+00,\n",
       "                       -5.0449e+00, -6.1708e+00, -6.7142e+00, -8.7842e+00, -1.4931e+01,\n",
       "                       -8.3758e+00,  4.8030e+00, -1.2311e+01, -5.9956e+00, -2.1967e+00,\n",
       "                       -2.2356e+00, -3.7703e+00, -5.8839e+00, -1.1787e+01, -1.0484e+01,\n",
       "                        9.5356e-02, -6.3985e+00, -6.5360e+00, -9.0980e+00, -9.6880e+00,\n",
       "                       -1.0938e+01, -8.2971e+00, -8.1249e+00, -3.1658e+00, -3.9382e+00,\n",
       "                       -5.5435e+00, -1.3640e+01, -1.0127e+01, -5.9742e+00, -9.9183e+00,\n",
       "                       -5.7110e+00, -2.7085e+00, -3.4386e+00, -9.2171e+00, -7.6556e+00,\n",
       "                       -8.4008e+00, -7.3623e+00, -9.9678e+00, -6.5990e+00, -1.0719e+01,\n",
       "                       -8.8565e+00, -2.6989e+00, -8.4863e+00, -4.6265e+00, -1.0382e+01,\n",
       "                       -9.7883e+00, -1.2193e+01, -6.3949e+00, -4.8447e+00,  5.8276e-03,\n",
       "                       -6.2136e+00, -1.0262e+01, -8.1288e+00, -2.5930e+00, -1.1328e+01,\n",
       "                       -3.8169e+00, -5.9234e+00, -1.1199e+01, -7.7389e+00, -8.8508e+00,\n",
       "                       -9.2099e+00, -1.2340e+01, -7.9534e+00, -7.4613e+00, -3.8052e+00,\n",
       "                       -6.5691e+00, -9.9729e+00, -1.3705e+00, -5.1512e+00, -1.0458e+00,\n",
       "                       -4.5330e+00, -1.1094e+01, -9.7869e+00, -5.6063e+00,  7.8726e-02,\n",
       "                       -2.8889e+00, -1.3183e+00, -3.8979e+00, -8.7061e+00, -9.4747e+00,\n",
       "                       -7.4667e+00, -6.6214e+00, -1.0910e+01, -4.1701e+00, -4.1629e+00,\n",
       "                       -7.0732e+00, -6.9208e+00, -6.2487e+00, -5.0185e+00, -5.0112e+00,\n",
       "                       -1.0220e+01, -1.0323e+01, -6.2955e+00, -5.8233e+00, -1.1548e+01,\n",
       "                       -6.7834e+00, -4.5839e+00, -1.3402e+01, -4.6271e+00, -1.2829e+01,\n",
       "                       -6.7772e+00, -6.7742e+00, -8.2506e+00,  4.2465e-01, -1.3567e+01,\n",
       "                       -3.2647e+00, -6.7446e+00,  3.3160e-01, -6.1321e+00, -6.4997e+00,\n",
       "                       -8.8729e+00, -5.6220e+00, -3.4813e+00, -5.9370e+00, -1.0709e+01,\n",
       "                       -6.4628e+00, -1.1719e+01, -3.9484e+00,  3.1026e+00, -6.6003e+00,\n",
       "                       -9.4827e+00, -8.4693e+00, -9.2676e+00, -1.1096e+01, -5.9350e+00,\n",
       "                       -9.8378e+00,  2.6526e+00, -9.2605e+00, -3.1468e+00, -9.9574e+00,\n",
       "                        2.6649e+00, -1.0790e+01, -7.9090e+00, -1.0677e+01, -7.9327e+00,\n",
       "                       -7.8905e+00, -6.0571e+00, -7.4595e+00, -1.0302e+01, -1.7779e+00,\n",
       "                       -6.6011e+00, -4.6557e+00, -1.1171e+01, -6.7969e+00, -3.7002e+00,\n",
       "                       -1.0312e+01, -1.0197e+01,  2.4224e+00, -5.5731e+00, -6.1909e+00,\n",
       "                        2.6746e-02, -1.0855e+01, -1.0937e+01, -1.0483e+01, -6.3921e+00,\n",
       "                       -7.5746e+00, -2.4169e+00, -1.0476e+01, -7.3055e-01, -4.6117e+00,\n",
       "                       -7.9135e+00, -6.3495e+00, -5.4649e+00, -9.6260e+00, -6.5566e+00,\n",
       "                       -9.5391e+00], device='cuda:0')),\n",
       "              ('conv_block3.bn2.running_var',\n",
       "               tensor([32.6233, 51.5683, 12.6306, 65.5238, 32.6754, 44.7554, 64.5536, 27.7206,\n",
       "                       39.5589, 38.3092, 26.6532, 33.9899, 30.0790, 54.5678, 51.9654, 59.6498,\n",
       "                       30.5240, 46.6019, 27.9788,  6.7656, 67.2831, 29.2543, 63.4173,  4.0350,\n",
       "                       27.5978,  2.7838, 46.1793, 22.1832, 76.4300, 27.9449, 36.9475, 48.0723,\n",
       "                       45.7297, 53.8783, 28.5872, 56.5120, 47.0346, 60.6090, 60.9651, 25.6091,\n",
       "                       42.1833, 48.8448, 35.1397, 50.1726, 56.0075, 34.9519, 36.2864, 35.8140,\n",
       "                       37.3637, 29.9512,  2.6348, 26.1510, 42.6052, 53.2502, 25.8395, 35.5810,\n",
       "                       40.8477, 38.8935, 45.3449, 51.7833, 39.9969, 43.2109, 25.6505, 36.0094,\n",
       "                       33.2648, 62.1977, 39.1122, 57.3670, 33.4389, 38.1868, 52.7368, 54.3924,\n",
       "                        3.6088, 64.9561, 36.4023, 15.0502, 40.6238, 54.7768, 29.0203, 38.0345,\n",
       "                       65.5473, 53.0213, 29.6840, 11.6785, 36.9148, 31.7697, 59.0567, 56.0098,\n",
       "                       53.6699, 58.3168, 48.9750, 37.4606, 42.3741, 51.5572, 94.3404, 24.0388,\n",
       "                       25.0426, 38.1994, 50.9014, 22.3653, 39.0551, 24.0783, 40.2843, 49.7629,\n",
       "                       37.6483,  3.2578, 38.6164, 40.2132, 63.3210, 47.4026, 42.1460, 22.7260,\n",
       "                       44.6575, 34.8594, 43.7083, 44.9351, 45.3688, 48.0210, 33.4751, 45.1288,\n",
       "                       53.3950, 32.8214, 57.7978, 36.8290, 41.1461, 38.3068, 33.7378, 57.2282,\n",
       "                       33.2330, 48.1275, 42.6299, 27.8076, 46.1160, 46.7283, 42.1512, 28.0513,\n",
       "                       57.9283, 39.8380, 43.2196,  3.5073, 28.0107, 46.1415, 68.1599, 48.5282,\n",
       "                       56.3766, 35.8305, 39.1425, 44.9112, 59.0459, 36.1491, 35.4118, 41.4488,\n",
       "                       45.1702, 27.1920, 49.6938, 47.7060, 31.0848, 15.4609, 26.2254, 29.7920,\n",
       "                       23.0079, 73.6208, 41.7077, 37.2194,  2.4906, 26.4361,  8.6566, 37.1917,\n",
       "                       42.9030, 79.9636, 34.5892, 25.0802, 57.8477, 48.7814, 38.4691, 44.0872,\n",
       "                       38.7179, 67.8061, 36.7731, 20.4657, 46.1175, 40.5765, 36.2589, 49.1754,\n",
       "                       39.0490, 35.3677, 44.1855, 75.3239, 30.7163, 40.1691, 43.4779, 36.5468,\n",
       "                       39.9022, 23.8207, 47.7200, 35.6861, 49.6604, 36.0345, 42.3438, 26.6729,\n",
       "                       38.3238, 25.3345, 33.1475, 36.2977, 30.7630, 33.7805, 52.9490, 27.6904,\n",
       "                       37.3234, 65.8518, 69.2531, 35.1666, 37.9871, 40.7733, 24.8778, 32.4508,\n",
       "                       39.5215, 46.5822, 29.6104, 39.9276, 35.4048, 68.5465, 58.7924, 26.3959,\n",
       "                       44.8660, 41.4652, 37.1311, 36.3811, 38.8422, 38.1316, 46.0219, 37.1965,\n",
       "                       53.9513, 32.3594, 31.7732, 46.6417, 45.2628,  7.0563, 49.5439, 32.8643,\n",
       "                        3.0042, 29.8262, 41.4070, 42.1796, 28.3282, 47.5921, 33.2856, 51.8637,\n",
       "                       34.3875, 31.0627, 32.7539, 48.3618, 42.0343, 42.5362, 42.4494, 46.9895],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block3.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block4.conv1.weight',\n",
       "               tensor([[[[-2.8117e-01, -1.9448e-01, -3.2072e-01],\n",
       "                         [ 1.6667e-01,  7.5469e-03, -1.2761e-01],\n",
       "                         [ 1.5804e-01,  1.4452e-01,  5.4735e-03]],\n",
       "               \n",
       "                        [[ 5.7425e-03, -1.6190e-02, -4.9775e-01],\n",
       "                         [ 6.9577e-02,  3.7016e-02, -2.2179e-01],\n",
       "                         [-2.1399e-01, -1.8292e-01, -2.7259e-01]],\n",
       "               \n",
       "                        [[-3.2275e-02,  6.3697e-02,  3.6232e-02],\n",
       "                         [-1.0834e-02,  2.3389e-01, -1.6246e-02],\n",
       "                         [ 1.3494e-01,  1.3342e-01, -1.4910e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 1.0493e-01,  6.6150e-03,  9.4810e-02],\n",
       "                         [ 7.5323e-02, -8.4515e-02, -2.6031e-01],\n",
       "                         [-4.4923e-02,  1.3767e-01, -1.3903e-02]],\n",
       "               \n",
       "                        [[ 5.8768e-02,  3.0249e-03,  1.2129e-01],\n",
       "                         [-1.4058e-02, -1.4894e-02,  1.1285e-01],\n",
       "                         [ 7.8302e-02, -5.2702e-03,  1.2461e-01]],\n",
       "               \n",
       "                        [[-2.8437e-02, -1.5080e-01, -1.7280e-02],\n",
       "                         [ 2.3192e-01, -1.1718e-02, -4.4942e-02],\n",
       "                         [ 6.1271e-01,  2.4129e-01,  1.4843e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 1.8397e-01,  1.0231e-01, -3.6553e-04],\n",
       "                         [ 3.4619e-01,  2.6139e-01,  2.4499e-01],\n",
       "                         [ 3.5390e-01,  2.8168e-01,  3.8342e-01]],\n",
       "               \n",
       "                        [[ 8.4976e-02,  2.6384e-01,  9.5468e-02],\n",
       "                         [-2.7714e-02, -2.2332e-02, -4.8102e-02],\n",
       "                         [-1.7257e-01,  6.8492e-02,  1.0205e-01]],\n",
       "               \n",
       "                        [[-2.5342e-02, -1.5528e-02, -6.1688e-02],\n",
       "                         [-2.7608e-02, -2.5081e-02, -6.0266e-02],\n",
       "                         [ 6.7514e-04, -1.2479e-03, -4.8764e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.2393e-01, -9.4306e-02, -1.9476e-01],\n",
       "                         [ 5.8398e-03, -7.9925e-02, -4.1517e-01],\n",
       "                         [-5.0327e-02, -1.9655e-01, -1.1735e-01]],\n",
       "               \n",
       "                        [[ 2.7297e-01, -4.6044e-02,  2.8592e-02],\n",
       "                         [ 7.4112e-01, -5.0212e-02, -1.0976e-01],\n",
       "                         [ 6.0514e-01, -6.1636e-02,  1.5829e-01]],\n",
       "               \n",
       "                        [[-8.9858e-02, -1.4299e-01, -8.8171e-02],\n",
       "                         [-2.7729e-02, -5.3546e-02,  1.1596e-03],\n",
       "                         [ 1.9970e-01,  5.9318e-02,  1.9625e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[-5.5145e-02, -7.8992e-02, -2.5136e-02],\n",
       "                         [-4.0007e-02, -3.4993e-02, -4.9632e-02],\n",
       "                         [ 2.2835e-02, -8.2773e-02, -1.4480e-01]],\n",
       "               \n",
       "                        [[ 8.8546e-02, -1.3631e-03,  7.4954e-05],\n",
       "                         [ 2.7300e-02, -2.4629e-02, -6.8863e-02],\n",
       "                         [ 9.9173e-02,  2.9239e-02, -1.0297e-02]],\n",
       "               \n",
       "                        [[ 1.6983e-02,  3.6542e-03, -6.4787e-02],\n",
       "                         [ 9.0322e-02,  2.4170e-02, -5.2050e-02],\n",
       "                         [ 6.6579e-02,  4.9823e-02, -2.5309e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-2.4695e-02,  4.1721e-02, -5.1636e-02],\n",
       "                         [-6.5091e-02, -4.3530e-02, -1.4238e-01],\n",
       "                         [-5.6960e-02, -3.9052e-02, -1.4414e-01]],\n",
       "               \n",
       "                        [[ 1.1531e-02,  5.8840e-02,  4.7447e-02],\n",
       "                         [ 6.2048e-02,  1.1637e-01,  5.8397e-02],\n",
       "                         [ 5.2231e-03, -4.5418e-03, -3.0628e-02]],\n",
       "               \n",
       "                        [[ 5.5873e-03,  3.9302e-02, -1.9303e-02],\n",
       "                         [-8.0556e-02,  4.2154e-03, -8.2461e-02],\n",
       "                         [-1.3790e-01, -1.9746e-02, -1.8784e-01]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[-1.5198e-01, -3.6075e-02, -1.4837e-01],\n",
       "                         [-2.3885e-01, -2.8460e-02, -1.0875e-01],\n",
       "                         [-1.4545e-01, -7.0426e-02, -6.8133e-02]],\n",
       "               \n",
       "                        [[-5.5952e-02, -4.0911e-02, -3.3310e-02],\n",
       "                         [-1.7451e-01, -8.7108e-02,  1.2693e-02],\n",
       "                         [-7.0759e-02, -4.8385e-02, -3.3718e-03]],\n",
       "               \n",
       "                        [[ 2.9875e-02,  6.5026e-03, -1.0522e-01],\n",
       "                         [ 9.7180e-02,  5.2470e-02, -5.8483e-02],\n",
       "                         [ 1.0137e-02,  2.4127e-02, -2.8789e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 7.7989e-02,  1.1075e-01,  9.5427e-02],\n",
       "                         [ 2.2058e-02,  4.7560e-02,  4.7533e-02],\n",
       "                         [-1.4979e-02, -4.1187e-02, -8.4268e-03]],\n",
       "               \n",
       "                        [[-5.8950e-03, -4.3256e-02, -1.0115e-01],\n",
       "                         [-4.2977e-02,  7.3435e-04, -1.7013e-02],\n",
       "                         [-1.0561e-01, -1.1956e-01, -4.2652e-02]],\n",
       "               \n",
       "                        [[-3.0934e-02, -1.9715e-02, -4.4373e-02],\n",
       "                         [ 1.9279e-01,  1.6256e-01,  1.3915e-01],\n",
       "                         [ 4.7260e-02,  1.3291e-01, -8.4166e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[-3.3602e-02,  2.0539e-02,  1.2633e-01],\n",
       "                         [-2.9732e-02,  6.9290e-02,  1.5418e-01],\n",
       "                         [ 7.1638e-02,  9.3394e-02,  1.5287e-01]],\n",
       "               \n",
       "                        [[-1.8831e-02,  1.6386e-02, -3.7939e-02],\n",
       "                         [-5.5418e-02,  3.2672e-03, -3.0469e-02],\n",
       "                         [ 1.9739e-03,  4.9307e-02, -2.8697e-02]],\n",
       "               \n",
       "                        [[ 1.1110e-02, -9.3922e-03, -1.0620e-01],\n",
       "                         [ 5.1250e-02,  4.8479e-02, -1.5916e-01],\n",
       "                         [ 2.6691e-02,  6.9313e-02, -1.7979e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.3847e-02, -1.4713e-02, -1.0052e-01],\n",
       "                         [ 1.9321e-02,  8.7875e-03, -5.4893e-02],\n",
       "                         [ 3.4401e-02,  1.7562e-02,  1.9163e-02]],\n",
       "               \n",
       "                        [[-1.8030e-04,  7.7708e-02,  1.5777e-01],\n",
       "                         [ 1.7430e-02,  5.9972e-02,  1.0575e-01],\n",
       "                         [-6.3385e-03,  6.1964e-02,  2.0596e-01]],\n",
       "               \n",
       "                        [[ 4.0382e-02,  1.6917e-01,  1.4179e-01],\n",
       "                         [ 6.5023e-02,  7.9723e-02,  1.8729e-01],\n",
       "                         [ 4.7586e-02,  1.4556e-01,  8.0061e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.9561e-02,  1.6063e-02,  4.5139e-02],\n",
       "                         [-1.0781e-01, -1.5374e-02,  8.8728e-05],\n",
       "                         [-4.4376e-02,  5.6114e-03,  6.6437e-02]],\n",
       "               \n",
       "                        [[-2.1091e-02,  1.9502e-03, -5.8937e-02],\n",
       "                         [-4.3717e-02, -4.9178e-03, -1.5190e-01],\n",
       "                         [ 6.7578e-02,  5.1915e-02,  2.1604e-02]],\n",
       "               \n",
       "                        [[ 2.7038e-03, -4.4696e-02, -8.6027e-02],\n",
       "                         [ 8.1351e-02,  3.4863e-02, -1.7840e-01],\n",
       "                         [ 3.4614e-02,  3.6288e-02, -1.2641e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 4.3675e-03,  1.8449e-02, -4.5892e-02],\n",
       "                         [ 3.9285e-02,  1.1169e-02, -4.6597e-02],\n",
       "                         [ 1.1016e-02, -1.7599e-02, -4.0958e-02]],\n",
       "               \n",
       "                        [[ 1.7124e-02,  4.0852e-02,  7.1878e-02],\n",
       "                         [ 1.9256e-02,  2.0039e-02,  6.9166e-02],\n",
       "                         [ 8.0109e-02,  1.0178e-01,  1.2642e-01]],\n",
       "               \n",
       "                        [[-1.3671e-02,  2.6154e-02, -1.1227e-03],\n",
       "                         [-5.0951e-02,  1.0144e-02, -8.1067e-02],\n",
       "                         [-4.0022e-02, -1.2864e-02, -1.0272e-01]]]], device='cuda:0')),\n",
       "              ('conv_block4.conv2.weight',\n",
       "               tensor([[[[-1.3141e-01, -1.7014e-01, -3.1536e-01],\n",
       "                         [ 1.4788e-04, -1.2086e-01, -3.0856e-01],\n",
       "                         [-5.1835e-02, -1.7605e-01, -3.0941e-01]],\n",
       "               \n",
       "                        [[-1.5246e-01, -1.2831e-01, -4.4812e-02],\n",
       "                         [-1.6314e-01, -1.2917e-01, -7.5320e-02],\n",
       "                         [-1.5122e-01, -1.1717e-01, -1.5710e-01]],\n",
       "               \n",
       "                        [[-5.3818e-02, -5.1342e-02, -1.5757e-01],\n",
       "                         [-7.5635e-02, -9.9171e-02, -2.1828e-01],\n",
       "                         [-1.0729e-03, -1.0431e-01, -2.2602e-01]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.4321e-02, -2.2552e-02, -8.8848e-02],\n",
       "                         [-2.5956e-02, -3.5327e-02, -1.3773e-01],\n",
       "                         [ 8.9133e-03,  3.0740e-03, -1.0050e-01]],\n",
       "               \n",
       "                        [[ 6.3828e-02,  1.4987e-05, -3.2330e-02],\n",
       "                         [ 1.6951e-03, -2.7668e-02, -1.7322e-01],\n",
       "                         [-6.9142e-03, -5.0586e-02, -1.9127e-01]],\n",
       "               \n",
       "                        [[-3.0931e-02, -6.4165e-02, -1.4262e-01],\n",
       "                         [-5.3583e-02, -1.3207e-01, -2.6642e-01],\n",
       "                         [-4.2838e-02, -6.4026e-02, -2.8391e-01]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 9.9623e-02, -6.3867e-02,  2.5452e-02],\n",
       "                         [ 1.1098e-01, -3.8810e-02,  1.3309e-01],\n",
       "                         [ 1.2145e-01, -2.1395e-02,  1.1927e-01]],\n",
       "               \n",
       "                        [[ 2.8668e-01,  1.7305e-02,  8.8408e-02],\n",
       "                         [ 2.5384e-01, -1.9117e-01, -2.0238e-01],\n",
       "                         [ 2.4004e-01, -2.0833e-01, -1.6091e-01]],\n",
       "               \n",
       "                        [[-2.6671e-02, -1.1001e-01,  3.0393e-02],\n",
       "                         [ 4.0007e-04, -1.1037e-01,  4.0861e-03],\n",
       "                         [-1.8974e-02, -1.4899e-01,  2.3437e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-3.5335e-02, -6.9298e-02, -4.2384e-03],\n",
       "                         [-3.2748e-02, -7.9837e-02, -3.2012e-02],\n",
       "                         [-9.6534e-02, -1.6497e-01, -8.8456e-02]],\n",
       "               \n",
       "                        [[-1.4191e-02, -5.7730e-02,  7.7663e-02],\n",
       "                         [-1.6944e-02, -1.2329e-01,  6.6457e-02],\n",
       "                         [-3.9793e-02, -5.5077e-02,  1.8633e-02]],\n",
       "               \n",
       "                        [[-4.3596e-02, -1.3971e-01,  1.0534e-02],\n",
       "                         [-4.4777e-02, -1.0370e-01,  2.5256e-02],\n",
       "                         [-2.9126e-02, -1.2420e-01,  1.6884e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-1.2084e-01, -6.4760e-02,  1.3030e-01],\n",
       "                         [-1.3044e-01, -2.5075e-02,  1.6151e-02],\n",
       "                         [-8.7644e-02,  1.5531e-03,  1.7084e-02]],\n",
       "               \n",
       "                        [[ 1.0630e-01,  6.8825e-02,  1.0841e-01],\n",
       "                         [ 6.3294e-02,  5.6313e-02,  9.1738e-02],\n",
       "                         [-8.5978e-02,  4.0142e-03,  4.2442e-02]],\n",
       "               \n",
       "                        [[-7.9506e-02, -5.3952e-01, -4.3850e-02],\n",
       "                         [-1.0070e-01, -6.0278e-01, -6.0825e-02],\n",
       "                         [-4.1294e-02, -4.5038e-01, -5.5793e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 3.0779e-02, -9.0226e-03,  3.3375e-03],\n",
       "                         [ 8.1960e-04, -7.6463e-02, -3.6247e-02],\n",
       "                         [ 1.9942e-02, -4.3963e-02, -3.7640e-02]],\n",
       "               \n",
       "                        [[-4.5117e-02, -9.3657e-02, -1.9836e-03],\n",
       "                         [-5.8529e-02, -8.0018e-02, -3.1515e-02],\n",
       "                         [-1.2475e-02, -7.1371e-02, -4.3010e-03]],\n",
       "               \n",
       "                        [[-5.3049e-02, -1.5731e-01, -2.5275e-02],\n",
       "                         [-5.1301e-02, -2.0356e-01, -2.3456e-02],\n",
       "                         [-2.6011e-02, -1.6314e-01, -5.0286e-03]]],\n",
       "               \n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "               \n",
       "                       [[[ 1.3632e-03, -1.2925e-02,  6.8488e-04],\n",
       "                         [-9.8775e-02, -8.1714e-02, -3.4547e-02],\n",
       "                         [-1.1710e-02, -7.6958e-02, -6.0914e-02]],\n",
       "               \n",
       "                        [[-1.0509e-01, -1.0036e-01, -3.5899e-02],\n",
       "                         [-1.3978e-01, -1.4804e-01, -3.0534e-02],\n",
       "                         [-1.9116e-01, -1.2482e-01, -7.7175e-02]],\n",
       "               \n",
       "                        [[ 1.0296e-02, -6.9565e-02,  7.9738e-02],\n",
       "                         [ 2.8699e-02, -1.6072e-01,  6.3567e-02],\n",
       "                         [ 1.6107e-02, -1.5727e-01,  4.8203e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-4.1035e-02, -1.2945e-01,  1.2868e-02],\n",
       "                         [-1.6226e-01, -2.2084e-01, -4.9709e-03],\n",
       "                         [-2.6686e-02, -8.8472e-02,  4.4570e-02]],\n",
       "               \n",
       "                        [[-5.2616e-03, -5.7111e-02,  5.4005e-02],\n",
       "                         [-2.7419e-02, -9.5018e-02,  4.9039e-02],\n",
       "                         [-2.7858e-04, -2.4506e-02,  3.1993e-02]],\n",
       "               \n",
       "                        [[-3.8276e-02, -7.3607e-02, -9.0714e-03],\n",
       "                         [-5.5761e-02, -1.2196e-01,  4.7025e-03],\n",
       "                         [-1.7847e-02, -1.2619e-01,  4.5440e-02]]],\n",
       "               \n",
       "               \n",
       "                       [[[-9.4819e-02, -1.4828e-01, -1.0668e-01],\n",
       "                         [ 4.5886e-02,  2.8900e-02,  4.0922e-02],\n",
       "                         [ 1.8913e-03,  2.3505e-02,  1.6824e-01]],\n",
       "               \n",
       "                        [[ 1.5831e-01,  1.1025e-01,  3.2725e-01],\n",
       "                         [ 3.3227e-01,  2.0414e-01,  3.9934e-01],\n",
       "                         [ 3.2118e-01,  2.7469e-01,  3.1816e-01]],\n",
       "               \n",
       "                        [[ 4.3839e-03, -1.8127e-01,  3.0586e-02],\n",
       "                         [-5.1334e-02, -2.2614e-01,  6.0986e-02],\n",
       "                         [-9.7718e-03, -2.2800e-01,  7.6102e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[ 5.9273e-02, -9.4798e-02, -1.8765e-02],\n",
       "                         [ 2.7452e-02, -1.2884e-01, -6.5547e-03],\n",
       "                         [-1.1060e-01, -2.2181e-01, -8.4998e-02]],\n",
       "               \n",
       "                        [[-1.2539e-02, -9.0758e-02,  3.2262e-02],\n",
       "                         [-2.7983e-02, -1.2655e-01,  1.7510e-03],\n",
       "                         [-7.8804e-03, -1.0630e-01,  3.6500e-02]],\n",
       "               \n",
       "                        [[-4.5780e-02, -1.7082e-01,  3.4723e-02],\n",
       "                         [-4.5897e-02, -2.2459e-01, -1.2138e-02],\n",
       "                         [-5.9276e-02, -1.9904e-01, -7.6359e-03]]],\n",
       "               \n",
       "               \n",
       "                       [[[ 6.4527e-02,  2.3626e-03,  3.5323e-02],\n",
       "                         [ 5.2964e-02,  8.6002e-03,  9.5076e-02],\n",
       "                         [ 2.5534e-01,  2.2776e-01,  6.3691e-01]],\n",
       "               \n",
       "                        [[-3.1473e-01, -1.5584e-01, -2.4066e-01],\n",
       "                         [-5.6614e-01, -2.5919e-01, -4.8721e-01],\n",
       "                         [-4.7625e-01, -4.3592e-01, -5.6699e-01]],\n",
       "               \n",
       "                        [[-8.0138e-02, -2.7227e-01, -3.8287e-03],\n",
       "                         [-8.9857e-02, -3.3922e-01, -7.3446e-03],\n",
       "                         [-8.2277e-02, -2.2914e-01, -2.5482e-02]],\n",
       "               \n",
       "                        ...,\n",
       "               \n",
       "                        [[-6.4436e-02, -1.6535e-01, -6.6169e-02],\n",
       "                         [-1.0076e-01, -1.9541e-01, -2.1543e-02],\n",
       "                         [-4.8573e-02, -2.3831e-01, -7.6474e-02]],\n",
       "               \n",
       "                        [[-6.5030e-02, -1.0340e-01, -1.7654e-02],\n",
       "                         [-4.2388e-02, -9.1843e-02, -4.4946e-02],\n",
       "                         [-5.0771e-02, -9.4325e-02, -3.5689e-02]],\n",
       "               \n",
       "                        [[-1.0607e-01, -1.3761e-01, -1.6891e-01],\n",
       "                         [-7.1688e-02, -1.0667e-01, -9.9844e-02],\n",
       "                         [-6.6565e-02, -1.0376e-01, -2.3241e-02]]]], device='cuda:0')),\n",
       "              ('conv_block4.bn1.weight',\n",
       "               tensor([1.0171, 0.5798, 0.5005, 0.9467, 0.4131, 0.9769, 0.4462, 1.0130, 0.9361,\n",
       "                       1.1435, 1.0755, 0.8172, 1.2160, 1.1708, 0.8326, 1.0605, 1.3565, 1.1408,\n",
       "                       0.9933, 1.1301, 1.0148, 1.1272, 0.9770, 0.5058, 0.8135, 0.6770, 1.1596,\n",
       "                       1.0459, 1.0975, 1.0943, 1.0097, 0.8133, 1.1153, 0.8899, 1.0428, 1.2536,\n",
       "                       0.9832, 0.6203, 0.9139, 0.8731, 0.6918, 1.1260, 0.2733, 1.0130, 1.0926,\n",
       "                       1.0720, 1.1631, 1.1839, 0.5973, 1.1405, 1.1763, 0.9800, 1.0225, 1.0436,\n",
       "                       0.8502, 1.1530, 0.9835, 1.3239, 0.6362, 0.9547, 0.8648, 0.7036, 0.9891,\n",
       "                       0.8956, 0.6684, 1.0972, 0.9076, 0.6384, 0.8603, 1.0418, 0.8226, 0.9889,\n",
       "                       0.4692, 0.4991, 0.8975, 0.8536, 1.2099, 0.9635, 1.1211, 1.0741, 1.1748,\n",
       "                       1.0328, 0.9639, 0.8464, 0.9222, 0.8646, 0.9812, 1.0259, 0.9026, 1.0985,\n",
       "                       1.3200, 1.3520, 0.8091, 0.8493, 1.0194, 0.5287, 0.9658, 0.9977, 0.9788,\n",
       "                       1.3655, 0.4898, 0.7785, 0.9938, 0.4714, 0.3356, 0.9735, 0.8762, 0.8690,\n",
       "                       1.3053, 0.7439, 0.7643, 0.6878, 1.0019, 1.0641, 1.0696, 1.1539, 1.1049,\n",
       "                       0.8718, 1.3012, 0.9538, 0.9531, 0.5643, 1.0746, 0.9723, 0.8656, 1.3475,\n",
       "                       0.9380, 0.8953, 1.3727, 0.4535, 1.1457, 0.6542, 1.0409, 1.0981, 0.9023,\n",
       "                       1.1144, 1.0815, 1.2134, 0.8978, 0.9925, 0.8624, 1.0421, 1.3380, 1.1504,\n",
       "                       0.9870, 0.4670, 1.0330, 1.1302, 1.1419, 1.2744, 1.2785, 1.2513, 1.0941,\n",
       "                       1.1802, 1.2290, 1.3752, 0.9396, 0.9662, 0.9707, 1.0778, 0.3860, 0.9183,\n",
       "                       1.1586, 0.8619, 0.6188, 1.1147, 1.3675, 1.0019, 1.1476, 1.0775, 1.0792,\n",
       "                       1.1930, 0.9706, 0.9071, 0.9174, 0.9868, 0.7037, 0.7321, 0.8768, 1.0496,\n",
       "                       0.9915, 1.0660, 0.8966, 0.9964, 0.8852, 1.2159, 1.1580, 0.7111, 0.4730,\n",
       "                       1.0353, 1.0192, 0.8928, 1.2706, 1.4263, 0.9980, 0.3532, 0.4918, 0.9829,\n",
       "                       0.7474, 1.0839, 0.5446, 1.0956, 1.0380, 1.0943, 1.0517, 0.7094, 1.0557,\n",
       "                       0.6625, 1.1248, 1.0023, 1.5281, 1.3572, 1.0759, 0.7746, 1.2011, 1.1546,\n",
       "                       0.5964, 0.9852, 0.8495, 0.9046, 0.9232, 1.2807, 0.5028, 0.9053, 1.1093,\n",
       "                       1.2315, 1.0267, 1.0194, 1.2623, 0.9689, 1.0482, 1.0786, 0.8586, 0.4864,\n",
       "                       1.2161, 1.0685, 1.0953, 0.9853, 0.8778, 1.0397, 1.2730, 0.9377, 1.2230,\n",
       "                       0.9753, 1.0981, 0.5209, 0.9376, 0.6086, 0.4151, 0.7702, 0.9797, 1.2388,\n",
       "                       1.0349, 0.9509, 0.8632, 1.2876, 1.6126, 1.1258, 0.4149, 1.0089, 1.0519,\n",
       "                       0.8221, 1.2245, 1.0256, 1.0461, 0.9651, 0.8645, 1.0192, 1.0774, 1.0158,\n",
       "                       1.1035, 0.9729, 1.2657, 1.1162, 1.0492, 0.8497, 1.1300, 1.0705, 0.9149,\n",
       "                       0.5904, 0.9442, 1.1462, 0.9009, 1.3760, 0.4095, 1.0837, 1.2117, 0.5813,\n",
       "                       1.1220, 1.3137, 0.5588, 1.1104, 0.7647, 0.8270, 1.7138, 1.0442, 0.9528,\n",
       "                       1.1511, 0.8160, 1.0942, 1.2062, 1.0723, 0.9839, 1.4398, 1.0917, 1.1048,\n",
       "                       1.0294, 1.0739, 1.1939, 1.0529, 1.0129, 1.0052, 1.4338, 1.0208, 0.9004,\n",
       "                       1.1145, 0.8237, 1.2433, 0.9026, 1.0068, 1.1364, 0.9539, 0.7693, 1.0401,\n",
       "                       1.3652, 0.4287, 1.0163, 0.9942, 1.1042, 0.4577, 0.9942, 0.9551, 0.9146,\n",
       "                       1.0011, 1.1516, 0.9862, 0.7260, 1.1630, 1.0532, 0.9281, 0.9433, 0.6011,\n",
       "                       0.6257, 1.1354, 0.9504, 0.9805, 0.9760, 0.9792, 0.4477, 0.7953, 0.9629,\n",
       "                       0.8023, 1.1022, 1.1797, 0.8836, 1.0323, 0.5699, 1.0605, 1.1273, 1.0621,\n",
       "                       0.7290, 0.9571, 0.8671, 0.6478, 0.3853, 0.9439, 0.8821, 0.8617, 0.4659,\n",
       "                       1.0389, 0.3590, 1.1582, 0.9726, 1.0988, 1.0964, 0.8692, 1.2900, 0.8554,\n",
       "                       1.1174, 0.9015, 0.9937, 1.2691, 0.9923, 0.9630, 1.0504, 0.7922, 0.5388,\n",
       "                       1.0412, 1.0914, 0.9493, 1.1033, 0.9571, 0.9168, 0.9361, 1.1429, 0.4560,\n",
       "                       1.0962, 1.0570, 0.6944, 1.0913, 1.0084, 0.9310, 0.8042, 0.9676, 1.1645,\n",
       "                       1.0108, 0.9704, 0.8509, 0.8505, 0.9832, 0.9930, 1.0751, 0.9806, 1.0307,\n",
       "                       1.1843, 1.0450, 0.8979, 0.8262, 0.7724, 0.8858, 0.9827, 1.0757, 1.1863,\n",
       "                       0.9124, 0.8604, 1.0140, 1.1726, 0.8133, 0.9450, 0.7757, 0.9359, 0.8902,\n",
       "                       0.4347, 0.8054, 0.9967, 0.8918, 1.1201, 0.8330, 1.3714, 0.6347, 0.6996,\n",
       "                       0.9285, 0.9511, 1.2236, 1.0164, 0.8717, 1.0107, 1.2076, 0.9399, 1.1091,\n",
       "                       0.9706, 1.1365, 1.0346, 1.1798, 1.2603, 1.0090, 0.9313, 0.8644, 1.0968,\n",
       "                       0.7437, 1.1048, 1.1171, 0.9892, 0.9939, 1.4142, 1.0721, 1.1209, 1.0621,\n",
       "                       1.1425, 0.8798, 1.1274, 0.9831, 1.0430, 0.9428, 0.3956, 0.9816, 1.0278,\n",
       "                       0.9393, 0.9891, 1.3775, 1.0050, 0.8539, 0.9556, 1.1961, 1.1283, 1.0901,\n",
       "                       0.9547, 1.0527, 1.6421, 1.0322, 1.0283, 0.7542, 0.9550, 1.1278, 0.9013,\n",
       "                       1.0847, 1.1320, 0.8843, 1.1033, 1.0025, 1.0018, 1.0766, 0.2731, 1.0976,\n",
       "                       1.3175, 1.2517, 1.0063, 1.2144, 1.1150, 0.8921, 0.4834, 0.4870],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.bias',\n",
       "               tensor([-0.9268, -0.6266, -0.5309, -0.6357, -0.5046, -1.1536, -0.5173, -1.4939,\n",
       "                       -0.7832, -1.5075, -0.6342, -0.5730, -1.1893, -1.1652, -0.7942, -1.0887,\n",
       "                       -1.3104, -1.3070, -0.8438, -1.5253, -0.9678, -1.0071, -0.9260, -0.5962,\n",
       "                       -1.2304, -0.2258, -0.6201, -0.8741, -0.9973, -0.2882, -1.0181, -0.0473,\n",
       "                       -1.2342, -0.8188, -0.9273, -1.0032, -1.1131, -0.5810, -0.9244, -0.8191,\n",
       "                       -0.4738, -0.7664, -0.1053, -1.1785, -1.2238, -1.2519, -1.0774, -1.7462,\n",
       "                       -1.2521, -1.0098, -1.3732, -1.0013, -0.9384, -0.9089, -0.7262, -1.2270,\n",
       "                       -1.0483, -1.5191, -0.4390, -1.0361, -0.8670, -0.8597, -1.4813, -0.6777,\n",
       "                       -0.4823, -1.1131, -0.8683, -0.1681, -0.6160, -1.1000, -0.6691, -0.6610,\n",
       "                        0.1074, -0.4299, -0.8592, -0.8151, -1.7040, -1.0895, -0.9872, -1.5288,\n",
       "                       -1.1496, -0.6807, -0.8016, -0.7891, -0.9479, -0.6210, -1.0759, -1.1950,\n",
       "                       -0.9956, -1.2665, -1.5158, -1.7583, -0.7382, -0.5999, -0.9451, -0.5500,\n",
       "                       -1.0278, -0.6882, -1.0760, -1.4877, -0.7106, -0.9699, -1.1468, -0.5725,\n",
       "                       -0.2269, -1.4250, -0.7481, -0.9016, -1.3545, -0.4090, -0.5920, -0.7844,\n",
       "                       -1.2422, -1.0947, -1.3283, -1.2184, -1.1426, -0.8193, -1.3204, -0.8605,\n",
       "                       -0.7378, -0.5170, -1.3469, -1.0916, -0.9371, -1.4747, -1.0785, -1.3800,\n",
       "                       -1.3396, -0.4237, -1.3274, -0.8327, -0.8605, -1.2755, -0.9883, -1.0643,\n",
       "                       -1.1332, -1.2407, -1.0683, -0.9353, -0.8443, -1.0549, -1.1899, -1.0002,\n",
       "                       -1.4368, -0.4605, -0.8931, -1.3795, -1.1537, -1.2295, -1.5573, -1.3294,\n",
       "                       -1.2111, -1.4382, -1.0037, -1.4445, -0.7545, -1.1937, -1.0555, -0.8604,\n",
       "                       -0.3483, -0.8547, -1.4832, -0.9992, -0.6245, -1.1271, -1.8393, -0.8570,\n",
       "                       -1.1873, -0.9002, -1.1650, -1.4616, -1.0966, -1.0338, -0.8798, -1.0539,\n",
       "                       -0.5295, -0.5991, -0.5281, -1.1401, -1.3800, -1.1607, -1.0025, -0.7102,\n",
       "                       -0.9779, -1.1512, -1.1975, -0.7246, -0.4748, -0.9941, -0.7571, -0.8653,\n",
       "                       -1.4647, -1.8294, -0.6385, -0.2421, -0.4240, -0.7561, -0.7323, -1.0429,\n",
       "                       -0.5567, -0.7589, -0.8982, -1.1422, -1.3670, -0.8966, -0.7570, -0.8501,\n",
       "                       -1.4752, -1.3566, -1.5417, -1.3120, -1.4789, -0.8098, -1.1903, -1.1919,\n",
       "                       -0.5641, -1.0068, -0.6368, -1.1082, -0.6602, -1.2209, -0.5706, -0.8450,\n",
       "                       -1.4457, -1.1181, -0.5517, -1.0157, -1.0188, -1.3320, -1.1227, -0.8480,\n",
       "                       -0.9637, -0.3996, -1.1952, -1.4615, -1.0471, -0.8518, -1.3566, -1.1436,\n",
       "                       -1.2017, -0.7486, -1.5245, -0.9609, -1.2642, -0.4812, -1.1266, -0.8732,\n",
       "                       -0.4258, -0.7096, -0.8881, -1.1568, -1.1495, -1.0584, -0.5065, -2.0450,\n",
       "                       -1.8439, -1.0001, -0.4478, -1.3064, -1.2587, -0.7340, -0.7342, -0.9460,\n",
       "                       -1.0269, -0.9412, -0.7271, -0.9116, -0.7955, -1.3599, -1.3335, -1.3596,\n",
       "                       -2.0832, -1.4160, -0.9864, -0.7417, -0.7941, -1.4409, -0.8184, -0.5528,\n",
       "                       -0.7167, -1.1789, -0.8158, -1.4325, -0.2628, -1.1581, -1.9050, -0.4080,\n",
       "                       -1.2944, -1.1235, -0.6202, -1.1652, -0.9671, -1.1774, -1.8213, -0.8847,\n",
       "                       -0.6611, -1.5906, -0.7409, -1.0386, -1.0712, -1.1633, -1.0001, -1.3512,\n",
       "                       -0.9485, -1.2225, -1.0768, -1.1959, -1.0779, -1.0752, -1.1522, -0.9081,\n",
       "                       -1.0947, -0.8541, -0.9721, -1.3169, -0.8332, -1.1959, -0.8614, -1.2096,\n",
       "                       -1.2910, -1.3517, -0.7324, -0.7874, -1.2204, -0.3987, -1.2808, -1.0477,\n",
       "                       -1.0734, -0.4106, -0.8290, -0.8418, -1.1694, -1.0074, -1.2381, -1.2645,\n",
       "                       -0.4686, -0.9527, -0.7772, -0.9946, -0.5623, -0.7630, -0.8910, -1.0892,\n",
       "                       -0.8300, -0.9807, -0.9775, -1.3635, -0.4377, -0.6563, -1.3178, -0.7624,\n",
       "                       -1.1922, -1.3888, -1.3011, -0.8241, -0.6315, -1.0948, -1.0740, -1.1862,\n",
       "                       -1.2401, -0.8922, -0.8188, -0.4529, -0.3196, -0.9116, -0.5977, -0.7753,\n",
       "                       -0.3463, -0.9359, -0.2351, -1.1351, -0.8505, -1.2622, -0.8808, -0.8275,\n",
       "                       -1.4604, -0.6374, -0.9875, -0.5543, -0.9385, -1.4324, -1.0252, -0.7666,\n",
       "                       -1.3167, -0.6675, -0.3785, -0.6188, -1.1109, -0.7665, -0.6459, -1.3750,\n",
       "                       -0.9565, -0.8162, -1.1617, -0.2942, -1.1032, -0.9313, -0.6704, -0.9382,\n",
       "                       -1.4996, -0.6677, -0.9241, -0.9116, -1.5874, -1.2366, -0.9990, -0.7313,\n",
       "                       -0.6550, -0.9268, -0.9094, -1.2075, -0.7507, -1.5805, -1.3963, -1.1001,\n",
       "                       -0.8197, -0.6291, -0.5572, -0.6652, -1.0816, -1.0449, -1.2613, -0.6382,\n",
       "                       -0.4380, -1.4386, -1.2137, -0.5551, -1.0229, -0.9086, -0.8036, -0.8823,\n",
       "                       -0.4433, -0.5666, -1.3386, -0.8249, -1.0241, -0.9359, -1.3669, -0.1792,\n",
       "                       -0.4910, -0.6613, -0.6006, -1.2904, -1.2362, -0.9800, -0.7748, -0.8731,\n",
       "                       -0.9160, -1.3455, -0.6145, -1.3676, -0.9559, -0.8511, -1.0169, -1.0877,\n",
       "                       -0.6715, -0.8468, -0.9053, -0.6382, -0.7508, -1.1323, -1.2330, -1.0002,\n",
       "                       -1.0657, -1.0172, -1.3319, -1.0393, -1.2256, -0.7244, -1.3001, -1.1020,\n",
       "                       -1.2895, -0.6108, -0.4768, -1.4196, -1.3897, -0.7835, -1.0923, -1.2570,\n",
       "                       -0.9177, -0.8924, -0.9494, -0.8150, -1.1034, -1.1010, -0.7710, -1.2923,\n",
       "                       -1.7607, -0.8246, -1.0299, -0.7357, -0.8449, -1.3700, -0.9031, -1.1970,\n",
       "                       -1.0119, -0.7387, -1.1051, -1.0061, -1.1059, -0.8715, -0.2503, -0.7411,\n",
       "                       -1.5400, -1.4532, -0.8578, -1.6902, -1.4873, -0.8968, -0.5279, -0.5539],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.running_mean',\n",
       "               tensor([-10.9466,  -4.7064,   0.4896, -13.0394,   1.0596,  -5.1966,   2.5946,\n",
       "                        -6.1204,  -4.9037,  -9.0592,  -4.7538,  -7.4809, -10.2353,  -4.2202,\n",
       "                       -11.6675,  -6.0336,  -7.8942,  -5.2304,  -5.9133,  -4.6640,  -6.5091,\n",
       "                        -8.8374,  -5.8615,  -0.1198,  -3.0118,  -5.2285,   3.0720,  -9.0669,\n",
       "                        -8.2644,  -2.2407, -16.7493,  -3.2580,  -6.2603,  -3.2431,  -8.6461,\n",
       "                        -5.1161,  -6.8665,   1.6716,  -2.8061,  -2.2973,  -6.4704,   0.0351,\n",
       "                         1.7752, -12.2334,  -7.8868,  -4.4822,  -6.7287,  -1.5001,  -1.8367,\n",
       "                        -9.2483,  -5.0554,  -7.2483,  -5.0116,  -2.3397,  -5.7115,  -7.1529,\n",
       "                        -4.5376,  -8.3607,  -3.2629,  -4.0760,  -8.0348,  -4.2006,  -6.1257,\n",
       "                        -3.2869,  -1.5678,  -5.3736,  -4.9567,  -0.0239,  -8.7057,  -6.1706,\n",
       "                        -9.4158,  -1.2394,  -0.2976,   2.0511,  -2.4322,  -7.2357,  -5.7281,\n",
       "                        -3.8909,  -6.6181,  -6.5762,  -6.2335,  -7.7848,  -3.6213,  -4.4694,\n",
       "                        -6.5564,  -1.7735,  -6.3409,  -3.5482,  -4.7265,  -9.7434,  -5.2787,\n",
       "                        -4.4089,  -8.5867,  -8.9784,  -8.3622,  -1.1242,  -1.6125,  -6.1353,\n",
       "                        -1.8334,  -6.4470,   1.9517,  -4.0501,  -7.9616,  -0.0614,   1.8526,\n",
       "                        -8.1184,  -7.6924,  -3.5090, -13.9613,  -1.8541,  -6.5741,  -1.1032,\n",
       "                        -7.2868,  -5.5170, -13.6198,  -8.7831,  -6.9043,  -9.8543,  -8.1938,\n",
       "                       -10.9025,  -1.5706,   0.2536,  -6.2698,  -4.7969,  -2.5400,  -6.6330,\n",
       "                        -8.2245,  -8.3690,  -3.3294,   1.4847,  -5.6580,  -0.6512,  -2.6138,\n",
       "                        -5.4812,  -8.3086,  -6.6517,  -0.9511,  -6.5308,  -0.4880, -10.0147,\n",
       "                       -10.0530,  -8.8695,  -8.9923,  -9.2739,  -5.5759,   1.4889,  -5.5971,\n",
       "                        -6.5623,  -6.1954,  -6.9607,  -4.3671, -10.0267,  -6.3242,  -1.5743,\n",
       "                        -5.8862,  -8.4250,  -9.6883,  -0.3161,  -6.0573,  -0.9220,   2.8667,\n",
       "                        -3.4738,  -5.6987,  -4.2769,  -1.2995,  -6.1807, -10.4538, -10.6439,\n",
       "                        -6.4368,  -7.6672,  -6.1779,  -6.6622, -12.6275,  -5.0543, -13.3042,\n",
       "                        -9.2222,  -2.8990,  -1.0521, -10.5863, -12.6526,  -5.7583,  -6.1315,\n",
       "                        -4.1107,  -7.5637,  -8.3993,  -3.6659,  -1.5571,  -5.7016,   0.4822,\n",
       "                        -4.1579,  -4.2678,  -3.1378,  -7.7058,  -5.8783,  -6.5717,   1.4404,\n",
       "                         0.1798,  -6.9300,  -2.0510,  -6.2335,   0.7833,  -5.9191,  -9.1841,\n",
       "                        -3.7911,  -7.2584,  -3.9278,  -5.4451,  -1.0859,  -8.4004,  -4.5896,\n",
       "                        -3.7839,  -2.1272,  -0.8305,  -3.9474,  -5.0292,  -4.3324,   1.6887,\n",
       "                        -5.2468,  -9.3235, -12.2824,  -5.9639,  -6.0610,   1.1145,  -4.4179,\n",
       "                        -6.1781,  -7.4969,  -6.3649,  -8.0785,  -5.8291,  -7.1095,   0.0293,\n",
       "                        -7.3850,  -5.0077,  -4.7580,  -2.4646,  -4.9892,  -6.5832,  -8.1314,\n",
       "                        -3.3271,  -6.9148,  -5.1012,  -6.6263,  -6.5491,  -5.4777,  -4.7112,\n",
       "                        -1.7681,  -2.9845,  -0.6280,   0.6161,  -4.8205,  -5.8634,  -3.7613,\n",
       "                       -12.9779,  -4.8706,  -3.6795,  -3.5789,  -7.1662,  -6.3291,   2.0748,\n",
       "                        -6.3364,  -5.2135,  -5.4410,  -3.6490,  -1.8804,  -6.5819,  -6.4984,\n",
       "                       -11.3954,  -9.8010, -11.5818,  -5.1824,  -4.9084,  -6.3417,  -7.3625,\n",
       "                       -11.8305, -11.8492,  -5.2052,  -3.5223,  -1.8082,  -4.9645,  -1.7844,\n",
       "                        -6.9489,  -7.0825,  -2.0701,  -4.3015,   0.9403,  -7.6335,  -8.7052,\n",
       "                        -0.3232,  -8.0548,  -6.3594,   0.0384, -10.3239,  -5.7635,   1.2717,\n",
       "                       -10.4732,  -6.6686,  -1.0650,  -2.5657,  -9.0322,  -6.0299,  -7.6969,\n",
       "                        -8.4339,  -5.6820,  -6.2278,  -6.9537,  -7.1906,  -9.3338,  -3.2026,\n",
       "                        -0.8080,  -8.3156,  -3.4238,  -6.3102,  -6.0365,  -7.9017,  -6.0254,\n",
       "                        -3.1737,  -3.8924,  -1.3887,  -7.4180,  -8.3821,  -6.3889,   0.2771,\n",
       "                       -13.0124,  -7.0043,  -6.5420,   0.5211, -10.5753,  -4.8199,  -8.8597,\n",
       "                         0.7271,  -6.9438,  -5.8706,  -6.6012, -11.7251,  -9.9602,  -3.5897,\n",
       "                        -3.7250,   1.3409,  -6.2583,  -8.7168,  -4.7366,   0.7047,   0.6778,\n",
       "                        -3.3599,  -5.2760,  -7.6540,  -7.4514,  -5.3712,   0.7601,  -9.1521,\n",
       "                        -4.2634,  -8.8234,  -7.7530,  -2.1752,  -6.7177,  -7.7468,   1.3792,\n",
       "                        -7.6447,  -4.8029, -10.1590,   0.7072,  -6.5925,  -4.7821,  -6.2494,\n",
       "                         2.2727,  -4.8053,  -7.1708,  -1.1976,  -0.4371,  -7.4698,   2.2801,\n",
       "                       -10.9002,  -7.5096,  -6.9487,  -6.1443,  -0.9438, -11.0681,  -5.3732,\n",
       "                        -6.2433,  -3.4355,  -7.4783,  -2.8342,  -2.9182,  -2.5896,  -2.3832,\n",
       "                        -3.8353,   1.1935,  -5.2662,  -8.6400,  -2.4046,  -4.8689,  -6.6092,\n",
       "                        -0.7686,  -5.4240,  -6.4915,  -0.1485,  -7.4101,  -5.3624,  -3.9568,\n",
       "                        -8.2369,  -6.2680,  -7.4459,  -1.5998, -12.1062,  -6.4252,  -4.5093,\n",
       "                        -9.1467,  -1.7616,  -4.1337,  -7.5233, -11.9482,  -9.0477,  -0.1674,\n",
       "                        -6.2516,  -5.3855, -13.4576,  -7.5187,  -8.5937,  -8.9846,  -7.8837,\n",
       "                        -7.2620,  -8.1858, -10.8179,   0.6603,  -8.9839,  -6.2542, -10.4111,\n",
       "                        -7.0609,  -5.5050,  -0.5491,  -4.2341,  -4.2832,   1.9065,  -6.6364,\n",
       "                        -9.1535,  -7.1616,  -5.9491,  -4.5903,  -6.4505,  -3.0236,  -6.1423,\n",
       "                        -2.2690,  -3.9202,  -6.1200, -10.3187, -10.1729,  -6.7391,  -7.7427,\n",
       "                        -8.7977, -11.9383,  -5.3453,  -5.8036,  -6.7242,   0.4427,  -9.2209,\n",
       "                        -3.7368,  -4.7518,  -9.7832,  -4.4224,   1.3990,  -2.4374,  -4.9322,\n",
       "                        -3.9685,  -8.2084,  -5.6697,  -4.8616,  -7.2400,  -9.3516,  -6.3486,\n",
       "                        -4.4132,  -8.5907,  -7.9852,  -3.4281,  -7.5983,   0.6316,  -4.0236,\n",
       "                        -4.1680,  -6.6564,  -7.3984,  -5.0515,  -9.8773,  -5.5165,  -3.4083,\n",
       "                        -4.0908,  -5.4502,  -7.5116,  -4.7940,  -6.8727,  -6.4855,  -3.8047,\n",
       "                        -4.6048,   2.2831,  -0.6845,  -9.2537,   2.3546,  -7.3868,  -6.5038,\n",
       "                        -8.1104,  -4.6953,  -6.2870,  -5.7926,  -7.7083,   1.6947,  -6.8570,\n",
       "                        -4.1531,  -4.1234,  -9.3761,  -7.1345,  -5.3935,  -2.3333,   1.9098,\n",
       "                         1.1853], device='cuda:0')),\n",
       "              ('conv_block4.bn1.running_var',\n",
       "               tensor([30.5615, 19.5194,  6.8431, 33.2307,  7.7484, 19.5720,  5.7041, 16.7709,\n",
       "                       20.6506, 32.5822, 12.8072, 25.8494, 28.5697,  9.8946, 38.2908, 12.4467,\n",
       "                       22.7973, 15.6550, 30.3211, 15.4183, 13.8769, 20.1674, 13.4068,  5.2064,\n",
       "                        9.3205, 19.1652, 13.3040, 28.8858, 23.1700, 17.6359, 36.8522, 17.2134,\n",
       "                       22.6639, 14.3213, 17.0298, 16.1659, 17.5653,  5.6243,  8.1378, 23.6647,\n",
       "                       17.6713, 10.8439,  6.3442, 18.7229, 28.5044, 15.1650, 16.8111, 27.2365,\n",
       "                       13.7515, 18.3758, 15.7615, 18.0450, 18.5931, 15.1795, 30.1187, 16.0600,\n",
       "                       18.4562, 15.7618,  6.0597,  9.8101, 25.0701, 10.5290, 20.8149,  8.2874,\n",
       "                       10.5557, 36.5706, 20.3083, 10.9105, 26.9362, 24.1466, 27.5407,  7.9009,\n",
       "                       10.2477,  7.5243,  7.9346, 31.0490, 16.5714, 16.9582, 15.1790, 15.1728,\n",
       "                       11.0975, 17.7968,  9.3774, 17.2617, 18.0170, 11.2026, 10.0479, 21.4738,\n",
       "                       12.8184, 27.9929, 34.9499,  8.7972, 20.2416, 38.6349, 35.8775, 26.6058,\n",
       "                        8.6860, 16.5672,  8.6107,  9.6205,  4.9644, 12.9083, 37.8021,  5.3654,\n",
       "                        4.3570, 33.3336, 28.2035,  9.7090, 34.4627, 10.1998, 32.1513,  6.2575,\n",
       "                       17.9305, 12.3358, 35.8649, 17.6484, 13.4068, 34.7466, 20.6096, 24.9320,\n",
       "                       12.1647,  5.1258, 15.6527, 36.4144, 13.6576, 15.8207, 12.5088, 21.6173,\n",
       "                       13.0574,  5.9408, 17.3958,  8.3152,  6.9040, 11.4219, 22.0784, 15.1430,\n",
       "                       15.8226, 26.2072, 13.5272, 31.2710, 25.6707, 19.4369, 19.3787, 27.3696,\n",
       "                       16.0319,  5.6787, 22.4620, 22.5795, 10.0631, 19.1722, 10.5147, 28.1664,\n",
       "                       12.4213, 25.4380, 12.6300, 23.6269, 41.7899, 11.3836, 18.0569,  8.7249,\n",
       "                        8.8377,  7.6490, 19.9988, 36.8825,  8.3112, 10.9120, 29.6565, 20.1334,\n",
       "                       13.5106, 28.7123, 16.1448, 27.9076, 31.5709, 19.4292, 30.4554, 25.3627,\n",
       "                       10.2696, 13.9052, 40.8040, 32.9910, 15.3921, 17.6103, 13.1719, 29.6313,\n",
       "                       18.9846, 22.1142, 12.7236, 18.7990,  5.8783, 13.0427, 12.2896,  5.8145,\n",
       "                       23.3267, 19.1351, 14.7191,  8.4226,  4.0103, 14.8062, 13.1337, 12.5089,\n",
       "                        5.3677, 21.5225, 24.8644, 17.3675, 13.8637, 14.5169, 15.1201,  6.6010,\n",
       "                       18.9283, 18.7039, 15.5907, 11.7995, 15.9959,  7.8538, 13.7008, 10.5229,\n",
       "                        4.6169, 13.7895, 36.4701, 28.8091, 16.2106, 11.9121,  4.6951, 12.1054,\n",
       "                       11.0117, 34.8793, 11.1683, 17.6856, 20.5549, 19.9955,  8.9615, 20.1625,\n",
       "                        9.6848, 19.9802, 14.8742, 17.6910, 19.3254, 24.4685, 21.4280, 29.3899,\n",
       "                       15.4179, 10.9351, 24.2829,  9.6252, 12.0946,  5.1307, 13.8964,  7.6012,\n",
       "                        6.3450, 14.6780, 14.1869, 24.8011, 26.2712, 22.6321, 14.2291, 18.8901,\n",
       "                       17.4181, 16.2870,  5.9781, 14.9376, 11.4820, 22.6166, 19.5444, 14.1481,\n",
       "                       14.4549, 16.9543, 19.7434, 27.3365, 32.2359, 20.6217, 26.1336, 24.1979,\n",
       "                       10.0762, 37.4724, 41.0546, 13.7372, 14.8969, 14.4313, 13.2454,  5.9549,\n",
       "                       14.9837, 19.6615, 10.9641, 12.4789,  4.1697, 20.6397, 20.3398,  4.9947,\n",
       "                       18.0992, 15.6661,  6.3609, 21.8676, 10.3437,  7.0835, 31.1422, 18.8504,\n",
       "                       12.8874, 12.5800, 25.5613, 21.8090, 15.6999, 21.7496, 22.0028, 15.8032,\n",
       "                       14.4817, 13.5646, 36.0756, 19.3523, 14.9007, 20.0335,  8.7787, 20.0837,\n",
       "                       17.5363, 12.9350, 13.9228, 12.1984,  7.4850, 18.1529, 15.2906, 15.3669,\n",
       "                       15.1041, 10.5410, 34.7928, 16.7722, 37.1760,  5.0407, 41.1197, 15.3174,\n",
       "                       27.7526,  2.9424, 16.8891, 20.1124, 14.4424, 34.8773, 22.7271, 20.1915,\n",
       "                        9.4582, 13.8497, 14.3264, 23.0631, 10.5649,  4.2221,  6.9832,  8.8682,\n",
       "                       18.3566, 20.9455, 20.9889, 22.7778,  7.7765, 26.7661,  7.1429, 13.2231,\n",
       "                       21.4396, 12.0353, 22.3188, 13.8094,  8.5693, 17.9074, 11.7283, 24.9059,\n",
       "                        8.4410, 11.4587, 16.0788, 37.7887,  6.3968, 15.5928, 10.7083,  7.3945,\n",
       "                        7.8200, 13.3485,  3.1345, 23.7982, 25.3734, 10.9349, 13.1362, 13.6335,\n",
       "                       24.6937, 23.0011, 18.5087, 23.0593, 15.7291, 13.5202, 15.2368, 10.1596,\n",
       "                       13.8289,  8.0219,  6.9101, 17.6363, 23.8544, 13.7632, 21.9881, 19.5875,\n",
       "                        7.7525, 13.8248, 12.9938,  5.0650, 14.1804, 29.8344, 12.4386, 20.9369,\n",
       "                        9.7813, 22.8497,  6.1871, 34.4481, 28.4984, 15.5763, 32.3126, 27.9873,\n",
       "                       28.5361, 21.9034, 29.6870, 19.2119, 15.0388, 12.2173, 16.7385, 36.1602,\n",
       "                       24.9092, 24.9316, 30.5120, 24.6249, 19.2227, 11.0939, 26.7466,  6.8273,\n",
       "                       12.3371, 20.9441, 39.4448, 14.4986, 11.7440,  6.7282, 15.6753, 23.5683,\n",
       "                        5.7090, 18.3468, 18.0073, 23.0290, 16.6334, 19.7900, 15.3393, 21.3345,\n",
       "                       11.5967, 10.6765, 24.2350, 16.5404, 35.5970, 35.3758, 10.5018, 15.7377,\n",
       "                       24.5646, 25.9001, 15.3133, 19.3552, 21.6175,  9.0542, 22.2412, 15.1988,\n",
       "                        6.7641, 17.1693, 23.0440,  5.8231,  6.8925, 10.3310, 16.7413, 15.4752,\n",
       "                       15.6510, 16.4781, 20.7925, 35.9258, 13.2031, 10.9192, 23.5391, 19.5459,\n",
       "                       17.7848, 12.5372,  3.6360, 11.2511, 10.7330, 14.0641,  9.4343, 13.3173,\n",
       "                       31.3042, 20.5273, 27.5875, 12.0333, 20.2981, 13.8537, 11.4676, 14.6925,\n",
       "                       16.4561, 14.0791, 15.1365,  6.3850,  7.7605, 27.7311, 18.7079, 18.9606,\n",
       "                       37.4239, 24.0474, 12.9374, 19.4589, 20.7373, 21.8877,  7.4155, 18.6823,\n",
       "                       22.3549, 14.1555, 25.8358, 15.2212, 22.2576,  8.2511,  6.0334,  4.6805],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn1.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('conv_block4.bn2.weight',\n",
       "               tensor([0.8692, 1.0196, 0.9362, 0.9131, 1.0375, 1.0444, 1.0132, 1.0092, 1.0608,\n",
       "                       1.0743, 1.0304, 1.1891, 1.0405, 1.0412, 1.0269, 0.9653, 1.0626, 1.0576,\n",
       "                       1.0416, 1.0394, 1.0032, 0.9530, 1.0887, 1.1196, 1.2284, 1.1845, 1.2006,\n",
       "                       1.0038, 0.9120, 0.9737, 1.0074, 1.0234, 0.9587, 0.9566, 1.1203, 1.0380,\n",
       "                       1.2199, 1.0974, 1.0536, 0.7612, 0.9293, 1.2127, 1.0957, 1.0487, 1.0060,\n",
       "                       0.9303, 1.1301, 0.9962, 0.9253, 0.9390, 1.0552, 1.0215, 0.6022, 1.1631,\n",
       "                       1.0075, 0.9166, 1.1436, 1.1242, 0.9639, 0.8867, 0.8757, 1.0242, 1.0773,\n",
       "                       1.0337, 1.0872, 0.9788, 0.9669, 0.9332, 0.7769, 1.0834, 1.1052, 1.0670,\n",
       "                       1.2093, 1.0479, 0.8535, 1.0409, 1.0113, 0.8261, 0.9043, 1.0220, 1.0291,\n",
       "                       1.0649, 0.9358, 1.2345, 0.9310, 0.9950, 1.1893, 1.0115, 0.7559, 1.0712,\n",
       "                       1.0209, 0.9954, 0.8501, 1.0186, 1.1557, 0.9994, 0.9954, 1.0819, 1.0597,\n",
       "                       1.0474, 1.0162, 0.9761, 0.9244, 0.9922, 0.9519, 1.1067, 0.9372, 0.9337,\n",
       "                       1.1715, 1.0161, 1.0217, 1.0195, 1.1220, 1.0149, 1.1270, 1.1602, 0.9379,\n",
       "                       1.0706, 1.1358, 1.0445, 0.9419, 1.0347, 0.9873, 1.0045, 0.9723, 1.0441,\n",
       "                       0.8574, 1.0103, 1.0524, 0.9981, 0.9770, 1.0063, 1.0351, 1.0704, 1.0712,\n",
       "                       1.1775, 1.0923, 1.0152, 1.0871, 1.0963, 0.9691, 1.0647, 0.6194, 1.0080,\n",
       "                       1.0311, 1.1069, 0.9379, 1.0183, 1.0397, 0.9723, 1.0926, 0.9570, 1.1201,\n",
       "                       0.6124, 1.0335, 1.0131, 1.0401, 1.0126, 0.9381, 1.0591, 1.0451, 0.6448,\n",
       "                       1.2713, 0.8568, 1.0401, 0.9968, 0.9266, 0.9932, 1.0042, 1.0146, 0.9523,\n",
       "                       1.0785, 1.0504, 1.0440, 0.8292, 1.0258, 0.8946, 1.0836, 0.9695, 1.1255,\n",
       "                       1.0539, 1.0798, 1.0433, 0.9571, 1.0015, 1.0899, 0.9283, 1.0606, 0.9519,\n",
       "                       0.7614, 0.7617, 0.9541, 1.1838, 0.9471, 1.0733, 1.1440, 1.0788, 1.0504,\n",
       "                       0.9725, 0.7654, 1.0277, 0.7071, 0.9312, 1.0306, 1.0887, 1.1121, 0.9629,\n",
       "                       1.0552, 1.0747, 1.1719, 0.8791, 1.0809, 1.0920, 0.8258, 1.0560, 0.9856,\n",
       "                       1.0623, 0.8904, 0.9770, 0.9496, 1.1909, 0.8231, 0.9825, 0.9999, 1.0781,\n",
       "                       1.0322, 0.9479, 0.6987, 1.0529, 0.9777, 1.0731, 1.0085, 1.0309, 0.9760,\n",
       "                       1.1300, 1.0308, 0.9500, 0.8970, 1.0981, 0.9828, 1.0356, 1.0897, 1.0457,\n",
       "                       1.1373, 1.0823, 1.0683, 1.1204, 1.0674, 1.1082, 1.0366, 1.0477, 0.7976,\n",
       "                       1.0946, 1.0202, 0.9869, 0.9141, 0.9358, 1.0071, 1.0090, 0.9882, 1.2007,\n",
       "                       0.9805, 0.9280, 0.9648, 1.1031, 1.0952, 1.0682, 0.9051, 0.9703, 0.9847,\n",
       "                       1.0507, 1.0302, 1.0373, 1.0126, 1.1133, 0.9373, 1.0751, 1.0259, 0.8999,\n",
       "                       0.9758, 1.0634, 0.9822, 0.9974, 1.1841, 1.0385, 0.9460, 1.0757, 1.0571,\n",
       "                       0.8684, 0.7430, 1.0869, 1.0043, 0.8735, 0.9567, 1.0572, 1.0317, 1.0294,\n",
       "                       1.0523, 1.0352, 1.0453, 1.1801, 1.1518, 1.0357, 1.0031, 1.0059, 1.0505,\n",
       "                       0.8497, 0.8277, 0.7445, 1.0762, 1.0021, 1.1202, 1.0641, 0.9924, 1.1110,\n",
       "                       1.0767, 0.9756, 1.0253, 1.1018, 0.9259, 0.9461, 1.0254, 1.0322, 0.9632,\n",
       "                       1.0843, 0.8916, 0.8301, 1.1465, 0.9954, 0.9512, 0.9322, 0.9779, 0.9065,\n",
       "                       0.9694, 0.5169, 1.1076, 1.0327, 0.9517, 1.1000, 0.9666, 0.9286, 0.9862,\n",
       "                       1.1279, 0.9118, 0.9248, 0.8618, 0.8209, 0.7729, 0.9371, 0.8842, 0.9992,\n",
       "                       1.0429, 1.0914, 0.8012, 1.0192, 1.0117, 1.0623, 1.0231, 1.0377, 1.1539,\n",
       "                       0.8518, 0.6366, 1.0854, 0.9593, 0.9821, 0.8839, 1.2614, 0.9315, 0.8245,\n",
       "                       0.9191, 1.0720, 0.9815, 0.7630, 1.0368, 1.0000, 1.0597, 0.9025, 1.0035,\n",
       "                       1.1145, 0.9382, 1.0012, 0.9382, 0.9492, 1.0129, 0.7285, 1.0805, 0.9569,\n",
       "                       1.0730, 1.0464, 0.8662, 0.5841, 0.9371, 0.7384, 0.9628, 1.1045, 0.9737,\n",
       "                       1.0557, 1.1154, 1.1908, 0.9917, 0.9906, 0.7624, 1.0398, 0.9751, 1.0418,\n",
       "                       1.0149, 0.8918, 0.9710, 0.9319, 0.9814, 0.9381, 0.9196, 1.1777, 1.0211,\n",
       "                       1.0665, 0.9604, 1.0621, 1.0200, 0.8991, 0.9888, 0.8206, 1.0428, 1.0212,\n",
       "                       1.0214, 1.0759, 1.0050, 0.9450, 0.9638, 1.0861, 1.0789, 0.9607, 0.7226,\n",
       "                       0.8935, 1.0180, 0.9566, 1.1027, 0.9531, 0.9753, 1.1532, 1.0002, 0.9920,\n",
       "                       1.0342, 0.9385, 0.8641, 0.9388, 0.9327, 1.0506, 1.0106, 1.0389, 0.9956,\n",
       "                       1.0707, 1.0160, 1.1350, 1.1605, 0.9819, 0.9502, 1.0184, 1.0517, 1.0610,\n",
       "                       1.0803, 0.9218, 0.9971, 1.0046, 1.0675, 0.9909, 1.1060, 0.7715, 1.0106,\n",
       "                       0.9804, 1.0199, 1.0249, 1.0042, 1.0969, 0.8566, 1.0517, 0.6326, 1.0388,\n",
       "                       1.0691, 1.0669, 0.9527, 1.0403, 1.0416, 0.7403, 1.1037, 1.0038, 1.0177,\n",
       "                       0.5930, 0.9599, 1.0896, 0.9358, 0.9490, 0.9979, 1.0591, 0.9622, 0.9875,\n",
       "                       0.9553, 1.0062, 1.0119, 1.1283, 1.0414, 1.0745, 1.0687, 0.8101, 1.0115,\n",
       "                       1.1221, 1.0903, 0.9864, 1.1624, 1.0129, 1.0907, 0.9775, 0.7475],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn2.bias',\n",
       "               tensor([-0.6357, -0.8527, -0.7240, -0.7183, -0.9574, -0.9813, -0.7130, -0.8558,\n",
       "                       -0.8158, -0.8945, -0.7349, -0.9749, -1.0785, -0.7781, -0.8201, -0.7343,\n",
       "                       -1.2163, -0.9349, -0.9170, -0.7448, -0.8741, -0.8969, -1.0082, -0.9573,\n",
       "                       -1.1156, -1.2825, -1.2379, -0.9295, -0.6968, -1.0297, -0.9719, -0.8778,\n",
       "                       -0.6440, -0.7050, -1.0121, -1.0072, -1.1827, -0.8992, -0.8494, -0.6630,\n",
       "                       -0.6907, -1.1151, -0.9045, -1.0034, -0.8512, -0.8988, -1.0106, -0.6670,\n",
       "                       -0.6949, -0.8435, -1.0474, -0.8233, -0.4661, -1.0223, -0.9171, -0.9080,\n",
       "                       -1.1544, -1.0028, -1.1745, -0.8494, -0.5735, -1.0519, -0.8442, -0.8575,\n",
       "                       -1.1057, -0.8953, -0.8886, -0.8457, -0.5678, -1.0093, -0.9063, -0.9730,\n",
       "                       -1.3149, -0.9343, -0.6227, -0.9176, -0.9047, -0.6808, -0.7603, -0.9709,\n",
       "                       -0.9282, -1.0250, -0.7901, -1.1732, -0.9183, -0.8938, -1.0894, -0.7654,\n",
       "                       -0.7095, -1.1964, -0.8708, -0.8142, -0.8661, -0.9949, -1.1258, -0.9737,\n",
       "                       -0.7671, -0.9461, -0.8957, -0.9559, -0.8173, -0.8774, -0.8777, -0.9807,\n",
       "                       -0.6896, -0.9080, -0.7666, -0.7901, -0.9920, -1.0560, -0.9186, -0.8876,\n",
       "                       -0.9487, -0.8476, -0.9140, -1.0839, -0.7586, -1.0032, -1.0627, -0.9870,\n",
       "                       -0.6890, -0.7998, -0.8275, -0.7153, -0.7468, -0.9308, -0.5439, -0.7082,\n",
       "                       -0.9491, -0.8077, -0.7686, -0.8005, -1.1216, -1.0302, -0.8449, -1.2532,\n",
       "                       -1.0404, -0.8978, -0.8028, -1.0356, -0.8640, -0.9739, -0.3478, -0.7908,\n",
       "                       -1.0078, -1.0894, -0.6264, -0.9284, -0.8441, -0.6705, -0.9099, -0.6895,\n",
       "                       -1.0781, -0.4041, -0.9598, -0.9002, -0.8591, -0.8593, -0.9035, -0.9717,\n",
       "                       -0.8061, -0.4209, -1.1186, -0.6594, -0.9079, -0.8793, -0.6905, -0.7890,\n",
       "                       -0.7763, -0.8181, -0.7768, -0.9247, -1.1757, -0.9052, -0.6392, -0.9119,\n",
       "                       -0.8816, -1.1514, -0.6032, -1.1121, -1.0446, -0.9701, -0.9160, -0.7903,\n",
       "                       -0.9031, -0.9186, -0.8806, -0.9007, -0.8075, -0.5293, -0.7690, -0.7966,\n",
       "                       -1.0551, -0.7402, -0.9771, -1.1216, -1.0144, -0.7270, -0.8152, -0.4969,\n",
       "                       -0.9188, -0.5080, -0.6954, -0.8943, -0.9111, -0.9846, -0.7691, -0.7996,\n",
       "                       -0.9310, -0.9318, -0.7881, -1.0120, -1.1179, -0.6427, -0.8588, -0.8852,\n",
       "                       -0.9369, -0.6432, -0.8372, -0.7708, -1.0399, -0.5446, -0.8622, -1.0342,\n",
       "                       -1.0385, -0.9053, -0.7958, -0.5640, -1.0736, -0.7351, -0.9306, -0.7655,\n",
       "                       -0.9475, -0.9423, -1.0223, -0.8780, -0.8575, -0.8953, -1.0348, -0.9474,\n",
       "                       -1.0599, -0.8597, -0.9905, -0.8517, -0.8602, -1.0753, -0.9481, -1.0397,\n",
       "                       -0.9873, -0.9807, -0.9107, -0.8368, -0.9407, -0.9491, -0.9919, -0.6827,\n",
       "                       -1.0033, -0.8495, -0.9439, -0.7659, -0.9812, -0.7008, -0.6716, -0.7872,\n",
       "                       -0.7998, -0.9925, -0.7968, -0.6551, -0.9045, -0.9280, -1.0423, -0.9507,\n",
       "                       -0.8546, -0.7400, -1.2037, -0.9359, -0.8926, -0.8114, -0.8905, -0.9073,\n",
       "                       -0.9369, -0.8521, -0.9964, -0.9729, -0.9072, -0.6744, -0.9125, -0.8992,\n",
       "                       -0.6318, -0.5347, -0.9464, -1.0394, -0.8523, -0.7701, -0.8907, -0.9499,\n",
       "                       -1.0483, -0.9705, -0.9066, -0.9237, -1.2272, -1.3275, -0.8460, -0.7763,\n",
       "                       -0.6645, -0.9437, -0.4811, -0.6286, -0.5974, -0.9572, -0.8808, -0.9409,\n",
       "                       -0.9350, -0.8788, -0.9325, -0.9302, -0.9094, -0.8218, -1.0726, -0.7214,\n",
       "                       -0.9896, -0.8111, -1.0361, -0.7955, -0.7910, -0.7099, -0.6057, -0.9668,\n",
       "                       -0.8110, -0.9454, -0.8162, -0.7066, -0.6406, -0.9381, -0.2838, -1.2096,\n",
       "                       -0.8564, -0.9551, -1.0171, -0.8412, -0.7527, -0.7537, -0.9505, -0.7497,\n",
       "                       -0.8901, -0.6481, -0.7140, -0.4668, -0.8714, -0.9210, -1.0737, -0.9736,\n",
       "                       -0.9253, -0.8462, -0.9520, -0.7971, -1.1652, -0.9690, -0.9288, -0.8844,\n",
       "                       -0.7713, -0.4085, -0.9273, -0.7709, -0.9965, -0.7296, -1.0591, -0.8909,\n",
       "                       -0.6816, -0.7582, -0.8895, -1.0022, -0.4112, -0.9052, -0.8330, -0.7699,\n",
       "                       -0.6271, -0.7419, -0.9814, -0.8401, -0.8756, -0.7851, -0.8853, -0.9722,\n",
       "                       -0.4361, -1.0040, -0.8905, -0.9258, -0.8468, -0.6977, -0.3273, -0.7692,\n",
       "                       -0.5724, -0.7710, -0.9961, -0.9429, -1.0810, -1.0256, -1.0846, -0.8732,\n",
       "                       -0.8395, -0.6623, -0.7299, -0.7672, -1.0518, -0.8442, -0.7411, -1.0576,\n",
       "                       -1.0265, -0.9971, -0.9094, -0.6428, -1.1716, -0.7394, -0.8364, -0.8228,\n",
       "                       -0.9271, -0.7503, -0.7941, -0.9165, -0.6003, -0.7904, -0.8405, -1.0136,\n",
       "                       -0.8585, -0.9383, -0.6179, -0.9837, -1.0112, -0.8642, -0.8000, -0.4619,\n",
       "                       -0.7208, -0.9207, -0.8988, -0.8371, -0.9391, -0.8320, -0.9519, -0.8000,\n",
       "                       -0.8909, -0.9169, -0.8799, -0.7483, -0.7430, -0.9219, -0.8550, -0.8171,\n",
       "                       -0.7724, -0.8056, -0.8571, -0.8749, -1.1316, -1.0753, -1.0479, -0.9392,\n",
       "                       -0.8136, -0.8701, -0.9236, -0.9709, -0.8798, -0.6883, -0.9078, -0.9579,\n",
       "                       -0.9275, -1.1071, -0.5766, -0.9774, -0.8089, -0.9832, -1.1391, -0.9514,\n",
       "                       -0.9571, -0.8613, -0.9184, -0.5020, -1.0454, -0.9861, -0.8187, -0.9366,\n",
       "                       -0.9146, -0.9690, -0.4672, -1.0258, -0.9856, -0.9362, -0.3431, -0.7617,\n",
       "                       -0.8894, -0.7865, -0.8302, -0.9095, -0.8643, -0.8991, -0.9230, -0.7429,\n",
       "                       -0.7601, -0.8827, -1.0443, -0.8199, -0.9924, -0.9508, -0.6007, -0.8046,\n",
       "                       -0.9269, -0.9579, -0.7895, -0.9726, -0.8318, -1.0327, -0.9359, -0.5078],\n",
       "                      device='cuda:0')),\n",
       "              ('conv_block4.bn2.running_mean',\n",
       "               tensor([ -7.0704,  -9.1402,  -7.7512, -11.1341,  -9.7865, -10.2807,  -9.2352,\n",
       "                       -11.5114, -11.2539, -11.2583, -10.6623, -12.7442,  -9.5280, -10.9777,\n",
       "                        -9.3166,  -9.5266, -10.3923,  -9.1503, -11.8856, -12.7874,  -9.3444,\n",
       "                        -8.8380, -11.3720, -10.5587, -14.1978,  -8.0652, -12.6958, -13.7487,\n",
       "                        -5.7113,  -6.2154, -13.2550, -13.7632,  -7.7563,  -8.4884, -15.6846,\n",
       "                       -12.8679, -12.5408, -10.1373, -11.0303,  -8.8317,  -8.6962, -11.2265,\n",
       "                       -13.3940, -12.6671, -10.5173, -11.1147,  -9.7191,  -9.3235, -10.5189,\n",
       "                        -9.2362,  -9.7928, -11.5436,  -5.3139, -11.4657,  -8.1820,  -9.7276,\n",
       "                       -12.8487, -12.4356, -11.3890,  -8.5416,  -7.0600, -12.1388,  -9.2885,\n",
       "                       -10.2390,  -8.3354,  -8.1266,  -7.4188,  -9.0289,  -6.1786, -13.6227,\n",
       "                       -11.5395,  -8.3719, -11.4114,  -9.3470, -10.4304, -11.7534,  -6.6131,\n",
       "                        -6.4860,  -7.7830, -14.2819,  -9.1729,  -9.4956,  -8.8200, -14.3914,\n",
       "                        -9.2733,  -9.3520, -13.5086,  -8.6649,  -7.7513, -12.5135, -13.1946,\n",
       "                       -12.8133,  -7.7209, -10.5792, -14.4326, -11.0646,  -9.8393, -13.3821,\n",
       "                       -10.0047, -10.6789, -11.1940,  -8.6306, -14.4514, -11.5956,  -9.7265,\n",
       "                       -15.0767, -12.2830, -10.7356,  -9.0361,  -6.8977,  -8.7512,  -9.1303,\n",
       "                        -8.6288,  -8.0765, -10.9246, -12.0117, -10.5883,  -8.1081, -12.3401,\n",
       "                       -12.3190, -12.3612, -11.6358,  -8.5028,  -9.4126, -12.0485,  -6.3837,\n",
       "                       -11.4244, -10.0863, -15.5683,  -9.1223, -12.6953, -11.5748,  -8.9412,\n",
       "                       -11.3644,  -8.8625, -12.2167, -11.1881,  -7.3360,  -8.7879, -10.7554,\n",
       "                        -7.0423, -11.7585,  -8.4510,  -9.6842, -10.4855,  -7.7066,  -6.3143,\n",
       "                        -9.5375,  -8.0087,  -9.2176, -12.3142,  -7.4595, -11.3879,  -4.9095,\n",
       "                        -7.0090, -10.2986, -12.8484,  -7.3264, -10.5119, -10.7336, -10.8010,\n",
       "                        -8.6696, -17.8151,  -9.2606,  -9.9283, -11.1807,  -7.9112,  -6.7784,\n",
       "                       -10.9137,  -8.0106,  -6.9620, -11.6688,  -9.5805,  -8.5959,  -9.7636,\n",
       "                        -8.5198, -12.2389,  -9.1478,  -8.1453, -12.4756,  -9.4083,  -7.3629,\n",
       "                       -13.1045,  -9.6270,  -9.6665,  -9.8933,  -7.9381, -10.6922,  -9.2425,\n",
       "                        -7.8954,  -9.3268, -11.8413, -13.3432, -10.3631, -10.5183, -10.0359,\n",
       "                        -9.9202,  -7.8625,  -8.1335,  -8.9402, -11.4192,  -5.9625,  -9.5392,\n",
       "                        -7.0874,  -8.0605,  -9.4473, -11.1855, -12.7950, -10.7949, -12.3419,\n",
       "                        -7.6562, -14.0854, -10.3612,  -9.8623, -10.4224,  -9.1409, -14.9591,\n",
       "                       -11.8854,  -8.6520, -10.1927, -11.4755, -10.1710,  -9.4750,  -7.7925,\n",
       "                       -10.2812, -12.2564,  -7.7537,  -6.6620, -10.8340, -10.4059, -11.9272,\n",
       "                       -11.0039, -12.3004, -10.3599,  -8.9955, -12.5240, -11.8692,  -9.8073,\n",
       "                       -10.7393, -10.6546, -12.2049, -10.8643, -10.2018, -11.6912, -11.3565,\n",
       "                        -9.4278, -12.8465,  -9.0102, -13.0422, -11.7360, -11.8573,  -9.6732,\n",
       "                       -13.5239, -11.4994, -11.8104,  -8.9863,  -9.1722,  -9.2032,  -9.9717,\n",
       "                       -11.1541,  -9.3149, -10.5394,  -9.8313,  -7.8685, -14.3521, -11.8711,\n",
       "                        -8.4968,  -6.1572, -12.4332,  -7.9072,  -9.5356,  -8.9708,  -7.0380,\n",
       "                       -14.7917, -13.4908,  -7.9742, -10.2905, -10.6549,  -9.9388,  -9.2936,\n",
       "                       -13.1623, -11.8600, -10.0409, -10.6516,  -7.1750,  -8.7823,  -9.1282,\n",
       "                       -11.7259, -12.0622,  -8.9568,  -8.7477, -12.5159,  -8.3625,  -9.3127,\n",
       "                       -10.3506,  -8.5225,  -8.0484, -11.9778,  -7.7152, -12.3258, -11.5251,\n",
       "                       -10.6074,  -9.3330, -11.6243,  -7.4509, -12.0330,  -8.5127,  -9.2744,\n",
       "                        -8.0115,  -8.7962, -11.2252,  -7.7782, -10.5103, -10.7580, -14.4433,\n",
       "                       -12.4094, -12.7848, -11.1887, -11.2455,  -8.8453,  -8.7306, -10.3607,\n",
       "                       -10.7794,  -7.5537, -10.0302, -12.2000,  -8.8585, -13.6904, -10.2506,\n",
       "                       -12.8044, -11.9870,  -8.5768, -10.6659, -11.1175,  -5.8667, -11.2665,\n",
       "                        -9.6447, -12.2697,  -7.1850, -11.4209,  -4.9475, -11.3445, -11.0180,\n",
       "                       -10.6976, -12.0633,  -9.4174, -10.2803,  -9.7666,  -8.6389, -12.2479,\n",
       "                        -8.8226, -16.4966, -12.9197, -10.8278, -10.5766,  -8.5228, -10.4537,\n",
       "                       -14.5190, -12.3608, -10.0704,  -7.2365,  -8.9748,  -8.5510, -13.3488,\n",
       "                        -6.3004,  -4.8657,  -9.5620, -11.1047, -10.6984, -12.2717,  -8.1002,\n",
       "                       -12.3814,  -6.1011, -10.1579, -11.3373,  -8.9346,  -7.1032, -10.6421,\n",
       "                        -8.5353,  -8.8176,  -8.6552, -10.7790, -11.1876,  -8.9152,  -8.6046,\n",
       "                       -10.1903, -13.3491, -10.9219, -11.4192,  -8.0122,  -5.0803,  -7.1907,\n",
       "                        -9.2910,  -6.4443, -11.2285, -11.1397, -11.4683,  -9.4067,  -9.7184,\n",
       "                        -8.4264,  -9.8142,  -5.1804, -14.5606, -12.8593, -11.3980,  -9.0743,\n",
       "                       -13.2523,  -9.1607, -11.2102,  -7.6098,  -9.4769,  -9.2939,  -9.0630,\n",
       "                       -10.9464, -12.5919, -11.1671,  -8.9951,  -8.9873, -10.7743,  -9.5763,\n",
       "                        -8.8532,  -6.3426, -11.5980,  -9.5338, -11.9581, -10.1507,  -7.6085,\n",
       "                        -7.8964, -16.3195,  -7.9698, -11.2983,  -6.1035, -10.8961, -14.8799,\n",
       "                        -8.5117,  -9.6699,  -6.9834,  -9.0393, -10.1701, -11.1316, -10.9523,\n",
       "                        -8.6811, -11.9509, -12.3365,  -8.9529,  -8.8247, -11.8243, -13.2038,\n",
       "                       -10.8081,  -7.0179, -11.2472, -10.8153, -11.1608, -14.5949, -10.3344,\n",
       "                        -9.6759, -10.2307,  -9.8480, -15.7847, -10.8683,  -5.9520, -10.4720,\n",
       "                        -8.1118,  -8.9037,  -9.4431, -11.0172, -11.3063, -10.3130, -10.1860,\n",
       "                       -14.6933,  -9.0615, -10.6036, -11.3590,  -8.2459,  -7.5740,  -5.9723,\n",
       "                       -12.3277, -11.0075, -14.9161,  -9.8716,  -8.6900,  -9.5916,  -5.1327,\n",
       "                        -9.1199, -12.2774, -10.8230,  -6.6812,  -8.3982,  -9.7224,  -8.3312,\n",
       "                        -6.6135, -11.8535, -12.5668,  -9.0417,  -7.1228, -10.2076,  -8.1796,\n",
       "                        -8.7434, -15.6028, -10.1699, -12.5138,  -9.8046, -11.9482,  -9.7467,\n",
       "                       -11.5575, -10.9710,  -5.8092, -10.2086, -11.6999, -10.3494, -15.2646,\n",
       "                        -7.8103], device='cuda:0')),\n",
       "              ('conv_block4.bn2.running_var',\n",
       "               tensor([119.5330, 111.5851, 105.8014, 194.3960, 145.1584, 151.1561, 170.7872,\n",
       "                       168.1288, 169.7325, 246.5773, 183.6257, 201.1760,  90.3726, 235.3835,\n",
       "                       136.1833, 151.5590, 101.7934,  94.6865, 159.6302, 232.4375,  98.5792,\n",
       "                        93.2172, 166.5209, 154.0410, 183.5350,  73.4258, 103.5562, 228.6407,\n",
       "                        65.5826,  34.5725, 184.1561, 244.0851, 165.4411, 139.0002, 209.6452,\n",
       "                       160.1482, 166.1909, 149.4473, 197.4758,  98.0435, 122.8118, 115.8345,\n",
       "                       191.0247, 147.4830, 144.7492, 102.1568, 111.2490, 178.6992, 177.2030,\n",
       "                        91.5468,  92.0047, 178.1482, 100.3087, 138.4312,  77.9875,  88.8078,\n",
       "                       142.7540, 176.0923,  75.0477, 113.5099, 117.4905,  93.1809, 104.7753,\n",
       "                       177.5880,  54.8149, 112.3250,  53.3386, 124.4382,  84.0634, 165.6850,\n",
       "                       164.8729, 100.4674, 109.0026, 107.4236, 151.6819, 193.3995,  55.3059,\n",
       "                       106.1447,  84.0162, 209.6905, 126.8873, 106.6894, 127.1495, 166.2238,\n",
       "                        64.3243, 171.6260, 167.2073, 121.4679,  67.4339, 137.6332, 173.0528,\n",
       "                       252.8767, 100.0092, 127.1863, 139.5112,  84.4245, 186.3425, 247.4683,\n",
       "                       146.9553, 155.3842, 137.5345,  75.3665, 207.3246, 126.8592, 214.1089,\n",
       "                       209.7989, 148.8357, 182.2472, 100.6449,  49.5003, 100.7825,  93.1085,\n",
       "                        71.4692,  83.5189, 136.7704, 158.8071, 147.4560,  93.2384, 131.4757,\n",
       "                       137.1293, 202.9832, 152.5964, 108.1116, 216.2217, 239.0280,  76.2350,\n",
       "                       140.5914, 153.3451, 260.5764, 172.4119, 169.4218, 197.7206,  80.6323,\n",
       "                       101.7465, 104.0214, 106.3632, 113.2930,  57.2918, 113.4499, 126.2890,\n",
       "                        72.6041, 137.7473, 211.8665,  87.2345,  82.5531,  80.0018, 108.3961,\n",
       "                        97.3852, 104.7040, 240.5546, 190.8302, 114.5864, 130.0359,  90.7443,\n",
       "                        64.4102, 139.4491, 165.0707,  84.4786,  95.4657, 101.3506, 175.5658,\n",
       "                       131.7360, 281.9009, 146.9190, 150.1954, 161.3970, 109.4073,  95.7615,\n",
       "                       182.3277,  96.4348,  73.4839, 115.9752,  99.4877, 137.9911, 166.9402,\n",
       "                        91.8582, 125.5850,  95.9300, 185.0470, 132.8921,  63.0050,  94.5155,\n",
       "                       174.8960, 150.6762,  76.0643, 121.6214,  64.4462, 157.4700, 121.1129,\n",
       "                       109.1967,  90.4049, 124.2251, 240.2950, 145.4362, 115.4441,  83.2565,\n",
       "                        92.3168, 167.5009,  89.1367, 160.1980, 179.0705, 108.8378, 124.8380,\n",
       "                        62.1686,  86.0124, 159.5369, 188.2807, 239.6436, 194.1266, 152.7062,\n",
       "                        91.3488, 181.7483, 103.0574, 125.0780, 102.0396,  76.1436, 230.8262,\n",
       "                       159.3068, 131.1642, 183.1092, 154.2262, 284.9601, 109.3947,  50.4844,\n",
       "                        77.8616, 153.9754,  98.7566, 124.5419,  93.7722, 167.6795, 185.0094,\n",
       "                       200.0618, 179.7574,  87.7052,  76.7539, 136.9572, 161.2445,  76.2044,\n",
       "                       123.4741,  98.5624, 123.3278, 201.6077, 105.0393, 207.5891, 177.8371,\n",
       "                        79.6234, 183.8452,  76.3404, 190.6858, 128.7299, 186.1456,  79.0408,\n",
       "                       194.2552, 167.2675, 143.1439, 208.0128,  93.1392, 134.3249,  97.7061,\n",
       "                       131.9269, 134.8008, 234.3669, 289.1217,  83.8410, 243.2776, 166.5899,\n",
       "                       138.5753,  93.8360, 135.3104, 102.1121, 130.6812,  88.0845,  87.4273,\n",
       "                       354.1793, 120.9376,  49.8033, 108.2608, 191.9858,  83.2218, 124.6435,\n",
       "                       198.9207, 151.3005, 114.5484, 187.6745,  80.2599, 128.1988, 115.1032,\n",
       "                       290.1814, 238.4541, 149.8992, 125.2472, 111.4082,  72.5357, 121.9289,\n",
       "                       138.8316, 105.3264,  81.6092, 150.1974,  96.3888, 165.7158, 101.1007,\n",
       "                        66.8240, 127.8578, 161.8440, 107.5237, 163.1043, 186.2200, 122.2260,\n",
       "                       129.0678,  98.6127, 102.1676,  73.6693, 138.8832, 144.4659, 208.6830,\n",
       "                       176.8513, 120.0968, 162.8605, 143.4462, 162.6996,  69.2330, 128.3018,\n",
       "                       133.2198, 112.4777, 174.3360, 258.6885, 207.6651, 204.3252, 165.8202,\n",
       "                       132.7782, 156.4254, 125.7472, 294.2368, 126.8540, 155.4616,  79.2299,\n",
       "                       123.1838, 105.4637,  66.7107, 156.1684,  70.9858, 182.2789, 158.8055,\n",
       "                       186.7225, 146.6785, 152.9809,  99.1145, 168.4443,  83.2520, 137.6243,\n",
       "                        68.5944, 237.3921, 201.5072, 105.9986, 118.1479, 134.5408,  87.5844,\n",
       "                       242.6606, 172.6103, 138.2726,  75.9145, 133.1461,  86.2201, 310.4858,\n",
       "                        45.1279,  77.7772, 123.9231, 114.0875, 139.8184, 162.8016, 140.3397,\n",
       "                        96.5330, 167.8691, 138.7544, 171.2143, 135.1889, 125.9986, 175.9455,\n",
       "                        81.4727,  89.3942,  81.5546, 122.4892, 134.6115,  83.5224,  94.3160,\n",
       "                       121.9861, 168.8695, 144.2761, 198.3965,  89.1466, 237.1340,  98.3379,\n",
       "                       186.9334,  59.1445, 144.5183, 105.5614, 113.5008, 122.7501, 101.8751,\n",
       "                        83.4345, 160.4523,  88.1170, 319.9019, 152.8835, 123.0919,  91.8793,\n",
       "                       199.7066,  96.4695,  98.2488,  60.2616,  92.5484, 172.1201,  80.0252,\n",
       "                       211.5920, 169.3102, 206.1817, 120.4552, 144.4899, 123.4716,  79.5671,\n",
       "                       113.1695,  83.3126, 222.6195,  83.9858, 176.4949, 132.8481, 148.8628,\n",
       "                        52.2881, 246.3003,  96.7397, 203.4213, 119.4787, 223.7660, 277.8627,\n",
       "                       124.3682, 131.0021,  59.6992, 108.7543, 137.5425, 206.7273, 142.7591,\n",
       "                        88.6648, 104.4339, 207.0668, 119.0594,  67.7863, 203.4793, 217.6955,\n",
       "                       184.5082,  83.2572, 108.5184, 182.4813, 112.8087, 159.0301, 109.1860,\n",
       "                        99.9105, 148.3253, 132.4963, 237.3271, 184.7216,  54.4456, 222.5535,\n",
       "                        95.5209,  95.9788,  83.0696, 104.1740, 256.7545, 112.8713, 214.7532,\n",
       "                       224.7012,  56.6445,  99.2389, 126.1396,  78.9249,  87.1820,  76.5859,\n",
       "                       144.2391, 131.5220, 268.1415,  70.4655, 139.8484,  78.6657,  99.4189,\n",
       "                       124.7197, 115.7797,  92.5335, 174.9718, 168.3002, 117.1443, 112.4444,\n",
       "                        84.0920, 159.9541, 203.4507,  80.1847,  81.9829, 186.1985, 118.6786,\n",
       "                       106.9935, 172.8516, 150.0677, 230.2883, 186.6628, 200.1913, 131.3280,\n",
       "                       185.2038, 122.9916, 113.0203, 149.2874, 144.6691, 110.0487, 158.8798,\n",
       "                       158.9126], device='cuda:0')),\n",
       "              ('conv_block4.bn2.num_batches_tracked',\n",
       "               tensor(440000, device='cuda:0')),\n",
       "              ('fc1.weight',\n",
       "               tensor([[-0.0162,  0.2051,  0.1045,  ..., -0.0675,  0.0420,  0.0474],\n",
       "                       [-0.1089, -0.0935, -0.1332,  ...,  0.1064,  0.1283,  0.1095],\n",
       "                       [-0.0769,  0.1070, -0.0794,  ..., -0.1325, -0.1202, -0.0031],\n",
       "                       ...,\n",
       "                       [-0.2049,  0.0241, -0.2252,  ..., -0.5683,  0.1057,  0.0919],\n",
       "                       [-0.1168, -0.1704,  0.0327,  ..., -0.0705, -0.1603,  0.0641],\n",
       "                       [ 0.0408, -0.0130, -0.0847,  ..., -0.0846,  0.0335,  0.0355]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc1.bias',\n",
       "               tensor([ 0.5390,  0.5386,  0.0718, -0.2857,  0.0245, -0.0327,  0.7104,  0.5407,\n",
       "                       -0.0533, -0.3832, -0.0618,  0.0038,  0.7356, -0.0791, -0.0786,  0.4660,\n",
       "                       -0.0875,  0.3958,  0.8654,  0.0343,  1.0210,  0.1983,  0.5465,  0.6340,\n",
       "                       -0.2606, -0.1079,  0.5308,  0.7250,  0.8561,  0.0458, -0.0163,  1.4613,\n",
       "                        0.1459,  0.5657,  0.0974, -0.3957,  0.4825,  0.0538, -0.2921,  0.6931,\n",
       "                        0.3894,  0.0033,  0.6783, -0.0054, -0.4779, -0.1824,  0.5314, -0.4128,\n",
       "                        0.3976,  0.6597, -0.3526,  0.4103,  0.6220, -0.0259, -0.2060,  0.2368,\n",
       "                       -0.0545,  0.0995,  0.1890,  0.7222, -0.0065,  0.9948,  0.0051, -0.0179,\n",
       "                       -0.2542, -0.0503,  0.2423,  0.0585,  0.7288, -0.2077,  1.3685, -0.0125,\n",
       "                        0.0168,  0.5329,  0.5047, -0.3545,  0.8285,  0.9625,  0.4309,  0.0344,\n",
       "                        0.6676, -0.1120, -0.0795,  0.2257, -0.1322,  0.7685, -0.2873, -0.1637,\n",
       "                        0.7472, -0.2636, -0.6023,  0.1480, -0.2895,  0.3800,  0.3542,  0.0336,\n",
       "                       -0.1534, -0.0077, -0.2535,  0.7723,  0.7742,  0.0843,  0.4135,  0.5900,\n",
       "                        0.7188,  0.5165,  0.5607,  1.4848, -0.2240,  0.7909, -0.0338,  0.8326,\n",
       "                        0.0656,  0.0045,  0.2118, -0.0539,  0.0855,  0.6208,  0.0530, -0.1141,\n",
       "                        0.2065,  0.2361,  1.0296,  0.0438,  0.4333,  0.3641, -0.0523,  0.7411,\n",
       "                        0.6331,  0.6274,  0.6925, -1.2867,  0.8086,  0.0173, -0.1901, -0.3369,\n",
       "                       -0.0032,  0.1064,  0.5409,  0.0720,  0.2645, -0.0785,  0.0313, -0.2220,\n",
       "                        0.2901,  0.5120, -0.0407,  0.4435, -0.4844,  0.0249,  0.7821,  0.6862,\n",
       "                       -0.7986, -0.0193,  0.8213,  1.0957, -0.3831,  0.6909, -0.0031, -0.0315,\n",
       "                        0.3736,  0.5035, -0.3834,  0.0250, -0.4908,  0.6797,  0.2503,  0.0392,\n",
       "                        0.0334,  0.0328,  0.7076,  0.6202,  0.6192, -0.0043,  0.5458, -0.2643,\n",
       "                       -0.7342, -0.0907,  0.7569,  0.0824,  0.0046, -0.1082,  0.0774, -0.0584,\n",
       "                       -0.0353,  0.0615,  0.5795, -0.2930,  0.6952,  0.2286,  0.4080,  0.6492,\n",
       "                       -0.1935,  0.8778,  0.5847,  0.0619,  0.7006,  1.0230,  0.6471,  0.6449,\n",
       "                        0.0760,  0.0229, -0.0660,  0.1966,  0.0250,  0.9624, -1.0504,  0.0090,\n",
       "                        0.5280,  0.8886, -0.3967,  0.3304,  0.3099, -0.0214,  1.0731,  0.7956,\n",
       "                        0.8134,  0.2016,  0.6136, -0.2428,  0.1177,  0.4334,  0.0131,  0.8510,\n",
       "                        0.0610,  0.7948,  0.5155, -0.0663,  0.4911, -0.8763,  0.8510,  0.7228,\n",
       "                        0.8229, -0.0220,  0.0983,  0.0610,  0.6902,  0.1753,  0.7661,  0.0874,\n",
       "                       -0.0046,  0.4422,  0.0411,  1.0061, -0.2448,  0.2282,  0.4859, -0.0152,\n",
       "                       -0.8320,  0.3044,  0.3033,  0.2701,  0.6300,  0.2581,  0.9366, -0.3989,\n",
       "                       -0.0423, -0.0848,  0.7038,  0.3513,  0.8420, -0.0679,  0.0851,  0.1601,\n",
       "                        0.8619,  0.9919, -0.0899,  0.6976, -0.0237,  1.0497,  0.4629, -0.0838,\n",
       "                        0.8751,  0.1089,  0.0120,  0.4143, -0.0554,  0.4155,  0.1813,  0.3214,\n",
       "                       -0.0190,  0.9575, -0.6662,  0.0173,  0.8417,  1.0557,  0.6580,  1.0432,\n",
       "                        0.1036,  0.5181, -0.3942,  0.4714, -0.6981,  0.5184,  0.0654,  0.5405,\n",
       "                        0.5567,  0.0060, -0.0396, -0.5671,  0.0902,  0.5639, -0.6331,  0.1842,\n",
       "                        0.0451, -0.1490, -0.2121,  0.8105,  0.0405,  0.0342,  0.5684,  0.3533,\n",
       "                        0.0036,  0.4902,  0.1283,  0.4577, -0.0264, -0.2958,  0.6845,  1.0332,\n",
       "                        0.6011,  0.6495,  0.8831,  0.0350,  0.7828,  0.9590, -0.0278,  0.9186,\n",
       "                        0.6269, -0.0297,  0.1410,  0.7537,  0.0240,  0.0256,  0.4615,  0.7308,\n",
       "                        0.1071, -0.9078,  0.1964,  0.4996,  0.5870, -0.0044, -0.1103,  0.1263,\n",
       "                        1.8711,  0.6102,  0.1896,  0.5381, -0.6056,  0.0078,  0.6531, -0.2677,\n",
       "                        0.0208,  0.5778,  0.0198,  0.2121,  0.0217,  0.1653, -0.0612,  0.0035,\n",
       "                       -1.0666, -0.0879, -0.0541, -0.1329,  0.6626,  0.7638,  0.2922,  0.0853,\n",
       "                        0.5237,  0.2026, -0.0352, -0.1551,  0.0853,  0.6013,  0.9664, -0.2932,\n",
       "                       -0.0207,  0.1017,  0.3746,  0.6826, -0.0119,  0.5998,  0.0069,  0.7347,\n",
       "                        0.3851, -0.0292, -0.6627,  0.7156,  0.9222,  0.1129,  0.8253, -0.0920,\n",
       "                        1.9585,  0.2107,  0.7375,  0.6403,  0.0144,  0.0324, -0.0371,  1.0825,\n",
       "                        0.1428,  0.7617,  0.2419,  0.3425,  0.7588, -0.0280,  0.8388,  0.0687,\n",
       "                        0.6463,  0.2129,  1.0098, -0.0627,  0.7320,  0.6724, -0.5646,  0.6478,\n",
       "                        0.9435,  0.7642, -0.5676, -0.0020,  0.4888,  0.5415,  0.0286, -0.0444,\n",
       "                        0.3874,  1.0348,  0.8692, -0.1861, -0.4097, -0.4449, -0.0587,  0.1921,\n",
       "                        0.1430,  0.1148, -0.0817,  0.2384,  0.1298,  0.5131,  0.4706,  0.2027,\n",
       "                        0.5833,  0.4381,  0.6469,  0.8394,  0.4661,  0.2742,  0.0402,  0.5458,\n",
       "                        0.0116,  0.1196,  0.9895, -0.3875,  0.7393, -0.0311,  0.3565,  0.0899,\n",
       "                       -0.0582,  0.3803, -0.0535,  0.4975,  0.3216, -0.4744,  0.2178,  0.6991,\n",
       "                       -0.1516,  0.1003,  0.6228,  0.1111,  0.7130,  0.8505,  0.5158,  0.7247,\n",
       "                        0.3823, -0.0385,  0.8897, -0.0693,  0.1624,  0.7634,  0.7517,  0.0310,\n",
       "                       -0.1659, -0.0226,  0.1614, -0.0026,  0.5967,  0.6866, -0.0344, -0.0937,\n",
       "                        0.9474,  0.6435,  0.5628, -0.1668,  0.1525,  0.6969,  0.5165, -0.0336,\n",
       "                        0.9038,  0.1055,  0.7125,  0.6618,  0.8524,  0.0132, -0.0358,  0.5847,\n",
       "                        0.5924,  0.0588,  0.0119, -0.1043, -0.5310,  0.3961,  0.5049,  0.0200],\n",
       "                      device='cuda:0')),\n",
       "              ('fc_audioset.weight',\n",
       "               tensor([[-0.0073,  0.0060, -0.0283,  ...,  0.1203,  0.0217,  0.0070],\n",
       "                       [-0.0506, -0.0685, -0.0697,  ..., -0.4943, -0.0545, -0.0633],\n",
       "                       [-0.0703,  0.0848, -0.0423,  ..., -0.3457, -0.1200, -0.0484],\n",
       "                       ...,\n",
       "                       [-0.2180,  0.1204, -0.0582,  ..., -0.4413, -0.1044,  0.0347],\n",
       "                       [-0.1677, -0.0202,  0.0103,  ..., -0.2483, -0.0535,  0.0531],\n",
       "                       [ 0.0720, -0.0735, -0.0046,  ..., -0.1864, -0.0848, -0.0013]],\n",
       "                      device='cuda:0')),\n",
       "              ('fc_audioset.bias',\n",
       "               tensor([-0.3537, -0.2475, -0.4678, -0.3557, -0.2614, -0.1378, -0.2048, -0.1257,\n",
       "                       -0.1749, -0.2945, -0.3129, -0.2637, -0.1914, -0.1700, -0.3302, -0.1657,\n",
       "                       -0.2608, -0.2377, -0.1867, -0.2388, -0.1955, -0.2924, -0.2105, -0.3577,\n",
       "                       -0.2468, -0.1999, -0.1309, -0.5515, -0.3622, -0.1173, -0.2123, -0.1828,\n",
       "                       -0.2515, -0.1763, -0.3372, -0.1570, -0.0807, -0.1679, -0.2259, -0.1356,\n",
       "                       -0.1636, -0.2332, -0.1912, -0.0908, -0.1744, -0.2277, -0.3101, -0.2606,\n",
       "                       -0.3547, -0.3004, -0.1540, -0.2947, -0.3089, -0.2579, -0.2052, -0.2061,\n",
       "                       -0.1698, -0.1022, -0.1111, -0.3086, -0.1498, -0.2120, -0.1458, -0.1753,\n",
       "                       -0.2398, -0.3907, -0.2612, -0.0982, -0.1615, -0.3293, -0.1837, -0.1444,\n",
       "                       -0.3892, -0.4273, -0.3540, -0.3073, -0.4383, -0.1952, -0.2886, -0.3588,\n",
       "                       -0.3360, -0.2398, -0.1421, -0.1347, -0.3262, -0.1405, -0.4570, -0.2578,\n",
       "                       -0.1269, -0.1527, -0.4155, -0.2492, -0.1334, -0.4670, -0.1903, -0.2552,\n",
       "                       -0.2842, -0.2360, -0.4018, -0.2526, -0.2655, -0.2518, -0.2827, -0.3671,\n",
       "                       -0.3984, -0.3830, -0.3744, -0.3047, -0.1646, -0.1996, -0.2509, -0.3250,\n",
       "                       -0.5594, -0.5244, -0.1877, -0.2838, -0.2151, -0.1936, -0.2393, -0.1575,\n",
       "                       -0.1752, -0.2057, -0.2905, -0.1186, -0.2225, -0.1959, -0.4943, -0.1772,\n",
       "                       -0.2159, -0.3115, -0.3668, -0.3608, -0.2743, -0.3169, -0.1906, -0.2425,\n",
       "                       -0.3258, -0.0824, -0.3836, -0.4122, -0.4331, -0.2660, -0.2795, -0.3327,\n",
       "                       -0.1466, -0.2250, -0.2795, -0.3054, -0.1550, -0.1840, -0.1815, -0.1592,\n",
       "                       -0.4298, -0.4890, -0.2363, -0.1592, -0.1590, -0.2616, -0.3309, -0.3767,\n",
       "                       -0.2094, -0.3770, -0.3146, -0.2613, -0.3801, -0.3506, -0.3313, -0.2533,\n",
       "                       -0.2320, -0.2512, -0.1647, -0.3419, -0.2479, -0.1421, -0.1017, -0.2116,\n",
       "                       -0.1598, -0.1726, -0.2312, -0.3537, -0.3291, -0.2786, -0.1483, -0.1008,\n",
       "                       -0.4618, -0.2376, -0.2810, -0.3911, -0.2135, -0.4936, -0.2967, -0.1877,\n",
       "                       -0.2395, -0.4240, -0.3124, -0.2018, -0.1087, -0.1425, -0.1351, -0.1676,\n",
       "                       -0.1632, -0.1270, -0.2043, -0.2486, -0.1300, -0.2162, -0.1435, -0.2751,\n",
       "                       -0.3062, -0.1338, -0.0713, -0.0956, -0.1972, -0.1580, -0.0643, -0.1403,\n",
       "                       -0.4107, -0.2211, -0.1588, -0.4987, -0.2738, -0.2291, -0.2731, -0.2987,\n",
       "                       -0.1822, -0.1467, -0.2558, -0.1972, -0.2504, -0.4129, -0.1368, -0.2726,\n",
       "                       -0.3382, -0.4004, -0.2259, -0.2899, -0.4035, -0.3396, -0.1842, -0.3142,\n",
       "                       -0.3869, -0.1684, -0.2231, -0.2617, -0.2228, -0.3131, -0.1719, -0.2044,\n",
       "                       -0.2608, -0.1847, -0.2231, -0.5349, -0.2338, -0.2676, -0.2062, -0.1604,\n",
       "                       -0.2111, -0.3981, -0.5671, -0.2596, -0.2773, -0.2150, -0.1242, -0.1820,\n",
       "                       -0.2427, -0.2429, -0.3614, -0.4391, -0.2054, -0.3485, -0.4412, -0.1954,\n",
       "                       -0.0835, -0.4123, -0.5304, -0.1837, -0.2821, -0.2137, -0.4026, -0.4592,\n",
       "                       -0.2952, -0.1925, -0.1274, -0.4139, -0.2321, -0.2406, -0.1972, -0.1861,\n",
       "                       -0.3665, -0.2442, -0.3615, -0.2871, -0.2453, -0.1878, -0.3397, -0.3027,\n",
       "                       -0.2172, -0.4743, -0.3484, -0.3001, -0.2101, -0.2944, -0.3144, -0.1834,\n",
       "                       -0.2437, -0.2355, -0.3975, -0.3203, -0.1148, -0.2099, -0.2535, -0.2963,\n",
       "                       -0.1439, -0.2473, -0.1720, -0.1529, -0.5164, -0.2371, -0.1876, -0.1773,\n",
       "                       -0.1149, -0.2334, -0.2916, -0.2899, -0.2943, -0.2745, -0.1975, -0.2519,\n",
       "                       -0.4191, -0.3885, -0.2116, -0.2630, -0.3070, -0.2339, -0.4336, -0.3425,\n",
       "                       -0.2274, -0.2695, -0.2546, -0.2056, -0.3684, -0.2268, -0.1964, -0.3175,\n",
       "                       -0.1842, -0.1835, -0.1965, -0.2230, -0.1884, -0.2829, -0.1854, -0.3985,\n",
       "                       -0.1619, -0.1548, -0.3096, -0.1665, -0.4278, -0.2216, -0.2344, -0.2738,\n",
       "                       -0.2025, -0.1480, -0.1634, -0.1746, -0.4287, -0.2180, -0.1856, -0.3711,\n",
       "                       -0.2545, -0.3254, -0.2575, -0.3963, -0.2103, -0.2107, -0.3120, -0.2376,\n",
       "                       -0.2510, -0.4727, -0.1735, -0.1642, -0.1472, -0.1427, -0.1937, -0.1302,\n",
       "                       -0.2861, -0.2194, -0.1853, -0.1560, -0.1799, -0.2459, -0.2076, -0.4442,\n",
       "                       -0.2122, -0.1669, -0.1696, -0.1358, -0.3067, -0.1089, -0.2226, -0.2297,\n",
       "                       -0.1976, -0.1133, -0.1483, -0.1591, -0.2220, -0.2332, -0.2406, -0.2138,\n",
       "                       -0.2284, -0.2109, -0.1738, -0.2394, -0.2299, -0.2842, -0.1720, -0.1865,\n",
       "                       -0.3023, -0.2254, -0.3218, -0.4740, -0.4103, -0.1863, -0.2450, -0.3028,\n",
       "                       -0.4664, -0.2292, -0.2503, -0.3617, -0.2133, -0.0949, -0.2192, -0.1527,\n",
       "                       -0.1928, -0.2296, -0.2942, -0.3051, -0.1859, -0.4133, -0.2166, -0.3207,\n",
       "                       -0.2160, -0.2232, -0.3179, -0.1327, -0.2912, -0.1611, -0.1601, -0.3654,\n",
       "                       -0.1933, -0.2057, -0.3190, -0.1902, -0.2419, -0.1603, -0.2589, -0.1674,\n",
       "                       -0.2111, -0.1031, -0.2695, -0.4614, -0.2496, -0.2255, -0.3635, -0.4138,\n",
       "                       -0.2433, -0.1642, -0.3051, -0.1986, -0.1814, -0.1407, -0.1998, -0.2335,\n",
       "                       -0.1610, -0.2577, -0.2172, -0.3175, -0.2816, -0.2251, -0.2851, -0.1637,\n",
       "                       -0.1873, -0.3904, -0.3235, -0.3839, -0.1854, -0.1589, -0.1304, -0.2944,\n",
       "                       -0.2398, -0.2792, -0.2389, -0.0767, -0.2468, -0.1448, -0.2242, -0.2961,\n",
       "                       -0.2477, -0.2238, -0.1844, -0.4480, -0.2059, -0.2270, -0.2432, -0.3335,\n",
       "                       -0.3057, -0.2527, -0.8537, -0.7422, -0.2719, -0.7250, -0.8501, -0.1985,\n",
       "                       -0.2027, -0.2493, -0.2233, -0.3995, -0.1986, -0.2389, -0.1356, -0.1837,\n",
       "                       -0.2550, -0.2296, -0.2841, -0.2581, -0.2493, -0.0848, -0.2910],\n",
       "                      device='cuda:0'))])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85049d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Transfer_Cnn14(freeze_base=True,pretrain_checkpoint=\"/home/hj20/dcase_2020_T6/models/Cnn14_mAP=0.431.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d589a10",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'named_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5422d96beabf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model parameter 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'name:{name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'param.shape:{param.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'named_parameters'"
     ]
    }
   ],
   "source": [
    "#model parameter 확인\n",
    "for name, param in cnn.named_parameters(): \n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str = 'Hello world, Python!'\n",
    "if str.startswith('Hello'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6db15c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5aab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer , fc 풀기 3개 \n",
    "for name, param in cnn.named_parameters():\n",
    "    if name.startswith('base.conv_block6'):\n",
    "        param.requires_grad=True\n",
    "    \n",
    "    elif name.startswith('base.conv_block5'):\n",
    "        param.requires_grad=True\n",
    "    \n",
    "    elif name.startswith('base.conv_block4'):\n",
    "        param.requires_grad=True\n",
    "    \n",
    "    elif name.startswith('base.fc'):\n",
    "        param.requires_grad=True\n",
    "    else:\n",
    "        param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923a85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de9a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1274d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_base=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70808b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerDecoder,TransformerDecoderLayer\n",
    "\n",
    "from hparams import hparams as hp\n",
    "from encoder import Cnn10, Cnn14,Transfer_Cnn14,init_layer\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, batch_size, dropout=0.5,pretrain_cnn=None,\n",
    "                 pretrain_emb=None,freeze_cnn=True):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.model_type = 'cnn14+transformer'\n",
    "        decoder_layers = TransformerDecoderLayer(d_model=nhid, nhead=nhead, dropout=dropout)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layers, nlayers)\n",
    "        self.word_emb = nn.Embedding(ntoken, nhid)\n",
    "        self.ninp = ninp\n",
    "        self.nhid = nhid\n",
    "        self.fc = nn.Linear(2048, 2048, bias=True)\n",
    "        self.fc1 = nn.Linear(2048, nhid, bias=True)\n",
    "        self.dec_fc = nn.Linear(nhid, ntoken)\n",
    "        self.batch_size = batch_size\n",
    "        self.ntoken = ntoken\n",
    "\n",
    "        #def __init__(self, freeze_base, pretrain_checkpoint=None):\n",
    "        pretrain_cnn=\"/home/hj20/dcase_2020_T6/models/Cnn14_mAP=0.431.pth\"\n",
    "        \n",
    "        #self.encoder = Transfer_ResNet54(freeze_base=freeze_cnn, pretrain_checkpoint=pretrain_cnn)\n",
    "        self.encoder = Cnn10()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pos_encoder = PositionalEncoding(nhid, dropout)\n",
    "        self.generator = nn.Softmax(dim=-1)\n",
    "        self.init_weights()\n",
    "\n",
    "        '''\n",
    "        if pretrain_cnn is not None:\n",
    "            dict_trained = pretrain_cnn\n",
    "            dict_new = self.encoder.state_dict().copy()\n",
    "            new_list = list(self.encoder.state_dict().keys())\n",
    "            trained_list = list(dict_trained.keys())\n",
    "            for i in range(len(new_list)):\n",
    "                dict_new[new_list[i]] = dict_trained[trained_list[i]]\n",
    "            self.encoder.load_state_dict(dict_new)\n",
    "        \n",
    "        if freeze_cnn:\n",
    "            self.freeze_cnn()\n",
    "        '''\n",
    "\n",
    "        if pretrain_emb is not None:\n",
    "            self.word_emb.weight.data = pretrain_emb\n",
    "\n",
    "    '''\n",
    "    def freeze_cnn(self):\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "    '''\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc)\n",
    "        self.word_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.dec_fc.bias.data.zero_()\n",
    "        self.dec_fc.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def encode(self, src, input_mask=None):\n",
    "        global x \n",
    "        x = self.encoder(src)  # (batch_size, 2048, T/16, mel_bins/16) ,mixup\n",
    "        x = torch.mean(x, dim=3)  # (batch_size, 2048, T/16)\n",
    "        x = x.permute(2, 0, 1)  # (T/16,batch_size,2048)\n",
    "        x = F.relu_(self.fc(x))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "    def decode(self, mem, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # tgt:(batch_size,T_out)\n",
    "        # mem:(T_mem,batch_size,nhid)\n",
    "\n",
    "        tgt = tgt.transpose(0, 1)  # (T_out,batch_size)\n",
    "        if target_mask is None or target_mask.size(0) != len(tgt):\n",
    "            device = tgt.device\n",
    "            target_mask = self.generate_square_subsequent_mask(len(tgt)).to(device)\n",
    "\n",
    "        tgt = self.dropout(self.word_emb(tgt)) * math.sqrt(self.nhid)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        # mem = self.pos_encoder(mem)\n",
    "        output = self.transformer_decoder(tgt, mem, memory_mask=input_mask, tgt_mask=target_mask,\n",
    "                                          tgt_key_padding_mask=target_padding_mask)\n",
    "        output = self.dec_fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, src, tgt, input_mask=None, target_mask=None, target_padding_mask=None):\n",
    "        # src:(batch_size,T_in,feature_dim)\n",
    "        # tgt:(batch_size,T_out)\n",
    "        mem = self.encode(src)\n",
    "        output = self.decode(mem, tgt, input_mask=input_mask, target_mask=target_mask,\n",
    "                             target_padding_mask=target_padding_mask)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e0614a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fea5803d990>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "from data_handling import get_clotho_loader, get_test_data_loader\n",
    "#from model import TransformerModel  # , RNNModel, RNNModelSmall\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "from util import get_file_list, get_padding, print_hparams, greedy_decode, \\\n",
    "    calculate_bleu, calculate_spider, LabelSmoothingLoss, beam_search, align_word_embedding, gen_str\n",
    "from hparams import hparams\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "\n",
    "hp = hparams()\n",
    "parser = argparse.ArgumentParser(description='hparams for model')\n",
    "\n",
    "device = torch.device('cuda')\n",
    "np.random.seed(hp.seed)\n",
    "torch.manual_seed(hp.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3166e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_emb = align_word_embedding(hp.word_dict_pickle_path, hp.pretrain_emb_path, hp.ntoken,\n",
    "                                        hp.nhid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0242a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "476ccfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(hp.ntoken, hp.ninp, hp.nhead, hp.nhid, hp.nlayers, hp.batch_size, dropout=0.2,\n",
    "                             pretrain_cnn=\"/home/hj20/dcase_2020_T6/models/Cnn14_mAP=0.431.pth\", pretrain_emb=pretrain_emb, freeze_cnn=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3e6cadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_emb): Embedding(4371, 192)\n",
       "  (fc): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (fc1): Linear(in_features=2048, out_features=192, bias=True)\n",
       "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
       "  (encoder): Transfer_Cnn14(\n",
       "    (base): Cnn14(\n",
       "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv_block1): ConvBlock(\n",
       "        (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block2): ConvBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block3): ConvBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block4): ConvBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block5): ConvBlock(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_block6): ConvBlock(\n",
       "        (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (fc_audioset): Linear(in_features=2048, out_features=527, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (generator): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14ee54d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:transformer_decoder.layers.0.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.0.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.self_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.in_proj_bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([576])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.multihead_attn.out_proj.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.linear2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:transformer_decoder.layers.1.norm3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:word_emb.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371, 192])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:dec_fc.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([4371])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.bn0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.bn0.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 1, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.conv_block1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.0.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.0.downsample.1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64, 64, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 64, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer1.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128, 128, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([128])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 128, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer2.3.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.3.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.4.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256, 256, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([256])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024, 256, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer3.5.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([1024])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 1024, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.0.downsample.2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 2048, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.1.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:False\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 2048, 1, 1])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512, 512, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([512])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.conv3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 512, 1, 1])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn3.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.resnet.layer4.2.bn3.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.conv1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.conv2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.conv_block_after1.bn2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc_audioset.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([527, 2048])\n",
      "param.requries_grad:True\n",
      "=====\n",
      "name:encoder.base.fc_audioset.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:torch.Size([527])\n",
      "param.requries_grad:True\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "#model parameter 확인\n",
    "for name, param in model.named_parameters(): \n",
    "    print(f'name:{name}') \n",
    "    print(type(param)) \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3255704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swa\n",
    "from torchcontrib.optim import SWA\n",
    "import torchcontrib\n",
    "\n",
    "base_opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=hp.lr, weight_decay=1e-6)\n",
    "optimizer = torchcontrib.optim.SWA(base_opt, swa_start=10, swa_freq=5, swa_lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, hp.scheduler_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b5da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swa 안할때\n",
    "optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=hp.lr, weight_decay=1e-6)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, hp.scheduler_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1809dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = hp.data_dir\n",
    "eval_data_dir = hp.eval_data_dir\n",
    "train_data_dir = hp.train_data_dir\n",
    "word_dict_pickle_path = hp.word_dict_pickle_path\n",
    "word_freq_pickle_path = hp.word_freq_pickle_path\n",
    "test_data_dir = hp.test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4fa72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixup\n",
    "#data_dir = hp.data_dir\n",
    "#eval_data_dir = hp.eval_data_dir\n",
    "#train_data_dir = hp.train_data_dir\n",
    "word_dict_pickle_path = hp.word_dict_pickle_path\n",
    "word_freq_pickle_path = hp.word_freq_pickle_path\n",
    "#test_data_dir = hp.test_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cc2cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = get_clotho_loader(data_dir=data_dir, split='development',\n",
    "                                      input_field_name='features',\n",
    "                                      output_field_name='words_ind',\n",
    "                                      load_into_memory=False,\n",
    "                                      batch_size=hp.batch_size,\n",
    "                                      nb_t_steps_pad='max',\n",
    "                                      num_workers=4, return_reference=True, augment=hp.spec_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29c2b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3051 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3051 [00:00<?, ?it/s]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전체 데이터 \n",
    "from tqdm import tqdm\n",
    "tqdm(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2304b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24420,\n",
       " 24739,\n",
       " 1,\n",
       " 718,\n",
       " 4808,\n",
       " 46,\n",
       " 16,\n",
       " 13138,\n",
       " 17,\n",
       " 24420,\n",
       " 45,\n",
       " 28,\n",
       " 71,\n",
       " 329,\n",
       " 873,\n",
       " 5,\n",
       " 7333,\n",
       " 12184,\n",
       " 768,\n",
       " 1,\n",
       " 97,\n",
       " 149,\n",
       " 45,\n",
       " 168,\n",
       " 132,\n",
       " 555,\n",
       " 1,\n",
       " 49,\n",
       " 3225,\n",
       " 1,\n",
       " 241,\n",
       " 1844,\n",
       " 9147,\n",
       " 81,\n",
       " 1,\n",
       " 991,\n",
       " 455,\n",
       " 14,\n",
       " 7,\n",
       " 3,\n",
       " 330,\n",
       " 1935,\n",
       " 36,\n",
       " 12,\n",
       " 62,\n",
       " 2,\n",
       " 3654,\n",
       " 258,\n",
       " 90,\n",
       " 84,\n",
       " 79,\n",
       " 2134,\n",
       " 1,\n",
       " 5,\n",
       " 75,\n",
       " 4060,\n",
       " 1703,\n",
       " 40,\n",
       " 2369,\n",
       " 468,\n",
       " 67,\n",
       " 630,\n",
       " 2,\n",
       " 114,\n",
       " 15,\n",
       " 5,\n",
       " 2986,\n",
       " 1905,\n",
       " 52,\n",
       " 481,\n",
       " 2,\n",
       " 5,\n",
       " 315,\n",
       " 3003,\n",
       " 121,\n",
       " 811,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 31,\n",
       " 2541,\n",
       " 15,\n",
       " 13,\n",
       " 172,\n",
       " 502,\n",
       " 567,\n",
       " 301,\n",
       " 844,\n",
       " 1,\n",
       " 2748,\n",
       " 2229,\n",
       " 28,\n",
       " 60,\n",
       " 133,\n",
       " 2,\n",
       " 423,\n",
       " 262,\n",
       " 88,\n",
       " 52,\n",
       " 1,\n",
       " 806,\n",
       " 282,\n",
       " 22,\n",
       " 211,\n",
       " 41,\n",
       " 759,\n",
       " 447,\n",
       " 338,\n",
       " 142,\n",
       " 454,\n",
       " 2337,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 22,\n",
       " 1,\n",
       " 129,\n",
       " 23,\n",
       " 268,\n",
       " 809,\n",
       " 692,\n",
       " 630,\n",
       " 417,\n",
       " 3,\n",
       " 148,\n",
       " 20,\n",
       " 55,\n",
       " 91,\n",
       " 38,\n",
       " 241,\n",
       " 2309,\n",
       " 783,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 52,\n",
       " 2,\n",
       " 134,\n",
       " 428,\n",
       " 107,\n",
       " 25,\n",
       " 1,\n",
       " 461,\n",
       " 11,\n",
       " 129,\n",
       " 36,\n",
       " 87,\n",
       " 492,\n",
       " 508,\n",
       " 7,\n",
       " 16,\n",
       " 28,\n",
       " 61,\n",
       " 27,\n",
       " 397,\n",
       " 40,\n",
       " 15,\n",
       " 25,\n",
       " 117,\n",
       " 22,\n",
       " 77,\n",
       " 873,\n",
       " 68,\n",
       " 21,\n",
       " 5,\n",
       " 1,\n",
       " 10,\n",
       " 44,\n",
       " 298,\n",
       " 428,\n",
       " 29,\n",
       " 103,\n",
       " 1259,\n",
       " 128,\n",
       " 1404,\n",
       " 1,\n",
       " 1149,\n",
       " 271,\n",
       " 1,\n",
       " 1,\n",
       " 274,\n",
       " 123,\n",
       " 59,\n",
       " 933,\n",
       " 404,\n",
       " 650,\n",
       " 446,\n",
       " 18,\n",
       " 600,\n",
       " 120,\n",
       " 1608,\n",
       " 11,\n",
       " 372,\n",
       " 209,\n",
       " 2,\n",
       " 900,\n",
       " 97,\n",
       " 46,\n",
       " 240,\n",
       " 60,\n",
       " 57,\n",
       " 9,\n",
       " 31,\n",
       " 175,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 526,\n",
       " 260,\n",
       " 44,\n",
       " 35,\n",
       " 319,\n",
       " 446,\n",
       " 87,\n",
       " 17,\n",
       " 5,\n",
       " 1,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 26,\n",
       " 15,\n",
       " 13,\n",
       " 1,\n",
       " 46,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 398,\n",
       " 8,\n",
       " 27,\n",
       " 6,\n",
       " 2,\n",
       " 10,\n",
       " 94,\n",
       " 241,\n",
       " 125,\n",
       " 2,\n",
       " 44,\n",
       " 77,\n",
       " 13,\n",
       " 29,\n",
       " 13,\n",
       " 538,\n",
       " 524,\n",
       " 410,\n",
       " 293,\n",
       " 209,\n",
       " 164,\n",
       " 107,\n",
       " 142,\n",
       " 137,\n",
       " 679,\n",
       " 104,\n",
       " 708,\n",
       " 323,\n",
       " 903,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 22,\n",
       " 32,\n",
       " 23,\n",
       " 3,\n",
       " 3,\n",
       " 298,\n",
       " 91,\n",
       " 1,\n",
       " 173,\n",
       " 9,\n",
       " 18,\n",
       " 115,\n",
       " 17,\n",
       " 1,\n",
       " 43,\n",
       " 2,\n",
       " 5,\n",
       " 299,\n",
       " 1325,\n",
       " 119,\n",
       " 423,\n",
       " 112,\n",
       " 30,\n",
       " 46,\n",
       " 423,\n",
       " 3,\n",
       " 174,\n",
       " 4,\n",
       " 1,\n",
       " 122,\n",
       " 65,\n",
       " 2,\n",
       " 206,\n",
       " 423,\n",
       " 17,\n",
       " 2216,\n",
       " 163,\n",
       " 14,\n",
       " 864,\n",
       " 273,\n",
       " 55,\n",
       " 61,\n",
       " 387,\n",
       " 15,\n",
       " 61,\n",
       " 4,\n",
       " 111,\n",
       " 136,\n",
       " 121,\n",
       " 372,\n",
       " 23,\n",
       " 238,\n",
       " 220,\n",
       " 20,\n",
       " 4,\n",
       " 124,\n",
       " 2,\n",
       " 16,\n",
       " 3,\n",
       " 12,\n",
       " 133,\n",
       " 967,\n",
       " 28,\n",
       " 1,\n",
       " 1,\n",
       " 191,\n",
       " 548,\n",
       " 189,\n",
       " 34,\n",
       " 4,\n",
       " 19,\n",
       " 5,\n",
       " 3,\n",
       " 10,\n",
       " 64,\n",
       " 468,\n",
       " 92,\n",
       " 146,\n",
       " 52,\n",
       " 160,\n",
       " 144,\n",
       " 180,\n",
       " 3,\n",
       " 342,\n",
       " 127,\n",
       " 430,\n",
       " 3,\n",
       " 1,\n",
       " 119,\n",
       " 4,\n",
       " 70,\n",
       " 5,\n",
       " 35,\n",
       " 1,\n",
       " 63,\n",
       " 73,\n",
       " 22,\n",
       " 5,\n",
       " 28,\n",
       " 1,\n",
       " 3,\n",
       " 158,\n",
       " 21,\n",
       " 25,\n",
       " 176,\n",
       " 4,\n",
       " 12,\n",
       " 181,\n",
       " 431,\n",
       " 81,\n",
       " 96,\n",
       " 8,\n",
       " 34,\n",
       " 522,\n",
       " 127,\n",
       " 1,\n",
       " 11,\n",
       " 8,\n",
       " 17,\n",
       " 3,\n",
       " 3,\n",
       " 30,\n",
       " 32,\n",
       " 899,\n",
       " 250,\n",
       " 50,\n",
       " 13,\n",
       " 1,\n",
       " 27,\n",
       " 10,\n",
       " 2,\n",
       " 15,\n",
       " 97,\n",
       " 4,\n",
       " 85,\n",
       " 5,\n",
       " 21,\n",
       " 12,\n",
       " 523,\n",
       " 537,\n",
       " 72,\n",
       " 12,\n",
       " 20,\n",
       " 128,\n",
       " 17,\n",
       " 44,\n",
       " 3,\n",
       " 9,\n",
       " 61,\n",
       " 3,\n",
       " 2,\n",
       " 20,\n",
       " 31,\n",
       " 160,\n",
       " 103,\n",
       " 47,\n",
       " 24,\n",
       " 126,\n",
       " 18,\n",
       " 124,\n",
       " 1,\n",
       " 8,\n",
       " 35,\n",
       " 76,\n",
       " 13,\n",
       " 13,\n",
       " 56,\n",
       " 1,\n",
       " 30,\n",
       " 17,\n",
       " 56,\n",
       " 990,\n",
       " 64,\n",
       " 4,\n",
       " 55,\n",
       " 64,\n",
       " 20,\n",
       " 39,\n",
       " 33,\n",
       " 633,\n",
       " 5,\n",
       " 137,\n",
       " 19,\n",
       " 3,\n",
       " 1170,\n",
       " 180,\n",
       " 1,\n",
       " 43,\n",
       " 629,\n",
       " 1,\n",
       " 4,\n",
       " 47,\n",
       " 373,\n",
       " 314,\n",
       " 47,\n",
       " 337,\n",
       " 217,\n",
       " 76,\n",
       " 335,\n",
       " 1011,\n",
       " 549,\n",
       " 75,\n",
       " 196,\n",
       " 224,\n",
       " 196,\n",
       " 22,\n",
       " 9,\n",
       " 227,\n",
       " 11,\n",
       " 9,\n",
       " 1,\n",
       " 87,\n",
       " 57,\n",
       " 1,\n",
       " 41,\n",
       " 1,\n",
       " 44,\n",
       " 150,\n",
       " 72,\n",
       " 33,\n",
       " 65,\n",
       " 10,\n",
       " 1,\n",
       " 4,\n",
       " 306,\n",
       " 39,\n",
       " 24,\n",
       " 6,\n",
       " 600,\n",
       " 149,\n",
       " 36,\n",
       " 19,\n",
       " 5,\n",
       " 11,\n",
       " 263,\n",
       " 39,\n",
       " 2,\n",
       " 926,\n",
       " 4,\n",
       " 79,\n",
       " 34,\n",
       " 1,\n",
       " 65,\n",
       " 61,\n",
       " 3,\n",
       " 37,\n",
       " 157,\n",
       " 25,\n",
       " 15,\n",
       " 193,\n",
       " 17,\n",
       " 4,\n",
       " 29,\n",
       " 67,\n",
       " 12,\n",
       " 759,\n",
       " 56,\n",
       " 16,\n",
       " 92,\n",
       " 20,\n",
       " 18,\n",
       " 95,\n",
       " 11,\n",
       " 5,\n",
       " 3,\n",
       " 29,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 103,\n",
       " 171,\n",
       " 411,\n",
       " 170,\n",
       " 100,\n",
       " 10,\n",
       " 142,\n",
       " 132,\n",
       " 4,\n",
       " 47,\n",
       " 4,\n",
       " 2,\n",
       " 127,\n",
       " 6,\n",
       " 2,\n",
       " 86,\n",
       " 106,\n",
       " 26,\n",
       " 40,\n",
       " 15,\n",
       " 32,\n",
       " 3,\n",
       " 4,\n",
       " 14,\n",
       " 68,\n",
       " 8,\n",
       " 13,\n",
       " 10,\n",
       " 672,\n",
       " 69,\n",
       " 36,\n",
       " 5,\n",
       " 15,\n",
       " 19,\n",
       " 50,\n",
       " 11,\n",
       " 313,\n",
       " 13,\n",
       " 21,\n",
       " 40,\n",
       " 33,\n",
       " 25,\n",
       " 41,\n",
       " 79,\n",
       " 111,\n",
       " 42,\n",
       " 75,\n",
       " 2,\n",
       " 1,\n",
       " 12,\n",
       " 23,\n",
       " 20,\n",
       " 124,\n",
       " 9,\n",
       " 7,\n",
       " 66,\n",
       " 43,\n",
       " 155,\n",
       " 85,\n",
       " 2,\n",
       " 7,\n",
       " 17,\n",
       " 145,\n",
       " 305,\n",
       " 51,\n",
       " 2,\n",
       " 441,\n",
       " 1,\n",
       " 34,\n",
       " 3,\n",
       " 24,\n",
       " 42,\n",
       " 47,\n",
       " 58,\n",
       " 2,\n",
       " 48,\n",
       " 7,\n",
       " 69,\n",
       " 126,\n",
       " 16,\n",
       " 169,\n",
       " 79,\n",
       " 17,\n",
       " 667,\n",
       " 232,\n",
       " 353,\n",
       " 38,\n",
       " 3,\n",
       " 3,\n",
       " 590,\n",
       " 399,\n",
       " 63,\n",
       " 82,\n",
       " 4,\n",
       " 3,\n",
       " 131,\n",
       " 9,\n",
       " 47,\n",
       " 288,\n",
       " 195,\n",
       " 8,\n",
       " 56,\n",
       " 1,\n",
       " 346,\n",
       " 6,\n",
       " 17,\n",
       " 60,\n",
       " 28,\n",
       " 47,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 41,\n",
       " 53,\n",
       " 32,\n",
       " 107,\n",
       " 50,\n",
       " 69,\n",
       " 97,\n",
       " 35,\n",
       " 22,\n",
       " 99,\n",
       " 107,\n",
       " 54,\n",
       " 849,\n",
       " 360,\n",
       " 115,\n",
       " 1,\n",
       " 43,\n",
       " 4,\n",
       " 1,\n",
       " 19,\n",
       " 170,\n",
       " 1,\n",
       " 3,\n",
       " 18,\n",
       " 38,\n",
       " 59,\n",
       " 112,\n",
       " 17,\n",
       " 140,\n",
       " 1,\n",
       " 130,\n",
       " 24,\n",
       " 7,\n",
       " 66,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 70,\n",
       " 6,\n",
       " 4,\n",
       " 23,\n",
       " 104,\n",
       " 25,\n",
       " 156,\n",
       " 28,\n",
       " 15,\n",
       " 5,\n",
       " 425,\n",
       " 86,\n",
       " 237,\n",
       " 92,\n",
       " 2,\n",
       " 10,\n",
       " 30,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 11,\n",
       " 6,\n",
       " 1,\n",
       " 52,\n",
       " 268,\n",
       " 176,\n",
       " 11,\n",
       " 7,\n",
       " 159,\n",
       " 33,\n",
       " 79,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 48,\n",
       " 2,\n",
       " 15,\n",
       " 139,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 131,\n",
       " 263,\n",
       " 12,\n",
       " 376,\n",
       " 9,\n",
       " 238,\n",
       " 21,\n",
       " 5,\n",
       " 128,\n",
       " 9,\n",
       " 107,\n",
       " 69,\n",
       " 129,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 116,\n",
       " 29,\n",
       " 43,\n",
       " 84,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 26,\n",
       " 279,\n",
       " 1,\n",
       " 157,\n",
       " 136,\n",
       " 48,\n",
       " 20,\n",
       " 16,\n",
       " 34,\n",
       " 223,\n",
       " 34,\n",
       " 16,\n",
       " 50,\n",
       " 5,\n",
       " 221,\n",
       " 55,\n",
       " 73,\n",
       " 43,\n",
       " 2,\n",
       " 80,\n",
       " 10,\n",
       " 89,\n",
       " 94,\n",
       " 3,\n",
       " 55,\n",
       " 57,\n",
       " 1,\n",
       " 51,\n",
       " 28,\n",
       " 115,\n",
       " 306,\n",
       " 12,\n",
       " 25,\n",
       " 275,\n",
       " 157,\n",
       " 8,\n",
       " 240,\n",
       " 8,\n",
       " 13,\n",
       " 43,\n",
       " 9,\n",
       " 31,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 22,\n",
       " 11,\n",
       " 5,\n",
       " 39,\n",
       " 17,\n",
       " 8,\n",
       " 14,\n",
       " 2,\n",
       " 39,\n",
       " 63,\n",
       " 6,\n",
       " 15,\n",
       " 8,\n",
       " 8,\n",
       " 14,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 24,\n",
       " 4,\n",
       " 10,\n",
       " 113,\n",
       " 3,\n",
       " 15,\n",
       " 20,\n",
       " 27,\n",
       " 21,\n",
       " 2,\n",
       " 48,\n",
       " 102,\n",
       " 75,\n",
       " 52,\n",
       " 314,\n",
       " 26,\n",
       " 26,\n",
       " 150,\n",
       " 6,\n",
       " 379,\n",
       " 9,\n",
       " 10,\n",
       " 2,\n",
       " 9,\n",
       " 91,\n",
       " 5,\n",
       " 195,\n",
       " 2,\n",
       " 27,\n",
       " 32,\n",
       " 51,\n",
       " 3,\n",
       " 35,\n",
       " 135,\n",
       " 60,\n",
       " 19,\n",
       " 1,\n",
       " 251,\n",
       " 33,\n",
       " 266,\n",
       " 28,\n",
       " 1,\n",
       " 13,\n",
       " 72,\n",
       " 25,\n",
       " 2,\n",
       " 79,\n",
       " 13,\n",
       " 41,\n",
       " 2,\n",
       " 5,\n",
       " 15,\n",
       " 101,\n",
       " 12,\n",
       " 56,\n",
       " 4,\n",
       " 27,\n",
       " 61,\n",
       " 61,\n",
       " 3,\n",
       " 4,\n",
       " 41,\n",
       " 9,\n",
       " 26,\n",
       " 188,\n",
       " 73,\n",
       " 36,\n",
       " 31,\n",
       " 17,\n",
       " 4,\n",
       " 10,\n",
       " 94,\n",
       " 23,\n",
       " 1,\n",
       " 16,\n",
       " 38,\n",
       " 131,\n",
       " 202,\n",
       " 27,\n",
       " 1,\n",
       " 180,\n",
       " 30,\n",
       " 3,\n",
       " 3,\n",
       " 84,\n",
       " 1,\n",
       " 147,\n",
       " 41,\n",
       " 3,\n",
       " 60,\n",
       " 1,\n",
       " 4,\n",
       " 21,\n",
       " 45,\n",
       " 175,\n",
       " 2,\n",
       " 104,\n",
       " 7,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 18,\n",
       " 8,\n",
       " 130,\n",
       " 2,\n",
       " 133,\n",
       " 9,\n",
       " 58,\n",
       " 20,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 133,\n",
       " 61,\n",
       " 8,\n",
       " 5,\n",
       " 103,\n",
       " 63,\n",
       " 5,\n",
       " 5,\n",
       " 251,\n",
       " 44,\n",
       " 3,\n",
       " 109,\n",
       " 2,\n",
       " 15,\n",
       " 7,\n",
       " 17,\n",
       " 76,\n",
       " 233,\n",
       " 282,\n",
       " 2,\n",
       " 29,\n",
       " 202,\n",
       " 50,\n",
       " 2,\n",
       " 56,\n",
       " 56,\n",
       " 73,\n",
       " 30,\n",
       " 89,\n",
       " 1,\n",
       " 5,\n",
       " 32,\n",
       " 2,\n",
       " 134,\n",
       " 2,\n",
       " 2,\n",
       " 179,\n",
       " 28,\n",
       " 87,\n",
       " 160,\n",
       " 12,\n",
       " 7,\n",
       " 4,\n",
       " 35,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 13,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 115,\n",
       " 2,\n",
       " 11,\n",
       " 39,\n",
       " 22,\n",
       " 62,\n",
       " 57,\n",
       " 3,\n",
       " 36,\n",
       " 1,\n",
       " 18,\n",
       " 1,\n",
       " 41,\n",
       " 34,\n",
       " 5,\n",
       " 17,\n",
       " 12,\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "#워드 개수 확인\n",
    "with open('./create_dataset/data/pickles/words_frequencies.p','rb') as f:\n",
    "    words_freq=pickle.load(f)\n",
    "words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85ae9cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4371"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f1f1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_beam = get_clotho_loader(data_dir=data_dir, split='evaluation',\n",
    "                                        input_field_name='features',\n",
    "                                        output_field_name='words_ind',\n",
    "                                        load_into_memory=False,\n",
    "                                        batch_size=32,\n",
    "                                        nb_t_steps_pad='max',\n",
    "                                        shuffle=False,\n",
    "                                        return_reference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cf2eb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "test_data = get_test_data_loader(data_dir=test_data_dir,\n",
    "                                     batch_size=hp.batch_size * 2,\n",
    "                                     nb_t_steps_pad='max',\n",
    "                                     shuffle=False,\n",
    "                                     drop_last=False,\n",
    "                                     input_pad_at='start',\n",
    "                                     num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "475347a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss_text = 0.\n",
    "    start_time = time.time()\n",
    "    batch = 0\n",
    "    for src, tgt, tgt_len,ref in training_data:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        tgt_pad_mask = get_padding(tgt, tgt_len)\n",
    "        tgt_in = tgt[:, :-1]\n",
    "        tgt_pad_mask = tgt_pad_mask[:, :-1]\n",
    "        tgt_y = tgt[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, tgt_in, target_padding_mask=tgt_pad_mask)\n",
    "\n",
    "        loss_text = criterion(output.contiguous().view(-1, hp.ntoken), tgt_y.transpose(0, 1).contiguous().view(-1))\n",
    "        loss = loss_text\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), hp.clip_grad)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "        total_loss_text += loss_text.item()\n",
    "\n",
    "        writer.add_scalar('Loss/train-text', loss_text.item(), (epoch - 1) * len(training_data) + batch)\n",
    "        \n",
    "        \n",
    "        batch += 1\n",
    "        \n",
    "        if batch % hp.log_interval == 0 and batch > 0:\n",
    "            mean_text_loss = total_loss_text / hp.log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            current_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\n",
    "            logging.info('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2e} | ms/batch {:5.2f} | '\n",
    "                         'loss-text {:5.4f}'.format(\n",
    "                epoch, batch, len(training_data), current_lr,\n",
    "                elapsed * 1000 / hp.log_interval, mean_text_loss))\n",
    "            total_loss_text = 0\n",
    "            start_time = time.time()\n",
    "        \n",
    "            optimizer.swap_swa_sgd()\n",
    "\n",
    "def eval_all(evaluation_data, max_len=30, eos_ind=9, word_dict_pickle_path=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_sentence_all = []\n",
    "        ref_all = []\n",
    "        for src, tgt, _, ref in evaluation_data:\n",
    "            src = src.to(device)\n",
    "            output = greedy_decode(model, src, max_len=max_len)\n",
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for i in range(output.size()[0]):\n",
    "                output_sentence_ind = []\n",
    "                for j in range(1, output.size(1)):\n",
    "                    sym = output[i, j]\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n",
    "\n",
    "        loss_mean = score\n",
    "        writer.add_scalar(f'Loss/eval_greddy', loss_mean, epoch)\n",
    "        msg = f'eval_greddy SPIDEr: {loss_mean:2.4f}'\n",
    "        logging.info(msg)\n",
    "\n",
    "\n",
    "def eval_with_beam(evaluation_data, max_len=30, eos_ind=9, word_dict_pickle_path=None, beam_size=3):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_sentence_all = []\n",
    "        ref_all = []\n",
    "        for src, tgt, _, ref in evaluation_data:\n",
    "            src = src.to(device)\n",
    "            output = beam_search(model, src, max_len, start_symbol_ind=0, beam_size=beam_size)\n",
    "\n",
    "            output_sentence_ind_batch = []\n",
    "            for single_sample in output:\n",
    "                output_sentence_ind = []\n",
    "                for sym in single_sample:\n",
    "                    if sym == eos_ind: break\n",
    "                    output_sentence_ind.append(sym.item())\n",
    "                output_sentence_ind_batch.append(output_sentence_ind)\n",
    "            output_sentence_all.extend(output_sentence_ind_batch)\n",
    "            ref_all.extend(ref)\n",
    "\n",
    "        score, output_str, ref_str = calculate_spider(output_sentence_all, ref_all, word_dict_pickle_path)\n",
    "\n",
    "        loss_mean = score\n",
    "        writer.add_scalar(f'Loss/eval_beam', loss_mean, epoch)\n",
    "        msg = f'eval_beam_{beam_size} SPIDEr: {loss_mean:2.4f}'\n",
    "        logging.info(msg)\n",
    "\n",
    "\n",
    "def test_with_beam(test_data, max_len=30, eos_ind=9, beam_size=3):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with open(\"test_out.csv\", \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['file_name', 'caption_predicted'])\n",
    "            for src, filename in test_data:\n",
    "                src = src.to(device)\n",
    "                output = beam_search(model, src, max_len, start_symbol_ind=0, beam_size=beam_size)\n",
    "\n",
    "                output_sentence_ind_batch = []\n",
    "                for single_sample in output:\n",
    "                    output_sentence_ind = []\n",
    "                    for sym in single_sample:\n",
    "                        if sym == eos_ind: break\n",
    "                        output_sentence_ind.append(sym.item())\n",
    "                    output_sentence_ind_batch.append(output_sentence_ind)\n",
    "                out_str = gen_str(output_sentence_ind_batch, hp.word_dict_pickle_path)\n",
    "                for caption, fn in zip(out_str, filename):\n",
    "                    writer.writerow(['{}.wav'.format(fn), caption])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d583cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hp.label_smoothing:\n",
    "    criterion = LabelSmoothingLoss(hp.ntoken, smoothing=0.1)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=hp.ntoken - 1)\n",
    "\n",
    "now_time = str(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(time.time())))\n",
    "log_dir = 'models/{name}'.format(name=hp.name)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "log_path = os.path.join(log_dir, 'train.log')\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                        format=\n",
    "                        '%(asctime)s - %(levelname)s: %(message)s',\n",
    "                        handlers=[\n",
    "                            logging.FileHandler(log_path),\n",
    "                            logging.StreamHandler(sys.stdout)]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0708d0f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-05 17:24:19,850 - INFO: TransformerModel(\n",
      "  (transformer_decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (dropout3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (dropout3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_emb): Embedding(4371, 192)\n",
      "  (fc): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (fc1): Linear(in_features=2048, out_features=192, bias=True)\n",
      "  (dec_fc): Linear(in_features=192, out_features=4371, bias=True)\n",
      "  (encoder): Transfer_Cnn14(\n",
      "    (base): Cnn14(\n",
      "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_block1): ConvBlock(\n",
      "        (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_block2): ConvBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_block3): ConvBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_block4): ConvBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_block5): ConvBlock(\n",
      "        (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_block6): ConvBlock(\n",
      "        (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "      (fc_audioset): Linear(in_features=2048, out_features=527, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (generator): Softmax(dim=-1)\n",
      ")\n",
      "2021-12-05 17:24:19,850 - INFO: {'batch_size': 8, 'beam_width': 3, 'checkpoint_save_interval': 5, 'clip_grad': 2.5, 'data_dir': PosixPath('/home/hj20/dcase_2020_T6/create_dataset/data/data_splits'), 'device': 'cuda', 'eval_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/data_splits/evaluation', 'freeze_cnn': True, 'label_smoothing': True, 'load_pretrain_cnn': True, 'load_pretrain_emb': False, 'load_pretrain_model': True, 'log_interval': 100, 'lr': 0.0001, 'mode': 'train', 'name': '1205cnn14일부', 'nhead': 4, 'nhid': 192, 'ninp': 64, 'nkeyword': 4979, 'nlayers': 2, 'ntoken': 4371, 'pretrain_cnn_path': '/home/hj20/dcase_2020_T6/models/tag_models/TagModel_45.pt', 'pretrain_emb_path': '/home/hj20/dcase_2020_T6/models/w2v_192.mod', 'pretrain_model_path': '/home/hj20/dcase_2020_T6/models/base/46.pt', 'scheduler_decay': 0.98, 'seed': 1111, 'spec_augmentation': True, 'test_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/test_data', 'train_data_dir': '/home/hj20/dcase_2020_T6/create_dataset/data/data_splits/development', 'training_epochs': 50, 'word_dict_pickle_path': '/home/hj20/dcase_2020_T6/create_dataset/data/pickles/words_list.p', 'word_freq_pickle_path': '/home/hj20/dcase_2020_T6/create_dataset/data/pickles/words_frequencies.p'}\n",
      "2021-12-05 17:24:19,851 - INFO: Data loaded!\n",
      "2021-12-05 17:24:19,852 - INFO: Data size: 3051\n",
      "2021-12-05 17:24:19,852 - INFO: Total Model parameters: 88053474\n"
     ]
    }
   ],
   "source": [
    "    logging.info(str(model))\n",
    "\n",
    "    logging.info(str(print_hparams(hp)))\n",
    "\n",
    "    logging.info('Data loaded!')\n",
    "    logging.info('Data size: ' + str(len(training_data)))\n",
    "\n",
    "    logging.info('Total Model parameters: ' + str(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51859f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-05 17:25:00,432 - INFO: | epoch   1 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 390.34 | loss-text 5.8549\n",
      "2021-12-05 17:25:39,164 - INFO: | epoch   1 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 387.31 | loss-text 5.1395\n",
      "2021-12-05 17:26:17,750 - INFO: | epoch   1 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 385.85 | loss-text 4.9406\n",
      "2021-12-05 17:26:56,740 - INFO: | epoch   1 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 389.89 | loss-text 4.8012\n",
      "2021-12-05 17:27:36,082 - INFO: | epoch   1 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 393.42 | loss-text 4.7680\n",
      "2021-12-05 17:28:15,107 - INFO: | epoch   1 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 390.24 | loss-text 4.7066\n",
      "2021-12-05 17:28:54,442 - INFO: | epoch   1 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 393.34 | loss-text 4.5962\n",
      "2021-12-05 17:29:33,941 - INFO: | epoch   1 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 394.98 | loss-text 4.5815\n",
      "2021-12-05 17:30:13,336 - INFO: | epoch   1 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 393.95 | loss-text 4.4910\n",
      "2021-12-05 17:30:53,111 - INFO: | epoch   1 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 397.74 | loss-text 4.5620\n",
      "2021-12-05 17:31:32,838 - INFO: | epoch   1 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 397.27 | loss-text 4.5045\n",
      "2021-12-05 17:32:12,521 - INFO: | epoch   1 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 396.82 | loss-text 4.4348\n",
      "2021-12-05 17:32:51,978 - INFO: | epoch   1 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 394.57 | loss-text 4.4724\n",
      "2021-12-05 17:33:31,757 - INFO: | epoch   1 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 397.79 | loss-text 4.4499\n",
      "2021-12-05 17:34:11,509 - INFO: | epoch   1 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.51 | loss-text 4.3666\n",
      "2021-12-05 17:34:51,225 - INFO: | epoch   1 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 397.15 | loss-text 4.4033\n",
      "2021-12-05 17:35:30,835 - INFO: | epoch   1 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 396.09 | loss-text 4.3699\n",
      "2021-12-05 17:36:10,752 - INFO: | epoch   1 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 399.17 | loss-text 4.3809\n",
      "2021-12-05 17:36:50,379 - INFO: | epoch   1 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 396.26 | loss-text 4.3554\n",
      "2021-12-05 17:38:49,478 - INFO: | epoch   1 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 399.74 | loss-text 4.2831\n",
      "2021-12-05 17:39:28,934 - INFO: | epoch   1 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 394.56 | loss-text 4.2014\n",
      "2021-12-05 17:40:08,529 - INFO: | epoch   1 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 395.94 | loss-text 4.2553\n",
      "2021-12-05 17:40:48,307 - INFO: | epoch   1 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.77 | loss-text 4.2347\n",
      "2021-12-05 17:41:28,022 - INFO: | epoch   1 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.14 | loss-text 4.2099\n",
      "2021-12-05 17:42:07,579 - INFO: | epoch   1 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 395.56 | loss-text 4.2391\n",
      "2021-12-05 17:42:47,426 - INFO: | epoch   1 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 398.46 | loss-text 4.2170\n",
      "2021-12-05 17:43:27,163 - INFO: | epoch   1 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 397.37 | loss-text 4.1997\n",
      "2021-12-05 17:44:07,089 - INFO: | epoch   1 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 399.25 | loss-text 4.1914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003915\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 12775, 'reflen': 11014, 'guess': [12775, 11751, 10727, 9703], 'correct': [4526, 1148, 314, 46]}\n",
      "ratio: 1.1598874160158743\n",
      "Bleu_1: 0.354\n",
      "Bleu_2: 0.186\n",
      "Bleu_3: 0.100\n",
      "Bleu_4: 0.047\n",
      "computing METEOR score...\n",
      "METEOR: 0.112\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.282\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.105\n",
      "computing SPICE score...\n",
      "SPICE: 0.068\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.087\n",
      "2021-12-05 17:45:01,586 - INFO: eval_greddy SPIDEr: 0.0867\n",
      "loading annotations into memory...\n",
      "0:00:00.003977\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8852, 'reflen': 9529, 'guess': [8852, 7828, 6805, 5782], 'correct': [4467, 1422, 480, 108]}\n",
      "ratio: 0.9289537202223812\n",
      "Bleu_1: 0.467\n",
      "Bleu_2: 0.280\n",
      "Bleu_3: 0.173\n",
      "Bleu_4: 0.097\n",
      "computing METEOR score...\n",
      "METEOR: 0.125\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.319\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.154\n",
      "computing SPICE score...\n",
      "SPICE: 0.078\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.116\n",
      "2021-12-05 17:45:32,229 - INFO: eval_beam_2 SPIDEr: 0.1163\n",
      "loading annotations into memory...\n",
      "0:00:00.003823\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8076, 'reflen': 9321, 'guess': [8076, 7052, 6029, 5006], 'correct': [4309, 1460, 491, 123]}\n",
      "ratio: 0.8664306404891249\n",
      "Bleu_1: 0.457\n",
      "Bleu_2: 0.285\n",
      "Bleu_3: 0.178\n",
      "Bleu_4: 0.105\n",
      "computing METEOR score...\n",
      "METEOR: 0.124\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.322\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.165\n",
      "computing SPICE score...\n",
      "SPICE: 0.080\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.122\n",
      "2021-12-05 17:46:03,866 - INFO: eval_beam_3 SPIDEr: 0.1224\n",
      "loading annotations into memory...\n",
      "0:00:00.003840\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 7096, 'reflen': 9196, 'guess': [7096, 6072, 5049, 4026], 'correct': [4059, 1445, 489, 116]}\n",
      "ratio: 0.7716398434100944\n",
      "Bleu_1: 0.425\n",
      "Bleu_2: 0.274\n",
      "Bleu_3: 0.176\n",
      "Bleu_4: 0.104\n",
      "computing METEOR score...\n",
      "METEOR: 0.122\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.332\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.179\n",
      "computing SPICE score...\n",
      "SPICE: 0.079\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.129\n",
      "2021-12-05 17:46:38,382 - INFO: eval_beam_4 SPIDEr: 0.1293\n",
      "2021-12-05 17:47:17,735 - INFO: | epoch   2 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 393.51 | loss-text 4.1444\n",
      "2021-12-05 17:47:57,063 - INFO: | epoch   2 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 393.27 | loss-text 4.1699\n",
      "2021-12-05 17:48:36,404 - INFO: | epoch   2 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 393.40 | loss-text 4.1041\n",
      "2021-12-05 17:49:15,711 - INFO: | epoch   2 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 393.06 | loss-text 4.1590\n",
      "2021-12-05 17:49:55,547 - INFO: | epoch   2 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 398.36 | loss-text 4.1009\n",
      "2021-12-05 17:50:35,114 - INFO: | epoch   2 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 395.66 | loss-text 4.2124\n",
      "2021-12-05 17:51:14,799 - INFO: | epoch   2 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 396.84 | loss-text 4.1202\n",
      "2021-12-05 17:51:54,454 - INFO: | epoch   2 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 396.54 | loss-text 4.0644\n",
      "2021-12-05 17:52:34,255 - INFO: | epoch   2 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 398.00 | loss-text 4.0352\n",
      "2021-12-05 17:53:14,249 - INFO: | epoch   2 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 399.93 | loss-text 4.0560\n",
      "2021-12-05 17:53:54,284 - INFO: | epoch   2 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 400.35 | loss-text 4.0510\n",
      "2021-12-05 17:54:34,214 - INFO: | epoch   2 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 399.29 | loss-text 4.0998\n",
      "2021-12-05 17:55:13,720 - INFO: | epoch   2 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 395.06 | loss-text 4.1312\n",
      "2021-12-05 17:55:53,475 - INFO: | epoch   2 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 397.54 | loss-text 4.0414\n",
      "2021-12-05 17:56:33,154 - INFO: | epoch   2 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.79 | loss-text 4.0093\n",
      "2021-12-05 17:57:13,118 - INFO: | epoch   2 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 399.63 | loss-text 4.0848\n",
      "2021-12-05 17:57:52,791 - INFO: | epoch   2 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 396.71 | loss-text 4.0121\n",
      "2021-12-05 17:58:32,293 - INFO: | epoch   2 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 395.01 | loss-text 3.9502\n",
      "2021-12-05 17:59:11,678 - INFO: | epoch   2 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 393.85 | loss-text 3.9620\n",
      "2021-12-05 17:59:51,395 - INFO: | epoch   2 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 397.16 | loss-text 3.9736\n",
      "2021-12-05 18:00:30,889 - INFO: | epoch   2 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 394.94 | loss-text 3.9820\n",
      "2021-12-05 18:01:10,623 - INFO: | epoch   2 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 397.33 | loss-text 4.0652\n",
      "2021-12-05 18:01:50,705 - INFO: | epoch   2 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 400.82 | loss-text 3.9762\n",
      "2021-12-05 18:02:30,903 - INFO: | epoch   2 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 401.96 | loss-text 3.9427\n",
      "2021-12-05 18:03:10,495 - INFO: | epoch   2 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 395.92 | loss-text 3.9258\n",
      "2021-12-05 18:03:50,212 - INFO: | epoch   2 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.16 | loss-text 3.9314\n",
      "2021-12-05 18:04:30,069 - INFO: | epoch   2 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 398.57 | loss-text 3.8700\n",
      "2021-12-05 18:05:09,971 - INFO: | epoch   2 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 399.01 | loss-text 4.0184\n",
      "2021-12-05 18:05:49,576 - INFO: | epoch   2 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 396.04 | loss-text 3.9227\n",
      "2021-12-05 18:06:29,424 - INFO: | epoch   2 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 398.47 | loss-text 3.9411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003845\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10359, 'reflen': 10361, 'guess': [10359, 9335, 8311, 7288], 'correct': [5054, 1607, 572, 149]}\n",
      "ratio: 0.9998069684392433\n",
      "Bleu_1: 0.488\n",
      "Bleu_2: 0.290\n",
      "Bleu_3: 0.179\n",
      "Bleu_4: 0.104\n",
      "computing METEOR score...\n",
      "METEOR: 0.137\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.330\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.203\n",
      "computing SPICE score...\n",
      "SPICE: 0.083\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.143\n",
      "2021-12-05 18:07:15,182 - INFO: eval_greddy SPIDEr: 0.1432\n",
      "loading annotations into memory...\n",
      "0:00:00.003740\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8968, 'reflen': 9546, 'guess': [8968, 7944, 6921, 5899], 'correct': [4753, 1693, 633, 191]}\n",
      "ratio: 0.9394510789858642\n",
      "Bleu_1: 0.497\n",
      "Bleu_2: 0.315\n",
      "Bleu_3: 0.204\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.141\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.334\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.217\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.155\n",
      "2021-12-05 18:07:42,376 - INFO: eval_beam_2 SPIDEr: 0.1549\n",
      "loading annotations into memory...\n",
      "0:00:00.004011\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8576, 'reflen': 9432, 'guess': [8576, 7552, 6529, 5507], 'correct': [4576, 1706, 672, 211]}\n",
      "ratio: 0.9092451229854845\n",
      "Bleu_1: 0.483\n",
      "Bleu_2: 0.314\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.140\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.333\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.231\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.162\n",
      "2021-12-05 18:08:11,518 - INFO: eval_beam_3 SPIDEr: 0.1617\n",
      "loading annotations into memory...\n",
      "0:00:00.003706\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8212, 'reflen': 9356, 'guess': [8212, 7188, 6166, 5151], 'correct': [4516, 1727, 673, 220]}\n",
      "ratio: 0.8777255237279951\n",
      "Bleu_1: 0.478\n",
      "Bleu_2: 0.316\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.139\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.338\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.242\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.167\n",
      "2021-12-05 18:08:44,868 - INFO: eval_beam_4 SPIDEr: 0.1667\n",
      "2021-12-05 18:09:24,512 - INFO: | epoch   3 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 396.41 | loss-text 3.8919\n",
      "2021-12-05 18:10:03,795 - INFO: | epoch   3 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 392.82 | loss-text 3.9004\n",
      "2021-12-05 18:10:43,375 - INFO: | epoch   3 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.79 | loss-text 3.9009\n",
      "2021-12-05 18:11:23,084 - INFO: | epoch   3 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 397.08 | loss-text 3.9159\n",
      "2021-12-05 18:12:02,749 - INFO: | epoch   3 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 396.65 | loss-text 3.8618\n",
      "2021-12-05 18:12:42,261 - INFO: | epoch   3 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 395.11 | loss-text 3.9077\n",
      "2021-12-05 18:13:22,098 - INFO: | epoch   3 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 398.36 | loss-text 3.9138\n",
      "2021-12-05 18:14:01,888 - INFO: | epoch   3 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 397.89 | loss-text 3.9461\n",
      "2021-12-05 18:14:41,813 - INFO: | epoch   3 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 399.25 | loss-text 3.8342\n",
      "2021-12-05 18:15:21,624 - INFO: | epoch   3 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 398.11 | loss-text 3.8884\n",
      "2021-12-05 18:16:01,399 - INFO: | epoch   3 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 397.74 | loss-text 3.8880\n",
      "2021-12-05 18:16:41,179 - INFO: | epoch   3 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 397.80 | loss-text 3.8693\n",
      "2021-12-05 18:17:21,350 - INFO: | epoch   3 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 401.70 | loss-text 3.8464\n",
      "2021-12-05 18:18:01,230 - INFO: | epoch   3 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 398.79 | loss-text 3.8152\n",
      "2021-12-05 18:18:40,904 - INFO: | epoch   3 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.73 | loss-text 3.8878\n",
      "2021-12-05 18:19:20,674 - INFO: | epoch   3 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 397.69 | loss-text 3.8619\n",
      "2021-12-05 18:20:00,408 - INFO: | epoch   3 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.34 | loss-text 3.8781\n",
      "2021-12-05 18:20:40,266 - INFO: | epoch   3 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 398.57 | loss-text 3.8097\n",
      "2021-12-05 18:21:19,849 - INFO: | epoch   3 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 395.82 | loss-text 3.8524\n",
      "2021-12-05 18:21:59,691 - INFO: | epoch   3 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 398.42 | loss-text 3.8431\n",
      "2021-12-05 18:22:39,377 - INFO: | epoch   3 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 396.85 | loss-text 3.7947\n",
      "2021-12-05 18:23:19,595 - INFO: | epoch   3 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 402.17 | loss-text 3.7730\n",
      "2021-12-05 18:23:59,361 - INFO: | epoch   3 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.65 | loss-text 3.7785\n",
      "2021-12-05 18:24:39,005 - INFO: | epoch   3 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 396.44 | loss-text 3.8605\n",
      "2021-12-05 18:25:19,000 - INFO: | epoch   3 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 399.95 | loss-text 3.7960\n",
      "2021-12-05 18:25:58,565 - INFO: | epoch   3 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 395.64 | loss-text 3.7546\n",
      "2021-12-05 18:26:38,027 - INFO: | epoch   3 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 394.61 | loss-text 3.8068\n",
      "2021-12-05 18:27:17,892 - INFO: | epoch   3 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 398.64 | loss-text 3.8222\n",
      "2021-12-05 18:27:57,110 - INFO: | epoch   3 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 392.18 | loss-text 3.7646\n",
      "2021-12-05 18:28:36,868 - INFO: | epoch   3 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 397.58 | loss-text 3.8154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003830\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10353, 'reflen': 10274, 'guess': [10353, 9329, 8305, 7281], 'correct': [5066, 1626, 533, 127]}\n",
      "ratio: 1.007689312828401\n",
      "Bleu_1: 0.489\n",
      "Bleu_2: 0.292\n",
      "Bleu_3: 0.176\n",
      "Bleu_4: 0.099\n",
      "computing METEOR score...\n",
      "METEOR: 0.139\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.332\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.203\n",
      "computing SPICE score...\n",
      "SPICE: 0.090\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.147\n",
      "2021-12-05 18:29:24,330 - INFO: eval_greddy SPIDEr: 0.1467\n",
      "loading annotations into memory...\n",
      "0:00:00.003807\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9021, 'reflen': 9641, 'guess': [9021, 7997, 6973, 5949], 'correct': [5014, 1789, 642, 160]}\n",
      "ratio: 0.9356913183278772\n",
      "Bleu_1: 0.519\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.124\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.348\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.260\n",
      "computing SPICE score...\n",
      "SPICE: 0.095\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.177\n",
      "2021-12-05 18:29:52,156 - INFO: eval_beam_2 SPIDEr: 0.1774\n",
      "loading annotations into memory...\n",
      "0:00:00.003852\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8731, 'reflen': 9535, 'guess': [8731, 7707, 6683, 5661], 'correct': [4856, 1851, 722, 217]}\n",
      "ratio: 0.9156790770843297\n",
      "Bleu_1: 0.507\n",
      "Bleu_2: 0.333\n",
      "Bleu_3: 0.222\n",
      "Bleu_4: 0.140\n",
      "computing METEOR score...\n",
      "METEOR: 0.145\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.349\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.265\n",
      "computing SPICE score...\n",
      "SPICE: 0.092\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.178\n",
      "2021-12-05 18:30:22,849 - INFO: eval_beam_3 SPIDEr: 0.1781\n",
      "loading annotations into memory...\n",
      "0:00:00.003928\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8382, 'reflen': 9413, 'guess': [8382, 7358, 6335, 5314], 'correct': [4806, 1898, 753, 228]}\n",
      "ratio: 0.8904706257302782\n",
      "Bleu_1: 0.507\n",
      "Bleu_2: 0.340\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.273\n",
      "computing SPICE score...\n",
      "SPICE: 0.093\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.183\n",
      "2021-12-05 18:30:56,815 - INFO: eval_beam_4 SPIDEr: 0.1830\n",
      "2021-12-05 18:31:36,342 - INFO: | epoch   4 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 395.25 | loss-text 3.7143\n",
      "2021-12-05 18:32:15,894 - INFO: | epoch   4 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 395.51 | loss-text 3.7822\n",
      "2021-12-05 18:32:55,509 - INFO: | epoch   4 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.14 | loss-text 3.7588\n",
      "2021-12-05 18:33:35,015 - INFO: | epoch   4 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.06 | loss-text 3.7851\n",
      "2021-12-05 18:34:14,881 - INFO: | epoch   4 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 398.66 | loss-text 3.7619\n",
      "2021-12-05 18:34:54,566 - INFO: | epoch   4 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 396.84 | loss-text 3.7268\n",
      "2021-12-05 18:35:34,338 - INFO: | epoch   4 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 397.72 | loss-text 3.7594\n",
      "2021-12-05 18:36:13,952 - INFO: | epoch   4 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 396.14 | loss-text 3.7783\n",
      "2021-12-05 18:36:53,992 - INFO: | epoch   4 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 400.39 | loss-text 3.7076\n",
      "2021-12-05 18:37:33,473 - INFO: | epoch   4 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 394.81 | loss-text 3.7949\n",
      "2021-12-05 18:38:13,450 - INFO: | epoch   4 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 399.76 | loss-text 3.7606\n",
      "2021-12-05 18:38:52,934 - INFO: | epoch   4 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 394.84 | loss-text 3.6395\n",
      "2021-12-05 18:39:32,733 - INFO: | epoch   4 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 397.98 | loss-text 3.7191\n",
      "2021-12-05 18:40:12,354 - INFO: | epoch   4 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 396.20 | loss-text 3.7674\n",
      "2021-12-05 18:40:51,928 - INFO: | epoch   4 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 395.74 | loss-text 3.7113\n",
      "2021-12-05 18:41:31,770 - INFO: | epoch   4 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 398.42 | loss-text 3.7512\n",
      "2021-12-05 18:42:11,166 - INFO: | epoch   4 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 393.95 | loss-text 3.7491\n",
      "2021-12-05 18:42:51,072 - INFO: | epoch   4 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 399.05 | loss-text 3.6621\n",
      "2021-12-05 18:43:30,382 - INFO: | epoch   4 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 393.09 | loss-text 3.7200\n",
      "2021-12-05 18:44:09,995 - INFO: | epoch   4 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.13 | loss-text 3.7548\n",
      "2021-12-05 18:44:49,747 - INFO: | epoch   4 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 397.51 | loss-text 3.6511\n",
      "2021-12-05 18:45:29,564 - INFO: | epoch   4 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 398.16 | loss-text 3.6914\n",
      "2021-12-05 18:46:08,896 - INFO: | epoch   4 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 393.32 | loss-text 3.7258\n",
      "2021-12-05 18:46:48,817 - INFO: | epoch   4 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 399.20 | loss-text 3.6442\n",
      "2021-12-05 18:47:28,733 - INFO: | epoch   4 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 399.16 | loss-text 3.6812\n",
      "2021-12-05 18:48:08,498 - INFO: | epoch   4 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.64 | loss-text 3.7266\n",
      "2021-12-05 18:48:48,110 - INFO: | epoch   4 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 396.12 | loss-text 3.6883\n",
      "2021-12-05 18:49:27,867 - INFO: | epoch   4 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 397.56 | loss-text 3.7334\n",
      "2021-12-05 18:50:07,761 - INFO: | epoch   4 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 398.94 | loss-text 3.6607\n",
      "2021-12-05 18:50:47,618 - INFO: | epoch   4 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 398.57 | loss-text 3.7227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003705\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10666, 'reflen': 10476, 'guess': [10666, 9643, 8620, 7597], 'correct': [5326, 1786, 628, 157]}\n",
      "ratio: 1.018136693394328\n",
      "Bleu_1: 0.499\n",
      "Bleu_2: 0.304\n",
      "Bleu_3: 0.189\n",
      "Bleu_4: 0.109\n",
      "computing METEOR score...\n",
      "METEOR: 0.146\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.344\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.229\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.163\n",
      "2021-12-05 18:51:34,405 - INFO: eval_greddy SPIDEr: 0.1628\n",
      "loading annotations into memory...\n",
      "0:00:00.003877\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9387, 'reflen': 9791, 'guess': [9387, 8363, 7340, 6317], 'correct': [5265, 1976, 788, 236]}\n",
      "ratio: 0.9587376161780248\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.294\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.198\n",
      "2021-12-05 18:52:03,358 - INFO: eval_beam_2 SPIDEr: 0.1979\n",
      "loading annotations into memory...\n",
      "0:00:00.003896\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8792, 'reflen': 9508, 'guess': [8792, 7768, 6745, 5722], 'correct': [5009, 1945, 793, 243]}\n",
      "ratio: 0.9246949936894273\n",
      "Bleu_1: 0.525\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.300\n",
      "computing SPICE score...\n",
      "SPICE: 0.098\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.199\n",
      "2021-12-05 18:52:33,900 - INFO: eval_beam_3 SPIDEr: 0.1987\n",
      "loading annotations into memory...\n",
      "0:00:00.003906\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8589, 'reflen': 9413, 'guess': [8589, 7565, 6542, 5519], 'correct': [4905, 1932, 794, 252]}\n",
      "ratio: 0.9124614894294154\n",
      "Bleu_1: 0.519\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.150\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.303\n",
      "computing SPICE score...\n",
      "SPICE: 0.096\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.199\n",
      "2021-12-05 18:53:07,918 - INFO: eval_beam_4 SPIDEr: 0.1994\n",
      "2021-12-05 18:53:47,417 - INFO: | epoch   5 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.97 | loss-text 3.6317\n",
      "2021-12-05 18:54:27,227 - INFO: | epoch   5 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 398.09 | loss-text 3.6976\n",
      "2021-12-05 18:55:06,705 - INFO: | epoch   5 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 394.76 | loss-text 3.6682\n",
      "2021-12-05 18:55:46,243 - INFO: | epoch   5 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.38 | loss-text 3.6912\n",
      "2021-12-05 18:56:25,815 - INFO: | epoch   5 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 395.71 | loss-text 3.6434\n",
      "2021-12-05 18:57:05,611 - INFO: | epoch   5 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.95 | loss-text 3.6208\n",
      "2021-12-05 18:57:45,408 - INFO: | epoch   5 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 397.97 | loss-text 3.6235\n",
      "2021-12-05 18:58:25,193 - INFO: | epoch   5 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 397.85 | loss-text 3.6422\n",
      "2021-12-05 18:59:04,879 - INFO: | epoch   5 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 396.85 | loss-text 3.5631\n",
      "2021-12-05 18:59:44,654 - INFO: | epoch   5 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 397.74 | loss-text 3.6286\n",
      "2021-12-05 19:00:24,320 - INFO: | epoch   5 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 396.66 | loss-text 3.6413\n",
      "2021-12-05 19:01:04,245 - INFO: | epoch   5 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 399.24 | loss-text 3.6549\n",
      "2021-12-05 19:01:43,901 - INFO: | epoch   5 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 396.55 | loss-text 3.6786\n",
      "2021-12-05 19:02:23,488 - INFO: | epoch   5 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 395.86 | loss-text 3.6073\n",
      "2021-12-05 19:03:03,022 - INFO: | epoch   5 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 395.33 | loss-text 3.6753\n",
      "2021-12-05 19:03:42,658 - INFO: | epoch   5 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 396.36 | loss-text 3.6230\n",
      "2021-12-05 19:04:22,499 - INFO: | epoch   5 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 398.40 | loss-text 3.6427\n",
      "2021-12-05 19:05:02,093 - INFO: | epoch   5 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 395.93 | loss-text 3.6357\n",
      "2021-12-05 19:05:41,338 - INFO: | epoch   5 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 392.45 | loss-text 3.6266\n",
      "2021-12-05 19:06:20,953 - INFO: | epoch   5 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.14 | loss-text 3.6089\n",
      "2021-12-05 19:07:00,558 - INFO: | epoch   5 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 396.04 | loss-text 3.6885\n",
      "2021-12-05 19:07:40,148 - INFO: | epoch   5 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 395.89 | loss-text 3.5852\n",
      "2021-12-05 19:08:19,810 - INFO: | epoch   5 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 396.61 | loss-text 3.6045\n",
      "2021-12-05 19:08:59,567 - INFO: | epoch   5 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.56 | loss-text 3.6211\n",
      "2021-12-05 19:09:39,342 - INFO: | epoch   5 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.74 | loss-text 3.6202\n",
      "2021-12-05 19:10:19,281 - INFO: | epoch   5 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 399.38 | loss-text 3.5756\n",
      "2021-12-05 19:10:59,229 - INFO: | epoch   5 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 399.48 | loss-text 3.6207\n",
      "2021-12-05 19:11:38,560 - INFO: | epoch   5 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 393.30 | loss-text 3.5959\n",
      "2021-12-05 19:12:17,875 - INFO: | epoch   5 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 393.15 | loss-text 3.5891\n",
      "2021-12-05 19:12:57,532 - INFO: | epoch   5 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 396.56 | loss-text 3.5757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003957\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10135, 'reflen': 10261, 'guess': [10135, 9111, 8087, 7063], 'correct': [5104, 1635, 539, 128]}\n",
      "ratio: 0.9877204950783561\n",
      "Bleu_1: 0.497\n",
      "Bleu_2: 0.297\n",
      "Bleu_3: 0.180\n",
      "Bleu_4: 0.101\n",
      "computing METEOR score...\n",
      "METEOR: 0.145\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.336\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.243\n",
      "computing SPICE score...\n",
      "SPICE: 0.101\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.172\n",
      "2021-12-05 19:13:44,665 - INFO: eval_greddy SPIDEr: 0.1721\n",
      "loading annotations into memory...\n",
      "0:00:00.003875\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8966, 'reflen': 9588, 'guess': [8966, 7942, 6918, 5894], 'correct': [5085, 1841, 683, 201]}\n",
      "ratio: 0.9351272423862187\n",
      "Bleu_1: 0.529\n",
      "Bleu_2: 0.338\n",
      "Bleu_3: 0.219\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.153\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.306\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.205\n",
      "2021-12-05 19:14:11,780 - INFO: eval_beam_2 SPIDEr: 0.2046\n",
      "loading annotations into memory...\n",
      "0:00:00.003866\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8589, 'reflen': 9439, 'guess': [8589, 7565, 6542, 5520], 'correct': [4971, 1888, 750, 237]}\n",
      "ratio: 0.9099480877210605\n",
      "Bleu_1: 0.524\n",
      "Bleu_2: 0.344\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.325\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.214\n",
      "2021-12-05 19:14:41,444 - INFO: eval_beam_3 SPIDEr: 0.2135\n",
      "loading annotations into memory...\n",
      "0:00:00.004016\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8421, 'reflen': 9371, 'guess': [8421, 7397, 6374, 5352], 'correct': [4940, 1896, 766, 246]}\n",
      "ratio: 0.8986234126559707\n",
      "Bleu_1: 0.524\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.155\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.328\n",
      "computing SPICE score...\n",
      "SPICE: 0.102\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.215\n",
      "2021-12-05 19:15:15,191 - INFO: eval_beam_4 SPIDEr: 0.2150\n",
      "2021-12-05 19:15:54,618 - INFO: | epoch   6 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.24 | loss-text 3.5038\n",
      "2021-12-05 19:16:34,005 - INFO: | epoch   6 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 393.86 | loss-text 3.5246\n",
      "2021-12-05 19:17:13,544 - INFO: | epoch   6 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.38 | loss-text 3.5745\n",
      "2021-12-05 19:17:52,967 - INFO: | epoch   6 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 394.23 | loss-text 3.5380\n",
      "2021-12-05 19:18:32,684 - INFO: | epoch   6 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 397.16 | loss-text 3.5550\n",
      "2021-12-05 19:19:11,987 - INFO: | epoch   6 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 393.02 | loss-text 3.5492\n",
      "2021-12-05 19:19:51,449 - INFO: | epoch   6 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 394.62 | loss-text 3.5576\n",
      "2021-12-05 19:20:31,322 - INFO: | epoch   6 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.72 | loss-text 3.5807\n",
      "2021-12-05 19:21:11,157 - INFO: | epoch   6 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 398.33 | loss-text 3.5156\n",
      "2021-12-05 19:21:50,581 - INFO: | epoch   6 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 394.23 | loss-text 3.6090\n",
      "2021-12-05 19:22:30,198 - INFO: | epoch   6 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 396.16 | loss-text 3.5993\n",
      "2021-12-05 19:23:09,834 - INFO: | epoch   6 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 396.36 | loss-text 3.5645\n",
      "2021-12-05 19:23:49,659 - INFO: | epoch   6 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 398.24 | loss-text 3.5246\n",
      "2021-12-05 19:24:29,179 - INFO: | epoch   6 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 395.19 | loss-text 3.5786\n",
      "2021-12-05 19:25:09,134 - INFO: | epoch   6 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 399.55 | loss-text 3.5360\n",
      "2021-12-05 19:25:48,743 - INFO: | epoch   6 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 396.09 | loss-text 3.6247\n",
      "2021-12-05 19:26:28,432 - INFO: | epoch   6 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 396.89 | loss-text 3.5456\n",
      "2021-12-05 19:27:07,919 - INFO: | epoch   6 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 394.86 | loss-text 3.5733\n",
      "2021-12-05 19:27:47,473 - INFO: | epoch   6 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 395.54 | loss-text 3.5482\n",
      "2021-12-05 19:28:27,350 - INFO: | epoch   6 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 398.76 | loss-text 3.5821\n",
      "2021-12-05 19:29:07,307 - INFO: | epoch   6 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 399.56 | loss-text 3.5133\n",
      "2021-12-05 19:29:47,485 - INFO: | epoch   6 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 401.77 | loss-text 3.5455\n",
      "2021-12-05 19:30:27,447 - INFO: | epoch   6 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 399.62 | loss-text 3.5727\n",
      "2021-12-05 19:31:07,047 - INFO: | epoch   6 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 395.99 | loss-text 3.5589\n",
      "2021-12-05 19:31:46,465 - INFO: | epoch   6 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 394.17 | loss-text 3.5784\n",
      "2021-12-05 19:32:26,436 - INFO: | epoch   6 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 399.70 | loss-text 3.5342\n",
      "2021-12-05 19:33:05,875 - INFO: | epoch   6 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 394.38 | loss-text 3.5309\n",
      "2021-12-05 19:33:45,374 - INFO: | epoch   6 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 394.99 | loss-text 3.5684\n",
      "2021-12-05 19:34:24,837 - INFO: | epoch   6 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 394.62 | loss-text 3.5595\n",
      "2021-12-05 19:35:04,456 - INFO: | epoch   6 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 396.19 | loss-text 3.5262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003778\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10601, 'reflen': 10502, 'guess': [10601, 9577, 8553, 7529], 'correct': [5579, 1941, 705, 193]}\n",
      "ratio: 1.0094267758521225\n",
      "Bleu_1: 0.526\n",
      "Bleu_2: 0.327\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.123\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.269\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.187\n",
      "2021-12-05 19:35:52,163 - INFO: eval_greddy SPIDEr: 0.1872\n",
      "loading annotations into memory...\n",
      "0:00:00.003885\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9266, 'reflen': 9752, 'guess': [9266, 8242, 7218, 6194], 'correct': [5413, 2064, 802, 246]}\n",
      "ratio: 0.9501640689088443\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.328\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.218\n",
      "2021-12-05 19:36:20,856 - INFO: eval_beam_2 SPIDEr: 0.2185\n",
      "loading annotations into memory...\n",
      "0:00:00.003830\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8839, 'reflen': 9555, 'guess': [8839, 7815, 6791, 5767], 'correct': [5231, 2055, 842, 267]}\n",
      "ratio: 0.9250654107795996\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.364\n",
      "Bleu_3: 0.247\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.337\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.223\n",
      "2021-12-05 19:36:50,863 - INFO: eval_beam_3 SPIDEr: 0.2227\n",
      "loading annotations into memory...\n",
      "0:00:00.003746\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8550, 'reflen': 9428, 'guess': [8550, 7526, 6502, 5478], 'correct': [5088, 2032, 850, 281]}\n",
      "ratio: 0.9068731438268024\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.362\n",
      "Bleu_3: 0.249\n",
      "Bleu_4: 0.163\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.373\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.342\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.224\n",
      "2021-12-05 19:37:25,107 - INFO: eval_beam_4 SPIDEr: 0.2236\n",
      "2021-12-05 19:38:04,474 - INFO: | epoch   7 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 393.64 | loss-text 3.4336\n",
      "2021-12-05 19:38:43,792 - INFO: | epoch   7 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 393.18 | loss-text 3.5063\n",
      "2021-12-05 19:39:23,241 - INFO: | epoch   7 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 394.48 | loss-text 3.4878\n",
      "2021-12-05 19:40:02,686 - INFO: | epoch   7 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 394.45 | loss-text 3.4818\n",
      "2021-12-05 19:40:42,128 - INFO: | epoch   7 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 394.41 | loss-text 3.4708\n",
      "2021-12-05 19:41:22,026 - INFO: | epoch   7 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 398.97 | loss-text 3.5090\n",
      "2021-12-05 19:42:01,595 - INFO: | epoch   7 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 395.68 | loss-text 3.5202\n",
      "2021-12-05 19:42:41,274 - INFO: | epoch   7 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 396.79 | loss-text 3.5158\n",
      "2021-12-05 19:43:20,852 - INFO: | epoch   7 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 395.77 | loss-text 3.5270\n",
      "2021-12-05 19:44:00,703 - INFO: | epoch   7 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 398.51 | loss-text 3.5701\n",
      "2021-12-05 19:44:40,772 - INFO: | epoch   7 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 400.69 | loss-text 3.5145\n",
      "2021-12-05 19:45:20,579 - INFO: | epoch   7 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 398.06 | loss-text 3.5310\n",
      "2021-12-05 19:46:00,835 - INFO: | epoch   7 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 402.55 | loss-text 3.5235\n",
      "2021-12-05 19:46:40,940 - INFO: | epoch   7 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 401.05 | loss-text 3.4873\n",
      "2021-12-05 19:47:21,005 - INFO: | epoch   7 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 400.64 | loss-text 3.4698\n",
      "2021-12-05 19:48:01,127 - INFO: | epoch   7 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 401.22 | loss-text 3.4952\n",
      "2021-12-05 19:48:40,910 - INFO: | epoch   7 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.82 | loss-text 3.4838\n",
      "2021-12-05 19:49:20,608 - INFO: | epoch   7 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 396.97 | loss-text 3.4959\n",
      "2021-12-05 19:50:00,383 - INFO: | epoch   7 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.74 | loss-text 3.4723\n",
      "2021-12-05 19:50:40,054 - INFO: | epoch   7 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.70 | loss-text 3.4887\n",
      "2021-12-05 19:52:39,018 - INFO: | epoch   7 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 394.79 | loss-text 3.5259\n",
      "2021-12-05 19:53:18,763 - INFO: | epoch   7 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.45 | loss-text 3.5140\n",
      "2021-12-05 19:55:18,316 - INFO: | epoch   7 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 397.69 | loss-text 3.5059\n",
      "2021-12-05 19:55:58,140 - INFO: | epoch   7 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 398.24 | loss-text 3.4694\n",
      "2021-12-05 19:56:37,962 - INFO: | epoch   7 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 398.21 | loss-text 3.4986\n",
      "2021-12-05 19:57:17,480 - INFO: | epoch   7 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 395.17 | loss-text 3.4841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003859\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10758, 'reflen': 10576, 'guess': [10758, 9734, 8710, 7686], 'correct': [5653, 1961, 719, 192]}\n",
      "ratio: 1.0172087745838674\n",
      "Bleu_1: 0.525\n",
      "Bleu_2: 0.325\n",
      "Bleu_3: 0.206\n",
      "Bleu_4: 0.122\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.310\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.209\n",
      "2021-12-05 19:58:04,530 - INFO: eval_greddy SPIDEr: 0.2092\n",
      "loading annotations into memory...\n",
      "0:00:00.003904\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9655, 'reflen': 10001, 'guess': [9655, 8631, 7608, 6586], 'correct': [5497, 2069, 829, 257]}\n",
      "ratio: 0.965403459653938\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.343\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.226\n",
      "2021-12-05 19:58:32,989 - INFO: eval_beam_2 SPIDEr: 0.2259\n",
      "loading annotations into memory...\n",
      "0:00:00.003935\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9159, 'reflen': 9709, 'guess': [9159, 8135, 7112, 6090], 'correct': [5217, 2012, 830, 274]}\n",
      "ratio: 0.943351529508606\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.344\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2021-12-05 19:59:03,428 - INFO: eval_beam_3 SPIDEr: 0.2249\n",
      "loading annotations into memory...\n",
      "0:00:00.003895\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8801, 'reflen': 9515, 'guess': [8801, 7777, 6755, 5733], 'correct': [5130, 1993, 841, 286]}\n",
      "ratio: 0.9249605885443063\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.157\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.350\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2021-12-05 19:59:39,275 - INFO: eval_beam_4 SPIDEr: 0.2283\n",
      "2021-12-05 20:00:18,730 - INFO: | epoch   8 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.53 | loss-text 3.4295\n",
      "2021-12-05 20:00:58,515 - INFO: | epoch   8 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 397.84 | loss-text 3.4621\n",
      "2021-12-05 20:01:38,166 - INFO: | epoch   8 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.50 | loss-text 3.4970\n",
      "2021-12-05 20:02:17,750 - INFO: | epoch   8 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.84 | loss-text 3.4487\n",
      "2021-12-05 20:02:57,448 - INFO: | epoch   8 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 396.97 | loss-text 3.4957\n",
      "2021-12-05 20:03:37,226 - INFO: | epoch   8 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.77 | loss-text 3.3590\n",
      "2021-12-05 20:04:17,264 - INFO: | epoch   8 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 400.37 | loss-text 3.4742\n",
      "2021-12-05 20:04:57,070 - INFO: | epoch   8 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.06 | loss-text 3.4969\n",
      "2021-12-05 20:05:36,848 - INFO: | epoch   8 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.78 | loss-text 3.4253\n",
      "2021-12-05 20:06:16,716 - INFO: | epoch   8 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 398.67 | loss-text 3.4850\n",
      "2021-12-05 20:06:56,521 - INFO: | epoch   8 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 398.04 | loss-text 3.4351\n",
      "2021-12-05 20:07:36,533 - INFO: | epoch   8 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 400.12 | loss-text 3.3887\n",
      "2021-12-05 20:08:16,050 - INFO: | epoch   8 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 395.16 | loss-text 3.4128\n",
      "2021-12-05 20:08:55,620 - INFO: | epoch   8 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 395.69 | loss-text 3.4588\n",
      "2021-12-05 20:09:35,516 - INFO: | epoch   8 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 398.95 | loss-text 3.4351\n",
      "2021-12-05 20:10:15,576 - INFO: | epoch   8 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 400.60 | loss-text 3.5031\n",
      "2021-12-05 20:10:55,148 - INFO: | epoch   8 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 395.72 | loss-text 3.5102\n",
      "2021-12-05 20:11:34,925 - INFO: | epoch   8 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 397.76 | loss-text 3.4790\n",
      "2021-12-05 20:12:14,659 - INFO: | epoch   8 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.33 | loss-text 3.5282\n",
      "2021-12-05 20:12:54,464 - INFO: | epoch   8 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 398.04 | loss-text 3.4873\n",
      "2021-12-05 20:15:32,821 - INFO: | epoch   8 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 395.87 | loss-text 3.4201\n",
      "2021-12-05 20:16:12,646 - INFO: | epoch   8 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 398.25 | loss-text 3.4600\n",
      "2021-12-05 20:16:52,182 - INFO: | epoch   8 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 395.35 | loss-text 3.4488\n",
      "2021-12-05 20:17:32,025 - INFO: | epoch   8 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 398.43 | loss-text 3.4386\n",
      "2021-12-05 20:18:11,718 - INFO: | epoch   8 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 396.92 | loss-text 3.4352\n",
      "2021-12-05 20:18:51,474 - INFO: | epoch   8 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 397.56 | loss-text 3.4248\n",
      "2021-12-05 20:19:31,492 - INFO: | epoch   8 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 400.17 | loss-text 3.4348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003819\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 11184, 'reflen': 10903, 'guess': [11184, 10160, 9136, 8112], 'correct': [5896, 2118, 774, 223]}\n",
      "ratio: 1.0257727231036389\n",
      "Bleu_1: 0.527\n",
      "Bleu_2: 0.332\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.126\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.299\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.205\n",
      "2021-12-05 20:20:19,260 - INFO: eval_greddy SPIDEr: 0.2047\n",
      "loading annotations into memory...\n",
      "0:00:00.003900\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9852, 'reflen': 10098, 'guess': [9852, 8828, 7804, 6780], 'correct': [5617, 2140, 844, 263]}\n",
      "ratio: 0.975638740344526\n",
      "Bleu_1: 0.556\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.346\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2021-12-05 20:20:47,850 - INFO: eval_beam_2 SPIDEr: 0.2291\n",
      "loading annotations into memory...\n",
      "0:00:00.003851\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9438, 'reflen': 9846, 'guess': [9438, 8414, 7390, 6366], 'correct': [5435, 2143, 876, 282]}\n",
      "ratio: 0.9585618525288484\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.367\n",
      "Bleu_3: 0.248\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.352\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-05 20:21:18,679 - INFO: eval_beam_3 SPIDEr: 0.2325\n",
      "loading annotations into memory...\n",
      "0:00:00.003936\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9254, 'reflen': 9749, 'guess': [9254, 8230, 7206, 6182], 'correct': [5342, 2143, 893, 304]}\n",
      "ratio: 0.9492255615959637\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.368\n",
      "Bleu_3: 0.251\n",
      "Bleu_4: 0.165\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.360\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.235\n",
      "2021-12-05 20:21:53,685 - INFO: eval_beam_4 SPIDEr: 0.2355\n",
      "2021-12-05 20:22:33,290 - INFO: | epoch   9 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 396.02 | loss-text 3.3973\n",
      "2021-12-05 20:23:12,759 - INFO: | epoch   9 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 394.68 | loss-text 3.3554\n",
      "2021-12-05 20:23:52,087 - INFO: | epoch   9 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 393.27 | loss-text 3.3586\n",
      "2021-12-05 20:24:31,489 - INFO: | epoch   9 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 394.01 | loss-text 3.3977\n",
      "2021-12-05 20:25:11,336 - INFO: | epoch   9 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 398.46 | loss-text 3.3850\n",
      "2021-12-05 20:25:50,825 - INFO: | epoch   9 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 394.88 | loss-text 3.4221\n",
      "2021-12-05 20:26:30,847 - INFO: | epoch   9 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 400.21 | loss-text 3.4348\n",
      "2021-12-05 20:27:10,452 - INFO: | epoch   9 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 396.04 | loss-text 3.3911\n",
      "2021-12-05 20:27:50,152 - INFO: | epoch   9 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.00 | loss-text 3.3918\n",
      "2021-12-05 20:28:30,099 - INFO: | epoch   9 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 399.45 | loss-text 3.4299\n",
      "2021-12-05 20:29:09,897 - INFO: | epoch   9 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 397.98 | loss-text 3.3660\n",
      "2021-12-05 20:29:49,735 - INFO: | epoch   9 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 398.38 | loss-text 3.3985\n",
      "2021-12-05 20:31:09,164 - INFO: | epoch   9 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 396.40 | loss-text 3.4143\n",
      "2021-12-05 20:31:48,952 - INFO: | epoch   9 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.87 | loss-text 3.4025\n",
      "2021-12-05 20:32:28,907 - INFO: | epoch   9 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 399.55 | loss-text 3.4117\n",
      "2021-12-05 20:33:08,640 - INFO: | epoch   9 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.32 | loss-text 3.3619\n",
      "2021-12-05 20:33:48,619 - INFO: | epoch   9 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 399.79 | loss-text 3.4272\n",
      "2021-12-05 20:34:28,465 - INFO: | epoch   9 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 398.45 | loss-text 3.3864\n",
      "2021-12-05 20:35:08,003 - INFO: | epoch   9 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 395.37 | loss-text 3.3498\n",
      "2021-12-05 20:35:47,926 - INFO: | epoch   9 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 399.23 | loss-text 3.4172\n",
      "2021-12-05 20:36:27,845 - INFO: | epoch   9 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 399.18 | loss-text 3.4272\n",
      "2021-12-05 20:37:07,803 - INFO: | epoch   9 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 399.58 | loss-text 3.3942\n",
      "2021-12-05 20:37:47,730 - INFO: | epoch   9 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 399.26 | loss-text 3.3685\n",
      "2021-12-05 20:38:27,536 - INFO: | epoch   9 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 398.05 | loss-text 3.4318\n",
      "2021-12-05 20:39:07,242 - INFO: | epoch   9 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.05 | loss-text 3.3533\n",
      "2021-12-05 20:39:46,508 - INFO: | epoch   9 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 392.65 | loss-text 3.3862\n",
      "2021-12-05 20:40:26,186 - INFO: | epoch   9 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 396.78 | loss-text 3.4440\n",
      "2021-12-05 20:41:06,010 - INFO: | epoch   9 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 398.23 | loss-text 3.4102\n",
      "2021-12-05 20:41:45,706 - INFO: | epoch   9 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 396.95 | loss-text 3.4372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003890\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10766, 'reflen': 10683, 'guess': [10766, 9742, 8718, 7694], 'correct': [5658, 1887, 663, 194]}\n",
      "ratio: 1.007769353177852\n",
      "Bleu_1: 0.526\n",
      "Bleu_2: 0.319\n",
      "Bleu_3: 0.198\n",
      "Bleu_4: 0.118\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.356\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.277\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.193\n",
      "2021-12-05 20:42:33,278 - INFO: eval_greddy SPIDEr: 0.1929\n",
      "loading annotations into memory...\n",
      "0:00:00.003793\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9366, 'reflen': 9815, 'guess': [9366, 8342, 7318, 6294], 'correct': [5313, 1993, 797, 257]}\n",
      "ratio: 0.9542536933264437\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.338\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.224\n",
      "2021-12-05 20:43:01,166 - INFO: eval_beam_2 SPIDEr: 0.2239\n",
      "loading annotations into memory...\n",
      "0:00:00.003916\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8934, 'reflen': 9565, 'guess': [8934, 7910, 6886, 5862], 'correct': [5172, 2041, 844, 279]}\n",
      "ratio: 0.9340303188707857\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.246\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.350\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2021-12-05 20:43:32,311 - INFO: eval_beam_3 SPIDEr: 0.2289\n",
      "loading annotations into memory...\n",
      "0:00:00.003832\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8748, 'reflen': 9473, 'guess': [8748, 7724, 6700, 5676], 'correct': [5114, 2038, 859, 299]}\n",
      "ratio: 0.9234666948167504\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.362\n",
      "Bleu_3: 0.249\n",
      "Bleu_4: 0.165\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.356\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-05 20:44:06,680 - INFO: eval_beam_4 SPIDEr: 0.2315\n",
      "2021-12-05 20:44:46,312 - INFO: | epoch  10 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 396.28 | loss-text 3.3439\n",
      "2021-12-05 20:45:25,777 - INFO: | epoch  10 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 394.64 | loss-text 3.3585\n",
      "2021-12-05 20:46:05,050 - INFO: | epoch  10 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 392.73 | loss-text 3.3979\n",
      "2021-12-05 20:48:04,023 - INFO: | epoch  10 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 396.86 | loss-text 3.3975\n",
      "2021-12-05 20:48:43,600 - INFO: | epoch  10 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 395.76 | loss-text 3.3516\n",
      "2021-12-05 20:49:23,106 - INFO: | epoch  10 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 395.05 | loss-text 3.3791\n",
      "2021-12-05 20:50:02,834 - INFO: | epoch  10 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.28 | loss-text 3.3814\n",
      "2021-12-05 20:50:43,115 - INFO: | epoch  10 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 402.80 | loss-text 3.3831\n",
      "2021-12-05 20:51:22,683 - INFO: | epoch  10 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 395.68 | loss-text 3.3182\n",
      "2021-12-05 20:52:02,430 - INFO: | epoch  10 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 397.46 | loss-text 3.3502\n",
      "2021-12-05 20:52:42,106 - INFO: | epoch  10 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 396.76 | loss-text 3.3534\n",
      "2021-12-05 20:53:21,429 - INFO: | epoch  10 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 393.21 | loss-text 3.3710\n",
      "2021-12-05 20:54:01,248 - INFO: | epoch  10 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 398.18 | loss-text 3.3734\n",
      "2021-12-05 20:54:41,180 - INFO: | epoch  10 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 399.32 | loss-text 3.3484\n",
      "2021-12-05 20:55:21,437 - INFO: | epoch  10 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 402.57 | loss-text 3.3519\n",
      "2021-12-05 20:56:01,149 - INFO: | epoch  10 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 397.12 | loss-text 3.3757\n",
      "2021-12-05 20:56:41,238 - INFO: | epoch  10 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 400.88 | loss-text 3.3418\n",
      "2021-12-05 20:57:20,727 - INFO: | epoch  10 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 394.88 | loss-text 3.3972\n",
      "2021-12-05 20:58:00,496 - INFO: | epoch  10 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 397.68 | loss-text 3.3507\n",
      "2021-12-05 20:58:40,192 - INFO: | epoch  10 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 396.95 | loss-text 3.2964\n",
      "2021-12-05 20:59:20,098 - INFO: | epoch  10 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 399.05 | loss-text 3.3573\n",
      "2021-12-05 20:59:59,755 - INFO: | epoch  10 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 396.56 | loss-text 3.3555\n",
      "2021-12-05 21:00:39,318 - INFO: | epoch  10 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 395.63 | loss-text 3.3596\n",
      "2021-12-05 21:01:19,454 - INFO: | epoch  10 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 401.35 | loss-text 3.3704\n",
      "2021-12-05 21:01:59,152 - INFO: | epoch  10 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 396.97 | loss-text 3.3748\n",
      "2021-12-05 21:03:58,077 - INFO: | epoch  10 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 394.79 | loss-text 3.3908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003749\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10146, 'reflen': 10233, 'guess': [10146, 9123, 8100, 7077], 'correct': [5243, 1757, 600, 169]}\n",
      "ratio: 0.9914980944003722\n",
      "Bleu_1: 0.512\n",
      "Bleu_2: 0.313\n",
      "Bleu_3: 0.193\n",
      "Bleu_4: 0.114\n",
      "computing METEOR score...\n",
      "METEOR: 0.151\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.343\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.290\n",
      "computing SPICE score...\n",
      "SPICE: 0.103\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.196\n",
      "2021-12-05 21:04:46,524 - INFO: eval_greddy SPIDEr: 0.1965\n",
      "loading annotations into memory...\n",
      "0:00:00.003842\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9325, 'reflen': 9782, 'guess': [9325, 8301, 7278, 6255], 'correct': [5245, 1938, 758, 249]}\n",
      "ratio: 0.9532815375177925\n",
      "Bleu_1: 0.536\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.145\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.347\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2021-12-05 21:05:14,339 - INFO: eval_beam_2 SPIDEr: 0.2270\n",
      "loading annotations into memory...\n",
      "0:00:00.100715\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8804, 'reflen': 9507, 'guess': [8804, 7780, 6757, 5734], 'correct': [5050, 1955, 804, 265]}\n",
      "ratio: 0.9260544861679892\n",
      "Bleu_1: 0.530\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.355\n",
      "computing SPICE score...\n",
      "SPICE: 0.106\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-05 21:05:44,752 - INFO: eval_beam_3 SPIDEr: 0.2308\n",
      "loading annotations into memory...\n",
      "0:00:00.003839\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8578, 'reflen': 9391, 'guess': [8578, 7554, 6531, 5508], 'correct': [4966, 1961, 832, 291]}\n",
      "ratio: 0.9134277499732815\n",
      "Bleu_1: 0.527\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.162\n",
      "computing METEOR score...\n",
      "METEOR: 0.158\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.105\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-05 21:06:19,145 - INFO: eval_beam_4 SPIDEr: 0.2333\n",
      "2021-12-05 21:06:58,935 - INFO: | epoch  11 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 397.87 | loss-text 3.3060\n",
      "2021-12-05 21:07:38,355 - INFO: | epoch  11 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 394.19 | loss-text 3.2992\n",
      "2021-12-05 21:08:17,882 - INFO: | epoch  11 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.27 | loss-text 3.3475\n",
      "2021-12-05 21:08:57,532 - INFO: | epoch  11 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 396.49 | loss-text 3.2855\n",
      "2021-12-05 21:09:36,895 - INFO: | epoch  11 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 393.62 | loss-text 3.3254\n",
      "2021-12-05 21:10:16,434 - INFO: | epoch  11 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 395.38 | loss-text 3.3475\n",
      "2021-12-05 21:10:55,993 - INFO: | epoch  11 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 395.58 | loss-text 3.3418\n",
      "2021-12-05 21:11:36,030 - INFO: | epoch  11 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 400.36 | loss-text 3.3899\n",
      "2021-12-05 21:12:15,657 - INFO: | epoch  11 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 396.26 | loss-text 3.3250\n",
      "2021-12-05 21:12:55,534 - INFO: | epoch  11 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 398.76 | loss-text 3.3156\n",
      "2021-12-05 21:13:35,049 - INFO: | epoch  11 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 395.15 | loss-text 3.3681\n",
      "2021-12-05 21:14:14,902 - INFO: | epoch  11 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 398.52 | loss-text 3.2984\n",
      "2021-12-05 21:14:54,880 - INFO: | epoch  11 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 399.77 | loss-text 3.2606\n",
      "2021-12-05 21:15:34,585 - INFO: | epoch  11 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 397.05 | loss-text 3.3631\n",
      "2021-12-05 21:16:14,307 - INFO: | epoch  11 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.20 | loss-text 3.2869\n",
      "2021-12-05 21:16:54,109 - INFO: | epoch  11 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 398.02 | loss-text 3.3620\n",
      "2021-12-05 21:17:33,763 - INFO: | epoch  11 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 396.53 | loss-text 3.3598\n",
      "2021-12-05 21:19:32,945 - INFO: | epoch  11 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 397.75 | loss-text 3.3194\n",
      "2021-12-05 21:20:12,702 - INFO: | epoch  11 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 397.57 | loss-text 3.3563\n",
      "2021-12-05 21:20:52,538 - INFO: | epoch  11 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 398.35 | loss-text 3.3841\n",
      "2021-12-05 21:21:32,449 - INFO: | epoch  11 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 399.11 | loss-text 3.3336\n",
      "2021-12-05 21:22:12,585 - INFO: | epoch  11 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 401.35 | loss-text 3.3751\n",
      "2021-12-05 21:22:51,977 - INFO: | epoch  11 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 393.91 | loss-text 3.3053\n",
      "2021-12-05 21:23:31,557 - INFO: | epoch  11 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 395.80 | loss-text 3.3682\n",
      "2021-12-05 21:24:11,302 - INFO: | epoch  11 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 397.44 | loss-text 3.3584\n",
      "2021-12-05 21:24:50,972 - INFO: | epoch  11 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 396.70 | loss-text 3.3283\n",
      "2021-12-05 21:25:30,888 - INFO: | epoch  11 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 399.15 | loss-text 3.2790\n",
      "2021-12-05 21:26:10,153 - INFO: | epoch  11 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 392.64 | loss-text 3.3293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003856\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10525, 'reflen': 10472, 'guess': [10525, 9501, 8477, 7453], 'correct': [5674, 1984, 724, 224]}\n",
      "ratio: 1.005061115355137\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.336\n",
      "Bleu_3: 0.213\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.324\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.217\n",
      "2021-12-05 21:26:57,071 - INFO: eval_greddy SPIDEr: 0.2172\n",
      "loading annotations into memory...\n",
      "0:00:00.003876\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9744, 'reflen': 9962, 'guess': [9744, 8720, 7696, 6672], 'correct': [5521, 2120, 853, 282]}\n",
      "ratio: 0.9781168440071293\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-05 21:27:25,409 - INFO: eval_beam_2 SPIDEr: 0.2421\n",
      "loading annotations into memory...\n",
      "0:00:00.003822\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9273, 'reflen': 9742, 'guess': [9273, 8249, 7225, 6201], 'correct': [5282, 2102, 881, 306]}\n",
      "ratio: 0.9518579347155663\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.362\n",
      "Bleu_3: 0.248\n",
      "Bleu_4: 0.163\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.367\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-05 21:27:56,140 - INFO: eval_beam_3 SPIDEr: 0.2396\n",
      "loading annotations into memory...\n",
      "0:00:00.003919\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8995, 'reflen': 9578, 'guess': [8995, 7971, 6947, 5923], 'correct': [5166, 2097, 893, 318]}\n",
      "ratio: 0.939131342660165\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.364\n",
      "Bleu_3: 0.252\n",
      "Bleu_4: 0.168\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.372\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-05 21:28:31,580 - INFO: eval_beam_4 SPIDEr: 0.2420\n",
      "2021-12-05 21:29:10,990 - INFO: | epoch  12 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.07 | loss-text 3.3128\n",
      "2021-12-05 21:29:50,433 - INFO: | epoch  12 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 394.42 | loss-text 3.3024\n",
      "2021-12-05 21:30:29,716 - INFO: | epoch  12 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 392.83 | loss-text 3.2950\n",
      "2021-12-05 21:31:09,508 - INFO: | epoch  12 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 397.91 | loss-text 3.2979\n",
      "2021-12-05 21:31:49,211 - INFO: | epoch  12 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 397.02 | loss-text 3.2894\n",
      "2021-12-05 21:32:28,724 - INFO: | epoch  12 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 395.13 | loss-text 3.3319\n",
      "2021-12-05 21:33:08,376 - INFO: | epoch  12 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 396.51 | loss-text 3.2934\n",
      "2021-12-05 21:33:47,881 - INFO: | epoch  12 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 395.04 | loss-text 3.2970\n",
      "2021-12-05 21:34:27,631 - INFO: | epoch  12 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.50 | loss-text 3.2635\n",
      "2021-12-05 21:35:07,181 - INFO: | epoch  12 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 395.48 | loss-text 3.3044\n",
      "2021-12-05 21:37:06,919 - INFO: | epoch  12 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 398.04 | loss-text 3.2563\n",
      "2021-12-05 21:37:46,195 - INFO: | epoch  12 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 392.76 | loss-text 3.3076\n",
      "2021-12-05 21:38:25,948 - INFO: | epoch  12 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.52 | loss-text 3.2790\n",
      "2021-12-05 21:39:05,473 - INFO: | epoch  12 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 395.24 | loss-text 3.2587\n",
      "2021-12-05 21:39:45,025 - INFO: | epoch  12 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 395.51 | loss-text 3.2830\n",
      "2021-12-05 21:40:24,365 - INFO: | epoch  12 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 393.40 | loss-text 3.3003\n",
      "2021-12-05 21:41:04,040 - INFO: | epoch  12 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 396.74 | loss-text 3.2648\n",
      "2021-12-05 21:41:43,661 - INFO: | epoch  12 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.21 | loss-text 3.3013\n",
      "2021-12-05 21:42:23,487 - INFO: | epoch  12 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 398.25 | loss-text 3.2286\n",
      "2021-12-05 21:43:03,220 - INFO: | epoch  12 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 397.33 | loss-text 3.3002\n",
      "2021-12-05 21:45:42,413 - INFO: | epoch  12 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.77 | loss-text 3.3053\n",
      "2021-12-05 21:46:22,173 - INFO: | epoch  12 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 397.58 | loss-text 3.3112\n",
      "2021-12-05 21:47:01,797 - INFO: | epoch  12 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 396.24 | loss-text 3.3356\n",
      "2021-12-05 21:47:41,360 - INFO: | epoch  12 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 395.62 | loss-text 3.3541\n",
      "2021-12-05 21:48:21,013 - INFO: | epoch  12 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 396.52 | loss-text 3.3021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003908\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10017, 'reflen': 10165, 'guess': [10017, 8994, 7971, 6948], 'correct': [5496, 1941, 685, 194]}\n",
      "ratio: 0.9854402361041824\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.326\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.218\n",
      "2021-12-05 21:49:07,656 - INFO: eval_greddy SPIDEr: 0.2177\n",
      "loading annotations into memory...\n",
      "0:00:00.003974\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9193, 'reflen': 9729, 'guess': [9193, 8170, 7147, 6124], 'correct': [5351, 2048, 814, 263]}\n",
      "ratio: 0.944906979134449\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-05 21:49:35,136 - INFO: eval_beam_2 SPIDEr: 0.2379\n",
      "loading annotations into memory...\n",
      "0:00:00.003850\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8725, 'reflen': 9490, 'guess': [8725, 7702, 6679, 5656], 'correct': [5119, 1990, 808, 279]}\n",
      "ratio: 0.9193888303476375\n",
      "Bleu_1: 0.537\n",
      "Bleu_2: 0.357\n",
      "Bleu_3: 0.242\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-05 21:50:05,024 - INFO: eval_beam_3 SPIDEr: 0.2365\n",
      "loading annotations into memory...\n",
      "0:00:00.003860\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8480, 'reflen': 9370, 'guess': [8480, 7457, 6434, 5411], 'correct': [5014, 1973, 811, 276]}\n",
      "ratio: 0.9050160085377903\n",
      "Bleu_1: 0.532\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-05 21:50:39,065 - INFO: eval_beam_4 SPIDEr: 0.2397\n",
      "2021-12-05 21:51:18,261 - INFO: | epoch  13 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 391.92 | loss-text 3.2485\n",
      "2021-12-05 21:51:57,659 - INFO: | epoch  13 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 393.97 | loss-text 3.2190\n",
      "2021-12-05 21:52:37,188 - INFO: | epoch  13 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.28 | loss-text 3.2426\n",
      "2021-12-05 21:53:16,768 - INFO: | epoch  13 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.80 | loss-text 3.2349\n",
      "2021-12-05 21:53:56,478 - INFO: | epoch  13 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 397.08 | loss-text 3.2167\n",
      "2021-12-05 21:54:36,292 - INFO: | epoch  13 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 398.13 | loss-text 3.2400\n",
      "2021-12-05 21:55:15,896 - INFO: | epoch  13 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 396.04 | loss-text 3.2620\n",
      "2021-12-05 21:55:55,529 - INFO: | epoch  13 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 396.32 | loss-text 3.3331\n",
      "2021-12-05 21:56:35,351 - INFO: | epoch  13 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 398.21 | loss-text 3.2844\n",
      "2021-12-05 21:57:15,055 - INFO: | epoch  13 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 397.03 | loss-text 3.2326\n",
      "2021-12-05 21:57:54,888 - INFO: | epoch  13 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 398.32 | loss-text 3.2435\n",
      "2021-12-05 21:58:34,690 - INFO: | epoch  13 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 398.01 | loss-text 3.2435\n",
      "2021-12-05 21:59:14,367 - INFO: | epoch  13 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 396.77 | loss-text 3.2477\n",
      "2021-12-05 21:59:54,224 - INFO: | epoch  13 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 398.56 | loss-text 3.2693\n",
      "2021-12-05 22:00:33,851 - INFO: | epoch  13 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.26 | loss-text 3.2548\n",
      "2021-12-05 22:02:33,186 - INFO: | epoch  13 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 398.25 | loss-text 3.2776\n",
      "2021-12-05 22:03:13,003 - INFO: | epoch  13 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 398.16 | loss-text 3.3192\n",
      "2021-12-05 22:03:52,680 - INFO: | epoch  13 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.76 | loss-text 3.2617\n",
      "2021-12-05 22:04:32,540 - INFO: | epoch  13 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 398.59 | loss-text 3.2595\n",
      "2021-12-05 22:05:12,033 - INFO: | epoch  13 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 394.93 | loss-text 3.2772\n",
      "2021-12-05 22:05:51,782 - INFO: | epoch  13 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.48 | loss-text 3.2412\n",
      "2021-12-05 22:06:31,510 - INFO: | epoch  13 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.28 | loss-text 3.2580\n",
      "2021-12-05 22:07:11,551 - INFO: | epoch  13 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 400.40 | loss-text 3.2790\n",
      "2021-12-05 22:07:51,335 - INFO: | epoch  13 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.83 | loss-text 3.3606\n",
      "2021-12-05 22:08:31,739 - INFO: | epoch  13 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 404.04 | loss-text 3.2549\n",
      "2021-12-05 22:09:11,760 - INFO: | epoch  13 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 400.20 | loss-text 3.2273\n",
      "2021-12-05 22:09:51,603 - INFO: | epoch  13 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 398.42 | loss-text 3.2279\n",
      "2021-12-05 22:10:31,821 - INFO: | epoch  13 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 402.17 | loss-text 3.2574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003798\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10135, 'reflen': 10266, 'guess': [10135, 9112, 8089, 7066], 'correct': [5572, 1940, 681, 189]}\n",
      "ratio: 0.9872394311317955\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.338\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.126\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.329\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.219\n",
      "2021-12-05 22:11:18,270 - INFO: eval_greddy SPIDEr: 0.2189\n",
      "loading annotations into memory...\n",
      "0:00:00.003851\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9327, 'reflen': 9767, 'guess': [9327, 8303, 7280, 6257], 'correct': [5365, 2020, 813, 262]}\n",
      "ratio: 0.954950342991609\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.357\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.118\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-05 22:11:47,435 - INFO: eval_beam_2 SPIDEr: 0.2393\n",
      "loading annotations into memory...\n",
      "0:00:00.003858\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8915, 'reflen': 9528, 'guess': [8915, 7891, 6868, 5845], 'correct': [5153, 2033, 821, 267]}\n",
      "ratio: 0.9356633081443182\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-05 22:12:18,646 - INFO: eval_beam_3 SPIDEr: 0.2394\n",
      "loading annotations into memory...\n",
      "0:00:00.003922\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8753, 'reflen': 9455, 'guess': [8753, 7729, 6706, 5683], 'correct': [5105, 2041, 845, 289]}\n",
      "ratio: 0.925753569539828\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.362\n",
      "Bleu_3: 0.248\n",
      "Bleu_4: 0.164\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-05 22:12:53,579 - INFO: eval_beam_4 SPIDEr: 0.2415\n",
      "2021-12-05 22:13:33,163 - INFO: | epoch  14 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 395.81 | loss-text 3.2233\n",
      "2021-12-05 22:14:12,757 - INFO: | epoch  14 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 395.94 | loss-text 3.2554\n",
      "2021-12-05 22:14:52,487 - INFO: | epoch  14 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 397.29 | loss-text 3.2619\n",
      "2021-12-05 22:15:32,020 - INFO: | epoch  14 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.32 | loss-text 3.2608\n",
      "2021-12-05 22:16:11,474 - INFO: | epoch  14 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 394.54 | loss-text 3.1996\n",
      "2021-12-05 22:16:51,160 - INFO: | epoch  14 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 396.85 | loss-text 3.2783\n",
      "2021-12-05 22:17:31,050 - INFO: | epoch  14 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 398.90 | loss-text 3.2510\n",
      "2021-12-05 22:18:10,903 - INFO: | epoch  14 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.52 | loss-text 3.2378\n",
      "2021-12-05 22:18:50,815 - INFO: | epoch  14 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 399.11 | loss-text 3.2316\n",
      "2021-12-05 22:21:30,161 - INFO: | epoch  14 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 397.73 | loss-text 3.1973\n",
      "2021-12-05 22:22:09,991 - INFO: | epoch  14 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 398.29 | loss-text 3.2344\n",
      "2021-12-05 22:22:49,966 - INFO: | epoch  14 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 399.74 | loss-text 3.2391\n",
      "2021-12-05 22:23:29,791 - INFO: | epoch  14 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 398.24 | loss-text 3.2277\n",
      "2021-12-05 22:24:09,804 - INFO: | epoch  14 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 400.13 | loss-text 3.2712\n",
      "2021-12-05 22:26:09,311 - INFO: | epoch  14 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 400.74 | loss-text 3.2884\n",
      "2021-12-05 22:26:49,206 - INFO: | epoch  14 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 398.95 | loss-text 3.1907\n",
      "2021-12-05 22:27:28,849 - INFO: | epoch  14 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 396.42 | loss-text 3.2156\n",
      "2021-12-05 22:28:08,386 - INFO: | epoch  14 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 395.37 | loss-text 3.2093\n",
      "2021-12-05 22:28:48,098 - INFO: | epoch  14 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.11 | loss-text 3.2765\n",
      "2021-12-05 22:29:28,139 - INFO: | epoch  14 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 400.41 | loss-text 3.2592\n",
      "2021-12-05 22:30:07,715 - INFO: | epoch  14 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 395.75 | loss-text 3.2110\n",
      "2021-12-05 22:30:46,856 - INFO: | epoch  14 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 391.40 | loss-text 3.1833\n",
      "2021-12-05 22:31:26,794 - INFO: | epoch  14 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 399.37 | loss-text 3.2382\n",
      "2021-12-05 22:32:06,332 - INFO: | epoch  14 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 395.38 | loss-text 3.2465\n",
      "2021-12-05 22:32:46,241 - INFO: | epoch  14 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 399.08 | loss-text 3.2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003865\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10400, 'reflen': 10406, 'guess': [10400, 9376, 8352, 7328], 'correct': [5735, 2053, 775, 226]}\n",
      "ratio: 0.999423409571305\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.224\n",
      "Bleu_4: 0.136\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.342\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2021-12-05 22:33:33,138 - INFO: eval_greddy SPIDEr: 0.2255\n",
      "loading annotations into memory...\n",
      "0:00:00.003841\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9669, 'reflen': 9971, 'guess': [9669, 8645, 7621, 6597], 'correct': [5526, 2058, 834, 274]}\n",
      "ratio: 0.9697121652792127\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-05 22:34:01,115 - INFO: eval_beam_2 SPIDEr: 0.2380\n",
      "loading annotations into memory...\n",
      "0:00:00.003847\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9276, 'reflen': 9730, 'guess': [9276, 8252, 7228, 6205], 'correct': [5370, 2037, 829, 281]}\n",
      "ratio: 0.9533401849947633\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.242\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-05 22:34:31,722 - INFO: eval_beam_3 SPIDEr: 0.2421\n",
      "loading annotations into memory...\n",
      "0:00:00.003863\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9074, 'reflen': 9632, 'guess': [9074, 8050, 7026, 6003], 'correct': [5262, 2006, 841, 294]}\n",
      "ratio: 0.9420681063121945\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.357\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.378\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-05 22:35:06,258 - INFO: eval_beam_4 SPIDEr: 0.2442\n",
      "2021-12-05 22:35:45,650 - INFO: | epoch  15 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 393.89 | loss-text 3.2233\n",
      "2021-12-05 22:36:25,211 - INFO: | epoch  15 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 395.59 | loss-text 3.2078\n",
      "2021-12-05 22:37:04,724 - INFO: | epoch  15 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.13 | loss-text 3.2090\n",
      "2021-12-05 22:37:44,405 - INFO: | epoch  15 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 396.80 | loss-text 3.2202\n",
      "2021-12-05 22:38:24,206 - INFO: | epoch  15 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 398.00 | loss-text 3.1851\n",
      "2021-12-05 22:39:04,246 - INFO: | epoch  15 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 400.39 | loss-text 3.2177\n",
      "2021-12-05 22:39:43,954 - INFO: | epoch  15 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 397.07 | loss-text 3.1929\n",
      "2021-12-05 22:40:23,780 - INFO: | epoch  15 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.26 | loss-text 3.2205\n",
      "2021-12-05 22:41:03,981 - INFO: | epoch  15 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 402.00 | loss-text 3.1670\n",
      "2021-12-05 22:41:43,846 - INFO: | epoch  15 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 398.65 | loss-text 3.1836\n",
      "2021-12-05 22:42:23,410 - INFO: | epoch  15 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 395.63 | loss-text 3.1946\n",
      "2021-12-05 22:43:03,259 - INFO: | epoch  15 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 398.49 | loss-text 3.2526\n",
      "2021-12-05 22:43:42,570 - INFO: | epoch  15 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 393.10 | loss-text 3.1843\n",
      "2021-12-05 22:44:22,310 - INFO: | epoch  15 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 397.40 | loss-text 3.2207\n",
      "2021-12-05 22:45:02,469 - INFO: | epoch  15 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 401.58 | loss-text 3.2183\n",
      "2021-12-05 22:45:42,157 - INFO: | epoch  15 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 396.88 | loss-text 3.2066\n",
      "2021-12-05 22:46:21,840 - INFO: | epoch  15 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 396.83 | loss-text 3.1751\n",
      "2021-12-05 22:47:02,007 - INFO: | epoch  15 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 401.66 | loss-text 3.2413\n",
      "2021-12-05 22:47:41,503 - INFO: | epoch  15 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 394.96 | loss-text 3.2187\n",
      "2021-12-05 22:48:21,442 - INFO: | epoch  15 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 399.38 | loss-text 3.2176\n",
      "2021-12-05 22:49:01,213 - INFO: | epoch  15 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 397.71 | loss-text 3.1754\n",
      "2021-12-05 22:49:40,772 - INFO: | epoch  15 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 395.58 | loss-text 3.2295\n",
      "2021-12-05 22:50:20,477 - INFO: | epoch  15 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.04 | loss-text 3.1935\n",
      "2021-12-05 22:50:59,687 - INFO: | epoch  15 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 392.09 | loss-text 3.2425\n",
      "2021-12-05 22:51:39,205 - INFO: | epoch  15 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 395.18 | loss-text 3.2500\n",
      "2021-12-05 22:52:18,754 - INFO: | epoch  15 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 395.48 | loss-text 3.1944\n",
      "2021-12-05 22:52:58,451 - INFO: | epoch  15 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 396.97 | loss-text 3.1832\n",
      "2021-12-05 22:53:38,523 - INFO: | epoch  15 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 400.71 | loss-text 3.2291\n",
      "2021-12-05 22:54:18,213 - INFO: | epoch  15 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 396.89 | loss-text 3.2265\n",
      "2021-12-05 22:54:57,904 - INFO: | epoch  15 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 396.90 | loss-text 3.1788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003839\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10344, 'reflen': 10404, 'guess': [10344, 9320, 8296, 7272], 'correct': [5600, 2004, 744, 236]}\n",
      "ratio: 0.9942329873124764\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.338\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.224\n",
      "2021-12-05 22:55:44,945 - INFO: eval_greddy SPIDEr: 0.2244\n",
      "loading annotations into memory...\n",
      "0:00:00.003993\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9414, 'reflen': 9804, 'guess': [9414, 8390, 7366, 6342], 'correct': [5382, 1973, 772, 246]}\n",
      "ratio: 0.9602203182373561\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-05 22:56:13,222 - INFO: eval_beam_2 SPIDEr: 0.2396\n",
      "loading annotations into memory...\n",
      "0:00:00.003854\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9075, 'reflen': 9621, 'guess': [9075, 8051, 7027, 6003], 'correct': [5227, 1967, 807, 276]}\n",
      "ratio: 0.9432491425006815\n",
      "Bleu_1: 0.542\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.108\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-05 22:56:43,512 - INFO: eval_beam_3 SPIDEr: 0.2344\n",
      "loading annotations into memory...\n",
      "0:00:00.003839\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8852, 'reflen': 9489, 'guess': [8852, 7828, 6804, 5780], 'correct': [5163, 1966, 804, 278]}\n",
      "ratio: 0.9328696385287245\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-05 22:57:18,459 - INFO: eval_beam_4 SPIDEr: 0.2399\n",
      "2021-12-05 22:57:57,851 - INFO: | epoch  16 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 393.89 | loss-text 3.1848\n",
      "2021-12-05 22:58:37,145 - INFO: | epoch  16 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 392.93 | loss-text 3.2060\n",
      "2021-12-05 22:59:16,401 - INFO: | epoch  16 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 392.55 | loss-text 3.1798\n",
      "2021-12-05 22:59:55,817 - INFO: | epoch  16 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 394.16 | loss-text 3.1286\n",
      "2021-12-05 23:00:35,681 - INFO: | epoch  16 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 398.63 | loss-text 3.1642\n",
      "2021-12-05 23:01:14,990 - INFO: | epoch  16 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 393.09 | loss-text 3.2226\n",
      "2021-12-05 23:01:54,566 - INFO: | epoch  16 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 395.75 | loss-text 3.1526\n",
      "2021-12-05 23:02:34,173 - INFO: | epoch  16 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 396.06 | loss-text 3.2050\n",
      "2021-12-05 23:05:13,318 - INFO: | epoch  16 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 396.44 | loss-text 3.1536\n",
      "2021-12-05 23:05:53,160 - INFO: | epoch  16 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 398.42 | loss-text 3.2014\n",
      "2021-12-05 23:06:32,990 - INFO: | epoch  16 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 398.29 | loss-text 3.2271\n",
      "2021-12-05 23:07:12,991 - INFO: | epoch  16 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 400.00 | loss-text 3.1696\n",
      "2021-12-05 23:07:52,608 - INFO: | epoch  16 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 396.17 | loss-text 3.1356\n",
      "2021-12-05 23:08:32,309 - INFO: | epoch  16 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.00 | loss-text 3.1149\n",
      "2021-12-05 23:09:12,057 - INFO: | epoch  16 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 397.47 | loss-text 3.1482\n",
      "2021-12-05 23:11:51,359 - INFO: | epoch  16 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 398.35 | loss-text 3.1778\n",
      "2021-12-05 23:12:31,111 - INFO: | epoch  16 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.52 | loss-text 3.1533\n",
      "2021-12-05 23:13:10,864 - INFO: | epoch  16 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.52 | loss-text 3.2104\n",
      "2021-12-05 23:13:50,616 - INFO: | epoch  16 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.52 | loss-text 3.2007\n",
      "2021-12-05 23:14:30,151 - INFO: | epoch  16 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 395.34 | loss-text 3.2163\n",
      "2021-12-05 23:15:10,080 - INFO: | epoch  16 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 399.29 | loss-text 3.2129\n",
      "2021-12-05 23:15:49,673 - INFO: | epoch  16 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 395.92 | loss-text 3.1977\n",
      "2021-12-05 23:16:29,610 - INFO: | epoch  16 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 399.37 | loss-text 3.1715\n",
      "2021-12-05 23:17:09,418 - INFO: | epoch  16 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 398.07 | loss-text 3.1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003775\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9700, 'reflen': 9979, 'guess': [9700, 8677, 7654, 6631], 'correct': [5503, 1973, 716, 207]}\n",
      "ratio: 0.9720412867019769\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.223\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.350\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-05 23:17:55,772 - INFO: eval_greddy SPIDEr: 0.2313\n",
      "loading annotations into memory...\n",
      "0:00:00.003833\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9126, 'reflen': 9649, 'guess': [9126, 8102, 7079, 6056], 'correct': [5370, 2050, 830, 276]}\n",
      "ratio: 0.9457974919679816\n",
      "Bleu_1: 0.556\n",
      "Bleu_2: 0.364\n",
      "Bleu_3: 0.245\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.375\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.385\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.250\n",
      "2021-12-05 23:18:23,261 - INFO: eval_beam_2 SPIDEr: 0.2498\n",
      "loading annotations into memory...\n",
      "0:00:00.003832\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8780, 'reflen': 9469, 'guess': [8780, 7756, 6733, 5710], 'correct': [5254, 2033, 849, 281]}\n",
      "ratio: 0.9272362445875036\n",
      "Bleu_1: 0.553\n",
      "Bleu_2: 0.366\n",
      "Bleu_3: 0.250\n",
      "Bleu_4: 0.163\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.377\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.387\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.250\n",
      "2021-12-05 23:18:53,031 - INFO: eval_beam_3 SPIDEr: 0.2503\n",
      "loading annotations into memory...\n",
      "0:00:00.004063\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8615, 'reflen': 9365, 'guess': [8615, 7591, 6568, 5545], 'correct': [5168, 1996, 839, 295]}\n",
      "ratio: 0.9199145755471522\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.364\n",
      "Bleu_3: 0.249\n",
      "Bleu_4: 0.166\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.374\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.383\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-05 23:19:26,400 - INFO: eval_beam_4 SPIDEr: 0.2465\n",
      "2021-12-05 23:20:05,488 - INFO: | epoch  17 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 390.85 | loss-text 3.0821\n",
      "2021-12-05 23:20:45,051 - INFO: | epoch  17 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 395.61 | loss-text 3.1265\n",
      "2021-12-05 23:21:24,508 - INFO: | epoch  17 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 394.56 | loss-text 3.1572\n",
      "2021-12-05 23:22:03,724 - INFO: | epoch  17 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 392.16 | loss-text 3.1643\n",
      "2021-12-05 23:22:43,225 - INFO: | epoch  17 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 395.00 | loss-text 3.1246\n",
      "2021-12-05 23:23:22,993 - INFO: | epoch  17 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.67 | loss-text 3.1967\n",
      "2021-12-05 23:24:02,924 - INFO: | epoch  17 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 399.31 | loss-text 3.0943\n",
      "2021-12-05 23:24:42,793 - INFO: | epoch  17 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.68 | loss-text 3.1759\n",
      "2021-12-05 23:25:22,774 - INFO: | epoch  17 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 399.80 | loss-text 3.1187\n",
      "2021-12-05 23:26:02,594 - INFO: | epoch  17 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 398.20 | loss-text 3.1637\n",
      "2021-12-05 23:26:42,679 - INFO: | epoch  17 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 400.85 | loss-text 3.1108\n",
      "2021-12-05 23:27:22,750 - INFO: | epoch  17 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 400.70 | loss-text 3.1520\n",
      "2021-12-05 23:28:02,374 - INFO: | epoch  17 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 396.23 | loss-text 3.1708\n",
      "2021-12-05 23:28:42,340 - INFO: | epoch  17 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 399.65 | loss-text 3.1547\n",
      "2021-12-05 23:29:22,097 - INFO: | epoch  17 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.56 | loss-text 3.1869\n",
      "2021-12-05 23:30:01,970 - INFO: | epoch  17 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 398.73 | loss-text 3.1976\n",
      "2021-12-05 23:30:41,577 - INFO: | epoch  17 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 396.06 | loss-text 3.1370\n",
      "2021-12-05 23:31:21,298 - INFO: | epoch  17 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 397.20 | loss-text 3.1568\n",
      "2021-12-05 23:34:00,341 - INFO: | epoch  17 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 399.10 | loss-text 3.1766\n",
      "2021-12-05 23:34:40,060 - INFO: | epoch  17 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.19 | loss-text 3.1350\n",
      "2021-12-05 23:35:19,607 - INFO: | epoch  17 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 395.47 | loss-text 3.1454\n",
      "2021-12-05 23:35:59,654 - INFO: | epoch  17 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 400.46 | loss-text 3.2071\n",
      "2021-12-05 23:36:39,393 - INFO: | epoch  17 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.39 | loss-text 3.1896\n",
      "2021-12-05 23:37:18,761 - INFO: | epoch  17 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 393.68 | loss-text 3.1401\n",
      "2021-12-05 23:37:58,451 - INFO: | epoch  17 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 396.89 | loss-text 3.2115\n",
      "2021-12-05 23:38:38,072 - INFO: | epoch  17 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 396.20 | loss-text 3.1697\n",
      "2021-12-05 23:39:18,083 - INFO: | epoch  17 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 400.10 | loss-text 3.1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003837\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10419, 'reflen': 10494, 'guess': [10419, 9395, 8371, 7347], 'correct': [5679, 1980, 734, 225]}\n",
      "ratio: 0.9928530588907001\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.336\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.338\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2021-12-05 23:40:05,454 - INFO: eval_greddy SPIDEr: 0.2254\n",
      "loading annotations into memory...\n",
      "0:00:00.004018\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9756, 'reflen': 10009, 'guess': [9756, 8732, 7708, 6684], 'correct': [5578, 2029, 808, 264]}\n",
      "ratio: 0.9747227495253297\n",
      "Bleu_1: 0.557\n",
      "Bleu_2: 0.355\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.382\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.249\n",
      "2021-12-05 23:40:33,740 - INFO: eval_beam_2 SPIDEr: 0.2490\n",
      "loading annotations into memory...\n",
      "0:00:00.003984\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9370, 'reflen': 9758, 'guess': [9370, 8346, 7322, 6298], 'correct': [5458, 2052, 843, 301]}\n",
      "ratio: 0.9602377536379422\n",
      "Bleu_1: 0.559\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.372\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.391\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.253\n",
      "2021-12-05 23:41:04,545 - INFO: eval_beam_3 SPIDEr: 0.2533\n",
      "loading annotations into memory...\n",
      "0:00:00.003938\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9099, 'reflen': 9605, 'guess': [9099, 8075, 7051, 6027], 'correct': [5314, 2013, 844, 300]}\n",
      "ratio: 0.9473191046329049\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.361\n",
      "Bleu_3: 0.245\n",
      "Bleu_4: 0.162\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.391\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.252\n",
      "2021-12-05 23:41:39,608 - INFO: eval_beam_4 SPIDEr: 0.2523\n",
      "2021-12-05 23:42:18,844 - INFO: | epoch  18 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 392.33 | loss-text 3.1465\n",
      "2021-12-05 23:42:58,565 - INFO: | epoch  18 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 397.21 | loss-text 3.1307\n",
      "2021-12-05 23:43:38,148 - INFO: | epoch  18 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.82 | loss-text 3.0769\n",
      "2021-12-05 23:44:17,511 - INFO: | epoch  18 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 393.63 | loss-text 3.1422\n",
      "2021-12-05 23:44:57,518 - INFO: | epoch  18 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 400.06 | loss-text 3.1264\n",
      "2021-12-05 23:45:37,251 - INFO: | epoch  18 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.32 | loss-text 3.1090\n",
      "2021-12-05 23:46:16,844 - INFO: | epoch  18 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 395.93 | loss-text 3.1878\n",
      "2021-12-05 23:46:56,832 - INFO: | epoch  18 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 399.87 | loss-text 3.1561\n",
      "2021-12-05 23:47:36,454 - INFO: | epoch  18 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 396.21 | loss-text 3.1494\n",
      "2021-12-05 23:48:16,364 - INFO: | epoch  18 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 399.10 | loss-text 3.1420\n",
      "2021-12-05 23:48:56,234 - INFO: | epoch  18 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 398.69 | loss-text 3.1057\n",
      "2021-12-05 23:49:35,547 - INFO: | epoch  18 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 393.13 | loss-text 3.1187\n",
      "2021-12-05 23:50:15,069 - INFO: | epoch  18 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 395.21 | loss-text 3.1294\n",
      "2021-12-05 23:52:14,557 - INFO: | epoch  18 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 396.42 | loss-text 3.1250\n",
      "2021-12-05 23:52:54,258 - INFO: | epoch  18 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.01 | loss-text 3.1206\n",
      "2021-12-05 23:53:34,275 - INFO: | epoch  18 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 400.16 | loss-text 3.1411\n",
      "2021-12-05 23:54:14,484 - INFO: | epoch  18 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 402.08 | loss-text 3.1516\n",
      "2021-12-05 23:54:53,923 - INFO: | epoch  18 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 394.39 | loss-text 3.1719\n",
      "2021-12-05 23:55:33,532 - INFO: | epoch  18 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 396.08 | loss-text 3.1206\n",
      "2021-12-05 23:56:13,380 - INFO: | epoch  18 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 398.47 | loss-text 3.0839\n",
      "2021-12-05 23:56:53,427 - INFO: | epoch  18 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 400.46 | loss-text 3.1481\n",
      "2021-12-05 23:57:33,329 - INFO: | epoch  18 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 399.01 | loss-text 3.1195\n",
      "2021-12-05 23:58:13,089 - INFO: | epoch  18 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.59 | loss-text 3.1499\n",
      "2021-12-05 23:58:52,865 - INFO: | epoch  18 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.75 | loss-text 3.1549\n",
      "2021-12-05 23:59:32,687 - INFO: | epoch  18 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 398.21 | loss-text 3.0930\n",
      "2021-12-06 00:00:12,424 - INFO: | epoch  18 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 397.37 | loss-text 3.1611\n",
      "2021-12-06 00:00:51,969 - INFO: | epoch  18 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 395.44 | loss-text 3.1230\n",
      "2021-12-06 00:01:31,486 - INFO: | epoch  18 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 395.17 | loss-text 3.1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003860\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10354, 'reflen': 10402, 'guess': [10354, 9330, 8306, 7282], 'correct': [5664, 1955, 704, 228]}\n",
      "ratio: 0.9953855027878297\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.212\n",
      "Bleu_4: 0.131\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.338\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2021-12-06 00:02:18,451 - INFO: eval_greddy SPIDEr: 0.2246\n",
      "loading annotations into memory...\n",
      "0:00:00.003819\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9545, 'reflen': 9905, 'guess': [9545, 8521, 7497, 6473], 'correct': [5449, 1978, 755, 254]}\n",
      "ratio: 0.963654719838368\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-06 00:02:48,917 - INFO: eval_beam_2 SPIDEr: 0.2427\n",
      "loading annotations into memory...\n",
      "0:00:00.003825\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9199, 'reflen': 9701, 'guess': [9199, 8175, 7151, 6127], 'correct': [5308, 1972, 794, 274]}\n",
      "ratio: 0.948252757447588\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.383\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.248\n",
      "2021-12-06 00:03:19,908 - INFO: eval_beam_3 SPIDEr: 0.2476\n",
      "loading annotations into memory...\n",
      "0:00:00.003889\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8974, 'reflen': 9553, 'guess': [8974, 7950, 6926, 5902], 'correct': [5205, 1961, 793, 265]}\n",
      "ratio: 0.9393907672981325\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.355\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-06 00:03:55,240 - INFO: eval_beam_4 SPIDEr: 0.2402\n",
      "2021-12-06 00:04:34,660 - INFO: | epoch  19 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.17 | loss-text 3.0855\n",
      "2021-12-06 00:05:13,930 - INFO: | epoch  19 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 392.68 | loss-text 3.1525\n",
      "2021-12-06 00:05:53,472 - INFO: | epoch  19 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.42 | loss-text 3.1180\n",
      "2021-12-06 00:06:33,053 - INFO: | epoch  19 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.80 | loss-text 3.0894\n",
      "2021-12-06 00:07:12,482 - INFO: | epoch  19 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 394.28 | loss-text 3.1031\n",
      "2021-12-06 00:07:52,564 - INFO: | epoch  19 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 400.82 | loss-text 3.1013\n",
      "2021-12-06 00:09:51,474 - INFO: | epoch  19 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 395.76 | loss-text 3.1260\n",
      "2021-12-06 00:10:31,055 - INFO: | epoch  19 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 395.81 | loss-text 3.1662\n",
      "2021-12-06 00:11:10,984 - INFO: | epoch  19 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 399.28 | loss-text 3.0822\n",
      "2021-12-06 00:11:50,833 - INFO: | epoch  19 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 398.48 | loss-text 3.1368\n",
      "2021-12-06 00:12:30,710 - INFO: | epoch  19 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 398.76 | loss-text 3.1292\n",
      "2021-12-06 00:13:10,571 - INFO: | epoch  19 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 398.61 | loss-text 3.1378\n",
      "2021-12-06 00:13:50,076 - INFO: | epoch  19 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 395.04 | loss-text 3.1202\n",
      "2021-12-06 00:14:29,676 - INFO: | epoch  19 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 395.99 | loss-text 3.1363\n",
      "2021-12-06 00:15:09,434 - INFO: | epoch  19 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.57 | loss-text 3.1189\n",
      "2021-12-06 00:15:49,269 - INFO: | epoch  19 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 398.35 | loss-text 3.1180\n",
      "2021-12-06 00:16:29,104 - INFO: | epoch  19 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 398.34 | loss-text 3.0850\n",
      "2021-12-06 00:17:08,857 - INFO: | epoch  19 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 397.53 | loss-text 3.1822\n",
      "2021-12-06 00:17:48,777 - INFO: | epoch  19 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 399.20 | loss-text 3.1434\n",
      "2021-12-06 00:18:28,193 - INFO: | epoch  19 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 394.15 | loss-text 3.0535\n",
      "2021-12-06 00:19:07,761 - INFO: | epoch  19 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 395.67 | loss-text 3.0914\n",
      "2021-12-06 00:19:47,576 - INFO: | epoch  19 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.15 | loss-text 3.1439\n",
      "2021-12-06 00:20:27,692 - INFO: | epoch  19 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 401.15 | loss-text 3.1432\n",
      "2021-12-06 00:21:07,541 - INFO: | epoch  19 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 398.48 | loss-text 3.0877\n",
      "2021-12-06 00:21:47,485 - INFO: | epoch  19 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 399.44 | loss-text 3.1530\n",
      "2021-12-06 00:22:27,216 - INFO: | epoch  19 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 397.30 | loss-text 3.0872\n",
      "2021-12-06 00:23:07,190 - INFO: | epoch  19 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 399.73 | loss-text 3.0962\n",
      "2021-12-06 00:23:47,104 - INFO: | epoch  19 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 399.14 | loss-text 3.1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003862\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10043, 'reflen': 10195, 'guess': [10043, 9019, 7995, 6971], 'correct': [5493, 1911, 671, 200]}\n",
      "ratio: 0.9850907307502712\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.335\n",
      "Bleu_3: 0.210\n",
      "Bleu_4: 0.127\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.339\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.225\n",
      "2021-12-06 00:24:35,239 - INFO: eval_greddy SPIDEr: 0.2246\n",
      "loading annotations into memory...\n",
      "0:00:00.003768\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9313, 'reflen': 9748, 'guess': [9313, 8289, 7265, 6241], 'correct': [5422, 2102, 829, 273]}\n",
      "ratio: 0.9553754616330574\n",
      "Bleu_1: 0.556\n",
      "Bleu_2: 0.367\n",
      "Bleu_3: 0.245\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.170\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.375\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.385\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.251\n",
      "2021-12-06 00:25:03,294 - INFO: eval_beam_2 SPIDEr: 0.2508\n",
      "loading annotations into memory...\n",
      "0:00:00.003890\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8997, 'reflen': 9551, 'guess': [8997, 7973, 6949, 5925], 'correct': [5330, 2073, 848, 292]}\n",
      "ratio: 0.9419956025546077\n",
      "Bleu_1: 0.557\n",
      "Bleu_2: 0.369\n",
      "Bleu_3: 0.250\n",
      "Bleu_4: 0.164\n",
      "computing METEOR score...\n",
      "METEOR: 0.169\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.376\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.391\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.252\n",
      "2021-12-06 00:25:33,185 - INFO: eval_beam_3 SPIDEr: 0.2523\n",
      "loading annotations into memory...\n",
      "0:00:00.003937\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8798, 'reflen': 9453, 'guess': [8798, 7774, 6750, 5726], 'correct': [5208, 2005, 826, 288]}\n",
      "ratio: 0.9307098275678694\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.246\n",
      "Bleu_4: 0.163\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.372\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.384\n",
      "computing SPICE score...\n",
      "2021-12-06 00:28:06,088 - INFO: | epoch  20 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 397.69 | loss-text 3.0578\n",
      "2021-12-06 00:28:45,870 - INFO: | epoch  20 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 397.81 | loss-text 3.0724\n",
      "2021-12-06 00:29:25,866 - INFO: | epoch  20 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 399.96 | loss-text 3.0666\n",
      "2021-12-06 00:30:05,914 - INFO: | epoch  20 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 400.47 | loss-text 3.1227\n",
      "2021-12-06 00:30:45,794 - INFO: | epoch  20 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 398.79 | loss-text 3.1177\n",
      "2021-12-06 00:31:25,202 - INFO: | epoch  20 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 394.08 | loss-text 3.0690\n",
      "2021-12-06 00:32:04,890 - INFO: | epoch  20 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 396.87 | loss-text 3.1062\n",
      "2021-12-06 00:32:44,637 - INFO: | epoch  20 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 397.46 | loss-text 3.1172\n",
      "2021-12-06 00:33:24,569 - INFO: | epoch  20 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 399.31 | loss-text 3.1356\n",
      "2021-12-06 00:34:04,586 - INFO: | epoch  20 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 400.16 | loss-text 3.0631\n",
      "2021-12-06 00:34:44,383 - INFO: | epoch  20 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 397.96 | loss-text 3.0980\n",
      "2021-12-06 00:35:24,654 - INFO: | epoch  20 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 402.70 | loss-text 3.0750\n",
      "2021-12-06 00:36:04,453 - INFO: | epoch  20 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.98 | loss-text 3.0912\n",
      "2021-12-06 00:36:44,246 - INFO: | epoch  20 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 397.93 | loss-text 3.1353\n",
      "2021-12-06 00:37:23,518 - INFO: | epoch  20 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 392.72 | loss-text 3.1047\n",
      "2021-12-06 00:38:03,324 - INFO: | epoch  20 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 398.05 | loss-text 3.0818\n",
      "2021-12-06 00:38:43,199 - INFO: | epoch  20 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 398.74 | loss-text 3.1086\n",
      "2021-12-06 00:39:22,899 - INFO: | epoch  20 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.99 | loss-text 3.1252\n",
      "2021-12-06 00:40:02,516 - INFO: | epoch  20 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 396.16 | loss-text 3.1047\n",
      "2021-12-06 00:40:42,068 - INFO: | epoch  20 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 395.52 | loss-text 3.0910\n",
      "2021-12-06 00:41:21,601 - INFO: | epoch  20 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 395.32 | loss-text 3.0813\n",
      "2021-12-06 00:42:01,419 - INFO: | epoch  20 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.17 | loss-text 3.0598\n",
      "2021-12-06 00:42:41,489 - INFO: | epoch  20 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 400.70 | loss-text 3.1007\n",
      "2021-12-06 00:43:21,428 - INFO: | epoch  20 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 399.38 | loss-text 3.1398\n",
      "2021-12-06 00:44:00,824 - INFO: | epoch  20 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 393.95 | loss-text 3.1207\n",
      "2021-12-06 00:44:40,612 - INFO: | epoch  20 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 397.88 | loss-text 3.1120\n",
      "2021-12-06 00:45:20,174 - INFO: | epoch  20 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 395.61 | loss-text 3.0776\n",
      "2021-12-06 00:45:59,931 - INFO: | epoch  20 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 397.56 | loss-text 3.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003865\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9884, 'reflen': 10057, 'guess': [9884, 8860, 7836, 6812], 'correct': [5529, 1959, 707, 201]}\n",
      "ratio: 0.9827980511085828\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "2021-12-06 00:48:57,305 - INFO: | epoch  21 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.54 | loss-text 3.0830\n",
      "2021-12-06 00:49:36,533 - INFO: | epoch  21 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 392.27 | loss-text 3.0996\n",
      "2021-12-06 00:50:16,166 - INFO: | epoch  21 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.32 | loss-text 3.0729\n",
      "2021-12-06 00:50:55,663 - INFO: | epoch  21 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 394.97 | loss-text 3.0666\n",
      "2021-12-06 00:51:35,371 - INFO: | epoch  21 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 397.08 | loss-text 3.0761\n",
      "2021-12-06 00:52:15,251 - INFO: | epoch  21 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 398.79 | loss-text 3.0688\n",
      "2021-12-06 00:52:54,887 - INFO: | epoch  21 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 396.36 | loss-text 3.1053\n",
      "2021-12-06 00:53:34,395 - INFO: | epoch  21 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 395.07 | loss-text 3.0892\n",
      "2021-12-06 00:54:14,188 - INFO: | epoch  21 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.92 | loss-text 3.0223\n",
      "2021-12-06 00:54:54,110 - INFO: | epoch  21 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 399.22 | loss-text 3.1318\n",
      "2021-12-06 00:55:33,825 - INFO: | epoch  21 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 397.14 | loss-text 3.0641\n",
      "2021-12-06 00:56:13,670 - INFO: | epoch  21 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 398.44 | loss-text 3.0751\n",
      "2021-12-06 00:56:53,605 - INFO: | epoch  21 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 399.35 | loss-text 3.0919\n",
      "2021-12-06 00:57:33,339 - INFO: | epoch  21 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 397.33 | loss-text 3.0493\n",
      "2021-12-06 00:58:12,956 - INFO: | epoch  21 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.17 | loss-text 3.0509\n",
      "2021-12-06 00:58:52,836 - INFO: | epoch  21 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 398.79 | loss-text 3.0612\n",
      "2021-12-06 00:59:32,647 - INFO: | epoch  21 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 398.11 | loss-text 3.0543\n",
      "2021-12-06 01:00:12,487 - INFO: | epoch  21 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 398.38 | loss-text 3.0253\n",
      "2021-12-06 01:00:52,081 - INFO: | epoch  21 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 395.94 | loss-text 3.0803\n",
      "2021-12-06 01:01:32,028 - INFO: | epoch  21 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 399.46 | loss-text 3.0853\n",
      "2021-12-06 01:02:11,938 - INFO: | epoch  21 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 399.10 | loss-text 3.0593\n",
      "2021-12-06 01:02:51,767 - INFO: | epoch  21 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 398.28 | loss-text 3.0863\n",
      "2021-12-06 01:03:31,534 - INFO: | epoch  21 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.67 | loss-text 3.0907\n",
      "2021-12-06 01:04:11,343 - INFO: | epoch  21 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.09 | loss-text 3.0722\n",
      "2021-12-06 01:04:51,223 - INFO: | epoch  21 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 398.79 | loss-text 3.0867\n",
      "2021-12-06 01:06:50,140 - INFO: | epoch  21 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 394.77 | loss-text 3.0703\n",
      "2021-12-06 01:07:29,986 - INFO: | epoch  21 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 398.45 | loss-text 3.0391\n",
      "2021-12-06 01:08:09,945 - INFO: | epoch  21 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 399.59 | loss-text 3.0649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003877\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10374, 'reflen': 10448, 'guess': [10374, 9350, 8326, 7302], 'correct': [5744, 2075, 748, 210]}\n",
      "ratio: 0.992917304747225\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.348\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.353\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-06 01:08:56,484 - INFO: eval_greddy SPIDEr: 0.2338\n",
      "loading annotations into memory...\n",
      "0:00:00.003799\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9568, 'reflen': 9892, 'guess': [9568, 8544, 7521, 6498], 'correct': [5572, 2126, 833, 272]}\n",
      "ratio: 0.9672462596036223\n",
      "Bleu_1: 0.563\n",
      "Bleu_2: 0.368\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.171\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.378\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.393\n",
      "computing SPICE score...\n",
      "SPICE: 0.119\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.256\n",
      "2021-12-06 01:09:24,703 - INFO: eval_beam_2 SPIDEr: 0.2562\n",
      "loading annotations into memory...\n",
      "0:00:00.003879\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9177, 'reflen': 9644, 'guess': [9177, 8153, 7130, 6107], 'correct': [5378, 2093, 874, 303]}\n",
      "ratio: 0.9515761094980348\n",
      "Bleu_1: 0.557\n",
      "Bleu_2: 0.369\n",
      "Bleu_3: 0.251\n",
      "Bleu_4: 0.165\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.375\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.398\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.257\n",
      "2021-12-06 01:09:55,359 - INFO: eval_beam_3 SPIDEr: 0.2573\n",
      "loading annotations into memory...\n",
      "0:00:00.003970\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9008, 'reflen': 9561, 'guess': [9008, 7984, 6961, 5938], 'correct': [5286, 2067, 865, 314]}\n",
      "ratio: 0.9421608618344376\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.367\n",
      "Bleu_3: 0.250\n",
      "Bleu_4: 0.167\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.372\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.402\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.259\n",
      "2021-12-06 01:10:29,629 - INFO: eval_beam_4 SPIDEr: 0.2590\n",
      "2021-12-06 01:11:09,043 - INFO: | epoch  22 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.11 | loss-text 3.0349\n",
      "2021-12-06 01:11:48,742 - INFO: | epoch  22 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 396.98 | loss-text 3.0418\n",
      "2021-12-06 01:12:28,226 - INFO: | epoch  22 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 394.83 | loss-text 3.0091\n",
      "2021-12-06 01:13:07,703 - INFO: | epoch  22 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 394.76 | loss-text 3.0094\n",
      "2021-12-06 01:13:47,429 - INFO: | epoch  22 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 397.26 | loss-text 3.0684\n",
      "2021-12-06 01:14:27,197 - INFO: | epoch  22 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.67 | loss-text 3.0678\n",
      "2021-12-06 01:15:07,069 - INFO: | epoch  22 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 398.71 | loss-text 3.0553\n",
      "2021-12-06 01:15:46,875 - INFO: | epoch  22 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.05 | loss-text 3.0123\n",
      "2021-12-06 01:16:27,018 - INFO: | epoch  22 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 401.42 | loss-text 3.0429\n",
      "2021-12-06 01:17:06,604 - INFO: | epoch  22 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 395.85 | loss-text 3.0467\n",
      "2021-12-06 01:17:46,526 - INFO: | epoch  22 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 399.21 | loss-text 3.0200\n",
      "2021-12-06 01:18:26,193 - INFO: | epoch  22 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 396.66 | loss-text 3.0791\n",
      "2021-12-06 01:19:06,080 - INFO: | epoch  22 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 398.86 | loss-text 3.0292\n",
      "2021-12-06 01:19:45,674 - INFO: | epoch  22 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 395.94 | loss-text 3.0798\n",
      "2021-12-06 01:20:25,363 - INFO: | epoch  22 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.87 | loss-text 3.0372\n",
      "2021-12-06 01:21:05,094 - INFO: | epoch  22 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 397.31 | loss-text 3.0507\n",
      "2021-12-06 01:21:45,065 - INFO: | epoch  22 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 399.70 | loss-text 3.0483\n",
      "2021-12-06 01:24:23,942 - INFO: | epoch  22 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 398.43 | loss-text 3.0868\n",
      "2021-12-06 01:25:03,693 - INFO: | epoch  22 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 397.50 | loss-text 3.0553\n",
      "2021-12-06 01:25:43,515 - INFO: | epoch  22 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 398.21 | loss-text 3.0792\n",
      "2021-12-06 01:26:23,172 - INFO: | epoch  22 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 396.57 | loss-text 3.0973\n",
      "2021-12-06 01:27:02,924 - INFO: | epoch  22 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.52 | loss-text 3.0651\n",
      "2021-12-06 01:27:42,511 - INFO: | epoch  22 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 395.86 | loss-text 3.0600\n",
      "2021-12-06 01:28:22,255 - INFO: | epoch  22 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 397.44 | loss-text 3.0457\n",
      "2021-12-06 01:29:02,031 - INFO: | epoch  22 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 397.75 | loss-text 3.0712\n",
      "2021-12-06 01:29:42,094 - INFO: | epoch  22 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 400.63 | loss-text 3.0899\n",
      "2021-12-06 01:30:21,749 - INFO: | epoch  22 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 396.54 | loss-text 3.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003832\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10513, 'reflen': 10493, 'guess': [10513, 9489, 8465, 7441], 'correct': [5771, 2032, 730, 226]}\n",
      "ratio: 1.0019060325930618\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.346\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.229\n",
      "2021-12-06 01:31:09,513 - INFO: eval_greddy SPIDEr: 0.2292\n",
      "loading annotations into memory...\n",
      "0:00:00.003834\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9639, 'reflen': 9888, 'guess': [9639, 8615, 7591, 6567], 'correct': [5538, 2023, 773, 263]}\n",
      "ratio: 0.9748179611649499\n",
      "Bleu_1: 0.560\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.233\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-06 01:31:37,911 - INFO: eval_beam_2 SPIDEr: 0.2415\n",
      "loading annotations into memory...\n",
      "0:00:00.003774\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9293, 'reflen': 9694, 'guess': [9293, 8269, 7245, 6221], 'correct': [5416, 2015, 809, 286]}\n",
      "ratio: 0.9586342067257109\n",
      "Bleu_1: 0.558\n",
      "Bleu_2: 0.361\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.387\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.251\n",
      "2021-12-06 01:32:08,738 - INFO: eval_beam_3 SPIDEr: 0.2507\n",
      "loading annotations into memory...\n",
      "0:00:00.003950\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9097, 'reflen': 9600, 'guess': [9097, 8073, 7049, 6025], 'correct': [5292, 1992, 812, 299]}\n",
      "ratio: 0.9476041666665679\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.382\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.247\n",
      "2021-12-06 01:32:44,033 - INFO: eval_beam_4 SPIDEr: 0.2473\n",
      "2021-12-06 01:33:23,159 - INFO: | epoch  23 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 391.23 | loss-text 3.0184\n",
      "2021-12-06 01:34:02,841 - INFO: | epoch  23 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 396.81 | loss-text 3.0192\n",
      "2021-12-06 01:34:42,354 - INFO: | epoch  23 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.13 | loss-text 3.0349\n",
      "2021-12-06 01:35:21,871 - INFO: | epoch  23 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.16 | loss-text 3.0300\n",
      "2021-12-06 01:36:01,605 - INFO: | epoch  23 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 397.33 | loss-text 3.0195\n",
      "2021-12-06 01:36:41,176 - INFO: | epoch  23 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 395.71 | loss-text 3.0247\n",
      "2021-12-06 01:37:20,907 - INFO: | epoch  23 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 397.31 | loss-text 3.0389\n",
      "2021-12-06 01:38:00,882 - INFO: | epoch  23 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 399.74 | loss-text 3.0516\n",
      "2021-12-06 01:38:40,825 - INFO: | epoch  23 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 399.42 | loss-text 3.0277\n",
      "2021-12-06 01:39:20,419 - INFO: | epoch  23 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 395.93 | loss-text 3.0654\n",
      "2021-12-06 01:40:00,317 - INFO: | epoch  23 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 398.98 | loss-text 3.0382\n",
      "2021-12-06 01:40:39,745 - INFO: | epoch  23 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 394.27 | loss-text 3.0203\n",
      "2021-12-06 01:41:19,423 - INFO: | epoch  23 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 396.77 | loss-text 3.0301\n",
      "2021-12-06 01:41:59,414 - INFO: | epoch  23 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 399.91 | loss-text 3.0160\n",
      "2021-12-06 01:42:39,174 - INFO: | epoch  23 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.59 | loss-text 3.0346\n",
      "2021-12-06 01:43:18,575 - INFO: | epoch  23 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 394.00 | loss-text 3.0610\n",
      "2021-12-06 01:43:58,292 - INFO: | epoch  23 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.17 | loss-text 3.0330\n",
      "2021-12-06 01:44:37,999 - INFO: | epoch  23 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 397.05 | loss-text 3.0404\n",
      "2021-12-06 01:45:17,754 - INFO: | epoch  23 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.54 | loss-text 3.0615\n",
      "2021-12-06 01:45:57,394 - INFO: | epoch  23 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.39 | loss-text 3.1049\n",
      "2021-12-06 01:46:37,257 - INFO: | epoch  23 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 398.63 | loss-text 3.0338\n",
      "2021-12-06 01:47:17,261 - INFO: | epoch  23 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 400.03 | loss-text 3.0653\n",
      "2021-12-06 01:47:57,202 - INFO: | epoch  23 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 399.40 | loss-text 3.0247\n",
      "2021-12-06 01:48:37,026 - INFO: | epoch  23 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.24 | loss-text 3.0738\n",
      "2021-12-06 01:49:16,803 - INFO: | epoch  23 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.76 | loss-text 3.0898\n",
      "2021-12-06 01:49:56,187 - INFO: | epoch  23 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 393.83 | loss-text 3.0128\n",
      "2021-12-06 01:50:35,941 - INFO: | epoch  23 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 397.54 | loss-text 3.0477\n",
      "2021-12-06 01:51:15,556 - INFO: | epoch  23 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 396.15 | loss-text 3.0397\n",
      "2021-12-06 01:51:55,427 - INFO: | epoch  23 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 398.70 | loss-text 3.0352\n",
      "2021-12-06 01:52:35,400 - INFO: | epoch  23 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 399.72 | loss-text 3.0219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003852\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10289, 'reflen': 10354, 'guess': [10289, 9265, 8241, 7217], 'correct': [5620, 2019, 751, 228]}\n",
      "ratio: 0.9937222329533519\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.360\n",
      "computing SPICE score...\n",
      "2021-12-06 01:55:38,213 - INFO: | epoch  24 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 397.20 | loss-text 2.9892\n",
      "2021-12-06 01:56:17,984 - INFO: | epoch  24 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 397.70 | loss-text 3.0249\n",
      "2021-12-06 01:56:57,670 - INFO: | epoch  24 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.85 | loss-text 3.0151\n",
      "2021-12-06 01:57:37,272 - INFO: | epoch  24 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 396.01 | loss-text 2.9918\n",
      "2021-12-06 01:58:16,917 - INFO: | epoch  24 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 396.45 | loss-text 3.0032\n",
      "2021-12-06 01:58:56,394 - INFO: | epoch  24 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 394.76 | loss-text 2.9916\n",
      "2021-12-06 01:59:36,087 - INFO: | epoch  24 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 396.92 | loss-text 3.0212\n",
      "2021-12-06 02:00:15,451 - INFO: | epoch  24 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 393.64 | loss-text 2.9710\n",
      "2021-12-06 02:00:55,213 - INFO: | epoch  24 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.61 | loss-text 2.9971\n",
      "2021-12-06 02:01:34,918 - INFO: | epoch  24 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 397.04 | loss-text 3.0643\n",
      "2021-12-06 02:02:14,990 - INFO: | epoch  24 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 400.72 | loss-text 2.9914\n",
      "2021-12-06 02:02:54,389 - INFO: | epoch  24 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 393.98 | loss-text 3.0423\n",
      "2021-12-06 02:03:34,453 - INFO: | epoch  24 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 400.63 | loss-text 2.9781\n",
      "2021-12-06 02:04:14,089 - INFO: | epoch  24 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 396.35 | loss-text 3.0364\n",
      "2021-12-06 02:04:54,007 - INFO: | epoch  24 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 399.18 | loss-text 3.0048\n",
      "2021-12-06 02:05:33,811 - INFO: | epoch  24 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 398.04 | loss-text 3.0028\n",
      "2021-12-06 02:06:13,777 - INFO: | epoch  24 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 399.64 | loss-text 3.0315\n",
      "2021-12-06 02:06:53,643 - INFO: | epoch  24 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 398.66 | loss-text 2.9768\n",
      "2021-12-06 02:07:33,374 - INFO: | epoch  24 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.30 | loss-text 3.0391\n",
      "2021-12-06 02:08:13,188 - INFO: | epoch  24 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 398.13 | loss-text 3.0493\n",
      "2021-12-06 02:08:52,852 - INFO: | epoch  24 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 396.63 | loss-text 3.0207\n",
      "2021-12-06 02:09:32,646 - INFO: | epoch  24 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 397.94 | loss-text 3.0438\n",
      "2021-12-06 02:10:12,396 - INFO: | epoch  24 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.49 | loss-text 3.0628\n",
      "2021-12-06 02:10:52,384 - INFO: | epoch  24 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 399.87 | loss-text 3.0323\n",
      "2021-12-06 02:11:32,182 - INFO: | epoch  24 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.98 | loss-text 3.0481\n",
      "2021-12-06 02:12:11,831 - INFO: | epoch  24 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 396.48 | loss-text 3.0844\n",
      "2021-12-06 02:12:51,711 - INFO: | epoch  24 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 398.79 | loss-text 2.9956\n",
      "2021-12-06 02:14:50,754 - INFO: | epoch  24 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 395.80 | loss-text 3.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003801\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10265, 'reflen': 10332, 'guess': [10265, 9241, 8217, 7193], 'correct': [5696, 2008, 742, 245]}\n",
      "ratio: 0.9935152922956839\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.351\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-06 02:15:38,423 - INFO: eval_greddy SPIDEr: 0.2336\n",
      "loading annotations into memory...\n",
      "0:00:00.003849\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9535, 'reflen': 9884, 'guess': [9535, 8511, 7487, 6463], 'correct': [5491, 2036, 780, 258]}\n",
      "ratio: 0.9646904087413026\n",
      "Bleu_1: 0.555\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.118\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-06 02:16:06,910 - INFO: eval_beam_2 SPIDEr: 0.2461\n",
      "loading annotations into memory...\n",
      "0:00:00.003738\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9171, 'reflen': 9686, 'guess': [9171, 8147, 7123, 6099], 'correct': [5337, 2005, 818, 297]}\n",
      "ratio: 0.9468304769769825\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.386\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.251\n",
      "2021-12-06 02:16:38,107 - INFO: eval_beam_3 SPIDEr: 0.2514\n",
      "loading annotations into memory...\n",
      "0:00:00.003824\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8988, 'reflen': 9573, 'guess': [8988, 7964, 6940, 5916], 'correct': [5257, 2033, 850, 322]}\n",
      "ratio: 0.938890629896486\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.362\n",
      "Bleu_3: 0.247\n",
      "Bleu_4: 0.166\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.372\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.394\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.255\n",
      "2021-12-06 02:17:12,439 - INFO: eval_beam_4 SPIDEr: 0.2546\n",
      "2021-12-06 02:17:52,158 - INFO: | epoch  25 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 397.16 | loss-text 3.0036\n",
      "2021-12-06 02:18:31,411 - INFO: | epoch  25 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 392.52 | loss-text 2.9853\n",
      "2021-12-06 02:19:11,148 - INFO: | epoch  25 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 397.36 | loss-text 2.9677\n",
      "2021-12-06 02:19:50,986 - INFO: | epoch  25 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 398.37 | loss-text 2.9532\n",
      "2021-12-06 02:20:30,844 - INFO: | epoch  25 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 398.58 | loss-text 2.9375\n",
      "2021-12-06 02:21:10,494 - INFO: | epoch  25 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 396.49 | loss-text 3.0019\n",
      "2021-12-06 02:21:50,055 - INFO: | epoch  25 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 395.61 | loss-text 3.0506\n",
      "2021-12-06 02:22:30,154 - INFO: | epoch  25 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 400.98 | loss-text 3.0076\n",
      "2021-12-06 02:23:09,996 - INFO: | epoch  25 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 398.41 | loss-text 2.9598\n",
      "2021-12-06 02:23:49,777 - INFO: | epoch  25 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 397.80 | loss-text 2.9958\n",
      "2021-12-06 02:24:29,454 - INFO: | epoch  25 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 396.77 | loss-text 3.0034\n",
      "2021-12-06 02:25:09,315 - INFO: | epoch  25 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 398.60 | loss-text 2.9987\n",
      "2021-12-06 02:25:49,080 - INFO: | epoch  25 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 397.64 | loss-text 2.9591\n",
      "2021-12-06 02:26:29,083 - INFO: | epoch  25 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 400.03 | loss-text 2.9826\n",
      "2021-12-06 02:27:08,803 - INFO: | epoch  25 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.19 | loss-text 3.0498\n",
      "2021-12-06 02:27:48,104 - INFO: | epoch  25 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 393.00 | loss-text 2.9862\n",
      "2021-12-06 02:28:28,077 - INFO: | epoch  25 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 399.72 | loss-text 3.0199\n",
      "2021-12-06 02:29:08,155 - INFO: | epoch  25 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 400.77 | loss-text 3.0431\n",
      "2021-12-06 02:31:07,326 - INFO: | epoch  25 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 398.00 | loss-text 2.9823\n",
      "2021-12-06 02:31:47,128 - INFO: | epoch  25 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 398.01 | loss-text 3.0003\n",
      "2021-12-06 02:32:26,889 - INFO: | epoch  25 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.61 | loss-text 2.9950\n",
      "2021-12-06 02:33:06,720 - INFO: | epoch  25 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.30 | loss-text 3.0492\n",
      "2021-12-06 02:33:46,492 - INFO: | epoch  25 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.71 | loss-text 2.9772\n",
      "2021-12-06 02:34:26,444 - INFO: | epoch  25 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 399.52 | loss-text 3.0197\n",
      "2021-12-06 02:35:06,199 - INFO: | epoch  25 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 397.55 | loss-text 2.9755\n",
      "2021-12-06 02:35:45,684 - INFO: | epoch  25 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 394.84 | loss-text 3.0351\n",
      "2021-12-06 02:36:25,740 - INFO: | epoch  25 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 400.56 | loss-text 2.9957\n",
      "2021-12-06 02:37:05,495 - INFO: | epoch  25 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 397.54 | loss-text 3.0458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.004033\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10320, 'reflen': 10324, 'guess': [10320, 9296, 8272, 7248], 'correct': [5656, 1982, 729, 229]}\n",
      "ratio: 0.9996125532738279\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.342\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.351\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-06 02:37:52,591 - INFO: eval_greddy SPIDEr: 0.2324\n",
      "loading annotations into memory...\n",
      "0:00:00.003863\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9501, 'reflen': 9798, 'guess': [9501, 8477, 7453, 6429], 'correct': [5470, 2025, 778, 262]}\n",
      "ratio: 0.9696876913654858\n",
      "Bleu_1: 0.558\n",
      "Bleu_2: 0.359\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.169\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.377\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-06 02:38:20,472 - INFO: eval_beam_2 SPIDEr: 0.2462\n",
      "loading annotations into memory...\n",
      "0:00:00.003855\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9223, 'reflen': 9664, 'guess': [9223, 8199, 7175, 6151], 'correct': [5364, 2012, 798, 279]}\n",
      "ratio: 0.9543667218542058\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.383\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.249\n",
      "2021-12-06 02:38:50,384 - INFO: eval_beam_3 SPIDEr: 0.2491\n",
      "loading annotations into memory...\n",
      "0:00:00.003773\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9073, 'reflen': 9584, 'guess': [9073, 8049, 7025, 6001], 'correct': [5306, 2025, 829, 300]}\n",
      "ratio: 0.9466819699498177\n",
      "Bleu_1: 0.553\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.245\n",
      "Bleu_4: 0.162\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.374\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.389\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.252\n",
      "2021-12-06 02:39:24,868 - INFO: eval_beam_4 SPIDEr: 0.2516\n",
      "2021-12-06 02:40:03,962 - INFO: | epoch  26 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 390.91 | loss-text 2.9926\n",
      "2021-12-06 02:40:43,337 - INFO: | epoch  26 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 393.73 | loss-text 2.9993\n",
      "2021-12-06 02:41:22,720 - INFO: | epoch  26 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 393.83 | loss-text 2.9621\n",
      "2021-12-06 02:42:02,321 - INFO: | epoch  26 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 396.00 | loss-text 2.9687\n",
      "2021-12-06 02:42:42,223 - INFO: | epoch  26 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 399.01 | loss-text 2.9895\n",
      "2021-12-06 02:43:21,906 - INFO: | epoch  26 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 396.83 | loss-text 2.9869\n",
      "2021-12-06 02:44:01,531 - INFO: | epoch  26 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 396.24 | loss-text 2.9661\n",
      "2021-12-06 02:44:41,060 - INFO: | epoch  26 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 395.28 | loss-text 2.9580\n",
      "2021-12-06 02:45:20,816 - INFO: | epoch  26 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.55 | loss-text 2.9551\n",
      "2021-12-06 02:46:00,878 - INFO: | epoch  26 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 400.62 | loss-text 2.9801\n",
      "2021-12-06 02:46:40,414 - INFO: | epoch  26 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 395.35 | loss-text 2.9910\n",
      "2021-12-06 02:47:20,117 - INFO: | epoch  26 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 397.03 | loss-text 2.9699\n",
      "2021-12-06 02:49:18,717 - INFO: | epoch  26 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 393.73 | loss-text 2.9775\n",
      "2021-12-06 02:49:58,232 - INFO: | epoch  26 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 395.14 | loss-text 2.9762\n",
      "2021-12-06 02:50:37,852 - INFO: | epoch  26 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 396.19 | loss-text 2.9540\n",
      "2021-12-06 02:51:17,495 - INFO: | epoch  26 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 396.43 | loss-text 3.0037\n",
      "2021-12-06 02:51:57,285 - INFO: | epoch  26 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.89 | loss-text 3.0023\n",
      "2021-12-06 02:52:37,059 - INFO: | epoch  26 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 397.73 | loss-text 3.0091\n",
      "2021-12-06 02:53:16,926 - INFO: | epoch  26 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 398.66 | loss-text 2.9693\n",
      "2021-12-06 02:53:56,836 - INFO: | epoch  26 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 399.10 | loss-text 2.9773\n",
      "2021-12-06 02:54:36,398 - INFO: | epoch  26 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 395.61 | loss-text 3.0218\n",
      "2021-12-06 02:55:16,284 - INFO: | epoch  26 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.85 | loss-text 2.9824\n",
      "2021-12-06 02:55:56,387 - INFO: | epoch  26 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 401.03 | loss-text 2.9885\n",
      "2021-12-06 02:56:36,320 - INFO: | epoch  26 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 399.32 | loss-text 2.9962\n",
      "2021-12-06 02:57:15,949 - INFO: | epoch  26 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 396.28 | loss-text 3.0203\n",
      "2021-12-06 02:57:55,626 - INFO: | epoch  26 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 396.77 | loss-text 3.0194\n",
      "2021-12-06 02:58:35,406 - INFO: | epoch  26 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 397.78 | loss-text 3.0053\n",
      "2021-12-06 02:59:15,172 - INFO: | epoch  26 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 397.66 | loss-text 2.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003807\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10125, 'reflen': 10234, 'guess': [10125, 9101, 8077, 7053], 'correct': [5589, 1984, 725, 242]}\n",
      "ratio: 0.9893492280632217\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.219\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.358\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-06 03:00:02,023 - INFO: eval_greddy SPIDEr: 0.2340\n",
      "loading annotations into memory...\n",
      "0:00:00.003881\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9415, 'reflen': 9824, 'guess': [9415, 8391, 7367, 6343], 'correct': [5367, 1956, 762, 263]}\n",
      "ratio: 0.9583672638435506\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.148\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.375\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-06 03:00:30,328 - INFO: eval_beam_2 SPIDEr: 0.2441\n",
      "loading annotations into memory...\n",
      "0:00:00.003814\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9087, 'reflen': 9632, 'guess': [9087, 8063, 7039, 6015], 'correct': [5299, 1995, 818, 306]}\n",
      "ratio: 0.9434177740862808\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.402\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.258\n",
      "2021-12-06 03:01:01,571 - INFO: eval_beam_3 SPIDEr: 0.2577\n",
      "loading annotations into memory...\n",
      "0:00:00.003909\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8833, 'reflen': 9508, 'guess': [8833, 7809, 6785, 5761], 'correct': [5232, 2021, 828, 304]}\n",
      "ratio: 0.92900715187201\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.246\n",
      "Bleu_4: 0.164\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.374\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.403\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.259\n",
      "2021-12-06 03:01:36,026 - INFO: eval_beam_4 SPIDEr: 0.2586\n",
      "2021-12-06 03:02:14,949 - INFO: | epoch  27 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 389.20 | loss-text 2.9637\n",
      "2021-12-06 03:02:54,367 - INFO: | epoch  27 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 394.17 | loss-text 2.9542\n",
      "2021-12-06 03:03:34,013 - INFO: | epoch  27 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.45 | loss-text 2.9248\n",
      "2021-12-06 03:04:13,488 - INFO: | epoch  27 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 394.75 | loss-text 2.9748\n",
      "2021-12-06 03:04:53,186 - INFO: | epoch  27 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 396.98 | loss-text 2.9721\n",
      "2021-12-06 03:05:32,944 - INFO: | epoch  27 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.58 | loss-text 2.9553\n",
      "2021-12-06 03:07:32,403 - INFO: | epoch  27 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 396.26 | loss-text 2.9475\n",
      "2021-12-06 03:08:12,060 - INFO: | epoch  27 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 396.55 | loss-text 2.9462\n",
      "2021-12-06 03:08:51,538 - INFO: | epoch  27 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 394.78 | loss-text 2.9794\n",
      "2021-12-06 03:09:31,332 - INFO: | epoch  27 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 397.93 | loss-text 2.9645\n",
      "2021-12-06 03:10:11,222 - INFO: | epoch  27 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 398.90 | loss-text 2.9859\n",
      "2021-12-06 03:10:51,036 - INFO: | epoch  27 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 398.13 | loss-text 2.9856\n",
      "2021-12-06 03:11:30,759 - INFO: | epoch  27 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.22 | loss-text 3.0056\n",
      "2021-12-06 03:12:10,529 - INFO: | epoch  27 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 397.70 | loss-text 2.9390\n",
      "2021-12-06 03:12:50,211 - INFO: | epoch  27 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 396.81 | loss-text 2.9696\n",
      "2021-12-06 03:13:29,770 - INFO: | epoch  27 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 395.58 | loss-text 3.0168\n",
      "2021-12-06 03:14:09,749 - INFO: | epoch  27 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 399.78 | loss-text 2.9564\n",
      "2021-12-06 03:14:49,319 - INFO: | epoch  27 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 395.69 | loss-text 2.9925\n",
      "2021-12-06 03:15:29,475 - INFO: | epoch  27 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 401.55 | loss-text 2.9917\n",
      "2021-12-06 03:16:09,299 - INFO: | epoch  27 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 398.24 | loss-text 2.9036\n",
      "2021-12-06 03:16:49,122 - INFO: | epoch  27 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 398.22 | loss-text 2.9282\n",
      "2021-12-06 03:17:28,930 - INFO: | epoch  27 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.07 | loss-text 2.9502\n",
      "2021-12-06 03:18:08,944 - INFO: | epoch  27 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 400.14 | loss-text 2.9837\n",
      "2021-12-06 03:18:48,714 - INFO: | epoch  27 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.69 | loss-text 3.0129\n",
      "2021-12-06 03:19:28,309 - INFO: | epoch  27 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 395.94 | loss-text 2.9644\n",
      "2021-12-06 03:20:08,043 - INFO: | epoch  27 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 397.34 | loss-text 2.9968\n",
      "2021-12-06 03:20:47,932 - INFO: | epoch  27 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 398.88 | loss-text 3.0164\n",
      "2021-12-06 03:21:27,497 - INFO: | epoch  27 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 395.65 | loss-text 2.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003879\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10293, 'reflen': 10372, 'guess': [10293, 9269, 8245, 7221], 'correct': [5712, 2032, 750, 224]}\n",
      "ratio: 0.992383339760799\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.348\n",
      "computing SPICE score...\n",
      "SPICE: 0.117\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.233\n",
      "2021-12-06 03:22:14,772 - INFO: eval_greddy SPIDEr: 0.2327\n",
      "loading annotations into memory...\n",
      "0:00:00.004043\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9576, 'reflen': 9906, 'guess': [9576, 8552, 7528, 6504], 'correct': [5491, 2015, 801, 267]}\n",
      "ratio: 0.9666868564505383\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.355\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.387\n",
      "computing SPICE score...\n",
      "SPICE: 0.119\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.253\n",
      "2021-12-06 03:22:42,862 - INFO: eval_beam_2 SPIDEr: 0.2526\n",
      "loading annotations into memory...\n",
      "0:00:00.003886\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9221, 'reflen': 9678, 'guess': [9221, 8197, 7174, 6151], 'correct': [5366, 2022, 832, 293]}\n",
      "ratio: 0.9527794998965744\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.361\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.398\n",
      "computing SPICE score...\n",
      "SPICE: 0.117\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.258\n",
      "2021-12-06 03:23:14,273 - INFO: eval_beam_3 SPIDEr: 0.2578\n",
      "loading annotations into memory...\n",
      "0:00:00.003828\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9059, 'reflen': 9568, 'guess': [9059, 8035, 7012, 5989], 'correct': [5270, 1993, 821, 288]}\n",
      "ratio: 0.9468018394647839\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.359\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.396\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.256\n",
      "2021-12-06 03:23:48,657 - INFO: eval_beam_4 SPIDEr: 0.2558\n",
      "2021-12-06 03:25:47,271 - INFO: | epoch  28 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.82 | loss-text 2.9672\n",
      "2021-12-06 03:26:26,962 - INFO: | epoch  28 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 396.91 | loss-text 2.9626\n",
      "2021-12-06 03:27:06,382 - INFO: | epoch  28 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 394.19 | loss-text 2.9439\n",
      "2021-12-06 03:27:45,977 - INFO: | epoch  28 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 395.94 | loss-text 2.9642\n",
      "2021-12-06 03:28:25,988 - INFO: | epoch  28 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 400.10 | loss-text 2.9339\n",
      "2021-12-06 03:29:05,795 - INFO: | epoch  28 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.07 | loss-text 2.9295\n",
      "2021-12-06 03:29:45,850 - INFO: | epoch  28 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 400.54 | loss-text 2.9644\n",
      "2021-12-06 03:30:25,581 - INFO: | epoch  28 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 397.30 | loss-text 2.9636\n",
      "2021-12-06 03:31:05,538 - INFO: | epoch  28 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 399.56 | loss-text 2.9674\n",
      "2021-12-06 03:31:45,452 - INFO: | epoch  28 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 399.13 | loss-text 2.9084\n",
      "2021-12-06 03:32:25,251 - INFO: | epoch  28 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 397.98 | loss-text 2.9843\n",
      "2021-12-06 03:33:05,531 - INFO: | epoch  28 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 402.79 | loss-text 2.9401\n",
      "2021-12-06 03:33:45,290 - INFO: | epoch  28 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.59 | loss-text 2.9340\n",
      "2021-12-06 03:34:25,153 - INFO: | epoch  28 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 398.63 | loss-text 2.9473\n",
      "2021-12-06 03:35:05,156 - INFO: | epoch  28 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 400.02 | loss-text 2.9588\n",
      "2021-12-06 03:35:44,702 - INFO: | epoch  28 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 395.45 | loss-text 2.9563\n",
      "2021-12-06 03:36:24,412 - INFO: | epoch  28 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.10 | loss-text 2.9797\n",
      "2021-12-06 03:37:04,529 - INFO: | epoch  28 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 401.16 | loss-text 2.9721\n",
      "2021-12-06 03:37:44,388 - INFO: | epoch  28 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 398.59 | loss-text 2.9539\n",
      "2021-12-06 03:38:23,942 - INFO: | epoch  28 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 395.53 | loss-text 2.9742\n",
      "2021-12-06 03:39:03,833 - INFO: | epoch  28 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 398.90 | loss-text 2.9412\n",
      "2021-12-06 03:39:43,552 - INFO: | epoch  28 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.18 | loss-text 2.9595\n",
      "2021-12-06 03:40:23,011 - INFO: | epoch  28 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 394.59 | loss-text 2.9715\n",
      "2021-12-06 03:42:22,260 - INFO: | epoch  28 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 400.02 | loss-text 2.9597\n",
      "2021-12-06 03:43:02,176 - INFO: | epoch  28 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 399.15 | loss-text 2.9934\n",
      "2021-12-06 03:43:41,906 - INFO: | epoch  28 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 397.30 | loss-text 2.9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003839\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10119, 'reflen': 10217, 'guess': [10119, 9095, 8071, 7047], 'correct': [5660, 2018, 743, 242]}\n",
      "ratio: 0.9904081432904971\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.223\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-06 03:44:29,434 - INFO: eval_greddy SPIDEr: 0.2391\n",
      "loading annotations into memory...\n",
      "0:00:00.003913\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9375, 'reflen': 9721, 'guess': [9375, 8351, 7327, 6303], 'correct': [5516, 2076, 824, 273]}\n",
      "ratio: 0.9644069540169772\n",
      "Bleu_1: 0.567\n",
      "Bleu_2: 0.369\n",
      "Bleu_3: 0.245\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.169\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.377\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.392\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.253\n",
      "2021-12-06 03:44:57,361 - INFO: eval_beam_2 SPIDEr: 0.2535\n",
      "loading annotations into memory...\n",
      "0:00:00.003881\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9126, 'reflen': 9593, 'guess': [9126, 8102, 7078, 6054], 'correct': [5418, 2067, 844, 293]}\n",
      "ratio: 0.9513186698633429\n",
      "Bleu_1: 0.564\n",
      "Bleu_2: 0.370\n",
      "Bleu_3: 0.249\n",
      "Bleu_4: 0.163\n",
      "computing METEOR score...\n",
      "METEOR: 0.169\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.379\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.404\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.258\n",
      "2021-12-06 03:45:28,136 - INFO: eval_beam_3 SPIDEr: 0.2584\n",
      "loading annotations into memory...\n",
      "0:00:00.003962\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8982, 'reflen': 9512, 'guess': [8982, 7958, 6934, 5910], 'correct': [5343, 2033, 846, 312]}\n",
      "ratio: 0.9442809083262254\n",
      "Bleu_1: 0.561\n",
      "Bleu_2: 0.367\n",
      "Bleu_3: 0.250\n",
      "Bleu_4: 0.167\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.376\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.405\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.257\n",
      "2021-12-06 03:46:02,626 - INFO: eval_beam_4 SPIDEr: 0.2575\n",
      "2021-12-06 03:46:42,141 - INFO: | epoch  29 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 395.11 | loss-text 2.9326\n",
      "2021-12-06 03:47:21,574 - INFO: | epoch  29 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 394.32 | loss-text 2.9123\n",
      "2021-12-06 03:48:01,078 - INFO: | epoch  29 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.04 | loss-text 2.8921\n",
      "2021-12-06 03:48:40,488 - INFO: | epoch  29 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 394.10 | loss-text 2.9812\n",
      "2021-12-06 03:49:20,036 - INFO: | epoch  29 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 395.47 | loss-text 2.9065\n",
      "2021-12-06 03:49:59,639 - INFO: | epoch  29 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 396.02 | loss-text 2.9627\n",
      "2021-12-06 03:50:39,772 - INFO: | epoch  29 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 401.32 | loss-text 2.9593\n",
      "2021-12-06 03:51:19,421 - INFO: | epoch  29 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 396.49 | loss-text 2.9360\n",
      "2021-12-06 03:51:59,209 - INFO: | epoch  29 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.87 | loss-text 2.9166\n",
      "2021-12-06 03:52:38,812 - INFO: | epoch  29 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 396.02 | loss-text 2.8737\n",
      "2021-12-06 03:53:18,659 - INFO: | epoch  29 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 398.47 | loss-text 2.9084\n",
      "2021-12-06 03:53:58,164 - INFO: | epoch  29 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 395.04 | loss-text 2.9621\n",
      "2021-12-06 03:54:38,110 - INFO: | epoch  29 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 399.45 | loss-text 2.9054\n",
      "2021-12-06 03:55:17,930 - INFO: | epoch  29 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 398.20 | loss-text 2.9347\n",
      "2021-12-06 03:55:57,601 - INFO: | epoch  29 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.70 | loss-text 2.9215\n",
      "2021-12-06 03:56:37,290 - INFO: | epoch  29 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 396.88 | loss-text 2.9618\n",
      "2021-12-06 03:57:17,068 - INFO: | epoch  29 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.77 | loss-text 2.9268\n",
      "2021-12-06 03:59:16,029 - INFO: | epoch  29 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.81 | loss-text 2.9468\n",
      "2021-12-06 03:59:56,022 - INFO: | epoch  29 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 399.92 | loss-text 2.9562\n",
      "2021-12-06 04:00:35,689 - INFO: | epoch  29 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 396.66 | loss-text 2.9552\n",
      "2021-12-06 04:01:15,502 - INFO: | epoch  29 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 398.13 | loss-text 2.9200\n",
      "2021-12-06 04:01:55,366 - INFO: | epoch  29 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.63 | loss-text 2.9427\n",
      "2021-12-06 04:02:35,623 - INFO: | epoch  29 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 402.57 | loss-text 2.9634\n",
      "2021-12-06 04:03:15,501 - INFO: | epoch  29 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 398.78 | loss-text 2.9012\n",
      "2021-12-06 04:03:55,300 - INFO: | epoch  29 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 397.98 | loss-text 2.9198\n",
      "2021-12-06 04:04:35,306 - INFO: | epoch  29 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 400.06 | loss-text 2.9321\n",
      "2021-12-06 04:05:15,062 - INFO: | epoch  29 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 397.55 | loss-text 2.9360\n",
      "2021-12-06 04:05:54,680 - INFO: | epoch  29 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 396.18 | loss-text 2.9332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003841\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10274, 'reflen': 10310, 'guess': [10274, 9250, 8226, 7202], 'correct': [5671, 2006, 725, 228]}\n",
      "ratio: 0.9965082444227937\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.219\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.117\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-06 04:06:42,878 - INFO: eval_greddy SPIDEr: 0.2408\n",
      "loading annotations into memory...\n",
      "0:00:00.003919\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9541, 'reflen': 9832, 'guess': [9541, 8517, 7493, 6469], 'correct': [5530, 2059, 790, 263]}\n",
      "ratio: 0.9704027664767116\n",
      "Bleu_1: 0.562\n",
      "Bleu_2: 0.363\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.390\n",
      "computing SPICE score...\n",
      "SPICE: 0.117\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.254\n",
      "2021-12-06 04:07:11,386 - INFO: eval_beam_2 SPIDEr: 0.2536\n",
      "loading annotations into memory...\n",
      "0:00:00.003882\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9181, 'reflen': 9641, 'guess': [9181, 8157, 7133, 6109], 'correct': [5362, 2062, 788, 271]}\n",
      "ratio: 0.9522871071464627\n",
      "Bleu_1: 0.555\n",
      "Bleu_2: 0.365\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.396\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.255\n",
      "2021-12-06 04:07:42,191 - INFO: eval_beam_3 SPIDEr: 0.2550\n",
      "loading annotations into memory...\n",
      "0:00:00.003903\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9002, 'reflen': 9539, 'guess': [9002, 7978, 6954, 5930], 'correct': [5264, 2001, 774, 268]}\n",
      "ratio: 0.9437047908584816\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.361\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.390\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.251\n",
      "2021-12-06 04:08:16,828 - INFO: eval_beam_4 SPIDEr: 0.2512\n",
      "2021-12-06 04:08:56,182 - INFO: | epoch  30 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 393.50 | loss-text 2.9082\n",
      "2021-12-06 04:09:35,961 - INFO: | epoch  30 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 397.78 | loss-text 2.9278\n",
      "2021-12-06 04:10:15,534 - INFO: | epoch  30 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.72 | loss-text 2.9072\n",
      "2021-12-06 04:10:54,943 - INFO: | epoch  30 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 394.08 | loss-text 2.8931\n",
      "2021-12-06 04:11:34,524 - INFO: | epoch  30 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 395.80 | loss-text 2.9203\n",
      "2021-12-06 04:12:14,307 - INFO: | epoch  30 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.83 | loss-text 2.9198\n",
      "2021-12-06 04:12:54,326 - INFO: | epoch  30 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 400.18 | loss-text 2.9194\n",
      "2021-12-06 04:13:34,133 - INFO: | epoch  30 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.07 | loss-text 2.9061\n",
      "2021-12-06 04:14:13,529 - INFO: | epoch  30 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 393.95 | loss-text 2.9237\n",
      "2021-12-06 04:14:53,196 - INFO: | epoch  30 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 396.67 | loss-text 2.8944\n",
      "2021-12-06 04:15:33,037 - INFO: | epoch  30 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 398.40 | loss-text 2.9666\n",
      "2021-12-06 04:16:13,144 - INFO: | epoch  30 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 401.07 | loss-text 2.8912\n",
      "2021-12-06 04:16:53,013 - INFO: | epoch  30 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 398.68 | loss-text 2.8819\n",
      "2021-12-06 04:19:32,506 - INFO: | epoch  30 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 398.51 | loss-text 2.9104\n",
      "2021-12-06 04:20:12,270 - INFO: | epoch  30 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 397.63 | loss-text 2.9485\n",
      "2021-12-06 04:20:51,786 - INFO: | epoch  30 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 395.15 | loss-text 2.9820\n",
      "2021-12-06 04:21:31,655 - INFO: | epoch  30 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 398.68 | loss-text 2.9216\n",
      "2021-12-06 04:22:11,451 - INFO: | epoch  30 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 397.96 | loss-text 2.9610\n",
      "2021-12-06 04:22:51,382 - INFO: | epoch  30 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 399.30 | loss-text 2.9264\n",
      "2021-12-06 04:23:30,887 - INFO: | epoch  30 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 395.04 | loss-text 2.9422\n",
      "2021-12-06 04:24:10,809 - INFO: | epoch  30 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 399.21 | loss-text 2.9483\n",
      "2021-12-06 04:24:50,462 - INFO: | epoch  30 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 396.53 | loss-text 2.9219\n",
      "2021-12-06 04:25:30,023 - INFO: | epoch  30 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 395.60 | loss-text 2.9558\n",
      "2021-12-06 04:26:10,144 - INFO: | epoch  30 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 401.21 | loss-text 2.9299\n",
      "2021-12-06 04:26:50,132 - INFO: | epoch  30 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 399.87 | loss-text 2.9369\n",
      "2021-12-06 04:27:29,826 - INFO: | epoch  30 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 396.94 | loss-text 2.9278\n",
      "2021-12-06 04:28:09,869 - INFO: | epoch  30 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 400.42 | loss-text 2.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003831\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10357, 'reflen': 10348, 'guess': [10357, 9333, 8309, 7285], 'correct': [5718, 2039, 781, 267]}\n",
      "ratio: 1.000869733281697\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-06 04:28:57,312 - INFO: eval_greddy SPIDEr: 0.2374\n",
      "loading annotations into memory...\n",
      "0:00:00.003912\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9633, 'reflen': 9921, 'guess': [9633, 8609, 7585, 6561], 'correct': [5478, 2026, 823, 296]}\n",
      "ratio: 0.9709706682793094\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.355\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.381\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.247\n",
      "2021-12-06 04:29:25,711 - INFO: eval_beam_2 SPIDEr: 0.2474\n",
      "loading annotations into memory...\n",
      "0:00:00.003846\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9287, 'reflen': 9703, 'guess': [9287, 8263, 7239, 6215], 'correct': [5342, 2000, 825, 308]}\n",
      "ratio: 0.9571266618570589\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.357\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.385\n",
      "computing SPICE score...\n",
      "SPICE: 0.109\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.247\n",
      "2021-12-06 04:29:56,979 - INFO: eval_beam_3 SPIDEr: 0.2470\n",
      "loading annotations into memory...\n",
      "0:00:00.003877\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9109, 'reflen': 9621, 'guess': [9109, 8085, 7061, 6037], 'correct': [5261, 1988, 834, 306]}\n",
      "ratio: 0.9467830786819512\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.242\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.385\n",
      "computing SPICE score...\n",
      "SPICE: 0.107\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-06 04:30:32,064 - INFO: eval_beam_4 SPIDEr: 0.2462\n",
      "2021-12-06 04:31:11,505 - INFO: | epoch  31 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.38 | loss-text 2.8514\n",
      "2021-12-06 04:31:51,025 - INFO: | epoch  31 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 395.19 | loss-text 2.8840\n",
      "2021-12-06 04:32:30,693 - INFO: | epoch  31 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.67 | loss-text 2.9053\n",
      "2021-12-06 04:33:10,345 - INFO: | epoch  31 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 396.51 | loss-text 2.9379\n",
      "2021-12-06 04:33:49,883 - INFO: | epoch  31 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 395.38 | loss-text 2.8574\n",
      "2021-12-06 04:34:29,805 - INFO: | epoch  31 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 399.21 | loss-text 2.9347\n",
      "2021-12-06 04:37:08,450 - INFO: | epoch  31 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 399.03 | loss-text 2.9194\n",
      "2021-12-06 04:37:48,146 - INFO: | epoch  31 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 396.95 | loss-text 2.9202\n",
      "2021-12-06 04:38:27,786 - INFO: | epoch  31 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 396.39 | loss-text 2.9098\n",
      "2021-12-06 04:39:07,334 - INFO: | epoch  31 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 395.47 | loss-text 2.9249\n",
      "2021-12-06 04:39:47,135 - INFO: | epoch  31 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 398.00 | loss-text 2.8782\n",
      "2021-12-06 04:40:26,733 - INFO: | epoch  31 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 395.97 | loss-text 2.8892\n",
      "2021-12-06 04:41:06,351 - INFO: | epoch  31 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 396.17 | loss-text 2.9366\n",
      "2021-12-06 04:41:46,068 - INFO: | epoch  31 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.16 | loss-text 2.9008\n",
      "2021-12-06 04:42:25,979 - INFO: | epoch  31 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 399.10 | loss-text 2.9314\n",
      "2021-12-06 04:43:05,712 - INFO: | epoch  31 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.32 | loss-text 2.9040\n",
      "2021-12-06 04:43:45,392 - INFO: | epoch  31 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.79 | loss-text 2.9271\n",
      "2021-12-06 04:44:24,925 - INFO: | epoch  31 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 395.33 | loss-text 2.8933\n",
      "2021-12-06 04:45:04,778 - INFO: | epoch  31 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 398.52 | loss-text 2.9260\n",
      "2021-12-06 04:45:44,447 - INFO: | epoch  31 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 396.68 | loss-text 2.9365\n",
      "2021-12-06 04:46:24,291 - INFO: | epoch  31 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.43 | loss-text 2.9308\n",
      "2021-12-06 04:47:03,770 - INFO: | epoch  31 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 394.79 | loss-text 2.9040\n",
      "2021-12-06 04:47:43,575 - INFO: | epoch  31 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 398.04 | loss-text 2.9447\n",
      "2021-12-06 04:48:23,643 - INFO: | epoch  31 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 400.67 | loss-text 2.9214\n",
      "2021-12-06 04:49:03,589 - INFO: | epoch  31 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 399.45 | loss-text 2.9610\n",
      "2021-12-06 04:49:43,500 - INFO: | epoch  31 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 399.11 | loss-text 2.8942\n",
      "2021-12-06 04:50:23,326 - INFO: | epoch  31 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 398.25 | loss-text 2.8544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003865\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10254, 'reflen': 10317, 'guess': [10254, 9230, 8206, 7182], 'correct': [5690, 1977, 718, 224]}\n",
      "ratio: 0.9938935737131923\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.351\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.232\n",
      "2021-12-06 04:51:13,384 - INFO: eval_greddy SPIDEr: 0.2318\n",
      "2021-12-06 04:53:28,897 - INFO: | epoch  32 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.70 | loss-text 2.8370\n",
      "2021-12-06 04:54:08,544 - INFO: | epoch  32 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 396.46 | loss-text 2.8209\n",
      "2021-12-06 04:54:48,145 - INFO: | epoch  32 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.00 | loss-text 2.8827\n",
      "2021-12-06 04:55:27,400 - INFO: | epoch  32 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 392.54 | loss-text 2.8959\n",
      "2021-12-06 04:56:07,080 - INFO: | epoch  32 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 396.79 | loss-text 2.9056\n",
      "2021-12-06 04:56:46,454 - INFO: | epoch  32 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 393.74 | loss-text 2.8832\n",
      "2021-12-06 04:57:26,035 - INFO: | epoch  32 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 395.80 | loss-text 2.8964\n",
      "2021-12-06 04:58:05,998 - INFO: | epoch  32 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 399.63 | loss-text 2.9031\n",
      "2021-12-06 04:58:45,774 - INFO: | epoch  32 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.75 | loss-text 2.9280\n",
      "2021-12-06 04:59:25,770 - INFO: | epoch  32 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 399.96 | loss-text 2.8957\n",
      "2021-12-06 05:00:05,690 - INFO: | epoch  32 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 399.19 | loss-text 2.8970\n",
      "2021-12-06 05:02:05,183 - INFO: | epoch  32 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 399.02 | loss-text 2.9116\n",
      "2021-12-06 05:02:44,846 - INFO: | epoch  32 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.62 | loss-text 2.8972\n",
      "2021-12-06 05:03:24,553 - INFO: | epoch  32 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 397.07 | loss-text 2.9010\n",
      "2021-12-06 05:04:04,293 - INFO: | epoch  32 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.39 | loss-text 2.8820\n",
      "2021-12-06 05:04:44,150 - INFO: | epoch  32 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 398.57 | loss-text 2.8510\n",
      "2021-12-06 05:05:23,873 - INFO: | epoch  32 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.23 | loss-text 2.8727\n",
      "2021-12-06 05:06:03,654 - INFO: | epoch  32 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 397.80 | loss-text 2.8504\n",
      "2021-12-06 05:06:43,370 - INFO: | epoch  32 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 397.15 | loss-text 2.9235\n",
      "2021-12-06 05:07:22,935 - INFO: | epoch  32 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 395.64 | loss-text 2.9191\n",
      "2021-12-06 05:08:02,841 - INFO: | epoch  32 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 399.05 | loss-text 2.9160\n",
      "2021-12-06 05:08:42,619 - INFO: | epoch  32 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.78 | loss-text 2.9256\n",
      "2021-12-06 05:09:22,480 - INFO: | epoch  32 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 398.60 | loss-text 2.8965\n",
      "2021-12-06 05:10:02,273 - INFO: | epoch  32 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.93 | loss-text 2.8712\n",
      "2021-12-06 05:10:42,136 - INFO: | epoch  32 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 398.62 | loss-text 2.9179\n",
      "2021-12-06 05:11:21,955 - INFO: | epoch  32 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 398.18 | loss-text 2.8852\n",
      "2021-12-06 05:12:01,893 - INFO: | epoch  32 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 399.38 | loss-text 2.8800\n",
      "2021-12-06 05:12:41,467 - INFO: | epoch  32 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 395.72 | loss-text 2.8686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003878\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10073, 'reflen': 10192, 'guess': [10073, 9049, 8025, 7001], 'correct': [5539, 1943, 686, 205]}\n",
      "ratio: 0.9883241758240788\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.340\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.130\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.342\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.227\n",
      "2021-12-06 05:13:29,587 - INFO: eval_greddy SPIDEr: 0.2273\n",
      "loading annotations into memory...\n",
      "0:00:00.004016\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9441, 'reflen': 9776, 'guess': [9441, 8417, 7393, 6369], 'correct': [5404, 1949, 769, 259]}\n",
      "ratio: 0.9657324058918816\n",
      "Bleu_1: 0.552\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.245\n",
      "2021-12-06 05:13:57,729 - INFO: eval_beam_2 SPIDEr: 0.2445\n",
      "loading annotations into memory...\n",
      "0:00:00.003747\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9171, 'reflen': 9630, 'guess': [9171, 8147, 7123, 6099], 'correct': [5281, 1947, 791, 269]}\n",
      "ratio: 0.9523364485980319\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.386\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.249\n",
      "2021-12-06 05:14:28,067 - INFO: eval_beam_3 SPIDEr: 0.2493\n",
      "loading annotations into memory...\n",
      "0:00:00.003755\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8995, 'reflen': 9529, 'guess': [8995, 7971, 6947, 5923], 'correct': [5202, 1919, 762, 252]}\n",
      "ratio: 0.9439605415047807\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.380\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-06 05:15:02,311 - INFO: eval_beam_4 SPIDEr: 0.2455\n",
      "2021-12-06 05:15:41,721 - INFO: | epoch  33 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.07 | loss-text 2.8557\n",
      "2021-12-06 05:16:21,108 - INFO: | epoch  33 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 393.86 | loss-text 2.8531\n",
      "2021-12-06 05:17:00,379 - INFO: | epoch  33 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 392.71 | loss-text 2.9006\n",
      "2021-12-06 05:18:59,346 - INFO: | epoch  33 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 398.29 | loss-text 2.8629\n",
      "2021-12-06 05:19:38,937 - INFO: | epoch  33 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 395.90 | loss-text 2.8417\n",
      "2021-12-06 05:20:18,773 - INFO: | epoch  33 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.36 | loss-text 2.8598\n",
      "2021-12-06 05:20:58,641 - INFO: | epoch  33 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 398.67 | loss-text 2.8303\n",
      "2021-12-06 05:21:38,178 - INFO: | epoch  33 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 395.37 | loss-text 2.9016\n",
      "2021-12-06 05:22:18,027 - INFO: | epoch  33 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 398.48 | loss-text 2.8736\n",
      "2021-12-06 05:22:57,792 - INFO: | epoch  33 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 397.65 | loss-text 2.9004\n",
      "2021-12-06 05:23:37,485 - INFO: | epoch  33 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 396.93 | loss-text 2.8490\n",
      "2021-12-06 05:24:17,321 - INFO: | epoch  33 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 398.35 | loss-text 2.8893\n",
      "2021-12-06 05:24:57,102 - INFO: | epoch  33 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.80 | loss-text 2.8650\n",
      "2021-12-06 05:25:36,752 - INFO: | epoch  33 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 396.50 | loss-text 2.8885\n",
      "2021-12-06 05:26:16,398 - INFO: | epoch  33 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 396.45 | loss-text 2.8663\n",
      "2021-12-06 05:26:55,998 - INFO: | epoch  33 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 396.00 | loss-text 2.9003\n",
      "2021-12-06 05:27:35,688 - INFO: | epoch  33 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 396.88 | loss-text 2.8896\n",
      "2021-12-06 05:28:15,645 - INFO: | epoch  33 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 399.57 | loss-text 2.9047\n",
      "2021-12-06 05:28:55,616 - INFO: | epoch  33 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 399.70 | loss-text 2.8498\n",
      "2021-12-06 05:29:35,648 - INFO: | epoch  33 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 400.31 | loss-text 2.8897\n",
      "2021-12-06 05:30:15,427 - INFO: | epoch  33 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.78 | loss-text 2.8514\n",
      "2021-12-06 05:30:55,094 - INFO: | epoch  33 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 396.66 | loss-text 2.8584\n",
      "2021-12-06 05:31:34,754 - INFO: | epoch  33 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 396.59 | loss-text 2.9263\n",
      "2021-12-06 05:32:14,438 - INFO: | epoch  33 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 396.84 | loss-text 2.9064\n",
      "2021-12-06 05:32:54,331 - INFO: | epoch  33 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 398.93 | loss-text 2.9039\n",
      "2021-12-06 05:33:33,942 - INFO: | epoch  33 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 396.09 | loss-text 2.9052\n",
      "2021-12-06 05:34:13,575 - INFO: | epoch  33 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 396.33 | loss-text 2.8872\n",
      "2021-12-06 05:34:53,483 - INFO: | epoch  33 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 399.08 | loss-text 2.8746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003822\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10199, 'reflen': 10289, 'guess': [10199, 9175, 8151, 7127], 'correct': [5615, 1916, 712, 233]}\n",
      "ratio: 0.9912527942461861\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.336\n",
      "Bleu_3: 0.214\n",
      "Bleu_4: 0.133\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.359\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.343\n",
      "computing SPICE score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.375\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.245\n",
      "2021-12-06 05:37:14,844 - INFO: eval_beam_4 SPIDEr: 0.2446\n",
      "2021-12-06 05:37:54,257 - INFO: | epoch  34 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.10 | loss-text 2.7958\n",
      "2021-12-06 05:38:33,878 - INFO: | epoch  34 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 396.20 | loss-text 2.8738\n",
      "2021-12-06 05:39:13,547 - INFO: | epoch  34 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.68 | loss-text 2.9134\n",
      "2021-12-06 05:39:53,309 - INFO: | epoch  34 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 397.61 | loss-text 2.8575\n",
      "2021-12-06 05:40:33,029 - INFO: | epoch  34 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 397.19 | loss-text 2.7926\n",
      "2021-12-06 05:41:13,062 - INFO: | epoch  34 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 400.32 | loss-text 2.8654\n",
      "2021-12-06 05:41:52,771 - INFO: | epoch  34 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 397.09 | loss-text 2.8357\n",
      "2021-12-06 05:42:32,577 - INFO: | epoch  34 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.05 | loss-text 2.8668\n",
      "2021-12-06 05:43:12,586 - INFO: | epoch  34 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 400.08 | loss-text 2.8464\n",
      "2021-12-06 05:43:52,472 - INFO: | epoch  34 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 398.85 | loss-text 2.8595\n",
      "2021-12-06 05:44:32,336 - INFO: | epoch  34 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 398.64 | loss-text 2.8779\n",
      "2021-12-06 05:45:12,213 - INFO: | epoch  34 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 398.76 | loss-text 2.8366\n",
      "2021-12-06 05:45:52,010 - INFO: | epoch  34 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 397.97 | loss-text 2.9104\n",
      "2021-12-06 05:46:31,729 - INFO: | epoch  34 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 397.18 | loss-text 2.8789\n",
      "2021-12-06 05:47:11,718 - INFO: | epoch  34 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 399.89 | loss-text 2.8696\n",
      "2021-12-06 05:47:51,621 - INFO: | epoch  34 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 399.03 | loss-text 2.9211\n",
      "2021-12-06 05:48:31,419 - INFO: | epoch  34 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.97 | loss-text 2.8708\n",
      "2021-12-06 05:49:11,140 - INFO: | epoch  34 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 397.21 | loss-text 2.8749\n",
      "2021-12-06 05:49:50,746 - INFO: | epoch  34 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 396.05 | loss-text 2.8665\n",
      "2021-12-06 05:50:30,434 - INFO: | epoch  34 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.87 | loss-text 2.8921\n",
      "2021-12-06 05:51:09,773 - INFO: | epoch  34 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 393.39 | loss-text 2.8678\n",
      "2021-12-06 05:53:09,409 - INFO: | epoch  34 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.33 | loss-text 2.8873\n",
      "2021-12-06 05:53:49,005 - INFO: | epoch  34 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 395.95 | loss-text 2.8680\n",
      "2021-12-06 05:54:28,804 - INFO: | epoch  34 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.98 | loss-text 2.8586\n",
      "2021-12-06 05:55:08,512 - INFO: | epoch  34 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 397.08 | loss-text 2.8436\n",
      "2021-12-06 05:55:48,181 - INFO: | epoch  34 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 396.68 | loss-text 2.9076\n",
      "2021-12-06 05:56:27,865 - INFO: | epoch  34 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 396.83 | loss-text 2.8658\n",
      "2021-12-06 05:57:07,746 - INFO: | epoch  34 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 398.80 | loss-text 2.9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003808\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10132, 'reflen': 10235, 'guess': [10132, 9108, 8084, 7060], 'correct': [5628, 1997, 732, 232]}\n",
      "ratio: 0.9899364924278465\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.356\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-06 05:57:55,113 - INFO: eval_greddy SPIDEr: 0.2359\n",
      "loading annotations into memory...\n",
      "0:00:00.004024\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9375, 'reflen': 9754, 'guess': [9375, 8351, 7327, 6303], 'correct': [5424, 2003, 784, 253]}\n",
      "ratio: 0.9611441459912896\n",
      "Bleu_1: 0.556\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.371\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.386\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.251\n",
      "2021-12-06 05:58:23,505 - INFO: eval_beam_2 SPIDEr: 0.2512\n",
      "loading annotations into memory...\n",
      "0:00:00.003894\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9095, 'reflen': 9585, 'guess': [9095, 8071, 7047, 6023], 'correct': [5284, 1982, 810, 278]}\n",
      "ratio: 0.9488784559206104\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.390\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.252\n",
      "2021-12-06 05:58:54,443 - INFO: eval_beam_3 SPIDEr: 0.2517\n",
      "loading annotations into memory...\n",
      "0:00:00.003936\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8954, 'reflen': 9503, 'guess': [8954, 7930, 6906, 5882], 'correct': [5229, 1968, 820, 293]}\n",
      "ratio: 0.9422287698620496\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.391\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.252\n",
      "2021-12-06 05:59:29,603 - INFO: eval_beam_4 SPIDEr: 0.2519\n",
      "2021-12-06 06:00:08,872 - INFO: | epoch  35 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 392.66 | loss-text 2.8275\n",
      "2021-12-06 06:00:48,506 - INFO: | epoch  35 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 396.33 | loss-text 2.8853\n",
      "2021-12-06 06:01:28,107 - INFO: | epoch  35 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.00 | loss-text 2.8583\n",
      "2021-12-06 06:02:07,977 - INFO: | epoch  35 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 398.69 | loss-text 2.8096\n",
      "2021-12-06 06:02:47,874 - INFO: | epoch  35 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 398.96 | loss-text 2.8486\n",
      "2021-12-06 06:03:27,343 - INFO: | epoch  35 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 394.68 | loss-text 2.8800\n",
      "2021-12-06 06:04:07,269 - INFO: | epoch  35 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 399.25 | loss-text 2.8764\n",
      "2021-12-06 06:04:46,976 - INFO: | epoch  35 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 397.07 | loss-text 2.8500\n",
      "2021-12-06 06:05:26,700 - INFO: | epoch  35 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.23 | loss-text 2.8476\n",
      "2021-12-06 06:06:06,659 - INFO: | epoch  35 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 399.59 | loss-text 2.8498\n",
      "2021-12-06 06:06:46,237 - INFO: | epoch  35 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 395.77 | loss-text 2.8237\n",
      "2021-12-06 06:07:25,804 - INFO: | epoch  35 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 395.67 | loss-text 2.8532\n",
      "2021-12-06 06:08:05,727 - INFO: | epoch  35 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 399.23 | loss-text 2.8267\n",
      "2021-12-06 06:08:45,500 - INFO: | epoch  35 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 397.72 | loss-text 2.8452\n",
      "2021-12-06 06:09:25,396 - INFO: | epoch  35 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 398.95 | loss-text 2.8537\n",
      "2021-12-06 06:10:04,831 - INFO: | epoch  35 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 394.35 | loss-text 2.8773\n",
      "2021-12-06 06:10:44,633 - INFO: | epoch  35 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 398.01 | loss-text 2.8299\n",
      "2021-12-06 06:13:24,489 - INFO: | epoch  35 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 398.96 | loss-text 2.8697\n",
      "2021-12-06 06:14:04,253 - INFO: | epoch  35 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 397.63 | loss-text 2.8615\n",
      "2021-12-06 06:14:43,826 - INFO: | epoch  35 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 395.72 | loss-text 2.8437\n",
      "2021-12-06 06:15:23,528 - INFO: | epoch  35 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.02 | loss-text 2.8623\n",
      "2021-12-06 06:16:03,326 - INFO: | epoch  35 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.98 | loss-text 2.8786\n",
      "2021-12-06 06:16:43,071 - INFO: | epoch  35 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.44 | loss-text 2.8798\n",
      "2021-12-06 06:17:22,908 - INFO: | epoch  35 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 398.37 | loss-text 2.8554\n",
      "2021-12-06 06:18:02,693 - INFO: | epoch  35 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 397.84 | loss-text 2.8533\n",
      "2021-12-06 06:18:42,611 - INFO: | epoch  35 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 399.17 | loss-text 2.8486\n",
      "2021-12-06 06:19:22,813 - INFO: | epoch  35 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 402.02 | loss-text 2.8756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003813\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9971, 'reflen': 10137, 'guess': [9971, 8947, 7923, 6899], 'correct': [5614, 1931, 699, 211]}\n",
      "ratio: 0.9836243464534888\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.217\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-06 06:20:09,731 - INFO: eval_greddy SPIDEr: 0.2396\n",
      "loading annotations into memory...\n",
      "0:00:00.003957\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9231, 'reflen': 9657, 'guess': [9231, 8207, 7183, 6159], 'correct': [5372, 1980, 779, 253]}\n",
      "ratio: 0.9558869214040637\n",
      "Bleu_1: 0.556\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.237\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.390\n",
      "computing SPICE score...\n",
      "SPICE: 0.119\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.254\n",
      "2021-12-06 06:20:38,088 - INFO: eval_beam_2 SPIDEr: 0.2542\n",
      "loading annotations into memory...\n",
      "0:00:00.003863\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8978, 'reflen': 9529, 'guess': [8978, 7954, 6930, 5906], 'correct': [5263, 1953, 776, 263]}\n",
      "ratio: 0.9421765137998801\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.357\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.389\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.251\n",
      "2021-12-06 06:21:08,365 - INFO: eval_beam_3 SPIDEr: 0.2512\n",
      "loading annotations into memory...\n",
      "0:00:00.003671\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8853, 'reflen': 9444, 'guess': [8853, 7829, 6805, 5781], 'correct': [5161, 1949, 800, 281]}\n",
      "ratio: 0.9374205844979947\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.389\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.250\n",
      "2021-12-06 06:21:42,590 - INFO: eval_beam_4 SPIDEr: 0.2502\n",
      "2021-12-06 06:22:22,147 - INFO: | epoch  36 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 395.54 | loss-text 2.8223\n",
      "2021-12-06 06:23:01,693 - INFO: | epoch  36 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 395.45 | loss-text 2.8390\n",
      "2021-12-06 06:23:41,270 - INFO: | epoch  36 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.77 | loss-text 2.8238\n",
      "2021-12-06 06:24:20,883 - INFO: | epoch  36 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 396.12 | loss-text 2.8069\n",
      "2021-12-06 06:25:00,574 - INFO: | epoch  36 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 396.91 | loss-text 2.8519\n",
      "2021-12-06 06:25:40,139 - INFO: | epoch  36 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 395.64 | loss-text 2.8419\n",
      "2021-12-06 06:26:19,980 - INFO: | epoch  36 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 398.40 | loss-text 2.8108\n",
      "2021-12-06 06:26:59,738 - INFO: | epoch  36 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 397.58 | loss-text 2.8439\n",
      "2021-12-06 06:27:39,533 - INFO: | epoch  36 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.94 | loss-text 2.8105\n",
      "2021-12-06 06:28:19,120 - INFO: | epoch  36 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 395.86 | loss-text 2.8450\n",
      "2021-12-06 06:28:58,910 - INFO: | epoch  36 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 397.89 | loss-text 2.8273\n",
      "2021-12-06 06:30:18,362 - INFO: | epoch  36 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 395.63 | loss-text 2.8179\n",
      "2021-12-06 06:30:58,312 - INFO: | epoch  36 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 399.49 | loss-text 2.8460\n",
      "2021-12-06 06:31:37,921 - INFO: | epoch  36 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.08 | loss-text 2.7929\n",
      "2021-12-06 06:32:17,494 - INFO: | epoch  36 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 395.72 | loss-text 2.7976\n",
      "2021-12-06 06:32:57,033 - INFO: | epoch  36 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 395.38 | loss-text 2.8366\n",
      "2021-12-06 06:33:36,845 - INFO: | epoch  36 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 398.11 | loss-text 2.8623\n",
      "2021-12-06 06:34:16,802 - INFO: | epoch  36 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 399.57 | loss-text 2.8548\n",
      "2021-12-06 06:34:56,703 - INFO: | epoch  36 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 399.01 | loss-text 2.8453\n",
      "2021-12-06 06:35:36,357 - INFO: | epoch  36 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 396.54 | loss-text 2.8668\n",
      "2021-12-06 06:36:16,198 - INFO: | epoch  36 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 398.40 | loss-text 2.8393\n",
      "2021-12-06 06:36:55,805 - INFO: | epoch  36 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 396.06 | loss-text 2.8580\n",
      "2021-12-06 06:37:35,718 - INFO: | epoch  36 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 399.13 | loss-text 2.8411\n",
      "2021-12-06 06:38:15,733 - INFO: | epoch  36 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 400.14 | loss-text 2.8501\n",
      "2021-12-06 06:38:55,646 - INFO: | epoch  36 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 399.12 | loss-text 2.8741\n",
      "2021-12-06 06:39:35,507 - INFO: | epoch  36 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 398.60 | loss-text 2.8691\n",
      "2021-12-06 06:40:15,307 - INFO: | epoch  36 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 398.00 | loss-text 2.8575\n",
      "2021-12-06 06:40:54,903 - INFO: | epoch  36 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 395.96 | loss-text 2.8338\n",
      "2021-12-06 06:41:34,774 - INFO: | epoch  36 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 398.70 | loss-text 2.8681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003788\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10263, 'reflen': 10322, 'guess': [10263, 9239, 8215, 7191], 'correct': [5649, 1998, 749, 254]}\n",
      "ratio: 0.9942840534779118\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.139\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.361\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-06 06:42:22,040 - INFO: eval_greddy SPIDEr: 0.2378\n",
      "loading annotations into memory...\n",
      "0:00:00.003860\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9489, 'reflen': 9796, 'guess': [9489, 8465, 7441, 6417], 'correct': [5444, 1960, 748, 254]}\n",
      "ratio: 0.9686606778275858\n",
      "Bleu_1: 0.555\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.230\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.367\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.240\n",
      "2021-12-06 06:42:50,609 - INFO: eval_beam_2 SPIDEr: 0.2402\n",
      "loading annotations into memory...\n",
      "0:00:00.003887\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9110, 'reflen': 9577, 'guess': [9110, 8086, 7062, 6038], 'correct': [5266, 1911, 756, 267]}\n",
      "ratio: 0.9512373394590214\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.369\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-06 06:43:22,147 - INFO: eval_beam_3 SPIDEr: 0.2407\n",
      "loading annotations into memory...\n",
      "0:00:00.003840\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8906, 'reflen': 9506, 'guess': [8906, 7882, 6858, 5834], 'correct': [5180, 1916, 772, 275]}\n",
      "ratio: 0.9368819692824598\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.235\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-06 06:43:56,382 - INFO: eval_beam_4 SPIDEr: 0.2372\n",
      "2021-12-06 06:44:35,516 - INFO: | epoch  37 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 391.31 | loss-text 2.7748\n",
      "2021-12-06 06:45:15,099 - INFO: | epoch  37 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 395.82 | loss-text 2.8260\n",
      "2021-12-06 06:45:55,058 - INFO: | epoch  37 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 399.58 | loss-text 2.8242\n",
      "2021-12-06 06:46:34,315 - INFO: | epoch  37 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 392.56 | loss-text 2.7831\n",
      "2021-12-06 06:47:14,162 - INFO: | epoch  37 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 398.47 | loss-text 2.7896\n",
      "2021-12-06 06:47:53,765 - INFO: | epoch  37 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 396.02 | loss-text 2.7890\n",
      "2021-12-06 06:48:33,575 - INFO: | epoch  37 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 398.10 | loss-text 2.8477\n",
      "2021-12-06 06:49:13,990 - INFO: | epoch  37 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 404.14 | loss-text 2.8099\n",
      "2021-12-06 06:49:53,559 - INFO: | epoch  37 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 395.69 | loss-text 2.8525\n",
      "2021-12-06 06:50:33,516 - INFO: | epoch  37 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 399.56 | loss-text 2.8137\n",
      "2021-12-06 06:51:13,435 - INFO: | epoch  37 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 399.19 | loss-text 2.7923\n",
      "2021-12-06 06:51:53,270 - INFO: | epoch  37 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 398.34 | loss-text 2.8539\n",
      "2021-12-06 06:53:52,404 - INFO: | epoch  37 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.84 | loss-text 2.8111\n",
      "2021-12-06 06:54:32,176 - INFO: | epoch  37 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 397.71 | loss-text 2.8291\n",
      "2021-12-06 06:55:11,983 - INFO: | epoch  37 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 398.06 | loss-text 2.8461\n",
      "2021-12-06 06:55:51,653 - INFO: | epoch  37 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 396.70 | loss-text 2.8550\n",
      "2021-12-06 06:56:30,911 - INFO: | epoch  37 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 392.57 | loss-text 2.8498\n",
      "2021-12-06 06:57:10,767 - INFO: | epoch  37 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 398.56 | loss-text 2.8050\n",
      "2021-12-06 06:57:50,688 - INFO: | epoch  37 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 399.20 | loss-text 2.8020\n",
      "2021-12-06 06:58:30,240 - INFO: | epoch  37 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 395.52 | loss-text 2.8403\n",
      "2021-12-06 06:59:10,260 - INFO: | epoch  37 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 400.20 | loss-text 2.8371\n",
      "2021-12-06 06:59:50,117 - INFO: | epoch  37 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.56 | loss-text 2.8152\n",
      "2021-12-06 07:00:29,447 - INFO: | epoch  37 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 393.29 | loss-text 2.8157\n",
      "2021-12-06 07:01:09,431 - INFO: | epoch  37 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 399.84 | loss-text 2.8319\n",
      "2021-12-06 07:01:49,121 - INFO: | epoch  37 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 396.89 | loss-text 2.8519\n",
      "2021-12-06 07:02:28,834 - INFO: | epoch  37 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 397.13 | loss-text 2.8038\n",
      "2021-12-06 07:03:08,717 - INFO: | epoch  37 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 398.82 | loss-text 2.8582\n",
      "2021-12-06 07:03:48,515 - INFO: | epoch  37 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 397.97 | loss-text 2.8622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003783\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10110, 'reflen': 10182, 'guess': [10110, 9086, 8062, 7038], 'correct': [5483, 1951, 737, 239]}\n",
      "ratio: 0.9929286977017292\n",
      "Bleu_1: 0.538\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.218\n",
      "Bleu_4: 0.137\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.348\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.230\n",
      "2021-12-06 07:04:36,083 - INFO: eval_greddy SPIDEr: 0.2298\n",
      "loading annotations into memory...\n",
      "0:00:00.003900\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9428, 'reflen': 9785, 'guess': [9428, 8404, 7380, 6356], 'correct': [5351, 2004, 808, 285]}\n",
      "ratio: 0.9635155850791044\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.155\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.384\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.249\n",
      "2021-12-06 07:05:05,043 - INFO: eval_beam_2 SPIDEr: 0.2486\n",
      "loading annotations into memory...\n",
      "0:00:00.003850\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9121, 'reflen': 9585, 'guess': [9121, 8097, 7073, 6049], 'correct': [5272, 2004, 818, 291]}\n",
      "ratio: 0.9515910276472663\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.359\n",
      "Bleu_3: 0.242\n",
      "Bleu_4: 0.160\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.391\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.253\n",
      "2021-12-06 07:05:37,208 - INFO: eval_beam_3 SPIDEr: 0.2530\n",
      "loading annotations into memory...\n",
      "0:00:00.003793\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 8996, 'reflen': 9522, 'guess': [8996, 7972, 6948, 5924], 'correct': [5187, 1971, 798, 286]}\n",
      "ratio: 0.9447595043057189\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.356\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.158\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.386\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.249\n",
      "2021-12-06 07:06:11,594 - INFO: eval_beam_4 SPIDEr: 0.2491\n",
      "2021-12-06 07:06:50,854 - INFO: | epoch  38 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 392.57 | loss-text 2.7841\n",
      "2021-12-06 07:07:30,083 - INFO: | epoch  38 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 392.28 | loss-text 2.7870\n",
      "2021-12-06 07:08:09,315 - INFO: | epoch  38 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 392.31 | loss-text 2.7967\n",
      "2021-12-06 07:10:08,560 - INFO: | epoch  38 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.82 | loss-text 2.7943\n",
      "2021-12-06 07:10:48,291 - INFO: | epoch  38 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 397.30 | loss-text 2.8189\n",
      "2021-12-06 07:11:28,239 - INFO: | epoch  38 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 399.47 | loss-text 2.7954\n",
      "2021-12-06 07:12:08,304 - INFO: | epoch  38 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 400.65 | loss-text 2.8038\n",
      "2021-12-06 07:12:48,365 - INFO: | epoch  38 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 400.60 | loss-text 2.8520\n",
      "2021-12-06 07:13:28,317 - INFO: | epoch  38 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 399.52 | loss-text 2.8534\n",
      "2021-12-06 07:14:08,091 - INFO: | epoch  38 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 397.73 | loss-text 2.7956\n",
      "2021-12-06 07:14:47,625 - INFO: | epoch  38 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 395.34 | loss-text 2.8160\n",
      "2021-12-06 07:15:27,472 - INFO: | epoch  38 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 398.47 | loss-text 2.8215\n",
      "2021-12-06 07:16:07,136 - INFO: | epoch  38 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.63 | loss-text 2.8208\n",
      "2021-12-06 07:16:47,062 - INFO: | epoch  38 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 399.25 | loss-text 2.8256\n",
      "2021-12-06 07:17:26,869 - INFO: | epoch  38 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 398.06 | loss-text 2.8324\n",
      "2021-12-06 07:18:06,691 - INFO: | epoch  38 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 398.21 | loss-text 2.8274\n",
      "2021-12-06 07:18:46,365 - INFO: | epoch  38 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 396.74 | loss-text 2.7747\n",
      "2021-12-06 07:19:25,925 - INFO: | epoch  38 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 395.59 | loss-text 2.8137\n",
      "2021-12-06 07:20:05,579 - INFO: | epoch  38 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 396.53 | loss-text 2.8164\n",
      "2021-12-06 07:20:45,320 - INFO: | epoch  38 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 397.41 | loss-text 2.8016\n",
      "2021-12-06 07:21:25,039 - INFO: | epoch  38 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.18 | loss-text 2.8013\n",
      "2021-12-06 07:22:04,805 - INFO: | epoch  38 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.65 | loss-text 2.8516\n",
      "2021-12-06 07:22:44,615 - INFO: | epoch  38 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 398.09 | loss-text 2.8222\n",
      "2021-12-06 07:23:24,069 - INFO: | epoch  38 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 394.53 | loss-text 2.8492\n",
      "2021-12-06 07:24:03,663 - INFO: | epoch  38 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 395.94 | loss-text 2.7998\n",
      "2021-12-06 07:24:43,050 - INFO: | epoch  38 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 393.86 | loss-text 2.8263\n",
      "2021-12-06 07:25:22,517 - INFO: | epoch  38 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 394.66 | loss-text 2.7897\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.365\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-06 07:27:19,727 - INFO: eval_beam_2 SPIDEr: 0.2409\n",
      "loading annotations into memory...\n",
      "0:00:00.003784\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9338, 'reflen': 9732, 'guess': [9338, 8314, 7290, 6266], 'correct': [5312, 1938, 744, 248]}\n",
      "ratio: 0.9595150020549774\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.370\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-06 07:27:52,030 - INFO: eval_beam_3 SPIDEr: 0.2408\n",
      "loading annotations into memory...\n",
      "0:00:00.004034\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9128, 'reflen': 9601, 'guess': [9128, 8104, 7080, 6056], 'correct': [5237, 1934, 751, 260]}\n",
      "ratio: 0.9507342985104728\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.374\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-06 07:28:27,139 - INFO: eval_beam_4 SPIDEr: 0.2426\n",
      "2021-12-06 07:29:06,638 - INFO: | epoch  39 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.96 | loss-text 2.7769\n",
      "2021-12-06 07:29:45,795 - INFO: | epoch  39 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 391.56 | loss-text 2.8138\n",
      "2021-12-06 07:30:25,614 - INFO: | epoch  39 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 398.19 | loss-text 2.7995\n",
      "2021-12-06 07:31:05,155 - INFO: | epoch  39 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.40 | loss-text 2.7992\n",
      "2021-12-06 07:31:45,190 - INFO: | epoch  39 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 400.34 | loss-text 2.7634\n",
      "2021-12-06 07:32:24,996 - INFO: | epoch  39 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 398.05 | loss-text 2.7698\n",
      "2021-12-06 07:33:05,206 - INFO: | epoch  39 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 402.09 | loss-text 2.7677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-06 07:33:45,293 - INFO: | epoch  39 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 400.86 | loss-text 2.8224\n",
      "2021-12-06 07:34:25,121 - INFO: | epoch  39 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 398.28 | loss-text 2.7656\n",
      "2021-12-06 07:35:04,635 - INFO: | epoch  39 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 395.13 | loss-text 2.7730\n",
      "2021-12-06 07:35:44,107 - INFO: | epoch  39 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 394.71 | loss-text 2.8187\n",
      "2021-12-06 07:36:23,806 - INFO: | epoch  39 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 396.99 | loss-text 2.7993\n",
      "2021-12-06 07:38:23,131 - INFO: | epoch  39 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.39 | loss-text 2.8089\n",
      "2021-12-06 07:39:03,017 - INFO: | epoch  39 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 398.85 | loss-text 2.8049\n",
      "2021-12-06 07:39:42,797 - INFO: | epoch  39 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 397.80 | loss-text 2.8325\n",
      "2021-12-06 07:40:22,527 - INFO: | epoch  39 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 397.29 | loss-text 2.8386\n",
      "2021-12-06 07:41:02,233 - INFO: | epoch  39 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.05 | loss-text 2.7792\n",
      "2021-12-06 07:41:42,045 - INFO: | epoch  39 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 398.11 | loss-text 2.8279\n",
      "2021-12-06 07:42:21,874 - INFO: | epoch  39 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 398.29 | loss-text 2.8344\n",
      "2021-12-06 07:43:01,360 - INFO: | epoch  39 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 394.85 | loss-text 2.8162\n",
      "2021-12-06 07:43:41,276 - INFO: | epoch  39 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 399.16 | loss-text 2.7820\n",
      "2021-12-06 07:44:21,014 - INFO: | epoch  39 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.37 | loss-text 2.7881\n",
      "2021-12-06 07:45:00,739 - INFO: | epoch  39 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.25 | loss-text 2.8123\n",
      "2021-12-06 07:45:40,350 - INFO: | epoch  39 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 396.11 | loss-text 2.8058\n",
      "2021-12-06 07:46:20,147 - INFO: | epoch  39 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 397.96 | loss-text 2.7916\n",
      "2021-12-06 07:47:00,136 - INFO: | epoch  39 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 399.89 | loss-text 2.8386\n",
      "2021-12-06 07:47:39,760 - INFO: | epoch  39 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 396.23 | loss-text 2.7831\n",
      "2021-12-06 07:48:19,593 - INFO: | epoch  39 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 398.32 | loss-text 2.7885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003901\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10191, 'reflen': 10241, 'guess': [10191, 9167, 8143, 7119], 'correct': [5630, 2015, 729, 221]}\n",
      "ratio: 0.9951176642904994\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.220\n",
      "Bleu_4: 0.135\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.362\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.239\n",
      "2021-12-06 07:49:08,073 - INFO: eval_greddy SPIDEr: 0.2389\n",
      "loading annotations into memory...\n",
      "0:00:00.003886\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9423, 'reflen': 9764, 'guess': [9423, 8399, 7375, 6351], 'correct': [5400, 2027, 777, 247]}\n",
      "ratio: 0.965075788611126\n",
      "Bleu_1: 0.553\n",
      "Bleu_2: 0.359\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.384\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.249\n",
      "2021-12-06 07:49:37,354 - INFO: eval_beam_2 SPIDEr: 0.2495\n",
      "loading annotations into memory...\n",
      "0:00:00.003920\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9229, 'reflen': 9673, 'guess': [9229, 8205, 7181, 6157], 'correct': [5279, 2028, 798, 264]}\n",
      "ratio: 0.9540990385608441\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.358\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.389\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.253\n",
      "2021-12-06 07:50:09,777 - INFO: eval_beam_3 SPIDEr: 0.2525\n",
      "loading annotations into memory...\n",
      "0:00:00.003710\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9103, 'reflen': 9598, 'guess': [9103, 8079, 7055, 6032], 'correct': [5252, 2025, 821, 284]}\n",
      "ratio: 0.948426755573979\n",
      "Bleu_1: 0.546\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.395\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.255\n",
      "2021-12-06 07:50:44,582 - INFO: eval_beam_4 SPIDEr: 0.2550\n",
      "2021-12-06 07:51:23,930 - INFO: | epoch  40 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 393.46 | loss-text 2.7403\n",
      "2021-12-06 07:52:03,246 - INFO: | epoch  40 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 393.14 | loss-text 2.7720\n",
      "2021-12-06 07:52:42,838 - INFO: | epoch  40 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.92 | loss-text 2.7628\n",
      "2021-12-06 07:54:41,992 - INFO: | epoch  40 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.76 | loss-text 2.7783\n",
      "2021-12-06 07:55:21,730 - INFO: | epoch  40 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 397.37 | loss-text 2.7990\n",
      "2021-12-06 07:56:01,725 - INFO: | epoch  40 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 399.95 | loss-text 2.7876\n",
      "2021-12-06 07:56:41,600 - INFO: | epoch  40 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 398.74 | loss-text 2.8011\n",
      "2021-12-06 07:57:21,378 - INFO: | epoch  40 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 397.78 | loss-text 2.7859\n",
      "2021-12-06 07:58:01,038 - INFO: | epoch  40 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 396.60 | loss-text 2.7583\n",
      "2021-12-06 07:58:40,775 - INFO: | epoch  40 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 397.36 | loss-text 2.8484\n",
      "2021-12-06 07:59:20,499 - INFO: | epoch  40 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 397.24 | loss-text 2.8156\n",
      "2021-12-06 08:00:00,130 - INFO: | epoch  40 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 396.31 | loss-text 2.7895\n",
      "2021-12-06 08:00:39,653 - INFO: | epoch  40 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 395.22 | loss-text 2.7789\n",
      "2021-12-06 08:01:19,514 - INFO: | epoch  40 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 398.61 | loss-text 2.8076\n",
      "2021-12-06 08:01:59,003 - INFO: | epoch  40 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 394.88 | loss-text 2.7874\n",
      "2021-12-06 08:02:38,546 - INFO: | epoch  40 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 395.42 | loss-text 2.7821\n",
      "2021-12-06 08:03:18,263 - INFO: | epoch  40 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.17 | loss-text 2.8009\n",
      "2021-12-06 08:03:57,868 - INFO: | epoch  40 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.04 | loss-text 2.7945\n",
      "2021-12-06 08:04:37,537 - INFO: | epoch  40 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 396.69 | loss-text 2.7697\n",
      "2021-12-06 08:05:17,335 - INFO: | epoch  40 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 397.97 | loss-text 2.8219\n",
      "2021-12-06 08:05:57,097 - INFO: | epoch  40 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.62 | loss-text 2.8054\n",
      "2021-12-06 08:06:36,836 - INFO: | epoch  40 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.38 | loss-text 2.7976\n",
      "2021-12-06 08:07:16,876 - INFO: | epoch  40 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 400.40 | loss-text 2.8220\n",
      "2021-12-06 08:07:56,534 - INFO: | epoch  40 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 396.57 | loss-text 2.7968\n",
      "2021-12-06 08:08:36,375 - INFO: | epoch  40 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 398.40 | loss-text 2.7762\n",
      "2021-12-06 08:09:15,915 - INFO: | epoch  40 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 395.39 | loss-text 2.8222\n",
      "2021-12-06 08:09:55,568 - INFO: | epoch  40 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 396.52 | loss-text 2.7815\n",
      "2021-12-06 08:10:35,423 - INFO: | epoch  40 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 398.54 | loss-text 2.8458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003823\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10589, 'reflen': 10479, 'guess': [10589, 9565, 8541, 7517], 'correct': [5666, 1930, 676, 190]}\n",
      "ratio: 1.0104971848457858\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.329\n",
      "Bleu_3: 0.204\n",
      "Bleu_4: 0.121\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.355\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.333\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.223\n",
      "2021-12-06 08:11:25,487 - INFO: eval_greddy SPIDEr: 0.2226\n",
      "2021-12-06 08:13:41,951 - INFO: | epoch  41 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.20 | loss-text 2.7362\n",
      "2021-12-06 08:14:21,147 - INFO: | epoch  41 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 391.96 | loss-text 2.8159\n",
      "2021-12-06 08:15:00,780 - INFO: | epoch  41 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.32 | loss-text 2.7794\n",
      "2021-12-06 08:15:40,375 - INFO: | epoch  41 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.95 | loss-text 2.7542\n",
      "2021-12-06 08:16:20,180 - INFO: | epoch  41 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 398.04 | loss-text 2.7470\n",
      "2021-12-06 08:16:59,900 - INFO: | epoch  41 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.19 | loss-text 2.7664\n",
      "2021-12-06 08:17:39,508 - INFO: | epoch  41 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 396.08 | loss-text 2.7751\n",
      "2021-12-06 08:18:19,334 - INFO: | epoch  41 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.25 | loss-text 2.7484\n",
      "2021-12-06 08:18:59,133 - INFO: | epoch  41 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.98 | loss-text 2.7930\n",
      "2021-12-06 08:19:38,750 - INFO: | epoch  41 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 396.17 | loss-text 2.7619\n",
      "2021-12-06 08:20:18,569 - INFO: | epoch  41 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 398.18 | loss-text 2.7807\n",
      "2021-12-06 08:20:58,043 - INFO: | epoch  41 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 394.73 | loss-text 2.8015\n",
      "2021-12-06 08:21:37,616 - INFO: | epoch  41 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 395.73 | loss-text 2.8024\n",
      "2021-12-06 08:22:17,388 - INFO: | epoch  41 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 397.71 | loss-text 2.8104\n",
      "2021-12-06 08:22:57,244 - INFO: | epoch  41 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 398.55 | loss-text 2.7268\n",
      "2021-12-06 08:23:36,906 - INFO: | epoch  41 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 396.62 | loss-text 2.8148\n",
      "2021-12-06 08:24:16,807 - INFO: | epoch  41 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 399.00 | loss-text 2.8050\n",
      "2021-12-06 08:24:56,278 - INFO: | epoch  41 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 394.70 | loss-text 2.7801\n",
      "2021-12-06 08:25:35,927 - INFO: | epoch  41 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 396.49 | loss-text 2.7810\n",
      "2021-12-06 08:26:15,612 - INFO: | epoch  41 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.84 | loss-text 2.7987\n",
      "2021-12-06 08:26:55,446 - INFO: | epoch  41 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 398.33 | loss-text 2.7488\n",
      "2021-12-06 08:28:54,353 - INFO: | epoch  41 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 394.20 | loss-text 2.7731\n",
      "2021-12-06 08:29:34,137 - INFO: | epoch  41 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.84 | loss-text 2.7804\n",
      "2021-12-06 08:30:13,351 - INFO: | epoch  41 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 392.14 | loss-text 2.7941\n",
      "2021-12-06 08:30:53,586 - INFO: | epoch  41 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 402.35 | loss-text 2.8007\n",
      "2021-12-06 08:31:33,416 - INFO: | epoch  41 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 398.29 | loss-text 2.8010\n",
      "2021-12-06 08:32:12,901 - INFO: | epoch  41 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 394.84 | loss-text 2.7818\n",
      "2021-12-06 08:32:52,600 - INFO: | epoch  41 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 396.98 | loss-text 2.7777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003939\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10366, 'reflen': 10386, 'guess': [10366, 9342, 8318, 7294], 'correct': [5681, 2017, 760, 249]}\n",
      "ratio: 0.9980743308298673\n",
      "Bleu_1: 0.547\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.221\n",
      "Bleu_4: 0.138\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.360\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-06 08:33:40,570 - INFO: eval_greddy SPIDEr: 0.2367\n",
      "loading annotations into memory...\n",
      "0:00:00.003883\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9563, 'reflen': 9847, 'guess': [9563, 8539, 7515, 6491], 'correct': [5405, 1992, 780, 276]}\n",
      "ratio: 0.9711587285466668\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.376\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-06 08:34:09,487 - INFO: eval_beam_2 SPIDEr: 0.2464\n",
      "loading annotations into memory...\n",
      "0:00:00.003877\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9237, 'reflen': 9653, 'guess': [9237, 8213, 7189, 6165], 'correct': [5247, 1967, 800, 297]}\n",
      "ratio: 0.9569045892467671\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.353\n",
      "Bleu_3: 0.236\n",
      "Bleu_4: 0.157\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.365\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.385\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.249\n",
      "2021-12-06 08:34:40,412 - INFO: eval_beam_3 SPIDEr: 0.2495\n",
      "loading annotations into memory...\n",
      "0:00:00.003696\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9113, 'reflen': 9586, 'guess': [9113, 8089, 7065, 6041], 'correct': [5224, 1976, 819, 304]}\n",
      "ratio: 0.9506572084288597\n",
      "Bleu_1: 0.544\n",
      "Bleu_2: 0.355\n",
      "Bleu_3: 0.240\n",
      "Bleu_4: 0.161\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.394\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.254\n",
      "2021-12-06 08:35:15,526 - INFO: eval_beam_4 SPIDEr: 0.2537\n",
      "2021-12-06 08:35:55,022 - INFO: | epoch  42 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.93 | loss-text 2.7397\n",
      "2021-12-06 08:36:34,318 - INFO: | epoch  42 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 392.95 | loss-text 2.7457\n",
      "2021-12-06 08:37:14,283 - INFO: | epoch  42 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 399.65 | loss-text 2.7566\n",
      "2021-12-06 08:37:53,874 - INFO: | epoch  42 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.90 | loss-text 2.7198\n",
      "2021-12-06 08:38:33,431 - INFO: | epoch  42 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 395.56 | loss-text 2.7350\n",
      "2021-12-06 08:39:13,335 - INFO: | epoch  42 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 399.03 | loss-text 2.7330\n",
      "2021-12-06 08:39:53,301 - INFO: | epoch  42 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 399.66 | loss-text 2.7657\n",
      "2021-12-06 08:40:32,853 - INFO: | epoch  42 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 395.52 | loss-text 2.7532\n",
      "2021-12-06 08:41:12,682 - INFO: | epoch  42 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 398.28 | loss-text 2.7694\n",
      "2021-12-06 08:41:52,584 - INFO: | epoch  42 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 399.01 | loss-text 2.7941\n",
      "2021-12-06 08:42:32,479 - INFO: | epoch  42 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 398.94 | loss-text 2.7128\n",
      "2021-12-06 08:43:12,581 - INFO: | epoch  42 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 401.00 | loss-text 2.7718\n",
      "2021-12-06 08:43:52,017 - INFO: | epoch  42 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 394.36 | loss-text 2.7838\n",
      "2021-12-06 08:44:31,669 - INFO: | epoch  42 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 396.51 | loss-text 2.7869\n",
      "2021-12-06 08:45:11,387 - INFO: | epoch  42 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 397.17 | loss-text 2.7792\n",
      "2021-12-06 08:47:10,342 - INFO: | epoch  42 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 392.56 | loss-text 2.7550\n",
      "2021-12-06 08:47:50,138 - INFO: | epoch  42 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.95 | loss-text 2.7783\n",
      "2021-12-06 08:48:30,019 - INFO: | epoch  42 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 398.81 | loss-text 2.8035\n",
      "2021-12-06 08:49:09,472 - INFO: | epoch  42 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 394.52 | loss-text 2.7778\n",
      "2021-12-06 08:49:49,349 - INFO: | epoch  42 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 398.76 | loss-text 2.7703\n",
      "2021-12-06 08:50:28,893 - INFO: | epoch  42 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 395.43 | loss-text 2.7474\n",
      "2021-12-06 08:51:08,689 - INFO: | epoch  42 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.95 | loss-text 2.7879\n",
      "2021-12-06 08:51:48,623 - INFO: | epoch  42 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 399.34 | loss-text 2.7754\n",
      "2021-12-06 08:52:28,700 - INFO: | epoch  42 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 400.76 | loss-text 2.8039\n",
      "2021-12-06 08:53:08,240 - INFO: | epoch  42 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 395.40 | loss-text 2.7586\n",
      "2021-12-06 08:53:47,990 - INFO: | epoch  42 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 397.49 | loss-text 2.7906\n",
      "2021-12-06 08:54:27,662 - INFO: | epoch  42 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 396.71 | loss-text 2.7824\n",
      "2021-12-06 08:55:07,333 - INFO: | epoch  42 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 396.71 | loss-text 2.7937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003777\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10384, 'reflen': 10386, 'guess': [10384, 9360, 8336, 7312], 'correct': [5696, 1964, 725, 225]}\n",
      "ratio: 0.9998074330829\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.132\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.347\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.231\n",
      "2021-12-06 08:55:55,066 - INFO: eval_greddy SPIDEr: 0.2315\n",
      "loading annotations into memory...\n",
      "0:00:00.004128\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9630, 'reflen': 9884, 'guess': [9630, 8606, 7582, 6558], 'correct': [5497, 1997, 777, 262]}\n",
      "ratio: 0.9743019020638432\n",
      "Bleu_1: 0.556\n",
      "Bleu_2: 0.354\n",
      "Bleu_3: 0.232\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.117\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-06 08:56:24,607 - INFO: eval_beam_2 SPIDEr: 0.2439\n",
      "loading annotations into memory...\n",
      "0:00:00.003817\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9258, 'reflen': 9658, 'guess': [9258, 8234, 7210, 6186], 'correct': [5293, 1950, 779, 275]}\n",
      "ratio: 0.9585835576722966\n",
      "Bleu_1: 0.548\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.234\n",
      "Bleu_4: 0.153\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.362\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-06 08:56:55,267 - INFO: eval_beam_3 SPIDEr: 0.2435\n",
      "loading annotations into memory...\n",
      "0:00:00.003702\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9091, 'reflen': 9579, 'guess': [9091, 8067, 7043, 6019], 'correct': [5182, 1885, 744, 258]}\n",
      "ratio: 0.9490552249711922\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.149\n",
      "computing METEOR score...\n",
      "METEOR: 0.160\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.364\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.237\n",
      "2021-12-06 08:57:30,563 - INFO: eval_beam_4 SPIDEr: 0.2370\n",
      "2021-12-06 08:58:10,064 - INFO: | epoch  43 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.99 | loss-text 2.7120\n",
      "2021-12-06 08:58:49,428 - INFO: | epoch  43 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 393.63 | loss-text 2.7076\n",
      "2021-12-06 08:59:29,098 - INFO: | epoch  43 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.70 | loss-text 2.7380\n",
      "2021-12-06 09:00:08,688 - INFO: | epoch  43 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.89 | loss-text 2.7716\n",
      "2021-12-06 09:00:48,383 - INFO: | epoch  43 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 396.94 | loss-text 2.7296\n",
      "2021-12-06 09:01:28,090 - INFO: | epoch  43 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.07 | loss-text 2.7110\n",
      "2021-12-06 09:03:27,195 - INFO: | epoch  43 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 396.27 | loss-text 2.8059\n",
      "2021-12-06 09:04:06,856 - INFO: | epoch  43 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 396.60 | loss-text 2.7488\n",
      "2021-12-06 09:04:46,267 - INFO: | epoch  43 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 394.11 | loss-text 2.7105\n",
      "2021-12-06 09:05:26,176 - INFO: | epoch  43 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 399.07 | loss-text 2.7382\n",
      "2021-12-06 09:06:05,985 - INFO: | epoch  43 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 398.09 | loss-text 2.7372\n",
      "2021-12-06 09:06:46,012 - INFO: | epoch  43 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 400.26 | loss-text 2.7524\n",
      "2021-12-06 09:07:25,666 - INFO: | epoch  43 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 396.53 | loss-text 2.7292\n",
      "2021-12-06 09:08:05,046 - INFO: | epoch  43 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 393.79 | loss-text 2.7925\n",
      "2021-12-06 09:08:44,666 - INFO: | epoch  43 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 396.20 | loss-text 2.7824\n",
      "2021-12-06 09:09:24,586 - INFO: | epoch  43 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 399.19 | loss-text 2.7690\n",
      "2021-12-06 09:10:04,527 - INFO: | epoch  43 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 399.41 | loss-text 2.7647\n",
      "2021-12-06 09:10:44,384 - INFO: | epoch  43 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 398.56 | loss-text 2.7660\n",
      "2021-12-06 09:11:24,078 - INFO: | epoch  43 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 396.94 | loss-text 2.7717\n",
      "2021-12-06 09:12:03,557 - INFO: | epoch  43 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 394.78 | loss-text 2.7722\n",
      "2021-12-06 09:12:43,425 - INFO: | epoch  43 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 398.67 | loss-text 2.7611\n",
      "2021-12-06 09:13:22,896 - INFO: | epoch  43 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 394.71 | loss-text 2.7909\n",
      "2021-12-06 09:14:02,693 - INFO: | epoch  43 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.96 | loss-text 2.8173\n",
      "2021-12-06 09:14:42,503 - INFO: | epoch  43 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 398.09 | loss-text 2.7457\n",
      "2021-12-06 09:15:22,127 - INFO: | epoch  43 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 396.24 | loss-text 2.7618\n",
      "2021-12-06 09:16:01,917 - INFO: | epoch  43 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 397.90 | loss-text 2.7246\n",
      "2021-12-06 09:16:41,896 - INFO: | epoch  43 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 399.78 | loss-text 2.7567\n",
      "2021-12-06 09:17:21,343 - INFO: | epoch  43 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 394.47 | loss-text 2.7786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003889\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10430, 'reflen': 10419, 'guess': [10430, 9406, 8382, 7358], 'correct': [5817, 2093, 810, 278]}\n",
      "ratio: 1.001055763508878\n",
      "Bleu_1: 0.558\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.169\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.366\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.368\n",
      "computing SPICE score...\n",
      "SPICE: 0.118\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.243\n",
      "2021-12-06 09:18:08,818 - INFO: eval_greddy SPIDEr: 0.2428\n",
      "loading annotations into memory...\n",
      "0:00:00.003875\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9706, 'reflen': 9948, 'guess': [9706, 8682, 7658, 6634], 'correct': [5595, 2078, 840, 311]}\n",
      "ratio: 0.9756735022114017\n",
      "Bleu_1: 0.562\n",
      "Bleu_2: 0.362\n",
      "Bleu_3: 0.241\n",
      "Bleu_4: 0.159\n",
      "computing METEOR score...\n",
      "METEOR: 0.170\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.372\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.394\n",
      "computing SPICE score...\n",
      "SPICE: 0.120\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.257\n",
      "2021-12-06 09:18:37,733 - INFO: eval_beam_2 SPIDEr: 0.2569\n",
      "loading annotations into memory...\n",
      "0:00:00.003910\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9281, 'reflen': 9690, 'guess': [9281, 8257, 7233, 6209], 'correct': [5407, 2021, 835, 311]}\n",
      "ratio: 0.9577915376675997\n",
      "Bleu_1: 0.557\n",
      "Bleu_2: 0.361\n",
      "Bleu_3: 0.243\n",
      "Bleu_4: 0.162\n",
      "computing METEOR score...\n",
      "METEOR: 0.168\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.370\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.396\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.256\n",
      "2021-12-06 09:19:09,283 - INFO: eval_beam_3 SPIDEr: 0.2558\n",
      "loading annotations into memory...\n",
      "0:00:00.003920\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9134, 'reflen': 9608, 'guess': [9134, 8110, 7086, 6062], 'correct': [5285, 2013, 842, 327]}\n",
      "ratio: 0.9506661115735896\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.244\n",
      "Bleu_4: 0.165\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.394\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.253\n",
      "2021-12-06 09:19:44,629 - INFO: eval_beam_4 SPIDEr: 0.2535\n",
      "2021-12-06 09:20:23,905 - INFO: | epoch  44 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 392.73 | loss-text 2.7358\n",
      "2021-12-06 09:21:03,716 - INFO: | epoch  44 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 398.10 | loss-text 2.7196\n",
      "2021-12-06 09:23:02,988 - INFO: | epoch  44 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 398.38 | loss-text 2.7331\n",
      "2021-12-06 09:23:42,390 - INFO: | epoch  44 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 394.01 | loss-text 2.7144\n",
      "2021-12-06 09:24:22,142 - INFO: | epoch  44 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 397.51 | loss-text 2.7123\n",
      "2021-12-06 09:25:01,924 - INFO: | epoch  44 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 397.82 | loss-text 2.7279\n",
      "2021-12-06 09:25:41,576 - INFO: | epoch  44 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 396.51 | loss-text 2.7282\n",
      "2021-12-06 09:26:21,466 - INFO: | epoch  44 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 398.89 | loss-text 2.7339\n",
      "2021-12-06 09:27:01,485 - INFO: | epoch  44 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 400.18 | loss-text 2.7323\n",
      "2021-12-06 09:27:41,166 - INFO: | epoch  44 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 396.81 | loss-text 2.7452\n",
      "2021-12-06 09:28:20,982 - INFO: | epoch  44 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 398.15 | loss-text 2.7536\n",
      "2021-12-06 09:29:00,588 - INFO: | epoch  44 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 396.05 | loss-text 2.7884\n",
      "2021-12-06 09:29:40,162 - INFO: | epoch  44 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 395.73 | loss-text 2.7233\n",
      "2021-12-06 09:30:20,107 - INFO: | epoch  44 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 399.45 | loss-text 2.7667\n",
      "2021-12-06 09:30:59,546 - INFO: | epoch  44 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 394.38 | loss-text 2.7622\n",
      "2021-12-06 09:31:39,526 - INFO: | epoch  44 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 399.79 | loss-text 2.7653\n",
      "2021-12-06 09:32:18,891 - INFO: | epoch  44 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 393.65 | loss-text 2.7571\n",
      "2021-12-06 09:32:58,542 - INFO: | epoch  44 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 396.50 | loss-text 2.7295\n",
      "2021-12-06 09:33:37,822 - INFO: | epoch  44 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 392.80 | loss-text 2.7708\n",
      "2021-12-06 09:34:17,672 - INFO: | epoch  44 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 398.49 | loss-text 2.7935\n",
      "2021-12-06 09:34:57,430 - INFO: | epoch  44 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 397.58 | loss-text 2.7472\n",
      "2021-12-06 09:35:36,991 - INFO: | epoch  44 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 395.60 | loss-text 2.7507\n",
      "2021-12-06 09:36:16,932 - INFO: | epoch  44 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 399.41 | loss-text 2.7341\n",
      "2021-12-06 09:36:56,670 - INFO: | epoch  44 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 397.37 | loss-text 2.7733\n",
      "2021-12-06 09:37:36,352 - INFO: | epoch  44 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 396.82 | loss-text 2.7312\n",
      "2021-12-06 09:38:16,059 - INFO: | epoch  44 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 397.06 | loss-text 2.7439\n",
      "2021-12-06 09:38:55,721 - INFO: | epoch  44 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 396.62 | loss-text 2.7283\n",
      "loading annotations into memory...\n",
      "0:00:00.003925\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9331, 'reflen': 9718, 'guess': [9331, 8307, 7283, 6259], 'correct': [5382, 2023, 805, 280]}\n",
      "ratio: 0.9601769911503436\n",
      "Bleu_1: 0.553\n",
      "Bleu_2: 0.360\n",
      "Bleu_3: 0.239\n",
      "Bleu_4: 0.156\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.369\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.388\n",
      "computing SPICE score...\n",
      "SPICE: 0.114\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.251\n",
      "2021-12-06 09:41:23,439 - INFO: eval_beam_3 SPIDEr: 0.2513\n",
      "loading annotations into memory...\n",
      "0:00:00.004012\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9141, 'reflen': 9617, 'guess': [9141, 8117, 7093, 6069], 'correct': [5283, 1983, 788, 271]}\n",
      "ratio: 0.950504315274935\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.357\n",
      "Bleu_3: 0.238\n",
      "Bleu_4: 0.154\n",
      "computing METEOR score...\n",
      "METEOR: 0.166\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.368\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.378\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.245\n",
      "2021-12-06 09:41:58,300 - INFO: eval_beam_4 SPIDEr: 0.2451\n",
      "2021-12-06 09:42:37,663 - INFO: | epoch  45 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 393.60 | loss-text 2.7003\n",
      "2021-12-06 09:43:17,356 - INFO: | epoch  45 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 396.91 | loss-text 2.7464\n",
      "2021-12-06 09:43:56,962 - INFO: | epoch  45 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 396.05 | loss-text 2.6663\n",
      "2021-12-06 09:44:36,822 - INFO: | epoch  45 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 398.60 | loss-text 2.7202\n",
      "2021-12-06 09:45:16,280 - INFO: | epoch  45 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 394.57 | loss-text 2.7199\n",
      "2021-12-06 09:45:56,126 - INFO: | epoch  45 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 398.44 | loss-text 2.7389\n",
      "2021-12-06 09:46:35,801 - INFO: | epoch  45 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 396.75 | loss-text 2.7315\n",
      "2021-12-06 09:47:15,606 - INFO: | epoch  45 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 398.04 | loss-text 2.7030\n",
      "2021-12-06 09:47:55,087 - INFO: | epoch  45 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 394.80 | loss-text 2.7457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-06 09:48:34,585 - INFO: | epoch  45 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 394.97 | loss-text 2.7292\n",
      "2021-12-06 09:49:14,218 - INFO: | epoch  45 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 396.32 | loss-text 2.7284\n",
      "2021-12-06 09:49:54,044 - INFO: | epoch  45 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 398.26 | loss-text 2.7284\n",
      "2021-12-06 09:50:33,759 - INFO: | epoch  45 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 397.15 | loss-text 2.7035\n",
      "2021-12-06 09:51:13,310 - INFO: | epoch  45 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 395.50 | loss-text 2.7360\n",
      "2021-12-06 09:51:53,321 - INFO: | epoch  45 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 400.10 | loss-text 2.7528\n",
      "2021-12-06 09:52:32,712 - INFO: | epoch  45 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 393.91 | loss-text 2.7234\n",
      "2021-12-06 09:53:12,596 - INFO: | epoch  45 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 398.83 | loss-text 2.7305\n",
      "2021-12-06 09:55:11,859 - INFO: | epoch  45 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 399.33 | loss-text 2.7815\n",
      "2021-12-06 09:55:51,798 - INFO: | epoch  45 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 399.38 | loss-text 2.7249\n",
      "2021-12-06 09:56:31,481 - INFO: | epoch  45 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 396.83 | loss-text 2.7660\n",
      "2021-12-06 09:57:11,426 - INFO: | epoch  45 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 399.44 | loss-text 2.7293\n",
      "2021-12-06 09:57:51,225 - INFO: | epoch  45 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.98 | loss-text 2.7683\n",
      "2021-12-06 09:58:30,993 - INFO: | epoch  45 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 397.67 | loss-text 2.7212\n",
      "2021-12-06 09:59:10,998 - INFO: | epoch  45 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 400.04 | loss-text 2.7322\n",
      "2021-12-06 09:59:50,679 - INFO: | epoch  45 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 396.81 | loss-text 2.7530\n",
      "2021-12-06 10:00:30,375 - INFO: | epoch  45 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 396.95 | loss-text 2.7511\n",
      "2021-12-06 10:01:09,806 - INFO: | epoch  45 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 394.30 | loss-text 2.7371\n",
      "loading annotations into memory...\n",
      "0:00:00.004027\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9475, 'reflen': 9786, 'guess': [9475, 8451, 7427, 6403], 'correct': [5394, 1935, 756, 257]}\n",
      "ratio: 0.9682199059880473\n",
      "Bleu_1: 0.551\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.372\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.242\n",
      "2021-12-06 10:03:06,401 - INFO: eval_beam_2 SPIDEr: 0.2416\n",
      "loading annotations into memory...\n",
      "0:00:00.003907\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9252, 'reflen': 9675, 'guess': [9252, 8228, 7204, 6180], 'correct': [5320, 1914, 761, 279]}\n",
      "ratio: 0.956279069767343\n",
      "Bleu_1: 0.549\n",
      "Bleu_2: 0.349\n",
      "Bleu_3: 0.231\n",
      "Bleu_4: 0.152\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.361\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.377\n",
      "computing SPICE score...\n",
      "SPICE: 0.112\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-06 10:03:37,486 - INFO: eval_beam_3 SPIDEr: 0.2442\n",
      "loading annotations into memory...\n",
      "0:00:00.004021\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9074, 'reflen': 9564, 'guess': [9074, 8050, 7026, 6002], 'correct': [5201, 1861, 743, 274]}\n",
      "ratio: 0.9487662066080145\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.151\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.363\n",
      "computing SPICE score...\n",
      "SPICE: 0.110\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-06 10:04:12,360 - INFO: eval_beam_4 SPIDEr: 0.2361\n",
      "2021-12-06 10:04:51,796 - INFO: | epoch  46 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.33 | loss-text 2.6974\n",
      "2021-12-06 10:05:31,151 - INFO: | epoch  46 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 393.54 | loss-text 2.6868\n",
      "2021-12-06 10:06:10,747 - INFO: | epoch  46 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 395.95 | loss-text 2.6993\n",
      "2021-12-06 10:06:50,403 - INFO: | epoch  46 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 396.56 | loss-text 2.7003\n",
      "2021-12-06 10:07:30,012 - INFO: | epoch  46 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 396.08 | loss-text 2.7172\n",
      "2021-12-06 10:08:09,912 - INFO: | epoch  46 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 399.00 | loss-text 2.7573\n",
      "2021-12-06 10:08:49,910 - INFO: | epoch  46 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 399.97 | loss-text 2.6766\n",
      "2021-12-06 10:09:29,376 - INFO: | epoch  46 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 394.66 | loss-text 2.7130\n",
      "2021-12-06 10:10:09,092 - INFO: | epoch  46 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 397.15 | loss-text 2.7460\n",
      "2021-12-06 10:10:49,203 - INFO: | epoch  46 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 401.11 | loss-text 2.7050\n",
      "2021-12-06 10:11:29,198 - INFO: | epoch  46 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 399.94 | loss-text 2.7063\n",
      "2021-12-06 10:12:08,918 - INFO: | epoch  46 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 397.19 | loss-text 2.7262\n",
      "2021-12-06 10:12:48,725 - INFO: | epoch  46 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 398.07 | loss-text 2.7306\n",
      "2021-12-06 10:13:28,404 - INFO: | epoch  46 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 396.78 | loss-text 2.7230\n",
      "2021-12-06 10:14:08,524 - INFO: | epoch  46 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 401.20 | loss-text 2.7422\n",
      "2021-12-06 10:14:48,320 - INFO: | epoch  46 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 397.95 | loss-text 2.7528\n",
      "2021-12-06 10:15:27,941 - INFO: | epoch  46 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 396.21 | loss-text 2.7006\n",
      "2021-12-06 10:16:07,436 - INFO: | epoch  46 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 394.95 | loss-text 2.6996\n",
      "2021-12-06 10:16:47,112 - INFO: | epoch  46 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 396.75 | loss-text 2.7363\n",
      "2021-12-06 10:17:26,942 - INFO: | epoch  46 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 398.30 | loss-text 2.7091\n",
      "2021-12-06 10:18:06,866 - INFO: | epoch  46 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 399.24 | loss-text 2.7303\n",
      "2021-12-06 10:18:46,780 - INFO: | epoch  46 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 399.13 | loss-text 2.6816\n",
      "2021-12-06 10:19:26,745 - INFO: | epoch  46 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 399.64 | loss-text 2.7449\n",
      "2021-12-06 10:20:06,460 - INFO: | epoch  46 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.14 | loss-text 2.7264\n",
      "2021-12-06 10:22:45,793 - INFO: | epoch  46 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 399.88 | loss-text 2.7666\n",
      "2021-12-06 10:23:25,596 - INFO: | epoch  46 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 398.03 | loss-text 2.7388\n",
      "2021-12-06 10:24:05,136 - INFO: | epoch  46 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 395.40 | loss-text 2.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003974\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10220, 'reflen': 10314, 'guess': [10220, 9196, 8172, 7148], 'correct': [5559, 1933, 691, 205]}\n",
      "ratio: 0.9908861741321513\n",
      "Bleu_1: 0.539\n",
      "Bleu_2: 0.335\n",
      "Bleu_3: 0.211\n",
      "Bleu_4: 0.128\n",
      "computing METEOR score...\n",
      "METEOR: 0.162\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.357\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.353\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.234\n",
      "2021-12-06 10:24:53,461 - INFO: eval_greddy SPIDEr: 0.2338\n",
      "loading annotations into memory...\n",
      "0:00:00.004029\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9491, 'reflen': 9795, 'guess': [9491, 8467, 7443, 6419], 'correct': [5340, 1920, 739, 243]}\n",
      "ratio: 0.9689637570187882\n",
      "Bleu_1: 0.545\n",
      "Bleu_2: 0.346\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.143\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.373\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.244\n",
      "2021-12-06 10:25:24,172 - INFO: eval_beam_2 SPIDEr: 0.2442\n",
      "loading annotations into memory...\n",
      "0:00:00.003904\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9184, 'reflen': 9607, 'guess': [9184, 8160, 7136, 6112], 'correct': [5225, 1896, 733, 248]}\n",
      "ratio: 0.9559696054958929\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.347\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.161\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.371\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-06 10:25:54,918 - INFO: eval_beam_3 SPIDEr: 0.2407\n",
      "loading annotations into memory...\n",
      "0:00:00.003890\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9123, 'reflen': 9586, 'guess': [9123, 8099, 7075, 6051], 'correct': [5124, 1872, 735, 251]}\n",
      "ratio: 0.951700396411334\n",
      "Bleu_1: 0.534\n",
      "Bleu_2: 0.342\n",
      "Bleu_3: 0.226\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.159\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.111\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.238\n",
      "2021-12-06 10:26:29,985 - INFO: eval_beam_4 SPIDEr: 0.2384\n",
      "2021-12-06 10:27:09,477 - INFO: | epoch  47 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.88 | loss-text 2.6442\n",
      "2021-12-06 10:27:48,700 - INFO: | epoch  47 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 392.23 | loss-text 2.6579\n",
      "2021-12-06 10:28:28,537 - INFO: | epoch  47 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 398.36 | loss-text 2.6866\n",
      "2021-12-06 10:30:27,567 - INFO: | epoch  47 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 397.22 | loss-text 2.7139\n",
      "2021-12-06 10:31:07,383 - INFO: | epoch  47 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 398.16 | loss-text 2.7575\n",
      "2021-12-06 10:31:46,927 - INFO: | epoch  47 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 395.44 | loss-text 2.6510\n",
      "2021-12-06 10:32:26,409 - INFO: | epoch  47 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 394.81 | loss-text 2.7267\n",
      "2021-12-06 10:33:05,896 - INFO: | epoch  47 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 394.86 | loss-text 2.7098\n",
      "2021-12-06 10:33:45,771 - INFO: | epoch  47 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 398.75 | loss-text 2.6890\n",
      "2021-12-06 10:34:25,545 - INFO: | epoch  47 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 397.73 | loss-text 2.7512\n",
      "2021-12-06 10:35:05,497 - INFO: | epoch  47 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 399.51 | loss-text 2.7687\n",
      "2021-12-06 10:35:45,339 - INFO: | epoch  47 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 398.41 | loss-text 2.6887\n",
      "2021-12-06 10:36:25,317 - INFO: | epoch  47 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 399.78 | loss-text 2.7648\n",
      "2021-12-06 10:37:05,306 - INFO: | epoch  47 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 399.88 | loss-text 2.7173\n",
      "2021-12-06 10:37:45,111 - INFO: | epoch  47 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 398.04 | loss-text 2.7491\n",
      "2021-12-06 10:38:24,863 - INFO: | epoch  47 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 397.52 | loss-text 2.6962\n",
      "2021-12-06 10:39:04,845 - INFO: | epoch  47 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 399.81 | loss-text 2.7474\n",
      "2021-12-06 10:39:44,721 - INFO: | epoch  47 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 398.75 | loss-text 2.7637\n",
      "2021-12-06 10:40:24,466 - INFO: | epoch  47 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 397.45 | loss-text 2.7092\n",
      "2021-12-06 10:41:04,416 - INFO: | epoch  47 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 399.50 | loss-text 2.6938\n",
      "2021-12-06 10:41:44,110 - INFO: | epoch  47 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 396.93 | loss-text 2.6947\n",
      "2021-12-06 10:42:23,890 - INFO: | epoch  47 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 397.80 | loss-text 2.7048\n",
      "2021-12-06 10:43:03,876 - INFO: | epoch  47 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 399.85 | loss-text 2.7228\n",
      "2021-12-06 10:43:43,770 - INFO: | epoch  47 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 398.93 | loss-text 2.7127\n",
      "2021-12-06 10:44:23,475 - INFO: | epoch  47 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 397.04 | loss-text 2.7477\n",
      "2021-12-06 10:45:03,587 - INFO: | epoch  47 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 401.11 | loss-text 2.6926\n",
      "2021-12-06 10:45:43,551 - INFO: | epoch  47 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 399.64 | loss-text 2.7487\n",
      "2021-12-06 10:46:23,372 - INFO: | epoch  47 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 398.20 | loss-text 2.7167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.246\n",
      "2021-12-06 10:48:49,970 - INFO: eval_beam_4 SPIDEr: 0.2463\n",
      "2021-12-06 10:49:29,651 - INFO: | epoch  48 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 396.78 | loss-text 2.6391\n",
      "2021-12-06 10:50:08,926 - INFO: | epoch  48 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 392.74 | loss-text 2.6841\n",
      "2021-12-06 10:50:48,706 - INFO: | epoch  48 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 397.79 | loss-text 2.7149\n",
      "2021-12-06 10:51:28,244 - INFO: | epoch  48 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.37 | loss-text 2.7033\n",
      "2021-12-06 10:52:08,210 - INFO: | epoch  48 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 399.65 | loss-text 2.6739\n",
      "2021-12-06 10:52:47,821 - INFO: | epoch  48 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 396.10 | loss-text 2.6886\n",
      "2021-12-06 10:53:27,348 - INFO: | epoch  48 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 395.26 | loss-text 2.7031\n",
      "2021-12-06 10:54:06,991 - INFO: | epoch  48 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 396.42 | loss-text 2.6671\n",
      "2021-12-06 10:54:46,523 - INFO: | epoch  48 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 395.32 | loss-text 2.7093\n",
      "2021-12-06 10:55:26,650 - INFO: | epoch  48 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 401.26 | loss-text 2.7233\n",
      "2021-12-06 10:56:06,591 - INFO: | epoch  48 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 399.40 | loss-text 2.7026\n",
      "2021-12-06 10:56:46,650 - INFO: | epoch  48 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 400.59 | loss-text 2.6661\n",
      "2021-12-06 10:57:26,637 - INFO: | epoch  48 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 399.86 | loss-text 2.6798\n",
      "2021-12-06 10:58:06,277 - INFO: | epoch  48 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 396.39 | loss-text 2.6905\n",
      "2021-12-06 10:58:46,333 - INFO: | epoch  48 |  1500/ 3051 batches | lr 1.00e-04 | ms/batch 400.55 | loss-text 2.7368\n",
      "2021-12-06 10:59:26,086 - INFO: | epoch  48 |  1600/ 3051 batches | lr 1.00e-04 | ms/batch 397.52 | loss-text 2.6935\n",
      "2021-12-06 11:00:06,159 - INFO: | epoch  48 |  1700/ 3051 batches | lr 1.00e-04 | ms/batch 400.73 | loss-text 2.7120\n",
      "2021-12-06 11:00:45,624 - INFO: | epoch  48 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 394.64 | loss-text 2.7178\n",
      "2021-12-06 11:01:25,389 - INFO: | epoch  48 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 397.64 | loss-text 2.7383\n",
      "2021-12-06 11:02:05,542 - INFO: | epoch  48 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 401.52 | loss-text 2.6906\n",
      "2021-12-06 11:02:45,296 - INFO: | epoch  48 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 397.53 | loss-text 2.6867\n",
      "2021-12-06 11:03:24,975 - INFO: | epoch  48 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 396.78 | loss-text 2.7335\n",
      "2021-12-06 11:04:04,896 - INFO: | epoch  48 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 399.20 | loss-text 2.7106\n",
      "2021-12-06 11:04:44,569 - INFO: | epoch  48 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 396.73 | loss-text 2.7539\n",
      "2021-12-06 11:06:43,497 - INFO: | epoch  48 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 397.46 | loss-text 2.6847\n",
      "2021-12-06 11:07:23,117 - INFO: | epoch  48 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 396.19 | loss-text 2.7076\n",
      "2021-12-06 11:08:02,822 - INFO: | epoch  48 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 397.05 | loss-text 2.7409\n",
      "2021-12-06 11:08:42,626 - INFO: | epoch  48 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 398.03 | loss-text 2.7234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003996\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10193, 'reflen': 10253, 'guess': [10193, 9169, 8145, 7121], 'correct': [5568, 1956, 711, 230]}\n",
      "ratio: 0.9941480542279338\n",
      "Bleu_1: 0.543\n",
      "Bleu_2: 0.339\n",
      "Bleu_3: 0.215\n",
      "Bleu_4: 0.134\n",
      "computing METEOR score...\n",
      "METEOR: 0.167\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.358\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.356\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.236\n",
      "2021-12-06 11:09:30,585 - INFO: eval_greddy SPIDEr: 0.2356\n",
      "loading annotations into memory...\n",
      "0:00:00.003960\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9369, 'reflen': 9736, 'guess': [9369, 8345, 7321, 6297], 'correct': [5359, 1936, 740, 259]}\n",
      "ratio: 0.9623048479867541\n",
      "Bleu_1: 0.550\n",
      "Bleu_2: 0.350\n",
      "Bleu_3: 0.228\n",
      "Bleu_4: 0.147\n",
      "computing METEOR score...\n",
      "METEOR: 0.165\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.364\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.379\n",
      "computing SPICE score...\n",
      "SPICE: 0.116\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.248\n",
      "2021-12-06 11:10:00,089 - INFO: eval_beam_2 SPIDEr: 0.2478\n",
      "2021-12-06 11:11:44,501 - INFO: | epoch  49 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 394.44 | loss-text 2.6688\n",
      "2021-12-06 11:12:23,831 - INFO: | epoch  49 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 393.29 | loss-text 2.6727\n",
      "2021-12-06 11:13:03,126 - INFO: | epoch  49 |   300/ 3051 batches | lr 1.00e-04 | ms/batch 392.95 | loss-text 2.6721\n",
      "2021-12-06 11:13:42,712 - INFO: | epoch  49 |   400/ 3051 batches | lr 1.00e-04 | ms/batch 395.86 | loss-text 2.6889\n",
      "2021-12-06 11:14:22,390 - INFO: | epoch  49 |   500/ 3051 batches | lr 1.00e-04 | ms/batch 396.77 | loss-text 2.6591\n",
      "2021-12-06 11:15:02,227 - INFO: | epoch  49 |   600/ 3051 batches | lr 1.00e-04 | ms/batch 398.36 | loss-text 2.6787\n",
      "2021-12-06 11:15:42,007 - INFO: | epoch  49 |   700/ 3051 batches | lr 1.00e-04 | ms/batch 397.80 | loss-text 2.6913\n",
      "2021-12-06 11:16:21,766 - INFO: | epoch  49 |   800/ 3051 batches | lr 1.00e-04 | ms/batch 397.58 | loss-text 2.6999\n",
      "2021-12-06 11:17:01,735 - INFO: | epoch  49 |   900/ 3051 batches | lr 1.00e-04 | ms/batch 399.68 | loss-text 2.6631\n",
      "2021-12-06 11:17:41,296 - INFO: | epoch  49 |  1000/ 3051 batches | lr 1.00e-04 | ms/batch 395.60 | loss-text 2.6702\n",
      "2021-12-06 11:18:20,822 - INFO: | epoch  49 |  1100/ 3051 batches | lr 1.00e-04 | ms/batch 395.25 | loss-text 2.7027\n",
      "2021-12-06 11:19:00,291 - INFO: | epoch  49 |  1200/ 3051 batches | lr 1.00e-04 | ms/batch 394.69 | loss-text 2.7059\n",
      "2021-12-06 11:19:39,760 - INFO: | epoch  49 |  1300/ 3051 batches | lr 1.00e-04 | ms/batch 394.69 | loss-text 2.6838\n",
      "2021-12-06 11:20:19,371 - INFO: | epoch  49 |  1400/ 3051 batches | lr 1.00e-04 | ms/batch 396.10 | loss-text 2.6808\n",
      "2021-12-06 11:22:58,125 - INFO: | epoch  49 |  1800/ 3051 batches | lr 1.00e-04 | ms/batch 398.14 | loss-text 2.7055\n",
      "2021-12-06 11:23:38,099 - INFO: | epoch  49 |  1900/ 3051 batches | lr 1.00e-04 | ms/batch 399.74 | loss-text 2.7037\n",
      "2021-12-06 11:24:17,866 - INFO: | epoch  49 |  2000/ 3051 batches | lr 1.00e-04 | ms/batch 397.67 | loss-text 2.6914\n",
      "2021-12-06 11:24:57,272 - INFO: | epoch  49 |  2100/ 3051 batches | lr 1.00e-04 | ms/batch 394.05 | loss-text 2.7008\n",
      "2021-12-06 11:25:37,276 - INFO: | epoch  49 |  2200/ 3051 batches | lr 1.00e-04 | ms/batch 400.04 | loss-text 2.6996\n",
      "2021-12-06 11:26:17,192 - INFO: | epoch  49 |  2300/ 3051 batches | lr 1.00e-04 | ms/batch 399.15 | loss-text 2.6993\n",
      "2021-12-06 11:26:57,016 - INFO: | epoch  49 |  2400/ 3051 batches | lr 1.00e-04 | ms/batch 398.23 | loss-text 2.6883\n",
      "2021-12-06 11:27:36,938 - INFO: | epoch  49 |  2500/ 3051 batches | lr 1.00e-04 | ms/batch 399.22 | loss-text 2.6624\n",
      "2021-12-06 11:28:16,581 - INFO: | epoch  49 |  2600/ 3051 batches | lr 1.00e-04 | ms/batch 396.42 | loss-text 2.6902\n",
      "2021-12-06 11:28:56,503 - INFO: | epoch  49 |  2700/ 3051 batches | lr 1.00e-04 | ms/batch 399.22 | loss-text 2.7112\n",
      "2021-12-06 11:29:36,373 - INFO: | epoch  49 |  2800/ 3051 batches | lr 1.00e-04 | ms/batch 398.70 | loss-text 2.7033\n",
      "2021-12-06 11:30:16,150 - INFO: | epoch  49 |  2900/ 3051 batches | lr 1.00e-04 | ms/batch 397.75 | loss-text 2.7133\n",
      "2021-12-06 11:30:56,236 - INFO: | epoch  49 |  3000/ 3051 batches | lr 1.00e-04 | ms/batch 400.86 | loss-text 2.7105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj20/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.003847\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10265, 'reflen': 10367, 'guess': [10265, 9241, 8217, 7193], 'correct': [5596, 1967, 735, 215]}\n",
      "ratio: 0.9901610880678122\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.337\n",
      "Bleu_3: 0.216\n",
      "Bleu_4: 0.131\n",
      "computing METEOR score...\n",
      "METEOR: 0.164\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.344\n",
      "computing SPICE score...\n",
      "SPICE: 0.113\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.228\n",
      "2021-12-06 11:31:45,439 - INFO: eval_greddy SPIDEr: 0.2282\n",
      "loading annotations into memory...\n",
      "0:00:00.003792\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9544, 'reflen': 9868, 'guess': [9544, 8520, 7496, 6472], 'correct': [5339, 1917, 754, 267]}\n",
      "ratio: 0.9671665991081305\n",
      "Bleu_1: 0.541\n",
      "Bleu_2: 0.343\n",
      "Bleu_3: 0.225\n",
      "Bleu_4: 0.146\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.360\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.366\n",
      "computing SPICE score...\n",
      "SPICE: 0.115\n",
      "computing SPIDEr score...\n",
      "SPIDEr: 0.241\n",
      "2021-12-06 11:32:14,481 - INFO: eval_beam_2 SPIDEr: 0.2406\n",
      "loading annotations into memory...\n",
      "0:00:00.004059\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9256, 'reflen': 9706, 'guess': [9256, 8232, 7208, 6184], 'correct': [5250, 1904, 760, 274]}\n",
      "ratio: 0.9536369256129246\n",
      "Bleu_1: 0.540\n",
      "Bleu_2: 0.345\n",
      "Bleu_3: 0.229\n",
      "Bleu_4: 0.150\n",
      "computing METEOR score...\n",
      "METEOR: 0.163\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.363\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.375\n",
      "computing SPICE score...\n"
     ]
    }
   ],
   "source": [
    "#일부 레이어 1131\n",
    "epoch = 1\n",
    "if hp.mode == 'train':\n",
    "    while epoch < hp.training_epochs + 1:\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        torch.save(model.state_dict(), '{log_dir}/{num_epoch}.pt'.format(log_dir=log_dir, num_epoch=epoch))\n",
    "        scheduler.step(epoch)\n",
    "        eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=2)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=3)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=4)\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5950aaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-04 14:04:22,352 - INFO: | epoch   1 |   100/ 3051 batches | lr 1.00e-04 | ms/batch 59.65 | loss-text 5.8095\n",
      "2021-12-04 14:04:28,155 - INFO: | epoch   1 |   200/ 3051 batches | lr 1.00e-04 | ms/batch 58.03 | loss-text 5.0831\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cb09f8526cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{log_dir}/{num_epoch}.pt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-94649549a569>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_pad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9d2cd804fa0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, input_mask, target_mask, target_padding_mask)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         output = self.decode(mem, tgt, input_mask=input_mask, target_mask=target_mask,\n\u001b[0;32m--> 126\u001b[0;31m                              target_padding_mask=target_padding_mask)\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9d2cd804fa0a>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, mem, tgt, input_mask, target_mask, target_padding_mask)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mtarget_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#mixup\n",
    "epoch = 1\n",
    "if hp.mode == 'train':\n",
    "    while epoch < hp.training_epochs + 1:\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        torch.save(model.state_dict(), '{log_dir}/{num_epoch}.pt'.format(log_dir=log_dir, num_epoch=epoch))\n",
    "        scheduler.step(epoch)\n",
    "        eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=2)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=3)\n",
    "        eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                           beam_size=4)\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b593960e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-85fdcc81b46f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dcase/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for src, tgt, tgt_len in training_data:\n",
    "    src = src.to(device)\n",
    "    tgt = tgt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3df15dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.training_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6fa65a",
   "metadata": {},
   "source": [
    "epoch=37 eval_beam_3 SPIDEr: 0.2344 # 2개 layer 만 trainable -06/9  \n",
    " SPIDEr: # 5개 layer 만 trainable -06/10 0.2252\n",
    "별 차이 없음 ;;;;;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19ee5c",
   "metadata": {},
   "source": [
    "model score check (eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3852d268",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/base/48.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2f0e4443ea7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#if hp.mode == 'eval':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Evaluation model score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/base/48.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0meval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_beam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_dict_pickle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/base/48.pt'"
     ]
    }
   ],
   "source": [
    "#if hp.mode == 'eval':\n",
    "# Evaluation model score\n",
    "model.load_state_dict(torch.load(\"./models/base/48.pt\"))\n",
    "eval_all(evaluation_beam, word_dict_pickle_path=word_dict_pickle_path)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=2)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=3)\n",
    "eval_with_beam(evaluation_beam, max_len=30, eos_ind=9, word_dict_pickle_path=word_dict_pickle_path,\n",
    "                       beam_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1735c2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./models/base/49.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixup(object):\n",
    "    def __init__(self, mixup_alpha, random_seed=1234):\n",
    "        \"\"\"Mixup coefficient generator.\n",
    "        \"\"\"\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    def get_lambda(self, batch_size):\n",
    "        \"\"\"Get mixup random coefficients.\n",
    "        Args:\n",
    "          batch_size: int\n",
    "        Returns:\n",
    "          mixup_lambdas: (batch_size,)\n",
    "        \"\"\"\n",
    "        mixup_lambdas = []\n",
    "        for n in range(0, batch_size, 2):\n",
    "            lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "            mixup_lambdas.append(lam)\n",
    "            mixup_lambdas.append(1. - lam)\n",
    "\n",
    "        return np.array(mixup_lambdas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fecb95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd36458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mixup(x, mixup_lambda):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes \n",
    "    (1, 3, 5, ...).\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0 :: 2].transpose(0, -1) * mixup_lambda[0 :: 2] + \\\n",
    "        x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d22dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.feature.inverse import mel_to_audio, mel_to_stft\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University, Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['feature_extraction']\n",
    "\n",
    "\n",
    "def feature_extraction(audio_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"Feature extraction function.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: Log mel-bands energies of shape=(t, nb_mels)\n",
    "    :rtype: numpy.ndarray, numpy.float\n",
    "    \"\"\"\n",
    "    y = audio_data/abs(audio_data).max()\n",
    "    mel_bands = melspectrogram(\n",
    "        y=y, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power, n_mels=nb_mels,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm).T\n",
    "\n",
    "    return np.log(mel_bands + np.finfo(float).eps)\n",
    "\n",
    "\n",
    "def from_mel_to_audio(mel_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"Feature extraction inverse function.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: audio data\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.exp(mel_data) - np.finfo(float).eps\n",
    "    audio_data = mel_to_audio(\n",
    "        M=y.T, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm)\n",
    "\n",
    "    return audio_data\n",
    "\n",
    "\n",
    "def from_mel_to_stft(mel_data: np.ndarray,\n",
    "                       sr: int,\n",
    "                       nb_fft: int,\n",
    "                       hop_size: int,\n",
    "                       nb_mels: int,\n",
    "                       f_min: float,\n",
    "                       f_max: float,\n",
    "                       htk: bool,\n",
    "                       power: float,\n",
    "                       norm: bool,\n",
    "                       window_function: str,\n",
    "                       center: bool)\\\n",
    "        -> (np.ndarray, np.float):\n",
    "    \"\"\"From logmelspectrogram to stft.\n",
    "    :param audio_data: Audio signal.\n",
    "    :type audio_data: numpy.ndarray\n",
    "    :param sr: Sampling frequency.\n",
    "    :type sr: int\n",
    "    :param nb_fft: Amount of FFT points.\n",
    "    :type nb_fft: int\n",
    "    :param hop_size: Hop size in samples.\n",
    "    :type hop_size: int\n",
    "    :param nb_mels: Amount of MEL bands.\n",
    "    :type nb_mels: int\n",
    "    :param f_min: Minimum frequency in Hertz for MEL band calculation.\n",
    "    :type f_min: float\n",
    "    :param f_max: Maximum frequency in Hertz for MEL band calculation.\n",
    "    :type f_max: float|None\n",
    "    :param htk: Use the HTK Toolbox formula instead of Auditory toolkit.\n",
    "    :type htk: bool\n",
    "    :param power: Power of the magnitude.\n",
    "    :type power: float\n",
    "    :param norm: Area normalization of MEL filters.\n",
    "    :type norm: bool\n",
    "    :param window_function: Window function.\n",
    "    :type window_function: str\n",
    "    :param center: Center the frame for FFT.\n",
    "    :type center: bool\n",
    "    :return: audio data\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.exp(mel_data) - np.finfo(float).eps\n",
    "    stft = mel_to_stft(\n",
    "        M=y.T, sr=sr, n_fft=nb_fft, hop_length=hop_size, win_length=nb_fft,\n",
    "        window=window_function, center=center, power=power,\n",
    "        fmin=f_min, fmax=f_max, htk=htk, norm=norm)\n",
    "\n",
    "    return stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beae2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "#from tools.features_log_mel_bands import feature_extraction, from_mel_to_audio, from_mel_to_stft\n",
    "from pathlib import Path\n",
    "import pysndfx\n",
    "import gc\n",
    "\n",
    "import copy\n",
    "\n",
    "#from tools.file_io import load_audio_file\n",
    "import torch\n",
    "\n",
    "\n",
    "__author__ = 'Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "\n",
    "class MixUp:\n",
    "\n",
    "    def __init__(self, p, settings_features, simple_concat_captions=True,\n",
    "                 sample_audio=False):\n",
    "\n",
    "        self.p = p\n",
    "        self.sample_audio = sample_audio\n",
    "        self.settings_features = settings_features\n",
    "        self.simple_concat_captions = simple_concat_captions\n",
    "\n",
    "    def from_mel(self, mel):\n",
    "        return 700 * (10 ** (mel / 2595.0) - 1)\n",
    "\n",
    "    def to_mel(self, hertz):\n",
    "        return 2595.0 * np.log10(1 + hertz / 700.0)\n",
    "\n",
    "    def mix_audio(self, first_audio, second_audio):\n",
    "\n",
    "        a = np.random.uniform(0.4, 0.6)\n",
    "\n",
    "        shorter, longer = first_audio, second_audio\n",
    "\n",
    "        if shorter.shape[0] == longer.shape[0]:\n",
    "            if self.sample_audio:\n",
    "                return (longer + shorter) / 2.0\n",
    "            else:\n",
    "                longer = from_mel_to_audio(longer, **self.settings_features['process']) * a\n",
    "                shorter = from_mel_to_audio(shorter,\n",
    "                                            **self.settings_features['process'])\n",
    "                return feature_extraction((longer + shorter) / 2, **self.settings_features['process'])\n",
    "\n",
    "        if first_audio.shape[0] > second_audio.shape[0]:\n",
    "            shorter, longer = longer, shorter\n",
    "\n",
    "\n",
    "        if self.sample_audio:\n",
    "            start = random.randint(0, longer.shape[0] - 1 - shorter.shape[0])\n",
    "            end = start + shorter.shape[0]\n",
    "            longer *= a\n",
    "            longer[start:end] += shorter * (1 - a)\n",
    "        else:\n",
    "            longer = from_mel_to_audio(longer, **self.settings_features['process']) * a\n",
    "            shorter = from_mel_to_audio(shorter,\n",
    "                                        **self.settings_features['process'])\n",
    "            start = random.randint(0, longer.shape[0] - 1 - shorter.shape[0])\n",
    "            end = start + shorter.shape[0]\n",
    "            longer[start:end] += shorter * (1 - a)\n",
    "            longer = feature_extraction(longer,\n",
    "                                        **self.settings_features['process'])\n",
    "\n",
    "        return longer\n",
    "\n",
    "    def mix_labels(self, first_labels, second_labels):\n",
    "        if self.simple_concat_captions:\n",
    "            return np.hstack([first_labels[:-1], second_labels[1:]])\n",
    "        else:\n",
    "\n",
    "            first_token = first_labels[0]\n",
    "            last_token = first_labels[-1]\n",
    "            first_labels = first_labels[1:-1]\n",
    "            second_labels = second_labels[1:-1]\n",
    "            res = np.empty((first_labels.size + second_labels.size,),\n",
    "                           dtype=first_labels.dtype)\n",
    "            min_size = min(first_labels.size, second_labels.size)\n",
    "            res[0:2*min_size:2] = first_labels[:min_size]\n",
    "            res[1:2*min_size:2] = second_labels[:min_size]\n",
    "            if first_labels.size > second_labels.size:\n",
    "                res[min_size * 2:] = first_labels[min_size:]\n",
    "            elif second_labels.size > first_labels.size:\n",
    "                res[min_size*2:] = second_labels[min_size:]\n",
    "            res = np.concatenate(([first_token], res))\n",
    "            res = np.concatenate((res, [last_token]))\n",
    "            return res\n",
    "\n",
    "    def mix_audio_and_labels(self,\n",
    "                             first_audio, second_audio,\n",
    "                             first_labels, second_labels):\n",
    "        mixed_audio = self.mix_audio(first_audio, second_audio)\n",
    "        mixed_labels = self.mix_labels(first_labels, second_labels)\n",
    "\n",
    "        return mixed_audio, mixed_labels\n",
    "\n",
    "    def __call__(self, dataset, inputs):\n",
    "        resulted_audio, resulted_labels, filename = inputs[0], inputs[1], inputs[2]\n",
    "        if np.random.uniform() <= self.p:\n",
    "            random_sample = dataset.random_sample(sample_audio=self.sample_audio)\n",
    "            resulted_audio, resulted_labels = self.mix_audio_and_labels(\n",
    "                resulted_audio, random_sample[0],\n",
    "                resulted_labels, random_sample[1]\n",
    "            )\n",
    "        return resulted_audio, resulted_labels\n",
    "\n",
    "\n",
    "class AudioAugmentation:\n",
    "    # https://github.com/ex4sperans/freesound-classification\n",
    "    def __init__(self, p):\n",
    "\n",
    "        self.p = p\n",
    "        self.effects_chain = (\n",
    "            pysndfx.AudioEffectsChain()\n",
    "                .reverb(\n",
    "                reverberance=random.randrange(50),\n",
    "                room_scale=random.randrange(50),\n",
    "                stereo_depth=random.randrange(50)\n",
    "            )\n",
    "                .pitch(shift=random.randrange(-300, 300))\n",
    "                .overdrive(gain=random.randrange(2, 10))\n",
    "                .speed(random.uniform(0.9, 1.1))\n",
    "        )\n",
    "\n",
    "    def __call__(self, dataset, inputs):\n",
    "\n",
    "        resulted_audio = inputs[0]\n",
    "        captions = inputs[1]\n",
    "        del inputs\n",
    "        gc.collect()\n",
    "        if np.random.uniform() < self.p:\n",
    "            resulted_audio = torch.from_numpy(self.effects_chain(resulted_audio.numpy()))\n",
    "        return resulted_audio, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a5ddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysndfx in /home/hj20/anaconda3/lib/python3.7/site-packages (0.3.6)\r\n",
      "Requirement already satisfied: numpy in /home/hj20/anaconda3/lib/python3.7/site-packages (from pysndfx) (1.20.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pysndfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f78e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchaudio\n",
    "from numpy import load as np_load, ndarray\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pympler import muppy, summary\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University, Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['ClothoDataset']\n",
    "\n",
    "\n",
    "class ClothoDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_dir: Path,\n",
    "                 split: str,\n",
    "                 input_field_name: str,\n",
    "                 output_field_name: str,\n",
    "                 load_into_memory: bool,\n",
    "                 settings_audio,\n",
    "                 settings_features,\n",
    "                 online_preprocessing=True,\n",
    "                 transforms=None) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "        :param data_dir: Data directory with Clotho dataset files.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: The split to use (`development`, `validation`)\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name for the input values\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name for the output (target) values.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load the dataset into memory?\n",
    "        :type load_into_memory: bool\n",
    "        :param settings_audio: Settings about audio loading\n",
    "        :type dict\n",
    "        :param settings_features: Settings about audio processing\n",
    "        :type dict\n",
    "        :param indexes: Indexes of files, which depends on validation strategy\n",
    "        :type indexes: numpy array\n",
    "        :param transforms: List of transforms\n",
    "        :type transforms: list\n",
    "        \"\"\"\n",
    "\n",
    "        super(ClothoDataset, self).__init__()\n",
    "        self.online_preprocessing = online_preprocessing\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "        self.split = split\n",
    "\n",
    "        self.settings_audio = settings_audio\n",
    "        self.settings_features = settings_features\n",
    "\n",
    "        #if indexes is None:\n",
    "        self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        #else:\n",
    "        #    self.examples: List[Path] = list(np.array(sorted(the_dir.iterdir()))[indexes])\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.transforms = transforms\n",
    "        self.resampler = torchaudio.transforms.Resample(orig_freq=settings_features['process']['sr'],\n",
    "                                                        new_freq=settings_features['process']['sr_resample'])\n",
    "        if load_into_memory:\n",
    "            self.examples: List[ndarray] = [\n",
    "                np_load(str(f), allow_pickle=True)\n",
    "                for f in self.examples]\n",
    "        self.cnt = 0\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int) \\\n",
    "            -> Tuple[ndarray, ndarray, Path]:\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values, and the Path of the file.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray, Path\n",
    "        \"\"\"\n",
    "\n",
    "        ex = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex = np_load(str(ex), allow_pickle=True)\n",
    "        if self.online_preprocessing:\n",
    "            in_e = torchaudio.load(Path('data', 'clotho_audio_files', self.split, ex.file_name[0]))[0][0]\n",
    "            ou_e = ex[self.output_name].item()\n",
    "        else:\n",
    "            in_e, ou_e = [ex[i].item()\n",
    "                          for i in [self.input_name, self.output_name]]\n",
    "        filename = ex.file_name[0]\n",
    "        del ex\n",
    "        if self.transforms is not None:\n",
    "            for transform in self.transforms:\n",
    "                in_e, ou_e = transform(dataset=self, inputs=(in_e, ou_e, filename))\n",
    "        return in_e, ou_e, filename\n",
    "\n",
    "    def random_sample(self, sample_audio=False):\n",
    "        \"\"\"\n",
    "        Sampling audio or melspectrogram and encoded output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        item = random.randint(0, len(self.examples) - 1)\n",
    "        ex = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex = np_load(str(ex), allow_pickle=True)\n",
    "        if sample_audio:\n",
    "            thedir = Path('./data/clotho_audio_files/').joinpath(self.split)\n",
    "            filename = Path(thedir, ex.file_name[0])\n",
    "            in_e = torchaudio.load(filepath=filename)[0][0]\n",
    "            #in_e = self.resampler.forward(in_e)\n",
    "            ou_e = ex[self.output_name].item()\n",
    "        else:\n",
    "            in_e, ou_e = [ex[i].item()\n",
    "                          for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        return in_e, ou_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c764639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import MutableSequence, MutableMapping, Union,\\\n",
    "    Tuple, List\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import cat, zeros, from_numpy, ones, Tensor\n",
    "from numpy import ndarray\n",
    "\n",
    "#from data_handlers._clotho import ClothoDataset\n",
    "#from tools.augmentations import MixUp, AudioAugmentation\n",
    "\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University. Nikita Kuzmin -- Lomonosov Moscow State University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['get_clotho_loader']\n",
    "\n",
    "\n",
    "def _clotho_collate_fn(batch: MutableSequence[ndarray]) \\\n",
    "        -> Tuple[Tensor, Tensor, List[str]]:\n",
    "    \"\"\"Pads data.\n",
    "    For each batch, the maximum input and output\\\n",
    "    time-steps are calculated. Then, then input and\\\n",
    "    output data are padded to match the maximum time-steps.\n",
    "    The input data are padded with zeros in front, and\\\n",
    "    the output with] <EOS> tokens at the end.\n",
    "    :param batch: Batch data of batch x time x features.\\\n",
    "                  First element in the list are the input\\\n",
    "                  data, second the output data.\n",
    "    :type batch: list[numpy.ndarray]\n",
    "    :return: Padded data. First tensor is the input data\\\n",
    "             and second the output.\n",
    "    :rtype: torch.Tensor, torch.Tensor, list[str]\n",
    "    \"\"\"\n",
    "    max_input_t_steps = max([i[0].shape[0] for i in batch])\n",
    "    max_output_t_steps = max([i[1].shape[0] for i in batch])\n",
    "\n",
    "    file_names = [i[2] for i in batch]\n",
    "\n",
    "    #input_features = batch[0][0].shape[-1]\n",
    "    eos_token = batch[0][1][-1]\n",
    "    input_tensor = cat([\n",
    "        cat([zeros(\n",
    "            max_input_t_steps - i[0].shape[0]).float(),\n",
    "             i[0].float()]).unsqueeze(0) for i in batch])\n",
    "    output_tensor = cat([\n",
    "        cat([\n",
    "            from_numpy(i[1]).long(),\n",
    "            ones(max_output_t_steps - len(i[1])).mul(eos_token).long()\n",
    "        ]).unsqueeze(0) for i in batch])\n",
    "    return [input_tensor, output_tensor, file_names]\n",
    "\n",
    "\n",
    "def get_clotho_loader(split: str,\n",
    "                      is_training: bool,\n",
    "                      settings_data: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      settings_io: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[\n",
    "                              str, Union[str, MutableMapping[str, str]]]]],\n",
    "                      settings_features: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      settings_dataset: MutableMapping[\n",
    "                          str, Union[str, bool, MutableMapping[str, str]]],\n",
    "                      ) \\\n",
    "        -> DataLoader:\n",
    "    \"\"\"Gets the data loader.\n",
    "    :param split: Split to be used.\n",
    "    :type split: str\n",
    "    :param is_training: Is training data?\n",
    "    :type is_training: bool\n",
    "    :param settings_data: Data loading and dataset settings.\n",
    "    :type settings_data: dict\n",
    "    :param settings_io: Files I/O settings.\n",
    "    :type settings_io: dict\n",
    "    :param settings_features: Audio preprocessing features.\n",
    "    :type settings_features: dict\n",
    "    :param settings_dataset: Dataset settings.\n",
    "    :type settings_dataset: dict\n",
    "    :param indexes: Indexes of audio files, which depends on validation_strategy.\n",
    "    :type indexes: numpy array\n",
    "    :type settings_training: dict\n",
    "    :return: Data loader.\n",
    "    :rtype: torch.utils.data.DataLoader\n",
    "    \"\"\"\n",
    "    data_dir = Path(\n",
    "        settings_io['root_dirs']['data'],\n",
    "        settings_io['dataset']['features_dirs']['output'])\n",
    "\n",
    "    transforms = []\n",
    "    if settings_data['transforms'] == 'None' or (not is_training):\n",
    "        transforms = None\n",
    "    else:\n",
    "        if 'MixUp' in settings_data['transforms']:\n",
    "            print(settings_features['simple_concat_captions'], 'lalalalalal')\n",
    "            transforms.append(MixUp(p=settings_data['MixUp_p'],\n",
    "                              settings_features=settings_features,\n",
    "                              simple_concat_captions=settings_features['simple_concat_captions'],\n",
    "                              sample_audio=True))\n",
    "        if 'another' in settings_data['transforms']:\n",
    "            transforms.append(AudioAugmentation(p=settings_data['MixUp_p']))\n",
    "\n",
    "    #if settings_training['validation_strategy']\n",
    "    dataset = ClothoDataset(\n",
    "        data_dir=data_dir,\n",
    "        split=split,\n",
    "        input_field_name=settings_data['input_field_name'],\n",
    "        output_field_name=settings_data['output_field_name'],\n",
    "        load_into_memory=settings_data['load_into_memory'],\n",
    "        settings_audio=settings_dataset['audio'],\n",
    "        settings_features=settings_features,\n",
    "        transforms=transforms)\n",
    "\n",
    "    shuffle = settings_data['shuffle'] if is_training else False\n",
    "    drop_last = settings_data['drop_last'] if is_training else False\n",
    "    if is_training:\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=settings_data['batch_size'],\n",
    "            shuffle=shuffle,\n",
    "            num_workers=settings_data['num_workers'],\n",
    "            drop_last=drop_last,\n",
    "            # pin_memory=True,\n",
    "            collate_fn=_clotho_collate_fn)\n",
    "    else:\n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=40,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=2,\n",
    "            drop_last=drop_last,\n",
    "            # pin_memory=True,\n",
    "            collate_fn=_clotho_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bdc159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file='main_settings'\n",
    "file_ext='yaml'\n",
    "file_dir='settings' \n",
    "settings = file_io.load_yaml_file(Path(\n",
    "        file_dir, f'{config_file}.{file_ext}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "282439e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.file_io import load_audio_file\n",
    "from tools import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba6d900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True lalalalalal\n"
     ]
    }
   ],
   "source": [
    "training_data = get_clotho_loader(\n",
    "            settings_io['dataset']['features_dirs']['development'],\n",
    "            is_training=True,\n",
    "            settings_data=settings_data,\n",
    "            settings_io=settings_io,\n",
    "            settings_features=settings_features,\n",
    "            settings_dataset=settings_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da33e988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fc96caf",
   "metadata": {},
   "outputs": [],
   "source": [
    " =  get_clotho_loader(\n",
    "            settings_io['dataset']['features_dirs']['evaluation'],\n",
    "            is_training=False,\n",
    "            settings_data=settings_data,\n",
    "            settings_io=settings_io,\n",
    "            settings_features=settings_features,\n",
    "            settings_dataset=settings_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2e22027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c197368",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_io=settings['dirs_and_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586cf61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MixUp']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_data['transforms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46972f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_dirs': {'outputs': 'outputs', 'data': 'data'},\n",
       " 'dataset': {'development': 'development',\n",
       "  'evaluation': 'evaluation',\n",
       "  'features_dirs': {'output': 'data_splits_mel',\n",
       "   'development': 'development',\n",
       "   'evaluation': 'evaluation'},\n",
       "  'audio_dirs': {'downloaded': 'clotho_audio_files',\n",
       "   'output': 'data_splits_audio_mel',\n",
       "   'development': 'development',\n",
       "   'evaluation': 'evaluation'},\n",
       "  'annotations_dir': 'clotho_csv_files',\n",
       "  'pickle_files_dir': 'pickles',\n",
       "  'files': {'np_file_name_template': 'clotho_file_{audio_file_name}_{caption_index}.npy',\n",
       "   'words_list_file_name': 'words_list.p',\n",
       "   'words_counter_file_name': 'words_frequencies.p',\n",
       "   'characters_list_file_name': 'characters_list.p',\n",
       "   'characters_frequencies_file_name': 'characters_frequencies.p'}},\n",
       " 'model': {'model_dir': 'models',\n",
       "  'checkpoint_model_name': 'dcase_model_baseline.pt',\n",
       "  'pre_trained_model_name': 'dcase_model_baseline_pre_trained.pt'},\n",
       " 'logging': {'logger_dir': 'logging',\n",
       "  'caption_logger_file': 'captions_baseline.txt'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201948df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'development'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_io['dataset']['features_dirs']['development']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc641b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_data=settings['dnn_training_settings']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa82501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_field_name': 'features',\n",
       " 'output_field_name': 'words_ind',\n",
       " 'load_into_memory': False,\n",
       " 'transforms': ['MixUp'],\n",
       " 'MixUp_p': 0.5,\n",
       " 'batch_size': 16,\n",
       " 'shuffle': True,\n",
       " 'num_workers': 4,\n",
       " 'drop_last': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0419e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_features=settings['feature_extraction_settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f7120db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keep_raw_audio_data': False,\n",
       " 'simple_concat_captions': True,\n",
       " 'process': {'sr': 44100,\n",
       "  'sr_resample': 16000,\n",
       "  'nb_fft': 1024,\n",
       "  'hop_size': 512,\n",
       "  'nb_mels': 64,\n",
       "  'window_function': 'hann',\n",
       "  'center': True,\n",
       "  'f_min': 0.0,\n",
       "  'f_max': None,\n",
       "  'htk': False,\n",
       "  'power': 1.0,\n",
       "  'norm': 1}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04521df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dataset=settings['dataset_creation_settings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd805b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workflow': {'create_dataset': True, 'validate_dataset': False},\n",
       " 'annotations': {'development_file': 'clotho_captions_development.csv',\n",
       "  'evaluation_file': 'clotho_captions_evaluation.csv',\n",
       "  'audio_file_column': 'file_name',\n",
       "  'captions_fields_prefix': 'caption_{}',\n",
       "  'use_special_tokens': True,\n",
       "  'nb_captions': 5,\n",
       "  'keep_case': False,\n",
       "  'remove_punctuation_words': True,\n",
       "  'remove_punctuation_chars': True,\n",
       "  'use_unique_words_per_caption': False,\n",
       "  'use_unique_chars_per_caption': False},\n",
       " 'audio': {'sr': 44100, 'to_mono': True, 'max_abs_value': 1.0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from typing import Tuple, List, AnyStr, Union\n",
    "from pathlib import Path\n",
    "\n",
    "from numpy import ndarray, recarray\n",
    "from torch.utils.data import Dataset\n",
    "from numpy import load as np_load\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "__author__ = 'Konstantinos Drossos -- Tampere University'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['ClothoDataset']\n",
    "\n",
    "\n",
    "class ClothoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir: Path,\n",
    "                 split: AnyStr,\n",
    "                 input_field_name: AnyStr,\n",
    "                 output_field_name: AnyStr,\n",
    "                 load_into_memory: bool,\n",
    "                 transforms=transforms) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "\n",
    "        :param data_dir: Directory with data.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name of the clotho data\\\n",
    "                                 to be used as input data to the\\\n",
    "                                 method.\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name of the clotho data\\\n",
    "                                 to be used as output data to the\\\n",
    "                                 method.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load all data into memory?\n",
    "        :type load_into_memory: bool\n",
    "        \"\"\"\n",
    "        super(ClothoDataset, self).__init__()\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "\n",
    "        self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.transforms=transforms\n",
    "        if load_into_memory:\n",
    "            self.examples: List[recarray] = [np_load(str(f), allow_pickle=True)\n",
    "                                             for f in self.examples]\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int) \\\n",
    "            -> Tuple[ndarray, ndarray]:\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray\n",
    "        \"\"\"\n",
    "        ex: Union[Path, recarray] = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex: recarray = np_load(str(ex), allow_pickle=True)\n",
    "\n",
    "        in_e, ou_e = [ex[i].item() for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        return in_e, ou_e\n",
    "\n",
    "\n",
    "class ClothoDatasetEval(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir: Path,\n",
    "                 split: AnyStr,\n",
    "                 input_field_name: AnyStr,\n",
    "                 output_field_name: AnyStr,\n",
    "                 load_into_memory: bool) \\\n",
    "            -> None:\n",
    "        \"\"\"Initialization of a Clotho dataset object.\n",
    "\n",
    "        :param data_dir: Directory with data.\n",
    "        :type data_dir: pathlib.Path\n",
    "        :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "        :type split: str\n",
    "        :param input_field_name: Field name of the clotho data\\\n",
    "                                 to be used as input data to the\\\n",
    "                                 method.\n",
    "        :type input_field_name: str\n",
    "        :param output_field_name: Field name of the clotho data\\\n",
    "                                 to be used as output data to the\\\n",
    "                                 method.\n",
    "        :type output_field_name: str\n",
    "        :param load_into_memory: Load all data into memory?\n",
    "        :type load_into_memory: bool\n",
    "        \"\"\"\n",
    "        super(ClothoDatasetEval, self).__init__()\n",
    "        the_dir: Path = data_dir.joinpath(split)\n",
    "        if split == 'evaluation':\n",
    "            self.examples: List[Path] = sorted(the_dir.iterdir())[::5]  # changed\n",
    "        else:\n",
    "            self.examples: List[Path] = sorted(the_dir.iterdir())  # changed\n",
    "        # self.examples: List[Path] = sorted(the_dir.iterdir())\n",
    "        self.input_name: str = input_field_name\n",
    "        self.output_name: str = output_field_name\n",
    "        self.load_into_memory: bool = load_into_memory\n",
    "        self.data_dir = the_dir\n",
    "\n",
    "        if load_into_memory:\n",
    "            self.examples: List[recarray] = [np_load(str(f), allow_pickle=True)\n",
    "                                             for f in self.examples]\n",
    "\n",
    "    def __len__(self) \\\n",
    "            -> int:\n",
    "        \"\"\"Gets the amount of examples in the dataset.\n",
    "\n",
    "        :return: Amount of examples in the dataset.\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    item: int):\n",
    "        \"\"\"Gets an example from the dataset.\n",
    "\n",
    "        :param item: Index of the item.\n",
    "        :type item: int\n",
    "        :return: Input and output values.\n",
    "        :rtype: numpy.ndarray. numpy.ndarray\n",
    "        \"\"\"\n",
    "        ex: Union[Path, recarray] = self.examples[item]\n",
    "        if not self.load_into_memory:\n",
    "            ex: recarray = np_load(str(ex), allow_pickle=True)\n",
    "\n",
    "        in_e, ou_e = [ex[i].item() for i in [self.input_name, self.output_name]]\n",
    "\n",
    "        all_ref = get_all_ref(ex['file_name'].item(), self.data_dir)\n",
    "\n",
    "        filename = str(ex['file_name'].item())\n",
    "        out_len = len(ou_e)\n",
    "        return in_e, ou_e, all_ref, filename,out_len\n",
    "\n",
    "\n",
    "def get_all_ref(filename, data_dir):\n",
    "    filename = str(filename)\n",
    "    # tgt = [np.load(d, allow_pickle=True).words_ind.tolist()\n",
    "    tgt = [np.load(d, allow_pickle=True)['words_ind'].item().tolist()\n",
    "           for d in [os.path.join(data_dir, 'clotho_file_{filename}.wav_{i}.npy'.\n",
    "                                  format(filename=filename[:-4],  # 删除'.wav'\n",
    "                                         i=i)) for i in range(5)]  # wav_0-wav_4\n",
    "           ]\n",
    "    return tgt\n",
    "# EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa295a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff041f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from typing import Callable, Union, Tuple, AnyStr, Optional\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from .clotho_dataset import ClothoDataset, ClothoDatasetEval\n",
    "from .collate_fn import clotho_collate_fn, clotho_collate_fn_eval\n",
    "\n",
    "__author__ = 'Konstantinos Drossos'\n",
    "__docformat__ = 'reStructuredText'\n",
    "__all__ = ['get_clotho_loader']\n",
    "\n",
    "\n",
    "def get_clotho_loader(data_dir: Path,\n",
    "                      split: str,\n",
    "                      input_field_name: str,\n",
    "                      output_field_name: str,\n",
    "                      load_into_memory: bool,\n",
    "                      batch_size: int,\n",
    "                      nb_t_steps_pad: Union[AnyStr, Tuple[int, int]],\n",
    "                      shuffle: Optional[bool] = True,\n",
    "                      drop_last: Optional[bool] = True,\n",
    "                      input_pad_at: Optional[str] = 'start',\n",
    "                      output_pad_at: Optional[str] = 'end',\n",
    "                      num_workers: Optional[int] = 1,\n",
    "                      return_reference: Optional[bool] = False,\n",
    "                      augment: Optional[bool] = False) \\\n",
    "        -> DataLoader:\n",
    "    \"\"\"Gets the clotho data loader.\n",
    "\n",
    "    :param return_reference:\n",
    "    :param data_dir: Directory with data.\n",
    "    :type data_dir: pathlib.Path\n",
    "    :param split: Split to use (i.e. 'development', 'evaluation')\n",
    "    :type split: str\n",
    "    :param input_field_name: Field name of the clotho data\\\n",
    "                             to be used as input data to the\\\n",
    "                             method.\n",
    "    :type input_field_name: str\n",
    "    :param output_field_name: Field name of the clotho data\\\n",
    "                             to be used as output data to the\\\n",
    "                             method.\n",
    "    :type output_field_name: str\n",
    "    :param load_into_memory: Load all data into memory?\n",
    "    :type load_into_memory: bool\n",
    "    :param batch_size: Batch size to use.\n",
    "    :type batch_size: int\n",
    "    :param nb_t_steps_pad: Number of time steps to\\\n",
    "                           pad/truncate to. Cab use\\\n",
    "                           'max', 'min', or exact number\\\n",
    "                           e.g. (1024, 10).\n",
    "    :type nb_t_steps_pad: str|(int, int)\n",
    "    :param shuffle: Shuffle examples? Defaults to True.\n",
    "    :type shuffle: bool, optional\n",
    "    :param drop_last: Drop the last examples if not making\\\n",
    "                      a batch of `batch_size`? Defaults to True.\n",
    "    :type drop_last: bool, optional\n",
    "    :param input_pad_at: Pad input at the start or\\\n",
    "                         at the end?\n",
    "    :type input_pad_at: str\n",
    "    :param output_pad_at: Pad output at the start or\\\n",
    "                          at the end?\n",
    "    :type output_pad_at: str\n",
    "    :param num_workers: Amount of workers, defaults to 1.\n",
    "    :type num_workers: int, optional\n",
    "    :return: Dataloader for Clotho data.\n",
    "    :rtype: torch.utils.data.dataloader.DataLoader\n",
    "    \"\"\"\n",
    "    if return_reference:\n",
    "        dataset: ClothoDatasetEval = ClothoDatasetEval(\n",
    "            data_dir=data_dir, split=split,\n",
    "            input_field_name=input_field_name,\n",
    "            output_field_name=output_field_name,\n",
    "            load_into_memory=load_into_memory\n",
    "            transforms=trans)\n",
    "\n",
    "        collate_fn: Callable = partial(\n",
    "            clotho_collate_fn_eval,\n",
    "            nb_t_steps=nb_t_steps_pad,\n",
    "            input_pad_at=input_pad_at,\n",
    "            output_pad_at=output_pad_at, split=split, augment=augment)\n",
    "    else:\n",
    "        dataset: ClothoDataset = ClothoDataset(\n",
    "            data_dir=data_dir, split=split,\n",
    "            input_field_name=input_field_name,\n",
    "            output_field_name=output_field_name,\n",
    "            load_into_memory=load_into_memory)\n",
    "\n",
    "        collate_fn: Callable = partial(\n",
    "            clotho_collate_fn,\n",
    "            nb_t_steps=nb_t_steps_pad,\n",
    "            input_pad_at=input_pad_at,\n",
    "            output_pad_at=output_pad_at)\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset=dataset, batch_size=batch_size,\n",
    "        shuffle=shuffle, num_workers=num_workers,\n",
    "        drop_last=drop_last, collate_fn=collate_fn)\n",
    "\n",
    "# EOF\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcaset6",
   "language": "python",
   "name": "dcase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
